{"version":3,"sources":["turbopack:///[project]/node_modules/ws/lib/constants.js","turbopack:///[project]/node_modules/ws/lib/buffer-util.js","turbopack:///[project]/node_modules/ws/lib/limiter.js","turbopack:///[project]/node_modules/ws/lib/permessage-deflate.js","turbopack:///[project]/node_modules/ws/lib/validation.js","turbopack:///[project]/node_modules/ws/lib/receiver.js","turbopack:///[project]/node_modules/ws/lib/sender.js","turbopack:///[project]/node_modules/ws/lib/event-target.js","turbopack:///[project]/node_modules/ws/lib/extension.js","turbopack:///[project]/node_modules/ws/lib/websocket.js","turbopack:///[project]/node_modules/ws/lib/stream.js","turbopack:///[project]/node_modules/ws/lib/subprotocol.js","turbopack:///[project]/node_modules/ws/lib/websocket-server.js","turbopack:///[project]/node_modules/next/src/server/route-modules/app-page/vendored/rsc/react-server-dom-turbopack-server.ts","turbopack:///[project]/node_modules/next/src/build/webpack/loaders/next-flight-loader/server-reference.ts","turbopack:///[project]/node_modules/next/src/server/lib/trace/constants.ts","turbopack:///[project]/node_modules/next/src/shared/lib/is-thenable.ts","turbopack:///[project]/node_modules/next/src/server/lib/trace/tracer.ts","turbopack:///[project]/node_modules/next/src/server/lib/clone-response.ts","turbopack:///[project]/node_modules/next/src/server/lib/dedupe-fetch.ts","turbopack:///[project]/node_modules/next/src/server/response-cache/types.ts","turbopack:///[project]/node_modules/next/src/lib/detached-promise.ts","turbopack:///[project]/node_modules/next/src/lib/batcher.ts","turbopack:///[project]/node_modules/next/src/server/stream-utils/encoded-tags.ts","turbopack:///[project]/node_modules/next/src/server/stream-utils/uint8array-helpers.ts","turbopack:///[project]/node_modules/next/src/shared/lib/errors/constants.ts","turbopack:///[project]/node_modules/next/src/shared/lib/segment-cache/output-export-prefetch-encoding.ts","turbopack:///[project]/node_modules/next/src/client/components/app-router-headers.ts","turbopack:///[project]/node_modules/next/src/shared/lib/hash.ts","turbopack:///[project]/node_modules/next/src/shared/lib/router/utils/cache-busting-search-param.ts","turbopack:///[project]/node_modules/next/src/server/stream-utils/node-web-streams-helper.ts","turbopack:///[project]/node_modules/next/src/server/request-meta.ts","turbopack:///[project]/node_modules/next/src/server/base-http/helpers.ts","turbopack:///[project]/node_modules/next/src/server/web/spec-extension/adapters/next-request.ts","turbopack:///[project]/node_modules/next/src/server/client-component-renderer-logger.ts","turbopack:///[project]/node_modules/next/src/server/pipe-readable.ts","turbopack:///[project]/node_modules/next/src/server/render-result.ts","turbopack:///[project]/node_modules/next/src/server/route-kind.ts","turbopack:///[project]/node_modules/next/src/server/response-cache/utils.ts","turbopack:///[project]/node_modules/next/src/server/response-cache/index.ts","turbopack:///[project]/node_modules/next/src/server/lib/patch-fetch.ts","turbopack:///[project]/node_modules/next/src/server/web/spec-extension/unstable-cache.ts","turbopack:///[project]/node_modules/next/src/shared/lib/router/utils/sorted-routes.ts","turbopack:///[project]/node_modules/next/src/shared/lib/page-path/ensure-leading-slash.ts","turbopack:///[project]/node_modules/next/src/shared/lib/segment.ts","turbopack:///[project]/node_modules/next/src/shared/lib/router/utils/app-paths.ts","turbopack:///[project]/node_modules/next/src/shared/lib/router/utils/interception-routes.ts","turbopack:///[project]/node_modules/next/src/shared/lib/router/utils/is-dynamic.ts","turbopack:///[project]/node_modules/next/src/shared/lib/router/utils/index.ts","turbopack:///[project]/node_modules/next/src/server/web/spec-extension/revalidate.ts","turbopack:///[project]/node_modules/next/src/server/web/spec-extension/unstable-no-store.ts","turbopack:///[project]/node_modules/next/src/server/use-cache/cache-life.ts","turbopack:///[project]/node_modules/next/src/server/use-cache/cache-tag.ts","turbopack:///[project]/node_modules/next/cache.js","turbopack:///[project]/node_modules/next/src/build/webpack/loaders/next-flight-loader/action-validate.ts","turbopack:///[project]/services/db.ts","turbopack:///[project]/node_modules/openai/internal/tslib.mjs","turbopack:///[project]/node_modules/ws/wrapper.mjs","turbopack:///[project]/node_modules/openai/src/_vendor/partial-json-parser/parser.ts","turbopack:///[project]/node_modules/openai/src/internal/utils/bytes.ts","turbopack:///[project]/node_modules/openai/src/core/uploads.ts","turbopack:///[project]/node_modules/openai/src/internal/qs/stringify.ts","turbopack:///[project]/node_modules/openai/src/internal/qs/utils.ts","turbopack:///[project]/node_modules/openai/src/internal/to-file.ts","turbopack:///[project]/node_modules/openai/src/version.ts","turbopack:///[project]/node_modules/openai/src/internal/utils/path.ts","turbopack:///[project]/node_modules/openai/src/lib/ResponsesParser.ts","turbopack:///[project]/node_modules/openai/src/azure.ts","turbopack:///[project]/node_modules/openai/src/internal/qs/formats.ts","turbopack:///[project]/node_modules/openai/src/lib/chatCompletionUtils.ts","turbopack:///[project]/node_modules/openai/src/resources/uploads/parts.ts","turbopack:///[project]/node_modules/openai/src/resources/beta/chatkit/sessions.ts","turbopack:///[project]/node_modules/openai/src/internal/utils/log.ts","turbopack:///[project]/node_modules/openai/src/resources/beta/chatkit/threads.ts","turbopack:///[project]/node_modules/openai/src/resources/chat/completions/index.ts","turbopack:///[project]/node_modules/openai/src/resources/beta/chatkit/chatkit.ts","turbopack:///[project]/node_modules/openai/src/resources/beta/threads/messages.ts","turbopack:///[project]/node_modules/openai/src/resources/beta/threads/runs/steps.ts","turbopack:///[project]/node_modules/openai/src/internal/parse.ts","turbopack:///[project]/node_modules/openai/src/internal/utils/base64.ts","turbopack:///[project]/node_modules/openai/src/resources/chat/index.ts","turbopack:///[project]/node_modules/openai/src/resources/beta/threads/runs/runs.ts","turbopack:///[project]/node_modules/openai/src/internal/headers.ts","turbopack:///[project]/node_modules/openai/src/resources/beta/threads/threads.ts","turbopack:///[project]/node_modules/openai/src/resources/beta/beta.ts","turbopack:///[project]/node_modules/openai/src/resources/audio/speech.ts","turbopack:///[project]/node_modules/openai/src/resources/completions.ts","turbopack:///[project]/node_modules/openai/src/resources/containers/files/content.ts","turbopack:///[project]/node_modules/openai/src/resources/containers/files/files.ts","turbopack:///[project]/node_modules/openai/src/resources/containers/containers.ts","turbopack:///[project]/node_modules/openai/src/lib/ChatCompletionRunner.ts","turbopack:///[project]/node_modules/openai/src/resources/conversations/items.ts","turbopack:///[project]/node_modules/openai/src/resources/audio/transcriptions.ts","turbopack:///[project]/node_modules/openai/src/resources/conversations/conversations.ts","turbopack:///[project]/node_modules/openai/src/resources/embeddings.ts","turbopack:///[project]/node_modules/openai/src/internal/utils/values.ts","turbopack:///[project]/node_modules/openai/src/resources/evals/runs/output-items.ts","turbopack:///[project]/node_modules/openai/src/resources/evals/runs/runs.ts","turbopack:///[project]/node_modules/openai/src/resources/chat/completions/completions.ts","turbopack:///[project]/node_modules/openai/src/resources/evals/evals.ts","turbopack:///[project]/node_modules/openai/src/resources/audio/translations.ts","turbopack:///[project]/node_modules/openai/src/resources/files.ts","turbopack:///[project]/node_modules/openai/src/resources/fine-tuning/methods.ts","turbopack:///[project]/node_modules/openai/src/resources/fine-tuning/alpha/graders.ts","turbopack:///[project]/node_modules/openai/src/internal/detect-platform.ts","turbopack:///[project]/node_modules/openai/src/resources/fine-tuning/alpha/alpha.ts","turbopack:///[project]/node_modules/openai/src/resources/fine-tuning/checkpoints/permissions.ts","turbopack:///[project]/node_modules/openai/src/resources/audio/audio.ts","turbopack:///[project]/node_modules/openai/src/core/error.ts","turbopack:///[project]/node_modules/openai/src/resources/fine-tuning/jobs/checkpoints.ts","turbopack:///[project]/node_modules/openai/src/resources/fine-tuning/jobs/jobs.ts","turbopack:///[project]/node_modules/openai/src/resources/fine-tuning/fine-tuning.ts","turbopack:///[project]/node_modules/openai/src/resources/chat/completions/messages.ts","turbopack:///[project]/node_modules/openai/src/resources/batches.ts","turbopack:///[project]/node_modules/openai/src/resources/graders/grader-models.ts","turbopack:///[project]/node_modules/openai/src/resources/graders/graders.ts","turbopack:///[project]/node_modules/openai/src/resources/images.ts","turbopack:///[project]/node_modules/openai/src/resources/models.ts","turbopack:///[project]/node_modules/openai/src/resources/beta/assistants.ts","turbopack:///[project]/node_modules/openai/src/resources/moderations.ts","turbopack:///[project]/node_modules/openai/src/resources/realtime/calls.ts","turbopack:///[project]/node_modules/openai/src/resources/realtime/client-secrets.ts","turbopack:///[project]/node_modules/openai/src/resources/realtime/realtime.ts","turbopack:///[project]/node_modules/openai/src/resources/chat/chat.ts","turbopack:///[project]/node_modules/openai/src/resources/beta/realtime/sessions.ts","turbopack:///[project]/node_modules/openai/src/resources/responses/input-items.ts","turbopack:///[project]/node_modules/openai/src/resources/responses/input-tokens.ts","turbopack:///[project]/node_modules/openai/src/resources/responses/responses.ts","turbopack:///[project]/node_modules/openai/src/resources/uploads/uploads.ts","turbopack:///[project]/node_modules/openai/src/resources/vector-stores/file-batches.ts","turbopack:///[project]/node_modules/openai/src/resources/beta/realtime/transcription-sessions.ts","turbopack:///[project]/node_modules/openai/src/resources/vector-stores/files.ts","turbopack:///[project]/node_modules/openai/src/resources/vector-stores/vector-stores.ts","turbopack:///[project]/node_modules/openai/src/resources/videos.ts","turbopack:///[project]/node_modules/openai/src/resources/beta/realtime/realtime.ts","turbopack:///[project]/node_modules/openai/src/index.ts","turbopack:///[project]/node_modules/openai/src/resources/fine-tuning/checkpoints/checkpoints.ts","turbopack:///[project]/node_modules/openai/src/lib/parser.ts","turbopack:///[project]/node_modules/openai/src/internal/uploads.ts","turbopack:///[project]/node_modules/openai/src/internal/request-options.ts","turbopack:///[project]/node_modules/openai/src/internal/utils/sleep.ts","turbopack:///[project]/node_modules/openai/src/lib/ChatCompletionStreamingRunner.ts","turbopack:///[project]/app/actions.ts","turbopack:///[project]/services/geminiService.ts","turbopack:///[project]/node_modules/openai/src/internal/decoders/line.ts","turbopack:///[project]/node_modules/openai/src/core/resource.ts","turbopack:///[project]/node_modules/openai/src/lib/Util.ts","turbopack:///[project]/node_modules/openai/src/resources/webhooks.ts","turbopack:///[project]/node_modules/openai/src/lib/AssistantStream.ts","turbopack:///[project]/node_modules/openai/src/lib/ChatCompletionStream.ts","turbopack:///[project]/node_modules/openai/src/core/streaming.ts","turbopack:///[project]/node_modules/openai/src/internal/utils/uuid.ts","turbopack:///[project]/node_modules/openai/src/internal/shims.ts","turbopack:///[project]/node_modules/openai/src/lib/EventStream.ts","turbopack:///[project]/node_modules/openai/src/internal/errors.ts","turbopack:///[project]/node_modules/openai/src/core/pagination.ts","turbopack:///[project]/node_modules/openai/src/lib/AbstractChatCompletionRunner.ts","turbopack:///[project]/node_modules/openai/src/client.ts","turbopack:///[project]/node_modules/openai/src/resources/index.ts","turbopack:///[project]/node_modules/openai/src/lib/responses/ResponseStream.ts","turbopack:///[project]/node_modules/openai/src/internal/utils/env.ts","turbopack:///[project]/node_modules/openai/src/core/api-promise.ts","turbopack:///[project]/node_modules/@google/genai/src/_base_url.ts","turbopack:///[project]/node_modules/@google/genai/src/_common.ts","turbopack:///[project]/node_modules/@google/genai/src/_base_transformers.ts","turbopack:///[project]/node_modules/@google/genai/src/converters/_operations_converters.ts","turbopack:///[project]/node_modules/@google/genai/src/types.ts","turbopack:///[project]/node_modules/@google/genai/src/_transformers.ts","turbopack:///[project]/node_modules/@google/genai/src/converters/_batches_converters.ts","turbopack:///[project]/node_modules/@google/genai/src/pagers.ts","turbopack:///[project]/node_modules/@google/genai/src/batches.ts","turbopack:///[project]/node_modules/@google/genai/src/converters/_caches_converters.ts","turbopack:///[project]/node_modules/@google/genai/src/caches.ts","turbopack:///[project]/node_modules/@google/genai/src/chats.ts","turbopack:///[project]/node_modules/@google/genai/src/errors.ts","turbopack:///[project]/node_modules/@google/genai/src/converters/_files_converters.ts","turbopack:///[project]/node_modules/@google/genai/src/files.ts","turbopack:///[project]/node_modules/@google/genai/src/converters/_live_converters.ts","turbopack:///[project]/node_modules/@google/genai/src/converters/_models_converters.ts","turbopack:///[project]/node_modules/@google/genai/src/_api_client.ts","turbopack:///[project]/node_modules/@google/genai/src/mcp/_mcp.ts","turbopack:///[project]/node_modules/@google/genai/src/music.ts","turbopack:///[project]/node_modules/@google/genai/src/live.ts","turbopack:///[project]/node_modules/@google/genai/src/_afc.ts","turbopack:///[project]/node_modules/@google/genai/src/models.ts","turbopack:///[project]/node_modules/@google/genai/src/operations.ts","turbopack:///[project]/node_modules/@google/genai/src/converters/_tokens_converters.ts","turbopack:///[project]/node_modules/@google/genai/src/tokens.ts","turbopack:///[project]/node_modules/@google/genai/src/node/_node_auth.ts","turbopack:///[project]/node_modules/@google/genai/src/node/_node_downloader.ts","turbopack:///[project]/node_modules/@google/genai/src/node/_node_websocket.ts","turbopack:///[project]/node_modules/@google/genai/src/converters/_tunings_converters.ts","turbopack:///[project]/node_modules/@google/genai/src/tunings.ts","turbopack:///[project]/node_modules/@google/genai/src/cross/_cross_uploader.ts","turbopack:///[project]/node_modules/@google/genai/src/node/_node_uploader.ts","turbopack:///[project]/node_modules/@google/genai/src/node/node_client.ts"],"sourcesContent":["'use strict';\n\nconst BINARY_TYPES = ['nodebuffer', 'arraybuffer', 'fragments'];\nconst hasBlob = typeof Blob !== 'undefined';\n\nif (hasBlob) BINARY_TYPES.push('blob');\n\nmodule.exports = {\n  BINARY_TYPES,\n  EMPTY_BUFFER: Buffer.alloc(0),\n  GUID: '258EAFA5-E914-47DA-95CA-C5AB0DC85B11',\n  hasBlob,\n  kForOnEventAttribute: Symbol('kIsForOnEventAttribute'),\n  kListener: Symbol('kListener'),\n  kStatusCode: Symbol('status-code'),\n  kWebSocket: Symbol('websocket'),\n  NOOP: () => {}\n};\n","'use strict';\n\nconst { EMPTY_BUFFER } = require('./constants');\n\nconst FastBuffer = Buffer[Symbol.species];\n\n/**\n * Merges an array of buffers into a new buffer.\n *\n * @param {Buffer[]} list The array of buffers to concat\n * @param {Number} totalLength The total length of buffers in the list\n * @return {Buffer} The resulting buffer\n * @public\n */\nfunction concat(list, totalLength) {\n  if (list.length === 0) return EMPTY_BUFFER;\n  if (list.length === 1) return list[0];\n\n  const target = Buffer.allocUnsafe(totalLength);\n  let offset = 0;\n\n  for (let i = 0; i < list.length; i++) {\n    const buf = list[i];\n    target.set(buf, offset);\n    offset += buf.length;\n  }\n\n  if (offset < totalLength) {\n    return new FastBuffer(target.buffer, target.byteOffset, offset);\n  }\n\n  return target;\n}\n\n/**\n * Masks a buffer using the given mask.\n *\n * @param {Buffer} source The buffer to mask\n * @param {Buffer} mask The mask to use\n * @param {Buffer} output The buffer where to store the result\n * @param {Number} offset The offset at which to start writing\n * @param {Number} length The number of bytes to mask.\n * @public\n */\nfunction _mask(source, mask, output, offset, length) {\n  for (let i = 0; i < length; i++) {\n    output[offset + i] = source[i] ^ mask[i & 3];\n  }\n}\n\n/**\n * Unmasks a buffer using the given mask.\n *\n * @param {Buffer} buffer The buffer to unmask\n * @param {Buffer} mask The mask to use\n * @public\n */\nfunction _unmask(buffer, mask) {\n  for (let i = 0; i < buffer.length; i++) {\n    buffer[i] ^= mask[i & 3];\n  }\n}\n\n/**\n * Converts a buffer to an `ArrayBuffer`.\n *\n * @param {Buffer} buf The buffer to convert\n * @return {ArrayBuffer} Converted buffer\n * @public\n */\nfunction toArrayBuffer(buf) {\n  if (buf.length === buf.buffer.byteLength) {\n    return buf.buffer;\n  }\n\n  return buf.buffer.slice(buf.byteOffset, buf.byteOffset + buf.length);\n}\n\n/**\n * Converts `data` to a `Buffer`.\n *\n * @param {*} data The data to convert\n * @return {Buffer} The buffer\n * @throws {TypeError}\n * @public\n */\nfunction toBuffer(data) {\n  toBuffer.readOnly = true;\n\n  if (Buffer.isBuffer(data)) return data;\n\n  let buf;\n\n  if (data instanceof ArrayBuffer) {\n    buf = new FastBuffer(data);\n  } else if (ArrayBuffer.isView(data)) {\n    buf = new FastBuffer(data.buffer, data.byteOffset, data.byteLength);\n  } else {\n    buf = Buffer.from(data);\n    toBuffer.readOnly = false;\n  }\n\n  return buf;\n}\n\nmodule.exports = {\n  concat,\n  mask: _mask,\n  toArrayBuffer,\n  toBuffer,\n  unmask: _unmask\n};\n\n/* istanbul ignore else  */\nif (!process.env.WS_NO_BUFFER_UTIL) {\n  try {\n    const bufferUtil = require('bufferutil');\n\n    module.exports.mask = function (source, mask, output, offset, length) {\n      if (length < 48) _mask(source, mask, output, offset, length);\n      else bufferUtil.mask(source, mask, output, offset, length);\n    };\n\n    module.exports.unmask = function (buffer, mask) {\n      if (buffer.length < 32) _unmask(buffer, mask);\n      else bufferUtil.unmask(buffer, mask);\n    };\n  } catch (e) {\n    // Continue regardless of the error.\n  }\n}\n","'use strict';\n\nconst kDone = Symbol('kDone');\nconst kRun = Symbol('kRun');\n\n/**\n * A very simple job queue with adjustable concurrency. Adapted from\n * https://github.com/STRML/async-limiter\n */\nclass Limiter {\n  /**\n   * Creates a new `Limiter`.\n   *\n   * @param {Number} [concurrency=Infinity] The maximum number of jobs allowed\n   *     to run concurrently\n   */\n  constructor(concurrency) {\n    this[kDone] = () => {\n      this.pending--;\n      this[kRun]();\n    };\n    this.concurrency = concurrency || Infinity;\n    this.jobs = [];\n    this.pending = 0;\n  }\n\n  /**\n   * Adds a job to the queue.\n   *\n   * @param {Function} job The job to run\n   * @public\n   */\n  add(job) {\n    this.jobs.push(job);\n    this[kRun]();\n  }\n\n  /**\n   * Removes a job from the queue and runs it if possible.\n   *\n   * @private\n   */\n  [kRun]() {\n    if (this.pending === this.concurrency) return;\n\n    if (this.jobs.length) {\n      const job = this.jobs.shift();\n\n      this.pending++;\n      job(this[kDone]);\n    }\n  }\n}\n\nmodule.exports = Limiter;\n","'use strict';\n\nconst zlib = require('zlib');\n\nconst bufferUtil = require('./buffer-util');\nconst Limiter = require('./limiter');\nconst { kStatusCode } = require('./constants');\n\nconst FastBuffer = Buffer[Symbol.species];\nconst TRAILER = Buffer.from([0x00, 0x00, 0xff, 0xff]);\nconst kPerMessageDeflate = Symbol('permessage-deflate');\nconst kTotalLength = Symbol('total-length');\nconst kCallback = Symbol('callback');\nconst kBuffers = Symbol('buffers');\nconst kError = Symbol('error');\n\n//\n// We limit zlib concurrency, which prevents severe memory fragmentation\n// as documented in https://github.com/nodejs/node/issues/8871#issuecomment-250915913\n// and https://github.com/websockets/ws/issues/1202\n//\n// Intentionally global; it's the global thread pool that's an issue.\n//\nlet zlibLimiter;\n\n/**\n * permessage-deflate implementation.\n */\nclass PerMessageDeflate {\n  /**\n   * Creates a PerMessageDeflate instance.\n   *\n   * @param {Object} [options] Configuration options\n   * @param {(Boolean|Number)} [options.clientMaxWindowBits] Advertise support\n   *     for, or request, a custom client window size\n   * @param {Boolean} [options.clientNoContextTakeover=false] Advertise/\n   *     acknowledge disabling of client context takeover\n   * @param {Number} [options.concurrencyLimit=10] The number of concurrent\n   *     calls to zlib\n   * @param {(Boolean|Number)} [options.serverMaxWindowBits] Request/confirm the\n   *     use of a custom server window size\n   * @param {Boolean} [options.serverNoContextTakeover=false] Request/accept\n   *     disabling of server context takeover\n   * @param {Number} [options.threshold=1024] Size (in bytes) below which\n   *     messages should not be compressed if context takeover is disabled\n   * @param {Object} [options.zlibDeflateOptions] Options to pass to zlib on\n   *     deflate\n   * @param {Object} [options.zlibInflateOptions] Options to pass to zlib on\n   *     inflate\n   * @param {Boolean} [isServer=false] Create the instance in either server or\n   *     client mode\n   * @param {Number} [maxPayload=0] The maximum allowed message length\n   */\n  constructor(options, isServer, maxPayload) {\n    this._maxPayload = maxPayload | 0;\n    this._options = options || {};\n    this._threshold =\n      this._options.threshold !== undefined ? this._options.threshold : 1024;\n    this._isServer = !!isServer;\n    this._deflate = null;\n    this._inflate = null;\n\n    this.params = null;\n\n    if (!zlibLimiter) {\n      const concurrency =\n        this._options.concurrencyLimit !== undefined\n          ? this._options.concurrencyLimit\n          : 10;\n      zlibLimiter = new Limiter(concurrency);\n    }\n  }\n\n  /**\n   * @type {String}\n   */\n  static get extensionName() {\n    return 'permessage-deflate';\n  }\n\n  /**\n   * Create an extension negotiation offer.\n   *\n   * @return {Object} Extension parameters\n   * @public\n   */\n  offer() {\n    const params = {};\n\n    if (this._options.serverNoContextTakeover) {\n      params.server_no_context_takeover = true;\n    }\n    if (this._options.clientNoContextTakeover) {\n      params.client_no_context_takeover = true;\n    }\n    if (this._options.serverMaxWindowBits) {\n      params.server_max_window_bits = this._options.serverMaxWindowBits;\n    }\n    if (this._options.clientMaxWindowBits) {\n      params.client_max_window_bits = this._options.clientMaxWindowBits;\n    } else if (this._options.clientMaxWindowBits == null) {\n      params.client_max_window_bits = true;\n    }\n\n    return params;\n  }\n\n  /**\n   * Accept an extension negotiation offer/response.\n   *\n   * @param {Array} configurations The extension negotiation offers/reponse\n   * @return {Object} Accepted configuration\n   * @public\n   */\n  accept(configurations) {\n    configurations = this.normalizeParams(configurations);\n\n    this.params = this._isServer\n      ? this.acceptAsServer(configurations)\n      : this.acceptAsClient(configurations);\n\n    return this.params;\n  }\n\n  /**\n   * Releases all resources used by the extension.\n   *\n   * @public\n   */\n  cleanup() {\n    if (this._inflate) {\n      this._inflate.close();\n      this._inflate = null;\n    }\n\n    if (this._deflate) {\n      const callback = this._deflate[kCallback];\n\n      this._deflate.close();\n      this._deflate = null;\n\n      if (callback) {\n        callback(\n          new Error(\n            'The deflate stream was closed while data was being processed'\n          )\n        );\n      }\n    }\n  }\n\n  /**\n   *  Accept an extension negotiation offer.\n   *\n   * @param {Array} offers The extension negotiation offers\n   * @return {Object} Accepted configuration\n   * @private\n   */\n  acceptAsServer(offers) {\n    const opts = this._options;\n    const accepted = offers.find((params) => {\n      if (\n        (opts.serverNoContextTakeover === false &&\n          params.server_no_context_takeover) ||\n        (params.server_max_window_bits &&\n          (opts.serverMaxWindowBits === false ||\n            (typeof opts.serverMaxWindowBits === 'number' &&\n              opts.serverMaxWindowBits > params.server_max_window_bits))) ||\n        (typeof opts.clientMaxWindowBits === 'number' &&\n          !params.client_max_window_bits)\n      ) {\n        return false;\n      }\n\n      return true;\n    });\n\n    if (!accepted) {\n      throw new Error('None of the extension offers can be accepted');\n    }\n\n    if (opts.serverNoContextTakeover) {\n      accepted.server_no_context_takeover = true;\n    }\n    if (opts.clientNoContextTakeover) {\n      accepted.client_no_context_takeover = true;\n    }\n    if (typeof opts.serverMaxWindowBits === 'number') {\n      accepted.server_max_window_bits = opts.serverMaxWindowBits;\n    }\n    if (typeof opts.clientMaxWindowBits === 'number') {\n      accepted.client_max_window_bits = opts.clientMaxWindowBits;\n    } else if (\n      accepted.client_max_window_bits === true ||\n      opts.clientMaxWindowBits === false\n    ) {\n      delete accepted.client_max_window_bits;\n    }\n\n    return accepted;\n  }\n\n  /**\n   * Accept the extension negotiation response.\n   *\n   * @param {Array} response The extension negotiation response\n   * @return {Object} Accepted configuration\n   * @private\n   */\n  acceptAsClient(response) {\n    const params = response[0];\n\n    if (\n      this._options.clientNoContextTakeover === false &&\n      params.client_no_context_takeover\n    ) {\n      throw new Error('Unexpected parameter \"client_no_context_takeover\"');\n    }\n\n    if (!params.client_max_window_bits) {\n      if (typeof this._options.clientMaxWindowBits === 'number') {\n        params.client_max_window_bits = this._options.clientMaxWindowBits;\n      }\n    } else if (\n      this._options.clientMaxWindowBits === false ||\n      (typeof this._options.clientMaxWindowBits === 'number' &&\n        params.client_max_window_bits > this._options.clientMaxWindowBits)\n    ) {\n      throw new Error(\n        'Unexpected or invalid parameter \"client_max_window_bits\"'\n      );\n    }\n\n    return params;\n  }\n\n  /**\n   * Normalize parameters.\n   *\n   * @param {Array} configurations The extension negotiation offers/reponse\n   * @return {Array} The offers/response with normalized parameters\n   * @private\n   */\n  normalizeParams(configurations) {\n    configurations.forEach((params) => {\n      Object.keys(params).forEach((key) => {\n        let value = params[key];\n\n        if (value.length > 1) {\n          throw new Error(`Parameter \"${key}\" must have only a single value`);\n        }\n\n        value = value[0];\n\n        if (key === 'client_max_window_bits') {\n          if (value !== true) {\n            const num = +value;\n            if (!Number.isInteger(num) || num < 8 || num > 15) {\n              throw new TypeError(\n                `Invalid value for parameter \"${key}\": ${value}`\n              );\n            }\n            value = num;\n          } else if (!this._isServer) {\n            throw new TypeError(\n              `Invalid value for parameter \"${key}\": ${value}`\n            );\n          }\n        } else if (key === 'server_max_window_bits') {\n          const num = +value;\n          if (!Number.isInteger(num) || num < 8 || num > 15) {\n            throw new TypeError(\n              `Invalid value for parameter \"${key}\": ${value}`\n            );\n          }\n          value = num;\n        } else if (\n          key === 'client_no_context_takeover' ||\n          key === 'server_no_context_takeover'\n        ) {\n          if (value !== true) {\n            throw new TypeError(\n              `Invalid value for parameter \"${key}\": ${value}`\n            );\n          }\n        } else {\n          throw new Error(`Unknown parameter \"${key}\"`);\n        }\n\n        params[key] = value;\n      });\n    });\n\n    return configurations;\n  }\n\n  /**\n   * Decompress data. Concurrency limited.\n   *\n   * @param {Buffer} data Compressed data\n   * @param {Boolean} fin Specifies whether or not this is the last fragment\n   * @param {Function} callback Callback\n   * @public\n   */\n  decompress(data, fin, callback) {\n    zlibLimiter.add((done) => {\n      this._decompress(data, fin, (err, result) => {\n        done();\n        callback(err, result);\n      });\n    });\n  }\n\n  /**\n   * Compress data. Concurrency limited.\n   *\n   * @param {(Buffer|String)} data Data to compress\n   * @param {Boolean} fin Specifies whether or not this is the last fragment\n   * @param {Function} callback Callback\n   * @public\n   */\n  compress(data, fin, callback) {\n    zlibLimiter.add((done) => {\n      this._compress(data, fin, (err, result) => {\n        done();\n        callback(err, result);\n      });\n    });\n  }\n\n  /**\n   * Decompress data.\n   *\n   * @param {Buffer} data Compressed data\n   * @param {Boolean} fin Specifies whether or not this is the last fragment\n   * @param {Function} callback Callback\n   * @private\n   */\n  _decompress(data, fin, callback) {\n    const endpoint = this._isServer ? 'client' : 'server';\n\n    if (!this._inflate) {\n      const key = `${endpoint}_max_window_bits`;\n      const windowBits =\n        typeof this.params[key] !== 'number'\n          ? zlib.Z_DEFAULT_WINDOWBITS\n          : this.params[key];\n\n      this._inflate = zlib.createInflateRaw({\n        ...this._options.zlibInflateOptions,\n        windowBits\n      });\n      this._inflate[kPerMessageDeflate] = this;\n      this._inflate[kTotalLength] = 0;\n      this._inflate[kBuffers] = [];\n      this._inflate.on('error', inflateOnError);\n      this._inflate.on('data', inflateOnData);\n    }\n\n    this._inflate[kCallback] = callback;\n\n    this._inflate.write(data);\n    if (fin) this._inflate.write(TRAILER);\n\n    this._inflate.flush(() => {\n      const err = this._inflate[kError];\n\n      if (err) {\n        this._inflate.close();\n        this._inflate = null;\n        callback(err);\n        return;\n      }\n\n      const data = bufferUtil.concat(\n        this._inflate[kBuffers],\n        this._inflate[kTotalLength]\n      );\n\n      if (this._inflate._readableState.endEmitted) {\n        this._inflate.close();\n        this._inflate = null;\n      } else {\n        this._inflate[kTotalLength] = 0;\n        this._inflate[kBuffers] = [];\n\n        if (fin && this.params[`${endpoint}_no_context_takeover`]) {\n          this._inflate.reset();\n        }\n      }\n\n      callback(null, data);\n    });\n  }\n\n  /**\n   * Compress data.\n   *\n   * @param {(Buffer|String)} data Data to compress\n   * @param {Boolean} fin Specifies whether or not this is the last fragment\n   * @param {Function} callback Callback\n   * @private\n   */\n  _compress(data, fin, callback) {\n    const endpoint = this._isServer ? 'server' : 'client';\n\n    if (!this._deflate) {\n      const key = `${endpoint}_max_window_bits`;\n      const windowBits =\n        typeof this.params[key] !== 'number'\n          ? zlib.Z_DEFAULT_WINDOWBITS\n          : this.params[key];\n\n      this._deflate = zlib.createDeflateRaw({\n        ...this._options.zlibDeflateOptions,\n        windowBits\n      });\n\n      this._deflate[kTotalLength] = 0;\n      this._deflate[kBuffers] = [];\n\n      this._deflate.on('data', deflateOnData);\n    }\n\n    this._deflate[kCallback] = callback;\n\n    this._deflate.write(data);\n    this._deflate.flush(zlib.Z_SYNC_FLUSH, () => {\n      if (!this._deflate) {\n        //\n        // The deflate stream was closed while data was being processed.\n        //\n        return;\n      }\n\n      let data = bufferUtil.concat(\n        this._deflate[kBuffers],\n        this._deflate[kTotalLength]\n      );\n\n      if (fin) {\n        data = new FastBuffer(data.buffer, data.byteOffset, data.length - 4);\n      }\n\n      //\n      // Ensure that the callback will not be called again in\n      // `PerMessageDeflate#cleanup()`.\n      //\n      this._deflate[kCallback] = null;\n\n      this._deflate[kTotalLength] = 0;\n      this._deflate[kBuffers] = [];\n\n      if (fin && this.params[`${endpoint}_no_context_takeover`]) {\n        this._deflate.reset();\n      }\n\n      callback(null, data);\n    });\n  }\n}\n\nmodule.exports = PerMessageDeflate;\n\n/**\n * The listener of the `zlib.DeflateRaw` stream `'data'` event.\n *\n * @param {Buffer} chunk A chunk of data\n * @private\n */\nfunction deflateOnData(chunk) {\n  this[kBuffers].push(chunk);\n  this[kTotalLength] += chunk.length;\n}\n\n/**\n * The listener of the `zlib.InflateRaw` stream `'data'` event.\n *\n * @param {Buffer} chunk A chunk of data\n * @private\n */\nfunction inflateOnData(chunk) {\n  this[kTotalLength] += chunk.length;\n\n  if (\n    this[kPerMessageDeflate]._maxPayload < 1 ||\n    this[kTotalLength] <= this[kPerMessageDeflate]._maxPayload\n  ) {\n    this[kBuffers].push(chunk);\n    return;\n  }\n\n  this[kError] = new RangeError('Max payload size exceeded');\n  this[kError].code = 'WS_ERR_UNSUPPORTED_MESSAGE_LENGTH';\n  this[kError][kStatusCode] = 1009;\n  this.removeListener('data', inflateOnData);\n\n  //\n  // The choice to employ `zlib.reset()` over `zlib.close()` is dictated by the\n  // fact that in Node.js versions prior to 13.10.0, the callback for\n  // `zlib.flush()` is not called if `zlib.close()` is used. Utilizing\n  // `zlib.reset()` ensures that either the callback is invoked or an error is\n  // emitted.\n  //\n  this.reset();\n}\n\n/**\n * The listener of the `zlib.InflateRaw` stream `'error'` event.\n *\n * @param {Error} err The emitted error\n * @private\n */\nfunction inflateOnError(err) {\n  //\n  // There is no need to call `Zlib#close()` as the handle is automatically\n  // closed when an error is emitted.\n  //\n  this[kPerMessageDeflate]._inflate = null;\n\n  if (this[kError]) {\n    this[kCallback](this[kError]);\n    return;\n  }\n\n  err[kStatusCode] = 1007;\n  this[kCallback](err);\n}\n","'use strict';\n\nconst { isUtf8 } = require('buffer');\n\nconst { hasBlob } = require('./constants');\n\n//\n// Allowed token characters:\n//\n// '!', '#', '$', '%', '&', ''', '*', '+', '-',\n// '.', 0-9, A-Z, '^', '_', '`', a-z, '|', '~'\n//\n// tokenChars[32] === 0 // ' '\n// tokenChars[33] === 1 // '!'\n// tokenChars[34] === 0 // '\"'\n// ...\n//\n// prettier-ignore\nconst tokenChars = [\n  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, // 0 - 15\n  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, // 16 - 31\n  0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, // 32 - 47\n  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, // 48 - 63\n  0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, // 64 - 79\n  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, // 80 - 95\n  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, // 96 - 111\n  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0 // 112 - 127\n];\n\n/**\n * Checks if a status code is allowed in a close frame.\n *\n * @param {Number} code The status code\n * @return {Boolean} `true` if the status code is valid, else `false`\n * @public\n */\nfunction isValidStatusCode(code) {\n  return (\n    (code >= 1000 &&\n      code <= 1014 &&\n      code !== 1004 &&\n      code !== 1005 &&\n      code !== 1006) ||\n    (code >= 3000 && code <= 4999)\n  );\n}\n\n/**\n * Checks if a given buffer contains only correct UTF-8.\n * Ported from https://www.cl.cam.ac.uk/%7Emgk25/ucs/utf8_check.c by\n * Markus Kuhn.\n *\n * @param {Buffer} buf The buffer to check\n * @return {Boolean} `true` if `buf` contains only correct UTF-8, else `false`\n * @public\n */\nfunction _isValidUTF8(buf) {\n  const len = buf.length;\n  let i = 0;\n\n  while (i < len) {\n    if ((buf[i] & 0x80) === 0) {\n      // 0xxxxxxx\n      i++;\n    } else if ((buf[i] & 0xe0) === 0xc0) {\n      // 110xxxxx 10xxxxxx\n      if (\n        i + 1 === len ||\n        (buf[i + 1] & 0xc0) !== 0x80 ||\n        (buf[i] & 0xfe) === 0xc0 // Overlong\n      ) {\n        return false;\n      }\n\n      i += 2;\n    } else if ((buf[i] & 0xf0) === 0xe0) {\n      // 1110xxxx 10xxxxxx 10xxxxxx\n      if (\n        i + 2 >= len ||\n        (buf[i + 1] & 0xc0) !== 0x80 ||\n        (buf[i + 2] & 0xc0) !== 0x80 ||\n        (buf[i] === 0xe0 && (buf[i + 1] & 0xe0) === 0x80) || // Overlong\n        (buf[i] === 0xed && (buf[i + 1] & 0xe0) === 0xa0) // Surrogate (U+D800 - U+DFFF)\n      ) {\n        return false;\n      }\n\n      i += 3;\n    } else if ((buf[i] & 0xf8) === 0xf0) {\n      // 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx\n      if (\n        i + 3 >= len ||\n        (buf[i + 1] & 0xc0) !== 0x80 ||\n        (buf[i + 2] & 0xc0) !== 0x80 ||\n        (buf[i + 3] & 0xc0) !== 0x80 ||\n        (buf[i] === 0xf0 && (buf[i + 1] & 0xf0) === 0x80) || // Overlong\n        (buf[i] === 0xf4 && buf[i + 1] > 0x8f) ||\n        buf[i] > 0xf4 // > U+10FFFF\n      ) {\n        return false;\n      }\n\n      i += 4;\n    } else {\n      return false;\n    }\n  }\n\n  return true;\n}\n\n/**\n * Determines whether a value is a `Blob`.\n *\n * @param {*} value The value to be tested\n * @return {Boolean} `true` if `value` is a `Blob`, else `false`\n * @private\n */\nfunction isBlob(value) {\n  return (\n    hasBlob &&\n    typeof value === 'object' &&\n    typeof value.arrayBuffer === 'function' &&\n    typeof value.type === 'string' &&\n    typeof value.stream === 'function' &&\n    (value[Symbol.toStringTag] === 'Blob' ||\n      value[Symbol.toStringTag] === 'File')\n  );\n}\n\nmodule.exports = {\n  isBlob,\n  isValidStatusCode,\n  isValidUTF8: _isValidUTF8,\n  tokenChars\n};\n\nif (isUtf8) {\n  module.exports.isValidUTF8 = function (buf) {\n    return buf.length < 24 ? _isValidUTF8(buf) : isUtf8(buf);\n  };\n} /* istanbul ignore else  */ else if (!process.env.WS_NO_UTF_8_VALIDATE) {\n  try {\n    const isValidUTF8 = require('utf-8-validate');\n\n    module.exports.isValidUTF8 = function (buf) {\n      return buf.length < 32 ? _isValidUTF8(buf) : isValidUTF8(buf);\n    };\n  } catch (e) {\n    // Continue regardless of the error.\n  }\n}\n","'use strict';\n\nconst { Writable } = require('stream');\n\nconst PerMessageDeflate = require('./permessage-deflate');\nconst {\n  BINARY_TYPES,\n  EMPTY_BUFFER,\n  kStatusCode,\n  kWebSocket\n} = require('./constants');\nconst { concat, toArrayBuffer, unmask } = require('./buffer-util');\nconst { isValidStatusCode, isValidUTF8 } = require('./validation');\n\nconst FastBuffer = Buffer[Symbol.species];\n\nconst GET_INFO = 0;\nconst GET_PAYLOAD_LENGTH_16 = 1;\nconst GET_PAYLOAD_LENGTH_64 = 2;\nconst GET_MASK = 3;\nconst GET_DATA = 4;\nconst INFLATING = 5;\nconst DEFER_EVENT = 6;\n\n/**\n * HyBi Receiver implementation.\n *\n * @extends Writable\n */\nclass Receiver extends Writable {\n  /**\n   * Creates a Receiver instance.\n   *\n   * @param {Object} [options] Options object\n   * @param {Boolean} [options.allowSynchronousEvents=true] Specifies whether\n   *     any of the `'message'`, `'ping'`, and `'pong'` events can be emitted\n   *     multiple times in the same tick\n   * @param {String} [options.binaryType=nodebuffer] The type for binary data\n   * @param {Object} [options.extensions] An object containing the negotiated\n   *     extensions\n   * @param {Boolean} [options.isServer=false] Specifies whether to operate in\n   *     client or server mode\n   * @param {Number} [options.maxPayload=0] The maximum allowed message length\n   * @param {Boolean} [options.skipUTF8Validation=false] Specifies whether or\n   *     not to skip UTF-8 validation for text and close messages\n   */\n  constructor(options = {}) {\n    super();\n\n    this._allowSynchronousEvents =\n      options.allowSynchronousEvents !== undefined\n        ? options.allowSynchronousEvents\n        : true;\n    this._binaryType = options.binaryType || BINARY_TYPES[0];\n    this._extensions = options.extensions || {};\n    this._isServer = !!options.isServer;\n    this._maxPayload = options.maxPayload | 0;\n    this._skipUTF8Validation = !!options.skipUTF8Validation;\n    this[kWebSocket] = undefined;\n\n    this._bufferedBytes = 0;\n    this._buffers = [];\n\n    this._compressed = false;\n    this._payloadLength = 0;\n    this._mask = undefined;\n    this._fragmented = 0;\n    this._masked = false;\n    this._fin = false;\n    this._opcode = 0;\n\n    this._totalPayloadLength = 0;\n    this._messageLength = 0;\n    this._fragments = [];\n\n    this._errored = false;\n    this._loop = false;\n    this._state = GET_INFO;\n  }\n\n  /**\n   * Implements `Writable.prototype._write()`.\n   *\n   * @param {Buffer} chunk The chunk of data to write\n   * @param {String} encoding The character encoding of `chunk`\n   * @param {Function} cb Callback\n   * @private\n   */\n  _write(chunk, encoding, cb) {\n    if (this._opcode === 0x08 && this._state == GET_INFO) return cb();\n\n    this._bufferedBytes += chunk.length;\n    this._buffers.push(chunk);\n    this.startLoop(cb);\n  }\n\n  /**\n   * Consumes `n` bytes from the buffered data.\n   *\n   * @param {Number} n The number of bytes to consume\n   * @return {Buffer} The consumed bytes\n   * @private\n   */\n  consume(n) {\n    this._bufferedBytes -= n;\n\n    if (n === this._buffers[0].length) return this._buffers.shift();\n\n    if (n < this._buffers[0].length) {\n      const buf = this._buffers[0];\n      this._buffers[0] = new FastBuffer(\n        buf.buffer,\n        buf.byteOffset + n,\n        buf.length - n\n      );\n\n      return new FastBuffer(buf.buffer, buf.byteOffset, n);\n    }\n\n    const dst = Buffer.allocUnsafe(n);\n\n    do {\n      const buf = this._buffers[0];\n      const offset = dst.length - n;\n\n      if (n >= buf.length) {\n        dst.set(this._buffers.shift(), offset);\n      } else {\n        dst.set(new Uint8Array(buf.buffer, buf.byteOffset, n), offset);\n        this._buffers[0] = new FastBuffer(\n          buf.buffer,\n          buf.byteOffset + n,\n          buf.length - n\n        );\n      }\n\n      n -= buf.length;\n    } while (n > 0);\n\n    return dst;\n  }\n\n  /**\n   * Starts the parsing loop.\n   *\n   * @param {Function} cb Callback\n   * @private\n   */\n  startLoop(cb) {\n    this._loop = true;\n\n    do {\n      switch (this._state) {\n        case GET_INFO:\n          this.getInfo(cb);\n          break;\n        case GET_PAYLOAD_LENGTH_16:\n          this.getPayloadLength16(cb);\n          break;\n        case GET_PAYLOAD_LENGTH_64:\n          this.getPayloadLength64(cb);\n          break;\n        case GET_MASK:\n          this.getMask();\n          break;\n        case GET_DATA:\n          this.getData(cb);\n          break;\n        case INFLATING:\n        case DEFER_EVENT:\n          this._loop = false;\n          return;\n      }\n    } while (this._loop);\n\n    if (!this._errored) cb();\n  }\n\n  /**\n   * Reads the first two bytes of a frame.\n   *\n   * @param {Function} cb Callback\n   * @private\n   */\n  getInfo(cb) {\n    if (this._bufferedBytes < 2) {\n      this._loop = false;\n      return;\n    }\n\n    const buf = this.consume(2);\n\n    if ((buf[0] & 0x30) !== 0x00) {\n      const error = this.createError(\n        RangeError,\n        'RSV2 and RSV3 must be clear',\n        true,\n        1002,\n        'WS_ERR_UNEXPECTED_RSV_2_3'\n      );\n\n      cb(error);\n      return;\n    }\n\n    const compressed = (buf[0] & 0x40) === 0x40;\n\n    if (compressed && !this._extensions[PerMessageDeflate.extensionName]) {\n      const error = this.createError(\n        RangeError,\n        'RSV1 must be clear',\n        true,\n        1002,\n        'WS_ERR_UNEXPECTED_RSV_1'\n      );\n\n      cb(error);\n      return;\n    }\n\n    this._fin = (buf[0] & 0x80) === 0x80;\n    this._opcode = buf[0] & 0x0f;\n    this._payloadLength = buf[1] & 0x7f;\n\n    if (this._opcode === 0x00) {\n      if (compressed) {\n        const error = this.createError(\n          RangeError,\n          'RSV1 must be clear',\n          true,\n          1002,\n          'WS_ERR_UNEXPECTED_RSV_1'\n        );\n\n        cb(error);\n        return;\n      }\n\n      if (!this._fragmented) {\n        const error = this.createError(\n          RangeError,\n          'invalid opcode 0',\n          true,\n          1002,\n          'WS_ERR_INVALID_OPCODE'\n        );\n\n        cb(error);\n        return;\n      }\n\n      this._opcode = this._fragmented;\n    } else if (this._opcode === 0x01 || this._opcode === 0x02) {\n      if (this._fragmented) {\n        const error = this.createError(\n          RangeError,\n          `invalid opcode ${this._opcode}`,\n          true,\n          1002,\n          'WS_ERR_INVALID_OPCODE'\n        );\n\n        cb(error);\n        return;\n      }\n\n      this._compressed = compressed;\n    } else if (this._opcode > 0x07 && this._opcode < 0x0b) {\n      if (!this._fin) {\n        const error = this.createError(\n          RangeError,\n          'FIN must be set',\n          true,\n          1002,\n          'WS_ERR_EXPECTED_FIN'\n        );\n\n        cb(error);\n        return;\n      }\n\n      if (compressed) {\n        const error = this.createError(\n          RangeError,\n          'RSV1 must be clear',\n          true,\n          1002,\n          'WS_ERR_UNEXPECTED_RSV_1'\n        );\n\n        cb(error);\n        return;\n      }\n\n      if (\n        this._payloadLength > 0x7d ||\n        (this._opcode === 0x08 && this._payloadLength === 1)\n      ) {\n        const error = this.createError(\n          RangeError,\n          `invalid payload length ${this._payloadLength}`,\n          true,\n          1002,\n          'WS_ERR_INVALID_CONTROL_PAYLOAD_LENGTH'\n        );\n\n        cb(error);\n        return;\n      }\n    } else {\n      const error = this.createError(\n        RangeError,\n        `invalid opcode ${this._opcode}`,\n        true,\n        1002,\n        'WS_ERR_INVALID_OPCODE'\n      );\n\n      cb(error);\n      return;\n    }\n\n    if (!this._fin && !this._fragmented) this._fragmented = this._opcode;\n    this._masked = (buf[1] & 0x80) === 0x80;\n\n    if (this._isServer) {\n      if (!this._masked) {\n        const error = this.createError(\n          RangeError,\n          'MASK must be set',\n          true,\n          1002,\n          'WS_ERR_EXPECTED_MASK'\n        );\n\n        cb(error);\n        return;\n      }\n    } else if (this._masked) {\n      const error = this.createError(\n        RangeError,\n        'MASK must be clear',\n        true,\n        1002,\n        'WS_ERR_UNEXPECTED_MASK'\n      );\n\n      cb(error);\n      return;\n    }\n\n    if (this._payloadLength === 126) this._state = GET_PAYLOAD_LENGTH_16;\n    else if (this._payloadLength === 127) this._state = GET_PAYLOAD_LENGTH_64;\n    else this.haveLength(cb);\n  }\n\n  /**\n   * Gets extended payload length (7+16).\n   *\n   * @param {Function} cb Callback\n   * @private\n   */\n  getPayloadLength16(cb) {\n    if (this._bufferedBytes < 2) {\n      this._loop = false;\n      return;\n    }\n\n    this._payloadLength = this.consume(2).readUInt16BE(0);\n    this.haveLength(cb);\n  }\n\n  /**\n   * Gets extended payload length (7+64).\n   *\n   * @param {Function} cb Callback\n   * @private\n   */\n  getPayloadLength64(cb) {\n    if (this._bufferedBytes < 8) {\n      this._loop = false;\n      return;\n    }\n\n    const buf = this.consume(8);\n    const num = buf.readUInt32BE(0);\n\n    //\n    // The maximum safe integer in JavaScript is 2^53 - 1. An error is returned\n    // if payload length is greater than this number.\n    //\n    if (num > Math.pow(2, 53 - 32) - 1) {\n      const error = this.createError(\n        RangeError,\n        'Unsupported WebSocket frame: payload length > 2^53 - 1',\n        false,\n        1009,\n        'WS_ERR_UNSUPPORTED_DATA_PAYLOAD_LENGTH'\n      );\n\n      cb(error);\n      return;\n    }\n\n    this._payloadLength = num * Math.pow(2, 32) + buf.readUInt32BE(4);\n    this.haveLength(cb);\n  }\n\n  /**\n   * Payload length has been read.\n   *\n   * @param {Function} cb Callback\n   * @private\n   */\n  haveLength(cb) {\n    if (this._payloadLength && this._opcode < 0x08) {\n      this._totalPayloadLength += this._payloadLength;\n      if (this._totalPayloadLength > this._maxPayload && this._maxPayload > 0) {\n        const error = this.createError(\n          RangeError,\n          'Max payload size exceeded',\n          false,\n          1009,\n          'WS_ERR_UNSUPPORTED_MESSAGE_LENGTH'\n        );\n\n        cb(error);\n        return;\n      }\n    }\n\n    if (this._masked) this._state = GET_MASK;\n    else this._state = GET_DATA;\n  }\n\n  /**\n   * Reads mask bytes.\n   *\n   * @private\n   */\n  getMask() {\n    if (this._bufferedBytes < 4) {\n      this._loop = false;\n      return;\n    }\n\n    this._mask = this.consume(4);\n    this._state = GET_DATA;\n  }\n\n  /**\n   * Reads data bytes.\n   *\n   * @param {Function} cb Callback\n   * @private\n   */\n  getData(cb) {\n    let data = EMPTY_BUFFER;\n\n    if (this._payloadLength) {\n      if (this._bufferedBytes < this._payloadLength) {\n        this._loop = false;\n        return;\n      }\n\n      data = this.consume(this._payloadLength);\n\n      if (\n        this._masked &&\n        (this._mask[0] | this._mask[1] | this._mask[2] | this._mask[3]) !== 0\n      ) {\n        unmask(data, this._mask);\n      }\n    }\n\n    if (this._opcode > 0x07) {\n      this.controlMessage(data, cb);\n      return;\n    }\n\n    if (this._compressed) {\n      this._state = INFLATING;\n      this.decompress(data, cb);\n      return;\n    }\n\n    if (data.length) {\n      //\n      // This message is not compressed so its length is the sum of the payload\n      // length of all fragments.\n      //\n      this._messageLength = this._totalPayloadLength;\n      this._fragments.push(data);\n    }\n\n    this.dataMessage(cb);\n  }\n\n  /**\n   * Decompresses data.\n   *\n   * @param {Buffer} data Compressed data\n   * @param {Function} cb Callback\n   * @private\n   */\n  decompress(data, cb) {\n    const perMessageDeflate = this._extensions[PerMessageDeflate.extensionName];\n\n    perMessageDeflate.decompress(data, this._fin, (err, buf) => {\n      if (err) return cb(err);\n\n      if (buf.length) {\n        this._messageLength += buf.length;\n        if (this._messageLength > this._maxPayload && this._maxPayload > 0) {\n          const error = this.createError(\n            RangeError,\n            'Max payload size exceeded',\n            false,\n            1009,\n            'WS_ERR_UNSUPPORTED_MESSAGE_LENGTH'\n          );\n\n          cb(error);\n          return;\n        }\n\n        this._fragments.push(buf);\n      }\n\n      this.dataMessage(cb);\n      if (this._state === GET_INFO) this.startLoop(cb);\n    });\n  }\n\n  /**\n   * Handles a data message.\n   *\n   * @param {Function} cb Callback\n   * @private\n   */\n  dataMessage(cb) {\n    if (!this._fin) {\n      this._state = GET_INFO;\n      return;\n    }\n\n    const messageLength = this._messageLength;\n    const fragments = this._fragments;\n\n    this._totalPayloadLength = 0;\n    this._messageLength = 0;\n    this._fragmented = 0;\n    this._fragments = [];\n\n    if (this._opcode === 2) {\n      let data;\n\n      if (this._binaryType === 'nodebuffer') {\n        data = concat(fragments, messageLength);\n      } else if (this._binaryType === 'arraybuffer') {\n        data = toArrayBuffer(concat(fragments, messageLength));\n      } else if (this._binaryType === 'blob') {\n        data = new Blob(fragments);\n      } else {\n        data = fragments;\n      }\n\n      if (this._allowSynchronousEvents) {\n        this.emit('message', data, true);\n        this._state = GET_INFO;\n      } else {\n        this._state = DEFER_EVENT;\n        setImmediate(() => {\n          this.emit('message', data, true);\n          this._state = GET_INFO;\n          this.startLoop(cb);\n        });\n      }\n    } else {\n      const buf = concat(fragments, messageLength);\n\n      if (!this._skipUTF8Validation && !isValidUTF8(buf)) {\n        const error = this.createError(\n          Error,\n          'invalid UTF-8 sequence',\n          true,\n          1007,\n          'WS_ERR_INVALID_UTF8'\n        );\n\n        cb(error);\n        return;\n      }\n\n      if (this._state === INFLATING || this._allowSynchronousEvents) {\n        this.emit('message', buf, false);\n        this._state = GET_INFO;\n      } else {\n        this._state = DEFER_EVENT;\n        setImmediate(() => {\n          this.emit('message', buf, false);\n          this._state = GET_INFO;\n          this.startLoop(cb);\n        });\n      }\n    }\n  }\n\n  /**\n   * Handles a control message.\n   *\n   * @param {Buffer} data Data to handle\n   * @return {(Error|RangeError|undefined)} A possible error\n   * @private\n   */\n  controlMessage(data, cb) {\n    if (this._opcode === 0x08) {\n      if (data.length === 0) {\n        this._loop = false;\n        this.emit('conclude', 1005, EMPTY_BUFFER);\n        this.end();\n      } else {\n        const code = data.readUInt16BE(0);\n\n        if (!isValidStatusCode(code)) {\n          const error = this.createError(\n            RangeError,\n            `invalid status code ${code}`,\n            true,\n            1002,\n            'WS_ERR_INVALID_CLOSE_CODE'\n          );\n\n          cb(error);\n          return;\n        }\n\n        const buf = new FastBuffer(\n          data.buffer,\n          data.byteOffset + 2,\n          data.length - 2\n        );\n\n        if (!this._skipUTF8Validation && !isValidUTF8(buf)) {\n          const error = this.createError(\n            Error,\n            'invalid UTF-8 sequence',\n            true,\n            1007,\n            'WS_ERR_INVALID_UTF8'\n          );\n\n          cb(error);\n          return;\n        }\n\n        this._loop = false;\n        this.emit('conclude', code, buf);\n        this.end();\n      }\n\n      this._state = GET_INFO;\n      return;\n    }\n\n    if (this._allowSynchronousEvents) {\n      this.emit(this._opcode === 0x09 ? 'ping' : 'pong', data);\n      this._state = GET_INFO;\n    } else {\n      this._state = DEFER_EVENT;\n      setImmediate(() => {\n        this.emit(this._opcode === 0x09 ? 'ping' : 'pong', data);\n        this._state = GET_INFO;\n        this.startLoop(cb);\n      });\n    }\n  }\n\n  /**\n   * Builds an error object.\n   *\n   * @param {function(new:Error|RangeError)} ErrorCtor The error constructor\n   * @param {String} message The error message\n   * @param {Boolean} prefix Specifies whether or not to add a default prefix to\n   *     `message`\n   * @param {Number} statusCode The status code\n   * @param {String} errorCode The exposed error code\n   * @return {(Error|RangeError)} The error\n   * @private\n   */\n  createError(ErrorCtor, message, prefix, statusCode, errorCode) {\n    this._loop = false;\n    this._errored = true;\n\n    const err = new ErrorCtor(\n      prefix ? `Invalid WebSocket frame: ${message}` : message\n    );\n\n    Error.captureStackTrace(err, this.createError);\n    err.code = errorCode;\n    err[kStatusCode] = statusCode;\n    return err;\n  }\n}\n\nmodule.exports = Receiver;\n","/* eslint no-unused-vars: [\"error\", { \"varsIgnorePattern\": \"^Duplex\" }] */\n\n'use strict';\n\nconst { Duplex } = require('stream');\nconst { randomFillSync } = require('crypto');\n\nconst PerMessageDeflate = require('./permessage-deflate');\nconst { EMPTY_BUFFER, kWebSocket, NOOP } = require('./constants');\nconst { isBlob, isValidStatusCode } = require('./validation');\nconst { mask: applyMask, toBuffer } = require('./buffer-util');\n\nconst kByteLength = Symbol('kByteLength');\nconst maskBuffer = Buffer.alloc(4);\nconst RANDOM_POOL_SIZE = 8 * 1024;\nlet randomPool;\nlet randomPoolPointer = RANDOM_POOL_SIZE;\n\nconst DEFAULT = 0;\nconst DEFLATING = 1;\nconst GET_BLOB_DATA = 2;\n\n/**\n * HyBi Sender implementation.\n */\nclass Sender {\n  /**\n   * Creates a Sender instance.\n   *\n   * @param {Duplex} socket The connection socket\n   * @param {Object} [extensions] An object containing the negotiated extensions\n   * @param {Function} [generateMask] The function used to generate the masking\n   *     key\n   */\n  constructor(socket, extensions, generateMask) {\n    this._extensions = extensions || {};\n\n    if (generateMask) {\n      this._generateMask = generateMask;\n      this._maskBuffer = Buffer.alloc(4);\n    }\n\n    this._socket = socket;\n\n    this._firstFragment = true;\n    this._compress = false;\n\n    this._bufferedBytes = 0;\n    this._queue = [];\n    this._state = DEFAULT;\n    this.onerror = NOOP;\n    this[kWebSocket] = undefined;\n  }\n\n  /**\n   * Frames a piece of data according to the HyBi WebSocket protocol.\n   *\n   * @param {(Buffer|String)} data The data to frame\n   * @param {Object} options Options object\n   * @param {Boolean} [options.fin=false] Specifies whether or not to set the\n   *     FIN bit\n   * @param {Function} [options.generateMask] The function used to generate the\n   *     masking key\n   * @param {Boolean} [options.mask=false] Specifies whether or not to mask\n   *     `data`\n   * @param {Buffer} [options.maskBuffer] The buffer used to store the masking\n   *     key\n   * @param {Number} options.opcode The opcode\n   * @param {Boolean} [options.readOnly=false] Specifies whether `data` can be\n   *     modified\n   * @param {Boolean} [options.rsv1=false] Specifies whether or not to set the\n   *     RSV1 bit\n   * @return {(Buffer|String)[]} The framed data\n   * @public\n   */\n  static frame(data, options) {\n    let mask;\n    let merge = false;\n    let offset = 2;\n    let skipMasking = false;\n\n    if (options.mask) {\n      mask = options.maskBuffer || maskBuffer;\n\n      if (options.generateMask) {\n        options.generateMask(mask);\n      } else {\n        if (randomPoolPointer === RANDOM_POOL_SIZE) {\n          /* istanbul ignore else  */\n          if (randomPool === undefined) {\n            //\n            // This is lazily initialized because server-sent frames must not\n            // be masked so it may never be used.\n            //\n            randomPool = Buffer.alloc(RANDOM_POOL_SIZE);\n          }\n\n          randomFillSync(randomPool, 0, RANDOM_POOL_SIZE);\n          randomPoolPointer = 0;\n        }\n\n        mask[0] = randomPool[randomPoolPointer++];\n        mask[1] = randomPool[randomPoolPointer++];\n        mask[2] = randomPool[randomPoolPointer++];\n        mask[3] = randomPool[randomPoolPointer++];\n      }\n\n      skipMasking = (mask[0] | mask[1] | mask[2] | mask[3]) === 0;\n      offset = 6;\n    }\n\n    let dataLength;\n\n    if (typeof data === 'string') {\n      if (\n        (!options.mask || skipMasking) &&\n        options[kByteLength] !== undefined\n      ) {\n        dataLength = options[kByteLength];\n      } else {\n        data = Buffer.from(data);\n        dataLength = data.length;\n      }\n    } else {\n      dataLength = data.length;\n      merge = options.mask && options.readOnly && !skipMasking;\n    }\n\n    let payloadLength = dataLength;\n\n    if (dataLength >= 65536) {\n      offset += 8;\n      payloadLength = 127;\n    } else if (dataLength > 125) {\n      offset += 2;\n      payloadLength = 126;\n    }\n\n    const target = Buffer.allocUnsafe(merge ? dataLength + offset : offset);\n\n    target[0] = options.fin ? options.opcode | 0x80 : options.opcode;\n    if (options.rsv1) target[0] |= 0x40;\n\n    target[1] = payloadLength;\n\n    if (payloadLength === 126) {\n      target.writeUInt16BE(dataLength, 2);\n    } else if (payloadLength === 127) {\n      target[2] = target[3] = 0;\n      target.writeUIntBE(dataLength, 4, 6);\n    }\n\n    if (!options.mask) return [target, data];\n\n    target[1] |= 0x80;\n    target[offset - 4] = mask[0];\n    target[offset - 3] = mask[1];\n    target[offset - 2] = mask[2];\n    target[offset - 1] = mask[3];\n\n    if (skipMasking) return [target, data];\n\n    if (merge) {\n      applyMask(data, mask, target, offset, dataLength);\n      return [target];\n    }\n\n    applyMask(data, mask, data, 0, dataLength);\n    return [target, data];\n  }\n\n  /**\n   * Sends a close message to the other peer.\n   *\n   * @param {Number} [code] The status code component of the body\n   * @param {(String|Buffer)} [data] The message component of the body\n   * @param {Boolean} [mask=false] Specifies whether or not to mask the message\n   * @param {Function} [cb] Callback\n   * @public\n   */\n  close(code, data, mask, cb) {\n    let buf;\n\n    if (code === undefined) {\n      buf = EMPTY_BUFFER;\n    } else if (typeof code !== 'number' || !isValidStatusCode(code)) {\n      throw new TypeError('First argument must be a valid error code number');\n    } else if (data === undefined || !data.length) {\n      buf = Buffer.allocUnsafe(2);\n      buf.writeUInt16BE(code, 0);\n    } else {\n      const length = Buffer.byteLength(data);\n\n      if (length > 123) {\n        throw new RangeError('The message must not be greater than 123 bytes');\n      }\n\n      buf = Buffer.allocUnsafe(2 + length);\n      buf.writeUInt16BE(code, 0);\n\n      if (typeof data === 'string') {\n        buf.write(data, 2);\n      } else {\n        buf.set(data, 2);\n      }\n    }\n\n    const options = {\n      [kByteLength]: buf.length,\n      fin: true,\n      generateMask: this._generateMask,\n      mask,\n      maskBuffer: this._maskBuffer,\n      opcode: 0x08,\n      readOnly: false,\n      rsv1: false\n    };\n\n    if (this._state !== DEFAULT) {\n      this.enqueue([this.dispatch, buf, false, options, cb]);\n    } else {\n      this.sendFrame(Sender.frame(buf, options), cb);\n    }\n  }\n\n  /**\n   * Sends a ping message to the other peer.\n   *\n   * @param {*} data The message to send\n   * @param {Boolean} [mask=false] Specifies whether or not to mask `data`\n   * @param {Function} [cb] Callback\n   * @public\n   */\n  ping(data, mask, cb) {\n    let byteLength;\n    let readOnly;\n\n    if (typeof data === 'string') {\n      byteLength = Buffer.byteLength(data);\n      readOnly = false;\n    } else if (isBlob(data)) {\n      byteLength = data.size;\n      readOnly = false;\n    } else {\n      data = toBuffer(data);\n      byteLength = data.length;\n      readOnly = toBuffer.readOnly;\n    }\n\n    if (byteLength > 125) {\n      throw new RangeError('The data size must not be greater than 125 bytes');\n    }\n\n    const options = {\n      [kByteLength]: byteLength,\n      fin: true,\n      generateMask: this._generateMask,\n      mask,\n      maskBuffer: this._maskBuffer,\n      opcode: 0x09,\n      readOnly,\n      rsv1: false\n    };\n\n    if (isBlob(data)) {\n      if (this._state !== DEFAULT) {\n        this.enqueue([this.getBlobData, data, false, options, cb]);\n      } else {\n        this.getBlobData(data, false, options, cb);\n      }\n    } else if (this._state !== DEFAULT) {\n      this.enqueue([this.dispatch, data, false, options, cb]);\n    } else {\n      this.sendFrame(Sender.frame(data, options), cb);\n    }\n  }\n\n  /**\n   * Sends a pong message to the other peer.\n   *\n   * @param {*} data The message to send\n   * @param {Boolean} [mask=false] Specifies whether or not to mask `data`\n   * @param {Function} [cb] Callback\n   * @public\n   */\n  pong(data, mask, cb) {\n    let byteLength;\n    let readOnly;\n\n    if (typeof data === 'string') {\n      byteLength = Buffer.byteLength(data);\n      readOnly = false;\n    } else if (isBlob(data)) {\n      byteLength = data.size;\n      readOnly = false;\n    } else {\n      data = toBuffer(data);\n      byteLength = data.length;\n      readOnly = toBuffer.readOnly;\n    }\n\n    if (byteLength > 125) {\n      throw new RangeError('The data size must not be greater than 125 bytes');\n    }\n\n    const options = {\n      [kByteLength]: byteLength,\n      fin: true,\n      generateMask: this._generateMask,\n      mask,\n      maskBuffer: this._maskBuffer,\n      opcode: 0x0a,\n      readOnly,\n      rsv1: false\n    };\n\n    if (isBlob(data)) {\n      if (this._state !== DEFAULT) {\n        this.enqueue([this.getBlobData, data, false, options, cb]);\n      } else {\n        this.getBlobData(data, false, options, cb);\n      }\n    } else if (this._state !== DEFAULT) {\n      this.enqueue([this.dispatch, data, false, options, cb]);\n    } else {\n      this.sendFrame(Sender.frame(data, options), cb);\n    }\n  }\n\n  /**\n   * Sends a data message to the other peer.\n   *\n   * @param {*} data The message to send\n   * @param {Object} options Options object\n   * @param {Boolean} [options.binary=false] Specifies whether `data` is binary\n   *     or text\n   * @param {Boolean} [options.compress=false] Specifies whether or not to\n   *     compress `data`\n   * @param {Boolean} [options.fin=false] Specifies whether the fragment is the\n   *     last one\n   * @param {Boolean} [options.mask=false] Specifies whether or not to mask\n   *     `data`\n   * @param {Function} [cb] Callback\n   * @public\n   */\n  send(data, options, cb) {\n    const perMessageDeflate = this._extensions[PerMessageDeflate.extensionName];\n    let opcode = options.binary ? 2 : 1;\n    let rsv1 = options.compress;\n\n    let byteLength;\n    let readOnly;\n\n    if (typeof data === 'string') {\n      byteLength = Buffer.byteLength(data);\n      readOnly = false;\n    } else if (isBlob(data)) {\n      byteLength = data.size;\n      readOnly = false;\n    } else {\n      data = toBuffer(data);\n      byteLength = data.length;\n      readOnly = toBuffer.readOnly;\n    }\n\n    if (this._firstFragment) {\n      this._firstFragment = false;\n      if (\n        rsv1 &&\n        perMessageDeflate &&\n        perMessageDeflate.params[\n          perMessageDeflate._isServer\n            ? 'server_no_context_takeover'\n            : 'client_no_context_takeover'\n        ]\n      ) {\n        rsv1 = byteLength >= perMessageDeflate._threshold;\n      }\n      this._compress = rsv1;\n    } else {\n      rsv1 = false;\n      opcode = 0;\n    }\n\n    if (options.fin) this._firstFragment = true;\n\n    const opts = {\n      [kByteLength]: byteLength,\n      fin: options.fin,\n      generateMask: this._generateMask,\n      mask: options.mask,\n      maskBuffer: this._maskBuffer,\n      opcode,\n      readOnly,\n      rsv1\n    };\n\n    if (isBlob(data)) {\n      if (this._state !== DEFAULT) {\n        this.enqueue([this.getBlobData, data, this._compress, opts, cb]);\n      } else {\n        this.getBlobData(data, this._compress, opts, cb);\n      }\n    } else if (this._state !== DEFAULT) {\n      this.enqueue([this.dispatch, data, this._compress, opts, cb]);\n    } else {\n      this.dispatch(data, this._compress, opts, cb);\n    }\n  }\n\n  /**\n   * Gets the contents of a blob as binary data.\n   *\n   * @param {Blob} blob The blob\n   * @param {Boolean} [compress=false] Specifies whether or not to compress\n   *     the data\n   * @param {Object} options Options object\n   * @param {Boolean} [options.fin=false] Specifies whether or not to set the\n   *     FIN bit\n   * @param {Function} [options.generateMask] The function used to generate the\n   *     masking key\n   * @param {Boolean} [options.mask=false] Specifies whether or not to mask\n   *     `data`\n   * @param {Buffer} [options.maskBuffer] The buffer used to store the masking\n   *     key\n   * @param {Number} options.opcode The opcode\n   * @param {Boolean} [options.readOnly=false] Specifies whether `data` can be\n   *     modified\n   * @param {Boolean} [options.rsv1=false] Specifies whether or not to set the\n   *     RSV1 bit\n   * @param {Function} [cb] Callback\n   * @private\n   */\n  getBlobData(blob, compress, options, cb) {\n    this._bufferedBytes += options[kByteLength];\n    this._state = GET_BLOB_DATA;\n\n    blob\n      .arrayBuffer()\n      .then((arrayBuffer) => {\n        if (this._socket.destroyed) {\n          const err = new Error(\n            'The socket was closed while the blob was being read'\n          );\n\n          //\n          // `callCallbacks` is called in the next tick to ensure that errors\n          // that might be thrown in the callbacks behave like errors thrown\n          // outside the promise chain.\n          //\n          process.nextTick(callCallbacks, this, err, cb);\n          return;\n        }\n\n        this._bufferedBytes -= options[kByteLength];\n        const data = toBuffer(arrayBuffer);\n\n        if (!compress) {\n          this._state = DEFAULT;\n          this.sendFrame(Sender.frame(data, options), cb);\n          this.dequeue();\n        } else {\n          this.dispatch(data, compress, options, cb);\n        }\n      })\n      .catch((err) => {\n        //\n        // `onError` is called in the next tick for the same reason that\n        // `callCallbacks` above is.\n        //\n        process.nextTick(onError, this, err, cb);\n      });\n  }\n\n  /**\n   * Dispatches a message.\n   *\n   * @param {(Buffer|String)} data The message to send\n   * @param {Boolean} [compress=false] Specifies whether or not to compress\n   *     `data`\n   * @param {Object} options Options object\n   * @param {Boolean} [options.fin=false] Specifies whether or not to set the\n   *     FIN bit\n   * @param {Function} [options.generateMask] The function used to generate the\n   *     masking key\n   * @param {Boolean} [options.mask=false] Specifies whether or not to mask\n   *     `data`\n   * @param {Buffer} [options.maskBuffer] The buffer used to store the masking\n   *     key\n   * @param {Number} options.opcode The opcode\n   * @param {Boolean} [options.readOnly=false] Specifies whether `data` can be\n   *     modified\n   * @param {Boolean} [options.rsv1=false] Specifies whether or not to set the\n   *     RSV1 bit\n   * @param {Function} [cb] Callback\n   * @private\n   */\n  dispatch(data, compress, options, cb) {\n    if (!compress) {\n      this.sendFrame(Sender.frame(data, options), cb);\n      return;\n    }\n\n    const perMessageDeflate = this._extensions[PerMessageDeflate.extensionName];\n\n    this._bufferedBytes += options[kByteLength];\n    this._state = DEFLATING;\n    perMessageDeflate.compress(data, options.fin, (_, buf) => {\n      if (this._socket.destroyed) {\n        const err = new Error(\n          'The socket was closed while data was being compressed'\n        );\n\n        callCallbacks(this, err, cb);\n        return;\n      }\n\n      this._bufferedBytes -= options[kByteLength];\n      this._state = DEFAULT;\n      options.readOnly = false;\n      this.sendFrame(Sender.frame(buf, options), cb);\n      this.dequeue();\n    });\n  }\n\n  /**\n   * Executes queued send operations.\n   *\n   * @private\n   */\n  dequeue() {\n    while (this._state === DEFAULT && this._queue.length) {\n      const params = this._queue.shift();\n\n      this._bufferedBytes -= params[3][kByteLength];\n      Reflect.apply(params[0], this, params.slice(1));\n    }\n  }\n\n  /**\n   * Enqueues a send operation.\n   *\n   * @param {Array} params Send operation parameters.\n   * @private\n   */\n  enqueue(params) {\n    this._bufferedBytes += params[3][kByteLength];\n    this._queue.push(params);\n  }\n\n  /**\n   * Sends a frame.\n   *\n   * @param {(Buffer | String)[]} list The frame to send\n   * @param {Function} [cb] Callback\n   * @private\n   */\n  sendFrame(list, cb) {\n    if (list.length === 2) {\n      this._socket.cork();\n      this._socket.write(list[0]);\n      this._socket.write(list[1], cb);\n      this._socket.uncork();\n    } else {\n      this._socket.write(list[0], cb);\n    }\n  }\n}\n\nmodule.exports = Sender;\n\n/**\n * Calls queued callbacks with an error.\n *\n * @param {Sender} sender The `Sender` instance\n * @param {Error} err The error to call the callbacks with\n * @param {Function} [cb] The first callback\n * @private\n */\nfunction callCallbacks(sender, err, cb) {\n  if (typeof cb === 'function') cb(err);\n\n  for (let i = 0; i < sender._queue.length; i++) {\n    const params = sender._queue[i];\n    const callback = params[params.length - 1];\n\n    if (typeof callback === 'function') callback(err);\n  }\n}\n\n/**\n * Handles a `Sender` error.\n *\n * @param {Sender} sender The `Sender` instance\n * @param {Error} err The error\n * @param {Function} [cb] The first pending callback\n * @private\n */\nfunction onError(sender, err, cb) {\n  callCallbacks(sender, err, cb);\n  sender.onerror(err);\n}\n","'use strict';\n\nconst { kForOnEventAttribute, kListener } = require('./constants');\n\nconst kCode = Symbol('kCode');\nconst kData = Symbol('kData');\nconst kError = Symbol('kError');\nconst kMessage = Symbol('kMessage');\nconst kReason = Symbol('kReason');\nconst kTarget = Symbol('kTarget');\nconst kType = Symbol('kType');\nconst kWasClean = Symbol('kWasClean');\n\n/**\n * Class representing an event.\n */\nclass Event {\n  /**\n   * Create a new `Event`.\n   *\n   * @param {String} type The name of the event\n   * @throws {TypeError} If the `type` argument is not specified\n   */\n  constructor(type) {\n    this[kTarget] = null;\n    this[kType] = type;\n  }\n\n  /**\n   * @type {*}\n   */\n  get target() {\n    return this[kTarget];\n  }\n\n  /**\n   * @type {String}\n   */\n  get type() {\n    return this[kType];\n  }\n}\n\nObject.defineProperty(Event.prototype, 'target', { enumerable: true });\nObject.defineProperty(Event.prototype, 'type', { enumerable: true });\n\n/**\n * Class representing a close event.\n *\n * @extends Event\n */\nclass CloseEvent extends Event {\n  /**\n   * Create a new `CloseEvent`.\n   *\n   * @param {String} type The name of the event\n   * @param {Object} [options] A dictionary object that allows for setting\n   *     attributes via object members of the same name\n   * @param {Number} [options.code=0] The status code explaining why the\n   *     connection was closed\n   * @param {String} [options.reason=''] A human-readable string explaining why\n   *     the connection was closed\n   * @param {Boolean} [options.wasClean=false] Indicates whether or not the\n   *     connection was cleanly closed\n   */\n  constructor(type, options = {}) {\n    super(type);\n\n    this[kCode] = options.code === undefined ? 0 : options.code;\n    this[kReason] = options.reason === undefined ? '' : options.reason;\n    this[kWasClean] = options.wasClean === undefined ? false : options.wasClean;\n  }\n\n  /**\n   * @type {Number}\n   */\n  get code() {\n    return this[kCode];\n  }\n\n  /**\n   * @type {String}\n   */\n  get reason() {\n    return this[kReason];\n  }\n\n  /**\n   * @type {Boolean}\n   */\n  get wasClean() {\n    return this[kWasClean];\n  }\n}\n\nObject.defineProperty(CloseEvent.prototype, 'code', { enumerable: true });\nObject.defineProperty(CloseEvent.prototype, 'reason', { enumerable: true });\nObject.defineProperty(CloseEvent.prototype, 'wasClean', { enumerable: true });\n\n/**\n * Class representing an error event.\n *\n * @extends Event\n */\nclass ErrorEvent extends Event {\n  /**\n   * Create a new `ErrorEvent`.\n   *\n   * @param {String} type The name of the event\n   * @param {Object} [options] A dictionary object that allows for setting\n   *     attributes via object members of the same name\n   * @param {*} [options.error=null] The error that generated this event\n   * @param {String} [options.message=''] The error message\n   */\n  constructor(type, options = {}) {\n    super(type);\n\n    this[kError] = options.error === undefined ? null : options.error;\n    this[kMessage] = options.message === undefined ? '' : options.message;\n  }\n\n  /**\n   * @type {*}\n   */\n  get error() {\n    return this[kError];\n  }\n\n  /**\n   * @type {String}\n   */\n  get message() {\n    return this[kMessage];\n  }\n}\n\nObject.defineProperty(ErrorEvent.prototype, 'error', { enumerable: true });\nObject.defineProperty(ErrorEvent.prototype, 'message', { enumerable: true });\n\n/**\n * Class representing a message event.\n *\n * @extends Event\n */\nclass MessageEvent extends Event {\n  /**\n   * Create a new `MessageEvent`.\n   *\n   * @param {String} type The name of the event\n   * @param {Object} [options] A dictionary object that allows for setting\n   *     attributes via object members of the same name\n   * @param {*} [options.data=null] The message content\n   */\n  constructor(type, options = {}) {\n    super(type);\n\n    this[kData] = options.data === undefined ? null : options.data;\n  }\n\n  /**\n   * @type {*}\n   */\n  get data() {\n    return this[kData];\n  }\n}\n\nObject.defineProperty(MessageEvent.prototype, 'data', { enumerable: true });\n\n/**\n * This provides methods for emulating the `EventTarget` interface. It's not\n * meant to be used directly.\n *\n * @mixin\n */\nconst EventTarget = {\n  /**\n   * Register an event listener.\n   *\n   * @param {String} type A string representing the event type to listen for\n   * @param {(Function|Object)} handler The listener to add\n   * @param {Object} [options] An options object specifies characteristics about\n   *     the event listener\n   * @param {Boolean} [options.once=false] A `Boolean` indicating that the\n   *     listener should be invoked at most once after being added. If `true`,\n   *     the listener would be automatically removed when invoked.\n   * @public\n   */\n  addEventListener(type, handler, options = {}) {\n    for (const listener of this.listeners(type)) {\n      if (\n        !options[kForOnEventAttribute] &&\n        listener[kListener] === handler &&\n        !listener[kForOnEventAttribute]\n      ) {\n        return;\n      }\n    }\n\n    let wrapper;\n\n    if (type === 'message') {\n      wrapper = function onMessage(data, isBinary) {\n        const event = new MessageEvent('message', {\n          data: isBinary ? data : data.toString()\n        });\n\n        event[kTarget] = this;\n        callListener(handler, this, event);\n      };\n    } else if (type === 'close') {\n      wrapper = function onClose(code, message) {\n        const event = new CloseEvent('close', {\n          code,\n          reason: message.toString(),\n          wasClean: this._closeFrameReceived && this._closeFrameSent\n        });\n\n        event[kTarget] = this;\n        callListener(handler, this, event);\n      };\n    } else if (type === 'error') {\n      wrapper = function onError(error) {\n        const event = new ErrorEvent('error', {\n          error,\n          message: error.message\n        });\n\n        event[kTarget] = this;\n        callListener(handler, this, event);\n      };\n    } else if (type === 'open') {\n      wrapper = function onOpen() {\n        const event = new Event('open');\n\n        event[kTarget] = this;\n        callListener(handler, this, event);\n      };\n    } else {\n      return;\n    }\n\n    wrapper[kForOnEventAttribute] = !!options[kForOnEventAttribute];\n    wrapper[kListener] = handler;\n\n    if (options.once) {\n      this.once(type, wrapper);\n    } else {\n      this.on(type, wrapper);\n    }\n  },\n\n  /**\n   * Remove an event listener.\n   *\n   * @param {String} type A string representing the event type to remove\n   * @param {(Function|Object)} handler The listener to remove\n   * @public\n   */\n  removeEventListener(type, handler) {\n    for (const listener of this.listeners(type)) {\n      if (listener[kListener] === handler && !listener[kForOnEventAttribute]) {\n        this.removeListener(type, listener);\n        break;\n      }\n    }\n  }\n};\n\nmodule.exports = {\n  CloseEvent,\n  ErrorEvent,\n  Event,\n  EventTarget,\n  MessageEvent\n};\n\n/**\n * Call an event listener\n *\n * @param {(Function|Object)} listener The listener to call\n * @param {*} thisArg The value to use as `this`` when calling the listener\n * @param {Event} event The event to pass to the listener\n * @private\n */\nfunction callListener(listener, thisArg, event) {\n  if (typeof listener === 'object' && listener.handleEvent) {\n    listener.handleEvent.call(listener, event);\n  } else {\n    listener.call(thisArg, event);\n  }\n}\n","'use strict';\n\nconst { tokenChars } = require('./validation');\n\n/**\n * Adds an offer to the map of extension offers or a parameter to the map of\n * parameters.\n *\n * @param {Object} dest The map of extension offers or parameters\n * @param {String} name The extension or parameter name\n * @param {(Object|Boolean|String)} elem The extension parameters or the\n *     parameter value\n * @private\n */\nfunction push(dest, name, elem) {\n  if (dest[name] === undefined) dest[name] = [elem];\n  else dest[name].push(elem);\n}\n\n/**\n * Parses the `Sec-WebSocket-Extensions` header into an object.\n *\n * @param {String} header The field value of the header\n * @return {Object} The parsed object\n * @public\n */\nfunction parse(header) {\n  const offers = Object.create(null);\n  let params = Object.create(null);\n  let mustUnescape = false;\n  let isEscaping = false;\n  let inQuotes = false;\n  let extensionName;\n  let paramName;\n  let start = -1;\n  let code = -1;\n  let end = -1;\n  let i = 0;\n\n  for (; i < header.length; i++) {\n    code = header.charCodeAt(i);\n\n    if (extensionName === undefined) {\n      if (end === -1 && tokenChars[code] === 1) {\n        if (start === -1) start = i;\n      } else if (\n        i !== 0 &&\n        (code === 0x20 /* ' ' */ || code === 0x09) /* '\\t' */\n      ) {\n        if (end === -1 && start !== -1) end = i;\n      } else if (code === 0x3b /* ';' */ || code === 0x2c /* ',' */) {\n        if (start === -1) {\n          throw new SyntaxError(`Unexpected character at index ${i}`);\n        }\n\n        if (end === -1) end = i;\n        const name = header.slice(start, end);\n        if (code === 0x2c) {\n          push(offers, name, params);\n          params = Object.create(null);\n        } else {\n          extensionName = name;\n        }\n\n        start = end = -1;\n      } else {\n        throw new SyntaxError(`Unexpected character at index ${i}`);\n      }\n    } else if (paramName === undefined) {\n      if (end === -1 && tokenChars[code] === 1) {\n        if (start === -1) start = i;\n      } else if (code === 0x20 || code === 0x09) {\n        if (end === -1 && start !== -1) end = i;\n      } else if (code === 0x3b || code === 0x2c) {\n        if (start === -1) {\n          throw new SyntaxError(`Unexpected character at index ${i}`);\n        }\n\n        if (end === -1) end = i;\n        push(params, header.slice(start, end), true);\n        if (code === 0x2c) {\n          push(offers, extensionName, params);\n          params = Object.create(null);\n          extensionName = undefined;\n        }\n\n        start = end = -1;\n      } else if (code === 0x3d /* '=' */ && start !== -1 && end === -1) {\n        paramName = header.slice(start, i);\n        start = end = -1;\n      } else {\n        throw new SyntaxError(`Unexpected character at index ${i}`);\n      }\n    } else {\n      //\n      // The value of a quoted-string after unescaping must conform to the\n      // token ABNF, so only token characters are valid.\n      // Ref: https://tools.ietf.org/html/rfc6455#section-9.1\n      //\n      if (isEscaping) {\n        if (tokenChars[code] !== 1) {\n          throw new SyntaxError(`Unexpected character at index ${i}`);\n        }\n        if (start === -1) start = i;\n        else if (!mustUnescape) mustUnescape = true;\n        isEscaping = false;\n      } else if (inQuotes) {\n        if (tokenChars[code] === 1) {\n          if (start === -1) start = i;\n        } else if (code === 0x22 /* '\"' */ && start !== -1) {\n          inQuotes = false;\n          end = i;\n        } else if (code === 0x5c /* '\\' */) {\n          isEscaping = true;\n        } else {\n          throw new SyntaxError(`Unexpected character at index ${i}`);\n        }\n      } else if (code === 0x22 && header.charCodeAt(i - 1) === 0x3d) {\n        inQuotes = true;\n      } else if (end === -1 && tokenChars[code] === 1) {\n        if (start === -1) start = i;\n      } else if (start !== -1 && (code === 0x20 || code === 0x09)) {\n        if (end === -1) end = i;\n      } else if (code === 0x3b || code === 0x2c) {\n        if (start === -1) {\n          throw new SyntaxError(`Unexpected character at index ${i}`);\n        }\n\n        if (end === -1) end = i;\n        let value = header.slice(start, end);\n        if (mustUnescape) {\n          value = value.replace(/\\\\/g, '');\n          mustUnescape = false;\n        }\n        push(params, paramName, value);\n        if (code === 0x2c) {\n          push(offers, extensionName, params);\n          params = Object.create(null);\n          extensionName = undefined;\n        }\n\n        paramName = undefined;\n        start = end = -1;\n      } else {\n        throw new SyntaxError(`Unexpected character at index ${i}`);\n      }\n    }\n  }\n\n  if (start === -1 || inQuotes || code === 0x20 || code === 0x09) {\n    throw new SyntaxError('Unexpected end of input');\n  }\n\n  if (end === -1) end = i;\n  const token = header.slice(start, end);\n  if (extensionName === undefined) {\n    push(offers, token, params);\n  } else {\n    if (paramName === undefined) {\n      push(params, token, true);\n    } else if (mustUnescape) {\n      push(params, paramName, token.replace(/\\\\/g, ''));\n    } else {\n      push(params, paramName, token);\n    }\n    push(offers, extensionName, params);\n  }\n\n  return offers;\n}\n\n/**\n * Builds the `Sec-WebSocket-Extensions` header field value.\n *\n * @param {Object} extensions The map of extensions and parameters to format\n * @return {String} A string representing the given object\n * @public\n */\nfunction format(extensions) {\n  return Object.keys(extensions)\n    .map((extension) => {\n      let configurations = extensions[extension];\n      if (!Array.isArray(configurations)) configurations = [configurations];\n      return configurations\n        .map((params) => {\n          return [extension]\n            .concat(\n              Object.keys(params).map((k) => {\n                let values = params[k];\n                if (!Array.isArray(values)) values = [values];\n                return values\n                  .map((v) => (v === true ? k : `${k}=${v}`))\n                  .join('; ');\n              })\n            )\n            .join('; ');\n        })\n        .join(', ');\n    })\n    .join(', ');\n}\n\nmodule.exports = { format, parse };\n","/* eslint no-unused-vars: [\"error\", { \"varsIgnorePattern\": \"^Duplex|Readable$\", \"caughtErrors\": \"none\" }] */\n\n'use strict';\n\nconst EventEmitter = require('events');\nconst https = require('https');\nconst http = require('http');\nconst net = require('net');\nconst tls = require('tls');\nconst { randomBytes, createHash } = require('crypto');\nconst { Duplex, Readable } = require('stream');\nconst { URL } = require('url');\n\nconst PerMessageDeflate = require('./permessage-deflate');\nconst Receiver = require('./receiver');\nconst Sender = require('./sender');\nconst { isBlob } = require('./validation');\n\nconst {\n  BINARY_TYPES,\n  EMPTY_BUFFER,\n  GUID,\n  kForOnEventAttribute,\n  kListener,\n  kStatusCode,\n  kWebSocket,\n  NOOP\n} = require('./constants');\nconst {\n  EventTarget: { addEventListener, removeEventListener }\n} = require('./event-target');\nconst { format, parse } = require('./extension');\nconst { toBuffer } = require('./buffer-util');\n\nconst closeTimeout = 30 * 1000;\nconst kAborted = Symbol('kAborted');\nconst protocolVersions = [8, 13];\nconst readyStates = ['CONNECTING', 'OPEN', 'CLOSING', 'CLOSED'];\nconst subprotocolRegex = /^[!#$%&'*+\\-.0-9A-Z^_`|a-z~]+$/;\n\n/**\n * Class representing a WebSocket.\n *\n * @extends EventEmitter\n */\nclass WebSocket extends EventEmitter {\n  /**\n   * Create a new `WebSocket`.\n   *\n   * @param {(String|URL)} address The URL to which to connect\n   * @param {(String|String[])} [protocols] The subprotocols\n   * @param {Object} [options] Connection options\n   */\n  constructor(address, protocols, options) {\n    super();\n\n    this._binaryType = BINARY_TYPES[0];\n    this._closeCode = 1006;\n    this._closeFrameReceived = false;\n    this._closeFrameSent = false;\n    this._closeMessage = EMPTY_BUFFER;\n    this._closeTimer = null;\n    this._errorEmitted = false;\n    this._extensions = {};\n    this._paused = false;\n    this._protocol = '';\n    this._readyState = WebSocket.CONNECTING;\n    this._receiver = null;\n    this._sender = null;\n    this._socket = null;\n\n    if (address !== null) {\n      this._bufferedAmount = 0;\n      this._isServer = false;\n      this._redirects = 0;\n\n      if (protocols === undefined) {\n        protocols = [];\n      } else if (!Array.isArray(protocols)) {\n        if (typeof protocols === 'object' && protocols !== null) {\n          options = protocols;\n          protocols = [];\n        } else {\n          protocols = [protocols];\n        }\n      }\n\n      initAsClient(this, address, protocols, options);\n    } else {\n      this._autoPong = options.autoPong;\n      this._isServer = true;\n    }\n  }\n\n  /**\n   * For historical reasons, the custom \"nodebuffer\" type is used by the default\n   * instead of \"blob\".\n   *\n   * @type {String}\n   */\n  get binaryType() {\n    return this._binaryType;\n  }\n\n  set binaryType(type) {\n    if (!BINARY_TYPES.includes(type)) return;\n\n    this._binaryType = type;\n\n    //\n    // Allow to change `binaryType` on the fly.\n    //\n    if (this._receiver) this._receiver._binaryType = type;\n  }\n\n  /**\n   * @type {Number}\n   */\n  get bufferedAmount() {\n    if (!this._socket) return this._bufferedAmount;\n\n    return this._socket._writableState.length + this._sender._bufferedBytes;\n  }\n\n  /**\n   * @type {String}\n   */\n  get extensions() {\n    return Object.keys(this._extensions).join();\n  }\n\n  /**\n   * @type {Boolean}\n   */\n  get isPaused() {\n    return this._paused;\n  }\n\n  /**\n   * @type {Function}\n   */\n  /* istanbul ignore next */\n  get onclose() {\n    return null;\n  }\n\n  /**\n   * @type {Function}\n   */\n  /* istanbul ignore next */\n  get onerror() {\n    return null;\n  }\n\n  /**\n   * @type {Function}\n   */\n  /* istanbul ignore next */\n  get onopen() {\n    return null;\n  }\n\n  /**\n   * @type {Function}\n   */\n  /* istanbul ignore next */\n  get onmessage() {\n    return null;\n  }\n\n  /**\n   * @type {String}\n   */\n  get protocol() {\n    return this._protocol;\n  }\n\n  /**\n   * @type {Number}\n   */\n  get readyState() {\n    return this._readyState;\n  }\n\n  /**\n   * @type {String}\n   */\n  get url() {\n    return this._url;\n  }\n\n  /**\n   * Set up the socket and the internal resources.\n   *\n   * @param {Duplex} socket The network socket between the server and client\n   * @param {Buffer} head The first packet of the upgraded stream\n   * @param {Object} options Options object\n   * @param {Boolean} [options.allowSynchronousEvents=false] Specifies whether\n   *     any of the `'message'`, `'ping'`, and `'pong'` events can be emitted\n   *     multiple times in the same tick\n   * @param {Function} [options.generateMask] The function used to generate the\n   *     masking key\n   * @param {Number} [options.maxPayload=0] The maximum allowed message size\n   * @param {Boolean} [options.skipUTF8Validation=false] Specifies whether or\n   *     not to skip UTF-8 validation for text and close messages\n   * @private\n   */\n  setSocket(socket, head, options) {\n    const receiver = new Receiver({\n      allowSynchronousEvents: options.allowSynchronousEvents,\n      binaryType: this.binaryType,\n      extensions: this._extensions,\n      isServer: this._isServer,\n      maxPayload: options.maxPayload,\n      skipUTF8Validation: options.skipUTF8Validation\n    });\n\n    const sender = new Sender(socket, this._extensions, options.generateMask);\n\n    this._receiver = receiver;\n    this._sender = sender;\n    this._socket = socket;\n\n    receiver[kWebSocket] = this;\n    sender[kWebSocket] = this;\n    socket[kWebSocket] = this;\n\n    receiver.on('conclude', receiverOnConclude);\n    receiver.on('drain', receiverOnDrain);\n    receiver.on('error', receiverOnError);\n    receiver.on('message', receiverOnMessage);\n    receiver.on('ping', receiverOnPing);\n    receiver.on('pong', receiverOnPong);\n\n    sender.onerror = senderOnError;\n\n    //\n    // These methods may not be available if `socket` is just a `Duplex`.\n    //\n    if (socket.setTimeout) socket.setTimeout(0);\n    if (socket.setNoDelay) socket.setNoDelay();\n\n    if (head.length > 0) socket.unshift(head);\n\n    socket.on('close', socketOnClose);\n    socket.on('data', socketOnData);\n    socket.on('end', socketOnEnd);\n    socket.on('error', socketOnError);\n\n    this._readyState = WebSocket.OPEN;\n    this.emit('open');\n  }\n\n  /**\n   * Emit the `'close'` event.\n   *\n   * @private\n   */\n  emitClose() {\n    if (!this._socket) {\n      this._readyState = WebSocket.CLOSED;\n      this.emit('close', this._closeCode, this._closeMessage);\n      return;\n    }\n\n    if (this._extensions[PerMessageDeflate.extensionName]) {\n      this._extensions[PerMessageDeflate.extensionName].cleanup();\n    }\n\n    this._receiver.removeAllListeners();\n    this._readyState = WebSocket.CLOSED;\n    this.emit('close', this._closeCode, this._closeMessage);\n  }\n\n  /**\n   * Start a closing handshake.\n   *\n   *          +----------+   +-----------+   +----------+\n   *     - - -|ws.close()|-->|close frame|-->|ws.close()|- - -\n   *    |     +----------+   +-----------+   +----------+     |\n   *          +----------+   +-----------+         |\n   * CLOSING  |ws.close()|<--|close frame|<--+-----+       CLOSING\n   *          +----------+   +-----------+   |\n   *    |           |                        |   +---+        |\n   *                +------------------------+-->|fin| - - - -\n   *    |         +---+                      |   +---+\n   *     - - - - -|fin|<---------------------+\n   *              +---+\n   *\n   * @param {Number} [code] Status code explaining why the connection is closing\n   * @param {(String|Buffer)} [data] The reason why the connection is\n   *     closing\n   * @public\n   */\n  close(code, data) {\n    if (this.readyState === WebSocket.CLOSED) return;\n    if (this.readyState === WebSocket.CONNECTING) {\n      const msg = 'WebSocket was closed before the connection was established';\n      abortHandshake(this, this._req, msg);\n      return;\n    }\n\n    if (this.readyState === WebSocket.CLOSING) {\n      if (\n        this._closeFrameSent &&\n        (this._closeFrameReceived || this._receiver._writableState.errorEmitted)\n      ) {\n        this._socket.end();\n      }\n\n      return;\n    }\n\n    this._readyState = WebSocket.CLOSING;\n    this._sender.close(code, data, !this._isServer, (err) => {\n      //\n      // This error is handled by the `'error'` listener on the socket. We only\n      // want to know if the close frame has been sent here.\n      //\n      if (err) return;\n\n      this._closeFrameSent = true;\n\n      if (\n        this._closeFrameReceived ||\n        this._receiver._writableState.errorEmitted\n      ) {\n        this._socket.end();\n      }\n    });\n\n    setCloseTimer(this);\n  }\n\n  /**\n   * Pause the socket.\n   *\n   * @public\n   */\n  pause() {\n    if (\n      this.readyState === WebSocket.CONNECTING ||\n      this.readyState === WebSocket.CLOSED\n    ) {\n      return;\n    }\n\n    this._paused = true;\n    this._socket.pause();\n  }\n\n  /**\n   * Send a ping.\n   *\n   * @param {*} [data] The data to send\n   * @param {Boolean} [mask] Indicates whether or not to mask `data`\n   * @param {Function} [cb] Callback which is executed when the ping is sent\n   * @public\n   */\n  ping(data, mask, cb) {\n    if (this.readyState === WebSocket.CONNECTING) {\n      throw new Error('WebSocket is not open: readyState 0 (CONNECTING)');\n    }\n\n    if (typeof data === 'function') {\n      cb = data;\n      data = mask = undefined;\n    } else if (typeof mask === 'function') {\n      cb = mask;\n      mask = undefined;\n    }\n\n    if (typeof data === 'number') data = data.toString();\n\n    if (this.readyState !== WebSocket.OPEN) {\n      sendAfterClose(this, data, cb);\n      return;\n    }\n\n    if (mask === undefined) mask = !this._isServer;\n    this._sender.ping(data || EMPTY_BUFFER, mask, cb);\n  }\n\n  /**\n   * Send a pong.\n   *\n   * @param {*} [data] The data to send\n   * @param {Boolean} [mask] Indicates whether or not to mask `data`\n   * @param {Function} [cb] Callback which is executed when the pong is sent\n   * @public\n   */\n  pong(data, mask, cb) {\n    if (this.readyState === WebSocket.CONNECTING) {\n      throw new Error('WebSocket is not open: readyState 0 (CONNECTING)');\n    }\n\n    if (typeof data === 'function') {\n      cb = data;\n      data = mask = undefined;\n    } else if (typeof mask === 'function') {\n      cb = mask;\n      mask = undefined;\n    }\n\n    if (typeof data === 'number') data = data.toString();\n\n    if (this.readyState !== WebSocket.OPEN) {\n      sendAfterClose(this, data, cb);\n      return;\n    }\n\n    if (mask === undefined) mask = !this._isServer;\n    this._sender.pong(data || EMPTY_BUFFER, mask, cb);\n  }\n\n  /**\n   * Resume the socket.\n   *\n   * @public\n   */\n  resume() {\n    if (\n      this.readyState === WebSocket.CONNECTING ||\n      this.readyState === WebSocket.CLOSED\n    ) {\n      return;\n    }\n\n    this._paused = false;\n    if (!this._receiver._writableState.needDrain) this._socket.resume();\n  }\n\n  /**\n   * Send a data message.\n   *\n   * @param {*} data The message to send\n   * @param {Object} [options] Options object\n   * @param {Boolean} [options.binary] Specifies whether `data` is binary or\n   *     text\n   * @param {Boolean} [options.compress] Specifies whether or not to compress\n   *     `data`\n   * @param {Boolean} [options.fin=true] Specifies whether the fragment is the\n   *     last one\n   * @param {Boolean} [options.mask] Specifies whether or not to mask `data`\n   * @param {Function} [cb] Callback which is executed when data is written out\n   * @public\n   */\n  send(data, options, cb) {\n    if (this.readyState === WebSocket.CONNECTING) {\n      throw new Error('WebSocket is not open: readyState 0 (CONNECTING)');\n    }\n\n    if (typeof options === 'function') {\n      cb = options;\n      options = {};\n    }\n\n    if (typeof data === 'number') data = data.toString();\n\n    if (this.readyState !== WebSocket.OPEN) {\n      sendAfterClose(this, data, cb);\n      return;\n    }\n\n    const opts = {\n      binary: typeof data !== 'string',\n      mask: !this._isServer,\n      compress: true,\n      fin: true,\n      ...options\n    };\n\n    if (!this._extensions[PerMessageDeflate.extensionName]) {\n      opts.compress = false;\n    }\n\n    this._sender.send(data || EMPTY_BUFFER, opts, cb);\n  }\n\n  /**\n   * Forcibly close the connection.\n   *\n   * @public\n   */\n  terminate() {\n    if (this.readyState === WebSocket.CLOSED) return;\n    if (this.readyState === WebSocket.CONNECTING) {\n      const msg = 'WebSocket was closed before the connection was established';\n      abortHandshake(this, this._req, msg);\n      return;\n    }\n\n    if (this._socket) {\n      this._readyState = WebSocket.CLOSING;\n      this._socket.destroy();\n    }\n  }\n}\n\n/**\n * @constant {Number} CONNECTING\n * @memberof WebSocket\n */\nObject.defineProperty(WebSocket, 'CONNECTING', {\n  enumerable: true,\n  value: readyStates.indexOf('CONNECTING')\n});\n\n/**\n * @constant {Number} CONNECTING\n * @memberof WebSocket.prototype\n */\nObject.defineProperty(WebSocket.prototype, 'CONNECTING', {\n  enumerable: true,\n  value: readyStates.indexOf('CONNECTING')\n});\n\n/**\n * @constant {Number} OPEN\n * @memberof WebSocket\n */\nObject.defineProperty(WebSocket, 'OPEN', {\n  enumerable: true,\n  value: readyStates.indexOf('OPEN')\n});\n\n/**\n * @constant {Number} OPEN\n * @memberof WebSocket.prototype\n */\nObject.defineProperty(WebSocket.prototype, 'OPEN', {\n  enumerable: true,\n  value: readyStates.indexOf('OPEN')\n});\n\n/**\n * @constant {Number} CLOSING\n * @memberof WebSocket\n */\nObject.defineProperty(WebSocket, 'CLOSING', {\n  enumerable: true,\n  value: readyStates.indexOf('CLOSING')\n});\n\n/**\n * @constant {Number} CLOSING\n * @memberof WebSocket.prototype\n */\nObject.defineProperty(WebSocket.prototype, 'CLOSING', {\n  enumerable: true,\n  value: readyStates.indexOf('CLOSING')\n});\n\n/**\n * @constant {Number} CLOSED\n * @memberof WebSocket\n */\nObject.defineProperty(WebSocket, 'CLOSED', {\n  enumerable: true,\n  value: readyStates.indexOf('CLOSED')\n});\n\n/**\n * @constant {Number} CLOSED\n * @memberof WebSocket.prototype\n */\nObject.defineProperty(WebSocket.prototype, 'CLOSED', {\n  enumerable: true,\n  value: readyStates.indexOf('CLOSED')\n});\n\n[\n  'binaryType',\n  'bufferedAmount',\n  'extensions',\n  'isPaused',\n  'protocol',\n  'readyState',\n  'url'\n].forEach((property) => {\n  Object.defineProperty(WebSocket.prototype, property, { enumerable: true });\n});\n\n//\n// Add the `onopen`, `onerror`, `onclose`, and `onmessage` attributes.\n// See https://html.spec.whatwg.org/multipage/comms.html#the-websocket-interface\n//\n['open', 'error', 'close', 'message'].forEach((method) => {\n  Object.defineProperty(WebSocket.prototype, `on${method}`, {\n    enumerable: true,\n    get() {\n      for (const listener of this.listeners(method)) {\n        if (listener[kForOnEventAttribute]) return listener[kListener];\n      }\n\n      return null;\n    },\n    set(handler) {\n      for (const listener of this.listeners(method)) {\n        if (listener[kForOnEventAttribute]) {\n          this.removeListener(method, listener);\n          break;\n        }\n      }\n\n      if (typeof handler !== 'function') return;\n\n      this.addEventListener(method, handler, {\n        [kForOnEventAttribute]: true\n      });\n    }\n  });\n});\n\nWebSocket.prototype.addEventListener = addEventListener;\nWebSocket.prototype.removeEventListener = removeEventListener;\n\nmodule.exports = WebSocket;\n\n/**\n * Initialize a WebSocket client.\n *\n * @param {WebSocket} websocket The client to initialize\n * @param {(String|URL)} address The URL to which to connect\n * @param {Array} protocols The subprotocols\n * @param {Object} [options] Connection options\n * @param {Boolean} [options.allowSynchronousEvents=true] Specifies whether any\n *     of the `'message'`, `'ping'`, and `'pong'` events can be emitted multiple\n *     times in the same tick\n * @param {Boolean} [options.autoPong=true] Specifies whether or not to\n *     automatically send a pong in response to a ping\n * @param {Function} [options.finishRequest] A function which can be used to\n *     customize the headers of each http request before it is sent\n * @param {Boolean} [options.followRedirects=false] Whether or not to follow\n *     redirects\n * @param {Function} [options.generateMask] The function used to generate the\n *     masking key\n * @param {Number} [options.handshakeTimeout] Timeout in milliseconds for the\n *     handshake request\n * @param {Number} [options.maxPayload=104857600] The maximum allowed message\n *     size\n * @param {Number} [options.maxRedirects=10] The maximum number of redirects\n *     allowed\n * @param {String} [options.origin] Value of the `Origin` or\n *     `Sec-WebSocket-Origin` header\n * @param {(Boolean|Object)} [options.perMessageDeflate=true] Enable/disable\n *     permessage-deflate\n * @param {Number} [options.protocolVersion=13] Value of the\n *     `Sec-WebSocket-Version` header\n * @param {Boolean} [options.skipUTF8Validation=false] Specifies whether or\n *     not to skip UTF-8 validation for text and close messages\n * @private\n */\nfunction initAsClient(websocket, address, protocols, options) {\n  const opts = {\n    allowSynchronousEvents: true,\n    autoPong: true,\n    protocolVersion: protocolVersions[1],\n    maxPayload: 100 * 1024 * 1024,\n    skipUTF8Validation: false,\n    perMessageDeflate: true,\n    followRedirects: false,\n    maxRedirects: 10,\n    ...options,\n    socketPath: undefined,\n    hostname: undefined,\n    protocol: undefined,\n    timeout: undefined,\n    method: 'GET',\n    host: undefined,\n    path: undefined,\n    port: undefined\n  };\n\n  websocket._autoPong = opts.autoPong;\n\n  if (!protocolVersions.includes(opts.protocolVersion)) {\n    throw new RangeError(\n      `Unsupported protocol version: ${opts.protocolVersion} ` +\n        `(supported versions: ${protocolVersions.join(', ')})`\n    );\n  }\n\n  let parsedUrl;\n\n  if (address instanceof URL) {\n    parsedUrl = address;\n  } else {\n    try {\n      parsedUrl = new URL(address);\n    } catch (e) {\n      throw new SyntaxError(`Invalid URL: ${address}`);\n    }\n  }\n\n  if (parsedUrl.protocol === 'http:') {\n    parsedUrl.protocol = 'ws:';\n  } else if (parsedUrl.protocol === 'https:') {\n    parsedUrl.protocol = 'wss:';\n  }\n\n  websocket._url = parsedUrl.href;\n\n  const isSecure = parsedUrl.protocol === 'wss:';\n  const isIpcUrl = parsedUrl.protocol === 'ws+unix:';\n  let invalidUrlMessage;\n\n  if (parsedUrl.protocol !== 'ws:' && !isSecure && !isIpcUrl) {\n    invalidUrlMessage =\n      'The URL\\'s protocol must be one of \"ws:\", \"wss:\", ' +\n      '\"http:\", \"https:\", or \"ws+unix:\"';\n  } else if (isIpcUrl && !parsedUrl.pathname) {\n    invalidUrlMessage = \"The URL's pathname is empty\";\n  } else if (parsedUrl.hash) {\n    invalidUrlMessage = 'The URL contains a fragment identifier';\n  }\n\n  if (invalidUrlMessage) {\n    const err = new SyntaxError(invalidUrlMessage);\n\n    if (websocket._redirects === 0) {\n      throw err;\n    } else {\n      emitErrorAndClose(websocket, err);\n      return;\n    }\n  }\n\n  const defaultPort = isSecure ? 443 : 80;\n  const key = randomBytes(16).toString('base64');\n  const request = isSecure ? https.request : http.request;\n  const protocolSet = new Set();\n  let perMessageDeflate;\n\n  opts.createConnection =\n    opts.createConnection || (isSecure ? tlsConnect : netConnect);\n  opts.defaultPort = opts.defaultPort || defaultPort;\n  opts.port = parsedUrl.port || defaultPort;\n  opts.host = parsedUrl.hostname.startsWith('[')\n    ? parsedUrl.hostname.slice(1, -1)\n    : parsedUrl.hostname;\n  opts.headers = {\n    ...opts.headers,\n    'Sec-WebSocket-Version': opts.protocolVersion,\n    'Sec-WebSocket-Key': key,\n    Connection: 'Upgrade',\n    Upgrade: 'websocket'\n  };\n  opts.path = parsedUrl.pathname + parsedUrl.search;\n  opts.timeout = opts.handshakeTimeout;\n\n  if (opts.perMessageDeflate) {\n    perMessageDeflate = new PerMessageDeflate(\n      opts.perMessageDeflate !== true ? opts.perMessageDeflate : {},\n      false,\n      opts.maxPayload\n    );\n    opts.headers['Sec-WebSocket-Extensions'] = format({\n      [PerMessageDeflate.extensionName]: perMessageDeflate.offer()\n    });\n  }\n  if (protocols.length) {\n    for (const protocol of protocols) {\n      if (\n        typeof protocol !== 'string' ||\n        !subprotocolRegex.test(protocol) ||\n        protocolSet.has(protocol)\n      ) {\n        throw new SyntaxError(\n          'An invalid or duplicated subprotocol was specified'\n        );\n      }\n\n      protocolSet.add(protocol);\n    }\n\n    opts.headers['Sec-WebSocket-Protocol'] = protocols.join(',');\n  }\n  if (opts.origin) {\n    if (opts.protocolVersion < 13) {\n      opts.headers['Sec-WebSocket-Origin'] = opts.origin;\n    } else {\n      opts.headers.Origin = opts.origin;\n    }\n  }\n  if (parsedUrl.username || parsedUrl.password) {\n    opts.auth = `${parsedUrl.username}:${parsedUrl.password}`;\n  }\n\n  if (isIpcUrl) {\n    const parts = opts.path.split(':');\n\n    opts.socketPath = parts[0];\n    opts.path = parts[1];\n  }\n\n  let req;\n\n  if (opts.followRedirects) {\n    if (websocket._redirects === 0) {\n      websocket._originalIpc = isIpcUrl;\n      websocket._originalSecure = isSecure;\n      websocket._originalHostOrSocketPath = isIpcUrl\n        ? opts.socketPath\n        : parsedUrl.host;\n\n      const headers = options && options.headers;\n\n      //\n      // Shallow copy the user provided options so that headers can be changed\n      // without mutating the original object.\n      //\n      options = { ...options, headers: {} };\n\n      if (headers) {\n        for (const [key, value] of Object.entries(headers)) {\n          options.headers[key.toLowerCase()] = value;\n        }\n      }\n    } else if (websocket.listenerCount('redirect') === 0) {\n      const isSameHost = isIpcUrl\n        ? websocket._originalIpc\n          ? opts.socketPath === websocket._originalHostOrSocketPath\n          : false\n        : websocket._originalIpc\n          ? false\n          : parsedUrl.host === websocket._originalHostOrSocketPath;\n\n      if (!isSameHost || (websocket._originalSecure && !isSecure)) {\n        //\n        // Match curl 7.77.0 behavior and drop the following headers. These\n        // headers are also dropped when following a redirect to a subdomain.\n        //\n        delete opts.headers.authorization;\n        delete opts.headers.cookie;\n\n        if (!isSameHost) delete opts.headers.host;\n\n        opts.auth = undefined;\n      }\n    }\n\n    //\n    // Match curl 7.77.0 behavior and make the first `Authorization` header win.\n    // If the `Authorization` header is set, then there is nothing to do as it\n    // will take precedence.\n    //\n    if (opts.auth && !options.headers.authorization) {\n      options.headers.authorization =\n        'Basic ' + Buffer.from(opts.auth).toString('base64');\n    }\n\n    req = websocket._req = request(opts);\n\n    if (websocket._redirects) {\n      //\n      // Unlike what is done for the `'upgrade'` event, no early exit is\n      // triggered here if the user calls `websocket.close()` or\n      // `websocket.terminate()` from a listener of the `'redirect'` event. This\n      // is because the user can also call `request.destroy()` with an error\n      // before calling `websocket.close()` or `websocket.terminate()` and this\n      // would result in an error being emitted on the `request` object with no\n      // `'error'` event listeners attached.\n      //\n      websocket.emit('redirect', websocket.url, req);\n    }\n  } else {\n    req = websocket._req = request(opts);\n  }\n\n  if (opts.timeout) {\n    req.on('timeout', () => {\n      abortHandshake(websocket, req, 'Opening handshake has timed out');\n    });\n  }\n\n  req.on('error', (err) => {\n    if (req === null || req[kAborted]) return;\n\n    req = websocket._req = null;\n    emitErrorAndClose(websocket, err);\n  });\n\n  req.on('response', (res) => {\n    const location = res.headers.location;\n    const statusCode = res.statusCode;\n\n    if (\n      location &&\n      opts.followRedirects &&\n      statusCode >= 300 &&\n      statusCode < 400\n    ) {\n      if (++websocket._redirects > opts.maxRedirects) {\n        abortHandshake(websocket, req, 'Maximum redirects exceeded');\n        return;\n      }\n\n      req.abort();\n\n      let addr;\n\n      try {\n        addr = new URL(location, address);\n      } catch (e) {\n        const err = new SyntaxError(`Invalid URL: ${location}`);\n        emitErrorAndClose(websocket, err);\n        return;\n      }\n\n      initAsClient(websocket, addr, protocols, options);\n    } else if (!websocket.emit('unexpected-response', req, res)) {\n      abortHandshake(\n        websocket,\n        req,\n        `Unexpected server response: ${res.statusCode}`\n      );\n    }\n  });\n\n  req.on('upgrade', (res, socket, head) => {\n    websocket.emit('upgrade', res);\n\n    //\n    // The user may have closed the connection from a listener of the\n    // `'upgrade'` event.\n    //\n    if (websocket.readyState !== WebSocket.CONNECTING) return;\n\n    req = websocket._req = null;\n\n    const upgrade = res.headers.upgrade;\n\n    if (upgrade === undefined || upgrade.toLowerCase() !== 'websocket') {\n      abortHandshake(websocket, socket, 'Invalid Upgrade header');\n      return;\n    }\n\n    const digest = createHash('sha1')\n      .update(key + GUID)\n      .digest('base64');\n\n    if (res.headers['sec-websocket-accept'] !== digest) {\n      abortHandshake(websocket, socket, 'Invalid Sec-WebSocket-Accept header');\n      return;\n    }\n\n    const serverProt = res.headers['sec-websocket-protocol'];\n    let protError;\n\n    if (serverProt !== undefined) {\n      if (!protocolSet.size) {\n        protError = 'Server sent a subprotocol but none was requested';\n      } else if (!protocolSet.has(serverProt)) {\n        protError = 'Server sent an invalid subprotocol';\n      }\n    } else if (protocolSet.size) {\n      protError = 'Server sent no subprotocol';\n    }\n\n    if (protError) {\n      abortHandshake(websocket, socket, protError);\n      return;\n    }\n\n    if (serverProt) websocket._protocol = serverProt;\n\n    const secWebSocketExtensions = res.headers['sec-websocket-extensions'];\n\n    if (secWebSocketExtensions !== undefined) {\n      if (!perMessageDeflate) {\n        const message =\n          'Server sent a Sec-WebSocket-Extensions header but no extension ' +\n          'was requested';\n        abortHandshake(websocket, socket, message);\n        return;\n      }\n\n      let extensions;\n\n      try {\n        extensions = parse(secWebSocketExtensions);\n      } catch (err) {\n        const message = 'Invalid Sec-WebSocket-Extensions header';\n        abortHandshake(websocket, socket, message);\n        return;\n      }\n\n      const extensionNames = Object.keys(extensions);\n\n      if (\n        extensionNames.length !== 1 ||\n        extensionNames[0] !== PerMessageDeflate.extensionName\n      ) {\n        const message = 'Server indicated an extension that was not requested';\n        abortHandshake(websocket, socket, message);\n        return;\n      }\n\n      try {\n        perMessageDeflate.accept(extensions[PerMessageDeflate.extensionName]);\n      } catch (err) {\n        const message = 'Invalid Sec-WebSocket-Extensions header';\n        abortHandshake(websocket, socket, message);\n        return;\n      }\n\n      websocket._extensions[PerMessageDeflate.extensionName] =\n        perMessageDeflate;\n    }\n\n    websocket.setSocket(socket, head, {\n      allowSynchronousEvents: opts.allowSynchronousEvents,\n      generateMask: opts.generateMask,\n      maxPayload: opts.maxPayload,\n      skipUTF8Validation: opts.skipUTF8Validation\n    });\n  });\n\n  if (opts.finishRequest) {\n    opts.finishRequest(req, websocket);\n  } else {\n    req.end();\n  }\n}\n\n/**\n * Emit the `'error'` and `'close'` events.\n *\n * @param {WebSocket} websocket The WebSocket instance\n * @param {Error} The error to emit\n * @private\n */\nfunction emitErrorAndClose(websocket, err) {\n  websocket._readyState = WebSocket.CLOSING;\n  //\n  // The following assignment is practically useless and is done only for\n  // consistency.\n  //\n  websocket._errorEmitted = true;\n  websocket.emit('error', err);\n  websocket.emitClose();\n}\n\n/**\n * Create a `net.Socket` and initiate a connection.\n *\n * @param {Object} options Connection options\n * @return {net.Socket} The newly created socket used to start the connection\n * @private\n */\nfunction netConnect(options) {\n  options.path = options.socketPath;\n  return net.connect(options);\n}\n\n/**\n * Create a `tls.TLSSocket` and initiate a connection.\n *\n * @param {Object} options Connection options\n * @return {tls.TLSSocket} The newly created socket used to start the connection\n * @private\n */\nfunction tlsConnect(options) {\n  options.path = undefined;\n\n  if (!options.servername && options.servername !== '') {\n    options.servername = net.isIP(options.host) ? '' : options.host;\n  }\n\n  return tls.connect(options);\n}\n\n/**\n * Abort the handshake and emit an error.\n *\n * @param {WebSocket} websocket The WebSocket instance\n * @param {(http.ClientRequest|net.Socket|tls.Socket)} stream The request to\n *     abort or the socket to destroy\n * @param {String} message The error message\n * @private\n */\nfunction abortHandshake(websocket, stream, message) {\n  websocket._readyState = WebSocket.CLOSING;\n\n  const err = new Error(message);\n  Error.captureStackTrace(err, abortHandshake);\n\n  if (stream.setHeader) {\n    stream[kAborted] = true;\n    stream.abort();\n\n    if (stream.socket && !stream.socket.destroyed) {\n      //\n      // On Node.js >= 14.3.0 `request.abort()` does not destroy the socket if\n      // called after the request completed. See\n      // https://github.com/websockets/ws/issues/1869.\n      //\n      stream.socket.destroy();\n    }\n\n    process.nextTick(emitErrorAndClose, websocket, err);\n  } else {\n    stream.destroy(err);\n    stream.once('error', websocket.emit.bind(websocket, 'error'));\n    stream.once('close', websocket.emitClose.bind(websocket));\n  }\n}\n\n/**\n * Handle cases where the `ping()`, `pong()`, or `send()` methods are called\n * when the `readyState` attribute is `CLOSING` or `CLOSED`.\n *\n * @param {WebSocket} websocket The WebSocket instance\n * @param {*} [data] The data to send\n * @param {Function} [cb] Callback\n * @private\n */\nfunction sendAfterClose(websocket, data, cb) {\n  if (data) {\n    const length = isBlob(data) ? data.size : toBuffer(data).length;\n\n    //\n    // The `_bufferedAmount` property is used only when the peer is a client and\n    // the opening handshake fails. Under these circumstances, in fact, the\n    // `setSocket()` method is not called, so the `_socket` and `_sender`\n    // properties are set to `null`.\n    //\n    if (websocket._socket) websocket._sender._bufferedBytes += length;\n    else websocket._bufferedAmount += length;\n  }\n\n  if (cb) {\n    const err = new Error(\n      `WebSocket is not open: readyState ${websocket.readyState} ` +\n        `(${readyStates[websocket.readyState]})`\n    );\n    process.nextTick(cb, err);\n  }\n}\n\n/**\n * The listener of the `Receiver` `'conclude'` event.\n *\n * @param {Number} code The status code\n * @param {Buffer} reason The reason for closing\n * @private\n */\nfunction receiverOnConclude(code, reason) {\n  const websocket = this[kWebSocket];\n\n  websocket._closeFrameReceived = true;\n  websocket._closeMessage = reason;\n  websocket._closeCode = code;\n\n  if (websocket._socket[kWebSocket] === undefined) return;\n\n  websocket._socket.removeListener('data', socketOnData);\n  process.nextTick(resume, websocket._socket);\n\n  if (code === 1005) websocket.close();\n  else websocket.close(code, reason);\n}\n\n/**\n * The listener of the `Receiver` `'drain'` event.\n *\n * @private\n */\nfunction receiverOnDrain() {\n  const websocket = this[kWebSocket];\n\n  if (!websocket.isPaused) websocket._socket.resume();\n}\n\n/**\n * The listener of the `Receiver` `'error'` event.\n *\n * @param {(RangeError|Error)} err The emitted error\n * @private\n */\nfunction receiverOnError(err) {\n  const websocket = this[kWebSocket];\n\n  if (websocket._socket[kWebSocket] !== undefined) {\n    websocket._socket.removeListener('data', socketOnData);\n\n    //\n    // On Node.js < 14.0.0 the `'error'` event is emitted synchronously. See\n    // https://github.com/websockets/ws/issues/1940.\n    //\n    process.nextTick(resume, websocket._socket);\n\n    websocket.close(err[kStatusCode]);\n  }\n\n  if (!websocket._errorEmitted) {\n    websocket._errorEmitted = true;\n    websocket.emit('error', err);\n  }\n}\n\n/**\n * The listener of the `Receiver` `'finish'` event.\n *\n * @private\n */\nfunction receiverOnFinish() {\n  this[kWebSocket].emitClose();\n}\n\n/**\n * The listener of the `Receiver` `'message'` event.\n *\n * @param {Buffer|ArrayBuffer|Buffer[])} data The message\n * @param {Boolean} isBinary Specifies whether the message is binary or not\n * @private\n */\nfunction receiverOnMessage(data, isBinary) {\n  this[kWebSocket].emit('message', data, isBinary);\n}\n\n/**\n * The listener of the `Receiver` `'ping'` event.\n *\n * @param {Buffer} data The data included in the ping frame\n * @private\n */\nfunction receiverOnPing(data) {\n  const websocket = this[kWebSocket];\n\n  if (websocket._autoPong) websocket.pong(data, !this._isServer, NOOP);\n  websocket.emit('ping', data);\n}\n\n/**\n * The listener of the `Receiver` `'pong'` event.\n *\n * @param {Buffer} data The data included in the pong frame\n * @private\n */\nfunction receiverOnPong(data) {\n  this[kWebSocket].emit('pong', data);\n}\n\n/**\n * Resume a readable stream\n *\n * @param {Readable} stream The readable stream\n * @private\n */\nfunction resume(stream) {\n  stream.resume();\n}\n\n/**\n * The `Sender` error event handler.\n *\n * @param {Error} The error\n * @private\n */\nfunction senderOnError(err) {\n  const websocket = this[kWebSocket];\n\n  if (websocket.readyState === WebSocket.CLOSED) return;\n  if (websocket.readyState === WebSocket.OPEN) {\n    websocket._readyState = WebSocket.CLOSING;\n    setCloseTimer(websocket);\n  }\n\n  //\n  // `socket.end()` is used instead of `socket.destroy()` to allow the other\n  // peer to finish sending queued data. There is no need to set a timer here\n  // because `CLOSING` means that it is already set or not needed.\n  //\n  this._socket.end();\n\n  if (!websocket._errorEmitted) {\n    websocket._errorEmitted = true;\n    websocket.emit('error', err);\n  }\n}\n\n/**\n * Set a timer to destroy the underlying raw socket of a WebSocket.\n *\n * @param {WebSocket} websocket The WebSocket instance\n * @private\n */\nfunction setCloseTimer(websocket) {\n  websocket._closeTimer = setTimeout(\n    websocket._socket.destroy.bind(websocket._socket),\n    closeTimeout\n  );\n}\n\n/**\n * The listener of the socket `'close'` event.\n *\n * @private\n */\nfunction socketOnClose() {\n  const websocket = this[kWebSocket];\n\n  this.removeListener('close', socketOnClose);\n  this.removeListener('data', socketOnData);\n  this.removeListener('end', socketOnEnd);\n\n  websocket._readyState = WebSocket.CLOSING;\n\n  let chunk;\n\n  //\n  // The close frame might not have been received or the `'end'` event emitted,\n  // for example, if the socket was destroyed due to an error. Ensure that the\n  // `receiver` stream is closed after writing any remaining buffered data to\n  // it. If the readable side of the socket is in flowing mode then there is no\n  // buffered data as everything has been already written and `readable.read()`\n  // will return `null`. If instead, the socket is paused, any possible buffered\n  // data will be read as a single chunk.\n  //\n  if (\n    !this._readableState.endEmitted &&\n    !websocket._closeFrameReceived &&\n    !websocket._receiver._writableState.errorEmitted &&\n    (chunk = websocket._socket.read()) !== null\n  ) {\n    websocket._receiver.write(chunk);\n  }\n\n  websocket._receiver.end();\n\n  this[kWebSocket] = undefined;\n\n  clearTimeout(websocket._closeTimer);\n\n  if (\n    websocket._receiver._writableState.finished ||\n    websocket._receiver._writableState.errorEmitted\n  ) {\n    websocket.emitClose();\n  } else {\n    websocket._receiver.on('error', receiverOnFinish);\n    websocket._receiver.on('finish', receiverOnFinish);\n  }\n}\n\n/**\n * The listener of the socket `'data'` event.\n *\n * @param {Buffer} chunk A chunk of data\n * @private\n */\nfunction socketOnData(chunk) {\n  if (!this[kWebSocket]._receiver.write(chunk)) {\n    this.pause();\n  }\n}\n\n/**\n * The listener of the socket `'end'` event.\n *\n * @private\n */\nfunction socketOnEnd() {\n  const websocket = this[kWebSocket];\n\n  websocket._readyState = WebSocket.CLOSING;\n  websocket._receiver.end();\n  this.end();\n}\n\n/**\n * The listener of the socket `'error'` event.\n *\n * @private\n */\nfunction socketOnError() {\n  const websocket = this[kWebSocket];\n\n  this.removeListener('error', socketOnError);\n  this.on('error', NOOP);\n\n  if (websocket) {\n    websocket._readyState = WebSocket.CLOSING;\n    this.destroy();\n  }\n}\n","/* eslint no-unused-vars: [\"error\", { \"varsIgnorePattern\": \"^WebSocket$\" }] */\n'use strict';\n\nconst WebSocket = require('./websocket');\nconst { Duplex } = require('stream');\n\n/**\n * Emits the `'close'` event on a stream.\n *\n * @param {Duplex} stream The stream.\n * @private\n */\nfunction emitClose(stream) {\n  stream.emit('close');\n}\n\n/**\n * The listener of the `'end'` event.\n *\n * @private\n */\nfunction duplexOnEnd() {\n  if (!this.destroyed && this._writableState.finished) {\n    this.destroy();\n  }\n}\n\n/**\n * The listener of the `'error'` event.\n *\n * @param {Error} err The error\n * @private\n */\nfunction duplexOnError(err) {\n  this.removeListener('error', duplexOnError);\n  this.destroy();\n  if (this.listenerCount('error') === 0) {\n    // Do not suppress the throwing behavior.\n    this.emit('error', err);\n  }\n}\n\n/**\n * Wraps a `WebSocket` in a duplex stream.\n *\n * @param {WebSocket} ws The `WebSocket` to wrap\n * @param {Object} [options] The options for the `Duplex` constructor\n * @return {Duplex} The duplex stream\n * @public\n */\nfunction createWebSocketStream(ws, options) {\n  let terminateOnDestroy = true;\n\n  const duplex = new Duplex({\n    ...options,\n    autoDestroy: false,\n    emitClose: false,\n    objectMode: false,\n    writableObjectMode: false\n  });\n\n  ws.on('message', function message(msg, isBinary) {\n    const data =\n      !isBinary && duplex._readableState.objectMode ? msg.toString() : msg;\n\n    if (!duplex.push(data)) ws.pause();\n  });\n\n  ws.once('error', function error(err) {\n    if (duplex.destroyed) return;\n\n    // Prevent `ws.terminate()` from being called by `duplex._destroy()`.\n    //\n    // - If the `'error'` event is emitted before the `'open'` event, then\n    //   `ws.terminate()` is a noop as no socket is assigned.\n    // - Otherwise, the error is re-emitted by the listener of the `'error'`\n    //   event of the `Receiver` object. The listener already closes the\n    //   connection by calling `ws.close()`. This allows a close frame to be\n    //   sent to the other peer. If `ws.terminate()` is called right after this,\n    //   then the close frame might not be sent.\n    terminateOnDestroy = false;\n    duplex.destroy(err);\n  });\n\n  ws.once('close', function close() {\n    if (duplex.destroyed) return;\n\n    duplex.push(null);\n  });\n\n  duplex._destroy = function (err, callback) {\n    if (ws.readyState === ws.CLOSED) {\n      callback(err);\n      process.nextTick(emitClose, duplex);\n      return;\n    }\n\n    let called = false;\n\n    ws.once('error', function error(err) {\n      called = true;\n      callback(err);\n    });\n\n    ws.once('close', function close() {\n      if (!called) callback(err);\n      process.nextTick(emitClose, duplex);\n    });\n\n    if (terminateOnDestroy) ws.terminate();\n  };\n\n  duplex._final = function (callback) {\n    if (ws.readyState === ws.CONNECTING) {\n      ws.once('open', function open() {\n        duplex._final(callback);\n      });\n      return;\n    }\n\n    // If the value of the `_socket` property is `null` it means that `ws` is a\n    // client websocket and the handshake failed. In fact, when this happens, a\n    // socket is never assigned to the websocket. Wait for the `'error'` event\n    // that will be emitted by the websocket.\n    if (ws._socket === null) return;\n\n    if (ws._socket._writableState.finished) {\n      callback();\n      if (duplex._readableState.endEmitted) duplex.destroy();\n    } else {\n      ws._socket.once('finish', function finish() {\n        // `duplex` is not destroyed here because the `'end'` event will be\n        // emitted on `duplex` after this `'finish'` event. The EOF signaling\n        // `null` chunk is, in fact, pushed when the websocket emits `'close'`.\n        callback();\n      });\n      ws.close();\n    }\n  };\n\n  duplex._read = function () {\n    if (ws.isPaused) ws.resume();\n  };\n\n  duplex._write = function (chunk, encoding, callback) {\n    if (ws.readyState === ws.CONNECTING) {\n      ws.once('open', function open() {\n        duplex._write(chunk, encoding, callback);\n      });\n      return;\n    }\n\n    ws.send(chunk, callback);\n  };\n\n  duplex.on('end', duplexOnEnd);\n  duplex.on('error', duplexOnError);\n  return duplex;\n}\n\nmodule.exports = createWebSocketStream;\n","'use strict';\n\nconst { tokenChars } = require('./validation');\n\n/**\n * Parses the `Sec-WebSocket-Protocol` header into a set of subprotocol names.\n *\n * @param {String} header The field value of the header\n * @return {Set} The subprotocol names\n * @public\n */\nfunction parse(header) {\n  const protocols = new Set();\n  let start = -1;\n  let end = -1;\n  let i = 0;\n\n  for (i; i < header.length; i++) {\n    const code = header.charCodeAt(i);\n\n    if (end === -1 && tokenChars[code] === 1) {\n      if (start === -1) start = i;\n    } else if (\n      i !== 0 &&\n      (code === 0x20 /* ' ' */ || code === 0x09) /* '\\t' */\n    ) {\n      if (end === -1 && start !== -1) end = i;\n    } else if (code === 0x2c /* ',' */) {\n      if (start === -1) {\n        throw new SyntaxError(`Unexpected character at index ${i}`);\n      }\n\n      if (end === -1) end = i;\n\n      const protocol = header.slice(start, end);\n\n      if (protocols.has(protocol)) {\n        throw new SyntaxError(`The \"${protocol}\" subprotocol is duplicated`);\n      }\n\n      protocols.add(protocol);\n      start = end = -1;\n    } else {\n      throw new SyntaxError(`Unexpected character at index ${i}`);\n    }\n  }\n\n  if (start === -1 || end !== -1) {\n    throw new SyntaxError('Unexpected end of input');\n  }\n\n  const protocol = header.slice(start, i);\n\n  if (protocols.has(protocol)) {\n    throw new SyntaxError(`The \"${protocol}\" subprotocol is duplicated`);\n  }\n\n  protocols.add(protocol);\n  return protocols;\n}\n\nmodule.exports = { parse };\n","/* eslint no-unused-vars: [\"error\", { \"varsIgnorePattern\": \"^Duplex$\", \"caughtErrors\": \"none\" }] */\n\n'use strict';\n\nconst EventEmitter = require('events');\nconst http = require('http');\nconst { Duplex } = require('stream');\nconst { createHash } = require('crypto');\n\nconst extension = require('./extension');\nconst PerMessageDeflate = require('./permessage-deflate');\nconst subprotocol = require('./subprotocol');\nconst WebSocket = require('./websocket');\nconst { GUID, kWebSocket } = require('./constants');\n\nconst keyRegex = /^[+/0-9A-Za-z]{22}==$/;\n\nconst RUNNING = 0;\nconst CLOSING = 1;\nconst CLOSED = 2;\n\n/**\n * Class representing a WebSocket server.\n *\n * @extends EventEmitter\n */\nclass WebSocketServer extends EventEmitter {\n  /**\n   * Create a `WebSocketServer` instance.\n   *\n   * @param {Object} options Configuration options\n   * @param {Boolean} [options.allowSynchronousEvents=true] Specifies whether\n   *     any of the `'message'`, `'ping'`, and `'pong'` events can be emitted\n   *     multiple times in the same tick\n   * @param {Boolean} [options.autoPong=true] Specifies whether or not to\n   *     automatically send a pong in response to a ping\n   * @param {Number} [options.backlog=511] The maximum length of the queue of\n   *     pending connections\n   * @param {Boolean} [options.clientTracking=true] Specifies whether or not to\n   *     track clients\n   * @param {Function} [options.handleProtocols] A hook to handle protocols\n   * @param {String} [options.host] The hostname where to bind the server\n   * @param {Number} [options.maxPayload=104857600] The maximum allowed message\n   *     size\n   * @param {Boolean} [options.noServer=false] Enable no server mode\n   * @param {String} [options.path] Accept only connections matching this path\n   * @param {(Boolean|Object)} [options.perMessageDeflate=false] Enable/disable\n   *     permessage-deflate\n   * @param {Number} [options.port] The port where to bind the server\n   * @param {(http.Server|https.Server)} [options.server] A pre-created HTTP/S\n   *     server to use\n   * @param {Boolean} [options.skipUTF8Validation=false] Specifies whether or\n   *     not to skip UTF-8 validation for text and close messages\n   * @param {Function} [options.verifyClient] A hook to reject connections\n   * @param {Function} [options.WebSocket=WebSocket] Specifies the `WebSocket`\n   *     class to use. It must be the `WebSocket` class or class that extends it\n   * @param {Function} [callback] A listener for the `listening` event\n   */\n  constructor(options, callback) {\n    super();\n\n    options = {\n      allowSynchronousEvents: true,\n      autoPong: true,\n      maxPayload: 100 * 1024 * 1024,\n      skipUTF8Validation: false,\n      perMessageDeflate: false,\n      handleProtocols: null,\n      clientTracking: true,\n      verifyClient: null,\n      noServer: false,\n      backlog: null, // use default (511 as implemented in net.js)\n      server: null,\n      host: null,\n      path: null,\n      port: null,\n      WebSocket,\n      ...options\n    };\n\n    if (\n      (options.port == null && !options.server && !options.noServer) ||\n      (options.port != null && (options.server || options.noServer)) ||\n      (options.server && options.noServer)\n    ) {\n      throw new TypeError(\n        'One and only one of the \"port\", \"server\", or \"noServer\" options ' +\n          'must be specified'\n      );\n    }\n\n    if (options.port != null) {\n      this._server = http.createServer((req, res) => {\n        const body = http.STATUS_CODES[426];\n\n        res.writeHead(426, {\n          'Content-Length': body.length,\n          'Content-Type': 'text/plain'\n        });\n        res.end(body);\n      });\n      this._server.listen(\n        options.port,\n        options.host,\n        options.backlog,\n        callback\n      );\n    } else if (options.server) {\n      this._server = options.server;\n    }\n\n    if (this._server) {\n      const emitConnection = this.emit.bind(this, 'connection');\n\n      this._removeListeners = addListeners(this._server, {\n        listening: this.emit.bind(this, 'listening'),\n        error: this.emit.bind(this, 'error'),\n        upgrade: (req, socket, head) => {\n          this.handleUpgrade(req, socket, head, emitConnection);\n        }\n      });\n    }\n\n    if (options.perMessageDeflate === true) options.perMessageDeflate = {};\n    if (options.clientTracking) {\n      this.clients = new Set();\n      this._shouldEmitClose = false;\n    }\n\n    this.options = options;\n    this._state = RUNNING;\n  }\n\n  /**\n   * Returns the bound address, the address family name, and port of the server\n   * as reported by the operating system if listening on an IP socket.\n   * If the server is listening on a pipe or UNIX domain socket, the name is\n   * returned as a string.\n   *\n   * @return {(Object|String|null)} The address of the server\n   * @public\n   */\n  address() {\n    if (this.options.noServer) {\n      throw new Error('The server is operating in \"noServer\" mode');\n    }\n\n    if (!this._server) return null;\n    return this._server.address();\n  }\n\n  /**\n   * Stop the server from accepting new connections and emit the `'close'` event\n   * when all existing connections are closed.\n   *\n   * @param {Function} [cb] A one-time listener for the `'close'` event\n   * @public\n   */\n  close(cb) {\n    if (this._state === CLOSED) {\n      if (cb) {\n        this.once('close', () => {\n          cb(new Error('The server is not running'));\n        });\n      }\n\n      process.nextTick(emitClose, this);\n      return;\n    }\n\n    if (cb) this.once('close', cb);\n\n    if (this._state === CLOSING) return;\n    this._state = CLOSING;\n\n    if (this.options.noServer || this.options.server) {\n      if (this._server) {\n        this._removeListeners();\n        this._removeListeners = this._server = null;\n      }\n\n      if (this.clients) {\n        if (!this.clients.size) {\n          process.nextTick(emitClose, this);\n        } else {\n          this._shouldEmitClose = true;\n        }\n      } else {\n        process.nextTick(emitClose, this);\n      }\n    } else {\n      const server = this._server;\n\n      this._removeListeners();\n      this._removeListeners = this._server = null;\n\n      //\n      // The HTTP/S server was created internally. Close it, and rely on its\n      // `'close'` event.\n      //\n      server.close(() => {\n        emitClose(this);\n      });\n    }\n  }\n\n  /**\n   * See if a given request should be handled by this server instance.\n   *\n   * @param {http.IncomingMessage} req Request object to inspect\n   * @return {Boolean} `true` if the request is valid, else `false`\n   * @public\n   */\n  shouldHandle(req) {\n    if (this.options.path) {\n      const index = req.url.indexOf('?');\n      const pathname = index !== -1 ? req.url.slice(0, index) : req.url;\n\n      if (pathname !== this.options.path) return false;\n    }\n\n    return true;\n  }\n\n  /**\n   * Handle a HTTP Upgrade request.\n   *\n   * @param {http.IncomingMessage} req The request object\n   * @param {Duplex} socket The network socket between the server and client\n   * @param {Buffer} head The first packet of the upgraded stream\n   * @param {Function} cb Callback\n   * @public\n   */\n  handleUpgrade(req, socket, head, cb) {\n    socket.on('error', socketOnError);\n\n    const key = req.headers['sec-websocket-key'];\n    const upgrade = req.headers.upgrade;\n    const version = +req.headers['sec-websocket-version'];\n\n    if (req.method !== 'GET') {\n      const message = 'Invalid HTTP method';\n      abortHandshakeOrEmitwsClientError(this, req, socket, 405, message);\n      return;\n    }\n\n    if (upgrade === undefined || upgrade.toLowerCase() !== 'websocket') {\n      const message = 'Invalid Upgrade header';\n      abortHandshakeOrEmitwsClientError(this, req, socket, 400, message);\n      return;\n    }\n\n    if (key === undefined || !keyRegex.test(key)) {\n      const message = 'Missing or invalid Sec-WebSocket-Key header';\n      abortHandshakeOrEmitwsClientError(this, req, socket, 400, message);\n      return;\n    }\n\n    if (version !== 13 && version !== 8) {\n      const message = 'Missing or invalid Sec-WebSocket-Version header';\n      abortHandshakeOrEmitwsClientError(this, req, socket, 400, message, {\n        'Sec-WebSocket-Version': '13, 8'\n      });\n      return;\n    }\n\n    if (!this.shouldHandle(req)) {\n      abortHandshake(socket, 400);\n      return;\n    }\n\n    const secWebSocketProtocol = req.headers['sec-websocket-protocol'];\n    let protocols = new Set();\n\n    if (secWebSocketProtocol !== undefined) {\n      try {\n        protocols = subprotocol.parse(secWebSocketProtocol);\n      } catch (err) {\n        const message = 'Invalid Sec-WebSocket-Protocol header';\n        abortHandshakeOrEmitwsClientError(this, req, socket, 400, message);\n        return;\n      }\n    }\n\n    const secWebSocketExtensions = req.headers['sec-websocket-extensions'];\n    const extensions = {};\n\n    if (\n      this.options.perMessageDeflate &&\n      secWebSocketExtensions !== undefined\n    ) {\n      const perMessageDeflate = new PerMessageDeflate(\n        this.options.perMessageDeflate,\n        true,\n        this.options.maxPayload\n      );\n\n      try {\n        const offers = extension.parse(secWebSocketExtensions);\n\n        if (offers[PerMessageDeflate.extensionName]) {\n          perMessageDeflate.accept(offers[PerMessageDeflate.extensionName]);\n          extensions[PerMessageDeflate.extensionName] = perMessageDeflate;\n        }\n      } catch (err) {\n        const message =\n          'Invalid or unacceptable Sec-WebSocket-Extensions header';\n        abortHandshakeOrEmitwsClientError(this, req, socket, 400, message);\n        return;\n      }\n    }\n\n    //\n    // Optionally call external client verification handler.\n    //\n    if (this.options.verifyClient) {\n      const info = {\n        origin:\n          req.headers[`${version === 8 ? 'sec-websocket-origin' : 'origin'}`],\n        secure: !!(req.socket.authorized || req.socket.encrypted),\n        req\n      };\n\n      if (this.options.verifyClient.length === 2) {\n        this.options.verifyClient(info, (verified, code, message, headers) => {\n          if (!verified) {\n            return abortHandshake(socket, code || 401, message, headers);\n          }\n\n          this.completeUpgrade(\n            extensions,\n            key,\n            protocols,\n            req,\n            socket,\n            head,\n            cb\n          );\n        });\n        return;\n      }\n\n      if (!this.options.verifyClient(info)) return abortHandshake(socket, 401);\n    }\n\n    this.completeUpgrade(extensions, key, protocols, req, socket, head, cb);\n  }\n\n  /**\n   * Upgrade the connection to WebSocket.\n   *\n   * @param {Object} extensions The accepted extensions\n   * @param {String} key The value of the `Sec-WebSocket-Key` header\n   * @param {Set} protocols The subprotocols\n   * @param {http.IncomingMessage} req The request object\n   * @param {Duplex} socket The network socket between the server and client\n   * @param {Buffer} head The first packet of the upgraded stream\n   * @param {Function} cb Callback\n   * @throws {Error} If called more than once with the same socket\n   * @private\n   */\n  completeUpgrade(extensions, key, protocols, req, socket, head, cb) {\n    //\n    // Destroy the socket if the client has already sent a FIN packet.\n    //\n    if (!socket.readable || !socket.writable) return socket.destroy();\n\n    if (socket[kWebSocket]) {\n      throw new Error(\n        'server.handleUpgrade() was called more than once with the same ' +\n          'socket, possibly due to a misconfiguration'\n      );\n    }\n\n    if (this._state > RUNNING) return abortHandshake(socket, 503);\n\n    const digest = createHash('sha1')\n      .update(key + GUID)\n      .digest('base64');\n\n    const headers = [\n      'HTTP/1.1 101 Switching Protocols',\n      'Upgrade: websocket',\n      'Connection: Upgrade',\n      `Sec-WebSocket-Accept: ${digest}`\n    ];\n\n    const ws = new this.options.WebSocket(null, undefined, this.options);\n\n    if (protocols.size) {\n      //\n      // Optionally call external protocol selection handler.\n      //\n      const protocol = this.options.handleProtocols\n        ? this.options.handleProtocols(protocols, req)\n        : protocols.values().next().value;\n\n      if (protocol) {\n        headers.push(`Sec-WebSocket-Protocol: ${protocol}`);\n        ws._protocol = protocol;\n      }\n    }\n\n    if (extensions[PerMessageDeflate.extensionName]) {\n      const params = extensions[PerMessageDeflate.extensionName].params;\n      const value = extension.format({\n        [PerMessageDeflate.extensionName]: [params]\n      });\n      headers.push(`Sec-WebSocket-Extensions: ${value}`);\n      ws._extensions = extensions;\n    }\n\n    //\n    // Allow external modification/inspection of handshake headers.\n    //\n    this.emit('headers', headers, req);\n\n    socket.write(headers.concat('\\r\\n').join('\\r\\n'));\n    socket.removeListener('error', socketOnError);\n\n    ws.setSocket(socket, head, {\n      allowSynchronousEvents: this.options.allowSynchronousEvents,\n      maxPayload: this.options.maxPayload,\n      skipUTF8Validation: this.options.skipUTF8Validation\n    });\n\n    if (this.clients) {\n      this.clients.add(ws);\n      ws.on('close', () => {\n        this.clients.delete(ws);\n\n        if (this._shouldEmitClose && !this.clients.size) {\n          process.nextTick(emitClose, this);\n        }\n      });\n    }\n\n    cb(ws, req);\n  }\n}\n\nmodule.exports = WebSocketServer;\n\n/**\n * Add event listeners on an `EventEmitter` using a map of <event, listener>\n * pairs.\n *\n * @param {EventEmitter} server The event emitter\n * @param {Object.<String, Function>} map The listeners to add\n * @return {Function} A function that will remove the added listeners when\n *     called\n * @private\n */\nfunction addListeners(server, map) {\n  for (const event of Object.keys(map)) server.on(event, map[event]);\n\n  return function removeListeners() {\n    for (const event of Object.keys(map)) {\n      server.removeListener(event, map[event]);\n    }\n  };\n}\n\n/**\n * Emit a `'close'` event on an `EventEmitter`.\n *\n * @param {EventEmitter} server The event emitter\n * @private\n */\nfunction emitClose(server) {\n  server._state = CLOSED;\n  server.emit('close');\n}\n\n/**\n * Handle socket errors.\n *\n * @private\n */\nfunction socketOnError() {\n  this.destroy();\n}\n\n/**\n * Close the connection when preconditions are not fulfilled.\n *\n * @param {Duplex} socket The socket of the upgrade request\n * @param {Number} code The HTTP response status code\n * @param {String} [message] The HTTP response body\n * @param {Object} [headers] Additional HTTP response headers\n * @private\n */\nfunction abortHandshake(socket, code, message, headers) {\n  //\n  // The socket is writable unless the user destroyed or ended it before calling\n  // `server.handleUpgrade()` or in the `verifyClient` function, which is a user\n  // error. Handling this does not make much sense as the worst that can happen\n  // is that some of the data written by the user might be discarded due to the\n  // call to `socket.end()` below, which triggers an `'error'` event that in\n  // turn causes the socket to be destroyed.\n  //\n  message = message || http.STATUS_CODES[code];\n  headers = {\n    Connection: 'close',\n    'Content-Type': 'text/html',\n    'Content-Length': Buffer.byteLength(message),\n    ...headers\n  };\n\n  socket.once('finish', socket.destroy);\n\n  socket.end(\n    `HTTP/1.1 ${code} ${http.STATUS_CODES[code]}\\r\\n` +\n      Object.keys(headers)\n        .map((h) => `${h}: ${headers[h]}`)\n        .join('\\r\\n') +\n      '\\r\\n\\r\\n' +\n      message\n  );\n}\n\n/**\n * Emit a `'wsClientError'` event on a `WebSocketServer` if there is at least\n * one listener for it, otherwise call `abortHandshake()`.\n *\n * @param {WebSocketServer} server The WebSocket server\n * @param {http.IncomingMessage} req The request object\n * @param {Duplex} socket The socket of the upgrade request\n * @param {Number} code The HTTP response status code\n * @param {String} message The HTTP response body\n * @param {Object} [headers] The HTTP response headers\n * @private\n */\nfunction abortHandshakeOrEmitwsClientError(\n  server,\n  req,\n  socket,\n  code,\n  message,\n  headers\n) {\n  if (server.listenerCount('wsClientError')) {\n    const err = new Error(message);\n    Error.captureStackTrace(err, abortHandshakeOrEmitwsClientError);\n\n    server.emit('wsClientError', err, socket, req);\n  } else {\n    abortHandshake(socket, code, message, headers);\n  }\n}\n","module.exports = (\n  require('../../module.compiled') as typeof import('../../module.compiled')\n).vendored['react-rsc']!.ReactServerDOMTurbopackServer\n","/* eslint-disable import/no-extraneous-dependencies */\nexport { registerServerReference } from 'react-server-dom-webpack/server'\n","/**\n * Contains predefined constants for the trace span name in next/server.\n *\n * Currently, next/server/tracer is internal implementation only for tracking\n * next.js's implementation only with known span names defined here.\n **/\n\n// eslint typescript has a bug with TS enums\n\nenum BaseServerSpan {\n  handleRequest = 'BaseServer.handleRequest',\n  run = 'BaseServer.run',\n  pipe = 'BaseServer.pipe',\n  getStaticHTML = 'BaseServer.getStaticHTML',\n  render = 'BaseServer.render',\n  renderToResponseWithComponents = 'BaseServer.renderToResponseWithComponents',\n  renderToResponse = 'BaseServer.renderToResponse',\n  renderToHTML = 'BaseServer.renderToHTML',\n  renderError = 'BaseServer.renderError',\n  renderErrorToResponse = 'BaseServer.renderErrorToResponse',\n  renderErrorToHTML = 'BaseServer.renderErrorToHTML',\n  render404 = 'BaseServer.render404',\n}\n\nenum LoadComponentsSpan {\n  loadDefaultErrorComponents = 'LoadComponents.loadDefaultErrorComponents',\n  loadComponents = 'LoadComponents.loadComponents',\n}\n\nenum NextServerSpan {\n  getRequestHandler = 'NextServer.getRequestHandler',\n  getRequestHandlerWithMetadata = 'NextServer.getRequestHandlerWithMetadata',\n  getServer = 'NextServer.getServer',\n  getServerRequestHandler = 'NextServer.getServerRequestHandler',\n  createServer = 'createServer.createServer',\n}\n\nenum NextNodeServerSpan {\n  compression = 'NextNodeServer.compression',\n  getBuildId = 'NextNodeServer.getBuildId',\n  createComponentTree = 'NextNodeServer.createComponentTree',\n  clientComponentLoading = 'NextNodeServer.clientComponentLoading',\n  getLayoutOrPageModule = 'NextNodeServer.getLayoutOrPageModule',\n  generateStaticRoutes = 'NextNodeServer.generateStaticRoutes',\n  generateFsStaticRoutes = 'NextNodeServer.generateFsStaticRoutes',\n  generatePublicRoutes = 'NextNodeServer.generatePublicRoutes',\n  generateImageRoutes = 'NextNodeServer.generateImageRoutes.route',\n  sendRenderResult = 'NextNodeServer.sendRenderResult',\n  proxyRequest = 'NextNodeServer.proxyRequest',\n  runApi = 'NextNodeServer.runApi',\n  render = 'NextNodeServer.render',\n  renderHTML = 'NextNodeServer.renderHTML',\n  imageOptimizer = 'NextNodeServer.imageOptimizer',\n  getPagePath = 'NextNodeServer.getPagePath',\n  getRoutesManifest = 'NextNodeServer.getRoutesManifest',\n  findPageComponents = 'NextNodeServer.findPageComponents',\n  getFontManifest = 'NextNodeServer.getFontManifest',\n  getServerComponentManifest = 'NextNodeServer.getServerComponentManifest',\n  getRequestHandler = 'NextNodeServer.getRequestHandler',\n  renderToHTML = 'NextNodeServer.renderToHTML',\n  renderError = 'NextNodeServer.renderError',\n  renderErrorToHTML = 'NextNodeServer.renderErrorToHTML',\n  render404 = 'NextNodeServer.render404',\n  startResponse = 'NextNodeServer.startResponse',\n\n  // nested inner span, does not require parent scope name\n  route = 'route',\n  onProxyReq = 'onProxyReq',\n  apiResolver = 'apiResolver',\n  internalFetch = 'internalFetch',\n}\n\nenum StartServerSpan {\n  startServer = 'startServer.startServer',\n}\n\nenum RenderSpan {\n  getServerSideProps = 'Render.getServerSideProps',\n  getStaticProps = 'Render.getStaticProps',\n  renderToString = 'Render.renderToString',\n  renderDocument = 'Render.renderDocument',\n  createBodyResult = 'Render.createBodyResult',\n}\n\nenum AppRenderSpan {\n  renderToString = 'AppRender.renderToString',\n  renderToReadableStream = 'AppRender.renderToReadableStream',\n  getBodyResult = 'AppRender.getBodyResult',\n  fetch = 'AppRender.fetch',\n}\n\nenum RouterSpan {\n  executeRoute = 'Router.executeRoute',\n}\n\nenum NodeSpan {\n  runHandler = 'Node.runHandler',\n}\n\nenum AppRouteRouteHandlersSpan {\n  runHandler = 'AppRouteRouteHandlers.runHandler',\n}\n\nenum ResolveMetadataSpan {\n  generateMetadata = 'ResolveMetadata.generateMetadata',\n  generateViewport = 'ResolveMetadata.generateViewport',\n}\n\nenum MiddlewareSpan {\n  execute = 'Middleware.execute',\n}\n\ntype SpanTypes =\n  | `${BaseServerSpan}`\n  | `${LoadComponentsSpan}`\n  | `${NextServerSpan}`\n  | `${StartServerSpan}`\n  | `${NextNodeServerSpan}`\n  | `${RenderSpan}`\n  | `${RouterSpan}`\n  | `${AppRenderSpan}`\n  | `${NodeSpan}`\n  | `${AppRouteRouteHandlersSpan}`\n  | `${ResolveMetadataSpan}`\n  | `${MiddlewareSpan}`\n\n// This list is used to filter out spans that are not relevant to the user\nexport const NextVanillaSpanAllowlist = [\n  MiddlewareSpan.execute,\n  BaseServerSpan.handleRequest,\n  RenderSpan.getServerSideProps,\n  RenderSpan.getStaticProps,\n  AppRenderSpan.fetch,\n  AppRenderSpan.getBodyResult,\n  RenderSpan.renderDocument,\n  NodeSpan.runHandler,\n  AppRouteRouteHandlersSpan.runHandler,\n  ResolveMetadataSpan.generateMetadata,\n  ResolveMetadataSpan.generateViewport,\n  NextNodeServerSpan.createComponentTree,\n  NextNodeServerSpan.findPageComponents,\n  NextNodeServerSpan.getLayoutOrPageModule,\n  NextNodeServerSpan.startResponse,\n  NextNodeServerSpan.clientComponentLoading,\n]\n\n// These Spans are allowed to be always logged\n// when the otel log prefix env is set\nexport const LogSpanAllowList = [\n  NextNodeServerSpan.findPageComponents,\n  NextNodeServerSpan.createComponentTree,\n  NextNodeServerSpan.clientComponentLoading,\n]\n\nexport {\n  BaseServerSpan,\n  LoadComponentsSpan,\n  NextServerSpan,\n  NextNodeServerSpan,\n  StartServerSpan,\n  RenderSpan,\n  RouterSpan,\n  AppRenderSpan,\n  NodeSpan,\n  AppRouteRouteHandlersSpan,\n  ResolveMetadataSpan,\n  MiddlewareSpan,\n}\n\nexport type { SpanTypes }\n","/**\n * Check to see if a value is Thenable.\n *\n * @param promise the maybe-thenable value\n * @returns true if the value is thenable\n */\nexport function isThenable<T = unknown>(\n  promise: Promise<T> | T\n): promise is Promise<T> {\n  return (\n    promise !== null &&\n    typeof promise === 'object' &&\n    'then' in promise &&\n    typeof promise.then === 'function'\n  )\n}\n","import type { FetchEventResult } from '../../web/types'\nimport type { TextMapSetter } from '@opentelemetry/api'\nimport type { SpanTypes } from './constants'\nimport { LogSpanAllowList, NextVanillaSpanAllowlist } from './constants'\n\nimport type {\n  ContextAPI,\n  Span,\n  SpanOptions,\n  Tracer,\n  AttributeValue,\n  TextMapGetter,\n} from 'next/dist/compiled/@opentelemetry/api'\nimport { isThenable } from '../../../shared/lib/is-thenable'\n\nlet api: typeof import('next/dist/compiled/@opentelemetry/api')\n\n// we want to allow users to use their own version of @opentelemetry/api if they\n// want to, so we try to require it first, and if it fails we fall back to the\n// version that is bundled with Next.js\n// this is because @opentelemetry/api has to be synced with the version of\n// @opentelemetry/tracing that is used, and we don't want to force users to use\n// the version that is bundled with Next.js.\n// the API is ~stable, so this should be fine\nif (process.env.NEXT_RUNTIME === 'edge') {\n  api = require('@opentelemetry/api') as typeof import('@opentelemetry/api')\n} else {\n  try {\n    api = require('@opentelemetry/api') as typeof import('@opentelemetry/api')\n  } catch (err) {\n    api =\n      require('next/dist/compiled/@opentelemetry/api') as typeof import('next/dist/compiled/@opentelemetry/api')\n  }\n}\n\nconst { context, propagation, trace, SpanStatusCode, SpanKind, ROOT_CONTEXT } =\n  api\n\nexport class BubbledError extends Error {\n  constructor(\n    public readonly bubble?: boolean,\n    public readonly result?: FetchEventResult\n  ) {\n    super()\n  }\n}\n\nexport function isBubbledError(error: unknown): error is BubbledError {\n  if (typeof error !== 'object' || error === null) return false\n  return error instanceof BubbledError\n}\n\nconst closeSpanWithError = (span: Span, error?: Error) => {\n  if (isBubbledError(error) && error.bubble) {\n    span.setAttribute('next.bubble', true)\n  } else {\n    if (error) {\n      span.recordException(error)\n      span.setAttribute('error.type', error.name)\n    }\n    span.setStatus({ code: SpanStatusCode.ERROR, message: error?.message })\n  }\n  span.end()\n}\n\ntype TracerSpanOptions = Omit<SpanOptions, 'attributes'> & {\n  parentSpan?: Span\n  spanName?: string\n  attributes?: Partial<Record<AttributeNames, AttributeValue | undefined>>\n  hideSpan?: boolean\n}\n\ninterface NextTracer {\n  getContext(): ContextAPI\n\n  /**\n   * Instruments a function by automatically creating a span activated on its\n   * scope.\n   *\n   * The span will automatically be finished when one of these conditions is\n   * met:\n   *\n   * * The function returns a promise, in which case the span will finish when\n   * the promise is resolved or rejected.\n   * * The function takes a callback as its second parameter, in which case the\n   * span will finish when that callback is called.\n   * * The function doesn't accept a callback and doesn't return a promise, in\n   * which case the span will finish at the end of the function execution.\n   *\n   */\n  trace<T>(\n    type: SpanTypes,\n    fn: (span?: Span, done?: (error?: Error) => any) => Promise<T>\n  ): Promise<T>\n  trace<T>(\n    type: SpanTypes,\n    fn: (span?: Span, done?: (error?: Error) => any) => T\n  ): T\n  trace<T>(\n    type: SpanTypes,\n    options: TracerSpanOptions,\n    fn: (span?: Span, done?: (error?: Error) => any) => Promise<T>\n  ): Promise<T>\n  trace<T>(\n    type: SpanTypes,\n    options: TracerSpanOptions,\n    fn: (span?: Span, done?: (error?: Error) => any) => T\n  ): T\n\n  /**\n   * Wrap a function to automatically create a span activated on its\n   * scope when it's called.\n   *\n   * The span will automatically be finished when one of these conditions is\n   * met:\n   *\n   * * The function returns a promise, in which case the span will finish when\n   * the promise is resolved or rejected.\n   * * The function takes a callback as its last parameter, in which case the\n   * span will finish when that callback is called.\n   * * The function doesn't accept a callback and doesn't return a promise, in\n   * which case the span will finish at the end of the function execution.\n   */\n  wrap<T = (...args: Array<any>) => any>(type: SpanTypes, fn: T): T\n  wrap<T = (...args: Array<any>) => any>(\n    type: SpanTypes,\n    options: TracerSpanOptions,\n    fn: T\n  ): T\n  wrap<T = (...args: Array<any>) => any>(\n    type: SpanTypes,\n    options: (...args: any[]) => TracerSpanOptions,\n    fn: T\n  ): T\n\n  /**\n   * Starts and returns a new Span representing a logical unit of work.\n   *\n   * This method do NOT modify the current Context by default. In result, any inner span will not\n   * automatically set its parent context to the span created by this method unless manually activate\n   * context via `tracer.getContext().with`. `trace`, or `wrap` is generally recommended as it gracefully\n   * handles context activation. (ref: https://github.com/open-telemetry/opentelemetry-js/issues/1923)\n   */\n  startSpan(type: SpanTypes): Span\n  startSpan(type: SpanTypes, options: TracerSpanOptions): Span\n\n  /**\n   * Returns currently activated span if current context is in the scope of the span.\n   * Returns undefined otherwise.\n   */\n  getActiveScopeSpan(): Span | undefined\n\n  /**\n   * Returns trace propagation data for the currently active context. The format is equal to data provided\n   * through the OpenTelemetry propagator API.\n   */\n  getTracePropagationData(): ClientTraceDataEntry[]\n}\n\ntype NextAttributeNames =\n  | 'next.route'\n  | 'next.page'\n  | 'next.rsc'\n  | 'next.segment'\n  | 'next.span_name'\n  | 'next.span_type'\n  | 'next.clientComponentLoadCount'\ntype OTELAttributeNames = `http.${string}` | `net.${string}`\ntype AttributeNames = NextAttributeNames | OTELAttributeNames\n\n/** we use this map to propagate attributes from nested spans to the top span */\nconst rootSpanAttributesStore = new Map<\n  number,\n  Map<AttributeNames, AttributeValue | undefined>\n>()\nconst rootSpanIdKey = api.createContextKey('next.rootSpanId')\nlet lastSpanId = 0\nconst getSpanId = () => lastSpanId++\n\nexport interface ClientTraceDataEntry {\n  key: string\n  value: string\n}\n\nconst clientTraceDataSetter: TextMapSetter<ClientTraceDataEntry[]> = {\n  set(carrier, key, value) {\n    carrier.push({\n      key,\n      value,\n    })\n  },\n}\n\nclass NextTracerImpl implements NextTracer {\n  /**\n   * Returns an instance to the trace with configured name.\n   * Since wrap / trace can be defined in any place prior to actual trace subscriber initialization,\n   * This should be lazily evaluated.\n   */\n  private getTracerInstance(): Tracer {\n    return trace.getTracer('next.js', '0.0.1')\n  }\n\n  public getContext(): ContextAPI {\n    return context\n  }\n\n  public getTracePropagationData(): ClientTraceDataEntry[] {\n    const activeContext = context.active()\n    const entries: ClientTraceDataEntry[] = []\n    propagation.inject(activeContext, entries, clientTraceDataSetter)\n    return entries\n  }\n\n  public getActiveScopeSpan(): Span | undefined {\n    return trace.getSpan(context?.active())\n  }\n\n  public withPropagatedContext<T, C>(\n    carrier: C,\n    fn: () => T,\n    getter?: TextMapGetter<C>\n  ): T {\n    const activeContext = context.active()\n    if (trace.getSpanContext(activeContext)) {\n      // Active span is already set, too late to propagate.\n      return fn()\n    }\n    const remoteContext = propagation.extract(activeContext, carrier, getter)\n    return context.with(remoteContext, fn)\n  }\n\n  // Trace, wrap implementation is inspired by datadog trace implementation\n  // (https://datadoghq.dev/dd-trace-js/interfaces/tracer.html#trace).\n  public trace<T>(\n    type: SpanTypes,\n    fn: (span?: Span, done?: (error?: Error) => any) => Promise<T>\n  ): Promise<T>\n  public trace<T>(\n    type: SpanTypes,\n    fn: (span?: Span, done?: (error?: Error) => any) => T\n  ): T\n  public trace<T>(\n    type: SpanTypes,\n    options: TracerSpanOptions,\n    fn: (span?: Span, done?: (error?: Error) => any) => Promise<T>\n  ): Promise<T>\n  public trace<T>(\n    type: SpanTypes,\n    options: TracerSpanOptions,\n    fn: (span?: Span, done?: (error?: Error) => any) => T\n  ): T\n  public trace<T>(...args: Array<any>) {\n    const [type, fnOrOptions, fnOrEmpty] = args\n\n    // coerce options form overload\n    const {\n      fn,\n      options,\n    }: {\n      fn: (span?: Span, done?: (error?: Error) => any) => T | Promise<T>\n      options: TracerSpanOptions\n    } =\n      typeof fnOrOptions === 'function'\n        ? {\n            fn: fnOrOptions,\n            options: {},\n          }\n        : {\n            fn: fnOrEmpty,\n            options: { ...fnOrOptions },\n          }\n\n    const spanName = options.spanName ?? type\n\n    if (\n      (!NextVanillaSpanAllowlist.includes(type) &&\n        process.env.NEXT_OTEL_VERBOSE !== '1') ||\n      options.hideSpan\n    ) {\n      return fn()\n    }\n\n    // Trying to get active scoped span to assign parent. If option specifies parent span manually, will try to use it.\n    let spanContext = this.getSpanContext(\n      options?.parentSpan ?? this.getActiveScopeSpan()\n    )\n    let isRootSpan = false\n\n    if (!spanContext) {\n      spanContext = context?.active() ?? ROOT_CONTEXT\n      isRootSpan = true\n    } else if (trace.getSpanContext(spanContext)?.isRemote) {\n      isRootSpan = true\n    }\n\n    const spanId = getSpanId()\n\n    options.attributes = {\n      'next.span_name': spanName,\n      'next.span_type': type,\n      ...options.attributes,\n    }\n\n    return context.with(spanContext.setValue(rootSpanIdKey, spanId), () =>\n      this.getTracerInstance().startActiveSpan(\n        spanName,\n        options,\n        (span: Span) => {\n          const startTime =\n            'performance' in globalThis && 'measure' in performance\n              ? globalThis.performance.now()\n              : undefined\n\n          const onCleanup = () => {\n            rootSpanAttributesStore.delete(spanId)\n            if (\n              startTime &&\n              process.env.NEXT_OTEL_PERFORMANCE_PREFIX &&\n              LogSpanAllowList.includes(type || ('' as any))\n            ) {\n              performance.measure(\n                `${process.env.NEXT_OTEL_PERFORMANCE_PREFIX}:next-${(\n                  type.split('.').pop() || ''\n                ).replace(\n                  /[A-Z]/g,\n                  (match: string) => '-' + match.toLowerCase()\n                )}`,\n                {\n                  start: startTime,\n                  end: performance.now(),\n                }\n              )\n            }\n          }\n\n          if (isRootSpan) {\n            rootSpanAttributesStore.set(\n              spanId,\n              new Map(\n                Object.entries(options.attributes ?? {}) as [\n                  AttributeNames,\n                  AttributeValue | undefined,\n                ][]\n              )\n            )\n          }\n          try {\n            if (fn.length > 1) {\n              return fn(span, (err) => closeSpanWithError(span, err))\n            }\n\n            const result = fn(span)\n            if (isThenable(result)) {\n              // If there's error make sure it throws\n              return result\n                .then((res) => {\n                  span.end()\n                  // Need to pass down the promise result,\n                  // it could be react stream response with error { error, stream }\n                  return res\n                })\n                .catch((err) => {\n                  closeSpanWithError(span, err)\n                  throw err\n                })\n                .finally(onCleanup)\n            } else {\n              span.end()\n              onCleanup()\n            }\n\n            return result\n          } catch (err: any) {\n            closeSpanWithError(span, err)\n            onCleanup()\n            throw err\n          }\n        }\n      )\n    )\n  }\n\n  public wrap<T = (...args: Array<any>) => any>(type: SpanTypes, fn: T): T\n  public wrap<T = (...args: Array<any>) => any>(\n    type: SpanTypes,\n    options: TracerSpanOptions,\n    fn: T\n  ): T\n  public wrap<T = (...args: Array<any>) => any>(\n    type: SpanTypes,\n    options: (...args: any[]) => TracerSpanOptions,\n    fn: T\n  ): T\n  public wrap(...args: Array<any>) {\n    const tracer = this\n    const [name, options, fn] =\n      args.length === 3 ? args : [args[0], {}, args[1]]\n\n    if (\n      !NextVanillaSpanAllowlist.includes(name) &&\n      process.env.NEXT_OTEL_VERBOSE !== '1'\n    ) {\n      return fn\n    }\n\n    return function (this: any) {\n      let optionsObj = options\n      if (typeof optionsObj === 'function' && typeof fn === 'function') {\n        optionsObj = optionsObj.apply(this, arguments)\n      }\n\n      const lastArgId = arguments.length - 1\n      const cb = arguments[lastArgId]\n\n      if (typeof cb === 'function') {\n        const scopeBoundCb = tracer.getContext().bind(context.active(), cb)\n        return tracer.trace(name, optionsObj, (_span, done) => {\n          arguments[lastArgId] = function (err: any) {\n            done?.(err)\n            return scopeBoundCb.apply(this, arguments)\n          }\n\n          return fn.apply(this, arguments)\n        })\n      } else {\n        return tracer.trace(name, optionsObj, () => fn.apply(this, arguments))\n      }\n    }\n  }\n\n  public startSpan(type: SpanTypes): Span\n  public startSpan(type: SpanTypes, options: TracerSpanOptions): Span\n  public startSpan(...args: Array<any>): Span {\n    const [type, options]: [string, TracerSpanOptions | undefined] = args as any\n\n    const spanContext = this.getSpanContext(\n      options?.parentSpan ?? this.getActiveScopeSpan()\n    )\n    return this.getTracerInstance().startSpan(type, options, spanContext)\n  }\n\n  private getSpanContext(parentSpan?: Span) {\n    const spanContext = parentSpan\n      ? trace.setSpan(context.active(), parentSpan)\n      : undefined\n\n    return spanContext\n  }\n\n  public getRootSpanAttributes() {\n    const spanId = context.active().getValue(rootSpanIdKey) as number\n    return rootSpanAttributesStore.get(spanId)\n  }\n\n  public setRootSpanAttribute(key: AttributeNames, value: AttributeValue) {\n    const spanId = context.active().getValue(rootSpanIdKey) as number\n    const attributes = rootSpanAttributesStore.get(spanId)\n    if (attributes && !attributes.has(key)) {\n      attributes.set(key, value)\n    }\n  }\n}\n\nconst getTracer = (() => {\n  const tracer = new NextTracerImpl()\n\n  return () => tracer\n})()\n\nexport { getTracer, SpanStatusCode, SpanKind }\nexport type { NextTracer, Span, SpanOptions, ContextAPI, TracerSpanOptions }\n","const noop = () => {}\n\nlet registry: FinalizationRegistry<WeakRef<ReadableStream>> | undefined\n\nif (globalThis.FinalizationRegistry) {\n  registry = new FinalizationRegistry((weakRef: WeakRef<ReadableStream>) => {\n    const stream = weakRef.deref()\n    if (stream && !stream.locked) {\n      stream.cancel('Response object has been garbage collected').then(noop)\n    }\n  })\n}\n\n/**\n * Clones a response by teeing the body so we can return two independent\n * ReadableStreams from it. This avoids the bug in the undici library around\n * response cloning.\n *\n * After cloning, the original response's body will be consumed and closed.\n *\n * @see https://github.com/vercel/next.js/pull/73274\n *\n * @param original - The original response to clone.\n * @returns A tuple containing two independent clones of the original response.\n */\nexport function cloneResponse(original: Response): [Response, Response] {\n  // If the response has no body, then we can just return the original response\n  // twice because it's immutable.\n  if (!original.body) {\n    return [original, original]\n  }\n\n  const [body1, body2] = original.body.tee()\n\n  const cloned1 = new Response(body1, {\n    status: original.status,\n    statusText: original.statusText,\n    headers: original.headers,\n  })\n\n  Object.defineProperty(cloned1, 'url', {\n    value: original.url,\n    // How the original response.url behaves\n    configurable: true,\n    enumerable: true,\n    writable: false,\n  })\n\n  // The Fetch Standard allows users to skip consuming the response body by\n  // relying on garbage collection to release connection resources.\n  // https://github.com/nodejs/undici?tab=readme-ov-file#garbage-collection\n  //\n  // To cancel the stream you then need to cancel both resulting branches.\n  // Teeing a stream will generally lock it for the duration, preventing other\n  // readers from locking it.\n  // https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream/tee\n\n  // cloned2 is stored in a react cache and cloned for subsequent requests.\n  // It is the original request, and is is garbage collected by a\n  // FinalizationRegistry in Undici, but since we're tee-ing the stream\n  // ourselves, we need to cancel clone1's stream (the response returned from\n  // our dedupe fetch) when clone1 is reclaimed, otherwise we leak memory.\n  if (registry && cloned1.body) {\n    registry.register(cloned1, new WeakRef(cloned1.body))\n  }\n\n  const cloned2 = new Response(body2, {\n    status: original.status,\n    statusText: original.statusText,\n    headers: original.headers,\n  })\n\n  Object.defineProperty(cloned2, 'url', {\n    value: original.url,\n    // How the original response.url behaves\n    configurable: true,\n    enumerable: true,\n    writable: false,\n  })\n\n  return [cloned1, cloned2]\n}\n","/**\n * Based on https://github.com/facebook/react/blob/d4e78c42a94be027b4dc7ed2659a5fddfbf9bd4e/packages/react/src/ReactFetch.js\n */\nimport * as React from 'react'\nimport { cloneResponse } from './clone-response'\nimport { InvariantError } from '../../shared/lib/invariant-error'\n\nconst simpleCacheKey = '[\"GET\",[],null,\"follow\",null,null,null,null]' // generateCacheKey(new Request('https://blank'));\n\n// Headers that should not affect deduplication\n// traceparent and tracestate are used for distributed tracing and should not affect cache keys\nconst headersToExcludeInCacheKey = new Set(['traceparent', 'tracestate'])\n\nfunction generateCacheKey(request: Request): string {\n  // We pick the fields that goes into the key used to dedupe requests.\n  // We don't include the `cache` field, because we end up using whatever\n  // caching resulted from the first request.\n  // Notably we currently don't consider non-standard (or future) options.\n  // This might not be safe. TODO: warn for non-standard extensions differing.\n  // IF YOU CHANGE THIS UPDATE THE simpleCacheKey ABOVE.\n\n  const filteredHeaders = Array.from(request.headers.entries()).filter(\n    ([key]) => !headersToExcludeInCacheKey.has(key.toLowerCase())\n  )\n\n  return JSON.stringify([\n    request.method,\n    filteredHeaders,\n    request.mode,\n    request.redirect,\n    request.credentials,\n    request.referrer,\n    request.referrerPolicy,\n    request.integrity,\n  ])\n}\n\ntype CacheEntry = [\n  key: string,\n  promise: Promise<Response>,\n  response: Response | null,\n]\n\nexport function createDedupeFetch(originalFetch: typeof fetch) {\n  const getCacheEntries = React.cache(\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars -- url is the cache key\n    (url: string): CacheEntry[] => []\n  )\n\n  return function dedupeFetch(\n    resource: URL | RequestInfo,\n    options?: RequestInit\n  ): Promise<Response> {\n    if (options && options.signal) {\n      // If we're passed a signal, then we assume that\n      // someone else controls the lifetime of this object and opts out of\n      // caching. It's effectively the opt-out mechanism.\n      // Ideally we should be able to check this on the Request but\n      // it always gets initialized with its own signal so we don't\n      // know if it's supposed to override - unless we also override the\n      // Request constructor.\n      return originalFetch(resource, options)\n    }\n    // Normalize the Request\n    let url: string\n    let cacheKey: string\n    if (typeof resource === 'string' && !options) {\n      // Fast path.\n      cacheKey = simpleCacheKey\n      url = resource\n    } else {\n      // Normalize the request.\n      // if resource is not a string or a URL (its an instance of Request)\n      // then do not instantiate a new Request but instead\n      // reuse the request as to not disturb the body in the event it's a ReadableStream.\n      const request =\n        typeof resource === 'string' || resource instanceof URL\n          ? new Request(resource, options)\n          : resource\n      if (\n        (request.method !== 'GET' && request.method !== 'HEAD') ||\n        request.keepalive\n      ) {\n        // We currently don't dedupe requests that might have side-effects. Those\n        // have to be explicitly cached. We assume that the request doesn't have a\n        // body if it's GET or HEAD.\n        // keepalive gets treated the same as if you passed a custom cache signal.\n        return originalFetch(resource, options)\n      }\n      cacheKey = generateCacheKey(request)\n      url = request.url\n    }\n\n    const cacheEntries = getCacheEntries(url)\n    for (let i = 0, j = cacheEntries.length; i < j; i += 1) {\n      const [key, promise] = cacheEntries[i]\n      if (key === cacheKey) {\n        return promise.then(() => {\n          const response = cacheEntries[i][2]\n          if (!response) throw new InvariantError('No cached response')\n\n          // We're cloning the response using this utility because there exists\n          // a bug in the undici library around response cloning. See the\n          // following pull request for more details:\n          // https://github.com/vercel/next.js/pull/73274\n          const [cloned1, cloned2] = cloneResponse(response)\n          cacheEntries[i][2] = cloned2\n          return cloned1\n        })\n      }\n    }\n\n    // We pass the original arguments here in case normalizing the Request\n    // doesn't include all the options in this environment.\n    const promise = originalFetch(resource, options)\n    const entry: CacheEntry = [cacheKey, promise, null]\n    cacheEntries.push(entry)\n\n    return promise.then((response) => {\n      // We're cloning the response using this utility because there exists\n      // a bug in the undici library around response cloning. See the\n      // following pull request for more details:\n      // https://github.com/vercel/next.js/pull/73274\n      const [cloned1, cloned2] = cloneResponse(response)\n      entry[2] = cloned2\n      return cloned1\n    })\n  }\n}\n","import type { OutgoingHttpHeaders } from 'http'\nimport type RenderResult from '../render-result'\nimport type { CacheControl, Revalidate } from '../lib/cache-control'\nimport type { RouteKind } from '../route-kind'\n\nexport interface ResponseCacheBase {\n  get(\n    key: string | null,\n    responseGenerator: ResponseGenerator,\n    context: {\n      isOnDemandRevalidate?: boolean\n      isPrefetch?: boolean\n      incrementalCache: IncrementalCache\n      /**\n       * This is a hint to the cache to help it determine what kind of route\n       * this is so it knows where to look up the cache entry from. If not\n       * provided it will test the filesystem to check.\n       */\n      routeKind: RouteKind\n\n      /**\n       * True if this is a fallback request.\n       */\n      isFallback?: boolean\n\n      /**\n       * True if the route is enabled for PPR.\n       */\n      isRoutePPREnabled?: boolean\n    }\n  ): Promise<ResponseCacheEntry | null>\n}\n\n// The server components HMR cache might store other data as well in the future,\n// at which point this should be refactored to a discriminated union type.\nexport interface ServerComponentsHmrCache {\n  get(key: string): CachedFetchData | undefined\n  set(key: string, data: CachedFetchData): void\n}\n\nexport type CachedFetchData = {\n  headers: Record<string, string>\n  body: string\n  url: string\n  status?: number\n}\n\nexport const enum CachedRouteKind {\n  APP_PAGE = 'APP_PAGE',\n  APP_ROUTE = 'APP_ROUTE',\n  PAGES = 'PAGES',\n  FETCH = 'FETCH',\n  REDIRECT = 'REDIRECT',\n  IMAGE = 'IMAGE',\n}\n\nexport interface CachedFetchValue {\n  kind: CachedRouteKind.FETCH\n  data: CachedFetchData\n  // tags are only present with file-system-cache\n  // fetch cache stores tags outside of cache entry\n  tags?: string[]\n  revalidate: number\n}\n\nexport interface CachedRedirectValue {\n  kind: CachedRouteKind.REDIRECT\n  props: Object\n}\n\nexport interface CachedAppPageValue {\n  kind: CachedRouteKind.APP_PAGE\n  // this needs to be a RenderResult so since renderResponse\n  // expects that type instead of a string\n  html: RenderResult\n  rscData: Buffer | undefined\n  status: number | undefined\n  postponed: string | undefined\n  headers: OutgoingHttpHeaders | undefined\n  segmentData: Map<string, Buffer> | undefined\n}\n\nexport interface CachedPageValue {\n  kind: CachedRouteKind.PAGES\n  // this needs to be a RenderResult so since renderResponse\n  // expects that type instead of a string\n  html: RenderResult\n  pageData: Object\n  status: number | undefined\n  headers: OutgoingHttpHeaders | undefined\n}\n\nexport interface CachedRouteValue {\n  kind: CachedRouteKind.APP_ROUTE\n  // this needs to be a RenderResult so since renderResponse\n  // expects that type instead of a string\n  body: Buffer\n  status: number\n  headers: OutgoingHttpHeaders\n}\n\nexport interface CachedImageValue {\n  kind: CachedRouteKind.IMAGE\n  etag: string\n  upstreamEtag: string\n  buffer: Buffer\n  extension: string\n  isMiss?: boolean\n  isStale?: boolean\n}\n\nexport interface IncrementalCachedAppPageValue {\n  kind: CachedRouteKind.APP_PAGE\n  // this needs to be a string since the cache expects to store\n  // the string value\n  html: string\n  rscData: Buffer | undefined\n  headers: OutgoingHttpHeaders | undefined\n  postponed: string | undefined\n  status: number | undefined\n  segmentData: Map<string, Buffer> | undefined\n}\n\nexport interface IncrementalCachedPageValue {\n  kind: CachedRouteKind.PAGES\n  // this needs to be a string since the cache expects to store\n  // the string value\n  html: string\n  pageData: Object\n  headers: OutgoingHttpHeaders | undefined\n  status: number | undefined\n}\n\nexport interface IncrementalResponseCacheEntry {\n  cacheControl?: CacheControl\n  /**\n   * timestamp in milliseconds to revalidate after\n   */\n  revalidateAfter?: Revalidate\n  /**\n   * `-1` here dictates a blocking revalidate should be used\n   */\n  isStale?: boolean | -1\n  isMiss?: boolean\n  value: Exclude<IncrementalCacheValue, CachedFetchValue> | null\n}\n\nexport interface IncrementalFetchCacheEntry {\n  /**\n   * `-1` here dictates a blocking revalidate should be used\n   */\n  isStale?: boolean | -1\n  value: CachedFetchValue\n}\n\nexport type IncrementalCacheEntry =\n  | IncrementalResponseCacheEntry\n  | IncrementalFetchCacheEntry\n\nexport type IncrementalCacheValue =\n  | CachedRedirectValue\n  | IncrementalCachedPageValue\n  | IncrementalCachedAppPageValue\n  | CachedImageValue\n  | CachedFetchValue\n  | CachedRouteValue\n\nexport type ResponseCacheValue =\n  | CachedRedirectValue\n  | CachedPageValue\n  | CachedAppPageValue\n  | CachedImageValue\n  | CachedRouteValue\n\nexport type ResponseCacheEntry = {\n  cacheControl?: CacheControl\n  value: ResponseCacheValue | null\n  isStale?: boolean | -1\n  isMiss?: boolean\n}\n\n/**\n * @param hasResolved whether the responseGenerator has resolved it's promise\n * @param previousCacheEntry the previous cache entry if it exists or the current\n */\nexport type ResponseGenerator = (state: {\n  hasResolved: boolean\n  previousCacheEntry?: IncrementalResponseCacheEntry | null\n  isRevalidating?: boolean\n  span?: any\n\n  /**\n   * When true, this indicates that the response generator is being called in a\n   * context where the response must be generated statically.\n   *\n   * CRITICAL: This should only currently be used when revalidating due to a\n   * dynamic RSC request.\n   */\n  forceStaticRender?: boolean\n}) => Promise<ResponseCacheEntry | null>\n\nexport const enum IncrementalCacheKind {\n  APP_PAGE = 'APP_PAGE',\n  APP_ROUTE = 'APP_ROUTE',\n  PAGES = 'PAGES',\n  FETCH = 'FETCH',\n  IMAGE = 'IMAGE',\n}\n\nexport interface GetIncrementalFetchCacheContext {\n  kind: IncrementalCacheKind.FETCH\n  revalidate?: Revalidate\n  fetchUrl?: string\n  fetchIdx?: number\n  tags?: string[]\n  softTags?: string[]\n}\n\nexport interface GetIncrementalResponseCacheContext {\n  kind: Exclude<IncrementalCacheKind, IncrementalCacheKind.FETCH>\n\n  /**\n   * True if the route is enabled for PPR.\n   */\n  isRoutePPREnabled?: boolean\n\n  /**\n   * True if this is a fallback request.\n   */\n  isFallback: boolean\n}\n\nexport interface SetIncrementalFetchCacheContext {\n  fetchCache: true\n  fetchUrl?: string\n  fetchIdx?: number\n  tags?: string[]\n  isImplicitBuildTimeCache?: boolean\n}\n\nexport interface SetIncrementalResponseCacheContext {\n  fetchCache?: false\n  cacheControl?: CacheControl\n\n  /**\n   * True if the route is enabled for PPR.\n   */\n  isRoutePPREnabled?: boolean\n\n  /**\n   * True if this is a fallback request.\n   */\n  isFallback?: boolean\n}\n\nexport interface IncrementalResponseCache {\n  get(\n    cacheKey: string,\n    ctx: GetIncrementalResponseCacheContext\n  ): Promise<IncrementalResponseCacheEntry | null>\n  set(\n    key: string,\n    data: Exclude<IncrementalCacheValue, CachedFetchValue> | null,\n    ctx: SetIncrementalResponseCacheContext\n  ): Promise<void>\n}\n\nexport interface IncrementalCache extends IncrementalResponseCache {\n  get(\n    cacheKey: string,\n    ctx: GetIncrementalFetchCacheContext\n  ): Promise<IncrementalFetchCacheEntry | null>\n  get(\n    cacheKey: string,\n    ctx: GetIncrementalResponseCacheContext\n  ): Promise<IncrementalResponseCacheEntry | null>\n  set(\n    key: string,\n    data: CachedFetchValue | null,\n    ctx: SetIncrementalFetchCacheContext\n  ): Promise<void>\n  set(\n    key: string,\n    data: Exclude<IncrementalCacheValue, CachedFetchValue> | null,\n    ctx: SetIncrementalResponseCacheContext\n  ): Promise<void>\n  revalidateTag(\n    tags: string | string[],\n    durations?: { expire?: number }\n  ): Promise<void>\n}\n","/**\n * A `Promise.withResolvers` implementation that exposes the `resolve` and\n * `reject` functions on a `Promise`.\n *\n * @see https://tc39.es/proposal-promise-with-resolvers/\n */\nexport class DetachedPromise<T = any> {\n  public readonly resolve: (value: T | PromiseLike<T>) => void\n  public readonly reject: (reason: any) => void\n  public readonly promise: Promise<T>\n\n  constructor() {\n    let resolve: (value: T | PromiseLike<T>) => void\n    let reject: (reason: any) => void\n\n    // Create the promise and assign the resolvers to the object.\n    this.promise = new Promise<T>((res, rej) => {\n      resolve = res\n      reject = rej\n    })\n\n    // We know that resolvers is defined because the Promise constructor runs\n    // synchronously.\n    this.resolve = resolve!\n    this.reject = reject!\n  }\n}\n","import type { SchedulerFn } from './scheduler'\n\nimport { DetachedPromise } from './detached-promise'\n\ntype CacheKeyFn<K, C extends string | number | null> = (\n  key: K\n) => PromiseLike<C> | C\n\ntype BatcherOptions<K, C extends string | number | null> = {\n  cacheKeyFn?: CacheKeyFn<K, C>\n  schedulerFn?: SchedulerFn<void>\n}\n\ntype WorkFnContext<V, K> = {\n  resolve: (value: V | PromiseLike<V>) => void\n  key: K\n}\n\ntype WorkFn<V, K> = (context: WorkFnContext<V, K>) => Promise<V>\n\n/**\n * A wrapper for a function that will only allow one call to the function to\n * execute at a time.\n */\nexport class Batcher<K, V, C extends string | number | null> {\n  private readonly pending = new Map<C, Promise<V>>()\n\n  protected constructor(\n    private readonly cacheKeyFn?: CacheKeyFn<K, C>,\n    /**\n     * A function that will be called to schedule the wrapped function to be\n     * executed. This defaults to a function that will execute the function\n     * immediately.\n     */\n    private readonly schedulerFn: SchedulerFn<void> = (fn) => fn()\n  ) {}\n\n  /**\n   * Creates a new instance of PendingWrapper. If the key extends a string or\n   * number, the key will be used as the cache key. If the key is an object, a\n   * cache key function must be provided.\n   */\n  public static create<K extends string | number | null, V>(\n    options?: BatcherOptions<K, K>\n  ): Batcher<K, V, K>\n  public static create<K, V, C extends string | number | null>(\n    options: BatcherOptions<K, C> &\n      Required<Pick<BatcherOptions<K, C>, 'cacheKeyFn'>>\n  ): Batcher<K, V, C>\n  public static create<K, V, C extends string | number | null>(\n    options?: BatcherOptions<K, C>\n  ): Batcher<K, V, C> {\n    return new Batcher<K, V, C>(options?.cacheKeyFn, options?.schedulerFn)\n  }\n\n  /**\n   * Wraps a function in a promise that will be resolved or rejected only once\n   * for a given key. This will allow multiple calls to the function to be\n   * made, but only one will be executed at a time. The result of the first\n   * call will be returned to all callers.\n   *\n   * @param key the key to use for the cache\n   * @param fn the function to wrap\n   * @returns a promise that resolves to the result of the function\n   */\n  public async batch(key: K, fn: WorkFn<V, K>): Promise<V> {\n    const cacheKey = (this.cacheKeyFn ? await this.cacheKeyFn(key) : key) as C\n    if (cacheKey === null) {\n      return fn({ resolve: (value) => Promise.resolve(value), key })\n    }\n\n    const pending = this.pending.get(cacheKey)\n    if (pending) return pending\n\n    const { promise, resolve, reject } = new DetachedPromise<V>()\n    this.pending.set(cacheKey, promise)\n\n    this.schedulerFn(async () => {\n      try {\n        const result = await fn({ resolve, key })\n\n        // Resolving a promise multiple times is a no-op, so we can safely\n        // resolve all pending promises with the same result.\n        resolve(result)\n      } catch (err) {\n        reject(err)\n      } finally {\n        this.pending.delete(cacheKey)\n      }\n    })\n\n    return promise\n  }\n}\n","export const ENCODED_TAGS = {\n  // opening tags do not have the closing `>` since they can contain other attributes such as `<body className=''>`\n  OPENING: {\n    // <html\n    HTML: new Uint8Array([60, 104, 116, 109, 108]),\n    // <body\n    BODY: new Uint8Array([60, 98, 111, 100, 121]),\n  },\n  CLOSED: {\n    // </head>\n    HEAD: new Uint8Array([60, 47, 104, 101, 97, 100, 62]),\n    // </body>\n    BODY: new Uint8Array([60, 47, 98, 111, 100, 121, 62]),\n    // </html>\n    HTML: new Uint8Array([60, 47, 104, 116, 109, 108, 62]),\n    // </body></html>\n    BODY_AND_HTML: new Uint8Array([\n      60, 47, 98, 111, 100, 121, 62, 60, 47, 104, 116, 109, 108, 62,\n    ]),\n  },\n  META: {\n    // Only the match the prefix cause the suffix can be different wether it's xml compatible or not \">\" or \"/>\"\n    // <meta name=\"nxt-icon\"\n    // This is a special mark that will be replaced by the icon insertion script tag.\n    ICON_MARK: new Uint8Array([\n      60, 109, 101, 116, 97, 32, 110, 97, 109, 101, 61, 34, 194, 171, 110, 120,\n      116, 45, 105, 99, 111, 110, 194, 187, 34,\n    ]),\n  },\n} as const\n","/**\n * Find the starting index of Uint8Array `b` within Uint8Array `a`.\n */\nexport function indexOfUint8Array(a: Uint8Array, b: Uint8Array) {\n  if (b.length === 0) return 0\n  if (a.length === 0 || b.length > a.length) return -1\n\n  // start iterating through `a`\n  for (let i = 0; i <= a.length - b.length; i++) {\n    let completeMatch = true\n    // from index `i`, iterate through `b` and check for mismatch\n    for (let j = 0; j < b.length; j++) {\n      // if the values do not match, then this isn't a complete match, exit `b` iteration early and iterate to next index of `a`.\n      if (a[i + j] !== b[j]) {\n        completeMatch = false\n        break\n      }\n    }\n\n    if (completeMatch) {\n      return i\n    }\n  }\n\n  return -1\n}\n\n/**\n * Check if two Uint8Arrays are strictly equivalent.\n */\nexport function isEquivalentUint8Arrays(a: Uint8Array, b: Uint8Array) {\n  if (a.length !== b.length) return false\n\n  for (let i = 0; i < a.length; i++) {\n    if (a[i] !== b[i]) return false\n  }\n\n  return true\n}\n\n/**\n * Remove Uint8Array `b` from Uint8Array `a`.\n *\n * If `b` is not in `a`, `a` is returned unchanged.\n *\n * Otherwise, the function returns a new Uint8Array instance with size `a.length - b.length`\n */\nexport function removeFromUint8Array(a: Uint8Array, b: Uint8Array) {\n  const tagIndex = indexOfUint8Array(a, b)\n  if (tagIndex === 0) return a.subarray(b.length)\n  if (tagIndex > -1) {\n    const removed = new Uint8Array(a.length - b.length)\n    removed.set(a.slice(0, tagIndex))\n    removed.set(a.slice(tagIndex + b.length), tagIndex)\n    return removed\n  } else {\n    return a\n  }\n}\n","export const MISSING_ROOT_TAGS_ERROR = 'NEXT_MISSING_ROOT_TAGS'\n","// In output: export mode, the build id is added to the start of the HTML\n// document, directly after the doctype declaration. During a prefetch, the\n// client performs a range request to get the build id, so it can check whether\n// the target page belongs to the same build.\n//\n// The first 64 bytes of the document are requested. The exact number isn't\n// too important; it must be larger than the build id + doctype + closing and\n// ending comment markers, but it doesn't need to match the end of the\n// comment exactly.\n//\n// Build ids are 21 bytes long in the default implementation, though this\n// can be overridden in the Next.js config. For the purposes of this check,\n// it's OK to only match the start of the id, so we'll truncate it if exceeds\n// a certain length.\n\nconst DOCTYPE_PREFIX = '<!DOCTYPE html>' // 15 bytes\nconst MAX_BUILD_ID_LENGTH = 24\n\n// Request the first 64 bytes. The Range header is inclusive of the end value.\nexport const DOC_PREFETCH_RANGE_HEADER_VALUE = 'bytes=0-63'\n\nfunction escapeBuildId(buildId: string) {\n  // If the build id is longer than the given limit, it's OK for our purposes\n  // to only match the beginning.\n  const truncated = buildId.slice(0, MAX_BUILD_ID_LENGTH)\n  // Replace hyphens with underscores so it doesn't break the HTML comment.\n  // (Unlikely, but if this did happen it would break the whole document.)\n  return truncated.replace(/-/g, '_')\n}\n\nexport function insertBuildIdComment(originalHtml: string, buildId: string) {\n  if (\n    // Skip if the build id contains a closing comment marker.\n    buildId.includes('-->') ||\n    // React always inserts a doctype at the start of the document. Skip if it\n    // isn't present. Shouldn't happen; suggests an issue elsewhere.\n    !originalHtml.startsWith(DOCTYPE_PREFIX)\n  ) {\n    // Return the original HTML unchanged. This means the document will not\n    // be prefetched.\n    // TODO: The build id comment is currently only used during prefetches, but\n    // if we eventually use this mechanism for regular navigations, we may need\n    // to error during build if we fail to insert it for some reason.\n    return originalHtml\n  }\n  // The comment must be inserted after the doctype.\n  return originalHtml.replace(\n    DOCTYPE_PREFIX,\n    DOCTYPE_PREFIX + '<!--' + escapeBuildId(buildId) + '-->'\n  )\n}\n\nexport function doesExportedHtmlMatchBuildId(\n  partialHtmlDocument: string,\n  buildId: string\n) {\n  // Check whether the document starts with the expected buildId.\n  return partialHtmlDocument.startsWith(\n    DOCTYPE_PREFIX + '<!--' + escapeBuildId(buildId) + '-->'\n  )\n}\n","export const RSC_HEADER = 'rsc' as const\nexport const ACTION_HEADER = 'next-action' as const\n// TODO: Instead of sending the full router state, we only need to send the\n// segment path. Saves bytes. Then we could also use this field for segment\n// prefetches, which also need to specify a particular segment.\nexport const NEXT_ROUTER_STATE_TREE_HEADER = 'next-router-state-tree' as const\nexport const NEXT_ROUTER_PREFETCH_HEADER = 'next-router-prefetch' as const\n// This contains the path to the segment being prefetched.\n// TODO: If we change next-router-state-tree to be a segment path, we can use\n// that instead. Then next-router-prefetch and next-router-segment-prefetch can\n// be merged into a single enum.\nexport const NEXT_ROUTER_SEGMENT_PREFETCH_HEADER =\n  'next-router-segment-prefetch' as const\nexport const NEXT_HMR_REFRESH_HEADER = 'next-hmr-refresh' as const\nexport const NEXT_HMR_REFRESH_HASH_COOKIE = '__next_hmr_refresh_hash__' as const\nexport const NEXT_URL = 'next-url' as const\nexport const RSC_CONTENT_TYPE_HEADER = 'text/x-component' as const\n\nexport const FLIGHT_HEADERS = [\n  RSC_HEADER,\n  NEXT_ROUTER_STATE_TREE_HEADER,\n  NEXT_ROUTER_PREFETCH_HEADER,\n  NEXT_HMR_REFRESH_HEADER,\n  NEXT_ROUTER_SEGMENT_PREFETCH_HEADER,\n] as const\n\nexport const NEXT_RSC_UNION_QUERY = '_rsc' as const\n\nexport const NEXT_ROUTER_STALE_TIME_HEADER = 'x-nextjs-stale-time' as const\nexport const NEXT_DID_POSTPONE_HEADER = 'x-nextjs-postponed' as const\nexport const NEXT_REWRITTEN_PATH_HEADER = 'x-nextjs-rewritten-path' as const\nexport const NEXT_REWRITTEN_QUERY_HEADER = 'x-nextjs-rewritten-query' as const\nexport const NEXT_IS_PRERENDER_HEADER = 'x-nextjs-prerender' as const\nexport const NEXT_ACTION_NOT_FOUND_HEADER = 'x-nextjs-action-not-found' as const\nexport const NEXT_REQUEST_ID_HEADER = 'x-nextjs-request-id' as const\nexport const NEXT_HTML_REQUEST_ID_HEADER = 'x-nextjs-html-request-id' as const\n","// http://www.cse.yorku.ca/~oz/hash.html\n// More specifically, 32-bit hash via djbxor\n// (ref: https://gist.github.com/eplawless/52813b1d8ad9af510d85?permalink_comment_id=3367765#gistcomment-3367765)\n// This is due to number type differences between rust for turbopack to js number types,\n// where rust does not have easy way to repreesnt js's 53-bit float number type for the matching\n// overflow behavior. This is more `correct` in terms of having canonical hash across different runtime / implementation\n// as can gaurantee determinstic output from 32bit hash.\nexport function djb2Hash(str: string) {\n  let hash = 5381\n  for (let i = 0; i < str.length; i++) {\n    const char = str.charCodeAt(i)\n    hash = ((hash << 5) + hash + char) & 0xffffffff\n  }\n  return hash >>> 0\n}\n\nexport function hexHash(str: string) {\n  return djb2Hash(str).toString(36).slice(0, 5)\n}\n","import { hexHash } from '../../hash'\n\nexport function computeCacheBustingSearchParam(\n  prefetchHeader: '1' | '2' | '0' | undefined,\n  segmentPrefetchHeader: string | string[] | undefined,\n  stateTreeHeader: string | string[] | undefined,\n  nextUrlHeader: string | string[] | undefined\n): string {\n  if (\n    (prefetchHeader === undefined || prefetchHeader === '0') &&\n    segmentPrefetchHeader === undefined &&\n    stateTreeHeader === undefined &&\n    nextUrlHeader === undefined\n  ) {\n    return ''\n  }\n  return hexHash(\n    [\n      prefetchHeader || '0',\n      segmentPrefetchHeader || '0',\n      stateTreeHeader || '0',\n      nextUrlHeader || '0',\n    ].join(',')\n  )\n}\n","import type { ReactDOMServerReadableStream } from 'react-dom/server'\nimport { getTracer } from '../lib/trace/tracer'\nimport { AppRenderSpan } from '../lib/trace/constants'\nimport { DetachedPromise } from '../../lib/detached-promise'\nimport { scheduleImmediate, atLeastOneTask } from '../../lib/scheduler'\nimport { ENCODED_TAGS } from './encoded-tags'\nimport {\n  indexOfUint8Array,\n  isEquivalentUint8Arrays,\n  removeFromUint8Array,\n} from './uint8array-helpers'\nimport { MISSING_ROOT_TAGS_ERROR } from '../../shared/lib/errors/constants'\nimport { insertBuildIdComment } from '../../shared/lib/segment-cache/output-export-prefetch-encoding'\nimport {\n  RSC_HEADER,\n  NEXT_ROUTER_PREFETCH_HEADER,\n  NEXT_ROUTER_SEGMENT_PREFETCH_HEADER,\n  NEXT_RSC_UNION_QUERY,\n} from '../../client/components/app-router-headers'\nimport { computeCacheBustingSearchParam } from '../../shared/lib/router/utils/cache-busting-search-param'\n\nfunction voidCatch() {\n  // this catcher is designed to be used with pipeTo where we expect the underlying\n  // pipe implementation to forward errors but we don't want the pipeTo promise to reject\n  // and be unhandled\n}\n\n// We can share the same encoder instance everywhere\n// Notably we cannot do the same for TextDecoder because it is stateful\n// when handling streaming data\nconst encoder = new TextEncoder()\n\nexport function chainStreams<T>(\n  ...streams: ReadableStream<T>[]\n): ReadableStream<T> {\n  // If we have no streams, return an empty stream. This behavior is\n  // intentional as we're now providing the `RenderResult.EMPTY` value.\n  if (streams.length === 0) {\n    return new ReadableStream<T>({\n      start(controller) {\n        controller.close()\n      },\n    })\n  }\n\n  // If we only have 1 stream we fast path it by returning just this stream\n  if (streams.length === 1) {\n    return streams[0]\n  }\n\n  const { readable, writable } = new TransformStream()\n\n  // We always initiate pipeTo immediately. We know we have at least 2 streams\n  // so we need to avoid closing the writable when this one finishes.\n  let promise = streams[0].pipeTo(writable, { preventClose: true })\n\n  let i = 1\n  for (; i < streams.length - 1; i++) {\n    const nextStream = streams[i]\n    promise = promise.then(() =>\n      nextStream.pipeTo(writable, { preventClose: true })\n    )\n  }\n\n  // We can omit the length check because we halted before the last stream and there\n  // is at least two streams so the lastStream here will always be defined\n  const lastStream = streams[i]\n  promise = promise.then(() => lastStream.pipeTo(writable))\n\n  // Catch any errors from the streams and ignore them, they will be handled\n  // by whatever is consuming the readable stream.\n  promise.catch(voidCatch)\n\n  return readable\n}\n\nexport function streamFromString(str: string): ReadableStream<Uint8Array> {\n  return new ReadableStream({\n    start(controller) {\n      controller.enqueue(encoder.encode(str))\n      controller.close()\n    },\n  })\n}\n\nexport function streamFromBuffer(chunk: Buffer): ReadableStream<Uint8Array> {\n  return new ReadableStream({\n    start(controller) {\n      controller.enqueue(chunk)\n      controller.close()\n    },\n  })\n}\n\nexport async function streamToBuffer(\n  stream: ReadableStream<Uint8Array>\n): Promise<Buffer> {\n  const reader = stream.getReader()\n  const chunks: Uint8Array[] = []\n\n  while (true) {\n    const { done, value } = await reader.read()\n    if (done) {\n      break\n    }\n\n    chunks.push(value)\n  }\n\n  return Buffer.concat(chunks)\n}\n\nexport async function streamToString(\n  stream: ReadableStream<Uint8Array>,\n  signal?: AbortSignal\n): Promise<string> {\n  const decoder = new TextDecoder('utf-8', { fatal: true })\n  let string = ''\n\n  for await (const chunk of stream) {\n    if (signal?.aborted) {\n      return string\n    }\n\n    string += decoder.decode(chunk, { stream: true })\n  }\n\n  string += decoder.decode()\n\n  return string\n}\n\nexport type BufferedTransformOptions = {\n  /**\n   * Flush synchronously once the buffer reaches this many bytes.\n   */\n  readonly maxBufferByteLength?: number\n}\n\nexport function createBufferedTransformStream(\n  options: BufferedTransformOptions = {}\n): TransformStream<Uint8Array, Uint8Array> {\n  const { maxBufferByteLength = Infinity } = options\n\n  let bufferedChunks: Array<Uint8Array> = []\n  let bufferByteLength: number = 0\n  let pending: DetachedPromise<void> | undefined\n\n  const flush = (controller: TransformStreamDefaultController) => {\n    try {\n      if (bufferedChunks.length === 0) {\n        return\n      }\n\n      const chunk = new Uint8Array(bufferByteLength)\n      let copiedBytes = 0\n\n      for (let i = 0; i < bufferedChunks.length; i++) {\n        const bufferedChunk = bufferedChunks[i]\n        chunk.set(bufferedChunk, copiedBytes)\n        copiedBytes += bufferedChunk.byteLength\n      }\n      // We just wrote all the buffered chunks so we need to reset the bufferedChunks array\n      // and our bufferByteLength to prepare for the next round of buffered chunks\n      bufferedChunks.length = 0\n      bufferByteLength = 0\n      controller.enqueue(chunk)\n    } catch {\n      // If an error occurs while enqueuing, it can't be due to this\n      // transformer. It's most likely caused by the controller having been\n      // errored (for example, if the stream was cancelled).\n    }\n  }\n\n  const scheduleFlush = (controller: TransformStreamDefaultController) => {\n    if (pending) {\n      return\n    }\n\n    const detached = new DetachedPromise<void>()\n    pending = detached\n\n    scheduleImmediate(() => {\n      try {\n        flush(controller)\n      } finally {\n        pending = undefined\n        detached.resolve()\n      }\n    })\n  }\n\n  return new TransformStream({\n    transform(chunk, controller) {\n      // Combine the previous buffer with the new chunk.\n      bufferedChunks.push(chunk)\n      bufferByteLength += chunk.byteLength\n\n      if (bufferByteLength >= maxBufferByteLength) {\n        flush(controller)\n      } else {\n        scheduleFlush(controller)\n      }\n    },\n    flush() {\n      return pending?.promise\n    },\n  })\n}\n\nfunction createPrefetchCommentStream(\n  isBuildTimePrerendering: boolean,\n  buildId: string\n): TransformStream<Uint8Array, Uint8Array> {\n  // Insert an extra comment at the beginning of the HTML document. This must\n  // come after the DOCTYPE, which is inserted by React.\n  //\n  // The first chunk sent by React will contain the doctype. After that, we can\n  // pass through the rest of the chunks as-is.\n  let didTransformFirstChunk = false\n  return new TransformStream({\n    transform(chunk, controller) {\n      if (isBuildTimePrerendering && !didTransformFirstChunk) {\n        didTransformFirstChunk = true\n        const decoder = new TextDecoder('utf-8', { fatal: true })\n        const chunkStr = decoder.decode(chunk, {\n          stream: true,\n        })\n        const updatedChunkStr = insertBuildIdComment(chunkStr, buildId)\n        controller.enqueue(encoder.encode(updatedChunkStr))\n        return\n      }\n      controller.enqueue(chunk)\n    },\n  })\n}\n\nexport function renderToInitialFizzStream({\n  ReactDOMServer,\n  element,\n  streamOptions,\n}: {\n  ReactDOMServer: {\n    renderToReadableStream: typeof import('react-dom/server').renderToReadableStream\n  }\n  element: React.ReactElement\n  streamOptions?: Parameters<typeof ReactDOMServer.renderToReadableStream>[1]\n}): Promise<ReactDOMServerReadableStream> {\n  return getTracer().trace(AppRenderSpan.renderToReadableStream, async () =>\n    ReactDOMServer.renderToReadableStream(element, streamOptions)\n  )\n}\n\nfunction createMetadataTransformStream(\n  insert: () => Promise<string> | string\n): TransformStream<Uint8Array, Uint8Array> {\n  let chunkIndex = -1\n  let isMarkRemoved = false\n\n  return new TransformStream({\n    async transform(chunk, controller) {\n      let iconMarkIndex = -1\n      let closedHeadIndex = -1\n      chunkIndex++\n\n      if (isMarkRemoved) {\n        controller.enqueue(chunk)\n        return\n      }\n      let iconMarkLength = 0\n      // Only search for the closed head tag once\n      if (iconMarkIndex === -1) {\n        iconMarkIndex = indexOfUint8Array(chunk, ENCODED_TAGS.META.ICON_MARK)\n        if (iconMarkIndex === -1) {\n          controller.enqueue(chunk)\n          return\n        } else {\n          // When we found the `<meta name=\"nxt-icon\"` tag prefix, we will remove it from the chunk.\n          // Its close tag could either be `/>` or `>`, checking the next char to ensure we cover both cases.\n          iconMarkLength = ENCODED_TAGS.META.ICON_MARK.length\n          // Check if next char is /, this is for xml mode.\n          if (chunk[iconMarkIndex + iconMarkLength] === 47) {\n            iconMarkLength += 2\n          } else {\n            // The last char is `>`\n            iconMarkLength++\n          }\n        }\n      }\n\n      // Check if icon mark is inside <head> tag in the first chunk.\n      if (chunkIndex === 0) {\n        closedHeadIndex = indexOfUint8Array(chunk, ENCODED_TAGS.CLOSED.HEAD)\n        if (iconMarkIndex !== -1) {\n          // The mark icon is located in the 1st chunk before the head tag.\n          // We do not need to insert the script tag in this case because it's in the head.\n          // Just remove the icon mark from the chunk.\n          if (iconMarkIndex < closedHeadIndex) {\n            const replaced = new Uint8Array(chunk.length - iconMarkLength)\n\n            // Remove the icon mark from the chunk.\n            replaced.set(chunk.subarray(0, iconMarkIndex))\n            replaced.set(\n              chunk.subarray(iconMarkIndex + iconMarkLength),\n              iconMarkIndex\n            )\n            chunk = replaced\n          } else {\n            // The icon mark is after the head tag, replace and insert the script tag at that position.\n            const insertion = await insert()\n            const encodedInsertion = encoder.encode(insertion)\n            const insertionLength = encodedInsertion.length\n            const replaced = new Uint8Array(\n              chunk.length - iconMarkLength + insertionLength\n            )\n            replaced.set(chunk.subarray(0, iconMarkIndex))\n            replaced.set(encodedInsertion, iconMarkIndex)\n            replaced.set(\n              chunk.subarray(iconMarkIndex + iconMarkLength),\n              iconMarkIndex + insertionLength\n            )\n            chunk = replaced\n          }\n          isMarkRemoved = true\n        }\n        // If there's no icon mark located, it will be handled later when if present in the following chunks.\n      } else {\n        // When it's appeared in the following chunks, we'll need to\n        // remove the mark and then insert the script tag at that position.\n        const insertion = await insert()\n        const encodedInsertion = encoder.encode(insertion)\n        const insertionLength = encodedInsertion.length\n        // Replace the icon mark with the hoist script or empty string.\n        const replaced = new Uint8Array(\n          chunk.length - iconMarkLength + insertionLength\n        )\n        // Set the first part of the chunk, before the icon mark.\n        replaced.set(chunk.subarray(0, iconMarkIndex))\n        // Set the insertion after the icon mark.\n        replaced.set(encodedInsertion, iconMarkIndex)\n\n        // Set the rest of the chunk after the icon mark.\n        replaced.set(\n          chunk.subarray(iconMarkIndex + iconMarkLength),\n          iconMarkIndex + insertionLength\n        )\n        chunk = replaced\n        isMarkRemoved = true\n      }\n      controller.enqueue(chunk)\n    },\n  })\n}\n\nfunction createHeadInsertionTransformStream(\n  insert: () => Promise<string>\n): TransformStream<Uint8Array, Uint8Array> {\n  let inserted = false\n\n  // We need to track if this transform saw any bytes because if it didn't\n  // we won't want to insert any server HTML at all\n  let hasBytes = false\n\n  return new TransformStream({\n    async transform(chunk, controller) {\n      hasBytes = true\n\n      const insertion = await insert()\n      if (inserted) {\n        if (insertion) {\n          const encodedInsertion = encoder.encode(insertion)\n          controller.enqueue(encodedInsertion)\n        }\n        controller.enqueue(chunk)\n      } else {\n        // TODO (@Ethan-Arrowood): Replace the generic `indexOfUint8Array` method with something finely tuned for the subset of things actually being checked for.\n        const index = indexOfUint8Array(chunk, ENCODED_TAGS.CLOSED.HEAD)\n        // In fully static rendering or non PPR rendering cases:\n        // `/head>` will always be found in the chunk in first chunk rendering.\n        if (index !== -1) {\n          if (insertion) {\n            const encodedInsertion = encoder.encode(insertion)\n            // Get the total count of the bytes in the chunk and the insertion\n            // e.g.\n            // chunk = <head><meta charset=\"utf-8\"></head>\n            // insertion = <script>...</script>\n            // output = <head><meta charset=\"utf-8\"> [ <script>...</script> ] </head>\n            const insertedHeadContent = new Uint8Array(\n              chunk.length + encodedInsertion.length\n            )\n            // Append the first part of the chunk, before the head tag\n            insertedHeadContent.set(chunk.slice(0, index))\n            // Append the server inserted content\n            insertedHeadContent.set(encodedInsertion, index)\n            // Append the rest of the chunk\n            insertedHeadContent.set(\n              chunk.slice(index),\n              index + encodedInsertion.length\n            )\n            controller.enqueue(insertedHeadContent)\n          } else {\n            controller.enqueue(chunk)\n          }\n          inserted = true\n        } else {\n          // This will happens in PPR rendering during next start, when the page is partially rendered.\n          // When the page resumes, the head tag will be found in the middle of the chunk.\n          // Where we just need to append the insertion and chunk to the current stream.\n          // e.g.\n          // PPR-static: <head>...</head><body> [ resume content ] </body>\n          // PPR-resume: [ insertion ] [ rest content ]\n          if (insertion) {\n            controller.enqueue(encoder.encode(insertion))\n          }\n          controller.enqueue(chunk)\n          inserted = true\n        }\n      }\n    },\n    async flush(controller) {\n      // Check before closing if there's anything remaining to insert.\n      if (hasBytes) {\n        const insertion = await insert()\n        if (insertion) {\n          controller.enqueue(encoder.encode(insertion))\n        }\n      }\n    },\n  })\n}\n\nfunction createClientResumeScriptInsertionTransformStream(): TransformStream<\n  Uint8Array,\n  Uint8Array\n> {\n  const segmentPath = '/_full'\n  const cacheBustingHeader = computeCacheBustingSearchParam(\n    '1', //            headers[NEXT_ROUTER_PREFETCH_HEADER]\n    '/_full', //       headers[NEXT_ROUTER_SEGMENT_PREFETCH_HEADER]\n    undefined, //      headers[NEXT_ROUTER_STATE_TREE_HEADER]\n    undefined //       headers[NEXT_URL]\n  )\n  const searchStr = `${NEXT_RSC_UNION_QUERY}=${cacheBustingHeader}`\n  const NEXT_CLIENT_RESUME_SCRIPT = `<script>__NEXT_CLIENT_RESUME=fetch(location.pathname+'?${searchStr}',{credentials:'same-origin',headers:{'${RSC_HEADER}': '1','${NEXT_ROUTER_PREFETCH_HEADER}': '1','${NEXT_ROUTER_SEGMENT_PREFETCH_HEADER}': '${segmentPath}'}})</script>`\n\n  let didAlreadyInsert = false\n  return new TransformStream({\n    transform(chunk, controller) {\n      if (didAlreadyInsert) {\n        // Already inserted the script into the head. Pass through.\n        controller.enqueue(chunk)\n        return\n      }\n      // TODO (@Ethan-Arrowood): Replace the generic `indexOfUint8Array` method with something finely tuned for the subset of things actually being checked for.\n      const headClosingTagIndex = indexOfUint8Array(\n        chunk,\n        ENCODED_TAGS.CLOSED.HEAD\n      )\n\n      if (headClosingTagIndex === -1) {\n        // In fully static rendering or non PPR rendering cases:\n        // `/head>` will always be found in the chunk in first chunk rendering.\n        controller.enqueue(chunk)\n        return\n      }\n\n      const encodedInsertion = encoder.encode(NEXT_CLIENT_RESUME_SCRIPT)\n      // Get the total count of the bytes in the chunk and the insertion\n      // e.g.\n      // chunk = <head><meta charset=\"utf-8\"></head>\n      // insertion = <script>...</script>\n      // output = <head><meta charset=\"utf-8\"> [ <script>...</script> ] </head>\n      const insertedHeadContent = new Uint8Array(\n        chunk.length + encodedInsertion.length\n      )\n      // Append the first part of the chunk, before the head tag\n      insertedHeadContent.set(chunk.slice(0, headClosingTagIndex))\n      // Append the server inserted content\n      insertedHeadContent.set(encodedInsertion, headClosingTagIndex)\n      // Append the rest of the chunk\n      insertedHeadContent.set(\n        chunk.slice(headClosingTagIndex),\n        headClosingTagIndex + encodedInsertion.length\n      )\n\n      controller.enqueue(insertedHeadContent)\n      didAlreadyInsert = true\n    },\n  })\n}\n\n// Suffix after main body content - scripts before </body>,\n// but wait for the major chunks to be enqueued.\nfunction createDeferredSuffixStream(\n  suffix: string\n): TransformStream<Uint8Array, Uint8Array> {\n  let flushed = false\n  let pending: DetachedPromise<void> | undefined\n\n  const flush = (controller: TransformStreamDefaultController) => {\n    const detached = new DetachedPromise<void>()\n    pending = detached\n\n    scheduleImmediate(() => {\n      try {\n        controller.enqueue(encoder.encode(suffix))\n      } catch {\n        // If an error occurs while enqueuing it can't be due to this\n        // transformers fault. It's likely due to the controller being\n        // errored due to the stream being cancelled.\n      } finally {\n        pending = undefined\n        detached.resolve()\n      }\n    })\n  }\n\n  return new TransformStream({\n    transform(chunk, controller) {\n      controller.enqueue(chunk)\n\n      // If we've already flushed, we're done.\n      if (flushed) return\n\n      // Schedule the flush to happen.\n      flushed = true\n      flush(controller)\n    },\n    flush(controller) {\n      if (pending) return pending.promise\n      if (flushed) return\n\n      // Flush now.\n      controller.enqueue(encoder.encode(suffix))\n    },\n  })\n}\n\nfunction createFlightDataInjectionTransformStream(\n  stream: ReadableStream<Uint8Array>,\n  delayDataUntilFirstHtmlChunk: boolean\n): TransformStream<Uint8Array, Uint8Array> {\n  let htmlStreamFinished = false\n\n  let pull: Promise<void> | null = null\n  let donePulling = false\n\n  function startOrContinuePulling(\n    controller: TransformStreamDefaultController\n  ) {\n    if (!pull) {\n      pull = startPulling(controller)\n    }\n    return pull\n  }\n\n  async function startPulling(controller: TransformStreamDefaultController) {\n    const reader = stream.getReader()\n\n    if (delayDataUntilFirstHtmlChunk) {\n      // NOTE: streaming flush\n      // We are buffering here for the inlined data stream because the\n      // \"shell\" stream might be chunkenized again by the underlying stream\n      // implementation, e.g. with a specific high-water mark. To ensure it's\n      // the safe timing to pipe the data stream, this extra tick is\n      // necessary.\n\n      // We don't start reading until we've left the current Task to ensure\n      // that it's inserted after flushing the shell. Note that this implementation\n      // might get stale if impl details of Fizz change in the future.\n      await atLeastOneTask()\n    }\n\n    try {\n      while (true) {\n        const { done, value } = await reader.read()\n        if (done) {\n          donePulling = true\n          return\n        }\n\n        // We want to prioritize HTML over RSC data.\n        // The SSR render is based on the same RSC stream, so when we get a new RSC chunk,\n        // we're likely to produce an HTML chunk as well, so give it a chance to flush first.\n        if (!delayDataUntilFirstHtmlChunk && !htmlStreamFinished) {\n          await atLeastOneTask()\n        }\n        controller.enqueue(value)\n      }\n    } catch (err) {\n      controller.error(err)\n    }\n  }\n\n  return new TransformStream({\n    start(controller) {\n      if (!delayDataUntilFirstHtmlChunk) {\n        startOrContinuePulling(controller)\n      }\n    },\n    transform(chunk, controller) {\n      controller.enqueue(chunk)\n\n      // Start the streaming if it hasn't already been started yet.\n      if (delayDataUntilFirstHtmlChunk) {\n        startOrContinuePulling(controller)\n      }\n    },\n    flush(controller) {\n      htmlStreamFinished = true\n      if (donePulling) {\n        return\n      }\n      return startOrContinuePulling(controller)\n    },\n  })\n}\n\nconst CLOSE_TAG = '</body></html>'\n\n/**\n * This transform stream moves the suffix to the end of the stream, so results\n * like `</body></html><script>...</script>` will be transformed to\n * `<script>...</script></body></html>`.\n */\nfunction createMoveSuffixStream(): TransformStream<Uint8Array, Uint8Array> {\n  let foundSuffix = false\n\n  return new TransformStream({\n    transform(chunk, controller) {\n      if (foundSuffix) {\n        return controller.enqueue(chunk)\n      }\n\n      const index = indexOfUint8Array(chunk, ENCODED_TAGS.CLOSED.BODY_AND_HTML)\n      if (index > -1) {\n        foundSuffix = true\n\n        // If the whole chunk is the suffix, then don't write anything, it will\n        // be written in the flush.\n        if (chunk.length === ENCODED_TAGS.CLOSED.BODY_AND_HTML.length) {\n          return\n        }\n\n        // Write out the part before the suffix.\n        const before = chunk.slice(0, index)\n        controller.enqueue(before)\n\n        // In the case where the suffix is in the middle of the chunk, we need\n        // to split the chunk into two parts.\n        if (chunk.length > ENCODED_TAGS.CLOSED.BODY_AND_HTML.length + index) {\n          // Write out the part after the suffix.\n          const after = chunk.slice(\n            index + ENCODED_TAGS.CLOSED.BODY_AND_HTML.length\n          )\n          controller.enqueue(after)\n        }\n      } else {\n        controller.enqueue(chunk)\n      }\n    },\n    flush(controller) {\n      // Even if we didn't find the suffix, the HTML is not valid if we don't\n      // add it, so insert it at the end.\n      controller.enqueue(ENCODED_TAGS.CLOSED.BODY_AND_HTML)\n    },\n  })\n}\n\nfunction createStripDocumentClosingTagsTransform(): TransformStream<\n  Uint8Array,\n  Uint8Array\n> {\n  return new TransformStream({\n    transform(chunk, controller) {\n      // We rely on the assumption that chunks will never break across a code unit.\n      // This is reasonable because we currently concat all of React's output from a single\n      // flush into one chunk before streaming it forward which means the chunk will represent\n      // a single coherent utf-8 string. This is not safe to use if we change our streaming to no\n      // longer do this large buffered chunk\n      if (\n        isEquivalentUint8Arrays(chunk, ENCODED_TAGS.CLOSED.BODY_AND_HTML) ||\n        isEquivalentUint8Arrays(chunk, ENCODED_TAGS.CLOSED.BODY) ||\n        isEquivalentUint8Arrays(chunk, ENCODED_TAGS.CLOSED.HTML)\n      ) {\n        // the entire chunk is the closing tags; return without enqueueing anything.\n        return\n      }\n\n      // We assume these tags will go at together at the end of the document and that\n      // they won't appear anywhere else in the document. This is not really a safe assumption\n      // but until we revamp our streaming infra this is a performant way to string the tags\n      chunk = removeFromUint8Array(chunk, ENCODED_TAGS.CLOSED.BODY)\n      chunk = removeFromUint8Array(chunk, ENCODED_TAGS.CLOSED.HTML)\n\n      controller.enqueue(chunk)\n    },\n  })\n}\n\n/*\n * Checks if the root layout is missing the html or body tags\n * and if so, it will inject a script tag to throw an error in the browser, showing the user\n * the error message in the error overlay.\n */\nexport function createRootLayoutValidatorStream(): TransformStream<\n  Uint8Array,\n  Uint8Array\n> {\n  let foundHtml = false\n  let foundBody = false\n  return new TransformStream({\n    async transform(chunk, controller) {\n      // Peek into the streamed chunk to see if the tags are present.\n      if (\n        !foundHtml &&\n        indexOfUint8Array(chunk, ENCODED_TAGS.OPENING.HTML) > -1\n      ) {\n        foundHtml = true\n      }\n\n      if (\n        !foundBody &&\n        indexOfUint8Array(chunk, ENCODED_TAGS.OPENING.BODY) > -1\n      ) {\n        foundBody = true\n      }\n\n      controller.enqueue(chunk)\n    },\n    flush(controller) {\n      const missingTags: ('html' | 'body')[] = []\n      if (!foundHtml) missingTags.push('html')\n      if (!foundBody) missingTags.push('body')\n\n      if (!missingTags.length) return\n\n      controller.enqueue(\n        encoder.encode(\n          `<html id=\"__next_error__\">\n            <template\n              data-next-error-message=\"Missing ${missingTags\n                .map((c) => `<${c}>`)\n                .join(\n                  missingTags.length > 1 ? ' and ' : ''\n                )} tags in the root layout.\\nRead more at https://nextjs.org/docs/messages/missing-root-layout-tags\"\n              data-next-error-digest=\"${MISSING_ROOT_TAGS_ERROR}\"\n              data-next-error-stack=\"\"\n            ></template>\n          `\n        )\n      )\n    },\n  })\n}\n\nfunction chainTransformers<T>(\n  readable: ReadableStream<T>,\n  transformers: ReadonlyArray<TransformStream<T, T> | null>\n): ReadableStream<T> {\n  let stream = readable\n  for (const transformer of transformers) {\n    if (!transformer) continue\n\n    stream = stream.pipeThrough(transformer)\n  }\n  return stream\n}\n\nexport type ContinueStreamOptions = {\n  inlinedDataStream: ReadableStream<Uint8Array> | undefined\n  isStaticGeneration: boolean\n  isBuildTimePrerendering: boolean\n  buildId: string\n  getServerInsertedHTML: () => Promise<string>\n  getServerInsertedMetadata: () => Promise<string>\n  validateRootLayout?: boolean\n  /**\n   * Suffix to inject after the buffered data, but before the close tags.\n   */\n  suffix?: string | undefined\n}\n\nexport async function continueFizzStream(\n  renderStream: ReactDOMServerReadableStream,\n  {\n    suffix,\n    inlinedDataStream,\n    isStaticGeneration,\n    isBuildTimePrerendering,\n    buildId,\n    getServerInsertedHTML,\n    getServerInsertedMetadata,\n    validateRootLayout,\n  }: ContinueStreamOptions\n): Promise<ReadableStream<Uint8Array>> {\n  // Suffix itself might contain close tags at the end, so we need to split it.\n  const suffixUnclosed = suffix ? suffix.split(CLOSE_TAG, 1)[0] : null\n\n  // If we're generating static HTML we need to wait for it to resolve before continuing.\n  if (isStaticGeneration) {\n    await renderStream.allReady\n  }\n\n  return chainTransformers(renderStream, [\n    // Buffer everything to avoid flushing too frequently\n    createBufferedTransformStream(),\n\n    // Add build id comment to start of the HTML document (in export mode)\n    createPrefetchCommentStream(isBuildTimePrerendering, buildId),\n\n    // Transform metadata\n    createMetadataTransformStream(getServerInsertedMetadata),\n\n    // Insert suffix content\n    suffixUnclosed != null && suffixUnclosed.length > 0\n      ? createDeferredSuffixStream(suffixUnclosed)\n      : null,\n\n    // Insert the inlined data (Flight data, form state, etc.) stream into the HTML\n    inlinedDataStream\n      ? createFlightDataInjectionTransformStream(inlinedDataStream, true)\n      : null,\n\n    // Validate the root layout for missing html or body tags\n    validateRootLayout ? createRootLayoutValidatorStream() : null,\n\n    // Close tags should always be deferred to the end\n    createMoveSuffixStream(),\n\n    // Special head insertions\n    // TODO-APP: Insert server side html to end of head in app layout rendering, to avoid\n    // hydration errors. Remove this once it's ready to be handled by react itself.\n    createHeadInsertionTransformStream(getServerInsertedHTML),\n  ])\n}\n\ntype ContinueDynamicPrerenderOptions = {\n  getServerInsertedHTML: () => Promise<string>\n  getServerInsertedMetadata: () => Promise<string>\n}\n\nexport async function continueDynamicPrerender(\n  prerenderStream: ReadableStream<Uint8Array>,\n  {\n    getServerInsertedHTML,\n    getServerInsertedMetadata,\n  }: ContinueDynamicPrerenderOptions\n) {\n  return (\n    prerenderStream\n      // Buffer everything to avoid flushing too frequently\n      .pipeThrough(createBufferedTransformStream())\n      .pipeThrough(createStripDocumentClosingTagsTransform())\n      // Insert generated tags to head\n      .pipeThrough(createHeadInsertionTransformStream(getServerInsertedHTML))\n      // Transform metadata\n      .pipeThrough(createMetadataTransformStream(getServerInsertedMetadata))\n  )\n}\n\ntype ContinueStaticPrerenderOptions = {\n  inlinedDataStream: ReadableStream<Uint8Array>\n  getServerInsertedHTML: () => Promise<string>\n  getServerInsertedMetadata: () => Promise<string>\n  isBuildTimePrerendering: boolean\n  buildId: string\n}\n\nexport async function continueStaticPrerender(\n  prerenderStream: ReadableStream<Uint8Array>,\n  {\n    inlinedDataStream,\n    getServerInsertedHTML,\n    getServerInsertedMetadata,\n    isBuildTimePrerendering,\n    buildId,\n  }: ContinueStaticPrerenderOptions\n) {\n  return (\n    prerenderStream\n      // Buffer everything to avoid flushing too frequently\n      .pipeThrough(createBufferedTransformStream())\n      // Add build id comment to start of the HTML document (in export mode)\n      .pipeThrough(\n        createPrefetchCommentStream(isBuildTimePrerendering, buildId)\n      )\n      // Insert generated tags to head\n      .pipeThrough(createHeadInsertionTransformStream(getServerInsertedHTML))\n      // Transform metadata\n      .pipeThrough(createMetadataTransformStream(getServerInsertedMetadata))\n      // Insert the inlined data (Flight data, form state, etc.) stream into the HTML\n      .pipeThrough(\n        createFlightDataInjectionTransformStream(inlinedDataStream, true)\n      )\n      // Close tags should always be deferred to the end\n      .pipeThrough(createMoveSuffixStream())\n  )\n}\n\nexport async function continueStaticFallbackPrerender(\n  prerenderStream: ReadableStream<Uint8Array>,\n  {\n    inlinedDataStream,\n    getServerInsertedHTML,\n    getServerInsertedMetadata,\n    isBuildTimePrerendering,\n    buildId,\n  }: ContinueStaticPrerenderOptions\n) {\n  // Same as `continueStaticPrerender`, but also inserts an additional script\n  // to instruct the client to start fetching the hydration data as early\n  // as possible.\n  return (\n    prerenderStream\n      // Buffer everything to avoid flushing too frequently\n      .pipeThrough(createBufferedTransformStream())\n      // Add build id comment to start of the HTML document (in export mode)\n      .pipeThrough(\n        createPrefetchCommentStream(isBuildTimePrerendering, buildId)\n      )\n      // Insert generated tags to head\n      .pipeThrough(createHeadInsertionTransformStream(getServerInsertedHTML))\n      // Insert the client resume script into the head\n      .pipeThrough(createClientResumeScriptInsertionTransformStream())\n      // Transform metadata\n      .pipeThrough(createMetadataTransformStream(getServerInsertedMetadata))\n      // Insert the inlined data (Flight data, form state, etc.) stream into the HTML\n      .pipeThrough(\n        createFlightDataInjectionTransformStream(inlinedDataStream, true)\n      )\n      // Close tags should always be deferred to the end\n      .pipeThrough(createMoveSuffixStream())\n  )\n}\n\ntype ContinueResumeOptions = {\n  inlinedDataStream: ReadableStream<Uint8Array>\n  getServerInsertedHTML: () => Promise<string>\n  getServerInsertedMetadata: () => Promise<string>\n  delayDataUntilFirstHtmlChunk: boolean\n}\n\nexport async function continueDynamicHTMLResume(\n  renderStream: ReadableStream<Uint8Array>,\n  {\n    delayDataUntilFirstHtmlChunk,\n    inlinedDataStream,\n    getServerInsertedHTML,\n    getServerInsertedMetadata,\n  }: ContinueResumeOptions\n) {\n  return (\n    renderStream\n      // Buffer everything to avoid flushing too frequently\n      .pipeThrough(createBufferedTransformStream())\n      // Insert generated tags to head\n      .pipeThrough(createHeadInsertionTransformStream(getServerInsertedHTML))\n      // Transform metadata\n      .pipeThrough(createMetadataTransformStream(getServerInsertedMetadata))\n      // Insert the inlined data (Flight data, form state, etc.) stream into the HTML\n      .pipeThrough(\n        createFlightDataInjectionTransformStream(\n          inlinedDataStream,\n          delayDataUntilFirstHtmlChunk\n        )\n      )\n      // Close tags should always be deferred to the end\n      .pipeThrough(createMoveSuffixStream())\n  )\n}\n\nexport function createDocumentClosingStream(): ReadableStream<Uint8Array> {\n  return streamFromString(CLOSE_TAG)\n}\n","import type { IncomingMessage } from 'http'\nimport type { ParsedUrlQuery } from 'querystring'\nimport type { UrlWithParsedQuery } from 'url'\nimport type { BaseNextRequest } from './base-http'\nimport type { CloneableBody } from './body-streams'\nimport type { RouteMatch } from './route-matches/route-match'\nimport type { NEXT_RSC_UNION_QUERY } from '../client/components/app-router-headers'\nimport type {\n  ResponseCacheEntry,\n  ServerComponentsHmrCache,\n} from './response-cache'\nimport type { PagesDevOverlayBridgeType } from '../next-devtools/userspace/pages/pages-dev-overlay-setup'\nimport type { OpaqueFallbackRouteParams } from './request/fallback-params'\nimport type { IncrementalCache } from './lib/incremental-cache'\n\n// FIXME: (wyattjoh) this is a temporary solution to allow us to pass data between bundled modules\nexport const NEXT_REQUEST_META = Symbol.for('NextInternalRequestMeta')\n\nexport type NextIncomingMessage = (BaseNextRequest | IncomingMessage) & {\n  [NEXT_REQUEST_META]?: RequestMeta\n}\n\n/**\n * The callback function to call when a response cache entry was generated or\n * looked up in the cache. When it returns true, the server assumes that the\n * handler has already responded to the request and will not do so itself.\n */\nexport type OnCacheEntryHandler = (\n  /**\n   * The response cache entry that was generated or looked up in the cache.\n   */\n  cacheEntry: ResponseCacheEntry,\n\n  /**\n   * The request metadata.\n   */\n  requestMeta: {\n    /**\n     * The URL that was used to make the request.\n     */\n    url: string | undefined\n  }\n) => Promise<boolean | void> | boolean | void\n\nexport interface RequestMeta {\n  /**\n   * The query that was used to make the request.\n   */\n  initQuery?: ParsedUrlQuery\n\n  /**\n   * The URL that was used to make the request.\n   */\n  initURL?: string\n\n  /**\n   * The protocol that was used to make the request.\n   */\n  initProtocol?: string\n\n  /**\n   * The body that was read from the request. This is used to allow the body to\n   * be read multiple times.\n   */\n  clonableBody?: CloneableBody\n\n  /**\n   * True when the request matched a locale domain that was configured in the\n   * next.config.js file.\n   */\n  isLocaleDomain?: boolean\n\n  /**\n   * True when the request had locale information stripped from the pathname\n   * part of the URL.\n   */\n  didStripLocale?: boolean\n\n  /**\n   * If the request had it's URL rewritten, this is the URL it was rewritten to.\n   */\n  rewroteURL?: string\n\n  /**\n   * The cookies that were added by middleware and were added to the response.\n   */\n  middlewareCookie?: string[]\n\n  /**\n   * The match on the request for a given route.\n   */\n  match?: RouteMatch\n\n  /**\n   * The incremental cache to use for the request.\n   */\n  incrementalCache?: IncrementalCache\n\n  /**\n   * The server components HMR cache, only for dev.\n   */\n  serverComponentsHmrCache?: ServerComponentsHmrCache\n\n  /**\n   * Equals the segment path that was used for the prefetch RSC request.\n   */\n  segmentPrefetchRSCRequest?: string\n\n  /**\n   * True when the request is for the prefetch flight data.\n   */\n  isPrefetchRSCRequest?: true\n\n  /**\n   * True when the request is for the flight data.\n   */\n  isRSCRequest?: true\n\n  /**\n   * A search param set by the Next.js client when performing RSC requests.\n   * Because some CDNs do not vary their cache entries on our custom headers,\n   * this search param represents a hash of the header values. For any cached\n   * RSC request, we should verify that the hash matches before responding.\n   * Otherwise this can lead to cache poisoning.\n   * TODO: Consider not using custom request headers at all, and instead encode\n   * everything into the search param.\n   */\n  cacheBustingSearchParam?: string\n\n  /**\n   * True when the request is for the `/_next/data` route using the pages\n   * router.\n   */\n  isNextDataReq?: true\n\n  /**\n   * Postponed state to use for resumption. If present it's assumed that the\n   * request is for a page that has postponed (there are no guarantees that the\n   * page actually has postponed though as it would incur an additional cache\n   * lookup).\n   */\n  postponed?: string\n\n  /**\n   * If provided, this will be called when a response cache entry was generated\n   * or looked up in the cache.\n   *\n   * @deprecated Use `onCacheEntryV2` instead.\n   */\n  onCacheEntry?: OnCacheEntryHandler\n\n  /**\n   * If provided, this will be called when a response cache entry was generated\n   * or looked up in the cache.\n   */\n  onCacheEntryV2?: OnCacheEntryHandler\n\n  /**\n   * The previous revalidate before rendering 404 page for notFound: true\n   */\n  notFoundRevalidate?: number | false\n\n  /**\n   * In development, the original source page that returned a 404.\n   */\n  developmentNotFoundSourcePage?: string\n\n  /**\n   * The path we routed to and should be invoked\n   */\n  invokePath?: string\n\n  /**\n   * The specific page output we should be matching\n   */\n  invokeOutput?: string\n\n  /**\n   * The status we are invoking the request with from routing\n   */\n  invokeStatus?: number\n\n  /**\n   * The routing error we are invoking with\n   */\n  invokeError?: Error\n\n  /**\n   * The query parsed for the invocation\n   */\n  invokeQuery?: Record<string, undefined | string | string[]>\n\n  /**\n   * Whether the request is a middleware invocation\n   */\n  middlewareInvoke?: boolean\n\n  /**\n   * Whether the request should render the fallback shell or not.\n   */\n  renderFallbackShell?: boolean\n\n  /**\n   * Whether the request is for the custom error page.\n   */\n  customErrorRender?: true\n\n  /**\n   * Whether to bubble up the NoFallbackError to the caller when a 404 is\n   * returned.\n   */\n  bubbleNoFallback?: true\n\n  /**\n   * True when the request had locale information inferred from the default\n   * locale.\n   */\n  localeInferredFromDefault?: true\n\n  /**\n   * The locale that was inferred or explicitly set for the request.\n   */\n  locale?: string\n\n  /**\n   * The default locale that was inferred or explicitly set for the request.\n   */\n  defaultLocale?: string\n\n  /**\n   * The relative project dir the server is running in from project root\n   */\n  relativeProjectDir?: string\n\n  /**\n   * The dist directory the server is currently using\n   */\n  distDir?: string\n\n  /**\n   * The query after resolving routes\n   */\n  query?: ParsedUrlQuery\n\n  /**\n   * The params after resolving routes\n   */\n  params?: ParsedUrlQuery\n\n  /**\n   * ErrorOverlay component to use in development for pages router\n   */\n  PagesErrorDebug?: PagesDevOverlayBridgeType\n\n  /**\n   * Whether server is in minimal mode (this will be replaced with more\n   * specific flags in future)\n   */\n  minimalMode?: boolean\n\n  /**\n   * DEV only: The fallback params that should be used when validating prerenders during dev\n   */\n  devValidatingFallbackParams?: OpaqueFallbackRouteParams\n\n  /**\n   * DEV only: Request timings in process.hrtime.bigint()\n   */\n  devRequestTimingStart?: bigint\n  devRequestTimingMiddlewareStart?: bigint\n  devRequestTimingMiddlewareEnd?: bigint\n  devRequestTimingInternalsEnd?: bigint\n}\n\n/**\n * Gets the request metadata. If no key is provided, the entire metadata object\n * is returned.\n *\n * @param req the request to get the metadata from\n * @param key the key to get from the metadata (optional)\n * @returns the value for the key or the entire metadata object\n */\nexport function getRequestMeta(\n  req: NextIncomingMessage,\n  key?: undefined\n): RequestMeta\nexport function getRequestMeta<K extends keyof RequestMeta>(\n  req: NextIncomingMessage,\n  key: K\n): RequestMeta[K]\nexport function getRequestMeta<K extends keyof RequestMeta>(\n  req: NextIncomingMessage,\n  key?: K\n): RequestMeta | RequestMeta[K] {\n  const meta = req[NEXT_REQUEST_META] || {}\n  return typeof key === 'string' ? meta[key] : meta\n}\n\n/**\n * Sets the request metadata.\n *\n * @param req the request to set the metadata on\n * @param meta the metadata to set\n * @returns the mutated request metadata\n */\nexport function setRequestMeta(req: NextIncomingMessage, meta: RequestMeta) {\n  req[NEXT_REQUEST_META] = meta\n  return meta\n}\n\n/**\n * Adds a value to the request metadata.\n *\n * @param request the request to mutate\n * @param key the key to set\n * @param value the value to set\n * @returns the mutated request metadata\n */\nexport function addRequestMeta<K extends keyof RequestMeta>(\n  request: NextIncomingMessage,\n  key: K,\n  value: RequestMeta[K]\n) {\n  const meta = getRequestMeta(request)\n  meta[key] = value\n  return setRequestMeta(request, meta)\n}\n\n/**\n * Removes a key from the request metadata.\n *\n * @param request the request to mutate\n * @param key the key to remove\n * @returns the mutated request metadata\n */\nexport function removeRequestMeta<K extends keyof RequestMeta>(\n  request: NextIncomingMessage,\n  key: K\n) {\n  const meta = getRequestMeta(request)\n  delete meta[key]\n  return setRequestMeta(request, meta)\n}\n\ntype NextQueryMetadata = {\n  /**\n   * The `_rsc` query parameter used for cache busting to ensure that the RSC\n   * requests do not get cached by the browser explicitly.\n   */\n  [NEXT_RSC_UNION_QUERY]?: string\n}\n\nexport type NextParsedUrlQuery = ParsedUrlQuery & NextQueryMetadata\n\nexport interface NextUrlWithParsedQuery extends UrlWithParsedQuery {\n  query: NextParsedUrlQuery\n}\n","import type { BaseNextRequest, BaseNextResponse } from './'\nimport type { NodeNextRequest, NodeNextResponse } from './node'\nimport type { WebNextRequest, WebNextResponse } from './web'\n\n/**\n * This file provides some helpers that should be used in conjunction with\n * explicit environment checks. When combined with the environment checks, it\n * will ensure that the correct typings are used as well as enable code\n * elimination.\n */\n\n/**\n * Type guard to determine if a request is a WebNextRequest. This does not\n * actually check the type of the request, but rather the runtime environment.\n * It's expected that when the runtime environment is the edge runtime, that any\n * base request is a WebNextRequest.\n */\nexport const isWebNextRequest = (req: BaseNextRequest): req is WebNextRequest =>\n  process.env.NEXT_RUNTIME === 'edge'\n\n/**\n * Type guard to determine if a response is a WebNextResponse. This does not\n * actually check the type of the response, but rather the runtime environment.\n * It's expected that when the runtime environment is the edge runtime, that any\n * base response is a WebNextResponse.\n */\nexport const isWebNextResponse = (\n  res: BaseNextResponse\n): res is WebNextResponse => process.env.NEXT_RUNTIME === 'edge'\n\n/**\n * Type guard to determine if a request is a NodeNextRequest. This does not\n * actually check the type of the request, but rather the runtime environment.\n * It's expected that when the runtime environment is the node runtime, that any\n * base request is a NodeNextRequest.\n */\nexport const isNodeNextRequest = (\n  req: BaseNextRequest\n): req is NodeNextRequest => process.env.NEXT_RUNTIME !== 'edge'\n\n/**\n * Type guard to determine if a response is a NodeNextResponse. This does not\n * actually check the type of the response, but rather the runtime environment.\n * It's expected that when the runtime environment is the node runtime, that any\n * base response is a NodeNextResponse.\n */\nexport const isNodeNextResponse = (\n  res: BaseNextResponse\n): res is NodeNextResponse => process.env.NEXT_RUNTIME !== 'edge'\n","import type { BaseNextRequest } from '../../../base-http'\nimport type { NodeNextRequest } from '../../../base-http/node'\nimport type { WebNextRequest } from '../../../base-http/web'\nimport type { Writable } from 'node:stream'\n\nimport { getRequestMeta } from '../../../request-meta'\nimport { fromNodeOutgoingHttpHeaders } from '../../utils'\nimport { NextRequest } from '../request'\nimport { isNodeNextRequest, isWebNextRequest } from '../../../base-http/helpers'\n\nexport const ResponseAbortedName = 'ResponseAborted'\nexport class ResponseAborted extends Error {\n  public readonly name = ResponseAbortedName\n}\n\n/**\n * Creates an AbortController tied to the closing of a ServerResponse (or other\n * appropriate Writable).\n *\n * If the `close` event is fired before the `finish` event, then we'll send the\n * `abort` signal.\n */\nexport function createAbortController(response: Writable): AbortController {\n  const controller = new AbortController()\n\n  // If `finish` fires first, then `res.end()` has been called and the close is\n  // just us finishing the stream on our side. If `close` fires first, then we\n  // know the client disconnected before we finished.\n  response.once('close', () => {\n    if (response.writableFinished) return\n\n    controller.abort(new ResponseAborted())\n  })\n\n  return controller\n}\n\n/**\n * Creates an AbortSignal tied to the closing of a ServerResponse (or other\n * appropriate Writable).\n *\n * This cannot be done with the request (IncomingMessage or Readable) because\n * the `abort` event will not fire if to data has been fully read (because that\n * will \"close\" the readable stream and nothing fires after that).\n */\nexport function signalFromNodeResponse(response: Writable): AbortSignal {\n  const { errored, destroyed } = response\n  if (errored || destroyed) {\n    return AbortSignal.abort(errored ?? new ResponseAborted())\n  }\n\n  const { signal } = createAbortController(response)\n  return signal\n}\n\nexport class NextRequestAdapter {\n  public static fromBaseNextRequest(\n    request: BaseNextRequest,\n    signal: AbortSignal\n  ): NextRequest {\n    if (\n      // The type check here ensures that `req` is correctly typed, and the\n      // environment variable check provides dead code elimination.\n      process.env.NEXT_RUNTIME === 'edge' &&\n      isWebNextRequest(request)\n    ) {\n      return NextRequestAdapter.fromWebNextRequest(request)\n    } else if (\n      // The type check here ensures that `req` is correctly typed, and the\n      // environment variable check provides dead code elimination.\n      process.env.NEXT_RUNTIME !== 'edge' &&\n      isNodeNextRequest(request)\n    ) {\n      return NextRequestAdapter.fromNodeNextRequest(request, signal)\n    } else {\n      throw new Error('Invariant: Unsupported NextRequest type')\n    }\n  }\n\n  public static fromNodeNextRequest(\n    request: NodeNextRequest,\n    signal: AbortSignal\n  ): NextRequest {\n    // HEAD and GET requests can not have a body.\n    let body: BodyInit | null = null\n    if (request.method !== 'GET' && request.method !== 'HEAD' && request.body) {\n      // @ts-expect-error - this is handled by undici, when streams/web land use it instead\n      body = request.body\n    }\n\n    let url: URL\n    if (request.url.startsWith('http')) {\n      url = new URL(request.url)\n    } else {\n      // Grab the full URL from the request metadata.\n      const base = getRequestMeta(request, 'initURL')\n      if (!base || !base.startsWith('http')) {\n        // Because the URL construction relies on the fact that the URL provided\n        // is absolute, we need to provide a base URL. We can't use the request\n        // URL because it's relative, so we use a dummy URL instead.\n        url = new URL(request.url, 'http://n')\n      } else {\n        url = new URL(request.url, base)\n      }\n    }\n\n    return new NextRequest(url, {\n      method: request.method,\n      headers: fromNodeOutgoingHttpHeaders(request.headers),\n      duplex: 'half',\n      signal,\n      // geo\n      // ip\n      // nextConfig\n\n      // body can not be passed if request was aborted\n      // or we get a Request body was disturbed error\n      ...(signal.aborted\n        ? {}\n        : {\n            body,\n          }),\n    })\n  }\n\n  public static fromWebNextRequest(request: WebNextRequest): NextRequest {\n    // HEAD and GET requests can not have a body.\n    let body: ReadableStream | null = null\n    if (request.method !== 'GET' && request.method !== 'HEAD') {\n      body = request.body\n    }\n\n    return new NextRequest(request.url, {\n      method: request.method,\n      headers: fromNodeOutgoingHttpHeaders(request.headers),\n      duplex: 'half',\n      signal: request.request.signal,\n      // geo\n      // ip\n      // nextConfig\n\n      // body can not be passed if request was aborted\n      // or we get a Request body was disturbed error\n      ...(request.request.signal.aborted\n        ? {}\n        : {\n            body,\n          }),\n    })\n  }\n}\n","import type { AppPageModule } from './route-modules/app-page/module'\n\n// Combined load times for loading client components\nlet clientComponentLoadStart = 0\nlet clientComponentLoadTimes = 0\nlet clientComponentLoadCount = 0\n\nexport function wrapClientComponentLoader(\n  ComponentMod: AppPageModule\n): AppPageModule['__next_app__'] {\n  if (!('performance' in globalThis)) {\n    return ComponentMod.__next_app__\n  }\n\n  return {\n    require: (...args) => {\n      const startTime = performance.now()\n\n      if (clientComponentLoadStart === 0) {\n        clientComponentLoadStart = startTime\n      }\n\n      try {\n        clientComponentLoadCount += 1\n        return ComponentMod.__next_app__.require(...args)\n      } finally {\n        clientComponentLoadTimes += performance.now() - startTime\n      }\n    },\n    loadChunk: (...args) => {\n      const startTime = performance.now()\n      const result = ComponentMod.__next_app__.loadChunk(...args)\n      // Avoid wrapping `loadChunk`'s result in an extra promise in case something like React depends on its identity.\n      // We only need to know when it's settled.\n      result.finally(() => {\n        clientComponentLoadTimes += performance.now() - startTime\n      })\n      return result\n    },\n  }\n}\n\nexport function getClientComponentLoaderMetrics(\n  options: { reset?: boolean } = {}\n) {\n  const metrics =\n    clientComponentLoadStart === 0\n      ? undefined\n      : {\n          clientComponentLoadStart,\n          clientComponentLoadTimes,\n          clientComponentLoadCount,\n        }\n\n  if (options.reset) {\n    clientComponentLoadStart = 0\n    clientComponentLoadTimes = 0\n    clientComponentLoadCount = 0\n  }\n\n  return metrics\n}\n","import type { ServerResponse } from 'node:http'\n\nimport {\n  ResponseAbortedName,\n  createAbortController,\n} from './web/spec-extension/adapters/next-request'\nimport { DetachedPromise } from '../lib/detached-promise'\nimport { getTracer } from './lib/trace/tracer'\nimport { NextNodeServerSpan } from './lib/trace/constants'\nimport { getClientComponentLoaderMetrics } from './client-component-renderer-logger'\n\nexport function isAbortError(e: any): e is Error & { name: 'AbortError' } {\n  return e?.name === 'AbortError' || e?.name === ResponseAbortedName\n}\n\nfunction createWriterFromResponse(\n  res: ServerResponse,\n  waitUntilForEnd?: Promise<unknown>\n): WritableStream<Uint8Array> {\n  let started = false\n\n  // Create a promise that will resolve once the response has drained. See\n  // https://nodejs.org/api/stream.html#stream_event_drain\n  let drained = new DetachedPromise<void>()\n  function onDrain() {\n    drained.resolve()\n  }\n  res.on('drain', onDrain)\n\n  // If the finish event fires, it means we shouldn't block and wait for the\n  // drain event.\n  res.once('close', () => {\n    res.off('drain', onDrain)\n    drained.resolve()\n  })\n\n  // Create a promise that will resolve once the response has finished. See\n  // https://nodejs.org/api/http.html#event-finish_1\n  const finished = new DetachedPromise<void>()\n  res.once('finish', () => {\n    finished.resolve()\n  })\n\n  // Create a writable stream that will write to the response.\n  return new WritableStream<Uint8Array>({\n    write: async (chunk) => {\n      // You'd think we'd want to use `start` instead of placing this in `write`\n      // but this ensures that we don't actually flush the headers until we've\n      // started writing chunks.\n      if (!started) {\n        started = true\n\n        if (\n          'performance' in globalThis &&\n          process.env.NEXT_OTEL_PERFORMANCE_PREFIX\n        ) {\n          const metrics = getClientComponentLoaderMetrics()\n          if (metrics) {\n            performance.measure(\n              `${process.env.NEXT_OTEL_PERFORMANCE_PREFIX}:next-client-component-loading`,\n              {\n                start: metrics.clientComponentLoadStart,\n                end:\n                  metrics.clientComponentLoadStart +\n                  metrics.clientComponentLoadTimes,\n              }\n            )\n          }\n        }\n\n        res.flushHeaders()\n        getTracer().trace(\n          NextNodeServerSpan.startResponse,\n          {\n            spanName: 'start response',\n          },\n          () => undefined\n        )\n      }\n\n      try {\n        const ok = res.write(chunk)\n\n        // Added by the `compression` middleware, this is a function that will\n        // flush the partially-compressed response to the client.\n        if ('flush' in res && typeof res.flush === 'function') {\n          res.flush()\n        }\n\n        // If the write returns false, it means there's some backpressure, so\n        // wait until it's streamed before continuing.\n        if (!ok) {\n          await drained.promise\n\n          // Reset the drained promise so that we can wait for the next drain event.\n          drained = new DetachedPromise<void>()\n        }\n      } catch (err) {\n        res.end()\n        throw new Error('failed to write chunk to response', { cause: err })\n      }\n    },\n    abort: (err) => {\n      if (res.writableFinished) return\n\n      res.destroy(err)\n    },\n    close: async () => {\n      // if a waitUntil promise was passed, wait for it to resolve before\n      // ending the response.\n      if (waitUntilForEnd) {\n        await waitUntilForEnd\n      }\n\n      if (res.writableFinished) return\n\n      res.end()\n      return finished.promise\n    },\n  })\n}\n\nexport async function pipeToNodeResponse(\n  readable: ReadableStream<Uint8Array>,\n  res: ServerResponse,\n  waitUntilForEnd?: Promise<unknown>\n) {\n  try {\n    // If the response has already errored, then just return now.\n    const { errored, destroyed } = res\n    if (errored || destroyed) return\n\n    // Create a new AbortController so that we can abort the readable if the\n    // client disconnects.\n    const controller = createAbortController(res)\n\n    const writer = createWriterFromResponse(res, waitUntilForEnd)\n\n    await readable.pipeTo(writer, { signal: controller.signal })\n  } catch (err: any) {\n    // If this isn't related to an abort error, re-throw it.\n    if (isAbortError(err)) return\n\n    throw new Error('failed to pipe response', { cause: err })\n  }\n}\n","import type { OutgoingHttpHeaders, ServerResponse } from 'http'\nimport type { CacheControl } from './lib/cache-control'\nimport type { FetchMetrics } from './base-http'\n\nimport {\n  chainStreams,\n  streamFromBuffer,\n  streamFromString,\n  streamToString,\n} from './stream-utils/node-web-streams-helper'\nimport { isAbortError, pipeToNodeResponse } from './pipe-readable'\nimport type { RenderResumeDataCache } from './resume-data-cache/resume-data-cache'\nimport { InvariantError } from '../shared/lib/invariant-error'\nimport type {\n  HTML_CONTENT_TYPE_HEADER,\n  JSON_CONTENT_TYPE_HEADER,\n  TEXT_PLAIN_CONTENT_TYPE_HEADER,\n} from '../lib/constants'\nimport type { RSC_CONTENT_TYPE_HEADER } from '../client/components/app-router-headers'\n\ntype ContentTypeOption =\n  | typeof RSC_CONTENT_TYPE_HEADER // For App Page RSC responses\n  | typeof HTML_CONTENT_TYPE_HEADER // For App Page, Pages HTML responses\n  | typeof JSON_CONTENT_TYPE_HEADER // For API routes, Next.js data requests\n  | typeof TEXT_PLAIN_CONTENT_TYPE_HEADER // For simplified errors\n\nexport type AppPageRenderResultMetadata = {\n  flightData?: Buffer\n  cacheControl?: CacheControl\n  staticBailoutInfo?: {\n    stack?: string\n    description?: string\n  }\n\n  /**\n   * The postponed state if the render had postponed and needs to be resumed.\n   */\n  postponed?: string\n\n  /**\n   * The headers to set on the response that were added by the render.\n   */\n  headers?: OutgoingHttpHeaders\n  statusCode?: number\n  fetchTags?: string\n  fetchMetrics?: FetchMetrics\n\n  segmentData?: Map<string, Buffer>\n\n  /**\n   * In development, the resume data cache is warmed up before the render. This\n   * is attached to the metadata so that it can be used during the render. When\n   * prerendering, the filled resume data cache is also attached to the metadata\n   * so that it can be used when prerendering matching fallback shells.\n   */\n  renderResumeDataCache?: RenderResumeDataCache\n}\n\nexport type PagesRenderResultMetadata = {\n  pageData?: any\n  cacheControl?: CacheControl\n  assetQueryString?: string\n  isNotFound?: boolean\n  isRedirect?: boolean\n}\n\nexport type StaticRenderResultMetadata = {}\n\nexport type RenderResultMetadata = AppPageRenderResultMetadata &\n  PagesRenderResultMetadata &\n  StaticRenderResultMetadata\n\nexport type RenderResultResponse =\n  | ReadableStream<Uint8Array>[]\n  | ReadableStream<Uint8Array>\n  | string\n  | Buffer\n  | null\n\nexport type RenderResultOptions<\n  Metadata extends RenderResultMetadata = RenderResultMetadata,\n> = {\n  contentType: ContentTypeOption | null\n  waitUntil?: Promise<unknown>\n  metadata: Metadata\n}\n\nexport default class RenderResult<\n  Metadata extends RenderResultMetadata = RenderResultMetadata,\n> {\n  /**\n   * The detected content type for the response. This is used to set the\n   * `Content-Type` header.\n   */\n  public readonly contentType: ContentTypeOption | null\n\n  /**\n   * The metadata for the response. This is used to set the revalidation times\n   * and other metadata.\n   */\n  public readonly metadata: Readonly<Metadata>\n\n  /**\n   * The response itself. This can be a string, a stream, or null. If it's a\n   * string, then it's a static response. If it's a stream, then it's a\n   * dynamic response. If it's null, then the response was not found or was\n   * already sent.\n   */\n  private response: RenderResultResponse\n\n  /**\n   * A render result that represents an empty response. This is used to\n   * represent a response that was not found or was already sent.\n   */\n  public static readonly EMPTY = new RenderResult<StaticRenderResultMetadata>(\n    null,\n    { metadata: {}, contentType: null }\n  )\n\n  /**\n   * Creates a new RenderResult instance from a static response.\n   *\n   * @param value the static response value\n   * @param contentType the content type of the response\n   * @returns a new RenderResult instance\n   */\n  public static fromStatic(\n    value: string | Buffer,\n    contentType: ContentTypeOption\n  ) {\n    return new RenderResult<StaticRenderResultMetadata>(value, {\n      metadata: {},\n      contentType,\n    })\n  }\n\n  private readonly waitUntil?: Promise<unknown>\n\n  constructor(\n    response: RenderResultResponse,\n    { contentType, waitUntil, metadata }: RenderResultOptions<Metadata>\n  ) {\n    this.response = response\n    this.contentType = contentType\n    this.metadata = metadata\n    this.waitUntil = waitUntil\n  }\n\n  public assignMetadata(metadata: Metadata) {\n    Object.assign(this.metadata, metadata)\n  }\n\n  /**\n   * Returns true if the response is null. It can be null if the response was\n   * not found or was already sent.\n   */\n  public get isNull(): boolean {\n    return this.response === null\n  }\n\n  /**\n   * Returns false if the response is a string. It can be a string if the page\n   * was prerendered. If it's not, then it was generated dynamically.\n   */\n  public get isDynamic(): boolean {\n    return typeof this.response !== 'string'\n  }\n\n  /**\n   * Returns the response if it is a string. If the page was dynamic, this will\n   * return a promise if the `stream` option is true, or it will throw an error.\n   *\n   * @param stream Whether or not to return a promise if the response is dynamic\n   * @returns The response as a string\n   */\n  public toUnchunkedString(stream?: false): string\n  public toUnchunkedString(stream: true): Promise<string>\n  public toUnchunkedString(stream = false): Promise<string> | string {\n    if (this.response === null) {\n      // If the response is null, return an empty string. This behavior is\n      // intentional as we're now providing the `RenderResult.EMPTY` value.\n      return ''\n    }\n\n    if (typeof this.response !== 'string') {\n      if (!stream) {\n        throw new InvariantError(\n          'dynamic responses cannot be unchunked. This is a bug in Next.js'\n        )\n      }\n\n      return streamToString(this.readable)\n    }\n\n    return this.response\n  }\n\n  /**\n   * Returns a readable stream of the response.\n   */\n  private get readable(): ReadableStream<Uint8Array> {\n    if (this.response === null) {\n      // If the response is null, return an empty stream. This behavior is\n      // intentional as we're now providing the `RenderResult.EMPTY` value.\n      return new ReadableStream<Uint8Array>({\n        start(controller) {\n          controller.close()\n        },\n      })\n    }\n\n    if (typeof this.response === 'string') {\n      return streamFromString(this.response)\n    }\n\n    if (Buffer.isBuffer(this.response)) {\n      return streamFromBuffer(this.response)\n    }\n\n    // If the response is an array of streams, then chain them together.\n    if (Array.isArray(this.response)) {\n      return chainStreams(...this.response)\n    }\n\n    return this.response\n  }\n\n  /**\n   * Coerces the response to an array of streams. This will convert the response\n   * to an array of streams if it is not already one.\n   *\n   * @returns An array of streams\n   */\n  private coerce(): ReadableStream<Uint8Array>[] {\n    if (this.response === null) {\n      // If the response is null, return an empty stream. This behavior is\n      // intentional as we're now providing the `RenderResult.EMPTY` value.\n      return []\n    }\n\n    if (typeof this.response === 'string') {\n      return [streamFromString(this.response)]\n    } else if (Array.isArray(this.response)) {\n      return this.response\n    } else if (Buffer.isBuffer(this.response)) {\n      return [streamFromBuffer(this.response)]\n    } else {\n      return [this.response]\n    }\n  }\n\n  /**\n   * Unshifts a new stream to the response. This will convert the response to an\n   * array of streams if it is not already one and will add the new stream to\n   * the start of the array. When this response is piped, all of the streams\n   * will be piped one after the other.\n   *\n   * @param readable The new stream to unshift\n   */\n  public unshift(readable: ReadableStream<Uint8Array>): void {\n    // Coerce the response to an array of streams.\n    this.response = this.coerce()\n\n    // Add the new stream to the start of the array.\n    this.response.unshift(readable)\n  }\n\n  /**\n   * Chains a new stream to the response. This will convert the response to an\n   * array of streams if it is not already one and will add the new stream to\n   * the end. When this response is piped, all of the streams will be piped\n   * one after the other.\n   *\n   * @param readable The new stream to chain\n   */\n  public push(readable: ReadableStream<Uint8Array>): void {\n    // Coerce the response to an array of streams.\n    this.response = this.coerce()\n\n    // Add the new stream to the end of the array.\n    this.response.push(readable)\n  }\n\n  /**\n   * Pipes the response to a writable stream. This will close/cancel the\n   * writable stream if an error is encountered. If this doesn't throw, then\n   * the writable stream will be closed or aborted.\n   *\n   * @param writable Writable stream to pipe the response to\n   */\n  public async pipeTo(writable: WritableStream<Uint8Array>): Promise<void> {\n    try {\n      await this.readable.pipeTo(writable, {\n        // We want to close the writable stream ourselves so that we can wait\n        // for the waitUntil promise to resolve before closing it. If an error\n        // is encountered, we'll abort the writable stream if we swallowed the\n        // error.\n        preventClose: true,\n      })\n\n      // If there is a waitUntil promise, wait for it to resolve before\n      // closing the writable stream.\n      if (this.waitUntil) await this.waitUntil\n\n      // Close the writable stream.\n      await writable.close()\n    } catch (err) {\n      // If this is an abort error, we should abort the writable stream (as we\n      // took ownership of it when we started piping). We don't need to re-throw\n      // because we handled the error.\n      if (isAbortError(err)) {\n        // Abort the writable stream if an error is encountered.\n        await writable.abort(err)\n\n        return\n      }\n\n      // We're not aborting the writer here as when this method throws it's not\n      // clear as to how so the caller should assume it's their responsibility\n      // to clean up the writer.\n      throw err\n    }\n  }\n\n  /**\n   * Pipes the response to a node response. This will close/cancel the node\n   * response if an error is encountered.\n   *\n   * @param res\n   */\n  public async pipeToNodeResponse(res: ServerResponse) {\n    await pipeToNodeResponse(this.readable, res, this.waitUntil)\n  }\n}\n","export const enum RouteKind {\n  /**\n   * `PAGES` represents all the React pages that are under `pages/`.\n   */\n  PAGES = 'PAGES',\n  /**\n   * `PAGES_API` represents all the API routes under `pages/api/`.\n   */\n  PAGES_API = 'PAGES_API',\n  /**\n   * `APP_PAGE` represents all the React pages that are under `app/` with the\n   * filename of `page.{j,t}s{,x}`.\n   */\n  APP_PAGE = 'APP_PAGE',\n  /**\n   * `APP_ROUTE` represents all the API routes and metadata routes that are under `app/` with the\n   * filename of `route.{j,t}s{,x}`.\n   */\n  APP_ROUTE = 'APP_ROUTE',\n\n  /**\n   * `IMAGE` represents all the images that are generated by `next/image`.\n   */\n  IMAGE = 'IMAGE',\n}\n","import {\n  CachedRouteKind,\n  IncrementalCacheKind,\n  type CachedAppPageValue,\n  type CachedPageValue,\n  type IncrementalResponseCacheEntry,\n  type ResponseCacheEntry,\n} from './types'\n\nimport RenderResult from '../render-result'\nimport { RouteKind } from '../route-kind'\nimport { HTML_CONTENT_TYPE_HEADER } from '../../lib/constants'\n\nexport async function fromResponseCacheEntry(\n  cacheEntry: ResponseCacheEntry\n): Promise<IncrementalResponseCacheEntry> {\n  return {\n    ...cacheEntry,\n    value:\n      cacheEntry.value?.kind === CachedRouteKind.PAGES\n        ? {\n            kind: CachedRouteKind.PAGES,\n            html: await cacheEntry.value.html.toUnchunkedString(true),\n            pageData: cacheEntry.value.pageData,\n            headers: cacheEntry.value.headers,\n            status: cacheEntry.value.status,\n          }\n        : cacheEntry.value?.kind === CachedRouteKind.APP_PAGE\n          ? {\n              kind: CachedRouteKind.APP_PAGE,\n              html: await cacheEntry.value.html.toUnchunkedString(true),\n              postponed: cacheEntry.value.postponed,\n              rscData: cacheEntry.value.rscData,\n              headers: cacheEntry.value.headers,\n              status: cacheEntry.value.status,\n              segmentData: cacheEntry.value.segmentData,\n            }\n          : cacheEntry.value,\n  }\n}\n\nexport async function toResponseCacheEntry(\n  response: IncrementalResponseCacheEntry | null\n): Promise<ResponseCacheEntry | null> {\n  if (!response) return null\n\n  return {\n    isMiss: response.isMiss,\n    isStale: response.isStale,\n    cacheControl: response.cacheControl,\n    value:\n      response.value?.kind === CachedRouteKind.PAGES\n        ? ({\n            kind: CachedRouteKind.PAGES,\n            html: RenderResult.fromStatic(\n              response.value.html,\n              HTML_CONTENT_TYPE_HEADER\n            ),\n            pageData: response.value.pageData,\n            headers: response.value.headers,\n            status: response.value.status,\n          } satisfies CachedPageValue)\n        : response.value?.kind === CachedRouteKind.APP_PAGE\n          ? ({\n              kind: CachedRouteKind.APP_PAGE,\n              html: RenderResult.fromStatic(\n                response.value.html,\n                HTML_CONTENT_TYPE_HEADER\n              ),\n              rscData: response.value.rscData,\n              headers: response.value.headers,\n              status: response.value.status,\n              postponed: response.value.postponed,\n              segmentData: response.value.segmentData,\n            } satisfies CachedAppPageValue)\n          : response.value,\n  }\n}\n\nexport function routeKindToIncrementalCacheKind(\n  routeKind: RouteKind\n): Exclude<IncrementalCacheKind, IncrementalCacheKind.FETCH> {\n  switch (routeKind) {\n    case RouteKind.PAGES:\n      return IncrementalCacheKind.PAGES\n    case RouteKind.APP_PAGE:\n      return IncrementalCacheKind.APP_PAGE\n    case RouteKind.IMAGE:\n      return IncrementalCacheKind.IMAGE\n    case RouteKind.APP_ROUTE:\n      return IncrementalCacheKind.APP_ROUTE\n    case RouteKind.PAGES_API:\n      // Pages Router API routes are not cached in the incremental cache.\n      throw new Error(`Unexpected route kind ${routeKind}`)\n    default:\n      return routeKind satisfies never\n  }\n}\n","import type {\n  ResponseCacheEntry,\n  ResponseGenerator,\n  ResponseCacheBase,\n  IncrementalResponseCacheEntry,\n  IncrementalResponseCache,\n} from './types'\n\nimport { Batcher } from '../../lib/batcher'\nimport { scheduleOnNextTick } from '../../lib/scheduler'\nimport {\n  fromResponseCacheEntry,\n  routeKindToIncrementalCacheKind,\n  toResponseCacheEntry,\n} from './utils'\nimport type { RouteKind } from '../route-kind'\n\nexport * from './types'\n\nexport default class ResponseCache implements ResponseCacheBase {\n  private readonly getBatcher = Batcher.create<\n    { key: string; isOnDemandRevalidate: boolean },\n    IncrementalResponseCacheEntry | null,\n    string\n  >({\n    // Ensure on-demand revalidate doesn't block normal requests, it should be\n    // safe to run an on-demand revalidate for the same key as a normal request.\n    cacheKeyFn: ({ key, isOnDemandRevalidate }) =>\n      `${key}-${isOnDemandRevalidate ? '1' : '0'}`,\n    // We wait to do any async work until after we've added our promise to\n    // `pendingResponses` to ensure that any any other calls will reuse the\n    // same promise until we've fully finished our work.\n    schedulerFn: scheduleOnNextTick,\n  })\n\n  private readonly revalidateBatcher = Batcher.create<\n    string,\n    IncrementalResponseCacheEntry | null\n  >({\n    // We wait to do any async work until after we've added our promise to\n    // `pendingResponses` to ensure that any any other calls will reuse the\n    // same promise until we've fully finished our work.\n    schedulerFn: scheduleOnNextTick,\n  })\n\n  private previousCacheItem?: {\n    key: string\n    entry: IncrementalResponseCacheEntry | null\n    expiresAt: number\n  }\n\n  // we don't use minimal_mode name here as this.minimal_mode is\n  // statically replace for server runtimes but we need it to\n  // be dynamic here\n  private minimal_mode?: boolean\n\n  constructor(minimal_mode: boolean) {\n    this.minimal_mode = minimal_mode\n  }\n\n  /**\n   * Gets the response cache entry for the given key.\n   *\n   * @param key - The key to get the response cache entry for.\n   * @param responseGenerator - The response generator to use to generate the response cache entry.\n   * @param context - The context for the get request.\n   * @returns The response cache entry.\n   */\n  public async get(\n    key: string | null,\n    responseGenerator: ResponseGenerator,\n    context: {\n      routeKind: RouteKind\n      isOnDemandRevalidate?: boolean\n      isPrefetch?: boolean\n      incrementalCache: IncrementalResponseCache\n      isRoutePPREnabled?: boolean\n      isFallback?: boolean\n      waitUntil?: (prom: Promise<any>) => void\n    }\n  ): Promise<ResponseCacheEntry | null> {\n    // If there is no key for the cache, we can't possibly look this up in the\n    // cache so just return the result of the response generator.\n    if (!key) {\n      return responseGenerator({\n        hasResolved: false,\n        previousCacheEntry: null,\n      })\n    }\n\n    // Check minimal mode cache before doing any other work\n    if (\n      this.minimal_mode &&\n      this.previousCacheItem?.key === key &&\n      this.previousCacheItem.expiresAt > Date.now()\n    ) {\n      return toResponseCacheEntry(this.previousCacheItem.entry)\n    }\n\n    const {\n      incrementalCache,\n      isOnDemandRevalidate = false,\n      isFallback = false,\n      isRoutePPREnabled = false,\n      isPrefetch = false,\n      waitUntil,\n      routeKind,\n    } = context\n\n    const response = await this.getBatcher.batch(\n      { key, isOnDemandRevalidate },\n      ({ resolve }) => {\n        const promise = this.handleGet(\n          key,\n          responseGenerator,\n          {\n            incrementalCache,\n            isOnDemandRevalidate,\n            isFallback,\n            isRoutePPREnabled,\n            isPrefetch,\n            routeKind,\n          },\n          resolve\n        )\n\n        // We need to ensure background revalidates are passed to waitUntil.\n        if (waitUntil) waitUntil(promise)\n\n        return promise\n      }\n    )\n\n    return toResponseCacheEntry(response)\n  }\n\n  /**\n   * Handles the get request for the response cache.\n   *\n   * @param key - The key to get the response cache entry for.\n   * @param responseGenerator - The response generator to use to generate the response cache entry.\n   * @param context - The context for the get request.\n   * @param resolve - The resolve function to use to resolve the response cache entry.\n   * @returns The response cache entry.\n   */\n  private async handleGet(\n    key: string,\n    responseGenerator: ResponseGenerator,\n    context: {\n      incrementalCache: IncrementalResponseCache\n      isOnDemandRevalidate: boolean\n      isFallback: boolean\n      isRoutePPREnabled: boolean\n      isPrefetch: boolean\n      routeKind: RouteKind\n    },\n    resolve: (value: IncrementalResponseCacheEntry | null) => void\n  ): Promise<IncrementalResponseCacheEntry | null> {\n    let previousIncrementalCacheEntry: IncrementalResponseCacheEntry | null =\n      null\n    let resolved = false\n\n    try {\n      // Get the previous cache entry if not in minimal mode\n      previousIncrementalCacheEntry = !this.minimal_mode\n        ? await context.incrementalCache.get(key, {\n            kind: routeKindToIncrementalCacheKind(context.routeKind),\n            isRoutePPREnabled: context.isRoutePPREnabled,\n            isFallback: context.isFallback,\n          })\n        : null\n\n      if (previousIncrementalCacheEntry && !context.isOnDemandRevalidate) {\n        resolve(previousIncrementalCacheEntry)\n        resolved = true\n\n        if (!previousIncrementalCacheEntry.isStale || context.isPrefetch) {\n          // The cached value is still valid, so we don't need to update it yet.\n          return previousIncrementalCacheEntry\n        }\n      }\n\n      // Revalidate the cache entry\n      const incrementalResponseCacheEntry = await this.revalidate(\n        key,\n        context.incrementalCache,\n        context.isRoutePPREnabled,\n        context.isFallback,\n        responseGenerator,\n        previousIncrementalCacheEntry,\n        previousIncrementalCacheEntry !== null && !context.isOnDemandRevalidate\n      )\n\n      // Handle null response\n      if (!incrementalResponseCacheEntry) {\n        // Unset the previous cache item if it was set so we don't use it again.\n        if (this.minimal_mode) this.previousCacheItem = undefined\n        return null\n      }\n\n      // Resolve for on-demand revalidation or if not already resolved\n      if (context.isOnDemandRevalidate && !resolved) {\n        return incrementalResponseCacheEntry\n      }\n\n      return incrementalResponseCacheEntry\n    } catch (err) {\n      // If we've already resolved the cache entry, we can't reject as we\n      // already resolved the cache entry so log the error here.\n      if (resolved) {\n        console.error(err)\n        return null\n      }\n\n      throw err\n    }\n  }\n\n  /**\n   * Revalidates the cache entry for the given key.\n   *\n   * @param key - The key to revalidate the cache entry for.\n   * @param incrementalCache - The incremental cache to use to revalidate the cache entry.\n   * @param isRoutePPREnabled - Whether the route is PPR enabled.\n   * @param isFallback - Whether the route is a fallback.\n   * @param responseGenerator - The response generator to use to generate the response cache entry.\n   * @param previousIncrementalCacheEntry - The previous cache entry to use to revalidate the cache entry.\n   * @param hasResolved - Whether the response has been resolved.\n   * @returns The revalidated cache entry.\n   */\n  public async revalidate(\n    key: string,\n    incrementalCache: IncrementalResponseCache,\n    isRoutePPREnabled: boolean,\n    isFallback: boolean,\n    responseGenerator: ResponseGenerator,\n    previousIncrementalCacheEntry: IncrementalResponseCacheEntry | null,\n    hasResolved: boolean,\n    waitUntil?: (prom: Promise<any>) => void\n  ) {\n    return this.revalidateBatcher.batch(key, () => {\n      const promise = this.handleRevalidate(\n        key,\n        incrementalCache,\n        isRoutePPREnabled,\n        isFallback,\n        responseGenerator,\n        previousIncrementalCacheEntry,\n        hasResolved\n      )\n\n      // We need to ensure background revalidates are passed to waitUntil.\n      if (waitUntil) waitUntil(promise)\n\n      return promise\n    })\n  }\n\n  private async handleRevalidate(\n    key: string,\n    incrementalCache: IncrementalResponseCache,\n    isRoutePPREnabled: boolean,\n    isFallback: boolean,\n    responseGenerator: ResponseGenerator,\n    previousIncrementalCacheEntry: IncrementalResponseCacheEntry | null,\n    hasResolved: boolean\n  ) {\n    try {\n      // Generate the response cache entry using the response generator.\n      const responseCacheEntry = await responseGenerator({\n        hasResolved,\n        previousCacheEntry: previousIncrementalCacheEntry,\n        isRevalidating: true,\n      })\n      if (!responseCacheEntry) {\n        return null\n      }\n\n      // Convert the response cache entry to an incremental response cache entry.\n      const incrementalResponseCacheEntry = await fromResponseCacheEntry({\n        ...responseCacheEntry,\n        isMiss: !previousIncrementalCacheEntry,\n      })\n\n      // We want to persist the result only if it has a cache control value\n      // defined.\n      if (incrementalResponseCacheEntry.cacheControl) {\n        if (this.minimal_mode) {\n          this.previousCacheItem = {\n            key,\n            entry: incrementalResponseCacheEntry,\n            expiresAt: Date.now() + 1000,\n          }\n        } else {\n          await incrementalCache.set(key, incrementalResponseCacheEntry.value, {\n            cacheControl: incrementalResponseCacheEntry.cacheControl,\n            isRoutePPREnabled,\n            isFallback,\n          })\n        }\n      }\n\n      return incrementalResponseCacheEntry\n    } catch (err) {\n      // When a path is erroring we automatically re-set the existing cache\n      // with new revalidate and expire times to prevent non-stop retrying.\n      if (previousIncrementalCacheEntry?.cacheControl) {\n        const revalidate = Math.min(\n          Math.max(\n            previousIncrementalCacheEntry.cacheControl.revalidate || 3,\n            3\n          ),\n          30\n        )\n        const expire =\n          previousIncrementalCacheEntry.cacheControl.expire === undefined\n            ? undefined\n            : Math.max(\n                revalidate + 3,\n                previousIncrementalCacheEntry.cacheControl.expire\n              )\n\n        await incrementalCache.set(key, previousIncrementalCacheEntry.value, {\n          cacheControl: { revalidate: revalidate, expire: expire },\n          isRoutePPREnabled,\n          isFallback,\n        })\n      }\n\n      // We haven't resolved yet, so let's throw to indicate an error.\n      throw err\n    }\n  }\n}\n","import type {\n  WorkAsyncStorage,\n  WorkStore,\n} from '../app-render/work-async-storage.external'\n\nimport { AppRenderSpan, NextNodeServerSpan } from './trace/constants'\nimport { getTracer, SpanKind } from './trace/tracer'\nimport {\n  CACHE_ONE_YEAR,\n  INFINITE_CACHE,\n  NEXT_CACHE_TAG_MAX_ITEMS,\n  NEXT_CACHE_TAG_MAX_LENGTH,\n} from '../../lib/constants'\nimport { markCurrentScopeAsDynamic } from '../app-render/dynamic-rendering'\nimport { makeHangingPromise } from '../dynamic-rendering-utils'\nimport type { FetchMetric } from '../base-http'\nimport { createDedupeFetch } from './dedupe-fetch'\nimport {\n  getCacheSignal,\n  type RevalidateStore,\n  type WorkUnitAsyncStorage,\n} from '../app-render/work-unit-async-storage.external'\nimport {\n  CachedRouteKind,\n  IncrementalCacheKind,\n  type CachedFetchData,\n  type ServerComponentsHmrCache,\n  type SetIncrementalFetchCacheContext,\n} from '../response-cache'\nimport { cloneResponse } from './clone-response'\nimport type { IncrementalCache } from './incremental-cache'\nimport { RenderStage } from '../app-render/staged-rendering'\n\nconst isEdgeRuntime = process.env.NEXT_RUNTIME === 'edge'\n\ntype Fetcher = typeof fetch\n\ntype PatchedFetcher = Fetcher & {\n  readonly __nextPatched: true\n  readonly __nextGetStaticStore: () => WorkAsyncStorage\n  readonly _nextOriginalFetch: Fetcher\n}\n\nexport const NEXT_PATCH_SYMBOL = Symbol.for('next-patch')\n\nfunction isFetchPatched() {\n  return (globalThis as Record<symbol, unknown>)[NEXT_PATCH_SYMBOL] === true\n}\n\nexport function validateRevalidate(\n  revalidateVal: unknown,\n  route: string\n): undefined | number {\n  try {\n    let normalizedRevalidate: number | undefined = undefined\n\n    if (revalidateVal === false) {\n      normalizedRevalidate = INFINITE_CACHE\n    } else if (\n      typeof revalidateVal === 'number' &&\n      !isNaN(revalidateVal) &&\n      revalidateVal > -1\n    ) {\n      normalizedRevalidate = revalidateVal\n    } else if (typeof revalidateVal !== 'undefined') {\n      throw new Error(\n        `Invalid revalidate value \"${revalidateVal}\" on \"${route}\", must be a non-negative number or false`\n      )\n    }\n    return normalizedRevalidate\n  } catch (err: any) {\n    // handle client component error from attempting to check revalidate value\n    if (err instanceof Error && err.message.includes('Invalid revalidate')) {\n      throw err\n    }\n    return undefined\n  }\n}\n\nexport function validateTags(tags: any[], description: string) {\n  const validTags: string[] = []\n  const invalidTags: Array<{\n    tag: any\n    reason: string\n  }> = []\n\n  for (let i = 0; i < tags.length; i++) {\n    const tag = tags[i]\n\n    if (typeof tag !== 'string') {\n      invalidTags.push({ tag, reason: 'invalid type, must be a string' })\n    } else if (tag.length > NEXT_CACHE_TAG_MAX_LENGTH) {\n      invalidTags.push({\n        tag,\n        reason: `exceeded max length of ${NEXT_CACHE_TAG_MAX_LENGTH}`,\n      })\n    } else {\n      validTags.push(tag)\n    }\n\n    if (validTags.length > NEXT_CACHE_TAG_MAX_ITEMS) {\n      console.warn(\n        `Warning: exceeded max tag count for ${description}, dropped tags:`,\n        tags.slice(i).join(', ')\n      )\n      break\n    }\n  }\n\n  if (invalidTags.length > 0) {\n    console.warn(`Warning: invalid tags passed to ${description}: `)\n\n    for (const { tag, reason } of invalidTags) {\n      console.log(`tag: \"${tag}\" ${reason}`)\n    }\n  }\n  return validTags\n}\n\nfunction trackFetchMetric(\n  workStore: WorkStore,\n  ctx: Omit<FetchMetric, 'end' | 'idx'>\n) {\n  if (!workStore.shouldTrackFetchMetrics) {\n    return\n  }\n\n  workStore.fetchMetrics ??= []\n\n  workStore.fetchMetrics.push({\n    ...ctx,\n    end: performance.timeOrigin + performance.now(),\n    idx: workStore.nextFetchId || 0,\n  })\n}\n\nasync function createCachedPrerenderResponse(\n  res: Response,\n  cacheKey: string,\n  incrementalCacheContext: SetIncrementalFetchCacheContext | undefined,\n  incrementalCache: IncrementalCache,\n  revalidate: number,\n  handleUnlock: () => Promise<void> | void\n): Promise<Response> {\n  // We are prerendering at build time or revalidate time with cacheComponents so we\n  // need to buffer the response so we can guarantee it can be read in a\n  // microtask.\n  const bodyBuffer = await res.arrayBuffer()\n\n  const fetchedData = {\n    headers: Object.fromEntries(res.headers.entries()),\n    body: Buffer.from(bodyBuffer).toString('base64'),\n    status: res.status,\n    url: res.url,\n  }\n\n  // We can skip setting the serverComponentsHmrCache because we aren't in dev\n  // mode.\n\n  if (incrementalCacheContext) {\n    await incrementalCache.set(\n      cacheKey,\n      { kind: CachedRouteKind.FETCH, data: fetchedData, revalidate },\n      incrementalCacheContext\n    )\n  }\n\n  await handleUnlock()\n\n  // We return a new Response to the caller.\n  return new Response(bodyBuffer, {\n    headers: res.headers,\n    status: res.status,\n    statusText: res.statusText,\n  })\n}\n\nasync function createCachedDynamicResponse(\n  workStore: WorkStore,\n  res: Response,\n  cacheKey: string,\n  incrementalCacheContext: SetIncrementalFetchCacheContext | undefined,\n  incrementalCache: IncrementalCache,\n  serverComponentsHmrCache: ServerComponentsHmrCache | undefined,\n  revalidate: number,\n  input: RequestInfo | URL,\n  handleUnlock: () => Promise<void> | void\n): Promise<Response> {\n  // We're cloning the response using this utility because there exists a bug in\n  // the undici library around response cloning. See the following pull request\n  // for more details: https://github.com/vercel/next.js/pull/73274\n  const [cloned1, cloned2] = cloneResponse(res)\n\n  // We are dynamically rendering including dev mode. We want to return the\n  // response to the caller as soon as possible because it might stream over a\n  // very long time.\n  const cacheSetPromise = cloned1\n    .arrayBuffer()\n    .then(async (arrayBuffer) => {\n      const bodyBuffer = Buffer.from(arrayBuffer)\n\n      const fetchedData = {\n        headers: Object.fromEntries(cloned1.headers.entries()),\n        body: bodyBuffer.toString('base64'),\n        status: cloned1.status,\n        url: cloned1.url,\n      }\n\n      serverComponentsHmrCache?.set(cacheKey, fetchedData)\n\n      if (incrementalCacheContext) {\n        await incrementalCache.set(\n          cacheKey,\n          { kind: CachedRouteKind.FETCH, data: fetchedData, revalidate },\n          incrementalCacheContext\n        )\n      }\n    })\n    .catch((error) => console.warn(`Failed to set fetch cache`, input, error))\n    .finally(handleUnlock)\n\n  const pendingRevalidateKey = `cache-set-${cacheKey}`\n  workStore.pendingRevalidates ??= {}\n\n  if (pendingRevalidateKey in workStore.pendingRevalidates) {\n    // there is already a pending revalidate entry that we need to await to\n    // avoid race conditions\n    await workStore.pendingRevalidates[pendingRevalidateKey]\n  }\n\n  workStore.pendingRevalidates[pendingRevalidateKey] = cacheSetPromise.finally(\n    () => {\n      // If the pending revalidate is not present in the store, then we have\n      // nothing to delete.\n      if (!workStore.pendingRevalidates?.[pendingRevalidateKey]) {\n        return\n      }\n\n      delete workStore.pendingRevalidates[pendingRevalidateKey]\n    }\n  )\n\n  return cloned2\n}\n\ninterface PatchableModule {\n  workAsyncStorage: WorkAsyncStorage\n  workUnitAsyncStorage: WorkUnitAsyncStorage\n}\n\nexport function createPatchedFetcher(\n  originFetch: Fetcher,\n  { workAsyncStorage, workUnitAsyncStorage }: PatchableModule\n): PatchedFetcher {\n  // Create the patched fetch function.\n  const patched = async function fetch(\n    input: RequestInfo | URL,\n    init: RequestInit | undefined\n  ): Promise<Response> {\n    let url: URL | undefined\n    try {\n      url = new URL(input instanceof Request ? input.url : input)\n      url.username = ''\n      url.password = ''\n    } catch {\n      // Error caused by malformed URL should be handled by native fetch\n      url = undefined\n    }\n    const fetchUrl = url?.href ?? ''\n    const method = init?.method?.toUpperCase() || 'GET'\n\n    // Do create a new span trace for internal fetches in the\n    // non-verbose mode.\n    const isInternal = (init?.next as any)?.internal === true\n    const hideSpan = process.env.NEXT_OTEL_FETCH_DISABLED === '1'\n    // We don't track fetch metrics for internal fetches\n    // so it's not critical that we have a start time, as it won't be recorded.\n    // This is to workaround a flaky issue where performance APIs might\n    // not be available and will require follow-up investigation.\n    const fetchStart: number | undefined = isInternal\n      ? undefined\n      : performance.timeOrigin + performance.now()\n\n    const workStore = workAsyncStorage.getStore()\n    const workUnitStore = workUnitAsyncStorage.getStore()\n\n    let cacheSignal = workUnitStore ? getCacheSignal(workUnitStore) : null\n    if (cacheSignal) {\n      cacheSignal.beginRead()\n    }\n\n    const result = getTracer().trace(\n      isInternal ? NextNodeServerSpan.internalFetch : AppRenderSpan.fetch,\n      {\n        hideSpan,\n        kind: SpanKind.CLIENT,\n        spanName: ['fetch', method, fetchUrl].filter(Boolean).join(' '),\n        attributes: {\n          'http.url': fetchUrl,\n          'http.method': method,\n          'net.peer.name': url?.hostname,\n          'net.peer.port': url?.port || undefined,\n        },\n      },\n      async () => {\n        // If this is an internal fetch, we should not do any special treatment.\n        if (isInternal) {\n          return originFetch(input, init)\n        }\n\n        // If the workStore is not available, we can't do any\n        // special treatment of fetch, therefore fallback to the original\n        // fetch implementation.\n        if (!workStore) {\n          return originFetch(input, init)\n        }\n\n        // We should also fallback to the original fetch implementation if we\n        // are in draft mode, it does not constitute a static generation.\n        if (workStore.isDraftMode) {\n          return originFetch(input, init)\n        }\n\n        const isRequestInput =\n          input &&\n          typeof input === 'object' &&\n          typeof (input as Request).method === 'string'\n\n        const getRequestMeta = (field: string) => {\n          // If request input is present but init is not, retrieve from input first.\n          const value = (init as any)?.[field]\n          return value || (isRequestInput ? (input as any)[field] : null)\n        }\n\n        let finalRevalidate: number | undefined = undefined\n        const getNextField = (field: 'revalidate' | 'tags') => {\n          return typeof init?.next?.[field] !== 'undefined'\n            ? init?.next?.[field]\n            : isRequestInput\n              ? (input as any).next?.[field]\n              : undefined\n        }\n        // RequestInit doesn't keep extra fields e.g. next so it's\n        // only available if init is used separate\n        const originalFetchRevalidate = getNextField('revalidate')\n        let currentFetchRevalidate = originalFetchRevalidate\n        const tags: string[] = validateTags(\n          getNextField('tags') || [],\n          `fetch ${input.toString()}`\n        )\n\n        let revalidateStore: RevalidateStore | undefined\n\n        if (workUnitStore) {\n          switch (workUnitStore.type) {\n            case 'prerender':\n            case 'prerender-runtime':\n            // TODO: Stop accumulating tags in client prerender. (fallthrough)\n            case 'prerender-client':\n            case 'prerender-ppr':\n            case 'prerender-legacy':\n            case 'cache':\n            case 'private-cache':\n              revalidateStore = workUnitStore\n              break\n            case 'request':\n            case 'unstable-cache':\n              break\n            default:\n              workUnitStore satisfies never\n          }\n        }\n\n        if (revalidateStore) {\n          if (Array.isArray(tags)) {\n            // Collect tags onto parent caches or parent prerenders.\n            const collectedTags =\n              revalidateStore.tags ?? (revalidateStore.tags = [])\n            for (const tag of tags) {\n              if (!collectedTags.includes(tag)) {\n                collectedTags.push(tag)\n              }\n            }\n          }\n        }\n\n        const implicitTags = workUnitStore?.implicitTags\n\n        let pageFetchCacheMode = workStore.fetchCache\n\n        if (workUnitStore) {\n          switch (workUnitStore.type) {\n            case 'unstable-cache':\n              // Inside unstable-cache we treat it the same as force-no-store on\n              // the page.\n              pageFetchCacheMode = 'force-no-store'\n              break\n            case 'prerender':\n            case 'prerender-client':\n            case 'prerender-runtime':\n            case 'prerender-ppr':\n            case 'prerender-legacy':\n            case 'request':\n            case 'cache':\n            case 'private-cache':\n              break\n            default:\n              workUnitStore satisfies never\n          }\n        }\n\n        const isUsingNoStore = !!workStore.isUnstableNoStore\n\n        let currentFetchCacheConfig = getRequestMeta('cache')\n        let cacheReason = ''\n        let cacheWarning: string | undefined\n\n        if (\n          typeof currentFetchCacheConfig === 'string' &&\n          typeof currentFetchRevalidate !== 'undefined'\n        ) {\n          // If the revalidate value conflicts with the cache value, we should warn the user and unset the conflicting values.\n          const isConflictingRevalidate =\n            // revalidate: 0 and cache: force-cache\n            (currentFetchCacheConfig === 'force-cache' &&\n              currentFetchRevalidate === 0) ||\n            // revalidate: >0 or revalidate: false and cache: no-store\n            (currentFetchCacheConfig === 'no-store' &&\n              (currentFetchRevalidate > 0 || currentFetchRevalidate === false))\n\n          if (isConflictingRevalidate) {\n            cacheWarning = `Specified \"cache: ${currentFetchCacheConfig}\" and \"revalidate: ${currentFetchRevalidate}\", only one should be specified.`\n            currentFetchCacheConfig = undefined\n            currentFetchRevalidate = undefined\n          }\n        }\n\n        const hasExplicitFetchCacheOptOut =\n          // fetch config itself signals not to cache\n          currentFetchCacheConfig === 'no-cache' ||\n          currentFetchCacheConfig === 'no-store' ||\n          // the fetch isn't explicitly caching and the segment level cache config signals not to cache\n          // note: `pageFetchCacheMode` is also set by being in an unstable_cache context.\n          pageFetchCacheMode === 'force-no-store' ||\n          pageFetchCacheMode === 'only-no-store'\n\n        // If no explicit fetch cache mode is set, but dynamic = `force-dynamic` is set,\n        // we shouldn't consider caching the fetch. This is because the `dynamic` cache\n        // is considered a \"top-level\" cache mode, whereas something like `fetchCache` is more\n        // fine-grained. Top-level modes are responsible for setting reasonable defaults for the\n        // other configurations.\n        const noFetchConfigAndForceDynamic =\n          !pageFetchCacheMode &&\n          !currentFetchCacheConfig &&\n          !currentFetchRevalidate &&\n          workStore.forceDynamic\n\n        if (\n          // force-cache was specified without a revalidate value. We set the revalidate value to false\n          // which will signal the cache to not revalidate\n          currentFetchCacheConfig === 'force-cache' &&\n          typeof currentFetchRevalidate === 'undefined'\n        ) {\n          currentFetchRevalidate = false\n        } else if (\n          hasExplicitFetchCacheOptOut ||\n          noFetchConfigAndForceDynamic\n        ) {\n          currentFetchRevalidate = 0\n        }\n\n        if (\n          currentFetchCacheConfig === 'no-cache' ||\n          currentFetchCacheConfig === 'no-store'\n        ) {\n          cacheReason = `cache: ${currentFetchCacheConfig}`\n        }\n\n        finalRevalidate = validateRevalidate(\n          currentFetchRevalidate,\n          workStore.route\n        )\n\n        const _headers = getRequestMeta('headers')\n        const initHeaders: Headers =\n          typeof _headers?.get === 'function'\n            ? _headers\n            : new Headers(_headers || {})\n\n        const hasUnCacheableHeader =\n          initHeaders.get('authorization') || initHeaders.get('cookie')\n\n        const isUnCacheableMethod = !['get', 'head'].includes(\n          getRequestMeta('method')?.toLowerCase() || 'get'\n        )\n\n        /**\n         * We automatically disable fetch caching under the following conditions:\n         * - Fetch cache configs are not set. Specifically:\n         *    - A page fetch cache mode is not set (export const fetchCache=...)\n         *    - A fetch cache mode is not set in the fetch call (fetch(url, { cache: ... }))\n         *      or the fetch cache mode is set to 'default'\n         *    - A fetch revalidate value is not set in the fetch call (fetch(url, { revalidate: ... }))\n         * - OR the fetch comes after a configuration that triggered dynamic rendering (e.g., reading cookies())\n         *   and the fetch was considered uncacheable (e.g., POST method or has authorization headers)\n         */\n        const hasNoExplicitCacheConfig =\n          // eslint-disable-next-line eqeqeq\n          pageFetchCacheMode == undefined &&\n          // eslint-disable-next-line eqeqeq\n          (currentFetchCacheConfig == undefined ||\n            // when considering whether to opt into the default \"no-cache\" fetch semantics,\n            // a \"default\" cache config should be treated the same as no cache config\n            currentFetchCacheConfig === 'default') &&\n          // eslint-disable-next-line eqeqeq\n          currentFetchRevalidate == undefined\n\n        let autoNoCache = Boolean(\n          (hasUnCacheableHeader || isUnCacheableMethod) &&\n            revalidateStore?.revalidate === 0\n        )\n\n        let isImplicitBuildTimeCache = false\n\n        if (!autoNoCache && hasNoExplicitCacheConfig) {\n          // We don't enable automatic no-cache behavior during build-time\n          // prerendering so that we can still leverage the fetch cache between\n          // export workers.\n          if (workStore.isBuildTimePrerendering) {\n            isImplicitBuildTimeCache = true\n          } else {\n            autoNoCache = true\n          }\n        }\n\n        // If we have no cache config, and we're in Dynamic I/O prerendering,\n        // it'll be a dynamic call. We don't have to issue that dynamic call.\n        if (hasNoExplicitCacheConfig && workUnitStore !== undefined) {\n          switch (workUnitStore.type) {\n            case 'prerender':\n            case 'prerender-runtime':\n            // While we don't want to do caching in the client scope we know the\n            // fetch will be dynamic for cacheComponents so we may as well avoid the\n            // call here. (fallthrough)\n            case 'prerender-client':\n              if (cacheSignal) {\n                cacheSignal.endRead()\n                cacheSignal = null\n              }\n\n              return makeHangingPromise<Response>(\n                workUnitStore.renderSignal,\n                workStore.route,\n                'fetch()'\n              )\n            case 'request':\n              if (\n                process.env.NODE_ENV === 'development' &&\n                workUnitStore.stagedRendering\n              ) {\n                if (cacheSignal) {\n                  cacheSignal.endRead()\n                  cacheSignal = null\n                }\n                await workUnitStore.stagedRendering.waitForStage(\n                  RenderStage.Dynamic\n                )\n              }\n              break\n            case 'prerender-ppr':\n            case 'prerender-legacy':\n            case 'cache':\n            case 'private-cache':\n            case 'unstable-cache':\n              break\n            default:\n              workUnitStore satisfies never\n          }\n        }\n\n        switch (pageFetchCacheMode) {\n          case 'force-no-store': {\n            cacheReason = 'fetchCache = force-no-store'\n            break\n          }\n          case 'only-no-store': {\n            if (\n              currentFetchCacheConfig === 'force-cache' ||\n              (typeof finalRevalidate !== 'undefined' && finalRevalidate > 0)\n            ) {\n              throw new Error(\n                `cache: 'force-cache' used on fetch for ${fetchUrl} with 'export const fetchCache = 'only-no-store'`\n              )\n            }\n            cacheReason = 'fetchCache = only-no-store'\n            break\n          }\n          case 'only-cache': {\n            if (currentFetchCacheConfig === 'no-store') {\n              throw new Error(\n                `cache: 'no-store' used on fetch for ${fetchUrl} with 'export const fetchCache = 'only-cache'`\n              )\n            }\n            break\n          }\n          case 'force-cache': {\n            if (\n              typeof currentFetchRevalidate === 'undefined' ||\n              currentFetchRevalidate === 0\n            ) {\n              cacheReason = 'fetchCache = force-cache'\n              finalRevalidate = INFINITE_CACHE\n            }\n            break\n          }\n          case 'default-cache':\n          case 'default-no-store':\n          case 'auto':\n          case undefined:\n            // sometimes we won't match the above cases. the reason we don't move\n            // everything to this switch is the use of autoNoCache which is not a fetchCacheMode\n            // I suspect this could be unified with fetchCacheMode however in which case we could\n            // simplify the switch case and ensure we have an exhaustive switch handling all modes\n            break\n          default:\n            pageFetchCacheMode satisfies never\n        }\n\n        if (typeof finalRevalidate === 'undefined') {\n          if (pageFetchCacheMode === 'default-cache' && !isUsingNoStore) {\n            finalRevalidate = INFINITE_CACHE\n            cacheReason = 'fetchCache = default-cache'\n          } else if (pageFetchCacheMode === 'default-no-store') {\n            finalRevalidate = 0\n            cacheReason = 'fetchCache = default-no-store'\n          } else if (isUsingNoStore) {\n            finalRevalidate = 0\n            cacheReason = 'noStore call'\n          } else if (autoNoCache) {\n            finalRevalidate = 0\n            cacheReason = 'auto no cache'\n          } else {\n            // TODO: should we consider this case an invariant?\n            cacheReason = 'auto cache'\n            finalRevalidate = revalidateStore\n              ? revalidateStore.revalidate\n              : INFINITE_CACHE\n          }\n        } else if (!cacheReason) {\n          cacheReason = `revalidate: ${finalRevalidate}`\n        }\n\n        if (\n          // when force static is configured we don't bail from\n          // `revalidate: 0` values\n          !(workStore.forceStatic && finalRevalidate === 0) &&\n          // we don't consider autoNoCache to switch to dynamic for ISR\n          !autoNoCache &&\n          // If the revalidate value isn't currently set or the value is less\n          // than the current revalidate value, we should update the revalidate\n          // value.\n          revalidateStore &&\n          finalRevalidate < revalidateStore.revalidate\n        ) {\n          // If we were setting the revalidate value to 0, we should try to\n          // postpone instead first.\n          if (finalRevalidate === 0) {\n            if (workUnitStore) {\n              switch (workUnitStore.type) {\n                case 'prerender':\n                case 'prerender-client':\n                case 'prerender-runtime':\n                  if (cacheSignal) {\n                    cacheSignal.endRead()\n                    cacheSignal = null\n                  }\n                  return makeHangingPromise<Response>(\n                    workUnitStore.renderSignal,\n                    workStore.route,\n                    'fetch()'\n                  )\n                case 'request':\n                  if (\n                    process.env.NODE_ENV === 'development' &&\n                    workUnitStore.stagedRendering\n                  ) {\n                    if (cacheSignal) {\n                      cacheSignal.endRead()\n                      cacheSignal = null\n                    }\n                    await workUnitStore.stagedRendering.waitForStage(\n                      RenderStage.Dynamic\n                    )\n                  }\n                  break\n                case 'prerender-ppr':\n                case 'prerender-legacy':\n                case 'cache':\n                case 'private-cache':\n                case 'unstable-cache':\n                  break\n                default:\n                  workUnitStore satisfies never\n              }\n            }\n\n            markCurrentScopeAsDynamic(\n              workStore,\n              workUnitStore,\n              `revalidate: 0 fetch ${input} ${workStore.route}`\n            )\n          }\n\n          // We only want to set the revalidate store's revalidate time if it\n          // was explicitly set for the fetch call, i.e.\n          // originalFetchRevalidate.\n          if (revalidateStore && originalFetchRevalidate === finalRevalidate) {\n            revalidateStore.revalidate = finalRevalidate\n          }\n        }\n\n        const isCacheableRevalidate =\n          typeof finalRevalidate === 'number' && finalRevalidate > 0\n\n        let cacheKey: string | undefined\n        const { incrementalCache } = workStore\n        let isHmrRefresh = false\n        let serverComponentsHmrCache: ServerComponentsHmrCache | undefined\n\n        if (workUnitStore) {\n          switch (workUnitStore.type) {\n            case 'request':\n            case 'cache':\n            case 'private-cache':\n              isHmrRefresh = workUnitStore.isHmrRefresh ?? false\n              serverComponentsHmrCache = workUnitStore.serverComponentsHmrCache\n              break\n            case 'prerender':\n            case 'prerender-client':\n            case 'prerender-runtime':\n            case 'prerender-ppr':\n            case 'prerender-legacy':\n            case 'unstable-cache':\n              break\n            default:\n              workUnitStore satisfies never\n          }\n        }\n\n        if (\n          incrementalCache &&\n          (isCacheableRevalidate || serverComponentsHmrCache)\n        ) {\n          try {\n            cacheKey = await incrementalCache.generateCacheKey(\n              fetchUrl,\n              isRequestInput ? (input as RequestInit) : init\n            )\n          } catch (err) {\n            console.error(`Failed to generate cache key for`, input)\n          }\n        }\n\n        const fetchIdx = workStore.nextFetchId ?? 1\n        workStore.nextFetchId = fetchIdx + 1\n\n        let handleUnlock: () => Promise<void> | void = () => {}\n\n        const doOriginalFetch = async (\n          isStale?: boolean,\n          cacheReasonOverride?: string\n        ) => {\n          const requestInputFields = [\n            'cache',\n            'credentials',\n            'headers',\n            'integrity',\n            'keepalive',\n            'method',\n            'mode',\n            'redirect',\n            'referrer',\n            'referrerPolicy',\n            'window',\n            'duplex',\n\n            // don't pass through signal when revalidating\n            ...(isStale ? [] : ['signal']),\n          ]\n\n          if (isRequestInput) {\n            const reqInput: Request = input as any\n            const reqOptions: RequestInit = {\n              body: (reqInput as any)._ogBody || reqInput.body,\n            }\n\n            for (const field of requestInputFields) {\n              // @ts-expect-error custom fields\n              reqOptions[field] = reqInput[field]\n            }\n            input = new Request(reqInput.url, reqOptions)\n          } else if (init) {\n            const { _ogBody, body, signal, ...otherInput } =\n              init as RequestInit & { _ogBody?: any }\n            init = {\n              ...otherInput,\n              body: _ogBody || body,\n              signal: isStale ? undefined : signal,\n            }\n          }\n\n          // add metadata to init without editing the original\n          const clonedInit = {\n            ...init,\n            next: { ...init?.next, fetchType: 'origin', fetchIdx },\n          }\n\n          return originFetch(input, clonedInit)\n            .then(async (res) => {\n              if (!isStale && fetchStart) {\n                trackFetchMetric(workStore, {\n                  start: fetchStart,\n                  url: fetchUrl,\n                  cacheReason: cacheReasonOverride || cacheReason,\n                  cacheStatus:\n                    finalRevalidate === 0 || cacheReasonOverride\n                      ? 'skip'\n                      : 'miss',\n                  cacheWarning,\n                  status: res.status,\n                  method: clonedInit.method || 'GET',\n                })\n              }\n              if (\n                res.status === 200 &&\n                incrementalCache &&\n                cacheKey &&\n                (isCacheableRevalidate || serverComponentsHmrCache)\n              ) {\n                const normalizedRevalidate =\n                  finalRevalidate >= INFINITE_CACHE\n                    ? CACHE_ONE_YEAR\n                    : finalRevalidate\n\n                const incrementalCacheConfig:\n                  | SetIncrementalFetchCacheContext\n                  | undefined = isCacheableRevalidate\n                  ? {\n                      fetchCache: true,\n                      fetchUrl,\n                      fetchIdx,\n                      tags,\n                      isImplicitBuildTimeCache,\n                    }\n                  : undefined\n\n                switch (workUnitStore?.type) {\n                  case 'prerender':\n                  case 'prerender-client':\n                  case 'prerender-runtime':\n                    return createCachedPrerenderResponse(\n                      res,\n                      cacheKey,\n                      incrementalCacheConfig,\n                      incrementalCache,\n                      normalizedRevalidate,\n                      handleUnlock\n                    )\n                  case 'request':\n                    if (\n                      process.env.NODE_ENV === 'development' &&\n                      workUnitStore.stagedRendering &&\n                      workUnitStore.cacheSignal\n                    ) {\n                      // We're filling caches for a staged render,\n                      // so we need to wait for the response to finish instead of streaming.\n                      return createCachedPrerenderResponse(\n                        res,\n                        cacheKey,\n                        incrementalCacheConfig,\n                        incrementalCache,\n                        normalizedRevalidate,\n                        handleUnlock\n                      )\n                    }\n                  // fallthrough\n                  case 'prerender-ppr':\n                  case 'prerender-legacy':\n                  case 'cache':\n                  case 'private-cache':\n                  case 'unstable-cache':\n                  case undefined:\n                    return createCachedDynamicResponse(\n                      workStore,\n                      res,\n                      cacheKey,\n                      incrementalCacheConfig,\n                      incrementalCache,\n                      serverComponentsHmrCache,\n                      normalizedRevalidate,\n                      input,\n                      handleUnlock\n                    )\n                  default:\n                    workUnitStore satisfies never\n                }\n              }\n\n              // we had response that we determined shouldn't be cached so we return it\n              // and don't cache it. This also needs to unlock the cache lock we acquired.\n              await handleUnlock()\n\n              return res\n            })\n            .catch((error) => {\n              handleUnlock()\n              throw error\n            })\n        }\n\n        let cacheReasonOverride\n        let isForegroundRevalidate = false\n        let isHmrRefreshCache = false\n\n        if (cacheKey && incrementalCache) {\n          let cachedFetchData: CachedFetchData | undefined\n\n          if (isHmrRefresh && serverComponentsHmrCache) {\n            cachedFetchData = serverComponentsHmrCache.get(cacheKey)\n            isHmrRefreshCache = true\n          }\n\n          if (isCacheableRevalidate && !cachedFetchData) {\n            handleUnlock = await incrementalCache.lock(cacheKey)\n            const entry = workStore.isOnDemandRevalidate\n              ? null\n              : await incrementalCache.get(cacheKey, {\n                  kind: IncrementalCacheKind.FETCH,\n                  revalidate: finalRevalidate,\n                  fetchUrl,\n                  fetchIdx,\n                  tags,\n                  softTags: implicitTags?.tags,\n                })\n\n            if (hasNoExplicitCacheConfig && workUnitStore) {\n              switch (workUnitStore.type) {\n                case 'prerender':\n                case 'prerender-client':\n                case 'prerender-runtime':\n                  // We sometimes use the cache to dedupe fetches that do not\n                  // specify a cache configuration. In these cases we want to\n                  // make sure we still exclude them from prerenders if\n                  // cacheComponents is on so we introduce an artificial task boundary\n                  // here.\n                  await getTimeoutBoundary()\n                  break\n                case 'request':\n                  if (\n                    process.env.NODE_ENV === 'development' &&\n                    workUnitStore.stagedRendering\n                  ) {\n                    await workUnitStore.stagedRendering.waitForStage(\n                      RenderStage.Dynamic\n                    )\n                  }\n                  break\n                case 'prerender-ppr':\n                case 'prerender-legacy':\n                case 'cache':\n                case 'private-cache':\n                case 'unstable-cache':\n                  break\n                default:\n                  workUnitStore satisfies never\n              }\n            }\n\n            if (entry) {\n              await handleUnlock()\n            } else {\n              // in dev, incremental cache response will be null in case the browser adds `cache-control: no-cache` in the request headers\n              // TODO: it seems like we also hit this after revalidates in dev?\n              cacheReasonOverride = 'cache-control: no-cache (hard refresh)'\n            }\n\n            if (entry?.value && entry.value.kind === CachedRouteKind.FETCH) {\n              // when stale and is revalidating we wait for fresh data\n              // so the revalidated entry has the updated data\n              if (workStore.isStaticGeneration && entry.isStale) {\n                isForegroundRevalidate = true\n              } else {\n                if (entry.isStale) {\n                  workStore.pendingRevalidates ??= {}\n                  if (!workStore.pendingRevalidates[cacheKey]) {\n                    const pendingRevalidate = doOriginalFetch(true)\n                      .then(async (response) => ({\n                        body: await response.arrayBuffer(),\n                        headers: response.headers,\n                        status: response.status,\n                        statusText: response.statusText,\n                      }))\n                      .finally(() => {\n                        workStore.pendingRevalidates ??= {}\n                        delete workStore.pendingRevalidates[cacheKey || '']\n                      })\n\n                    // Attach the empty catch here so we don't get a \"unhandled\n                    // promise rejection\" warning.\n                    pendingRevalidate.catch(console.error)\n\n                    workStore.pendingRevalidates[cacheKey] = pendingRevalidate\n                  }\n                }\n\n                cachedFetchData = entry.value.data\n              }\n            }\n          }\n\n          if (cachedFetchData) {\n            if (fetchStart) {\n              trackFetchMetric(workStore, {\n                start: fetchStart,\n                url: fetchUrl,\n                cacheReason,\n                cacheStatus: isHmrRefreshCache ? 'hmr' : 'hit',\n                cacheWarning,\n                status: cachedFetchData.status || 200,\n                method: init?.method || 'GET',\n              })\n            }\n\n            const response = new Response(\n              Buffer.from(cachedFetchData.body, 'base64'),\n              {\n                headers: cachedFetchData.headers,\n                status: cachedFetchData.status,\n              }\n            )\n\n            Object.defineProperty(response, 'url', {\n              value: cachedFetchData.url,\n            })\n\n            return response\n          }\n        }\n\n        if (\n          (workStore.isStaticGeneration ||\n            (process.env.NODE_ENV === 'development' &&\n              process.env.__NEXT_CACHE_COMPONENTS &&\n              workUnitStore &&\n              // eslint-disable-next-line no-restricted-syntax\n              workUnitStore.type === 'request' &&\n              workUnitStore.stagedRendering)) &&\n          init &&\n          typeof init === 'object'\n        ) {\n          const { cache } = init\n\n          // Delete `cache` property as Cloudflare Workers will throw an error\n          if (isEdgeRuntime) delete init.cache\n\n          if (cache === 'no-store') {\n            // If enabled, we should bail out of static generation.\n            if (workUnitStore) {\n              switch (workUnitStore.type) {\n                case 'prerender':\n                case 'prerender-client':\n                case 'prerender-runtime':\n                  if (cacheSignal) {\n                    cacheSignal.endRead()\n                    cacheSignal = null\n                  }\n                  return makeHangingPromise<Response>(\n                    workUnitStore.renderSignal,\n                    workStore.route,\n                    'fetch()'\n                  )\n                case 'request':\n                  if (\n                    process.env.NODE_ENV === 'development' &&\n                    workUnitStore.stagedRendering\n                  ) {\n                    if (cacheSignal) {\n                      cacheSignal.endRead()\n                      cacheSignal = null\n                    }\n                    await workUnitStore.stagedRendering.waitForStage(\n                      RenderStage.Dynamic\n                    )\n                  }\n                  break\n                case 'prerender-ppr':\n                case 'prerender-legacy':\n                case 'cache':\n                case 'private-cache':\n                case 'unstable-cache':\n                  break\n                default:\n                  workUnitStore satisfies never\n              }\n            }\n            markCurrentScopeAsDynamic(\n              workStore,\n              workUnitStore,\n              `no-store fetch ${input} ${workStore.route}`\n            )\n          }\n\n          const hasNextConfig = 'next' in init\n          const { next = {} } = init\n          if (\n            typeof next.revalidate === 'number' &&\n            revalidateStore &&\n            next.revalidate < revalidateStore.revalidate\n          ) {\n            if (next.revalidate === 0) {\n              // If enabled, we should bail out of static generation.\n              if (workUnitStore) {\n                switch (workUnitStore.type) {\n                  case 'prerender':\n                  case 'prerender-client':\n                  case 'prerender-runtime':\n                    return makeHangingPromise<Response>(\n                      workUnitStore.renderSignal,\n                      workStore.route,\n                      'fetch()'\n                    )\n                  case 'request':\n                    if (\n                      process.env.NODE_ENV === 'development' &&\n                      workUnitStore.stagedRendering\n                    ) {\n                      await workUnitStore.stagedRendering.waitForStage(\n                        RenderStage.Dynamic\n                      )\n                    }\n                    break\n                  case 'cache':\n                  case 'private-cache':\n                  case 'unstable-cache':\n                  case 'prerender-legacy':\n                  case 'prerender-ppr':\n                    break\n                  default:\n                    workUnitStore satisfies never\n                }\n              }\n              markCurrentScopeAsDynamic(\n                workStore,\n                workUnitStore,\n                `revalidate: 0 fetch ${input} ${workStore.route}`\n              )\n            }\n\n            if (!workStore.forceStatic || next.revalidate !== 0) {\n              revalidateStore.revalidate = next.revalidate\n            }\n          }\n          if (hasNextConfig) delete init.next\n        }\n\n        // if we are revalidating the whole page via time or on-demand and\n        // the fetch cache entry is stale we should still de-dupe the\n        // origin hit if it's a cache-able entry\n        if (cacheKey && isForegroundRevalidate) {\n          const pendingRevalidateKey = cacheKey\n          workStore.pendingRevalidates ??= {}\n          let pendingRevalidate =\n            workStore.pendingRevalidates[pendingRevalidateKey]\n\n          if (pendingRevalidate) {\n            const revalidatedResult: {\n              body: ArrayBuffer\n              headers: Headers\n              status: number\n              statusText: string\n            } = await pendingRevalidate\n            return new Response(revalidatedResult.body, {\n              headers: revalidatedResult.headers,\n              status: revalidatedResult.status,\n              statusText: revalidatedResult.statusText,\n            })\n          }\n\n          // We used to just resolve the Response and clone it however for\n          // static generation with cacheComponents we need the response to be able to\n          // be resolved in a microtask and cloning the response will never have\n          // a body that can resolve in a microtask in node (as observed through\n          // experimentation) So instead we await the body and then when it is\n          // available we construct manually cloned Response objects with the\n          // body as an ArrayBuffer. This will be resolvable in a microtask\n          // making it compatible with cacheComponents.\n          const pendingResponse = doOriginalFetch(true, cacheReasonOverride)\n            // We're cloning the response using this utility because there\n            // exists a bug in the undici library around response cloning.\n            // See the following pull request for more details:\n            // https://github.com/vercel/next.js/pull/73274\n            .then(cloneResponse)\n\n          pendingRevalidate = pendingResponse\n            .then(async (responses) => {\n              const response = responses[0]\n              return {\n                body: await response.arrayBuffer(),\n                headers: response.headers,\n                status: response.status,\n                statusText: response.statusText,\n              }\n            })\n            .finally(() => {\n              // If the pending revalidate is not present in the store, then\n              // we have nothing to delete.\n              if (!workStore.pendingRevalidates?.[pendingRevalidateKey]) {\n                return\n              }\n\n              delete workStore.pendingRevalidates[pendingRevalidateKey]\n            })\n\n          // Attach the empty catch here so we don't get a \"unhandled promise\n          // rejection\" warning\n          pendingRevalidate.catch(() => {})\n\n          workStore.pendingRevalidates[pendingRevalidateKey] = pendingRevalidate\n\n          return pendingResponse.then((responses) => responses[1])\n        } else {\n          return doOriginalFetch(false, cacheReasonOverride)\n        }\n      }\n    )\n\n    if (cacheSignal) {\n      try {\n        return await result\n      } finally {\n        if (cacheSignal) {\n          cacheSignal.endRead()\n        }\n      }\n    }\n    return result\n  }\n\n  // Attach the necessary properties to the patched fetch function.\n  // We don't use this to determine if the fetch function has been patched,\n  // but for external consumers to determine if the fetch function has been\n  // patched.\n  patched.__nextPatched = true as const\n  patched.__nextGetStaticStore = () => workAsyncStorage\n  patched._nextOriginalFetch = originFetch\n  ;(globalThis as Record<symbol, unknown>)[NEXT_PATCH_SYMBOL] = true\n\n  // Assign the function name also as a name property, so that it's preserved\n  // even when mangling is enabled.\n  Object.defineProperty(patched, 'name', { value: 'fetch', writable: false })\n\n  return patched\n}\n\n// we patch fetch to collect cache information used for\n// determining if a page is static or not\nexport function patchFetch(options: PatchableModule) {\n  // If we've already patched fetch, we should not patch it again.\n  if (isFetchPatched()) return\n\n  // Grab the original fetch function. We'll attach this so we can use it in\n  // the patched fetch function.\n  const original = createDedupeFetch(globalThis.fetch)\n\n  // Set the global fetch to the patched fetch.\n  globalThis.fetch = createPatchedFetcher(original, options)\n}\n\nlet currentTimeoutBoundary: null | Promise<void> = null\nfunction getTimeoutBoundary() {\n  if (!currentTimeoutBoundary) {\n    currentTimeoutBoundary = new Promise((r) => {\n      setTimeout(() => {\n        currentTimeoutBoundary = null\n        r()\n      }, 0)\n    })\n  }\n  return currentTimeoutBoundary\n}\n","import type { IncrementalCache } from '../../lib/incremental-cache'\n\nimport { CACHE_ONE_YEAR } from '../../../lib/constants'\nimport { validateRevalidate, validateTags } from '../../lib/patch-fetch'\nimport {\n  workAsyncStorage,\n  type WorkStore,\n} from '../../app-render/work-async-storage.external'\nimport {\n  getCacheSignal,\n  getDraftModeProviderForCacheScope,\n  workUnitAsyncStorage,\n} from '../../app-render/work-unit-async-storage.external'\nimport {\n  CachedRouteKind,\n  IncrementalCacheKind,\n  type CachedFetchData,\n} from '../../response-cache'\nimport type {\n  UnstableCacheStore,\n  WorkUnitStore,\n} from '../../app-render/work-unit-async-storage.external'\n\ntype Callback = (...args: any[]) => Promise<any>\n\nlet noStoreFetchIdx = 0\n\nasync function cacheNewResult<T>(\n  result: T,\n  incrementalCache: IncrementalCache,\n  cacheKey: string,\n  tags: string[],\n  revalidate: number | false | undefined,\n  fetchIdx: number,\n  fetchUrl: string\n): Promise<unknown> {\n  await incrementalCache.set(\n    cacheKey,\n    {\n      kind: CachedRouteKind.FETCH,\n      data: {\n        headers: {},\n        // TODO: handle non-JSON values?\n        body: JSON.stringify(result),\n        status: 200,\n        url: '',\n      } satisfies CachedFetchData,\n      revalidate: typeof revalidate !== 'number' ? CACHE_ONE_YEAR : revalidate,\n    },\n    { fetchCache: true, tags, fetchIdx, fetchUrl }\n  )\n  return\n}\n\n/**\n * This function allows you to cache the results of expensive operations, like database queries, and reuse them across multiple requests.\n *\n * Read more: [Next.js Docs: `unstable_cache`](https://nextjs.org/docs/app/api-reference/functions/unstable_cache)\n */\nexport function unstable_cache<T extends Callback>(\n  cb: T,\n  keyParts?: string[],\n  options: {\n    /**\n     * The revalidation interval in seconds.\n     */\n    revalidate?: number | false\n    tags?: string[]\n  } = {}\n): T {\n  if (options.revalidate === 0) {\n    throw new Error(\n      `Invariant revalidate: 0 can not be passed to unstable_cache(), must be \"false\" or \"> 0\" ${cb.toString()}`\n    )\n  }\n\n  // Validate the tags provided are valid\n  const tags = options.tags\n    ? validateTags(options.tags, `unstable_cache ${cb.toString()}`)\n    : []\n\n  // Validate the revalidate options\n  validateRevalidate(\n    options.revalidate,\n    `unstable_cache ${cb.name || cb.toString()}`\n  )\n\n  // Stash the fixed part of the key at construction time. The invocation key will combine\n  // the fixed key with the arguments when actually called\n  // @TODO if cb.toString() is long we should hash it\n  // @TODO come up with a collision-free way to combine keyParts\n  // @TODO consider validating the keyParts are all strings. TS can't provide runtime guarantees\n  // and the error produced by accidentally using something that cannot be safely coerced is likely\n  // hard to debug\n  const fixedKey = `${cb.toString()}-${\n    Array.isArray(keyParts) && keyParts.join(',')\n  }`\n\n  const cachedCb = async (...args: any[]) => {\n    const workStore = workAsyncStorage.getStore()\n    const workUnitStore = workUnitAsyncStorage.getStore()\n\n    // We must be able to find the incremental cache otherwise we throw\n    const maybeIncrementalCache:\n      | import('../../lib/incremental-cache').IncrementalCache\n      | undefined =\n      workStore?.incrementalCache || (globalThis as any).__incrementalCache\n\n    if (!maybeIncrementalCache) {\n      throw new Error(\n        `Invariant: incrementalCache missing in unstable_cache ${cb.toString()}`\n      )\n    }\n    const incrementalCache = maybeIncrementalCache\n\n    const cacheSignal = workUnitStore ? getCacheSignal(workUnitStore) : null\n    if (cacheSignal) {\n      cacheSignal.beginRead()\n    }\n    try {\n      // If there's no request store, we aren't in a request (or we're not in\n      // app router) and if there's no static generation store, we aren't in app\n      // router. Default to an empty pathname and search params when there's no\n      // request store or static generation store available.\n      const fetchUrlPrefix =\n        workStore && workUnitStore\n          ? getFetchUrlPrefix(workStore, workUnitStore)\n          : ''\n\n      // Construct the complete cache key for this function invocation\n      // @TODO stringify is likely not safe here. We will coerce undefined to null which will make\n      // the keyspace smaller than the execution space\n      const invocationKey = `${fixedKey}-${JSON.stringify(args)}`\n      const cacheKey = await incrementalCache.generateCacheKey(invocationKey)\n      // $urlWithPath,$sortedQueryStringKeys,$hashOfEveryThingElse\n      const fetchUrl = `unstable_cache ${fetchUrlPrefix} ${cb.name ? ` ${cb.name}` : cacheKey}`\n      const fetchIdx =\n        (workStore ? workStore.nextFetchId : noStoreFetchIdx) ?? 1\n\n      const implicitTags = workUnitStore?.implicitTags\n\n      const innerCacheStore: UnstableCacheStore = {\n        type: 'unstable-cache',\n        phase: 'render',\n        implicitTags,\n        draftMode:\n          workUnitStore &&\n          workStore &&\n          getDraftModeProviderForCacheScope(workStore, workUnitStore),\n      }\n\n      if (workStore) {\n        workStore.nextFetchId = fetchIdx + 1\n\n        // We are in an App Router context. We try to return the cached entry if it exists and is valid\n        // If the entry is fresh we return it. If the entry is stale we return it but revalidate the entry in\n        // the background. If the entry is missing or invalid we generate a new entry and return it.\n\n        let isNestedUnstableCache = false\n\n        if (workUnitStore) {\n          switch (workUnitStore.type) {\n            case 'cache':\n            case 'private-cache':\n            case 'prerender':\n            case 'prerender-runtime':\n            case 'prerender-ppr':\n            case 'prerender-legacy':\n              // We update the store's revalidate property if the option.revalidate is a higher precedence\n              // options.revalidate === undefined doesn't affect timing.\n              // options.revalidate === false doesn't shrink timing. it stays at the maximum.\n              if (typeof options.revalidate === 'number') {\n                if (workUnitStore.revalidate < options.revalidate) {\n                  // The store is already revalidating on a shorter time interval, leave it alone\n                } else {\n                  workUnitStore.revalidate = options.revalidate\n                }\n              }\n\n              // We need to accumulate the tags for this invocation within the store\n              const collectedTags = workUnitStore.tags\n              if (collectedTags === null) {\n                workUnitStore.tags = tags.slice()\n              } else {\n                for (const tag of tags) {\n                  // @TODO refactor tags to be a set to avoid this O(n) lookup\n                  if (!collectedTags.includes(tag)) {\n                    collectedTags.push(tag)\n                  }\n                }\n              }\n              break\n            case 'unstable-cache':\n              isNestedUnstableCache = true\n              break\n            case 'prerender-client':\n            case 'request':\n              break\n            default:\n              workUnitStore satisfies never\n          }\n        }\n\n        if (\n          // when we are nested inside of other unstable_cache's\n          // we should bypass cache similar to fetches\n          !isNestedUnstableCache &&\n          workStore.fetchCache !== 'force-no-store' &&\n          !workStore.isOnDemandRevalidate &&\n          !incrementalCache.isOnDemandRevalidate &&\n          !workStore.isDraftMode\n        ) {\n          // We attempt to get the current cache entry from the incremental cache.\n          const cacheEntry = await incrementalCache.get(cacheKey, {\n            kind: IncrementalCacheKind.FETCH,\n            revalidate: options.revalidate,\n            tags,\n            softTags: implicitTags?.tags,\n            fetchIdx,\n            fetchUrl,\n          })\n\n          if (cacheEntry && cacheEntry.value) {\n            // The entry exists and has a value\n            if (cacheEntry.value.kind !== CachedRouteKind.FETCH) {\n              // The entry is invalid and we need a special warning\n              // @TODO why do we warn this way? Should this just be an error? How are these errors surfaced\n              // so bugs can be reported\n              // @TODO the invocation key can have sensitive data in it. we should not log this entire object\n              console.error(\n                `Invariant invalid cacheEntry returned for ${invocationKey}`\n              )\n              // will fall through to generating a new cache entry below\n            } else {\n              // We have a valid cache entry so we will be returning it. We also check to see if we need\n              // to background revalidate it by checking if it is stale.\n              const cachedResponse =\n                cacheEntry.value.data.body !== undefined\n                  ? JSON.parse(cacheEntry.value.data.body)\n                  : undefined\n\n              if (cacheEntry.isStale) {\n                if (!workStore.pendingRevalidates) {\n                  workStore.pendingRevalidates = {}\n                }\n\n                // Check if there's already a pending revalidation to avoid duplicate work\n                if (!workStore.pendingRevalidates[invocationKey]) {\n                  // Create the revalidation promise\n                  const revalidationPromise = workUnitAsyncStorage\n                    .run(innerCacheStore, cb, ...args)\n                    .then(async (result) => {\n                      await cacheNewResult(\n                        result,\n                        incrementalCache,\n                        cacheKey,\n                        tags,\n                        options.revalidate,\n                        fetchIdx,\n                        fetchUrl\n                      )\n                      return result\n                    })\n                    .catch((err) => {\n                      // @TODO This error handling seems wrong. We swallow the error?\n                      console.error(\n                        `revalidating cache with key: ${invocationKey}`,\n                        err\n                      )\n                      // Return the stale value on error for foreground revalidation\n                      return cachedResponse\n                    })\n\n                  // Attach the empty catch here so we don't get a \"unhandled promise\n                  // rejection\" warning. (Behavior is matched with patch-fetch)\n                  if (workStore.isStaticGeneration) {\n                    revalidationPromise.catch(() => {})\n                  }\n\n                  workStore.pendingRevalidates[invocationKey] =\n                    revalidationPromise\n                }\n\n                // Check if we need to do foreground revalidation\n                if (workStore.isStaticGeneration) {\n                  // When the page is revalidating and the cache entry is stale,\n                  // we need to wait for fresh data (blocking revalidate)\n                  return workStore.pendingRevalidates[invocationKey]\n                }\n                // Otherwise, we're doing background revalidation - return stale immediately\n              }\n\n              // We had a valid cache entry so we return it here\n              return cachedResponse\n            }\n          }\n        }\n\n        // If we got this far then we had an invalid cache entry and need to generate a new one\n        const result = await workUnitAsyncStorage.run(\n          innerCacheStore,\n          cb,\n          ...args\n        )\n\n        if (!workStore.isDraftMode) {\n          if (!workStore.pendingRevalidates) {\n            workStore.pendingRevalidates = {}\n          }\n\n          // We need to push the cache result promise to pending\n          // revalidates otherwise it won't be awaited and is just\n          // dangling\n          workStore.pendingRevalidates[invocationKey] = cacheNewResult(\n            result,\n            incrementalCache,\n            cacheKey,\n            tags,\n            options.revalidate,\n            fetchIdx,\n            fetchUrl\n          )\n        }\n\n        return result\n      } else {\n        noStoreFetchIdx += 1\n        // We are in Pages Router or were called outside of a render. We don't have a store\n        // so we just call the callback directly when it needs to run.\n        // If the entry is fresh we return it. If the entry is stale we return it but revalidate the entry in\n        // the background. If the entry is missing or invalid we generate a new entry and return it.\n\n        if (!incrementalCache.isOnDemandRevalidate) {\n          // We aren't doing an on demand revalidation so we check use the cache if valid\n          const cacheEntry = await incrementalCache.get(cacheKey, {\n            kind: IncrementalCacheKind.FETCH,\n            revalidate: options.revalidate,\n            tags,\n            fetchIdx,\n            fetchUrl,\n            softTags: implicitTags?.tags,\n          })\n\n          if (cacheEntry && cacheEntry.value) {\n            // The entry exists and has a value\n            if (cacheEntry.value.kind !== CachedRouteKind.FETCH) {\n              // The entry is invalid and we need a special warning\n              // @TODO why do we warn this way? Should this just be an error? How are these errors surfaced\n              // so bugs can be reported\n              console.error(\n                `Invariant invalid cacheEntry returned for ${invocationKey}`\n              )\n              // will fall through to generating a new cache entry below\n            } else if (!cacheEntry.isStale) {\n              // We have a valid cache entry and it is fresh so we return it\n              return cacheEntry.value.data.body !== undefined\n                ? JSON.parse(cacheEntry.value.data.body)\n                : undefined\n            }\n          }\n        }\n\n        // If we got this far then we had an invalid cache entry and need to generate a new one\n        const result = await workUnitAsyncStorage.run(\n          innerCacheStore,\n          cb,\n          ...args\n        )\n\n        // we need to wait setting the new cache result here as\n        // we don't have pending revalidates on workStore to\n        // push to and we can't have a dangling promise\n        await cacheNewResult(\n          result,\n          incrementalCache,\n          cacheKey,\n          tags,\n          options.revalidate,\n          fetchIdx,\n          fetchUrl\n        )\n        return result\n      }\n    } finally {\n      if (cacheSignal) {\n        cacheSignal.endRead()\n      }\n    }\n  }\n  // TODO: once AsyncLocalStorage.run() returns the correct types this override will no longer be necessary\n  return cachedCb as unknown as T\n}\n\nfunction getFetchUrlPrefix(\n  workStore: WorkStore,\n  workUnitStore: WorkUnitStore\n): string {\n  switch (workUnitStore.type) {\n    case 'request':\n      const pathname = workUnitStore.url.pathname\n      const searchParams = new URLSearchParams(workUnitStore.url.search)\n\n      const sortedSearch = [...searchParams.keys()]\n        .sort((a, b) => a.localeCompare(b))\n        .map((key) => `${key}=${searchParams.get(key)}`)\n        .join('&')\n\n      return `${pathname}${sortedSearch.length ? '?' : ''}${sortedSearch}`\n    case 'prerender':\n    case 'prerender-client':\n    case 'prerender-runtime':\n    case 'prerender-ppr':\n    case 'prerender-legacy':\n    case 'cache':\n    case 'private-cache':\n    case 'unstable-cache':\n      return workStore.route\n    default:\n      return workUnitStore satisfies never\n  }\n}\n","class UrlNode {\n  placeholder: boolean = true\n  children: Map<string, UrlNode> = new Map()\n  slugName: string | null = null\n  restSlugName: string | null = null\n  optionalRestSlugName: string | null = null\n\n  insert(urlPath: string): void {\n    this._insert(urlPath.split('/').filter(Boolean), [], false)\n  }\n\n  smoosh(): string[] {\n    return this._smoosh()\n  }\n\n  private _smoosh(prefix: string = '/'): string[] {\n    const childrenPaths = [...this.children.keys()].sort()\n    if (this.slugName !== null) {\n      childrenPaths.splice(childrenPaths.indexOf('[]'), 1)\n    }\n    if (this.restSlugName !== null) {\n      childrenPaths.splice(childrenPaths.indexOf('[...]'), 1)\n    }\n    if (this.optionalRestSlugName !== null) {\n      childrenPaths.splice(childrenPaths.indexOf('[[...]]'), 1)\n    }\n\n    const routes = childrenPaths\n      .map((c) => this.children.get(c)!._smoosh(`${prefix}${c}/`))\n      .reduce((prev, curr) => [...prev, ...curr], [])\n\n    if (this.slugName !== null) {\n      routes.push(\n        ...this.children.get('[]')!._smoosh(`${prefix}[${this.slugName}]/`)\n      )\n    }\n\n    if (!this.placeholder) {\n      const r = prefix === '/' ? '/' : prefix.slice(0, -1)\n      if (this.optionalRestSlugName != null) {\n        throw new Error(\n          `You cannot define a route with the same specificity as a optional catch-all route (\"${r}\" and \"${r}[[...${this.optionalRestSlugName}]]\").`\n        )\n      }\n\n      routes.unshift(r)\n    }\n\n    if (this.restSlugName !== null) {\n      routes.push(\n        ...this.children\n          .get('[...]')!\n          ._smoosh(`${prefix}[...${this.restSlugName}]/`)\n      )\n    }\n\n    if (this.optionalRestSlugName !== null) {\n      routes.push(\n        ...this.children\n          .get('[[...]]')!\n          ._smoosh(`${prefix}[[...${this.optionalRestSlugName}]]/`)\n      )\n    }\n\n    return routes\n  }\n\n  private _insert(\n    urlPaths: string[],\n    slugNames: string[],\n    isCatchAll: boolean\n  ): void {\n    if (urlPaths.length === 0) {\n      this.placeholder = false\n      return\n    }\n\n    if (isCatchAll) {\n      throw new Error(`Catch-all must be the last part of the URL.`)\n    }\n\n    // The next segment in the urlPaths list\n    let nextSegment = urlPaths[0]\n\n    // Check if the segment matches `[something]`\n    if (nextSegment.startsWith('[') && nextSegment.endsWith(']')) {\n      // Strip `[` and `]`, leaving only `something`\n      let segmentName = nextSegment.slice(1, -1)\n\n      let isOptional = false\n      if (segmentName.startsWith('[') && segmentName.endsWith(']')) {\n        // Strip optional `[` and `]`, leaving only `something`\n        segmentName = segmentName.slice(1, -1)\n        isOptional = true\n      }\n\n      if (segmentName.startsWith('')) {\n        throw new Error(\n          `Detected a three-dot character ('') at ('${segmentName}'). Did you mean ('...')?`\n        )\n      }\n\n      if (segmentName.startsWith('...')) {\n        // Strip `...`, leaving only `something`\n        segmentName = segmentName.substring(3)\n        isCatchAll = true\n      }\n\n      if (segmentName.startsWith('[') || segmentName.endsWith(']')) {\n        throw new Error(\n          `Segment names may not start or end with extra brackets ('${segmentName}').`\n        )\n      }\n\n      if (segmentName.startsWith('.')) {\n        throw new Error(\n          `Segment names may not start with erroneous periods ('${segmentName}').`\n        )\n      }\n\n      function handleSlug(previousSlug: string | null, nextSlug: string) {\n        if (previousSlug !== null) {\n          // If the specific segment already has a slug but the slug is not `something`\n          // This prevents collisions like:\n          // pages/[post]/index.js\n          // pages/[id]/index.js\n          // Because currently multiple dynamic params on the same segment level are not supported\n          if (previousSlug !== nextSlug) {\n            // TODO: This error seems to be confusing for users, needs an error link, the description can be based on above comment.\n            throw new Error(\n              `You cannot use different slug names for the same dynamic path ('${previousSlug}' !== '${nextSlug}').`\n            )\n          }\n        }\n\n        slugNames.forEach((slug) => {\n          if (slug === nextSlug) {\n            throw new Error(\n              `You cannot have the same slug name \"${nextSlug}\" repeat within a single dynamic path`\n            )\n          }\n\n          if (slug.replace(/\\W/g, '') === nextSegment.replace(/\\W/g, '')) {\n            throw new Error(\n              `You cannot have the slug names \"${slug}\" and \"${nextSlug}\" differ only by non-word symbols within a single dynamic path`\n            )\n          }\n        })\n\n        slugNames.push(nextSlug)\n      }\n\n      if (isCatchAll) {\n        if (isOptional) {\n          if (this.restSlugName != null) {\n            throw new Error(\n              `You cannot use both an required and optional catch-all route at the same level (\"[...${this.restSlugName}]\" and \"${urlPaths[0]}\" ).`\n            )\n          }\n\n          handleSlug(this.optionalRestSlugName, segmentName)\n          // slugName is kept as it can only be one particular slugName\n          this.optionalRestSlugName = segmentName\n          // nextSegment is overwritten to [[...]] so that it can later be sorted specifically\n          nextSegment = '[[...]]'\n        } else {\n          if (this.optionalRestSlugName != null) {\n            throw new Error(\n              `You cannot use both an optional and required catch-all route at the same level (\"[[...${this.optionalRestSlugName}]]\" and \"${urlPaths[0]}\").`\n            )\n          }\n\n          handleSlug(this.restSlugName, segmentName)\n          // slugName is kept as it can only be one particular slugName\n          this.restSlugName = segmentName\n          // nextSegment is overwritten to [...] so that it can later be sorted specifically\n          nextSegment = '[...]'\n        }\n      } else {\n        if (isOptional) {\n          throw new Error(\n            `Optional route parameters are not yet supported (\"${urlPaths[0]}\").`\n          )\n        }\n        handleSlug(this.slugName, segmentName)\n        // slugName is kept as it can only be one particular slugName\n        this.slugName = segmentName\n        // nextSegment is overwritten to [] so that it can later be sorted specifically\n        nextSegment = '[]'\n      }\n    }\n\n    // If this UrlNode doesn't have the nextSegment yet we create a new child UrlNode\n    if (!this.children.has(nextSegment)) {\n      this.children.set(nextSegment, new UrlNode())\n    }\n\n    this.children\n      .get(nextSegment)!\n      ._insert(urlPaths.slice(1), slugNames, isCatchAll)\n  }\n}\n\n/**\n * @deprecated Use `sortSortableRoutes` or `sortPages` instead.\n */\nexport function getSortedRoutes(\n  normalizedPages: ReadonlyArray<string>\n): string[] {\n  // First the UrlNode is created, and every UrlNode can have only 1 dynamic segment\n  // Eg you can't have pages/[post]/abc.js and pages/[hello]/something-else.js\n  // Only 1 dynamic segment per nesting level\n\n  // So in the case that is test/integration/dynamic-routing it'll be this:\n  // pages/[post]/comments.js\n  // pages/blog/[post]/comment/[id].js\n  // Both are fine because `pages/[post]` and `pages/blog` are on the same level\n  // So in this case `UrlNode` created here has `this.slugName === 'post'`\n  // And since your PR passed through `slugName` as an array basically it'd including it in too many possibilities\n  // Instead what has to be passed through is the upwards path's dynamic names\n  const root = new UrlNode()\n\n  // Here the `root` gets injected multiple paths, and insert will break them up into sublevels\n  normalizedPages.forEach((pagePath) => root.insert(pagePath))\n  // Smoosh will then sort those sublevels up to the point where you get the correct route definition priority\n  return root.smoosh()\n}\n\n/**\n * @deprecated Use `sortSortableRouteObjects` or `sortPageObjects` instead.\n */\nexport function getSortedRouteObjects<T>(\n  objects: T[],\n  getter: (obj: T) => string\n): T[] {\n  // We're assuming here that all the pathnames are unique, that way we can\n  // sort the list and use the index as the key.\n  const indexes: Record<string, number> = {}\n  const pathnames: string[] = []\n  for (let i = 0; i < objects.length; i++) {\n    const pathname = getter(objects[i])\n    indexes[pathname] = i\n    pathnames[i] = pathname\n  }\n\n  // Sort the pathnames.\n  const sorted = getSortedRoutes(pathnames)\n\n  // Map the sorted pathnames back to the original objects using the new sorted\n  // index.\n  return sorted.map((pathname) => objects[indexes[pathname]])\n}\n","/**\n * For a given page path, this function ensures that there is a leading slash.\n * If there is not a leading slash, one is added, otherwise it is noop.\n */\nexport function ensureLeadingSlash(path: string) {\n  return path.startsWith('/') ? path : `/${path}`\n}\n","import type { FlightRouterState, Segment } from './app-router-types'\n\nexport function getSegmentValue(segment: Segment) {\n  return Array.isArray(segment) ? segment[1] : segment\n}\n\nexport function isGroupSegment(segment: string) {\n  // Use array[0] for performant purpose\n  return segment[0] === '(' && segment.endsWith(')')\n}\n\nexport function isParallelRouteSegment(segment: string) {\n  return segment.startsWith('@') && segment !== '@children'\n}\n\nexport function addSearchParamsIfPageSegment(\n  segment: Segment,\n  searchParams: Record<string, string | string[] | undefined>\n) {\n  const isPageSegment = segment.includes(PAGE_SEGMENT_KEY)\n\n  if (isPageSegment) {\n    const stringifiedQuery = JSON.stringify(searchParams)\n    return stringifiedQuery !== '{}'\n      ? PAGE_SEGMENT_KEY + '?' + stringifiedQuery\n      : PAGE_SEGMENT_KEY\n  }\n\n  return segment\n}\n\nexport function computeSelectedLayoutSegment(\n  segments: string[] | null,\n  parallelRouteKey: string\n): string | null {\n  if (!segments || segments.length === 0) {\n    return null\n  }\n\n  // For 'children', use first segment; for other parallel routes, use last segment\n  const rawSegment =\n    parallelRouteKey === 'children'\n      ? segments[0]\n      : segments[segments.length - 1]\n\n  // If the default slot is showing, return null since it's not technically \"selected\" (it's a fallback)\n  // Returning an internal value like `__DEFAULT__` would be confusing\n  return rawSegment === DEFAULT_SEGMENT_KEY ? null : rawSegment\n}\n\n/** Get the canonical parameters from the current level to the leaf node. */\nexport function getSelectedLayoutSegmentPath(\n  tree: FlightRouterState,\n  parallelRouteKey: string,\n  first = true,\n  segmentPath: string[] = []\n): string[] {\n  let node: FlightRouterState\n  if (first) {\n    // Use the provided parallel route key on the first parallel route\n    node = tree[1][parallelRouteKey]\n  } else {\n    // After first parallel route prefer children, if there's no children pick the first parallel route.\n    const parallelRoutes = tree[1]\n    node = parallelRoutes.children ?? Object.values(parallelRoutes)[0]\n  }\n\n  if (!node) return segmentPath\n  const segment = node[0]\n\n  let segmentValue = getSegmentValue(segment)\n\n  if (!segmentValue || segmentValue.startsWith(PAGE_SEGMENT_KEY)) {\n    return segmentPath\n  }\n\n  segmentPath.push(segmentValue)\n\n  return getSelectedLayoutSegmentPath(\n    node,\n    parallelRouteKey,\n    false,\n    segmentPath\n  )\n}\n\nexport const PAGE_SEGMENT_KEY = '__PAGE__'\nexport const DEFAULT_SEGMENT_KEY = '__DEFAULT__'\n","import { ensureLeadingSlash } from '../../page-path/ensure-leading-slash'\nimport { isGroupSegment } from '../../segment'\n\n/**\n * Normalizes an app route so it represents the actual request path. Essentially\n * performing the following transformations:\n *\n * - `/(dashboard)/user/[id]/page` to `/user/[id]`\n * - `/(dashboard)/account/page` to `/account`\n * - `/user/[id]/page` to `/user/[id]`\n * - `/account/page` to `/account`\n * - `/page` to `/`\n * - `/(dashboard)/user/[id]/route` to `/user/[id]`\n * - `/(dashboard)/account/route` to `/account`\n * - `/user/[id]/route` to `/user/[id]`\n * - `/account/route` to `/account`\n * - `/route` to `/`\n * - `/` to `/`\n *\n * @param route the app route to normalize\n * @returns the normalized pathname\n */\nexport function normalizeAppPath(route: string) {\n  return ensureLeadingSlash(\n    route.split('/').reduce((pathname, segment, index, segments) => {\n      // Empty segments are ignored.\n      if (!segment) {\n        return pathname\n      }\n\n      // Groups are ignored.\n      if (isGroupSegment(segment)) {\n        return pathname\n      }\n\n      // Parallel segments are ignored.\n      if (segment[0] === '@') {\n        return pathname\n      }\n\n      // The last segment (if it's a leaf) should be ignored.\n      if (\n        (segment === 'page' || segment === 'route') &&\n        index === segments.length - 1\n      ) {\n        return pathname\n      }\n\n      return `${pathname}/${segment}`\n    }, '')\n  )\n}\n\n/**\n * Strips the `.rsc` extension if it's in the pathname.\n * Since this function is used on full urls it checks `?` for searchParams handling.\n */\nexport function normalizeRscURL(url: string) {\n  return url.replace(\n    /\\.rsc($|\\?)/,\n    // $1 ensures `?` is preserved\n    '$1'\n  )\n}\n","import { normalizeAppPath } from './app-paths'\n\n// order matters here, the first match will be used\nexport const INTERCEPTION_ROUTE_MARKERS = [\n  '(..)(..)',\n  '(.)',\n  '(..)',\n  '(...)',\n] as const\n\nexport function isInterceptionRouteAppPath(path: string): boolean {\n  // TODO-APP: add more serious validation\n  return (\n    path\n      .split('/')\n      .find((segment) =>\n        INTERCEPTION_ROUTE_MARKERS.find((m) => segment.startsWith(m))\n      ) !== undefined\n  )\n}\n\ntype InterceptionRouteInformation = {\n  /**\n   * The intercepting route. This is the route that is being intercepted or the\n   * route that the user was coming from. This is matched by the Next-Url\n   * header.\n   */\n  interceptingRoute: string\n\n  /**\n   * The intercepted route. This is the route that is being intercepted or the\n   * route that the user is going to. This is matched by the request pathname.\n   */\n  interceptedRoute: string\n}\n\nexport function extractInterceptionRouteInformation(\n  path: string\n): InterceptionRouteInformation {\n  let interceptingRoute: string | undefined\n  let marker: (typeof INTERCEPTION_ROUTE_MARKERS)[number] | undefined\n  let interceptedRoute: string | undefined\n\n  for (const segment of path.split('/')) {\n    marker = INTERCEPTION_ROUTE_MARKERS.find((m) => segment.startsWith(m))\n    if (marker) {\n      ;[interceptingRoute, interceptedRoute] = path.split(marker, 2)\n      break\n    }\n  }\n\n  if (!interceptingRoute || !marker || !interceptedRoute) {\n    throw new Error(\n      `Invalid interception route: ${path}. Must be in the format /<intercepting route>/(..|...|..)(..)/<intercepted route>`\n    )\n  }\n\n  interceptingRoute = normalizeAppPath(interceptingRoute) // normalize the path, e.g. /(blog)/feed -> /feed\n\n  switch (marker) {\n    case '(.)':\n      // (.) indicates that we should match with sibling routes, so we just need to append the intercepted route to the intercepting route\n      if (interceptingRoute === '/') {\n        interceptedRoute = `/${interceptedRoute}`\n      } else {\n        interceptedRoute = interceptingRoute + '/' + interceptedRoute\n      }\n      break\n    case '(..)':\n      // (..) indicates that we should match at one level up, so we need to remove the last segment of the intercepting route\n      if (interceptingRoute === '/') {\n        throw new Error(\n          `Invalid interception route: ${path}. Cannot use (..) marker at the root level, use (.) instead.`\n        )\n      }\n      interceptedRoute = interceptingRoute\n        .split('/')\n        .slice(0, -1)\n        .concat(interceptedRoute)\n        .join('/')\n      break\n    case '(...)':\n      // (...) will match the route segment in the root directory, so we need to use the root directory to prepend the intercepted route\n      interceptedRoute = '/' + interceptedRoute\n      break\n    case '(..)(..)':\n      // (..)(..) indicates that we should match at two levels up, so we need to remove the last two segments of the intercepting route\n\n      const splitInterceptingRoute = interceptingRoute.split('/')\n      if (splitInterceptingRoute.length <= 2) {\n        throw new Error(\n          `Invalid interception route: ${path}. Cannot use (..)(..) marker at the root level or one level up.`\n        )\n      }\n\n      interceptedRoute = splitInterceptingRoute\n        .slice(0, -2)\n        .concat(interceptedRoute)\n        .join('/')\n      break\n    default:\n      throw new Error('Invariant: unexpected marker')\n  }\n\n  return { interceptingRoute, interceptedRoute }\n}\n","import {\n  extractInterceptionRouteInformation,\n  isInterceptionRouteAppPath,\n} from './interception-routes'\n\n// Identify /.*[param].*/ in route string\nconst TEST_ROUTE = /\\/[^/]*\\[[^/]+\\][^/]*(?=\\/|$)/\n\n// Identify /[param]/ in route string\nconst TEST_STRICT_ROUTE = /\\/\\[[^/]+\\](?=\\/|$)/\n\n/**\n * Check if a route is dynamic.\n *\n * @param route - The route to check.\n * @param strict - Whether to use strict mode which prohibits segments with prefixes/suffixes (default: true).\n * @returns Whether the route is dynamic.\n */\nexport function isDynamicRoute(route: string, strict: boolean = true): boolean {\n  if (isInterceptionRouteAppPath(route)) {\n    route = extractInterceptionRouteInformation(route).interceptedRoute\n  }\n\n  if (strict) {\n    return TEST_STRICT_ROUTE.test(route)\n  }\n\n  return TEST_ROUTE.test(route)\n}\n","export { getSortedRoutes, getSortedRouteObjects } from './sorted-routes'\nexport { isDynamicRoute } from './is-dynamic'\n","import {\n  abortAndThrowOnSynchronousRequestDataAccess,\n  postponeWithTracking,\n} from '../../app-render/dynamic-rendering'\nimport { isDynamicRoute } from '../../../shared/lib/router/utils'\nimport {\n  NEXT_CACHE_IMPLICIT_TAG_ID,\n  NEXT_CACHE_SOFT_TAG_MAX_LENGTH,\n} from '../../../lib/constants'\nimport { workAsyncStorage } from '../../app-render/work-async-storage.external'\nimport { workUnitAsyncStorage } from '../../app-render/work-unit-async-storage.external'\nimport { DynamicServerError } from '../../../client/components/hooks-server-context'\nimport { InvariantError } from '../../../shared/lib/invariant-error'\n\ntype CacheLifeConfig = {\n  expire?: number\n}\n\n/**\n * This function allows you to purge [cached data](https://nextjs.org/docs/app/building-your-application/caching) on-demand for a specific cache tag.\n *\n * Read more: [Next.js Docs: `revalidateTag`](https://nextjs.org/docs/app/api-reference/functions/revalidateTag)\n */\nexport function revalidateTag(tag: string, profile: string | CacheLifeConfig) {\n  if (!profile) {\n    console.warn(\n      '\"revalidateTag\" without the second argument is now deprecated, add second argument of \"max\" or use \"updateTag\". See more info here: https://nextjs.org/docs/messages/revalidate-tag-single-arg'\n    )\n  }\n  return revalidate([tag], `revalidateTag ${tag}`, profile)\n}\n\n/**\n * This function allows you to update [cached data](https://nextjs.org/docs/app/building-your-application/caching) on-demand for a specific cache tag.\n * This can only be called from within a Server Action to enable read-your-own-writes semantics.\n *\n * Read more: [Next.js Docs: `updateTag`](https://nextjs.org/docs/app/api-reference/functions/updateTag)\n */\nexport function updateTag(tag: string) {\n  const workStore = workAsyncStorage.getStore()\n\n  // TODO: change this after investigating why phase: 'action' is\n  // set for route handlers\n  if (!workStore || workStore.page.endsWith('/route')) {\n    throw new Error(\n      'updateTag can only be called from within a Server Action. ' +\n        'To invalidate cache tags in Route Handlers or other contexts, use revalidateTag instead. ' +\n        'See more info here: https://nextjs.org/docs/app/api-reference/functions/updateTag'\n    )\n  }\n  // updateTag uses immediate expiration (no profile) without deprecation warning\n  return revalidate([tag], `updateTag ${tag}`, undefined)\n}\n\n/**\n * This function allows you to refresh client cache from server actions.\n * It's useful as dynamic data can be cached on the client which won't\n * be refreshed by expireTag\n */\nexport function refresh() {\n  const workStore = workAsyncStorage.getStore()\n  const workUnitStore = workUnitAsyncStorage.getStore()\n\n  if (\n    !workStore ||\n    workStore.page.endsWith('/route') ||\n    workUnitStore?.phase !== 'action'\n  ) {\n    throw new Error(\n      'refresh can only be called from within a Server Action. ' +\n        'See more info here: https://nextjs.org/docs/app/api-reference/functions/refresh'\n    )\n  }\n\n  if (workStore) {\n    // TODO: break this to it's own field\n    workStore.pathWasRevalidated = true\n  }\n}\n\n/**\n * This function allows you to purge [cached data](https://nextjs.org/docs/app/building-your-application/caching) on-demand for a specific path.\n *\n * Read more: [Next.js Docs: `revalidatePath`](https://nextjs.org/docs/app/api-reference/functions/revalidatePath)\n */\nexport function revalidatePath(originalPath: string, type?: 'layout' | 'page') {\n  if (originalPath.length > NEXT_CACHE_SOFT_TAG_MAX_LENGTH) {\n    console.warn(\n      `Warning: revalidatePath received \"${originalPath}\" which exceeded max length of ${NEXT_CACHE_SOFT_TAG_MAX_LENGTH}. See more info here https://nextjs.org/docs/app/api-reference/functions/revalidatePath`\n    )\n    return\n  }\n\n  let normalizedPath = `${NEXT_CACHE_IMPLICIT_TAG_ID}${originalPath || '/'}`\n\n  if (type) {\n    normalizedPath += `${normalizedPath.endsWith('/') ? '' : '/'}${type}`\n  } else if (isDynamicRoute(originalPath)) {\n    console.warn(\n      `Warning: a dynamic page path \"${originalPath}\" was passed to \"revalidatePath\", but the \"type\" parameter is missing. This has no effect by default, see more info here https://nextjs.org/docs/app/api-reference/functions/revalidatePath`\n    )\n  }\n\n  const tags = [normalizedPath]\n  if (normalizedPath === `${NEXT_CACHE_IMPLICIT_TAG_ID}/`) {\n    tags.push(`${NEXT_CACHE_IMPLICIT_TAG_ID}/index`)\n  } else if (normalizedPath === `${NEXT_CACHE_IMPLICIT_TAG_ID}/index`) {\n    tags.push(`${NEXT_CACHE_IMPLICIT_TAG_ID}/`)\n  }\n\n  return revalidate(tags, `revalidatePath ${originalPath}`)\n}\n\nfunction revalidate(\n  tags: string[],\n  expression: string,\n  profile?: string | CacheLifeConfig\n) {\n  const store = workAsyncStorage.getStore()\n  if (!store || !store.incrementalCache) {\n    throw new Error(\n      `Invariant: static generation store missing in ${expression}`\n    )\n  }\n\n  const workUnitStore = workUnitAsyncStorage.getStore()\n  if (workUnitStore) {\n    if (workUnitStore.phase === 'render') {\n      throw new Error(\n        `Route ${store.route} used \"${expression}\" during render which is unsupported. To ensure revalidation is performed consistently it must always happen outside of renders and cached functions. See more info here: https://nextjs.org/docs/app/building-your-application/rendering/static-and-dynamic#dynamic-rendering`\n      )\n    }\n\n    switch (workUnitStore.type) {\n      case 'cache':\n      case 'private-cache':\n        throw new Error(\n          `Route ${store.route} used \"${expression}\" inside a \"use cache\" which is unsupported. To ensure revalidation is performed consistently it must always happen outside of renders and cached functions. See more info here: https://nextjs.org/docs/app/building-your-application/rendering/static-and-dynamic#dynamic-rendering`\n        )\n      case 'unstable-cache':\n        throw new Error(\n          `Route ${store.route} used \"${expression}\" inside a function cached with \"unstable_cache(...)\" which is unsupported. To ensure revalidation is performed consistently it must always happen outside of renders and cached functions. See more info here: https://nextjs.org/docs/app/building-your-application/rendering/static-and-dynamic#dynamic-rendering`\n        )\n      case 'prerender':\n      case 'prerender-runtime':\n        // cacheComponents Prerender\n        const error = new Error(\n          `Route ${store.route} used ${expression} without first calling \\`await connection()\\`.`\n        )\n        return abortAndThrowOnSynchronousRequestDataAccess(\n          store.route,\n          expression,\n          error,\n          workUnitStore\n        )\n      case 'prerender-client':\n        throw new InvariantError(\n          `${expression} must not be used within a client component. Next.js should be preventing ${expression} from being included in client components statically, but did not in this case.`\n        )\n      case 'prerender-ppr':\n        return postponeWithTracking(\n          store.route,\n          expression,\n          workUnitStore.dynamicTracking\n        )\n      case 'prerender-legacy':\n        workUnitStore.revalidate = 0\n\n        const err = new DynamicServerError(\n          `Route ${store.route} couldn't be rendered statically because it used \\`${expression}\\`. See more info here: https://nextjs.org/docs/messages/dynamic-server-error`\n        )\n        store.dynamicUsageDescription = expression\n        store.dynamicUsageStack = err.stack\n\n        throw err\n      case 'request':\n        if (process.env.NODE_ENV !== 'production') {\n          // TODO: This is most likely incorrect. It would lead to the ISR\n          // status being flipped when revalidating a static page with a server\n          // action.\n          workUnitStore.usedDynamic = true\n        }\n        break\n      default:\n        workUnitStore satisfies never\n    }\n  }\n\n  if (!store.pendingRevalidatedTags) {\n    store.pendingRevalidatedTags = []\n  }\n\n  for (const tag of tags) {\n    const existingIndex = store.pendingRevalidatedTags.findIndex((item) => {\n      if (item.tag !== tag) return false\n      // Compare profiles: both strings, both objects, or both undefined\n      if (typeof item.profile === 'string' && typeof profile === 'string') {\n        return item.profile === profile\n      }\n      if (typeof item.profile === 'object' && typeof profile === 'object') {\n        return JSON.stringify(item.profile) === JSON.stringify(profile)\n      }\n      return item.profile === profile\n    })\n    if (existingIndex === -1) {\n      store.pendingRevalidatedTags.push({\n        tag,\n        profile,\n      })\n    }\n  }\n\n  // if profile is provided and this is a stale-while-revalidate\n  // update we do not mark the path as revalidated so that server\n  // actions don't pull their own writes\n  const cacheLife =\n    profile && typeof profile === 'object'\n      ? profile\n      : profile &&\n          typeof profile === 'string' &&\n          store?.cacheLifeProfiles?.[profile]\n        ? store.cacheLifeProfiles[profile]\n        : undefined\n\n  if (!profile || cacheLife?.expire === 0) {\n    // TODO: only revalidate if the path matches\n    store.pathWasRevalidated = true\n  }\n}\n","import { workAsyncStorage } from '../../app-render/work-async-storage.external'\nimport { workUnitAsyncStorage } from '../../app-render/work-unit-async-storage.external'\nimport { markCurrentScopeAsDynamic } from '../../app-render/dynamic-rendering'\n\n/**\n * This function can be used to declaratively opt out of static rendering and indicate a particular component should not be cached.\n *\n * It marks the current scope as dynamic.\n *\n * - In [non-PPR](https://nextjs.org/docs/app/api-reference/next-config-js/partial-prerendering) cases this will make a static render\n * halt and mark the page as dynamic.\n * - In PPR cases this will postpone the render at this location.\n *\n * If we are inside a cache scope then this function does nothing.\n *\n * @note It expects to be called within App Router and will error otherwise.\n *\n * Read more: [Next.js Docs: `unstable_noStore`](https://nextjs.org/docs/app/api-reference/functions/unstable_noStore)\n */\nexport function unstable_noStore() {\n  const callingExpression = 'unstable_noStore()'\n  const store = workAsyncStorage.getStore()\n  const workUnitStore = workUnitAsyncStorage.getStore()\n  if (!store) {\n    // This generally implies we are being called in Pages router. We should probably not support\n    // unstable_noStore in contexts outside of `react-server` condition but since we historically\n    // have not errored here previously, we maintain that behavior for now.\n    return\n  } else if (store.forceStatic) {\n    return\n  } else {\n    store.isUnstableNoStore = true\n    if (workUnitStore) {\n      switch (workUnitStore.type) {\n        case 'prerender':\n        case 'prerender-client':\n        case 'prerender-runtime':\n          // unstable_noStore() is a noop in Dynamic I/O.\n          return\n        case 'prerender-ppr':\n        case 'prerender-legacy':\n        case 'request':\n        case 'cache':\n        case 'private-cache':\n        case 'unstable-cache':\n          break\n        default:\n          workUnitStore satisfies never\n      }\n    }\n    markCurrentScopeAsDynamic(store, workUnitStore, callingExpression)\n  }\n}\n","import { InvariantError } from '../../shared/lib/invariant-error'\nimport { workAsyncStorage } from '../app-render/work-async-storage.external'\nimport { workUnitAsyncStorage } from '../app-render/work-unit-async-storage.external'\n\nexport type CacheLife = {\n  // How long the client can cache a value without checking with the server.\n  stale?: number\n  // How frequently you want the cache to refresh on the server.\n  // Stale values may be served while revalidating.\n  revalidate?: number\n  // In the worst case scenario, where you haven't had traffic in a while,\n  // how stale can a value be until you prefer deopting to dynamic.\n  // Must be longer than revalidate.\n  expire?: number\n}\n// The equivalent header is kind of like:\n// Cache-Control: max-age=[stale],s-max-age=[revalidate],stale-while-revalidate=[expire-revalidate],stale-if-error=[expire-revalidate]\n// Except that stale-while-revalidate/stale-if-error only applies to shared caches - not private caches.\n\n// The default revalidates relatively frequently but doesn't expire to ensure it's always\n// able to serve fast results but by default doesn't hang.\n\n// This gets overridden by the next-types-plugin\ntype CacheLifeProfiles =\n  | 'default'\n  | 'seconds'\n  | 'minutes'\n  | 'hours'\n  | 'days'\n  | 'weeks'\n  | 'max'\n  | (string & {})\n\nfunction validateCacheLife(profile: CacheLife) {\n  if (profile.stale !== undefined) {\n    if ((profile.stale as any) === false) {\n      throw new Error(\n        'Pass `Infinity` instead of `false` if you want to cache on the client forever ' +\n          'without checking with the server.'\n      )\n    } else if (typeof profile.stale !== 'number') {\n      throw new Error('The stale option must be a number of seconds.')\n    }\n  }\n  if (profile.revalidate !== undefined) {\n    if ((profile.revalidate as any) === false) {\n      throw new Error(\n        'Pass `Infinity` instead of `false` if you do not want to revalidate by time.'\n      )\n    } else if (typeof profile.revalidate !== 'number') {\n      throw new Error('The revalidate option must be a number of seconds.')\n    }\n  }\n  if (profile.expire !== undefined) {\n    if ((profile.expire as any) === false) {\n      throw new Error(\n        'Pass `Infinity` instead of `false` if you want to cache on the server forever ' +\n          'without checking with the origin.'\n      )\n    } else if (typeof profile.expire !== 'number') {\n      throw new Error('The expire option must be a number of seconds.')\n    }\n  }\n\n  if (profile.revalidate !== undefined && profile.expire !== undefined) {\n    if (profile.revalidate > profile.expire) {\n      throw new Error(\n        'If providing both the revalidate and expire options, ' +\n          'the expire option must be greater than the revalidate option. ' +\n          'The expire option indicates how many seconds from the start ' +\n          'until it can no longer be used.'\n      )\n    }\n  }\n}\n\nexport function cacheLife(profile: CacheLifeProfiles | CacheLife): void {\n  if (!process.env.__NEXT_USE_CACHE) {\n    throw new Error(\n      '`cacheLife()` is only available with the `cacheComponents` config.'\n    )\n  }\n\n  const workUnitStore = workUnitAsyncStorage.getStore()\n\n  switch (workUnitStore?.type) {\n    case 'prerender':\n    case 'prerender-client':\n    case 'prerender-runtime':\n    case 'prerender-ppr':\n    case 'prerender-legacy':\n    case 'request':\n    case 'unstable-cache':\n    case undefined:\n      throw new Error(\n        '`cacheLife()` can only be called inside a \"use cache\" function.'\n      )\n    case 'cache':\n    case 'private-cache':\n      break\n    default:\n      workUnitStore satisfies never\n  }\n\n  if (typeof profile === 'string') {\n    const workStore = workAsyncStorage.getStore()\n    if (!workStore) {\n      throw new Error(\n        '`cacheLife()` can only be called during App Router rendering at the moment.'\n      )\n    }\n    if (!workStore.cacheLifeProfiles) {\n      throw new InvariantError('`cacheLifeProfiles` should always be provided.')\n    }\n\n    // TODO: This should be globally available and not require an AsyncLocalStorage.\n    const configuredProfile = workStore.cacheLifeProfiles[profile]\n    if (configuredProfile === undefined) {\n      if (workStore.cacheLifeProfiles[profile.trim()]) {\n        throw new Error(\n          `Unknown \\`cacheLife()\\` profile \"${profile}\" is not configured in next.config.js\\n` +\n            `Did you mean \"${profile.trim()}\" without the spaces?`\n        )\n      }\n      throw new Error(\n        `Unknown \\`cacheLife()\\` profile \"${profile}\" is not configured in next.config.js\\n` +\n          'module.exports = {\\n' +\n          '  cacheLife: {\\n' +\n          `    \"${profile}\": ...\\n` +\n          '  }\\n' +\n          '}'\n      )\n    }\n    profile = configuredProfile\n  } else if (\n    typeof profile !== 'object' ||\n    profile === null ||\n    Array.isArray(profile)\n  ) {\n    throw new Error(\n      'Invalid `cacheLife()` option. Either pass a profile name or object.'\n    )\n  } else {\n    validateCacheLife(profile)\n  }\n\n  if (profile.revalidate !== undefined) {\n    // Track the explicit revalidate time.\n    if (\n      workUnitStore.explicitRevalidate === undefined ||\n      workUnitStore.explicitRevalidate > profile.revalidate\n    ) {\n      workUnitStore.explicitRevalidate = profile.revalidate\n    }\n  }\n  if (profile.expire !== undefined) {\n    // Track the explicit expire time.\n    if (\n      workUnitStore.explicitExpire === undefined ||\n      workUnitStore.explicitExpire > profile.expire\n    ) {\n      workUnitStore.explicitExpire = profile.expire\n    }\n  }\n  if (profile.stale !== undefined) {\n    // Track the explicit stale time.\n    if (\n      workUnitStore.explicitStale === undefined ||\n      workUnitStore.explicitStale > profile.stale\n    ) {\n      workUnitStore.explicitStale = profile.stale\n    }\n  }\n}\n","import { workUnitAsyncStorage } from '../app-render/work-unit-async-storage.external'\nimport { validateTags } from '../lib/patch-fetch'\n\nexport function cacheTag(...tags: string[]): void {\n  if (!process.env.__NEXT_USE_CACHE) {\n    throw new Error(\n      '`cacheTag()` is only available with the `cacheComponents` config.'\n    )\n  }\n\n  const workUnitStore = workUnitAsyncStorage.getStore()\n\n  switch (workUnitStore?.type) {\n    case 'prerender':\n    case 'prerender-client':\n    case 'prerender-runtime':\n    case 'prerender-ppr':\n    case 'prerender-legacy':\n    case 'request':\n    case 'unstable-cache':\n    case undefined:\n      throw new Error(\n        '`cacheTag()` can only be called inside a \"use cache\" function.'\n      )\n    case 'cache':\n    case 'private-cache':\n      break\n    default:\n      workUnitStore satisfies never\n  }\n\n  const validTags = validateTags(tags, '`cacheTag()`')\n\n  if (!workUnitStore.tags) {\n    workUnitStore.tags = validTags\n  } else {\n    workUnitStore.tags.push(...validTags)\n  }\n}\n","const cacheExports = {\n  unstable_cache: require('next/dist/server/web/spec-extension/unstable-cache')\n    .unstable_cache,\n\n  updateTag: require('next/dist/server/web/spec-extension/revalidate')\n    .updateTag,\n\n  revalidateTag: require('next/dist/server/web/spec-extension/revalidate')\n    .revalidateTag,\n  revalidatePath: require('next/dist/server/web/spec-extension/revalidate')\n    .revalidatePath,\n\n  refresh: require('next/dist/server/web/spec-extension/revalidate').refresh,\n\n  unstable_noStore:\n    require('next/dist/server/web/spec-extension/unstable-no-store')\n      .unstable_noStore,\n  cacheLife: require('next/dist/server/use-cache/cache-life').cacheLife,\n  cacheTag: require('next/dist/server/use-cache/cache-tag').cacheTag,\n}\n\nlet didWarnCacheLife = false\nfunction unstable_cacheLife() {\n  if (!didWarnCacheLife) {\n    didWarnCacheLife = true\n    const error = new Error(\n      '`unstable_cacheLife` was recently stabilized and should be imported as `cacheLife`. The `unstable` prefixed form will be removed in a future version of Next.js.'\n    )\n    console.error(error)\n  }\n  return cacheExports.cacheLife.apply(this, arguments)\n}\n\nlet didWarnCacheTag = false\nfunction unstable_cacheTag() {\n  if (!didWarnCacheTag) {\n    didWarnCacheTag = true\n    const error = new Error(\n      '`unstable_cacheTag` was recently stabilized and should be imported as `cacheTag`. The `unstable` prefixed form will be removed in a future version of Next.js.'\n    )\n    console.error(error)\n  }\n  return cacheExports.cacheTag.apply(this, arguments)\n}\n\ncacheExports.unstable_cacheLife = unstable_cacheLife\ncacheExports.unstable_cacheTag = unstable_cacheTag\n\n// https://nodejs.org/api/esm.html#commonjs-namespaces\n// When importing CommonJS modules, the module.exports object is provided as the default export\nmodule.exports = cacheExports\n\n// make import { xxx } from 'next/cache' work\nexports.unstable_cache = cacheExports.unstable_cache\nexports.revalidatePath = cacheExports.revalidatePath\nexports.revalidateTag = cacheExports.revalidateTag\nexports.updateTag = cacheExports.updateTag\nexports.unstable_noStore = cacheExports.unstable_noStore\nexports.cacheLife = cacheExports.cacheLife\nexports.unstable_cacheLife = cacheExports.unstable_cacheLife\nexports.cacheTag = cacheExports.cacheTag\nexports.unstable_cacheTag = cacheExports.unstable_cacheTag\nexports.refresh = cacheExports.refresh\n","// This function ensures that all the exported values are valid server actions,\n// during the runtime. By definition all actions are required to be async\n// functions, but here we can only check that they are functions.\nexport function ensureServerEntryExports(actions: any[]) {\n  for (let i = 0; i < actions.length; i++) {\n    const action = actions[i]\n    if (typeof action !== 'function') {\n      throw new Error(\n        `A \"use server\" file can only export async functions, found ${typeof action}.\\nRead more: https://nextjs.org/docs/messages/invalid-use-server-value`\n      )\n    }\n  }\n}\n","import { neon, neonConfig } from \"@neondatabase/serverless\";\nimport { ArtigoNoticia } from \"../types\";\n\n//  Melhora performance e cache de conexo no ambiente serverless\nneonConfig.fetchConnectionCache = true;\n\nif (!process.env.POSTGRES_URL) {\n  throw new Error(\"Varivel de ambiente POSTGRES_URL no definida.\");\n}\n\nconst sql = neon(process.env.POSTGRES_URL);\n\n/* =========================================================\n    Funo auxiliar para mapear o resultado\n   ========================================================= */\nconst mapRowToArticle = (row: any): ArtigoNoticia => ({\n  id: String(row.id),\n  generationDate: row.generation_date,\n  title: row.title,\n  rawContent: row.raw_content,\n  formattedContent: row.formatted_content || \"\",\n  published: row.published,\n  keywords: Array.isArray(row.keywords)\n    ? row.keywords\n    : typeof row.keywords === \"string\"\n    ? row.keywords.split(\",\").map((k: string) => k.trim())\n    : [],\n  metaDescription: row.meta_description || \"\",\n});\n\n/* =========================================================\n    Criao da tabela\n   ========================================================= */\nexport async function setupDatabase() {\n  try {\n    await sql`\n      CREATE TABLE IF NOT EXISTS articles (\n        id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n        generation_date TIMESTAMPTZ NOT NULL,\n        title TEXT NOT NULL,\n        raw_content TEXT NOT NULL,\n        formatted_content TEXT,\n        published BOOLEAN NOT NULL DEFAULT false,\n        keywords TEXT[],\n        meta_description TEXT\n      );\n    `;\n    console.log(\" Tabela 'articles' verificada/criada com sucesso.\");\n  } catch (error) {\n    console.error(\" Falha na configurao do banco de dados:\", error);\n    throw new Error(\"Falha ao configurar a tabela do banco de dados.\");\n  }\n}\n\n/* =========================================================\n    Inserir artigo completo\n   ========================================================= */\nexport async function saveArticle(article: Omit<ArtigoNoticia, \"id\">): Promise<ArtigoNoticia> {\n  try {\n    const result = await sql`\n      INSERT INTO articles (\n        generation_date, title, raw_content, formatted_content, published, keywords, meta_description\n      )\n      VALUES (\n        ${article.generationDate},\n        ${article.title},\n        ${article.rawContent},\n        ${article.formattedContent || \"\"},\n        ${article.published ?? false},\n        ${Array.isArray(article.keywords) ? article.keywords : [article.keywords]},\n        ${article.metaDescription || \"\"}\n      )\n      RETURNING *;\n    `;\n\n    const row = Array.isArray(result) ? result[0] : (result as any);\n    console.log(` Artigo salvo com sucesso (ID: ${row.id})`);\n    return mapRowToArticle(row);\n  } catch (error) {\n    console.error(\" Erro ao salvar artigo:\", error);\n    throw new Error(\"Falha ao salvar o artigo.\");\n  }\n}\n\n/* =========================================================\n    Salvar rascunho inicial (pr-formatao)\n   ========================================================= */\nexport async function saveArticleDraft(data: {\n  title: string;\n  content: string;\n  language: string;\n}): Promise<{ id: string }> {\n  try {\n    const result = await sql`\n      INSERT INTO articles (generation_date, title, raw_content, formatted_content, published)\n      VALUES (NOW(), ${data.title}, ${data.content}, '', false)\n      RETURNING id;\n    `;\n\n    const row = Array.isArray(result) ? result[0] : (result as any);\n    console.log(` Rascunho salvo com ID: ${row.id}`);\n    return { id: String(row.id) };\n  } catch (error) {\n    console.error(\" Erro ao salvar rascunho:\", error);\n    throw new Error(\"Falha ao salvar o rascunho do artigo.\");\n  }\n}\n\n/* =========================================================\n    Buscar artigo por ID\n   ========================================================= */\nexport async function getArticleById(id: string | number) {\n  try {\n    const result = await sql`SELECT * FROM articles WHERE id = ${id} LIMIT 1;`;\n    const row = Array.isArray(result) ? result[0] : (result as any);\n    if (!row) return null;\n\n    console.log(\"## retorno do select\");\n    console.log(row);\n    return mapRowToArticle(row);\n  } catch (error) {\n    console.error(\" Erro ao buscar artigo:\", error);\n    throw new Error(\"Falha ao buscar o artigo por ID.\");\n  }\n}\n\n/* =========================================================\n    Atualizar artigo genrico\n   ========================================================= */\nexport async function updateArticle(id: string, data: Partial<ArtigoNoticia>): Promise<void> {\n  try {\n    const keys = Object.keys(data);\n    if (keys.length === 0) return;\n\n    // Monta os campos dinamicamente\n    const setClause = keys\n      .map((key, i) => `${key.replace(/([A-Z])/g, \"_$1\").toLowerCase()} = $${i + 1}`)\n      .join(\", \");\n    const values = Object.values(data);\n\n    const query = `\n      UPDATE articles\n      SET ${setClause}\n      WHERE id = $${keys.length + 1};\n    `;\n\n    await sql(query, [...values, id]);\n    console.log(` Artigo ${id} atualizado (${keys.join(\", \")})`);\n  } catch (error) {\n    console.error(\" Erro ao atualizar artigo:\", error);\n    throw new Error(\"Falha ao atualizar o artigo.\");\n  }\n}\n\n/* =========================================================\n    Atualizar apenas o HTML\n   ========================================================= */\nexport async function updateArticleHtml(id: string | number, html: string) {\n  try {\n    const result = await sql`\n      UPDATE articles\n      SET formatted_content = ${html}\n      WHERE id = ${id}\n      RETURNING id, title, formatted_content;\n    `;\n\n    // Normaliza para garantir compatibilidade\n    const row = Array.isArray(result) ? result[0] : (result as any);\n    if (!row) throw new Error(`Nenhum artigo retornado aps o update (ID ${id}).`);\n\n    console.log(` HTML atualizado com sucesso para o artigo ID ${id}.`);\n    return {\n      id: String(row.id),\n      title: row.title,\n      formattedContent: row.formatted_content,\n    };\n  } catch (error) {\n    console.error(\" Erro ao atualizar o artigo:\", error);\n    throw new Error(\"Falha ao atualizar o artigo.\");\n  }\n}\n\n/* =========================================================\n    Buscar todos os artigos\n   ========================================================= */\nexport async function getArticles(): Promise<ArtigoNoticia[]> {\n  try {\n    const result = await sql`SELECT * FROM articles ORDER BY generation_date DESC;`;\n    const rows = Array.isArray(result) ? result : (result ? [result] : []);\n    return rows.map(mapRowToArticle);\n  } catch (error) {\n    console.error(\" Erro ao buscar artigos:\", error);\n    throw new Error(\"Falha ao buscar os artigos.\");\n  }\n}\n\n/* =========================================================\n    Excluir artigo\n   ========================================================= */\nexport async function deleteArticle(id: string): Promise<void> {\n  try {\n    await sql`DELETE FROM articles WHERE id = ${id};`;\n    console.log(` Artigo ${id} removido com sucesso.`);\n  } catch (error) {\n    console.error(\" Erro ao excluir artigo:\", error);\n    throw new Error(\"Falha ao excluir o artigo.\");\n  }\n}\n","function __classPrivateFieldSet(receiver, state, value, kind, f) {\n    if (kind === \"m\")\n        throw new TypeError(\"Private method is not writable\");\n    if (kind === \"a\" && !f)\n        throw new TypeError(\"Private accessor was defined without a setter\");\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver))\n        throw new TypeError(\"Cannot write private member to an object whose class did not declare it\");\n    return kind === \"a\" ? f.call(receiver, value) : f ? (f.value = value) : state.set(receiver, value), value;\n}\nfunction __classPrivateFieldGet(receiver, state, kind, f) {\n    if (kind === \"a\" && !f)\n        throw new TypeError(\"Private accessor was defined without a getter\");\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver))\n        throw new TypeError(\"Cannot read private member from an object whose class did not declare it\");\n    return kind === \"m\" ? f : kind === \"a\" ? f.call(receiver) : f ? f.value : state.get(receiver);\n}\nexport { __classPrivateFieldSet, __classPrivateFieldGet };\n","import createWebSocketStream from './lib/stream.js';\nimport Receiver from './lib/receiver.js';\nimport Sender from './lib/sender.js';\nimport WebSocket from './lib/websocket.js';\nimport WebSocketServer from './lib/websocket-server.js';\n\nexport { createWebSocketStream, Receiver, Sender, WebSocket, WebSocketServer };\nexport default WebSocket;\n","const STR = 0b000000001;\nconst NUM = 0b000000010;\nconst ARR = 0b000000100;\nconst OBJ = 0b000001000;\nconst NULL = 0b000010000;\nconst BOOL = 0b000100000;\nconst NAN = 0b001000000;\nconst INFINITY = 0b010000000;\nconst MINUS_INFINITY = 0b100000000;\n\nconst INF = INFINITY | MINUS_INFINITY;\nconst SPECIAL = NULL | BOOL | INF | NAN;\nconst ATOM = STR | NUM | SPECIAL;\nconst COLLECTION = ARR | OBJ;\nconst ALL = ATOM | COLLECTION;\n\nconst Allow = {\n  STR,\n  NUM,\n  ARR,\n  OBJ,\n  NULL,\n  BOOL,\n  NAN,\n  INFINITY,\n  MINUS_INFINITY,\n  INF,\n  SPECIAL,\n  ATOM,\n  COLLECTION,\n  ALL,\n};\n\n// The JSON string segment was unable to be parsed completely\nclass PartialJSON extends Error {}\n\nclass MalformedJSON extends Error {}\n\n/**\n * Parse incomplete JSON\n * @param {string} jsonString Partial JSON to be parsed\n * @param {number} allowPartial Specify what types are allowed to be partial, see {@link Allow} for details\n * @returns The parsed JSON\n * @throws {PartialJSON} If the JSON is incomplete (related to the `allow` parameter)\n * @throws {MalformedJSON} If the JSON is malformed\n */\nfunction parseJSON(jsonString: string, allowPartial: number = Allow.ALL): any {\n  if (typeof jsonString !== 'string') {\n    throw new TypeError(`expecting str, got ${typeof jsonString}`);\n  }\n  if (!jsonString.trim()) {\n    throw new Error(`${jsonString} is empty`);\n  }\n  return _parseJSON(jsonString.trim(), allowPartial);\n}\n\nconst _parseJSON = (jsonString: string, allow: number) => {\n  const length = jsonString.length;\n  let index = 0;\n\n  const markPartialJSON = (msg: string) => {\n    throw new PartialJSON(`${msg} at position ${index}`);\n  };\n\n  const throwMalformedError = (msg: string) => {\n    throw new MalformedJSON(`${msg} at position ${index}`);\n  };\n\n  const parseAny: () => any = () => {\n    skipBlank();\n    if (index >= length) markPartialJSON('Unexpected end of input');\n    if (jsonString[index] === '\"') return parseStr();\n    if (jsonString[index] === '{') return parseObj();\n    if (jsonString[index] === '[') return parseArr();\n    if (\n      jsonString.substring(index, index + 4) === 'null' ||\n      (Allow.NULL & allow && length - index < 4 && 'null'.startsWith(jsonString.substring(index)))\n    ) {\n      index += 4;\n      return null;\n    }\n    if (\n      jsonString.substring(index, index + 4) === 'true' ||\n      (Allow.BOOL & allow && length - index < 4 && 'true'.startsWith(jsonString.substring(index)))\n    ) {\n      index += 4;\n      return true;\n    }\n    if (\n      jsonString.substring(index, index + 5) === 'false' ||\n      (Allow.BOOL & allow && length - index < 5 && 'false'.startsWith(jsonString.substring(index)))\n    ) {\n      index += 5;\n      return false;\n    }\n    if (\n      jsonString.substring(index, index + 8) === 'Infinity' ||\n      (Allow.INFINITY & allow && length - index < 8 && 'Infinity'.startsWith(jsonString.substring(index)))\n    ) {\n      index += 8;\n      return Infinity;\n    }\n    if (\n      jsonString.substring(index, index + 9) === '-Infinity' ||\n      (Allow.MINUS_INFINITY & allow &&\n        1 < length - index &&\n        length - index < 9 &&\n        '-Infinity'.startsWith(jsonString.substring(index)))\n    ) {\n      index += 9;\n      return -Infinity;\n    }\n    if (\n      jsonString.substring(index, index + 3) === 'NaN' ||\n      (Allow.NAN & allow && length - index < 3 && 'NaN'.startsWith(jsonString.substring(index)))\n    ) {\n      index += 3;\n      return NaN;\n    }\n    return parseNum();\n  };\n\n  const parseStr: () => string = () => {\n    const start = index;\n    let escape = false;\n    index++; // skip initial quote\n    while (index < length && (jsonString[index] !== '\"' || (escape && jsonString[index - 1] === '\\\\'))) {\n      escape = jsonString[index] === '\\\\' ? !escape : false;\n      index++;\n    }\n    if (jsonString.charAt(index) == '\"') {\n      try {\n        return JSON.parse(jsonString.substring(start, ++index - Number(escape)));\n      } catch (e) {\n        throwMalformedError(String(e));\n      }\n    } else if (Allow.STR & allow) {\n      try {\n        return JSON.parse(jsonString.substring(start, index - Number(escape)) + '\"');\n      } catch (e) {\n        // SyntaxError: Invalid escape sequence\n        return JSON.parse(jsonString.substring(start, jsonString.lastIndexOf('\\\\')) + '\"');\n      }\n    }\n    markPartialJSON('Unterminated string literal');\n  };\n\n  const parseObj = () => {\n    index++; // skip initial brace\n    skipBlank();\n    const obj: Record<string, any> = {};\n    try {\n      while (jsonString[index] !== '}') {\n        skipBlank();\n        if (index >= length && Allow.OBJ & allow) return obj;\n        const key = parseStr();\n        skipBlank();\n        index++; // skip colon\n        try {\n          const value = parseAny();\n          Object.defineProperty(obj, key, { value, writable: true, enumerable: true, configurable: true });\n        } catch (e) {\n          if (Allow.OBJ & allow) return obj;\n          else throw e;\n        }\n        skipBlank();\n        if (jsonString[index] === ',') index++; // skip comma\n      }\n    } catch (e) {\n      if (Allow.OBJ & allow) return obj;\n      else markPartialJSON(\"Expected '}' at end of object\");\n    }\n    index++; // skip final brace\n    return obj;\n  };\n\n  const parseArr = () => {\n    index++; // skip initial bracket\n    const arr = [];\n    try {\n      while (jsonString[index] !== ']') {\n        arr.push(parseAny());\n        skipBlank();\n        if (jsonString[index] === ',') {\n          index++; // skip comma\n        }\n      }\n    } catch (e) {\n      if (Allow.ARR & allow) {\n        return arr;\n      }\n      markPartialJSON(\"Expected ']' at end of array\");\n    }\n    index++; // skip final bracket\n    return arr;\n  };\n\n  const parseNum = () => {\n    if (index === 0) {\n      if (jsonString === '-' && Allow.NUM & allow) markPartialJSON(\"Not sure what '-' is\");\n      try {\n        return JSON.parse(jsonString);\n      } catch (e) {\n        if (Allow.NUM & allow) {\n          try {\n            if ('.' === jsonString[jsonString.length - 1])\n              return JSON.parse(jsonString.substring(0, jsonString.lastIndexOf('.')));\n            return JSON.parse(jsonString.substring(0, jsonString.lastIndexOf('e')));\n          } catch (e) {}\n        }\n        throwMalformedError(String(e));\n      }\n    }\n\n    const start = index;\n\n    if (jsonString[index] === '-') index++;\n    while (jsonString[index] && !',]}'.includes(jsonString[index]!)) index++;\n\n    if (index == length && !(Allow.NUM & allow)) markPartialJSON('Unterminated number literal');\n\n    try {\n      return JSON.parse(jsonString.substring(start, index));\n    } catch (e) {\n      if (jsonString.substring(start, index) === '-' && Allow.NUM & allow)\n        markPartialJSON(\"Not sure what '-' is\");\n      try {\n        return JSON.parse(jsonString.substring(start, jsonString.lastIndexOf('e')));\n      } catch (e) {\n        throwMalformedError(String(e));\n      }\n    }\n  };\n\n  const skipBlank = () => {\n    while (index < length && ' \\n\\r\\t'.includes(jsonString[index]!)) {\n      index++;\n    }\n  };\n\n  return parseAny();\n};\n\n// using this function with malformed JSON is undefined behavior\nconst partialParse = (input: string) => parseJSON(input, Allow.ALL ^ Allow.NUM);\n\nexport { partialParse, PartialJSON, MalformedJSON };\n","export function concatBytes(buffers: Uint8Array[]): Uint8Array {\n  let length = 0;\n  for (const buffer of buffers) {\n    length += buffer.length;\n  }\n  const output = new Uint8Array(length);\n  let index = 0;\n  for (const buffer of buffers) {\n    output.set(buffer, index);\n    index += buffer.length;\n  }\n\n  return output;\n}\n\nlet encodeUTF8_: (str: string) => Uint8Array;\nexport function encodeUTF8(str: string) {\n  let encoder;\n  return (\n    encodeUTF8_ ??\n    ((encoder = new (globalThis as any).TextEncoder()), (encodeUTF8_ = encoder.encode.bind(encoder)))\n  )(str);\n}\n\nlet decodeUTF8_: (bytes: Uint8Array) => string;\nexport function decodeUTF8(bytes: Uint8Array) {\n  let decoder;\n  return (\n    decodeUTF8_ ??\n    ((decoder = new (globalThis as any).TextDecoder()), (decodeUTF8_ = decoder.decode.bind(decoder)))\n  )(bytes);\n}\n","export { type Uploadable } from '../internal/uploads';\nexport { toFile, type ToFileInput } from '../internal/to-file';\n","import { encode, is_buffer, maybe_map, has } from './utils';\nimport { default_format, default_formatter, formatters } from './formats';\nimport type { NonNullableProperties, StringifyOptions } from './types';\nimport { isArray } from '../utils/values';\n\nconst array_prefix_generators = {\n  brackets(prefix: PropertyKey) {\n    return String(prefix) + '[]';\n  },\n  comma: 'comma',\n  indices(prefix: PropertyKey, key: string) {\n    return String(prefix) + '[' + key + ']';\n  },\n  repeat(prefix: PropertyKey) {\n    return String(prefix);\n  },\n};\n\nconst push_to_array = function (arr: any[], value_or_array: any) {\n  Array.prototype.push.apply(arr, isArray(value_or_array) ? value_or_array : [value_or_array]);\n};\n\nlet toISOString;\n\nconst defaults = {\n  addQueryPrefix: false,\n  allowDots: false,\n  allowEmptyArrays: false,\n  arrayFormat: 'indices',\n  charset: 'utf-8',\n  charsetSentinel: false,\n  delimiter: '&',\n  encode: true,\n  encodeDotInKeys: false,\n  encoder: encode,\n  encodeValuesOnly: false,\n  format: default_format,\n  formatter: default_formatter,\n  /** @deprecated */\n  indices: false,\n  serializeDate(date) {\n    return (toISOString ??= Function.prototype.call.bind(Date.prototype.toISOString))(date);\n  },\n  skipNulls: false,\n  strictNullHandling: false,\n} as NonNullableProperties<StringifyOptions & { formatter: (typeof formatters)['RFC1738'] }>;\n\nfunction is_non_nullish_primitive(v: unknown): v is string | number | boolean | symbol | bigint {\n  return (\n    typeof v === 'string' ||\n    typeof v === 'number' ||\n    typeof v === 'boolean' ||\n    typeof v === 'symbol' ||\n    typeof v === 'bigint'\n  );\n}\n\nconst sentinel = {};\n\nfunction inner_stringify(\n  object: any,\n  prefix: PropertyKey,\n  generateArrayPrefix: StringifyOptions['arrayFormat'] | ((prefix: string, key: string) => string),\n  commaRoundTrip: boolean,\n  allowEmptyArrays: boolean,\n  strictNullHandling: boolean,\n  skipNulls: boolean,\n  encodeDotInKeys: boolean,\n  encoder: StringifyOptions['encoder'],\n  filter: StringifyOptions['filter'],\n  sort: StringifyOptions['sort'],\n  allowDots: StringifyOptions['allowDots'],\n  serializeDate: StringifyOptions['serializeDate'],\n  format: StringifyOptions['format'],\n  formatter: StringifyOptions['formatter'],\n  encodeValuesOnly: boolean,\n  charset: StringifyOptions['charset'],\n  sideChannel: WeakMap<any, any>,\n) {\n  let obj = object;\n\n  let tmp_sc = sideChannel;\n  let step = 0;\n  let find_flag = false;\n  while ((tmp_sc = tmp_sc.get(sentinel)) !== void undefined && !find_flag) {\n    // Where object last appeared in the ref tree\n    const pos = tmp_sc.get(object);\n    step += 1;\n    if (typeof pos !== 'undefined') {\n      if (pos === step) {\n        throw new RangeError('Cyclic object value');\n      } else {\n        find_flag = true; // Break while\n      }\n    }\n    if (typeof tmp_sc.get(sentinel) === 'undefined') {\n      step = 0;\n    }\n  }\n\n  if (typeof filter === 'function') {\n    obj = filter(prefix, obj);\n  } else if (obj instanceof Date) {\n    obj = serializeDate?.(obj);\n  } else if (generateArrayPrefix === 'comma' && isArray(obj)) {\n    obj = maybe_map(obj, function (value) {\n      if (value instanceof Date) {\n        return serializeDate?.(value);\n      }\n      return value;\n    });\n  }\n\n  if (obj === null) {\n    if (strictNullHandling) {\n      return encoder && !encodeValuesOnly ?\n          // @ts-expect-error\n          encoder(prefix, defaults.encoder, charset, 'key', format)\n        : prefix;\n    }\n\n    obj = '';\n  }\n\n  if (is_non_nullish_primitive(obj) || is_buffer(obj)) {\n    if (encoder) {\n      const key_value =\n        encodeValuesOnly ? prefix\n          // @ts-expect-error\n        : encoder(prefix, defaults.encoder, charset, 'key', format);\n      return [\n        formatter?.(key_value) +\n          '=' +\n          // @ts-expect-error\n          formatter?.(encoder(obj, defaults.encoder, charset, 'value', format)),\n      ];\n    }\n    return [formatter?.(prefix) + '=' + formatter?.(String(obj))];\n  }\n\n  const values: string[] = [];\n\n  if (typeof obj === 'undefined') {\n    return values;\n  }\n\n  let obj_keys;\n  if (generateArrayPrefix === 'comma' && isArray(obj)) {\n    // we need to join elements in\n    if (encodeValuesOnly && encoder) {\n      // @ts-expect-error values only\n      obj = maybe_map(obj, encoder);\n    }\n    obj_keys = [{ value: obj.length > 0 ? obj.join(',') || null : void undefined }];\n  } else if (isArray(filter)) {\n    obj_keys = filter;\n  } else {\n    const keys = Object.keys(obj);\n    obj_keys = sort ? keys.sort(sort) : keys;\n  }\n\n  const encoded_prefix = encodeDotInKeys ? String(prefix).replace(/\\./g, '%2E') : String(prefix);\n\n  const adjusted_prefix =\n    commaRoundTrip && isArray(obj) && obj.length === 1 ? encoded_prefix + '[]' : encoded_prefix;\n\n  if (allowEmptyArrays && isArray(obj) && obj.length === 0) {\n    return adjusted_prefix + '[]';\n  }\n\n  for (let j = 0; j < obj_keys.length; ++j) {\n    const key = obj_keys[j];\n    const value =\n      // @ts-ignore\n      typeof key === 'object' && typeof key.value !== 'undefined' ? key.value : obj[key as any];\n\n    if (skipNulls && value === null) {\n      continue;\n    }\n\n    // @ts-ignore\n    const encoded_key = allowDots && encodeDotInKeys ? (key as any).replace(/\\./g, '%2E') : key;\n    const key_prefix =\n      isArray(obj) ?\n        typeof generateArrayPrefix === 'function' ?\n          generateArrayPrefix(adjusted_prefix, encoded_key)\n        : adjusted_prefix\n      : adjusted_prefix + (allowDots ? '.' + encoded_key : '[' + encoded_key + ']');\n\n    sideChannel.set(object, step);\n    const valueSideChannel = new WeakMap();\n    valueSideChannel.set(sentinel, sideChannel);\n    push_to_array(\n      values,\n      inner_stringify(\n        value,\n        key_prefix,\n        generateArrayPrefix,\n        commaRoundTrip,\n        allowEmptyArrays,\n        strictNullHandling,\n        skipNulls,\n        encodeDotInKeys,\n        // @ts-ignore\n        generateArrayPrefix === 'comma' && encodeValuesOnly && isArray(obj) ? null : encoder,\n        filter,\n        sort,\n        allowDots,\n        serializeDate,\n        format,\n        formatter,\n        encodeValuesOnly,\n        charset,\n        valueSideChannel,\n      ),\n    );\n  }\n\n  return values;\n}\n\nfunction normalize_stringify_options(\n  opts: StringifyOptions = defaults,\n): NonNullableProperties<Omit<StringifyOptions, 'indices'>> & { indices?: boolean } {\n  if (typeof opts.allowEmptyArrays !== 'undefined' && typeof opts.allowEmptyArrays !== 'boolean') {\n    throw new TypeError('`allowEmptyArrays` option can only be `true` or `false`, when provided');\n  }\n\n  if (typeof opts.encodeDotInKeys !== 'undefined' && typeof opts.encodeDotInKeys !== 'boolean') {\n    throw new TypeError('`encodeDotInKeys` option can only be `true` or `false`, when provided');\n  }\n\n  if (opts.encoder !== null && typeof opts.encoder !== 'undefined' && typeof opts.encoder !== 'function') {\n    throw new TypeError('Encoder has to be a function.');\n  }\n\n  const charset = opts.charset || defaults.charset;\n  if (typeof opts.charset !== 'undefined' && opts.charset !== 'utf-8' && opts.charset !== 'iso-8859-1') {\n    throw new TypeError('The charset option must be either utf-8, iso-8859-1, or undefined');\n  }\n\n  let format = default_format;\n  if (typeof opts.format !== 'undefined') {\n    if (!has(formatters, opts.format)) {\n      throw new TypeError('Unknown format option provided.');\n    }\n    format = opts.format;\n  }\n  const formatter = formatters[format];\n\n  let filter = defaults.filter;\n  if (typeof opts.filter === 'function' || isArray(opts.filter)) {\n    filter = opts.filter;\n  }\n\n  let arrayFormat: StringifyOptions['arrayFormat'];\n  if (opts.arrayFormat && opts.arrayFormat in array_prefix_generators) {\n    arrayFormat = opts.arrayFormat;\n  } else if ('indices' in opts) {\n    arrayFormat = opts.indices ? 'indices' : 'repeat';\n  } else {\n    arrayFormat = defaults.arrayFormat;\n  }\n\n  if ('commaRoundTrip' in opts && typeof opts.commaRoundTrip !== 'boolean') {\n    throw new TypeError('`commaRoundTrip` must be a boolean, or absent');\n  }\n\n  const allowDots =\n    typeof opts.allowDots === 'undefined' ?\n      !!opts.encodeDotInKeys === true ?\n        true\n      : defaults.allowDots\n    : !!opts.allowDots;\n\n  return {\n    addQueryPrefix: typeof opts.addQueryPrefix === 'boolean' ? opts.addQueryPrefix : defaults.addQueryPrefix,\n    // @ts-ignore\n    allowDots: allowDots,\n    allowEmptyArrays:\n      typeof opts.allowEmptyArrays === 'boolean' ? !!opts.allowEmptyArrays : defaults.allowEmptyArrays,\n    arrayFormat: arrayFormat,\n    charset: charset,\n    charsetSentinel:\n      typeof opts.charsetSentinel === 'boolean' ? opts.charsetSentinel : defaults.charsetSentinel,\n    commaRoundTrip: !!opts.commaRoundTrip,\n    delimiter: typeof opts.delimiter === 'undefined' ? defaults.delimiter : opts.delimiter,\n    encode: typeof opts.encode === 'boolean' ? opts.encode : defaults.encode,\n    encodeDotInKeys:\n      typeof opts.encodeDotInKeys === 'boolean' ? opts.encodeDotInKeys : defaults.encodeDotInKeys,\n    encoder: typeof opts.encoder === 'function' ? opts.encoder : defaults.encoder,\n    encodeValuesOnly:\n      typeof opts.encodeValuesOnly === 'boolean' ? opts.encodeValuesOnly : defaults.encodeValuesOnly,\n    filter: filter,\n    format: format,\n    formatter: formatter,\n    serializeDate: typeof opts.serializeDate === 'function' ? opts.serializeDate : defaults.serializeDate,\n    skipNulls: typeof opts.skipNulls === 'boolean' ? opts.skipNulls : defaults.skipNulls,\n    // @ts-ignore\n    sort: typeof opts.sort === 'function' ? opts.sort : null,\n    strictNullHandling:\n      typeof opts.strictNullHandling === 'boolean' ? opts.strictNullHandling : defaults.strictNullHandling,\n  };\n}\n\nexport function stringify(object: any, opts: StringifyOptions = {}) {\n  let obj = object;\n  const options = normalize_stringify_options(opts);\n\n  let obj_keys: PropertyKey[] | undefined;\n  let filter;\n\n  if (typeof options.filter === 'function') {\n    filter = options.filter;\n    obj = filter('', obj);\n  } else if (isArray(options.filter)) {\n    filter = options.filter;\n    obj_keys = filter;\n  }\n\n  const keys: string[] = [];\n\n  if (typeof obj !== 'object' || obj === null) {\n    return '';\n  }\n\n  const generateArrayPrefix = array_prefix_generators[options.arrayFormat];\n  const commaRoundTrip = generateArrayPrefix === 'comma' && options.commaRoundTrip;\n\n  if (!obj_keys) {\n    obj_keys = Object.keys(obj);\n  }\n\n  if (options.sort) {\n    obj_keys.sort(options.sort);\n  }\n\n  const sideChannel = new WeakMap();\n  for (let i = 0; i < obj_keys.length; ++i) {\n    const key = obj_keys[i]!;\n\n    if (options.skipNulls && obj[key] === null) {\n      continue;\n    }\n    push_to_array(\n      keys,\n      inner_stringify(\n        obj[key],\n        key,\n        // @ts-expect-error\n        generateArrayPrefix,\n        commaRoundTrip,\n        options.allowEmptyArrays,\n        options.strictNullHandling,\n        options.skipNulls,\n        options.encodeDotInKeys,\n        options.encode ? options.encoder : null,\n        options.filter,\n        options.sort,\n        options.allowDots,\n        options.serializeDate,\n        options.format,\n        options.formatter,\n        options.encodeValuesOnly,\n        options.charset,\n        sideChannel,\n      ),\n    );\n  }\n\n  const joined = keys.join(options.delimiter);\n  let prefix = options.addQueryPrefix === true ? '?' : '';\n\n  if (options.charsetSentinel) {\n    if (options.charset === 'iso-8859-1') {\n      // encodeURIComponent('&#10003;'), the \"numeric entity\" representation of a checkmark\n      prefix += 'utf8=%26%2310003%3B&';\n    } else {\n      // encodeURIComponent('')\n      prefix += 'utf8=%E2%9C%93&';\n    }\n  }\n\n  return joined.length > 0 ? prefix + joined : '';\n}\n","import { RFC1738 } from './formats';\nimport type { DefaultEncoder, Format } from './types';\nimport { isArray } from '../utils/values';\n\nexport let has = (obj: object, key: PropertyKey): boolean => (\n  (has = (Object as any).hasOwn ?? Function.prototype.call.bind(Object.prototype.hasOwnProperty)),\n  has(obj, key)\n);\n\nconst hex_table = /* @__PURE__ */ (() => {\n  const array = [];\n  for (let i = 0; i < 256; ++i) {\n    array.push('%' + ((i < 16 ? '0' : '') + i.toString(16)).toUpperCase());\n  }\n\n  return array;\n})();\n\nfunction compact_queue<T extends Record<string, any>>(queue: Array<{ obj: T; prop: string }>) {\n  while (queue.length > 1) {\n    const item = queue.pop();\n    if (!item) continue;\n\n    const obj = item.obj[item.prop];\n\n    if (isArray(obj)) {\n      const compacted: unknown[] = [];\n\n      for (let j = 0; j < obj.length; ++j) {\n        if (typeof obj[j] !== 'undefined') {\n          compacted.push(obj[j]);\n        }\n      }\n\n      // @ts-ignore\n      item.obj[item.prop] = compacted;\n    }\n  }\n}\n\nfunction array_to_object(source: any[], options: { plainObjects: boolean }) {\n  const obj = options && options.plainObjects ? Object.create(null) : {};\n  for (let i = 0; i < source.length; ++i) {\n    if (typeof source[i] !== 'undefined') {\n      obj[i] = source[i];\n    }\n  }\n\n  return obj;\n}\n\nexport function merge(\n  target: any,\n  source: any,\n  options: { plainObjects?: boolean; allowPrototypes?: boolean } = {},\n) {\n  if (!source) {\n    return target;\n  }\n\n  if (typeof source !== 'object') {\n    if (isArray(target)) {\n      target.push(source);\n    } else if (target && typeof target === 'object') {\n      if ((options && (options.plainObjects || options.allowPrototypes)) || !has(Object.prototype, source)) {\n        target[source] = true;\n      }\n    } else {\n      return [target, source];\n    }\n\n    return target;\n  }\n\n  if (!target || typeof target !== 'object') {\n    return [target].concat(source);\n  }\n\n  let mergeTarget = target;\n  if (isArray(target) && !isArray(source)) {\n    // @ts-ignore\n    mergeTarget = array_to_object(target, options);\n  }\n\n  if (isArray(target) && isArray(source)) {\n    source.forEach(function (item, i) {\n      if (has(target, i)) {\n        const targetItem = target[i];\n        if (targetItem && typeof targetItem === 'object' && item && typeof item === 'object') {\n          target[i] = merge(targetItem, item, options);\n        } else {\n          target.push(item);\n        }\n      } else {\n        target[i] = item;\n      }\n    });\n    return target;\n  }\n\n  return Object.keys(source).reduce(function (acc, key) {\n    const value = source[key];\n\n    if (has(acc, key)) {\n      acc[key] = merge(acc[key], value, options);\n    } else {\n      acc[key] = value;\n    }\n    return acc;\n  }, mergeTarget);\n}\n\nexport function assign_single_source(target: any, source: any) {\n  return Object.keys(source).reduce(function (acc, key) {\n    acc[key] = source[key];\n    return acc;\n  }, target);\n}\n\nexport function decode(str: string, _: any, charset: string) {\n  const strWithoutPlus = str.replace(/\\+/g, ' ');\n  if (charset === 'iso-8859-1') {\n    // unescape never throws, no try...catch needed:\n    return strWithoutPlus.replace(/%[0-9a-f]{2}/gi, unescape);\n  }\n  // utf-8\n  try {\n    return decodeURIComponent(strWithoutPlus);\n  } catch (e) {\n    return strWithoutPlus;\n  }\n}\n\nconst limit = 1024;\n\nexport const encode: (\n  str: any,\n  defaultEncoder: DefaultEncoder,\n  charset: string,\n  type: 'key' | 'value',\n  format: Format,\n) => string = (str, _defaultEncoder, charset, _kind, format: Format) => {\n  // This code was originally written by Brian White for the io.js core querystring library.\n  // It has been adapted here for stricter adherence to RFC 3986\n  if (str.length === 0) {\n    return str;\n  }\n\n  let string = str;\n  if (typeof str === 'symbol') {\n    string = Symbol.prototype.toString.call(str);\n  } else if (typeof str !== 'string') {\n    string = String(str);\n  }\n\n  if (charset === 'iso-8859-1') {\n    return escape(string).replace(/%u[0-9a-f]{4}/gi, function ($0) {\n      return '%26%23' + parseInt($0.slice(2), 16) + '%3B';\n    });\n  }\n\n  let out = '';\n  for (let j = 0; j < string.length; j += limit) {\n    const segment = string.length >= limit ? string.slice(j, j + limit) : string;\n    const arr = [];\n\n    for (let i = 0; i < segment.length; ++i) {\n      let c = segment.charCodeAt(i);\n      if (\n        c === 0x2d || // -\n        c === 0x2e || // .\n        c === 0x5f || // _\n        c === 0x7e || // ~\n        (c >= 0x30 && c <= 0x39) || // 0-9\n        (c >= 0x41 && c <= 0x5a) || // a-z\n        (c >= 0x61 && c <= 0x7a) || // A-Z\n        (format === RFC1738 && (c === 0x28 || c === 0x29)) // ( )\n      ) {\n        arr[arr.length] = segment.charAt(i);\n        continue;\n      }\n\n      if (c < 0x80) {\n        arr[arr.length] = hex_table[c];\n        continue;\n      }\n\n      if (c < 0x800) {\n        arr[arr.length] = hex_table[0xc0 | (c >> 6)]! + hex_table[0x80 | (c & 0x3f)];\n        continue;\n      }\n\n      if (c < 0xd800 || c >= 0xe000) {\n        arr[arr.length] =\n          hex_table[0xe0 | (c >> 12)]! + hex_table[0x80 | ((c >> 6) & 0x3f)] + hex_table[0x80 | (c & 0x3f)];\n        continue;\n      }\n\n      i += 1;\n      c = 0x10000 + (((c & 0x3ff) << 10) | (segment.charCodeAt(i) & 0x3ff));\n\n      arr[arr.length] =\n        hex_table[0xf0 | (c >> 18)]! +\n        hex_table[0x80 | ((c >> 12) & 0x3f)] +\n        hex_table[0x80 | ((c >> 6) & 0x3f)] +\n        hex_table[0x80 | (c & 0x3f)];\n    }\n\n    out += arr.join('');\n  }\n\n  return out;\n};\n\nexport function compact(value: any) {\n  const queue = [{ obj: { o: value }, prop: 'o' }];\n  const refs = [];\n\n  for (let i = 0; i < queue.length; ++i) {\n    const item = queue[i];\n    // @ts-ignore\n    const obj = item.obj[item.prop];\n\n    const keys = Object.keys(obj);\n    for (let j = 0; j < keys.length; ++j) {\n      const key = keys[j]!;\n      const val = obj[key];\n      if (typeof val === 'object' && val !== null && refs.indexOf(val) === -1) {\n        queue.push({ obj: obj, prop: key });\n        refs.push(val);\n      }\n    }\n  }\n\n  compact_queue(queue);\n\n  return value;\n}\n\nexport function is_regexp(obj: any) {\n  return Object.prototype.toString.call(obj) === '[object RegExp]';\n}\n\nexport function is_buffer(obj: any) {\n  if (!obj || typeof obj !== 'object') {\n    return false;\n  }\n\n  return !!(obj.constructor && obj.constructor.isBuffer && obj.constructor.isBuffer(obj));\n}\n\nexport function combine(a: any, b: any) {\n  return [].concat(a, b);\n}\n\nexport function maybe_map<T>(val: T[], fn: (v: T) => T) {\n  if (isArray(val)) {\n    const mapped = [];\n    for (let i = 0; i < val.length; i += 1) {\n      mapped.push(fn(val[i]!));\n    }\n    return mapped;\n  }\n  return fn(val);\n}\n","import { BlobPart, getName, makeFile, isAsyncIterable } from './uploads';\nimport type { FilePropertyBag } from './builtin-types';\nimport { checkFileSupport } from './uploads';\n\ntype BlobLikePart = string | ArrayBuffer | ArrayBufferView | BlobLike | DataView;\n\n/**\n * Intended to match DOM Blob, node-fetch Blob, node:buffer Blob, etc.\n * Don't add arrayBuffer here, node-fetch doesn't have it\n */\ninterface BlobLike {\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/size) */\n  readonly size: number;\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/type) */\n  readonly type: string;\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/text) */\n  text(): Promise<string>;\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/slice) */\n  slice(start?: number, end?: number): BlobLike;\n}\n\n/**\n * This check adds the arrayBuffer() method type because it is available and used at runtime\n */\nconst isBlobLike = (value: any): value is BlobLike & { arrayBuffer(): Promise<ArrayBuffer> } =>\n  value != null &&\n  typeof value === 'object' &&\n  typeof value.size === 'number' &&\n  typeof value.type === 'string' &&\n  typeof value.text === 'function' &&\n  typeof value.slice === 'function' &&\n  typeof value.arrayBuffer === 'function';\n\n/**\n * Intended to match DOM File, node:buffer File, undici File, etc.\n */\ninterface FileLike extends BlobLike {\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/File/lastModified) */\n  readonly lastModified: number;\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/File/name) */\n  readonly name?: string | undefined;\n}\n\n/**\n * This check adds the arrayBuffer() method type because it is available and used at runtime\n */\nconst isFileLike = (value: any): value is FileLike & { arrayBuffer(): Promise<ArrayBuffer> } =>\n  value != null &&\n  typeof value === 'object' &&\n  typeof value.name === 'string' &&\n  typeof value.lastModified === 'number' &&\n  isBlobLike(value);\n\n/**\n * Intended to match DOM Response, node-fetch Response, undici Response, etc.\n */\nexport interface ResponseLike {\n  url: string;\n  blob(): Promise<BlobLike>;\n}\n\nconst isResponseLike = (value: any): value is ResponseLike =>\n  value != null &&\n  typeof value === 'object' &&\n  typeof value.url === 'string' &&\n  typeof value.blob === 'function';\n\nexport type ToFileInput =\n  | FileLike\n  | ResponseLike\n  | Exclude<BlobLikePart, string>\n  | AsyncIterable<BlobLikePart>;\n\n/**\n * Helper for creating a {@link File} to pass to an SDK upload method from a variety of different data formats\n * @param value the raw content of the file. Can be an {@link Uploadable}, BlobLikePart, or AsyncIterable of BlobLikeParts\n * @param {string=} name the name of the file. If omitted, toFile will try to determine a file name from bits if possible\n * @param {Object=} options additional properties\n * @param {string=} options.type the MIME type of the content\n * @param {number=} options.lastModified the last modified timestamp\n * @returns a {@link File} with the given properties\n */\nexport async function toFile(\n  value: ToFileInput | PromiseLike<ToFileInput>,\n  name?: string | null | undefined,\n  options?: FilePropertyBag | undefined,\n): Promise<File> {\n  checkFileSupport();\n\n  // If it's a promise, resolve it.\n  value = await value;\n\n  // If we've been given a `File` we don't need to do anything\n  if (isFileLike(value)) {\n    if (value instanceof File) {\n      return value;\n    }\n    return makeFile([await value.arrayBuffer()], value.name);\n  }\n\n  if (isResponseLike(value)) {\n    const blob = await value.blob();\n    name ||= new URL(value.url).pathname.split(/[\\\\/]/).pop();\n\n    return makeFile(await getBytes(blob), name, options);\n  }\n\n  const parts = await getBytes(value);\n\n  name ||= getName(value);\n\n  if (!options?.type) {\n    const type = parts.find((part) => typeof part === 'object' && 'type' in part && part.type);\n    if (typeof type === 'string') {\n      options = { ...options, type };\n    }\n  }\n\n  return makeFile(parts, name, options);\n}\n\nasync function getBytes(value: BlobLikePart | AsyncIterable<BlobLikePart>): Promise<Array<BlobPart>> {\n  let parts: Array<BlobPart> = [];\n  if (\n    typeof value === 'string' ||\n    ArrayBuffer.isView(value) || // includes Uint8Array, Buffer, etc.\n    value instanceof ArrayBuffer\n  ) {\n    parts.push(value);\n  } else if (isBlobLike(value)) {\n    parts.push(value instanceof Blob ? value : await value.arrayBuffer());\n  } else if (\n    isAsyncIterable(value) // includes Readable, ReadableStream, etc.\n  ) {\n    for await (const chunk of value) {\n      parts.push(...(await getBytes(chunk as BlobLikePart))); // TODO, consider validating?\n    }\n  } else {\n    const constructor = value?.constructor?.name;\n    throw new Error(\n      `Unexpected data type: ${typeof value}${\n        constructor ? `; constructor: ${constructor}` : ''\n      }${propsForError(value)}`,\n    );\n  }\n\n  return parts;\n}\n\nfunction propsForError(value: unknown): string {\n  if (typeof value !== 'object' || value === null) return '';\n  const props = Object.getOwnPropertyNames(value);\n  return `; props: [${props.map((p) => `\"${p}\"`).join(', ')}]`;\n}\n","export const VERSION = '6.8.1'; // x-release-please-version\n","import { OpenAIError } from '../../core/error';\n\n/**\n * Percent-encode everything that isn't safe to have in a path without encoding safe chars.\n *\n * Taken from https://datatracker.ietf.org/doc/html/rfc3986#section-3.3:\n * > unreserved  = ALPHA / DIGIT / \"-\" / \".\" / \"_\" / \"~\"\n * > sub-delims  = \"!\" / \"$\" / \"&\" / \"'\" / \"(\" / \")\" / \"*\" / \"+\" / \",\" / \";\" / \"=\"\n * > pchar       = unreserved / pct-encoded / sub-delims / \":\" / \"@\"\n */\nexport function encodeURIPath(str: string) {\n  return str.replace(/[^A-Za-z0-9\\-._~!$&'()*+,;=:@]+/g, encodeURIComponent);\n}\n\nconst EMPTY = /* @__PURE__ */ Object.freeze(/* @__PURE__ */ Object.create(null));\n\nexport const createPathTagFunction = (pathEncoder = encodeURIPath) =>\n  function path(statics: readonly string[], ...params: readonly unknown[]): string {\n    // If there are no params, no processing is needed.\n    if (statics.length === 1) return statics[0]!;\n\n    let postPath = false;\n    const invalidSegments = [];\n    const path = statics.reduce((previousValue, currentValue, index) => {\n      if (/[?#]/.test(currentValue)) {\n        postPath = true;\n      }\n      const value = params[index];\n      let encoded = (postPath ? encodeURIComponent : pathEncoder)('' + value);\n      if (\n        index !== params.length &&\n        (value == null ||\n          (typeof value === 'object' &&\n            // handle values from other realms\n            value.toString ===\n              Object.getPrototypeOf(Object.getPrototypeOf((value as any).hasOwnProperty ?? EMPTY) ?? EMPTY)\n                ?.toString))\n      ) {\n        encoded = value + '';\n        invalidSegments.push({\n          start: previousValue.length + currentValue.length,\n          length: encoded.length,\n          error: `Value of type ${Object.prototype.toString\n            .call(value)\n            .slice(8, -1)} is not a valid path parameter`,\n        });\n      }\n      return previousValue + currentValue + (index === params.length ? '' : encoded);\n    }, '');\n\n    const pathOnly = path.split(/[?#]/, 1)[0]!;\n    const invalidSegmentPattern = /(?<=^|\\/)(?:\\.|%2e){1,2}(?=\\/|$)/gi;\n    let match;\n\n    // Find all invalid segments\n    while ((match = invalidSegmentPattern.exec(pathOnly)) !== null) {\n      invalidSegments.push({\n        start: match.index,\n        length: match[0].length,\n        error: `Value \"${match[0]}\" can\\'t be safely passed as a path parameter`,\n      });\n    }\n\n    invalidSegments.sort((a, b) => a.start - b.start);\n\n    if (invalidSegments.length > 0) {\n      let lastEnd = 0;\n      const underline = invalidSegments.reduce((acc, segment) => {\n        const spaces = ' '.repeat(segment.start - lastEnd);\n        const arrows = '^'.repeat(segment.length);\n        lastEnd = segment.start + segment.length;\n        return acc + spaces + arrows;\n      }, '');\n\n      throw new OpenAIError(\n        `Path parameters result in path with invalid segments:\\n${invalidSegments\n          .map((e) => e.error)\n          .join('\\n')}\\n${path}\\n${underline}`,\n      );\n    }\n\n    return path;\n  };\n\n/**\n * URI-encodes path params and ensures no unsafe /./ or /../ path segments are introduced.\n */\nexport const path = /* @__PURE__ */ createPathTagFunction(encodeURIPath);\n","import { OpenAIError } from '../error';\nimport type { ChatCompletionTool } from '../resources/chat/completions';\nimport {\n  ResponseTextConfig,\n  type FunctionTool,\n  type ParsedContent,\n  type ParsedResponse,\n  type ParsedResponseFunctionToolCall,\n  type ParsedResponseOutputItem,\n  type Response,\n  type ResponseCreateParamsBase,\n  type ResponseCreateParamsNonStreaming,\n  type ResponseFunctionToolCall,\n  type Tool,\n} from '../resources/responses/responses';\nimport { type AutoParseableTextFormat, isAutoParsableResponseFormat } from '../lib/parser';\n\nexport type ParseableToolsParams = Array<Tool> | ChatCompletionTool | null;\n\nexport type ResponseCreateParamsWithTools = ResponseCreateParamsBase & {\n  tools?: ParseableToolsParams;\n};\n\ntype TextConfigParams = { text?: ResponseTextConfig };\n\nexport type ExtractParsedContentFromParams<Params extends TextConfigParams> =\n  NonNullable<Params['text']>['format'] extends AutoParseableTextFormat<infer P> ? P : null;\n\nexport function maybeParseResponse<\n  Params extends ResponseCreateParamsBase | null,\n  ParsedT = Params extends null ? null : ExtractParsedContentFromParams<NonNullable<Params>>,\n>(response: Response, params: Params): ParsedResponse<ParsedT> {\n  if (!params || !hasAutoParseableInput(params)) {\n    return {\n      ...response,\n      output_parsed: null,\n      output: response.output.map((item) => {\n        if (item.type === 'function_call') {\n          return {\n            ...item,\n            parsed_arguments: null,\n          };\n        }\n\n        if (item.type === 'message') {\n          return {\n            ...item,\n            content: item.content.map((content) => ({\n              ...content,\n              parsed: null,\n            })),\n          };\n        } else {\n          return item;\n        }\n      }),\n    };\n  }\n\n  return parseResponse(response, params);\n}\n\nexport function parseResponse<\n  Params extends ResponseCreateParamsBase,\n  ParsedT = ExtractParsedContentFromParams<Params>,\n>(response: Response, params: Params): ParsedResponse<ParsedT> {\n  const output: Array<ParsedResponseOutputItem<ParsedT>> = response.output.map(\n    (item): ParsedResponseOutputItem<ParsedT> => {\n      if (item.type === 'function_call') {\n        return {\n          ...item,\n          parsed_arguments: parseToolCall(params, item),\n        };\n      }\n      if (item.type === 'message') {\n        const content: Array<ParsedContent<ParsedT>> = item.content.map((content) => {\n          if (content.type === 'output_text') {\n            return {\n              ...content,\n              parsed: parseTextFormat(params, content.text),\n            };\n          }\n\n          return content;\n        });\n\n        return {\n          ...item,\n          content,\n        };\n      }\n\n      return item;\n    },\n  );\n\n  const parsed: Omit<ParsedResponse<ParsedT>, 'output_parsed'> = Object.assign({}, response, { output });\n  if (!Object.getOwnPropertyDescriptor(response, 'output_text')) {\n    addOutputText(parsed);\n  }\n\n  Object.defineProperty(parsed, 'output_parsed', {\n    enumerable: true,\n    get() {\n      for (const output of parsed.output) {\n        if (output.type !== 'message') {\n          continue;\n        }\n\n        for (const content of output.content) {\n          if (content.type === 'output_text' && content.parsed !== null) {\n            return content.parsed;\n          }\n        }\n      }\n\n      return null;\n    },\n  });\n\n  return parsed as ParsedResponse<ParsedT>;\n}\n\nfunction parseTextFormat<\n  Params extends ResponseCreateParamsBase,\n  ParsedT = ExtractParsedContentFromParams<Params>,\n>(params: Params, content: string): ParsedT | null {\n  if (params.text?.format?.type !== 'json_schema') {\n    return null;\n  }\n\n  if ('$parseRaw' in params.text?.format) {\n    const text_format = params.text?.format as unknown as AutoParseableTextFormat<ParsedT>;\n    return text_format.$parseRaw(content);\n  }\n\n  return JSON.parse(content);\n}\n\nexport function hasAutoParseableInput(params: ResponseCreateParamsWithTools): boolean {\n  if (isAutoParsableResponseFormat(params.text?.format)) {\n    return true;\n  }\n\n  return false;\n}\n\ntype ToolOptions = {\n  name: string;\n  arguments: any;\n  function?: ((args: any) => any) | undefined;\n};\n\nexport type AutoParseableResponseTool<\n  OptionsT extends ToolOptions,\n  HasFunction = OptionsT['function'] extends Function ? true : false,\n> = FunctionTool & {\n  __arguments: OptionsT['arguments']; // type-level only\n  __name: OptionsT['name']; // type-level only\n\n  $brand: 'auto-parseable-tool';\n  $callback: ((args: OptionsT['arguments']) => any) | undefined;\n  $parseRaw(args: string): OptionsT['arguments'];\n};\n\nexport function makeParseableResponseTool<OptionsT extends ToolOptions>(\n  tool: FunctionTool,\n  {\n    parser,\n    callback,\n  }: {\n    parser: (content: string) => OptionsT['arguments'];\n    callback: ((args: any) => any) | undefined;\n  },\n): AutoParseableResponseTool<OptionsT['arguments']> {\n  const obj = { ...tool };\n\n  Object.defineProperties(obj, {\n    $brand: {\n      value: 'auto-parseable-tool',\n      enumerable: false,\n    },\n    $parseRaw: {\n      value: parser,\n      enumerable: false,\n    },\n    $callback: {\n      value: callback,\n      enumerable: false,\n    },\n  });\n\n  return obj as AutoParseableResponseTool<OptionsT['arguments']>;\n}\n\nexport function isAutoParsableTool(tool: any): tool is AutoParseableResponseTool<any> {\n  return tool?.['$brand'] === 'auto-parseable-tool';\n}\n\nfunction getInputToolByName(input_tools: Array<Tool>, name: string): FunctionTool | undefined {\n  return input_tools.find((tool) => tool.type === 'function' && tool.name === name) as\n    | FunctionTool\n    | undefined;\n}\n\nfunction parseToolCall<Params extends ResponseCreateParamsBase>(\n  params: Params,\n  toolCall: ResponseFunctionToolCall,\n): ParsedResponseFunctionToolCall {\n  const inputTool = getInputToolByName(params.tools ?? [], toolCall.name);\n\n  return {\n    ...toolCall,\n    ...toolCall,\n    parsed_arguments:\n      isAutoParsableTool(inputTool) ? inputTool.$parseRaw(toolCall.arguments)\n      : inputTool?.strict ? JSON.parse(toolCall.arguments)\n      : null,\n  };\n}\n\nexport function shouldParseToolCall(\n  params: ResponseCreateParamsNonStreaming | null | undefined,\n  toolCall: ResponseFunctionToolCall,\n): boolean {\n  if (!params) {\n    return false;\n  }\n\n  const inputTool = getInputToolByName(params.tools ?? [], toolCall.name);\n  return isAutoParsableTool(inputTool) || inputTool?.strict || false;\n}\n\nexport function validateInputTools(tools: ChatCompletionTool[] | undefined) {\n  for (const tool of tools ?? []) {\n    if (tool.type !== 'function') {\n      throw new OpenAIError(\n        `Currently only \\`function\\` tool types support auto-parsing; Received \\`${tool.type}\\``,\n      );\n    }\n\n    if (tool.function.strict !== true) {\n      throw new OpenAIError(\n        `The \\`${tool.function.name}\\` tool is not marked with \\`strict: true\\`. Only strict function tools can be auto-parsed`,\n      );\n    }\n  }\n}\n\nexport function addOutputText(rsp: Response): void {\n  const texts: string[] = [];\n  for (const output of rsp.output) {\n    if (output.type !== 'message') {\n      continue;\n    }\n\n    for (const content of output.content) {\n      if (content.type === 'output_text') {\n        texts.push(content.text);\n      }\n    }\n  }\n\n  rsp.output_text = texts.join('');\n}\n","import type { RequestInit } from './internal/builtin-types';\nimport type { NullableHeaders } from './internal/headers';\nimport { buildHeaders } from './internal/headers';\nimport * as Errors from './error';\nimport { FinalRequestOptions } from './internal/request-options';\nimport { isObj, readEnv } from './internal/utils';\nimport { ClientOptions, OpenAI } from './client';\n\n/** API Client for interfacing with the Azure OpenAI API. */\nexport interface AzureClientOptions extends ClientOptions {\n  /**\n   * Defaults to process.env['OPENAI_API_VERSION'].\n   */\n  apiVersion?: string | undefined;\n\n  /**\n   * Your Azure endpoint, including the resource, e.g. `https://example-resource.azure.openai.com/`\n   */\n  endpoint?: string | undefined;\n\n  /**\n   * A model deployment, if given, sets the base client URL to include `/deployments/{deployment}`.\n   * Note: this means you won't be able to use non-deployment endpoints. Not supported with Assistants APIs.\n   */\n  deployment?: string | undefined;\n\n  /**\n   * Defaults to process.env['AZURE_OPENAI_API_KEY'].\n   */\n  apiKey?: string | undefined;\n\n  /**\n   * A function that returns an access token for Microsoft Entra (formerly known as Azure Active Directory),\n   * which will be invoked on every request.\n   */\n  azureADTokenProvider?: (() => Promise<string>) | undefined;\n}\n\n/** API Client for interfacing with the Azure OpenAI API. */\nexport class AzureOpenAI extends OpenAI {\n  deploymentName: string | undefined;\n  apiVersion: string = '';\n\n  /**\n   * API Client for interfacing with the Azure OpenAI API.\n   *\n   * @param {string | undefined} [opts.apiVersion=process.env['OPENAI_API_VERSION'] ?? undefined]\n   * @param {string | undefined} [opts.endpoint=process.env['AZURE_OPENAI_ENDPOINT'] ?? undefined] - Your Azure endpoint, including the resource, e.g. `https://example-resource.azure.openai.com/`\n   * @param {string | undefined} [opts.apiKey=process.env['AZURE_OPENAI_API_KEY'] ?? undefined]\n   * @param {string | undefined} opts.deployment - A model deployment, if given, sets the base client URL to include `/deployments/{deployment}`.\n   * @param {string | null | undefined} [opts.organization=process.env['OPENAI_ORG_ID'] ?? null]\n   * @param {string} [opts.baseURL=process.env['OPENAI_BASE_URL']] - Sets the base URL for the API, e.g. `https://example-resource.azure.openai.com/openai/`.\n   * @param {number} [opts.timeout=10 minutes] - The maximum amount of time (in milliseconds) the client will wait for a response before timing out.\n   * @param {number} [opts.httpAgent] - An HTTP agent used to manage HTTP(s) connections.\n   * @param {Fetch} [opts.fetch] - Specify a custom `fetch` function implementation.\n   * @param {number} [opts.maxRetries=2] - The maximum number of times the client will retry a request.\n   * @param {Headers} opts.defaultHeaders - Default headers to include with every request to the API.\n   * @param {DefaultQuery} opts.defaultQuery - Default query parameters to include with every request to the API.\n   * @param {boolean} [opts.dangerouslyAllowBrowser=false] - By default, client-side use of this library is not allowed, as it risks exposing your secret API credentials to attackers.\n   */\n  constructor({\n    baseURL = readEnv('OPENAI_BASE_URL'),\n    apiKey = readEnv('AZURE_OPENAI_API_KEY'),\n    apiVersion = readEnv('OPENAI_API_VERSION'),\n    endpoint,\n    deployment,\n    azureADTokenProvider,\n    dangerouslyAllowBrowser,\n    ...opts\n  }: AzureClientOptions = {}) {\n    if (!apiVersion) {\n      throw new Errors.OpenAIError(\n        \"The OPENAI_API_VERSION environment variable is missing or empty; either provide it, or instantiate the AzureOpenAI client with an apiVersion option, like new AzureOpenAI({ apiVersion: 'My API Version' }).\",\n      );\n    }\n\n    if (typeof azureADTokenProvider === 'function') {\n      dangerouslyAllowBrowser = true;\n    }\n\n    if (!azureADTokenProvider && !apiKey) {\n      throw new Errors.OpenAIError(\n        'Missing credentials. Please pass one of `apiKey` and `azureADTokenProvider`, or set the `AZURE_OPENAI_API_KEY` environment variable.',\n      );\n    }\n\n    if (azureADTokenProvider && apiKey) {\n      throw new Errors.OpenAIError(\n        'The `apiKey` and `azureADTokenProvider` arguments are mutually exclusive; only one can be passed at a time.',\n      );\n    }\n\n    opts.defaultQuery = { ...opts.defaultQuery, 'api-version': apiVersion };\n\n    if (!baseURL) {\n      if (!endpoint) {\n        endpoint = process.env['AZURE_OPENAI_ENDPOINT'];\n      }\n\n      if (!endpoint) {\n        throw new Errors.OpenAIError(\n          'Must provide one of the `baseURL` or `endpoint` arguments, or the `AZURE_OPENAI_ENDPOINT` environment variable',\n        );\n      }\n\n      baseURL = `${endpoint}/openai`;\n    } else {\n      if (endpoint) {\n        throw new Errors.OpenAIError('baseURL and endpoint are mutually exclusive');\n      }\n    }\n\n    super({\n      apiKey: azureADTokenProvider ?? apiKey,\n      baseURL,\n      ...opts,\n      ...(dangerouslyAllowBrowser !== undefined ? { dangerouslyAllowBrowser } : {}),\n    });\n\n    this.apiVersion = apiVersion;\n    this.deploymentName = deployment;\n  }\n\n  override async buildRequest(\n    options: FinalRequestOptions,\n    props: { retryCount?: number } = {},\n  ): Promise<{ req: RequestInit & { headers: Headers }; url: string; timeout: number }> {\n    if (_deployments_endpoints.has(options.path) && options.method === 'post' && options.body !== undefined) {\n      if (!isObj(options.body)) {\n        throw new Error('Expected request body to be an object');\n      }\n      const model = this.deploymentName || options.body['model'] || options.__metadata?.['model'];\n      if (model !== undefined && !this.baseURL.includes('/deployments')) {\n        options.path = `/deployments/${model}${options.path}`;\n      }\n    }\n    return super.buildRequest(options, props);\n  }\n\n  protected override async authHeaders(opts: FinalRequestOptions): Promise<NullableHeaders | undefined> {\n    if (typeof this._options.apiKey === 'string') {\n      return buildHeaders([{ 'api-key': this.apiKey }]);\n    }\n    return super.authHeaders(opts);\n  }\n}\n\nconst _deployments_endpoints = new Set([\n  '/completions',\n  '/chat/completions',\n  '/embeddings',\n  '/audio/transcriptions',\n  '/audio/translations',\n  '/audio/speech',\n  '/images/generations',\n  '/batches',\n  '/images/edits',\n]);\n","import type { Format } from './types';\n\nexport const default_format: Format = 'RFC3986';\nexport const default_formatter = (v: PropertyKey) => String(v);\nexport const formatters: Record<Format, (str: PropertyKey) => string> = {\n  RFC1738: (v: PropertyKey) => String(v).replace(/%20/g, '+'),\n  RFC3986: default_formatter,\n};\nexport const RFC1738 = 'RFC1738';\nexport const RFC3986 = 'RFC3986';\n","import {\n  type ChatCompletionAssistantMessageParam,\n  type ChatCompletionMessageParam,\n  type ChatCompletionToolMessageParam,\n} from '../resources';\n\nexport const isAssistantMessage = (\n  message: ChatCompletionMessageParam | null | undefined,\n): message is ChatCompletionAssistantMessageParam => {\n  return message?.role === 'assistant';\n};\n\nexport const isToolMessage = (\n  message: ChatCompletionMessageParam | null | undefined,\n): message is ChatCompletionToolMessageParam => {\n  return message?.role === 'tool';\n};\n\nexport function isPresent<T>(obj: T | null | undefined): obj is T {\n  return obj != null;\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport { APIPromise } from '../../core/api-promise';\nimport { type Uploadable } from '../../core/uploads';\nimport { RequestOptions } from '../../internal/request-options';\nimport { multipartFormRequestOptions } from '../../internal/uploads';\nimport { path } from '../../internal/utils/path';\n\nexport class Parts extends APIResource {\n  /**\n   * Adds a\n   * [Part](https://platform.openai.com/docs/api-reference/uploads/part-object) to an\n   * [Upload](https://platform.openai.com/docs/api-reference/uploads/object) object.\n   * A Part represents a chunk of bytes from the file you are trying to upload.\n   *\n   * Each Part can be at most 64 MB, and you can add Parts until you hit the Upload\n   * maximum of 8 GB.\n   *\n   * It is possible to add multiple Parts in parallel. You can decide the intended\n   * order of the Parts when you\n   * [complete the Upload](https://platform.openai.com/docs/api-reference/uploads/complete).\n   */\n  create(uploadID: string, body: PartCreateParams, options?: RequestOptions): APIPromise<UploadPart> {\n    return this._client.post(\n      path`/uploads/${uploadID}/parts`,\n      multipartFormRequestOptions({ body, ...options }, this._client),\n    );\n  }\n}\n\n/**\n * The upload Part represents a chunk of bytes we can add to an Upload object.\n */\nexport interface UploadPart {\n  /**\n   * The upload Part unique identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the Part was created.\n   */\n  created_at: number;\n\n  /**\n   * The object type, which is always `upload.part`.\n   */\n  object: 'upload.part';\n\n  /**\n   * The ID of the Upload object that this Part was added to.\n   */\n  upload_id: string;\n}\n\nexport interface PartCreateParams {\n  /**\n   * The chunk of bytes for this Part.\n   */\n  data: Uploadable;\n}\n\nexport declare namespace Parts {\n  export { type UploadPart as UploadPart, type PartCreateParams as PartCreateParams };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport * as ThreadsAPI from './threads';\nimport { APIPromise } from '../../../core/api-promise';\nimport { buildHeaders } from '../../../internal/headers';\nimport { RequestOptions } from '../../../internal/request-options';\nimport { path } from '../../../internal/utils/path';\n\nexport class Sessions extends APIResource {\n  /**\n   * Create a ChatKit session\n   *\n   * @example\n   * ```ts\n   * const chatSession =\n   *   await client.beta.chatkit.sessions.create({\n   *     user: 'x',\n   *     workflow: { id: 'id' },\n   *   });\n   * ```\n   */\n  create(body: SessionCreateParams, options?: RequestOptions): APIPromise<ThreadsAPI.ChatSession> {\n    return this._client.post('/chatkit/sessions', {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'chatkit_beta=v1' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Cancel a ChatKit session\n   *\n   * @example\n   * ```ts\n   * const chatSession =\n   *   await client.beta.chatkit.sessions.cancel('cksess_123');\n   * ```\n   */\n  cancel(sessionID: string, options?: RequestOptions): APIPromise<ThreadsAPI.ChatSession> {\n    return this._client.post(path`/chatkit/sessions/${sessionID}/cancel`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'chatkit_beta=v1' }, options?.headers]),\n    });\n  }\n}\n\nexport interface SessionCreateParams {\n  /**\n   * A free-form string that identifies your end user; ensures this Session can\n   * access other objects that have the same `user` scope.\n   */\n  user: string;\n\n  /**\n   * Workflow that powers the session.\n   */\n  workflow: ThreadsAPI.ChatSessionWorkflowParam;\n\n  /**\n   * Optional overrides for ChatKit runtime configuration features\n   */\n  chatkit_configuration?: ThreadsAPI.ChatSessionChatKitConfigurationParam;\n\n  /**\n   * Optional override for session expiration timing in seconds from creation.\n   * Defaults to 10 minutes.\n   */\n  expires_after?: ThreadsAPI.ChatSessionExpiresAfterParam;\n\n  /**\n   * Optional override for per-minute request limits. When omitted, defaults to 10.\n   */\n  rate_limits?: ThreadsAPI.ChatSessionRateLimitsParam;\n}\n\nexport declare namespace Sessions {\n  export { type SessionCreateParams as SessionCreateParams };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { hasOwn } from './values';\nimport { type OpenAI } from '../../client';\nimport { RequestOptions } from '../request-options';\n\ntype LogFn = (message: string, ...rest: unknown[]) => void;\nexport type Logger = {\n  error: LogFn;\n  warn: LogFn;\n  info: LogFn;\n  debug: LogFn;\n};\nexport type LogLevel = 'off' | 'error' | 'warn' | 'info' | 'debug';\n\nconst levelNumbers = {\n  off: 0,\n  error: 200,\n  warn: 300,\n  info: 400,\n  debug: 500,\n};\n\nexport const parseLogLevel = (\n  maybeLevel: string | undefined,\n  sourceName: string,\n  client: OpenAI,\n): LogLevel | undefined => {\n  if (!maybeLevel) {\n    return undefined;\n  }\n  if (hasOwn(levelNumbers, maybeLevel)) {\n    return maybeLevel;\n  }\n  loggerFor(client).warn(\n    `${sourceName} was set to ${JSON.stringify(maybeLevel)}, expected one of ${JSON.stringify(\n      Object.keys(levelNumbers),\n    )}`,\n  );\n  return undefined;\n};\n\nfunction noop() {}\n\nfunction makeLogFn(fnLevel: keyof Logger, logger: Logger | undefined, logLevel: LogLevel) {\n  if (!logger || levelNumbers[fnLevel] > levelNumbers[logLevel]) {\n    return noop;\n  } else {\n    // Don't wrap logger functions, we want the stacktrace intact!\n    return logger[fnLevel].bind(logger);\n  }\n}\n\nconst noopLogger = {\n  error: noop,\n  warn: noop,\n  info: noop,\n  debug: noop,\n};\n\nlet cachedLoggers = /* @__PURE__ */ new WeakMap<Logger, [LogLevel, Logger]>();\n\nexport function loggerFor(client: OpenAI): Logger {\n  const logger = client.logger;\n  const logLevel = client.logLevel ?? 'off';\n  if (!logger) {\n    return noopLogger;\n  }\n\n  const cachedLogger = cachedLoggers.get(logger);\n  if (cachedLogger && cachedLogger[0] === logLevel) {\n    return cachedLogger[1];\n  }\n\n  const levelLogger = {\n    error: makeLogFn('error', logger, logLevel),\n    warn: makeLogFn('warn', logger, logLevel),\n    info: makeLogFn('info', logger, logLevel),\n    debug: makeLogFn('debug', logger, logLevel),\n  };\n\n  cachedLoggers.set(logger, [logLevel, levelLogger]);\n\n  return levelLogger;\n}\n\nexport const formatRequestDetails = (details: {\n  options?: RequestOptions | undefined;\n  headers?: Headers | Record<string, string> | undefined;\n  retryOfRequestLogID?: string | undefined;\n  retryOf?: string | undefined;\n  url?: string | undefined;\n  status?: number | undefined;\n  method?: string | undefined;\n  durationMs?: number | undefined;\n  message?: unknown;\n  body?: unknown;\n}) => {\n  if (details.options) {\n    details.options = { ...details.options };\n    delete details.options['headers']; // redundant + leaks internals\n  }\n  if (details.headers) {\n    details.headers = Object.fromEntries(\n      (details.headers instanceof Headers ? [...details.headers] : Object.entries(details.headers)).map(\n        ([name, value]) => [\n          name,\n          (\n            name.toLowerCase() === 'authorization' ||\n            name.toLowerCase() === 'cookie' ||\n            name.toLowerCase() === 'set-cookie'\n          ) ?\n            '***'\n          : value,\n        ],\n      ),\n    );\n  }\n  if ('retryOfRequestLogID' in details) {\n    if (details.retryOfRequestLogID) {\n      details.retryOf = details.retryOfRequestLogID;\n    }\n    delete details.retryOfRequestLogID;\n  }\n  return details;\n};\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport * as ChatKitAPI from './chatkit';\nimport { APIPromise } from '../../../core/api-promise';\nimport {\n  ConversationCursorPage,\n  type ConversationCursorPageParams,\n  PagePromise,\n} from '../../../core/pagination';\nimport { buildHeaders } from '../../../internal/headers';\nimport { RequestOptions } from '../../../internal/request-options';\nimport { path } from '../../../internal/utils/path';\n\nexport class Threads extends APIResource {\n  /**\n   * Retrieve a ChatKit thread\n   *\n   * @example\n   * ```ts\n   * const chatkitThread =\n   *   await client.beta.chatkit.threads.retrieve('cthr_123');\n   * ```\n   */\n  retrieve(threadID: string, options?: RequestOptions): APIPromise<ChatKitThread> {\n    return this._client.get(path`/chatkit/threads/${threadID}`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'chatkit_beta=v1' }, options?.headers]),\n    });\n  }\n\n  /**\n   * List ChatKit threads\n   *\n   * @example\n   * ```ts\n   * // Automatically fetches more pages as needed.\n   * for await (const chatkitThread of client.beta.chatkit.threads.list()) {\n   *   // ...\n   * }\n   * ```\n   */\n  list(\n    query: ThreadListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<ChatKitThreadsPage, ChatKitThread> {\n    return this._client.getAPIList('/chatkit/threads', ConversationCursorPage<ChatKitThread>, {\n      query,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'chatkit_beta=v1' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Delete a ChatKit thread\n   *\n   * @example\n   * ```ts\n   * const thread = await client.beta.chatkit.threads.delete(\n   *   'cthr_123',\n   * );\n   * ```\n   */\n  delete(threadID: string, options?: RequestOptions): APIPromise<ThreadDeleteResponse> {\n    return this._client.delete(path`/chatkit/threads/${threadID}`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'chatkit_beta=v1' }, options?.headers]),\n    });\n  }\n\n  /**\n   * List ChatKit thread items\n   *\n   * @example\n   * ```ts\n   * // Automatically fetches more pages as needed.\n   * for await (const thread of client.beta.chatkit.threads.listItems(\n   *   'cthr_123',\n   * )) {\n   *   // ...\n   * }\n   * ```\n   */\n  listItems(\n    threadID: string,\n    query: ThreadListItemsParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<\n    ChatKitThreadItemListDataPage,\n    | ChatKitThreadUserMessageItem\n    | ChatKitThreadAssistantMessageItem\n    | ChatKitWidgetItem\n    | ChatKitThreadItemList.ChatKitClientToolCall\n    | ChatKitThreadItemList.ChatKitTask\n    | ChatKitThreadItemList.ChatKitTaskGroup\n  > {\n    return this._client.getAPIList(\n      path`/chatkit/threads/${threadID}/items`,\n      ConversationCursorPage<\n        | ChatKitThreadUserMessageItem\n        | ChatKitThreadAssistantMessageItem\n        | ChatKitWidgetItem\n        | ChatKitThreadItemList.ChatKitClientToolCall\n        | ChatKitThreadItemList.ChatKitTask\n        | ChatKitThreadItemList.ChatKitTaskGroup\n      >,\n      { query, ...options, headers: buildHeaders([{ 'OpenAI-Beta': 'chatkit_beta=v1' }, options?.headers]) },\n    );\n  }\n}\n\nexport type ChatKitThreadsPage = ConversationCursorPage<ChatKitThread>;\n\nexport type ChatKitThreadItemListDataPage = ConversationCursorPage<\n  | ChatKitThreadUserMessageItem\n  | ChatKitThreadAssistantMessageItem\n  | ChatKitWidgetItem\n  | ChatKitThreadItemList.ChatKitClientToolCall\n  | ChatKitThreadItemList.ChatKitTask\n  | ChatKitThreadItemList.ChatKitTaskGroup\n>;\n\n/**\n * Represents a ChatKit session and its resolved configuration.\n */\nexport interface ChatSession {\n  /**\n   * Identifier for the ChatKit session.\n   */\n  id: string;\n\n  /**\n   * Resolved ChatKit feature configuration for the session.\n   */\n  chatkit_configuration: ChatSessionChatKitConfiguration;\n\n  /**\n   * Ephemeral client secret that authenticates session requests.\n   */\n  client_secret: string;\n\n  /**\n   * Unix timestamp (in seconds) for when the session expires.\n   */\n  expires_at: number;\n\n  /**\n   * Convenience copy of the per-minute request limit.\n   */\n  max_requests_per_1_minute: number;\n\n  /**\n   * Type discriminator that is always `chatkit.session`.\n   */\n  object: 'chatkit.session';\n\n  /**\n   * Resolved rate limit values.\n   */\n  rate_limits: ChatSessionRateLimits;\n\n  /**\n   * Current lifecycle state of the session.\n   */\n  status: ChatSessionStatus;\n\n  /**\n   * User identifier associated with the session.\n   */\n  user: string;\n\n  /**\n   * Workflow metadata for the session.\n   */\n  workflow: ChatKitAPI.ChatKitWorkflow;\n}\n\n/**\n * Automatic thread title preferences for the session.\n */\nexport interface ChatSessionAutomaticThreadTitling {\n  /**\n   * Whether automatic thread titling is enabled.\n   */\n  enabled: boolean;\n}\n\n/**\n * ChatKit configuration for the session.\n */\nexport interface ChatSessionChatKitConfiguration {\n  /**\n   * Automatic thread titling preferences.\n   */\n  automatic_thread_titling: ChatSessionAutomaticThreadTitling;\n\n  /**\n   * Upload settings for the session.\n   */\n  file_upload: ChatSessionFileUpload;\n\n  /**\n   * History retention configuration.\n   */\n  history: ChatSessionHistory;\n}\n\n/**\n * Optional per-session configuration settings for ChatKit behavior.\n */\nexport interface ChatSessionChatKitConfigurationParam {\n  /**\n   * Configuration for automatic thread titling. When omitted, automatic thread\n   * titling is enabled by default.\n   */\n  automatic_thread_titling?: ChatSessionChatKitConfigurationParam.AutomaticThreadTitling;\n\n  /**\n   * Configuration for upload enablement and limits. When omitted, uploads are\n   * disabled by default (max_files 10, max_file_size 512 MB).\n   */\n  file_upload?: ChatSessionChatKitConfigurationParam.FileUpload;\n\n  /**\n   * Configuration for chat history retention. When omitted, history is enabled by\n   * default with no limit on recent_threads (null).\n   */\n  history?: ChatSessionChatKitConfigurationParam.History;\n}\n\nexport namespace ChatSessionChatKitConfigurationParam {\n  /**\n   * Configuration for automatic thread titling. When omitted, automatic thread\n   * titling is enabled by default.\n   */\n  export interface AutomaticThreadTitling {\n    /**\n     * Enable automatic thread title generation. Defaults to true.\n     */\n    enabled?: boolean;\n  }\n\n  /**\n   * Configuration for upload enablement and limits. When omitted, uploads are\n   * disabled by default (max_files 10, max_file_size 512 MB).\n   */\n  export interface FileUpload {\n    /**\n     * Enable uploads for this session. Defaults to false.\n     */\n    enabled?: boolean;\n\n    /**\n     * Maximum size in megabytes for each uploaded file. Defaults to 512 MB, which is\n     * the maximum allowable size.\n     */\n    max_file_size?: number;\n\n    /**\n     * Maximum number of files that can be uploaded to the session. Defaults to 10.\n     */\n    max_files?: number;\n  }\n\n  /**\n   * Configuration for chat history retention. When omitted, history is enabled by\n   * default with no limit on recent_threads (null).\n   */\n  export interface History {\n    /**\n     * Enables chat users to access previous ChatKit threads. Defaults to true.\n     */\n    enabled?: boolean;\n\n    /**\n     * Number of recent ChatKit threads users have access to. Defaults to unlimited\n     * when unset.\n     */\n    recent_threads?: number;\n  }\n}\n\n/**\n * Controls when the session expires relative to an anchor timestamp.\n */\nexport interface ChatSessionExpiresAfterParam {\n  /**\n   * Base timestamp used to calculate expiration. Currently fixed to `created_at`.\n   */\n  anchor: 'created_at';\n\n  /**\n   * Number of seconds after the anchor when the session expires.\n   */\n  seconds: number;\n}\n\n/**\n * Upload permissions and limits applied to the session.\n */\nexport interface ChatSessionFileUpload {\n  /**\n   * Indicates if uploads are enabled for the session.\n   */\n  enabled: boolean;\n\n  /**\n   * Maximum upload size in megabytes.\n   */\n  max_file_size: number | null;\n\n  /**\n   * Maximum number of uploads allowed during the session.\n   */\n  max_files: number | null;\n}\n\n/**\n * History retention preferences returned for the session.\n */\nexport interface ChatSessionHistory {\n  /**\n   * Indicates if chat history is persisted for the session.\n   */\n  enabled: boolean;\n\n  /**\n   * Number of prior threads surfaced in history views. Defaults to null when all\n   * history is retained.\n   */\n  recent_threads: number | null;\n}\n\n/**\n * Active per-minute request limit for the session.\n */\nexport interface ChatSessionRateLimits {\n  /**\n   * Maximum allowed requests per one-minute window.\n   */\n  max_requests_per_1_minute: number;\n}\n\n/**\n * Controls request rate limits for the session.\n */\nexport interface ChatSessionRateLimitsParam {\n  /**\n   * Maximum number of requests allowed per minute for the session. Defaults to 10.\n   */\n  max_requests_per_1_minute?: number;\n}\n\nexport type ChatSessionStatus = 'active' | 'expired' | 'cancelled';\n\n/**\n * Workflow reference and overrides applied to the chat session.\n */\nexport interface ChatSessionWorkflowParam {\n  /**\n   * Identifier for the workflow invoked by the session.\n   */\n  id: string;\n\n  /**\n   * State variables forwarded to the workflow. Keys may be up to 64 characters,\n   * values must be primitive types, and the map defaults to an empty object.\n   */\n  state_variables?: { [key: string]: string | boolean | number };\n\n  /**\n   * Optional tracing overrides for the workflow invocation. When omitted, tracing is\n   * enabled by default.\n   */\n  tracing?: ChatSessionWorkflowParam.Tracing;\n\n  /**\n   * Specific workflow version to run. Defaults to the latest deployed version.\n   */\n  version?: string;\n}\n\nexport namespace ChatSessionWorkflowParam {\n  /**\n   * Optional tracing overrides for the workflow invocation. When omitted, tracing is\n   * enabled by default.\n   */\n  export interface Tracing {\n    /**\n     * Whether tracing is enabled during the session. Defaults to true.\n     */\n    enabled?: boolean;\n  }\n}\n\n/**\n * Attachment metadata included on thread items.\n */\nexport interface ChatKitAttachment {\n  /**\n   * Identifier for the attachment.\n   */\n  id: string;\n\n  /**\n   * MIME type of the attachment.\n   */\n  mime_type: string;\n\n  /**\n   * Original display name for the attachment.\n   */\n  name: string;\n\n  /**\n   * Preview URL for rendering the attachment inline.\n   */\n  preview_url: string | null;\n\n  /**\n   * Attachment discriminator.\n   */\n  type: 'image' | 'file';\n}\n\n/**\n * Assistant response text accompanied by optional annotations.\n */\nexport interface ChatKitResponseOutputText {\n  /**\n   * Ordered list of annotations attached to the response text.\n   */\n  annotations: Array<ChatKitResponseOutputText.File | ChatKitResponseOutputText.URL>;\n\n  /**\n   * Assistant generated text.\n   */\n  text: string;\n\n  /**\n   * Type discriminator that is always `output_text`.\n   */\n  type: 'output_text';\n}\n\nexport namespace ChatKitResponseOutputText {\n  /**\n   * Annotation that references an uploaded file.\n   */\n  export interface File {\n    /**\n     * File attachment referenced by the annotation.\n     */\n    source: File.Source;\n\n    /**\n     * Type discriminator that is always `file` for this annotation.\n     */\n    type: 'file';\n  }\n\n  export namespace File {\n    /**\n     * File attachment referenced by the annotation.\n     */\n    export interface Source {\n      /**\n       * Filename referenced by the annotation.\n       */\n      filename: string;\n\n      /**\n       * Type discriminator that is always `file`.\n       */\n      type: 'file';\n    }\n  }\n\n  /**\n   * Annotation that references a URL.\n   */\n  export interface URL {\n    /**\n     * URL referenced by the annotation.\n     */\n    source: URL.Source;\n\n    /**\n     * Type discriminator that is always `url` for this annotation.\n     */\n    type: 'url';\n  }\n\n  export namespace URL {\n    /**\n     * URL referenced by the annotation.\n     */\n    export interface Source {\n      /**\n       * Type discriminator that is always `url`.\n       */\n      type: 'url';\n\n      /**\n       * URL referenced by the annotation.\n       */\n      url: string;\n    }\n  }\n}\n\n/**\n * Represents a ChatKit thread and its current status.\n */\nexport interface ChatKitThread {\n  /**\n   * Identifier of the thread.\n   */\n  id: string;\n\n  /**\n   * Unix timestamp (in seconds) for when the thread was created.\n   */\n  created_at: number;\n\n  /**\n   * Type discriminator that is always `chatkit.thread`.\n   */\n  object: 'chatkit.thread';\n\n  /**\n   * Current status for the thread. Defaults to `active` for newly created threads.\n   */\n  status: ChatKitThread.Active | ChatKitThread.Locked | ChatKitThread.Closed;\n\n  /**\n   * Optional human-readable title for the thread. Defaults to null when no title has\n   * been generated.\n   */\n  title: string | null;\n\n  /**\n   * Free-form string that identifies your end user who owns the thread.\n   */\n  user: string;\n}\n\nexport namespace ChatKitThread {\n  /**\n   * Indicates that a thread is active.\n   */\n  export interface Active {\n    /**\n     * Status discriminator that is always `active`.\n     */\n    type: 'active';\n  }\n\n  /**\n   * Indicates that a thread is locked and cannot accept new input.\n   */\n  export interface Locked {\n    /**\n     * Reason that the thread was locked. Defaults to null when no reason is recorded.\n     */\n    reason: string | null;\n\n    /**\n     * Status discriminator that is always `locked`.\n     */\n    type: 'locked';\n  }\n\n  /**\n   * Indicates that a thread has been closed.\n   */\n  export interface Closed {\n    /**\n     * Reason that the thread was closed. Defaults to null when no reason is recorded.\n     */\n    reason: string | null;\n\n    /**\n     * Status discriminator that is always `closed`.\n     */\n    type: 'closed';\n  }\n}\n\n/**\n * Assistant-authored message within a thread.\n */\nexport interface ChatKitThreadAssistantMessageItem {\n  /**\n   * Identifier of the thread item.\n   */\n  id: string;\n\n  /**\n   * Ordered assistant response segments.\n   */\n  content: Array<ChatKitResponseOutputText>;\n\n  /**\n   * Unix timestamp (in seconds) for when the item was created.\n   */\n  created_at: number;\n\n  /**\n   * Type discriminator that is always `chatkit.thread_item`.\n   */\n  object: 'chatkit.thread_item';\n\n  /**\n   * Identifier of the parent thread.\n   */\n  thread_id: string;\n\n  /**\n   * Type discriminator that is always `chatkit.assistant_message`.\n   */\n  type: 'chatkit.assistant_message';\n}\n\n/**\n * A paginated list of thread items rendered for the ChatKit API.\n */\nexport interface ChatKitThreadItemList {\n  /**\n   * A list of items\n   */\n  data: Array<\n    | ChatKitThreadUserMessageItem\n    | ChatKitThreadAssistantMessageItem\n    | ChatKitWidgetItem\n    | ChatKitThreadItemList.ChatKitClientToolCall\n    | ChatKitThreadItemList.ChatKitTask\n    | ChatKitThreadItemList.ChatKitTaskGroup\n  >;\n\n  /**\n   * The ID of the first item in the list.\n   */\n  first_id: string | null;\n\n  /**\n   * Whether there are more items available.\n   */\n  has_more: boolean;\n\n  /**\n   * The ID of the last item in the list.\n   */\n  last_id: string | null;\n\n  /**\n   * The type of object returned, must be `list`.\n   */\n  object: 'list';\n}\n\nexport namespace ChatKitThreadItemList {\n  /**\n   * Record of a client side tool invocation initiated by the assistant.\n   */\n  export interface ChatKitClientToolCall {\n    /**\n     * Identifier of the thread item.\n     */\n    id: string;\n\n    /**\n     * JSON-encoded arguments that were sent to the tool.\n     */\n    arguments: string;\n\n    /**\n     * Identifier for the client tool call.\n     */\n    call_id: string;\n\n    /**\n     * Unix timestamp (in seconds) for when the item was created.\n     */\n    created_at: number;\n\n    /**\n     * Tool name that was invoked.\n     */\n    name: string;\n\n    /**\n     * Type discriminator that is always `chatkit.thread_item`.\n     */\n    object: 'chatkit.thread_item';\n\n    /**\n     * JSON-encoded output captured from the tool. Defaults to null while execution is\n     * in progress.\n     */\n    output: string | null;\n\n    /**\n     * Execution status for the tool call.\n     */\n    status: 'in_progress' | 'completed';\n\n    /**\n     * Identifier of the parent thread.\n     */\n    thread_id: string;\n\n    /**\n     * Type discriminator that is always `chatkit.client_tool_call`.\n     */\n    type: 'chatkit.client_tool_call';\n  }\n\n  /**\n   * Task emitted by the workflow to show progress and status updates.\n   */\n  export interface ChatKitTask {\n    /**\n     * Identifier of the thread item.\n     */\n    id: string;\n\n    /**\n     * Unix timestamp (in seconds) for when the item was created.\n     */\n    created_at: number;\n\n    /**\n     * Optional heading for the task. Defaults to null when not provided.\n     */\n    heading: string | null;\n\n    /**\n     * Type discriminator that is always `chatkit.thread_item`.\n     */\n    object: 'chatkit.thread_item';\n\n    /**\n     * Optional summary that describes the task. Defaults to null when omitted.\n     */\n    summary: string | null;\n\n    /**\n     * Subtype for the task.\n     */\n    task_type: 'custom' | 'thought';\n\n    /**\n     * Identifier of the parent thread.\n     */\n    thread_id: string;\n\n    /**\n     * Type discriminator that is always `chatkit.task`.\n     */\n    type: 'chatkit.task';\n  }\n\n  /**\n   * Collection of workflow tasks grouped together in the thread.\n   */\n  export interface ChatKitTaskGroup {\n    /**\n     * Identifier of the thread item.\n     */\n    id: string;\n\n    /**\n     * Unix timestamp (in seconds) for when the item was created.\n     */\n    created_at: number;\n\n    /**\n     * Type discriminator that is always `chatkit.thread_item`.\n     */\n    object: 'chatkit.thread_item';\n\n    /**\n     * Tasks included in the group.\n     */\n    tasks: Array<ChatKitTaskGroup.Task>;\n\n    /**\n     * Identifier of the parent thread.\n     */\n    thread_id: string;\n\n    /**\n     * Type discriminator that is always `chatkit.task_group`.\n     */\n    type: 'chatkit.task_group';\n  }\n\n  export namespace ChatKitTaskGroup {\n    /**\n     * Task entry that appears within a TaskGroup.\n     */\n    export interface Task {\n      /**\n       * Optional heading for the grouped task. Defaults to null when not provided.\n       */\n      heading: string | null;\n\n      /**\n       * Optional summary that describes the grouped task. Defaults to null when omitted.\n       */\n      summary: string | null;\n\n      /**\n       * Subtype for the grouped task.\n       */\n      type: 'custom' | 'thought';\n    }\n  }\n}\n\n/**\n * User-authored messages within a thread.\n */\nexport interface ChatKitThreadUserMessageItem {\n  /**\n   * Identifier of the thread item.\n   */\n  id: string;\n\n  /**\n   * Attachments associated with the user message. Defaults to an empty list.\n   */\n  attachments: Array<ChatKitAttachment>;\n\n  /**\n   * Ordered content elements supplied by the user.\n   */\n  content: Array<ChatKitThreadUserMessageItem.InputText | ChatKitThreadUserMessageItem.QuotedText>;\n\n  /**\n   * Unix timestamp (in seconds) for when the item was created.\n   */\n  created_at: number;\n\n  /**\n   * Inference overrides applied to the message. Defaults to null when unset.\n   */\n  inference_options: ChatKitThreadUserMessageItem.InferenceOptions | null;\n\n  /**\n   * Type discriminator that is always `chatkit.thread_item`.\n   */\n  object: 'chatkit.thread_item';\n\n  /**\n   * Identifier of the parent thread.\n   */\n  thread_id: string;\n\n  type: 'chatkit.user_message';\n}\n\nexport namespace ChatKitThreadUserMessageItem {\n  /**\n   * Text block that a user contributed to the thread.\n   */\n  export interface InputText {\n    /**\n     * Plain-text content supplied by the user.\n     */\n    text: string;\n\n    /**\n     * Type discriminator that is always `input_text`.\n     */\n    type: 'input_text';\n  }\n\n  /**\n   * Quoted snippet that the user referenced in their message.\n   */\n  export interface QuotedText {\n    /**\n     * Quoted text content.\n     */\n    text: string;\n\n    /**\n     * Type discriminator that is always `quoted_text`.\n     */\n    type: 'quoted_text';\n  }\n\n  /**\n   * Inference overrides applied to the message. Defaults to null when unset.\n   */\n  export interface InferenceOptions {\n    /**\n     * Model name that generated the response. Defaults to null when using the session\n     * default.\n     */\n    model: string | null;\n\n    /**\n     * Preferred tool to invoke. Defaults to null when ChatKit should auto-select.\n     */\n    tool_choice: InferenceOptions.ToolChoice | null;\n  }\n\n  export namespace InferenceOptions {\n    /**\n     * Preferred tool to invoke. Defaults to null when ChatKit should auto-select.\n     */\n    export interface ToolChoice {\n      /**\n       * Identifier of the requested tool.\n       */\n      id: string;\n    }\n  }\n}\n\n/**\n * Thread item that renders a widget payload.\n */\nexport interface ChatKitWidgetItem {\n  /**\n   * Identifier of the thread item.\n   */\n  id: string;\n\n  /**\n   * Unix timestamp (in seconds) for when the item was created.\n   */\n  created_at: number;\n\n  /**\n   * Type discriminator that is always `chatkit.thread_item`.\n   */\n  object: 'chatkit.thread_item';\n\n  /**\n   * Identifier of the parent thread.\n   */\n  thread_id: string;\n\n  /**\n   * Type discriminator that is always `chatkit.widget`.\n   */\n  type: 'chatkit.widget';\n\n  /**\n   * Serialized widget payload rendered in the UI.\n   */\n  widget: string;\n}\n\n/**\n * Confirmation payload returned after deleting a thread.\n */\nexport interface ThreadDeleteResponse {\n  /**\n   * Identifier of the deleted thread.\n   */\n  id: string;\n\n  /**\n   * Indicates that the thread has been deleted.\n   */\n  deleted: boolean;\n\n  /**\n   * Type discriminator that is always `chatkit.thread.deleted`.\n   */\n  object: 'chatkit.thread.deleted';\n}\n\nexport interface ThreadListParams extends ConversationCursorPageParams {\n  /**\n   * List items created before this thread item ID. Defaults to null for the newest\n   * results.\n   */\n  before?: string;\n\n  /**\n   * Sort order for results by creation time. Defaults to `desc`.\n   */\n  order?: 'asc' | 'desc';\n\n  /**\n   * Filter threads that belong to this user identifier. Defaults to null to return\n   * all users.\n   */\n  user?: string;\n}\n\nexport interface ThreadListItemsParams extends ConversationCursorPageParams {\n  /**\n   * List items created before this thread item ID. Defaults to null for the newest\n   * results.\n   */\n  before?: string;\n\n  /**\n   * Sort order for results by creation time. Defaults to `desc`.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport declare namespace Threads {\n  export {\n    type ChatSession as ChatSession,\n    type ChatSessionAutomaticThreadTitling as ChatSessionAutomaticThreadTitling,\n    type ChatSessionChatKitConfiguration as ChatSessionChatKitConfiguration,\n    type ChatSessionChatKitConfigurationParam as ChatSessionChatKitConfigurationParam,\n    type ChatSessionExpiresAfterParam as ChatSessionExpiresAfterParam,\n    type ChatSessionFileUpload as ChatSessionFileUpload,\n    type ChatSessionHistory as ChatSessionHistory,\n    type ChatSessionRateLimits as ChatSessionRateLimits,\n    type ChatSessionRateLimitsParam as ChatSessionRateLimitsParam,\n    type ChatSessionStatus as ChatSessionStatus,\n    type ChatSessionWorkflowParam as ChatSessionWorkflowParam,\n    type ChatKitAttachment as ChatKitAttachment,\n    type ChatKitResponseOutputText as ChatKitResponseOutputText,\n    type ChatKitThread as ChatKitThread,\n    type ChatKitThreadAssistantMessageItem as ChatKitThreadAssistantMessageItem,\n    type ChatKitThreadItemList as ChatKitThreadItemList,\n    type ChatKitThreadUserMessageItem as ChatKitThreadUserMessageItem,\n    type ChatKitWidgetItem as ChatKitWidgetItem,\n    type ThreadDeleteResponse as ThreadDeleteResponse,\n    type ChatKitThreadsPage as ChatKitThreadsPage,\n    type ChatKitThreadItemListDataPage as ChatKitThreadItemListDataPage,\n    type ThreadListParams as ThreadListParams,\n    type ThreadListItemsParams as ThreadListItemsParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nexport {\n  Completions,\n  type ChatCompletion,\n  type ChatCompletionAllowedToolChoice,\n  type ChatCompletionAssistantMessageParam,\n  type ChatCompletionAudio,\n  type ChatCompletionAudioParam,\n  type ChatCompletionChunk,\n  type ChatCompletionContentPart,\n  type ChatCompletionContentPartImage,\n  type ChatCompletionContentPartInputAudio,\n  type ChatCompletionContentPartRefusal,\n  type ChatCompletionContentPartText,\n  type ChatCompletionCustomTool,\n  type ChatCompletionDeleted,\n  type ChatCompletionDeveloperMessageParam,\n  type ChatCompletionFunctionCallOption,\n  type ChatCompletionFunctionMessageParam,\n  type ChatCompletionFunctionTool,\n  type ChatCompletionMessage,\n  type ChatCompletionMessageCustomToolCall,\n  type ChatCompletionMessageFunctionToolCall,\n  type ChatCompletionMessageParam,\n  type ChatCompletionMessageToolCall,\n  type ChatCompletionModality,\n  type ChatCompletionNamedToolChoice,\n  type ChatCompletionNamedToolChoiceCustom,\n  type ChatCompletionPredictionContent,\n  type ChatCompletionRole,\n  type ChatCompletionStoreMessage,\n  type ChatCompletionStreamOptions,\n  type ChatCompletionSystemMessageParam,\n  type ChatCompletionTokenLogprob,\n  type ChatCompletionTool,\n  type ChatCompletionToolChoiceOption,\n  type ChatCompletionToolMessageParam,\n  type ChatCompletionUserMessageParam,\n  type ChatCompletionAllowedTools,\n  type ChatCompletionCreateParams,\n  type ChatCompletionCreateParamsNonStreaming,\n  type ChatCompletionCreateParamsStreaming,\n  type ChatCompletionUpdateParams,\n  type ChatCompletionListParams,\n  type ChatCompletionStoreMessagesPage,\n  type ChatCompletionsPage,\n} from './completions';\nexport * from './completions';\nexport { Messages, type MessageListParams } from './messages';\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport * as SessionsAPI from './sessions';\nimport { SessionCreateParams, Sessions } from './sessions';\nimport * as ThreadsAPI from './threads';\nimport {\n  ChatKitAttachment,\n  ChatKitResponseOutputText,\n  ChatKitThread,\n  ChatKitThreadAssistantMessageItem,\n  ChatKitThreadItemList,\n  ChatKitThreadItemListDataPage,\n  ChatKitThreadUserMessageItem,\n  ChatKitThreadsPage,\n  ChatKitWidgetItem,\n  ChatSession,\n  ChatSessionAutomaticThreadTitling,\n  ChatSessionChatKitConfiguration,\n  ChatSessionChatKitConfigurationParam,\n  ChatSessionExpiresAfterParam,\n  ChatSessionFileUpload,\n  ChatSessionHistory,\n  ChatSessionRateLimits,\n  ChatSessionRateLimitsParam,\n  ChatSessionStatus,\n  ChatSessionWorkflowParam,\n  ThreadDeleteResponse,\n  ThreadListItemsParams,\n  ThreadListParams,\n  Threads,\n} from './threads';\n\nexport class ChatKit extends APIResource {\n  sessions: SessionsAPI.Sessions = new SessionsAPI.Sessions(this._client);\n  threads: ThreadsAPI.Threads = new ThreadsAPI.Threads(this._client);\n}\n\n/**\n * Workflow metadata and state returned for the session.\n */\nexport interface ChatKitWorkflow {\n  /**\n   * Identifier of the workflow backing the session.\n   */\n  id: string;\n\n  /**\n   * State variable key-value pairs applied when invoking the workflow. Defaults to\n   * null when no overrides were provided.\n   */\n  state_variables: { [key: string]: string | boolean | number } | null;\n\n  /**\n   * Tracing settings applied to the workflow.\n   */\n  tracing: ChatKitWorkflow.Tracing;\n\n  /**\n   * Specific workflow version used for the session. Defaults to null when using the\n   * latest deployment.\n   */\n  version: string | null;\n}\n\nexport namespace ChatKitWorkflow {\n  /**\n   * Tracing settings applied to the workflow.\n   */\n  export interface Tracing {\n    /**\n     * Indicates whether tracing is enabled.\n     */\n    enabled: boolean;\n  }\n}\n\nChatKit.Sessions = Sessions;\nChatKit.Threads = Threads;\n\nexport declare namespace ChatKit {\n  export { type ChatKitWorkflow as ChatKitWorkflow };\n\n  export { Sessions as Sessions, type SessionCreateParams as SessionCreateParams };\n\n  export {\n    Threads as Threads,\n    type ChatSession as ChatSession,\n    type ChatSessionAutomaticThreadTitling as ChatSessionAutomaticThreadTitling,\n    type ChatSessionChatKitConfiguration as ChatSessionChatKitConfiguration,\n    type ChatSessionChatKitConfigurationParam as ChatSessionChatKitConfigurationParam,\n    type ChatSessionExpiresAfterParam as ChatSessionExpiresAfterParam,\n    type ChatSessionFileUpload as ChatSessionFileUpload,\n    type ChatSessionHistory as ChatSessionHistory,\n    type ChatSessionRateLimits as ChatSessionRateLimits,\n    type ChatSessionRateLimitsParam as ChatSessionRateLimitsParam,\n    type ChatSessionStatus as ChatSessionStatus,\n    type ChatSessionWorkflowParam as ChatSessionWorkflowParam,\n    type ChatKitAttachment as ChatKitAttachment,\n    type ChatKitResponseOutputText as ChatKitResponseOutputText,\n    type ChatKitThread as ChatKitThread,\n    type ChatKitThreadAssistantMessageItem as ChatKitThreadAssistantMessageItem,\n    type ChatKitThreadItemList as ChatKitThreadItemList,\n    type ChatKitThreadUserMessageItem as ChatKitThreadUserMessageItem,\n    type ChatKitWidgetItem as ChatKitWidgetItem,\n    type ThreadDeleteResponse as ThreadDeleteResponse,\n    type ChatKitThreadsPage as ChatKitThreadsPage,\n    type ChatKitThreadItemListDataPage as ChatKitThreadItemListDataPage,\n    type ThreadListParams as ThreadListParams,\n    type ThreadListItemsParams as ThreadListItemsParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport * as Shared from '../../shared';\nimport * as AssistantsAPI from '../assistants';\nimport { APIPromise } from '../../../core/api-promise';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../../../core/pagination';\nimport { buildHeaders } from '../../../internal/headers';\nimport { RequestOptions } from '../../../internal/request-options';\nimport { path } from '../../../internal/utils/path';\n\n/**\n * @deprecated The Assistants API is deprecated in favor of the Responses API\n */\nexport class Messages extends APIResource {\n  /**\n   * Create a message.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  create(threadID: string, body: MessageCreateParams, options?: RequestOptions): APIPromise<Message> {\n    return this._client.post(path`/threads/${threadID}/messages`, {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Retrieve a message.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  retrieve(messageID: string, params: MessageRetrieveParams, options?: RequestOptions): APIPromise<Message> {\n    const { thread_id } = params;\n    return this._client.get(path`/threads/${thread_id}/messages/${messageID}`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Modifies a message.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  update(messageID: string, params: MessageUpdateParams, options?: RequestOptions): APIPromise<Message> {\n    const { thread_id, ...body } = params;\n    return this._client.post(path`/threads/${thread_id}/messages/${messageID}`, {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Returns a list of messages for a given thread.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  list(\n    threadID: string,\n    query: MessageListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<MessagesPage, Message> {\n    return this._client.getAPIList(path`/threads/${threadID}/messages`, CursorPage<Message>, {\n      query,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Deletes a message.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  delete(\n    messageID: string,\n    params: MessageDeleteParams,\n    options?: RequestOptions,\n  ): APIPromise<MessageDeleted> {\n    const { thread_id } = params;\n    return this._client.delete(path`/threads/${thread_id}/messages/${messageID}`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n}\n\nexport type MessagesPage = CursorPage<Message>;\n\n/**\n * A citation within the message that points to a specific quote from a specific\n * File associated with the assistant or the message. Generated when the assistant\n * uses the \"file_search\" tool to search files.\n */\nexport type Annotation = FileCitationAnnotation | FilePathAnnotation;\n\n/**\n * A citation within the message that points to a specific quote from a specific\n * File associated with the assistant or the message. Generated when the assistant\n * uses the \"file_search\" tool to search files.\n */\nexport type AnnotationDelta = FileCitationDeltaAnnotation | FilePathDeltaAnnotation;\n\n/**\n * A citation within the message that points to a specific quote from a specific\n * File associated with the assistant or the message. Generated when the assistant\n * uses the \"file_search\" tool to search files.\n */\nexport interface FileCitationAnnotation {\n  end_index: number;\n\n  file_citation: FileCitationAnnotation.FileCitation;\n\n  start_index: number;\n\n  /**\n   * The text in the message content that needs to be replaced.\n   */\n  text: string;\n\n  /**\n   * Always `file_citation`.\n   */\n  type: 'file_citation';\n}\n\nexport namespace FileCitationAnnotation {\n  export interface FileCitation {\n    /**\n     * The ID of the specific File the citation is from.\n     */\n    file_id: string;\n  }\n}\n\n/**\n * A citation within the message that points to a specific quote from a specific\n * File associated with the assistant or the message. Generated when the assistant\n * uses the \"file_search\" tool to search files.\n */\nexport interface FileCitationDeltaAnnotation {\n  /**\n   * The index of the annotation in the text content part.\n   */\n  index: number;\n\n  /**\n   * Always `file_citation`.\n   */\n  type: 'file_citation';\n\n  end_index?: number;\n\n  file_citation?: FileCitationDeltaAnnotation.FileCitation;\n\n  start_index?: number;\n\n  /**\n   * The text in the message content that needs to be replaced.\n   */\n  text?: string;\n}\n\nexport namespace FileCitationDeltaAnnotation {\n  export interface FileCitation {\n    /**\n     * The ID of the specific File the citation is from.\n     */\n    file_id?: string;\n\n    /**\n     * The specific quote in the file.\n     */\n    quote?: string;\n  }\n}\n\n/**\n * A URL for the file that's generated when the assistant used the\n * `code_interpreter` tool to generate a file.\n */\nexport interface FilePathAnnotation {\n  end_index: number;\n\n  file_path: FilePathAnnotation.FilePath;\n\n  start_index: number;\n\n  /**\n   * The text in the message content that needs to be replaced.\n   */\n  text: string;\n\n  /**\n   * Always `file_path`.\n   */\n  type: 'file_path';\n}\n\nexport namespace FilePathAnnotation {\n  export interface FilePath {\n    /**\n     * The ID of the file that was generated.\n     */\n    file_id: string;\n  }\n}\n\n/**\n * A URL for the file that's generated when the assistant used the\n * `code_interpreter` tool to generate a file.\n */\nexport interface FilePathDeltaAnnotation {\n  /**\n   * The index of the annotation in the text content part.\n   */\n  index: number;\n\n  /**\n   * Always `file_path`.\n   */\n  type: 'file_path';\n\n  end_index?: number;\n\n  file_path?: FilePathDeltaAnnotation.FilePath;\n\n  start_index?: number;\n\n  /**\n   * The text in the message content that needs to be replaced.\n   */\n  text?: string;\n}\n\nexport namespace FilePathDeltaAnnotation {\n  export interface FilePath {\n    /**\n     * The ID of the file that was generated.\n     */\n    file_id?: string;\n  }\n}\n\nexport interface ImageFile {\n  /**\n   * The [File](https://platform.openai.com/docs/api-reference/files) ID of the image\n   * in the message content. Set `purpose=\"vision\"` when uploading the File if you\n   * need to later display the file content.\n   */\n  file_id: string;\n\n  /**\n   * Specifies the detail level of the image if specified by the user. `low` uses\n   * fewer tokens, you can opt in to high resolution using `high`.\n   */\n  detail?: 'auto' | 'low' | 'high';\n}\n\n/**\n * References an image [File](https://platform.openai.com/docs/api-reference/files)\n * in the content of a message.\n */\nexport interface ImageFileContentBlock {\n  image_file: ImageFile;\n\n  /**\n   * Always `image_file`.\n   */\n  type: 'image_file';\n}\n\nexport interface ImageFileDelta {\n  /**\n   * Specifies the detail level of the image if specified by the user. `low` uses\n   * fewer tokens, you can opt in to high resolution using `high`.\n   */\n  detail?: 'auto' | 'low' | 'high';\n\n  /**\n   * The [File](https://platform.openai.com/docs/api-reference/files) ID of the image\n   * in the message content. Set `purpose=\"vision\"` when uploading the File if you\n   * need to later display the file content.\n   */\n  file_id?: string;\n}\n\n/**\n * References an image [File](https://platform.openai.com/docs/api-reference/files)\n * in the content of a message.\n */\nexport interface ImageFileDeltaBlock {\n  /**\n   * The index of the content part in the message.\n   */\n  index: number;\n\n  /**\n   * Always `image_file`.\n   */\n  type: 'image_file';\n\n  image_file?: ImageFileDelta;\n}\n\nexport interface ImageURL {\n  /**\n   * The external URL of the image, must be a supported image types: jpeg, jpg, png,\n   * gif, webp.\n   */\n  url: string;\n\n  /**\n   * Specifies the detail level of the image. `low` uses fewer tokens, you can opt in\n   * to high resolution using `high`. Default value is `auto`\n   */\n  detail?: 'auto' | 'low' | 'high';\n}\n\n/**\n * References an image URL in the content of a message.\n */\nexport interface ImageURLContentBlock {\n  image_url: ImageURL;\n\n  /**\n   * The type of the content part.\n   */\n  type: 'image_url';\n}\n\nexport interface ImageURLDelta {\n  /**\n   * Specifies the detail level of the image. `low` uses fewer tokens, you can opt in\n   * to high resolution using `high`.\n   */\n  detail?: 'auto' | 'low' | 'high';\n\n  /**\n   * The URL of the image, must be a supported image types: jpeg, jpg, png, gif,\n   * webp.\n   */\n  url?: string;\n}\n\n/**\n * References an image URL in the content of a message.\n */\nexport interface ImageURLDeltaBlock {\n  /**\n   * The index of the content part in the message.\n   */\n  index: number;\n\n  /**\n   * Always `image_url`.\n   */\n  type: 'image_url';\n\n  image_url?: ImageURLDelta;\n}\n\n/**\n * Represents a message within a\n * [thread](https://platform.openai.com/docs/api-reference/threads).\n */\nexport interface Message {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * If applicable, the ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) that\n   * authored this message.\n   */\n  assistant_id: string | null;\n\n  /**\n   * A list of files attached to the message, and the tools they were added to.\n   */\n  attachments: Array<Message.Attachment> | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the message was completed.\n   */\n  completed_at: number | null;\n\n  /**\n   * The content of the message in array of text and/or images.\n   */\n  content: Array<MessageContent>;\n\n  /**\n   * The Unix timestamp (in seconds) for when the message was created.\n   */\n  created_at: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the message was marked as incomplete.\n   */\n  incomplete_at: number | null;\n\n  /**\n   * On an incomplete message, details about why the message is incomplete.\n   */\n  incomplete_details: Message.IncompleteDetails | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * The object type, which is always `thread.message`.\n   */\n  object: 'thread.message';\n\n  /**\n   * The entity that produced the message. One of `user` or `assistant`.\n   */\n  role: 'user' | 'assistant';\n\n  /**\n   * The ID of the [run](https://platform.openai.com/docs/api-reference/runs)\n   * associated with the creation of this message. Value is `null` when messages are\n   * created manually using the create message or create thread endpoints.\n   */\n  run_id: string | null;\n\n  /**\n   * The status of the message, which can be either `in_progress`, `incomplete`, or\n   * `completed`.\n   */\n  status: 'in_progress' | 'incomplete' | 'completed';\n\n  /**\n   * The [thread](https://platform.openai.com/docs/api-reference/threads) ID that\n   * this message belongs to.\n   */\n  thread_id: string;\n}\n\nexport namespace Message {\n  export interface Attachment {\n    /**\n     * The ID of the file to attach to the message.\n     */\n    file_id?: string;\n\n    /**\n     * The tools to add this file to.\n     */\n    tools?: Array<AssistantsAPI.CodeInterpreterTool | Attachment.AssistantToolsFileSearchTypeOnly>;\n  }\n\n  export namespace Attachment {\n    export interface AssistantToolsFileSearchTypeOnly {\n      /**\n       * The type of tool being defined: `file_search`\n       */\n      type: 'file_search';\n    }\n  }\n\n  /**\n   * On an incomplete message, details about why the message is incomplete.\n   */\n  export interface IncompleteDetails {\n    /**\n     * The reason the message is incomplete.\n     */\n    reason: 'content_filter' | 'max_tokens' | 'run_cancelled' | 'run_expired' | 'run_failed';\n  }\n}\n\n/**\n * References an image [File](https://platform.openai.com/docs/api-reference/files)\n * in the content of a message.\n */\nexport type MessageContent =\n  | ImageFileContentBlock\n  | ImageURLContentBlock\n  | TextContentBlock\n  | RefusalContentBlock;\n\n/**\n * References an image [File](https://platform.openai.com/docs/api-reference/files)\n * in the content of a message.\n */\nexport type MessageContentDelta =\n  | ImageFileDeltaBlock\n  | TextDeltaBlock\n  | RefusalDeltaBlock\n  | ImageURLDeltaBlock;\n\n/**\n * References an image [File](https://platform.openai.com/docs/api-reference/files)\n * in the content of a message.\n */\nexport type MessageContentPartParam = ImageFileContentBlock | ImageURLContentBlock | TextContentBlockParam;\n\nexport interface MessageDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'thread.message.deleted';\n}\n\n/**\n * The delta containing the fields that have changed on the Message.\n */\nexport interface MessageDelta {\n  /**\n   * The content of the message in array of text and/or images.\n   */\n  content?: Array<MessageContentDelta>;\n\n  /**\n   * The entity that produced the message. One of `user` or `assistant`.\n   */\n  role?: 'user' | 'assistant';\n}\n\n/**\n * Represents a message delta i.e. any changed fields on a message during\n * streaming.\n */\nexport interface MessageDeltaEvent {\n  /**\n   * The identifier of the message, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The delta containing the fields that have changed on the Message.\n   */\n  delta: MessageDelta;\n\n  /**\n   * The object type, which is always `thread.message.delta`.\n   */\n  object: 'thread.message.delta';\n}\n\n/**\n * The refusal content generated by the assistant.\n */\nexport interface RefusalContentBlock {\n  refusal: string;\n\n  /**\n   * Always `refusal`.\n   */\n  type: 'refusal';\n}\n\n/**\n * The refusal content that is part of a message.\n */\nexport interface RefusalDeltaBlock {\n  /**\n   * The index of the refusal part in the message.\n   */\n  index: number;\n\n  /**\n   * Always `refusal`.\n   */\n  type: 'refusal';\n\n  refusal?: string;\n}\n\nexport interface Text {\n  annotations: Array<Annotation>;\n\n  /**\n   * The data that makes up the text.\n   */\n  value: string;\n}\n\n/**\n * The text content that is part of a message.\n */\nexport interface TextContentBlock {\n  text: Text;\n\n  /**\n   * Always `text`.\n   */\n  type: 'text';\n}\n\n/**\n * The text content that is part of a message.\n */\nexport interface TextContentBlockParam {\n  /**\n   * Text content to be sent to the model\n   */\n  text: string;\n\n  /**\n   * Always `text`.\n   */\n  type: 'text';\n}\n\nexport interface TextDelta {\n  annotations?: Array<AnnotationDelta>;\n\n  /**\n   * The data that makes up the text.\n   */\n  value?: string;\n}\n\n/**\n * The text content that is part of a message.\n */\nexport interface TextDeltaBlock {\n  /**\n   * The index of the content part in the message.\n   */\n  index: number;\n\n  /**\n   * Always `text`.\n   */\n  type: 'text';\n\n  text?: TextDelta;\n}\n\nexport interface MessageCreateParams {\n  /**\n   * The text contents of the message.\n   */\n  content: string | Array<MessageContentPartParam>;\n\n  /**\n   * The role of the entity that is creating the message. Allowed values include:\n   *\n   * - `user`: Indicates the message is sent by an actual user and should be used in\n   *   most cases to represent user-generated messages.\n   * - `assistant`: Indicates the message is generated by the assistant. Use this\n   *   value to insert messages from the assistant into the conversation.\n   */\n  role: 'user' | 'assistant';\n\n  /**\n   * A list of files attached to the message, and the tools they should be added to.\n   */\n  attachments?: Array<MessageCreateParams.Attachment> | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n}\n\nexport namespace MessageCreateParams {\n  export interface Attachment {\n    /**\n     * The ID of the file to attach to the message.\n     */\n    file_id?: string;\n\n    /**\n     * The tools to add this file to.\n     */\n    tools?: Array<AssistantsAPI.CodeInterpreterTool | Attachment.FileSearch>;\n  }\n\n  export namespace Attachment {\n    export interface FileSearch {\n      /**\n       * The type of tool being defined: `file_search`\n       */\n      type: 'file_search';\n    }\n  }\n}\n\nexport interface MessageRetrieveParams {\n  /**\n   * The ID of the [thread](https://platform.openai.com/docs/api-reference/threads)\n   * to which this message belongs.\n   */\n  thread_id: string;\n}\n\nexport interface MessageUpdateParams {\n  /**\n   * Path param: The ID of the thread to which this message belongs.\n   */\n  thread_id: string;\n\n  /**\n   * Body param: Set of 16 key-value pairs that can be attached to an object. This\n   * can be useful for storing additional information about the object in a\n   * structured format, and querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n}\n\nexport interface MessageListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * starting with obj_foo, your subsequent call can include before=obj_foo in order\n   * to fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n\n  /**\n   * Filter messages by the run ID that generated them.\n   */\n  run_id?: string;\n}\n\nexport interface MessageDeleteParams {\n  /**\n   * The ID of the thread to which this message belongs.\n   */\n  thread_id: string;\n}\n\nexport declare namespace Messages {\n  export {\n    type Annotation as Annotation,\n    type AnnotationDelta as AnnotationDelta,\n    type FileCitationAnnotation as FileCitationAnnotation,\n    type FileCitationDeltaAnnotation as FileCitationDeltaAnnotation,\n    type FilePathAnnotation as FilePathAnnotation,\n    type FilePathDeltaAnnotation as FilePathDeltaAnnotation,\n    type ImageFile as ImageFile,\n    type ImageFileContentBlock as ImageFileContentBlock,\n    type ImageFileDelta as ImageFileDelta,\n    type ImageFileDeltaBlock as ImageFileDeltaBlock,\n    type ImageURL as ImageURL,\n    type ImageURLContentBlock as ImageURLContentBlock,\n    type ImageURLDelta as ImageURLDelta,\n    type ImageURLDeltaBlock as ImageURLDeltaBlock,\n    type Message as Message,\n    type MessageContent as MessageContent,\n    type MessageContentDelta as MessageContentDelta,\n    type MessageContentPartParam as MessageContentPartParam,\n    type MessageDeleted as MessageDeleted,\n    type MessageDelta as MessageDelta,\n    type MessageDeltaEvent as MessageDeltaEvent,\n    type RefusalContentBlock as RefusalContentBlock,\n    type RefusalDeltaBlock as RefusalDeltaBlock,\n    type Text as Text,\n    type TextContentBlock as TextContentBlock,\n    type TextContentBlockParam as TextContentBlockParam,\n    type TextDelta as TextDelta,\n    type TextDeltaBlock as TextDeltaBlock,\n    type MessagesPage as MessagesPage,\n    type MessageCreateParams as MessageCreateParams,\n    type MessageRetrieveParams as MessageRetrieveParams,\n    type MessageUpdateParams as MessageUpdateParams,\n    type MessageListParams as MessageListParams,\n    type MessageDeleteParams as MessageDeleteParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../../core/resource';\nimport * as StepsAPI from './steps';\nimport * as Shared from '../../../shared';\nimport { APIPromise } from '../../../../core/api-promise';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../../../../core/pagination';\nimport { buildHeaders } from '../../../../internal/headers';\nimport { RequestOptions } from '../../../../internal/request-options';\nimport { path } from '../../../../internal/utils/path';\n\n/**\n * @deprecated The Assistants API is deprecated in favor of the Responses API\n */\nexport class Steps extends APIResource {\n  /**\n   * Retrieves a run step.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  retrieve(stepID: string, params: StepRetrieveParams, options?: RequestOptions): APIPromise<RunStep> {\n    const { thread_id, run_id, ...query } = params;\n    return this._client.get(path`/threads/${thread_id}/runs/${run_id}/steps/${stepID}`, {\n      query,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Returns a list of run steps belonging to a run.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  list(runID: string, params: StepListParams, options?: RequestOptions): PagePromise<RunStepsPage, RunStep> {\n    const { thread_id, ...query } = params;\n    return this._client.getAPIList(path`/threads/${thread_id}/runs/${runID}/steps`, CursorPage<RunStep>, {\n      query,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n}\n\nexport type RunStepsPage = CursorPage<RunStep>;\n\n/**\n * Text output from the Code Interpreter tool call as part of a run step.\n */\nexport interface CodeInterpreterLogs {\n  /**\n   * The index of the output in the outputs array.\n   */\n  index: number;\n\n  /**\n   * Always `logs`.\n   */\n  type: 'logs';\n\n  /**\n   * The text output from the Code Interpreter tool call.\n   */\n  logs?: string;\n}\n\nexport interface CodeInterpreterOutputImage {\n  /**\n   * The index of the output in the outputs array.\n   */\n  index: number;\n\n  /**\n   * Always `image`.\n   */\n  type: 'image';\n\n  image?: CodeInterpreterOutputImage.Image;\n}\n\nexport namespace CodeInterpreterOutputImage {\n  export interface Image {\n    /**\n     * The [file](https://platform.openai.com/docs/api-reference/files) ID of the\n     * image.\n     */\n    file_id?: string;\n  }\n}\n\n/**\n * Details of the Code Interpreter tool call the run step was involved in.\n */\nexport interface CodeInterpreterToolCall {\n  /**\n   * The ID of the tool call.\n   */\n  id: string;\n\n  /**\n   * The Code Interpreter tool call definition.\n   */\n  code_interpreter: CodeInterpreterToolCall.CodeInterpreter;\n\n  /**\n   * The type of tool call. This is always going to be `code_interpreter` for this\n   * type of tool call.\n   */\n  type: 'code_interpreter';\n}\n\nexport namespace CodeInterpreterToolCall {\n  /**\n   * The Code Interpreter tool call definition.\n   */\n  export interface CodeInterpreter {\n    /**\n     * The input to the Code Interpreter tool call.\n     */\n    input: string;\n\n    /**\n     * The outputs from the Code Interpreter tool call. Code Interpreter can output one\n     * or more items, including text (`logs`) or images (`image`). Each of these are\n     * represented by a different object type.\n     */\n    outputs: Array<CodeInterpreter.Logs | CodeInterpreter.Image>;\n  }\n\n  export namespace CodeInterpreter {\n    /**\n     * Text output from the Code Interpreter tool call as part of a run step.\n     */\n    export interface Logs {\n      /**\n       * The text output from the Code Interpreter tool call.\n       */\n      logs: string;\n\n      /**\n       * Always `logs`.\n       */\n      type: 'logs';\n    }\n\n    export interface Image {\n      image: Image.Image;\n\n      /**\n       * Always `image`.\n       */\n      type: 'image';\n    }\n\n    export namespace Image {\n      export interface Image {\n        /**\n         * The [file](https://platform.openai.com/docs/api-reference/files) ID of the\n         * image.\n         */\n        file_id: string;\n      }\n    }\n  }\n}\n\n/**\n * Details of the Code Interpreter tool call the run step was involved in.\n */\nexport interface CodeInterpreterToolCallDelta {\n  /**\n   * The index of the tool call in the tool calls array.\n   */\n  index: number;\n\n  /**\n   * The type of tool call. This is always going to be `code_interpreter` for this\n   * type of tool call.\n   */\n  type: 'code_interpreter';\n\n  /**\n   * The ID of the tool call.\n   */\n  id?: string;\n\n  /**\n   * The Code Interpreter tool call definition.\n   */\n  code_interpreter?: CodeInterpreterToolCallDelta.CodeInterpreter;\n}\n\nexport namespace CodeInterpreterToolCallDelta {\n  /**\n   * The Code Interpreter tool call definition.\n   */\n  export interface CodeInterpreter {\n    /**\n     * The input to the Code Interpreter tool call.\n     */\n    input?: string;\n\n    /**\n     * The outputs from the Code Interpreter tool call. Code Interpreter can output one\n     * or more items, including text (`logs`) or images (`image`). Each of these are\n     * represented by a different object type.\n     */\n    outputs?: Array<StepsAPI.CodeInterpreterLogs | StepsAPI.CodeInterpreterOutputImage>;\n  }\n}\n\nexport interface FileSearchToolCall {\n  /**\n   * The ID of the tool call object.\n   */\n  id: string;\n\n  /**\n   * For now, this is always going to be an empty object.\n   */\n  file_search: FileSearchToolCall.FileSearch;\n\n  /**\n   * The type of tool call. This is always going to be `file_search` for this type of\n   * tool call.\n   */\n  type: 'file_search';\n}\n\nexport namespace FileSearchToolCall {\n  /**\n   * For now, this is always going to be an empty object.\n   */\n  export interface FileSearch {\n    /**\n     * The ranking options for the file search.\n     */\n    ranking_options?: FileSearch.RankingOptions;\n\n    /**\n     * The results of the file search.\n     */\n    results?: Array<FileSearch.Result>;\n  }\n\n  export namespace FileSearch {\n    /**\n     * The ranking options for the file search.\n     */\n    export interface RankingOptions {\n      /**\n       * The ranker to use for the file search. If not specified will use the `auto`\n       * ranker.\n       */\n      ranker: 'auto' | 'default_2024_08_21';\n\n      /**\n       * The score threshold for the file search. All values must be a floating point\n       * number between 0 and 1.\n       */\n      score_threshold: number;\n    }\n\n    /**\n     * A result instance of the file search.\n     */\n    export interface Result {\n      /**\n       * The ID of the file that result was found in.\n       */\n      file_id: string;\n\n      /**\n       * The name of the file that result was found in.\n       */\n      file_name: string;\n\n      /**\n       * The score of the result. All values must be a floating point number between 0\n       * and 1.\n       */\n      score: number;\n\n      /**\n       * The content of the result that was found. The content is only included if\n       * requested via the include query parameter.\n       */\n      content?: Array<Result.Content>;\n    }\n\n    export namespace Result {\n      export interface Content {\n        /**\n         * The text content of the file.\n         */\n        text?: string;\n\n        /**\n         * The type of the content.\n         */\n        type?: 'text';\n      }\n    }\n  }\n}\n\nexport interface FileSearchToolCallDelta {\n  /**\n   * For now, this is always going to be an empty object.\n   */\n  file_search: unknown;\n\n  /**\n   * The index of the tool call in the tool calls array.\n   */\n  index: number;\n\n  /**\n   * The type of tool call. This is always going to be `file_search` for this type of\n   * tool call.\n   */\n  type: 'file_search';\n\n  /**\n   * The ID of the tool call object.\n   */\n  id?: string;\n}\n\nexport interface FunctionToolCall {\n  /**\n   * The ID of the tool call object.\n   */\n  id: string;\n\n  /**\n   * The definition of the function that was called.\n   */\n  function: FunctionToolCall.Function;\n\n  /**\n   * The type of tool call. This is always going to be `function` for this type of\n   * tool call.\n   */\n  type: 'function';\n}\n\nexport namespace FunctionToolCall {\n  /**\n   * The definition of the function that was called.\n   */\n  export interface Function {\n    /**\n     * The arguments passed to the function.\n     */\n    arguments: string;\n\n    /**\n     * The name of the function.\n     */\n    name: string;\n\n    /**\n     * The output of the function. This will be `null` if the outputs have not been\n     * [submitted](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs)\n     * yet.\n     */\n    output: string | null;\n  }\n}\n\nexport interface FunctionToolCallDelta {\n  /**\n   * The index of the tool call in the tool calls array.\n   */\n  index: number;\n\n  /**\n   * The type of tool call. This is always going to be `function` for this type of\n   * tool call.\n   */\n  type: 'function';\n\n  /**\n   * The ID of the tool call object.\n   */\n  id?: string;\n\n  /**\n   * The definition of the function that was called.\n   */\n  function?: FunctionToolCallDelta.Function;\n}\n\nexport namespace FunctionToolCallDelta {\n  /**\n   * The definition of the function that was called.\n   */\n  export interface Function {\n    /**\n     * The arguments passed to the function.\n     */\n    arguments?: string;\n\n    /**\n     * The name of the function.\n     */\n    name?: string;\n\n    /**\n     * The output of the function. This will be `null` if the outputs have not been\n     * [submitted](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs)\n     * yet.\n     */\n    output?: string | null;\n  }\n}\n\n/**\n * Details of the message creation by the run step.\n */\nexport interface MessageCreationStepDetails {\n  message_creation: MessageCreationStepDetails.MessageCreation;\n\n  /**\n   * Always `message_creation`.\n   */\n  type: 'message_creation';\n}\n\nexport namespace MessageCreationStepDetails {\n  export interface MessageCreation {\n    /**\n     * The ID of the message that was created by this run step.\n     */\n    message_id: string;\n  }\n}\n\n/**\n * Represents a step in execution of a run.\n */\nexport interface RunStep {\n  /**\n   * The identifier of the run step, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants)\n   * associated with the run step.\n   */\n  assistant_id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run step was cancelled.\n   */\n  cancelled_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run step completed.\n   */\n  completed_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run step was created.\n   */\n  created_at: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run step expired. A step is\n   * considered expired if the parent run is expired.\n   */\n  expired_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run step failed.\n   */\n  failed_at: number | null;\n\n  /**\n   * The last error associated with this run step. Will be `null` if there are no\n   * errors.\n   */\n  last_error: RunStep.LastError | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * The object type, which is always `thread.run.step`.\n   */\n  object: 'thread.run.step';\n\n  /**\n   * The ID of the [run](https://platform.openai.com/docs/api-reference/runs) that\n   * this run step is a part of.\n   */\n  run_id: string;\n\n  /**\n   * The status of the run step, which can be either `in_progress`, `cancelled`,\n   * `failed`, `completed`, or `expired`.\n   */\n  status: 'in_progress' | 'cancelled' | 'failed' | 'completed' | 'expired';\n\n  /**\n   * The details of the run step.\n   */\n  step_details: MessageCreationStepDetails | ToolCallsStepDetails;\n\n  /**\n   * The ID of the [thread](https://platform.openai.com/docs/api-reference/threads)\n   * that was run.\n   */\n  thread_id: string;\n\n  /**\n   * The type of run step, which can be either `message_creation` or `tool_calls`.\n   */\n  type: 'message_creation' | 'tool_calls';\n\n  /**\n   * Usage statistics related to the run step. This value will be `null` while the\n   * run step's status is `in_progress`.\n   */\n  usage: RunStep.Usage | null;\n}\n\nexport namespace RunStep {\n  /**\n   * The last error associated with this run step. Will be `null` if there are no\n   * errors.\n   */\n  export interface LastError {\n    /**\n     * One of `server_error` or `rate_limit_exceeded`.\n     */\n    code: 'server_error' | 'rate_limit_exceeded';\n\n    /**\n     * A human-readable description of the error.\n     */\n    message: string;\n  }\n\n  /**\n   * Usage statistics related to the run step. This value will be `null` while the\n   * run step's status is `in_progress`.\n   */\n  export interface Usage {\n    /**\n     * Number of completion tokens used over the course of the run step.\n     */\n    completion_tokens: number;\n\n    /**\n     * Number of prompt tokens used over the course of the run step.\n     */\n    prompt_tokens: number;\n\n    /**\n     * Total number of tokens used (prompt + completion).\n     */\n    total_tokens: number;\n  }\n}\n\n/**\n * The delta containing the fields that have changed on the run step.\n */\nexport interface RunStepDelta {\n  /**\n   * The details of the run step.\n   */\n  step_details?: RunStepDeltaMessageDelta | ToolCallDeltaObject;\n}\n\n/**\n * Represents a run step delta i.e. any changed fields on a run step during\n * streaming.\n */\nexport interface RunStepDeltaEvent {\n  /**\n   * The identifier of the run step, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The delta containing the fields that have changed on the run step.\n   */\n  delta: RunStepDelta;\n\n  /**\n   * The object type, which is always `thread.run.step.delta`.\n   */\n  object: 'thread.run.step.delta';\n}\n\n/**\n * Details of the message creation by the run step.\n */\nexport interface RunStepDeltaMessageDelta {\n  /**\n   * Always `message_creation`.\n   */\n  type: 'message_creation';\n\n  message_creation?: RunStepDeltaMessageDelta.MessageCreation;\n}\n\nexport namespace RunStepDeltaMessageDelta {\n  export interface MessageCreation {\n    /**\n     * The ID of the message that was created by this run step.\n     */\n    message_id?: string;\n  }\n}\n\nexport type RunStepInclude = 'step_details.tool_calls[*].file_search.results[*].content';\n\n/**\n * Details of the Code Interpreter tool call the run step was involved in.\n */\nexport type ToolCall = CodeInterpreterToolCall | FileSearchToolCall | FunctionToolCall;\n\n/**\n * Details of the Code Interpreter tool call the run step was involved in.\n */\nexport type ToolCallDelta = CodeInterpreterToolCallDelta | FileSearchToolCallDelta | FunctionToolCallDelta;\n\n/**\n * Details of the tool call.\n */\nexport interface ToolCallDeltaObject {\n  /**\n   * Always `tool_calls`.\n   */\n  type: 'tool_calls';\n\n  /**\n   * An array of tool calls the run step was involved in. These can be associated\n   * with one of three types of tools: `code_interpreter`, `file_search`, or\n   * `function`.\n   */\n  tool_calls?: Array<ToolCallDelta>;\n}\n\n/**\n * Details of the tool call.\n */\nexport interface ToolCallsStepDetails {\n  /**\n   * An array of tool calls the run step was involved in. These can be associated\n   * with one of three types of tools: `code_interpreter`, `file_search`, or\n   * `function`.\n   */\n  tool_calls: Array<ToolCall>;\n\n  /**\n   * Always `tool_calls`.\n   */\n  type: 'tool_calls';\n}\n\nexport interface StepRetrieveParams {\n  /**\n   * Path param: The ID of the thread to which the run and run step belongs.\n   */\n  thread_id: string;\n\n  /**\n   * Path param: The ID of the run to which the run step belongs.\n   */\n  run_id: string;\n\n  /**\n   * Query param: A list of additional fields to include in the response. Currently\n   * the only supported value is\n   * `step_details.tool_calls[*].file_search.results[*].content` to fetch the file\n   * search result content.\n   *\n   * See the\n   * [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings)\n   * for more information.\n   */\n  include?: Array<RunStepInclude>;\n}\n\nexport interface StepListParams extends CursorPageParams {\n  /**\n   * Path param: The ID of the thread the run and run steps belong to.\n   */\n  thread_id: string;\n\n  /**\n   * Query param: A cursor for use in pagination. `before` is an object ID that\n   * defines your place in the list. For instance, if you make a list request and\n   * receive 100 objects, starting with obj_foo, your subsequent call can include\n   * before=obj_foo in order to fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Query param: A list of additional fields to include in the response. Currently\n   * the only supported value is\n   * `step_details.tool_calls[*].file_search.results[*].content` to fetch the file\n   * search result content.\n   *\n   * See the\n   * [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings)\n   * for more information.\n   */\n  include?: Array<RunStepInclude>;\n\n  /**\n   * Query param: Sort order by the `created_at` timestamp of the objects. `asc` for\n   * ascending order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport declare namespace Steps {\n  export {\n    type CodeInterpreterLogs as CodeInterpreterLogs,\n    type CodeInterpreterOutputImage as CodeInterpreterOutputImage,\n    type CodeInterpreterToolCall as CodeInterpreterToolCall,\n    type CodeInterpreterToolCallDelta as CodeInterpreterToolCallDelta,\n    type FileSearchToolCall as FileSearchToolCall,\n    type FileSearchToolCallDelta as FileSearchToolCallDelta,\n    type FunctionToolCall as FunctionToolCall,\n    type FunctionToolCallDelta as FunctionToolCallDelta,\n    type MessageCreationStepDetails as MessageCreationStepDetails,\n    type RunStep as RunStep,\n    type RunStepDelta as RunStepDelta,\n    type RunStepDeltaEvent as RunStepDeltaEvent,\n    type RunStepDeltaMessageDelta as RunStepDeltaMessageDelta,\n    type RunStepInclude as RunStepInclude,\n    type ToolCall as ToolCall,\n    type ToolCallDelta as ToolCallDelta,\n    type ToolCallDeltaObject as ToolCallDeltaObject,\n    type ToolCallsStepDetails as ToolCallsStepDetails,\n    type RunStepsPage as RunStepsPage,\n    type StepRetrieveParams as StepRetrieveParams,\n    type StepListParams as StepListParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport type { FinalRequestOptions } from './request-options';\nimport { Stream } from '../core/streaming';\nimport { type OpenAI } from '../client';\nimport { formatRequestDetails, loggerFor } from './utils/log';\nimport type { AbstractPage } from '../pagination';\n\nexport type APIResponseProps = {\n  response: Response;\n  options: FinalRequestOptions;\n  controller: AbortController;\n  requestLogID: string;\n  retryOfRequestLogID: string | undefined;\n  startTime: number;\n};\n\nexport async function defaultParseResponse<T>(\n  client: OpenAI,\n  props: APIResponseProps,\n): Promise<WithRequestID<T>> {\n  const { response, requestLogID, retryOfRequestLogID, startTime } = props;\n  const body = await (async () => {\n    if (props.options.stream) {\n      loggerFor(client).debug('response', response.status, response.url, response.headers, response.body);\n\n      // Note: there is an invariant here that isn't represented in the type system\n      // that if you set `stream: true` the response type must also be `Stream<T>`\n\n      if (props.options.__streamClass) {\n        return props.options.__streamClass.fromSSEResponse(response, props.controller, client) as any;\n      }\n\n      return Stream.fromSSEResponse(response, props.controller, client) as any;\n    }\n\n    // fetch refuses to read the body when the status code is 204.\n    if (response.status === 204) {\n      return null as T;\n    }\n\n    if (props.options.__binaryResponse) {\n      return response as unknown as T;\n    }\n\n    const contentType = response.headers.get('content-type');\n    const mediaType = contentType?.split(';')[0]?.trim();\n    const isJSON = mediaType?.includes('application/json') || mediaType?.endsWith('+json');\n    if (isJSON) {\n      const json = await response.json();\n      return addRequestID(json as T, response);\n    }\n\n    const text = await response.text();\n    return text as unknown as T;\n  })();\n  loggerFor(client).debug(\n    `[${requestLogID}] response parsed`,\n    formatRequestDetails({\n      retryOfRequestLogID,\n      url: response.url,\n      status: response.status,\n      body,\n      durationMs: Date.now() - startTime,\n    }),\n  );\n  return body;\n}\n\nexport type WithRequestID<T> =\n  T extends Array<any> | Response | AbstractPage<any> ? T\n  : T extends Record<string, any> ? T & { _request_id?: string | null }\n  : T;\n\nexport function addRequestID<T>(value: T, response: Response): WithRequestID<T> {\n  if (!value || typeof value !== 'object' || Array.isArray(value)) {\n    return value as WithRequestID<T>;\n  }\n\n  return Object.defineProperty(value, '_request_id', {\n    value: response.headers.get('x-request-id'),\n    enumerable: false,\n  }) as WithRequestID<T>;\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { OpenAIError } from '../../core/error';\nimport { encodeUTF8 } from './bytes';\n\nexport const toBase64 = (data: string | Uint8Array | null | undefined): string => {\n  if (!data) return '';\n\n  if (typeof (globalThis as any).Buffer !== 'undefined') {\n    return (globalThis as any).Buffer.from(data).toString('base64');\n  }\n\n  if (typeof data === 'string') {\n    data = encodeUTF8(data);\n  }\n\n  if (typeof btoa !== 'undefined') {\n    return btoa(String.fromCharCode.apply(null, data as any));\n  }\n\n  throw new OpenAIError('Cannot generate base64 string; Expected `Buffer` or `btoa` to be defined');\n};\n\nexport const fromBase64 = (str: string): Uint8Array => {\n  if (typeof (globalThis as any).Buffer !== 'undefined') {\n    const buf = (globalThis as any).Buffer.from(str, 'base64');\n    return new Uint8Array(buf.buffer, buf.byteOffset, buf.byteLength);\n  }\n\n  if (typeof atob !== 'undefined') {\n    const bstr = atob(str);\n    const buf = new Uint8Array(bstr.length);\n    for (let i = 0; i < bstr.length; i++) {\n      buf[i] = bstr.charCodeAt(i);\n    }\n    return buf;\n  }\n\n  throw new OpenAIError('Cannot decode base64 string; Expected `Buffer` or `atob` to be defined');\n};\n\n/**\n * Converts a Base64 encoded string to a Float32Array.\n * @param base64Str - The Base64 encoded string.\n * @returns An Array of numbers interpreted as Float32 values.\n */\nexport const toFloat32Array = (base64Str: string): Array<number> => {\n  if (typeof Buffer !== 'undefined') {\n    // for Node.js environment\n    const buf = Buffer.from(base64Str, 'base64');\n    return Array.from(\n      new Float32Array(buf.buffer, buf.byteOffset, buf.length / Float32Array.BYTES_PER_ELEMENT),\n    );\n  } else {\n    // for legacy web platform APIs\n    const binaryStr = atob(base64Str);\n    const len = binaryStr.length;\n    const bytes = new Uint8Array(len);\n    for (let i = 0; i < len; i++) {\n      bytes[i] = binaryStr.charCodeAt(i);\n    }\n    return Array.from(new Float32Array(bytes.buffer));\n  }\n};\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nexport { Chat } from './chat';\nexport {\n  Completions,\n  type ChatCompletion,\n  type ChatCompletionAllowedToolChoice,\n  type ChatCompletionAssistantMessageParam,\n  type ChatCompletionAudio,\n  type ChatCompletionAudioParam,\n  type ChatCompletionChunk,\n  type ChatCompletionContentPart,\n  type ChatCompletionContentPartImage,\n  type ChatCompletionContentPartInputAudio,\n  type ChatCompletionContentPartRefusal,\n  type ChatCompletionContentPartText,\n  type ChatCompletionCustomTool,\n  type ChatCompletionDeleted,\n  type ChatCompletionDeveloperMessageParam,\n  type ChatCompletionFunctionCallOption,\n  type ChatCompletionFunctionMessageParam,\n  type ChatCompletionFunctionTool,\n  type ChatCompletionMessage,\n  type ChatCompletionMessageCustomToolCall,\n  type ChatCompletionMessageFunctionToolCall,\n  type ChatCompletionMessageParam,\n  type ChatCompletionMessageToolCall,\n  type ChatCompletionModality,\n  type ChatCompletionNamedToolChoice,\n  type ChatCompletionNamedToolChoiceCustom,\n  type ChatCompletionPredictionContent,\n  type ChatCompletionRole,\n  type ChatCompletionStoreMessage,\n  type ChatCompletionStreamOptions,\n  type ChatCompletionSystemMessageParam,\n  type ChatCompletionTokenLogprob,\n  type ChatCompletionTool,\n  type ChatCompletionToolChoiceOption,\n  type ChatCompletionToolMessageParam,\n  type ChatCompletionUserMessageParam,\n  type ChatCompletionAllowedTools,\n  type ChatCompletionCreateParams,\n  type ChatCompletionCreateParamsNonStreaming,\n  type ChatCompletionCreateParamsStreaming,\n  type ChatCompletionUpdateParams,\n  type ChatCompletionListParams,\n  type ChatCompletionStoreMessagesPage,\n  type ChatCompletionsPage,\n} from './completions/index';\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../../core/resource';\nimport * as RunsAPI from './runs';\nimport * as Shared from '../../../shared';\nimport * as AssistantsAPI from '../../assistants';\nimport * as MessagesAPI from '../messages';\nimport * as ThreadsAPI from '../threads';\nimport * as StepsAPI from './steps';\nimport {\n  CodeInterpreterLogs,\n  CodeInterpreterOutputImage,\n  CodeInterpreterToolCall,\n  CodeInterpreterToolCallDelta,\n  FileSearchToolCall,\n  FileSearchToolCallDelta,\n  FunctionToolCall,\n  FunctionToolCallDelta,\n  MessageCreationStepDetails,\n  RunStep,\n  RunStepDelta,\n  RunStepDeltaEvent,\n  RunStepDeltaMessageDelta,\n  RunStepInclude,\n  RunStepsPage,\n  StepListParams,\n  StepRetrieveParams,\n  Steps,\n  ToolCall,\n  ToolCallDelta,\n  ToolCallDeltaObject,\n  ToolCallsStepDetails,\n} from './steps';\nimport { APIPromise } from '../../../../core/api-promise';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../../../../core/pagination';\nimport { Stream } from '../../../../core/streaming';\nimport { buildHeaders } from '../../../../internal/headers';\nimport { RequestOptions } from '../../../../internal/request-options';\nimport { AssistantStream, RunCreateParamsBaseStream } from '../../../../lib/AssistantStream';\nimport { sleep } from '../../../../internal/utils/sleep';\nimport { RunSubmitToolOutputsParamsStream } from '../../../../lib/AssistantStream';\nimport { path } from '../../../../internal/utils/path';\n\n/**\n * @deprecated The Assistants API is deprecated in favor of the Responses API\n */\nexport class Runs extends APIResource {\n  steps: StepsAPI.Steps = new StepsAPI.Steps(this._client);\n\n  /**\n   * Create a run.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  create(threadID: string, params: RunCreateParamsNonStreaming, options?: RequestOptions): APIPromise<Run>;\n  create(\n    threadID: string,\n    params: RunCreateParamsStreaming,\n    options?: RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  create(\n    threadID: string,\n    params: RunCreateParamsBase,\n    options?: RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent> | Run>;\n  create(\n    threadID: string,\n    params: RunCreateParams,\n    options?: RequestOptions,\n  ): APIPromise<Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>> {\n    const { include, ...body } = params;\n    return this._client.post(path`/threads/${threadID}/runs`, {\n      query: { include },\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n      stream: params.stream ?? false,\n    }) as APIPromise<Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  }\n\n  /**\n   * Retrieves a run.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  retrieve(runID: string, params: RunRetrieveParams, options?: RequestOptions): APIPromise<Run> {\n    const { thread_id } = params;\n    return this._client.get(path`/threads/${thread_id}/runs/${runID}`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Modifies a run.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  update(runID: string, params: RunUpdateParams, options?: RequestOptions): APIPromise<Run> {\n    const { thread_id, ...body } = params;\n    return this._client.post(path`/threads/${thread_id}/runs/${runID}`, {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Returns a list of runs belonging to a thread.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  list(\n    threadID: string,\n    query: RunListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<RunsPage, Run> {\n    return this._client.getAPIList(path`/threads/${threadID}/runs`, CursorPage<Run>, {\n      query,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Cancels a run that is `in_progress`.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  cancel(runID: string, params: RunCancelParams, options?: RequestOptions): APIPromise<Run> {\n    const { thread_id } = params;\n    return this._client.post(path`/threads/${thread_id}/runs/${runID}/cancel`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * A helper to create a run an poll for a terminal state. More information on Run\n   * lifecycles can be found here:\n   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n   */\n  async createAndPoll(\n    threadId: string,\n    body: RunCreateParamsNonStreaming,\n    options?: RequestOptions & { pollIntervalMs?: number },\n  ): Promise<Run> {\n    const run = await this.create(threadId, body, options);\n    return await this.poll(run.id, { thread_id: threadId }, options);\n  }\n\n  /**\n   * Create a Run stream\n   *\n   * @deprecated use `stream` instead\n   */\n  createAndStream(\n    threadId: string,\n    body: RunCreateParamsBaseStream,\n    options?: RequestOptions,\n  ): AssistantStream {\n    return AssistantStream.createAssistantStream(threadId, this._client.beta.threads.runs, body, options);\n  }\n\n  /**\n   * A helper to poll a run status until it reaches a terminal state. More\n   * information on Run lifecycles can be found here:\n   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n   */\n  async poll(\n    runId: string,\n    params: RunRetrieveParams,\n    options?: RequestOptions & { pollIntervalMs?: number },\n  ): Promise<Run> {\n    const headers = buildHeaders([\n      options?.headers,\n      {\n        'X-Stainless-Poll-Helper': 'true',\n        'X-Stainless-Custom-Poll-Interval': options?.pollIntervalMs?.toString() ?? undefined,\n      },\n    ]);\n\n    while (true) {\n      const { data: run, response } = await this.retrieve(runId, params, {\n        ...options,\n        headers: { ...options?.headers, ...headers },\n      }).withResponse();\n\n      switch (run.status) {\n        //If we are in any sort of intermediate state we poll\n        case 'queued':\n        case 'in_progress':\n        case 'cancelling':\n          let sleepInterval = 5000;\n\n          if (options?.pollIntervalMs) {\n            sleepInterval = options.pollIntervalMs;\n          } else {\n            const headerInterval = response.headers.get('openai-poll-after-ms');\n            if (headerInterval) {\n              const headerIntervalMs = parseInt(headerInterval);\n              if (!isNaN(headerIntervalMs)) {\n                sleepInterval = headerIntervalMs;\n              }\n            }\n          }\n          await sleep(sleepInterval);\n          break;\n        //We return the run in any terminal state.\n        case 'requires_action':\n        case 'incomplete':\n        case 'cancelled':\n        case 'completed':\n        case 'failed':\n        case 'expired':\n          return run;\n      }\n    }\n  }\n\n  /**\n   * Create a Run stream\n   */\n  stream(threadId: string, body: RunCreateParamsBaseStream, options?: RequestOptions): AssistantStream {\n    return AssistantStream.createAssistantStream(threadId, this._client.beta.threads.runs, body, options);\n  }\n\n  /**\n   * When a run has the `status: \"requires_action\"` and `required_action.type` is\n   * `submit_tool_outputs`, this endpoint can be used to submit the outputs from the\n   * tool calls once they're all completed. All outputs must be submitted in a single\n   * request.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  submitToolOutputs(\n    runID: string,\n    params: RunSubmitToolOutputsParamsNonStreaming,\n    options?: RequestOptions,\n  ): APIPromise<Run>;\n  submitToolOutputs(\n    runID: string,\n    params: RunSubmitToolOutputsParamsStreaming,\n    options?: RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  submitToolOutputs(\n    runID: string,\n    params: RunSubmitToolOutputsParamsBase,\n    options?: RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent> | Run>;\n  submitToolOutputs(\n    runID: string,\n    params: RunSubmitToolOutputsParams,\n    options?: RequestOptions,\n  ): APIPromise<Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>> {\n    const { thread_id, ...body } = params;\n    return this._client.post(path`/threads/${thread_id}/runs/${runID}/submit_tool_outputs`, {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n      stream: params.stream ?? false,\n    }) as APIPromise<Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  }\n\n  /**\n   * A helper to submit a tool output to a run and poll for a terminal run state.\n   * More information on Run lifecycles can be found here:\n   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n   */\n  async submitToolOutputsAndPoll(\n    runId: string,\n    params: RunSubmitToolOutputsParamsNonStreaming,\n    options?: RequestOptions & { pollIntervalMs?: number },\n  ): Promise<Run> {\n    const run = await this.submitToolOutputs(runId, params, options);\n    return await this.poll(run.id, params, options);\n  }\n\n  /**\n   * Submit the tool outputs from a previous run and stream the run to a terminal\n   * state. More information on Run lifecycles can be found here:\n   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n   */\n  submitToolOutputsStream(\n    runId: string,\n    params: RunSubmitToolOutputsParamsStream,\n    options?: RequestOptions,\n  ): AssistantStream {\n    return AssistantStream.createToolAssistantStream(runId, this._client.beta.threads.runs, params, options);\n  }\n}\n\nexport type RunsPage = CursorPage<Run>;\n\n/**\n * Tool call objects\n */\nexport interface RequiredActionFunctionToolCall {\n  /**\n   * The ID of the tool call. This ID must be referenced when you submit the tool\n   * outputs in using the\n   * [Submit tool outputs to run](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs)\n   * endpoint.\n   */\n  id: string;\n\n  /**\n   * The function definition.\n   */\n  function: RequiredActionFunctionToolCall.Function;\n\n  /**\n   * The type of tool call the output is required for. For now, this is always\n   * `function`.\n   */\n  type: 'function';\n}\n\nexport namespace RequiredActionFunctionToolCall {\n  /**\n   * The function definition.\n   */\n  export interface Function {\n    /**\n     * The arguments that the model expects you to pass to the function.\n     */\n    arguments: string;\n\n    /**\n     * The name of the function.\n     */\n    name: string;\n  }\n}\n\n/**\n * Represents an execution run on a\n * [thread](https://platform.openai.com/docs/api-reference/threads).\n */\nexport interface Run {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) used for\n   * execution of this run.\n   */\n  assistant_id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run was cancelled.\n   */\n  cancelled_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run was completed.\n   */\n  completed_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run was created.\n   */\n  created_at: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run will expire.\n   */\n  expires_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run failed.\n   */\n  failed_at: number | null;\n\n  /**\n   * Details on why the run is incomplete. Will be `null` if the run is not\n   * incomplete.\n   */\n  incomplete_details: Run.IncompleteDetails | null;\n\n  /**\n   * The instructions that the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) used for\n   * this run.\n   */\n  instructions: string;\n\n  /**\n   * The last error associated with this run. Will be `null` if there are no errors.\n   */\n  last_error: Run.LastError | null;\n\n  /**\n   * The maximum number of completion tokens specified to have been used over the\n   * course of the run.\n   */\n  max_completion_tokens: number | null;\n\n  /**\n   * The maximum number of prompt tokens specified to have been used over the course\n   * of the run.\n   */\n  max_prompt_tokens: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * The model that the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) used for\n   * this run.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always `thread.run`.\n   */\n  object: 'thread.run';\n\n  /**\n   * Whether to enable\n   * [parallel function calling](https://platform.openai.com/docs/guides/function-calling#configuring-parallel-function-calling)\n   * during tool use.\n   */\n  parallel_tool_calls: boolean;\n\n  /**\n   * Details on the action required to continue the run. Will be `null` if no action\n   * is required.\n   */\n  required_action: Run.RequiredAction | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models#gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run was started.\n   */\n  started_at: number | null;\n\n  /**\n   * The status of the run, which can be either `queued`, `in_progress`,\n   * `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`,\n   * `incomplete`, or `expired`.\n   */\n  status: RunStatus;\n\n  /**\n   * The ID of the [thread](https://platform.openai.com/docs/api-reference/threads)\n   * that was executed on as a part of this run.\n   */\n  thread_id: string;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice: ThreadsAPI.AssistantToolChoiceOption | null;\n\n  /**\n   * The list of tools that the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) used for\n   * this run.\n   */\n  tools: Array<AssistantsAPI.AssistantTool>;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the initial context window of the run.\n   */\n  truncation_strategy: Run.TruncationStrategy | null;\n\n  /**\n   * Usage statistics related to the run. This value will be `null` if the run is not\n   * in a terminal state (i.e. `in_progress`, `queued`, etc.).\n   */\n  usage: Run.Usage | null;\n\n  /**\n   * The sampling temperature used for this run. If not set, defaults to 1.\n   */\n  temperature?: number | null;\n\n  /**\n   * The nucleus sampling value used for this run. If not set, defaults to 1.\n   */\n  top_p?: number | null;\n}\n\nexport namespace Run {\n  /**\n   * Details on why the run is incomplete. Will be `null` if the run is not\n   * incomplete.\n   */\n  export interface IncompleteDetails {\n    /**\n     * The reason why the run is incomplete. This will point to which specific token\n     * limit was reached over the course of the run.\n     */\n    reason?: 'max_completion_tokens' | 'max_prompt_tokens';\n  }\n\n  /**\n   * The last error associated with this run. Will be `null` if there are no errors.\n   */\n  export interface LastError {\n    /**\n     * One of `server_error`, `rate_limit_exceeded`, or `invalid_prompt`.\n     */\n    code: 'server_error' | 'rate_limit_exceeded' | 'invalid_prompt';\n\n    /**\n     * A human-readable description of the error.\n     */\n    message: string;\n  }\n\n  /**\n   * Details on the action required to continue the run. Will be `null` if no action\n   * is required.\n   */\n  export interface RequiredAction {\n    /**\n     * Details on the tool outputs needed for this run to continue.\n     */\n    submit_tool_outputs: RequiredAction.SubmitToolOutputs;\n\n    /**\n     * For now, this is always `submit_tool_outputs`.\n     */\n    type: 'submit_tool_outputs';\n  }\n\n  export namespace RequiredAction {\n    /**\n     * Details on the tool outputs needed for this run to continue.\n     */\n    export interface SubmitToolOutputs {\n      /**\n       * A list of the relevant tool calls.\n       */\n      tool_calls: Array<RunsAPI.RequiredActionFunctionToolCall>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the initial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n\n  /**\n   * Usage statistics related to the run. This value will be `null` if the run is not\n   * in a terminal state (i.e. `in_progress`, `queued`, etc.).\n   */\n  export interface Usage {\n    /**\n     * Number of completion tokens used over the course of the run.\n     */\n    completion_tokens: number;\n\n    /**\n     * Number of prompt tokens used over the course of the run.\n     */\n    prompt_tokens: number;\n\n    /**\n     * Total number of tokens used (prompt + completion).\n     */\n    total_tokens: number;\n  }\n}\n\n/**\n * The status of the run, which can be either `queued`, `in_progress`,\n * `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`,\n * `incomplete`, or `expired`.\n */\nexport type RunStatus =\n  | 'queued'\n  | 'in_progress'\n  | 'requires_action'\n  | 'cancelling'\n  | 'cancelled'\n  | 'failed'\n  | 'completed'\n  | 'incomplete'\n  | 'expired';\n\nexport type RunCreateParams = RunCreateParamsNonStreaming | RunCreateParamsStreaming;\n\nexport interface RunCreateParamsBase {\n  /**\n   * Body param: The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Query param: A list of additional fields to include in the response. Currently\n   * the only supported value is\n   * `step_details.tool_calls[*].file_search.results[*].content` to fetch the file\n   * search result content.\n   *\n   * See the\n   * [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings)\n   * for more information.\n   */\n  include?: Array<StepsAPI.RunStepInclude>;\n\n  /**\n   * Body param: Appends additional instructions at the end of the instructions for\n   * the run. This is useful for modifying the behavior on a per-run basis without\n   * overriding other instructions.\n   */\n  additional_instructions?: string | null;\n\n  /**\n   * Body param: Adds additional messages to the thread before creating the run.\n   */\n  additional_messages?: Array<RunCreateParams.AdditionalMessage> | null;\n\n  /**\n   * Body param: Overrides the\n   * [instructions](https://platform.openai.com/docs/api-reference/assistants/createAssistant)\n   * of the assistant. This is useful for modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * Body param: The maximum number of completion tokens that may be used over the\n   * course of the run. The run will make a best effort to use only the number of\n   * completion tokens specified, across multiple turns of the run. If the run\n   * exceeds the number of completion tokens specified, the run will end with status\n   * `incomplete`. See `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * Body param: The maximum number of prompt tokens that may be used over the course\n   * of the run. The run will make a best effort to use only the number of prompt\n   * tokens specified, across multiple turns of the run. If the run exceeds the\n   * number of prompt tokens specified, the run will end with status `incomplete`.\n   * See `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Body param: Set of 16 key-value pairs that can be attached to an object. This\n   * can be useful for storing additional information about the object in a\n   * structured format, and querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * Body param: The ID of the\n   * [Model](https://platform.openai.com/docs/api-reference/models) to be used to\n   * execute this run. If a value is provided here, it will override the model\n   * associated with the assistant. If not, the model associated with the assistant\n   * will be used.\n   */\n  model?: (string & {}) | Shared.ChatModel | null;\n\n  /**\n   * Body param: Whether to enable\n   * [parallel function calling](https://platform.openai.com/docs/guides/function-calling#configuring-parallel-function-calling)\n   * during tool use.\n   */\n  parallel_tool_calls?: boolean;\n\n  /**\n   * Body param: Constrains effort on reasoning for\n   * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n   * supported values are `minimal`, `low`, `medium`, and `high`. Reducing reasoning\n   * effort can result in faster responses and fewer tokens used on reasoning in a\n   * response.\n   *\n   * Note: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning\n   * effort.\n   */\n  reasoning_effort?: Shared.ReasoningEffort | null;\n\n  /**\n   * Body param: Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models#gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * Body param: If `true`, returns a stream of events that happen during the Run as\n   * server-sent events, terminating when the Run enters a terminal state with a\n   * `data: [DONE]` message.\n   */\n  stream?: boolean | null;\n\n  /**\n   * Body param: What sampling temperature to use, between 0 and 2. Higher values\n   * like 0.8 will make the output more random, while lower values like 0.2 will make\n   * it more focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * Body param: Controls which (if any) tool is called by the model. `none` means\n   * the model will not call any tools and instead generates a message. `auto` is the\n   * default value and means the model can pick between generating a message or\n   * calling one or more tools. `required` means the model must call one or more\n   * tools before responding to the user. Specifying a particular tool like\n   * `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: ThreadsAPI.AssistantToolChoiceOption | null;\n\n  /**\n   * Body param: Override the tools the assistant can use for this run. This is\n   * useful for modifying the behavior on a per-run basis.\n   */\n  tools?: Array<AssistantsAPI.AssistantTool> | null;\n\n  /**\n   * Body param: An alternative to sampling with temperature, called nucleus\n   * sampling, where the model considers the results of the tokens with top_p\n   * probability mass. So 0.1 means only the tokens comprising the top 10%\n   * probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Body param: Controls for how a thread will be truncated prior to the run. Use\n   * this to control the initial context window of the run.\n   */\n  truncation_strategy?: RunCreateParams.TruncationStrategy | null;\n}\n\nexport namespace RunCreateParams {\n  export interface AdditionalMessage {\n    /**\n     * The text contents of the message.\n     */\n    content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n    /**\n     * The role of the entity that is creating the message. Allowed values include:\n     *\n     * - `user`: Indicates the message is sent by an actual user and should be used in\n     *   most cases to represent user-generated messages.\n     * - `assistant`: Indicates the message is generated by the assistant. Use this\n     *   value to insert messages from the assistant into the conversation.\n     */\n    role: 'user' | 'assistant';\n\n    /**\n     * A list of files attached to the message, and the tools they should be added to.\n     */\n    attachments?: Array<AdditionalMessage.Attachment> | null;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format, and\n     * querying for objects via API or the dashboard.\n     *\n     * Keys are strings with a maximum length of 64 characters. Values are strings with\n     * a maximum length of 512 characters.\n     */\n    metadata?: Shared.Metadata | null;\n  }\n\n  export namespace AdditionalMessage {\n    export interface Attachment {\n      /**\n       * The ID of the file to attach to the message.\n       */\n      file_id?: string;\n\n      /**\n       * The tools to add this file to.\n       */\n      tools?: Array<AssistantsAPI.CodeInterpreterTool | Attachment.FileSearch>;\n    }\n\n    export namespace Attachment {\n      export interface FileSearch {\n        /**\n         * The type of tool being defined: `file_search`\n         */\n        type: 'file_search';\n      }\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the initial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n\n  export type RunCreateParamsNonStreaming = RunsAPI.RunCreateParamsNonStreaming;\n  export type RunCreateParamsStreaming = RunsAPI.RunCreateParamsStreaming;\n}\n\nexport interface RunCreateParamsNonStreaming extends RunCreateParamsBase {\n  /**\n   * Body param: If `true`, returns a stream of events that happen during the Run as\n   * server-sent events, terminating when the Run enters a terminal state with a\n   * `data: [DONE]` message.\n   */\n  stream?: false | null;\n}\n\nexport interface RunCreateParamsStreaming extends RunCreateParamsBase {\n  /**\n   * Body param: If `true`, returns a stream of events that happen during the Run as\n   * server-sent events, terminating when the Run enters a terminal state with a\n   * `data: [DONE]` message.\n   */\n  stream: true;\n}\n\nexport interface RunRetrieveParams {\n  /**\n   * The ID of the [thread](https://platform.openai.com/docs/api-reference/threads)\n   * that was run.\n   */\n  thread_id: string;\n}\n\nexport interface RunUpdateParams {\n  /**\n   * Path param: The ID of the\n   * [thread](https://platform.openai.com/docs/api-reference/threads) that was run.\n   */\n  thread_id: string;\n\n  /**\n   * Body param: Set of 16 key-value pairs that can be attached to an object. This\n   * can be useful for storing additional information about the object in a\n   * structured format, and querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n}\n\nexport interface RunListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * starting with obj_foo, your subsequent call can include before=obj_foo in order\n   * to fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport interface RunCancelParams {\n  /**\n   * The ID of the thread to which this run belongs.\n   */\n  thread_id: string;\n}\n\nexport type RunCreateAndPollParams = ThreadsAPI.ThreadCreateAndRunParamsNonStreaming;\n\nexport type RunCreateAndStreamParams = RunCreateParamsBaseStream;\n\nexport type RunStreamParams = RunCreateParamsBaseStream;\n\nexport type RunSubmitToolOutputsParams =\n  | RunSubmitToolOutputsParamsNonStreaming\n  | RunSubmitToolOutputsParamsStreaming;\n\nexport interface RunSubmitToolOutputsParamsBase {\n  /**\n   * Path param: The ID of the\n   * [thread](https://platform.openai.com/docs/api-reference/threads) to which this\n   * run belongs.\n   */\n  thread_id: string;\n\n  /**\n   * Body param: A list of tools for which the outputs are being submitted.\n   */\n  tool_outputs: Array<RunSubmitToolOutputsParams.ToolOutput>;\n\n  /**\n   * Body param: If `true`, returns a stream of events that happen during the Run as\n   * server-sent events, terminating when the Run enters a terminal state with a\n   * `data: [DONE]` message.\n   */\n  stream?: boolean | null;\n}\n\nexport namespace RunSubmitToolOutputsParams {\n  export interface ToolOutput {\n    /**\n     * The output of the tool call to be submitted to continue the run.\n     */\n    output?: string;\n\n    /**\n     * The ID of the tool call in the `required_action` object within the run object\n     * the output is being submitted for.\n     */\n    tool_call_id?: string;\n  }\n\n  export type RunSubmitToolOutputsParamsNonStreaming = RunsAPI.RunSubmitToolOutputsParamsNonStreaming;\n  export type RunSubmitToolOutputsParamsStreaming = RunsAPI.RunSubmitToolOutputsParamsStreaming;\n}\n\nexport interface RunSubmitToolOutputsParamsNonStreaming extends RunSubmitToolOutputsParamsBase {\n  /**\n   * Body param: If `true`, returns a stream of events that happen during the Run as\n   * server-sent events, terminating when the Run enters a terminal state with a\n   * `data: [DONE]` message.\n   */\n  stream?: false | null;\n}\n\nexport interface RunSubmitToolOutputsParamsStreaming extends RunSubmitToolOutputsParamsBase {\n  /**\n   * Body param: If `true`, returns a stream of events that happen during the Run as\n   * server-sent events, terminating when the Run enters a terminal state with a\n   * `data: [DONE]` message.\n   */\n  stream: true;\n}\n\nexport type RunSubmitToolOutputsAndPollParams = RunSubmitToolOutputsParamsNonStreaming;\nexport type RunSubmitToolOutputsStreamParams = RunSubmitToolOutputsParamsStream;\n\nRuns.Steps = Steps;\n\nexport declare namespace Runs {\n  export {\n    type RequiredActionFunctionToolCall as RequiredActionFunctionToolCall,\n    type Run as Run,\n    type RunStatus as RunStatus,\n    type RunsPage as RunsPage,\n    type RunCreateParams as RunCreateParams,\n    type RunCreateParamsNonStreaming as RunCreateParamsNonStreaming,\n    type RunCreateParamsStreaming as RunCreateParamsStreaming,\n    type RunRetrieveParams as RunRetrieveParams,\n    type RunUpdateParams as RunUpdateParams,\n    type RunListParams as RunListParams,\n    type RunCreateAndPollParams,\n    type RunCreateAndStreamParams,\n    type RunStreamParams,\n    type RunSubmitToolOutputsParams as RunSubmitToolOutputsParams,\n    type RunSubmitToolOutputsParamsNonStreaming as RunSubmitToolOutputsParamsNonStreaming,\n    type RunSubmitToolOutputsParamsStreaming as RunSubmitToolOutputsParamsStreaming,\n    type RunSubmitToolOutputsAndPollParams,\n    type RunSubmitToolOutputsStreamParams,\n  };\n\n  export {\n    Steps as Steps,\n    type CodeInterpreterLogs as CodeInterpreterLogs,\n    type CodeInterpreterOutputImage as CodeInterpreterOutputImage,\n    type CodeInterpreterToolCall as CodeInterpreterToolCall,\n    type CodeInterpreterToolCallDelta as CodeInterpreterToolCallDelta,\n    type FileSearchToolCall as FileSearchToolCall,\n    type FileSearchToolCallDelta as FileSearchToolCallDelta,\n    type FunctionToolCall as FunctionToolCall,\n    type FunctionToolCallDelta as FunctionToolCallDelta,\n    type MessageCreationStepDetails as MessageCreationStepDetails,\n    type RunStep as RunStep,\n    type RunStepDelta as RunStepDelta,\n    type RunStepDeltaEvent as RunStepDeltaEvent,\n    type RunStepDeltaMessageDelta as RunStepDeltaMessageDelta,\n    type RunStepInclude as RunStepInclude,\n    type ToolCall as ToolCall,\n    type ToolCallDelta as ToolCallDelta,\n    type ToolCallDeltaObject as ToolCallDeltaObject,\n    type ToolCallsStepDetails as ToolCallsStepDetails,\n    type RunStepsPage as RunStepsPage,\n    type StepRetrieveParams as StepRetrieveParams,\n    type StepListParams as StepListParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { isReadonlyArray } from './utils/values';\n\ntype HeaderValue = string | undefined | null;\nexport type HeadersLike =\n  | Headers\n  | readonly HeaderValue[][]\n  | Record<string, HeaderValue | readonly HeaderValue[]>\n  | undefined\n  | null\n  | NullableHeaders;\n\nconst brand_privateNullableHeaders = /* @__PURE__ */ Symbol('brand.privateNullableHeaders');\n\n/**\n * @internal\n * Users can pass explicit nulls to unset default headers. When we parse them\n * into a standard headers type we need to preserve that information.\n */\nexport type NullableHeaders = {\n  /** Brand check, prevent users from creating a NullableHeaders. */\n  [brand_privateNullableHeaders]: true;\n  /** Parsed headers. */\n  values: Headers;\n  /** Set of lowercase header names explicitly set to null. */\n  nulls: Set<string>;\n};\n\nfunction* iterateHeaders(headers: HeadersLike): IterableIterator<readonly [string, string | null]> {\n  if (!headers) return;\n\n  if (brand_privateNullableHeaders in headers) {\n    const { values, nulls } = headers;\n    yield* values.entries();\n    for (const name of nulls) {\n      yield [name, null];\n    }\n    return;\n  }\n\n  let shouldClear = false;\n  let iter: Iterable<readonly (HeaderValue | readonly HeaderValue[])[]>;\n  if (headers instanceof Headers) {\n    iter = headers.entries();\n  } else if (isReadonlyArray(headers)) {\n    iter = headers;\n  } else {\n    shouldClear = true;\n    iter = Object.entries(headers ?? {});\n  }\n  for (let row of iter) {\n    const name = row[0];\n    if (typeof name !== 'string') throw new TypeError('expected header name to be a string');\n    const values = isReadonlyArray(row[1]) ? row[1] : [row[1]];\n    let didClear = false;\n    for (const value of values) {\n      if (value === undefined) continue;\n\n      // Objects keys always overwrite older headers, they never append.\n      // Yield a null to clear the header before adding the new values.\n      if (shouldClear && !didClear) {\n        didClear = true;\n        yield [name, null];\n      }\n      yield [name, value];\n    }\n  }\n}\n\nexport const buildHeaders = (newHeaders: HeadersLike[]): NullableHeaders => {\n  const targetHeaders = new Headers();\n  const nullHeaders = new Set<string>();\n  for (const headers of newHeaders) {\n    const seenHeaders = new Set<string>();\n    for (const [name, value] of iterateHeaders(headers)) {\n      const lowerName = name.toLowerCase();\n      if (!seenHeaders.has(lowerName)) {\n        targetHeaders.delete(name);\n        seenHeaders.add(lowerName);\n      }\n      if (value === null) {\n        targetHeaders.delete(name);\n        nullHeaders.add(lowerName);\n      } else {\n        targetHeaders.append(name, value);\n        nullHeaders.delete(lowerName);\n      }\n    }\n  }\n  return { [brand_privateNullableHeaders]: true, values: targetHeaders, nulls: nullHeaders };\n};\n\nexport const isEmptyHeaders = (headers: HeadersLike) => {\n  for (const _ of iterateHeaders(headers)) return false;\n  return true;\n};\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport * as ThreadsAPI from './threads';\nimport * as Shared from '../../shared';\nimport * as AssistantsAPI from '../assistants';\nimport * as MessagesAPI from './messages';\nimport {\n  Annotation,\n  AnnotationDelta,\n  FileCitationAnnotation,\n  FileCitationDeltaAnnotation,\n  FilePathAnnotation,\n  FilePathDeltaAnnotation,\n  ImageFile,\n  ImageFileContentBlock,\n  ImageFileDelta,\n  ImageFileDeltaBlock,\n  ImageURL,\n  ImageURLContentBlock,\n  ImageURLDelta,\n  ImageURLDeltaBlock,\n  Message as MessagesAPIMessage,\n  MessageContent,\n  MessageContentDelta,\n  MessageContentPartParam,\n  MessageCreateParams,\n  MessageDeleteParams,\n  MessageDeleted,\n  MessageDelta,\n  MessageDeltaEvent,\n  MessageListParams,\n  MessageRetrieveParams,\n  MessageUpdateParams,\n  Messages,\n  MessagesPage,\n  RefusalContentBlock,\n  RefusalDeltaBlock,\n  Text,\n  TextContentBlock,\n  TextContentBlockParam,\n  TextDelta,\n  TextDeltaBlock,\n} from './messages';\nimport * as RunsAPI from './runs/runs';\nimport {\n  RequiredActionFunctionToolCall,\n  Run,\n  RunCreateAndPollParams,\n  RunCreateAndStreamParams,\n  RunCancelParams,\n  RunCreateParams,\n  RunCreateParamsNonStreaming,\n  RunCreateParamsStreaming,\n  RunListParams,\n  RunRetrieveParams,\n  RunStatus,\n  RunStreamParams,\n  RunSubmitToolOutputsAndPollParams,\n  RunSubmitToolOutputsParams,\n  RunSubmitToolOutputsParamsNonStreaming,\n  RunSubmitToolOutputsParamsStreaming,\n  RunSubmitToolOutputsStreamParams,\n  RunUpdateParams,\n  Runs,\n  RunsPage,\n} from './runs/runs';\nimport { APIPromise } from '../../../core/api-promise';\nimport { Stream } from '../../../core/streaming';\nimport { buildHeaders } from '../../../internal/headers';\nimport { RequestOptions } from '../../../internal/request-options';\nimport { AssistantStream, ThreadCreateAndRunParamsBaseStream } from '../../../lib/AssistantStream';\nimport { path } from '../../../internal/utils/path';\n\n/**\n * @deprecated The Assistants API is deprecated in favor of the Responses API\n */\nexport class Threads extends APIResource {\n  runs: RunsAPI.Runs = new RunsAPI.Runs(this._client);\n  messages: MessagesAPI.Messages = new MessagesAPI.Messages(this._client);\n\n  /**\n   * Create a thread.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  create(body: ThreadCreateParams | null | undefined = {}, options?: RequestOptions): APIPromise<Thread> {\n    return this._client.post('/threads', {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Retrieves a thread.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  retrieve(threadID: string, options?: RequestOptions): APIPromise<Thread> {\n    return this._client.get(path`/threads/${threadID}`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Modifies a thread.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  update(threadID: string, body: ThreadUpdateParams, options?: RequestOptions): APIPromise<Thread> {\n    return this._client.post(path`/threads/${threadID}`, {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Delete a thread.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  delete(threadID: string, options?: RequestOptions): APIPromise<ThreadDeleted> {\n    return this._client.delete(path`/threads/${threadID}`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Create a thread and run it in one request.\n   *\n   * @deprecated The Assistants API is deprecated in favor of the Responses API\n   */\n  createAndRun(body: ThreadCreateAndRunParamsNonStreaming, options?: RequestOptions): APIPromise<RunsAPI.Run>;\n  createAndRun(\n    body: ThreadCreateAndRunParamsStreaming,\n    options?: RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  createAndRun(\n    body: ThreadCreateAndRunParamsBase,\n    options?: RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent> | RunsAPI.Run>;\n  createAndRun(\n    body: ThreadCreateAndRunParams,\n    options?: RequestOptions,\n  ): APIPromise<RunsAPI.Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>> {\n    return this._client.post('/threads/runs', {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n      stream: body.stream ?? false,\n    }) as APIPromise<RunsAPI.Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  }\n\n  /**\n   * A helper to create a thread, start a run and then poll for a terminal state.\n   * More information on Run lifecycles can be found here:\n   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n   */\n  async createAndRunPoll(\n    body: ThreadCreateAndRunParamsNonStreaming,\n    options?: RequestOptions & { pollIntervalMs?: number },\n  ): Promise<Threads.Run> {\n    const run = await this.createAndRun(body, options);\n    return await this.runs.poll(run.id, { thread_id: run.thread_id }, options);\n  }\n\n  /**\n   * Create a thread and stream the run back\n   */\n  createAndRunStream(body: ThreadCreateAndRunParamsBaseStream, options?: RequestOptions): AssistantStream {\n    return AssistantStream.createThreadAssistantStream(body, this._client.beta.threads, options);\n  }\n}\n\n/**\n * Specifies the format that the model must output. Compatible with\n * [GPT-4o](https://platform.openai.com/docs/models#gpt-4o),\n * [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4),\n * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n *\n * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n * Outputs which ensures the model will match your supplied JSON schema. Learn more\n * in the\n * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n *\n * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n * message the model generates is valid JSON.\n *\n * **Important:** when using JSON mode, you **must** also instruct the model to\n * produce JSON yourself via a system or user message. Without this, the model may\n * generate an unending stream of whitespace until the generation reaches the token\n * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n * the message content may be partially cut off if `finish_reason=\"length\"`, which\n * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n * max context length.\n */\nexport type AssistantResponseFormatOption =\n  | 'auto'\n  | Shared.ResponseFormatText\n  | Shared.ResponseFormatJSONObject\n  | Shared.ResponseFormatJSONSchema;\n\n/**\n * Specifies a tool the model should use. Use to force the model to call a specific\n * tool.\n */\nexport interface AssistantToolChoice {\n  /**\n   * The type of the tool. If type is `function`, the function name must be set\n   */\n  type: 'function' | 'code_interpreter' | 'file_search';\n\n  function?: AssistantToolChoiceFunction;\n}\n\nexport interface AssistantToolChoiceFunction {\n  /**\n   * The name of the function to call.\n   */\n  name: string;\n}\n\n/**\n * Controls which (if any) tool is called by the model. `none` means the model will\n * not call any tools and instead generates a message. `auto` is the default value\n * and means the model can pick between generating a message or calling one or more\n * tools. `required` means the model must call one or more tools before responding\n * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n * call that tool.\n */\nexport type AssistantToolChoiceOption = 'none' | 'auto' | 'required' | AssistantToolChoice;\n\n/**\n * Represents a thread that contains\n * [messages](https://platform.openai.com/docs/api-reference/messages).\n */\nexport interface Thread {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the thread was created.\n   */\n  created_at: number;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * The object type, which is always `thread`.\n   */\n  object: 'thread';\n\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  tool_resources: Thread.ToolResources | null;\n}\n\nexport namespace Thread {\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this thread. There can be a maximum of 1 vector store attached to\n       * the thread.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n}\n\nexport interface ThreadDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'thread.deleted';\n}\n\nexport interface ThreadCreateParams {\n  /**\n   * A list of [messages](https://platform.openai.com/docs/api-reference/messages) to\n   * start the thread with.\n   */\n  messages?: Array<ThreadCreateParams.Message>;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  tool_resources?: ThreadCreateParams.ToolResources | null;\n}\n\nexport namespace ThreadCreateParams {\n  export interface Message {\n    /**\n     * The text contents of the message.\n     */\n    content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n    /**\n     * The role of the entity that is creating the message. Allowed values include:\n     *\n     * - `user`: Indicates the message is sent by an actual user and should be used in\n     *   most cases to represent user-generated messages.\n     * - `assistant`: Indicates the message is generated by the assistant. Use this\n     *   value to insert messages from the assistant into the conversation.\n     */\n    role: 'user' | 'assistant';\n\n    /**\n     * A list of files attached to the message, and the tools they should be added to.\n     */\n    attachments?: Array<Message.Attachment> | null;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format, and\n     * querying for objects via API or the dashboard.\n     *\n     * Keys are strings with a maximum length of 64 characters. Values are strings with\n     * a maximum length of 512 characters.\n     */\n    metadata?: Shared.Metadata | null;\n  }\n\n  export namespace Message {\n    export interface Attachment {\n      /**\n       * The ID of the file to attach to the message.\n       */\n      file_id?: string;\n\n      /**\n       * The tools to add this file to.\n       */\n      tools?: Array<AssistantsAPI.CodeInterpreterTool | Attachment.FileSearch>;\n    }\n\n    export namespace Attachment {\n      export interface FileSearch {\n        /**\n         * The type of tool being defined: `file_search`\n         */\n        type: 'file_search';\n      }\n    }\n  }\n\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this thread. There can be a maximum of 1 vector store attached to\n       * the thread.\n       */\n      vector_store_ids?: Array<string>;\n\n      /**\n       * A helper to create a\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * with file_ids and attach it to this thread. There can be a maximum of 1 vector\n       * store attached to the thread.\n       */\n      vector_stores?: Array<FileSearch.VectorStore>;\n    }\n\n    export namespace FileSearch {\n      export interface VectorStore {\n        /**\n         * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n         * strategy.\n         */\n        chunking_strategy?: VectorStore.Auto | VectorStore.Static;\n\n        /**\n         * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs to\n         * add to the vector store. There can be a maximum of 10000 files in a vector\n         * store.\n         */\n        file_ids?: Array<string>;\n\n        /**\n         * Set of 16 key-value pairs that can be attached to an object. This can be useful\n         * for storing additional information about the object in a structured format, and\n         * querying for objects via API or the dashboard.\n         *\n         * Keys are strings with a maximum length of 64 characters. Values are strings with\n         * a maximum length of 512 characters.\n         */\n        metadata?: Shared.Metadata | null;\n      }\n\n      export namespace VectorStore {\n        /**\n         * The default strategy. This strategy currently uses a `max_chunk_size_tokens` of\n         * `800` and `chunk_overlap_tokens` of `400`.\n         */\n        export interface Auto {\n          /**\n           * Always `auto`.\n           */\n          type: 'auto';\n        }\n\n        export interface Static {\n          static: Static.Static;\n\n          /**\n           * Always `static`.\n           */\n          type: 'static';\n        }\n\n        export namespace Static {\n          export interface Static {\n            /**\n             * The number of tokens that overlap between chunks. The default value is `400`.\n             *\n             * Note that the overlap must not exceed half of `max_chunk_size_tokens`.\n             */\n            chunk_overlap_tokens: number;\n\n            /**\n             * The maximum number of tokens in each chunk. The default value is `800`. The\n             * minimum value is `100` and the maximum value is `4096`.\n             */\n            max_chunk_size_tokens: number;\n          }\n        }\n      }\n    }\n  }\n}\n\nexport interface ThreadUpdateParams {\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  tool_resources?: ThreadUpdateParams.ToolResources | null;\n}\n\nexport namespace ThreadUpdateParams {\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this thread. There can be a maximum of 1 vector store attached to\n       * the thread.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n}\n\nexport type ThreadCreateAndRunParams =\n  | ThreadCreateAndRunParamsNonStreaming\n  | ThreadCreateAndRunParamsStreaming;\n\nexport interface ThreadCreateAndRunParamsBase {\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Override the default system message of the assistant. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * The maximum number of completion tokens that may be used over the course of the\n   * run. The run will make a best effort to use only the number of completion tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * completion tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * The maximum number of prompt tokens that may be used over the course of the run.\n   * The run will make a best effort to use only the number of prompt tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * prompt tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to\n   * be used to execute this run. If a value is provided here, it will override the\n   * model associated with the assistant. If not, the model associated with the\n   * assistant will be used.\n   */\n  model?: (string & {}) | Shared.ChatModel | null;\n\n  /**\n   * Whether to enable\n   * [parallel function calling](https://platform.openai.com/docs/guides/function-calling#configuring-parallel-function-calling)\n   * during tool use.\n   */\n  parallel_tool_calls?: boolean;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models#gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: AssistantResponseFormatOption | null;\n\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream?: boolean | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * Options to create a new thread. If no thread is provided when running a request,\n   * an empty thread will be created.\n   */\n  thread?: ThreadCreateAndRunParams.Thread;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: AssistantToolChoiceOption | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: ThreadCreateAndRunParams.ToolResources | null;\n\n  /**\n   * Override the tools the assistant can use for this run. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  tools?: Array<AssistantsAPI.AssistantTool> | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the initial context window of the run.\n   */\n  truncation_strategy?: ThreadCreateAndRunParams.TruncationStrategy | null;\n}\n\nexport namespace ThreadCreateAndRunParams {\n  /**\n   * Options to create a new thread. If no thread is provided when running a request,\n   * an empty thread will be created.\n   */\n  export interface Thread {\n    /**\n     * A list of [messages](https://platform.openai.com/docs/api-reference/messages) to\n     * start the thread with.\n     */\n    messages?: Array<Thread.Message>;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format, and\n     * querying for objects via API or the dashboard.\n     *\n     * Keys are strings with a maximum length of 64 characters. Values are strings with\n     * a maximum length of 512 characters.\n     */\n    metadata?: Shared.Metadata | null;\n\n    /**\n     * A set of resources that are made available to the assistant's tools in this\n     * thread. The resources are specific to the type of tool. For example, the\n     * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n     * tool requires a list of vector store IDs.\n     */\n    tool_resources?: Thread.ToolResources | null;\n  }\n\n  export namespace Thread {\n    export interface Message {\n      /**\n       * The text contents of the message.\n       */\n      content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n      /**\n       * The role of the entity that is creating the message. Allowed values include:\n       *\n       * - `user`: Indicates the message is sent by an actual user and should be used in\n       *   most cases to represent user-generated messages.\n       * - `assistant`: Indicates the message is generated by the assistant. Use this\n       *   value to insert messages from the assistant into the conversation.\n       */\n      role: 'user' | 'assistant';\n\n      /**\n       * A list of files attached to the message, and the tools they should be added to.\n       */\n      attachments?: Array<Message.Attachment> | null;\n\n      /**\n       * Set of 16 key-value pairs that can be attached to an object. This can be useful\n       * for storing additional information about the object in a structured format, and\n       * querying for objects via API or the dashboard.\n       *\n       * Keys are strings with a maximum length of 64 characters. Values are strings with\n       * a maximum length of 512 characters.\n       */\n      metadata?: Shared.Metadata | null;\n    }\n\n    export namespace Message {\n      export interface Attachment {\n        /**\n         * The ID of the file to attach to the message.\n         */\n        file_id?: string;\n\n        /**\n         * The tools to add this file to.\n         */\n        tools?: Array<AssistantsAPI.CodeInterpreterTool | Attachment.FileSearch>;\n      }\n\n      export namespace Attachment {\n        export interface FileSearch {\n          /**\n           * The type of tool being defined: `file_search`\n           */\n          type: 'file_search';\n        }\n      }\n    }\n\n    /**\n     * A set of resources that are made available to the assistant's tools in this\n     * thread. The resources are specific to the type of tool. For example, the\n     * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n     * tool requires a list of vector store IDs.\n     */\n    export interface ToolResources {\n      code_interpreter?: ToolResources.CodeInterpreter;\n\n      file_search?: ToolResources.FileSearch;\n    }\n\n    export namespace ToolResources {\n      export interface CodeInterpreter {\n        /**\n         * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n         * available to the `code_interpreter` tool. There can be a maximum of 20 files\n         * associated with the tool.\n         */\n        file_ids?: Array<string>;\n      }\n\n      export interface FileSearch {\n        /**\n         * The\n         * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n         * attached to this thread. There can be a maximum of 1 vector store attached to\n         * the thread.\n         */\n        vector_store_ids?: Array<string>;\n\n        /**\n         * A helper to create a\n         * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n         * with file_ids and attach it to this thread. There can be a maximum of 1 vector\n         * store attached to the thread.\n         */\n        vector_stores?: Array<FileSearch.VectorStore>;\n      }\n\n      export namespace FileSearch {\n        export interface VectorStore {\n          /**\n           * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n           * strategy.\n           */\n          chunking_strategy?: VectorStore.Auto | VectorStore.Static;\n\n          /**\n           * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs to\n           * add to the vector store. There can be a maximum of 10000 files in a vector\n           * store.\n           */\n          file_ids?: Array<string>;\n\n          /**\n           * Set of 16 key-value pairs that can be attached to an object. This can be useful\n           * for storing additional information about the object in a structured format, and\n           * querying for objects via API or the dashboard.\n           *\n           * Keys are strings with a maximum length of 64 characters. Values are strings with\n           * a maximum length of 512 characters.\n           */\n          metadata?: Shared.Metadata | null;\n        }\n\n        export namespace VectorStore {\n          /**\n           * The default strategy. This strategy currently uses a `max_chunk_size_tokens` of\n           * `800` and `chunk_overlap_tokens` of `400`.\n           */\n          export interface Auto {\n            /**\n             * Always `auto`.\n             */\n            type: 'auto';\n          }\n\n          export interface Static {\n            static: Static.Static;\n\n            /**\n             * Always `static`.\n             */\n            type: 'static';\n          }\n\n          export namespace Static {\n            export interface Static {\n              /**\n               * The number of tokens that overlap between chunks. The default value is `400`.\n               *\n               * Note that the overlap must not exceed half of `max_chunk_size_tokens`.\n               */\n              chunk_overlap_tokens: number;\n\n              /**\n               * The maximum number of tokens in each chunk. The default value is `800`. The\n               * minimum value is `100` and the maximum value is `4096`.\n               */\n              max_chunk_size_tokens: number;\n            }\n          }\n        }\n      }\n    }\n  }\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The ID of the\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the initial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n\n  export type ThreadCreateAndRunParamsNonStreaming = ThreadsAPI.ThreadCreateAndRunParamsNonStreaming;\n  export type ThreadCreateAndRunParamsStreaming = ThreadsAPI.ThreadCreateAndRunParamsStreaming;\n}\n\nexport interface ThreadCreateAndRunParamsNonStreaming extends ThreadCreateAndRunParamsBase {\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream?: false | null;\n}\n\nexport interface ThreadCreateAndRunParamsStreaming extends ThreadCreateAndRunParamsBase {\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream: true;\n}\n\nexport interface ThreadCreateAndRunPollParams {\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Override the default system message of the assistant. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * The maximum number of completion tokens that may be used over the course of the\n   * run. The run will make a best effort to use only the number of completion tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * completion tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * The maximum number of prompt tokens that may be used over the course of the run.\n   * The run will make a best effort to use only the number of prompt tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * prompt tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to\n   * be used to execute this run. If a value is provided here, it will override the\n   * model associated with the assistant. If not, the model associated with the\n   * assistant will be used.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-4o'\n    | 'gpt-4o-2024-05-13'\n    | 'gpt-4-turbo'\n    | 'gpt-4-turbo-2024-04-09'\n    | 'gpt-4-0125-preview'\n    | 'gpt-4-turbo-preview'\n    | 'gpt-4-1106-preview'\n    | 'gpt-4-vision-preview'\n    | 'gpt-4'\n    | 'gpt-4-0314'\n    | 'gpt-4-0613'\n    | 'gpt-4-32k'\n    | 'gpt-4-32k-0314'\n    | 'gpt-4-32k-0613'\n    | 'gpt-3.5-turbo'\n    | 'gpt-3.5-turbo-16k'\n    | 'gpt-3.5-turbo-0613'\n    | 'gpt-3.5-turbo-1106'\n    | 'gpt-3.5-turbo-0125'\n    | 'gpt-3.5-turbo-16k-0613'\n    | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * If no thread is provided, an empty thread will be created.\n   */\n  thread?: ThreadCreateAndRunPollParams.Thread;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: AssistantToolChoiceOption | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: ThreadCreateAndRunPollParams.ToolResources | null;\n\n  /**\n   * Override the tools the assistant can use for this run. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  tools?: Array<\n    AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool | AssistantsAPI.FunctionTool\n  > | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  truncation_strategy?: ThreadCreateAndRunPollParams.TruncationStrategy | null;\n}\n\nexport namespace ThreadCreateAndRunPollParams {\n  /**\n   * If no thread is provided, an empty thread will be created.\n   */\n  export interface Thread {\n    /**\n     * A list of [messages](https://platform.openai.com/docs/api-reference/messages) to\n     * start the thread with.\n     */\n    messages?: Array<Thread.Message>;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format. Keys\n     * can be a maximum of 64 characters long and values can be a maxium of 512\n     * characters long.\n     */\n    metadata?: unknown | null;\n\n    /**\n     * A set of resources that are made available to the assistant's tools in this\n     * thread. The resources are specific to the type of tool. For example, the\n     * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n     * tool requires a list of vector store IDs.\n     */\n    tool_resources?: Thread.ToolResources | null;\n  }\n\n  export namespace Thread {\n    export interface Message {\n      /**\n       * The text contents of the message.\n       */\n      content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n      /**\n       * The role of the entity that is creating the message. Allowed values include:\n       *\n       * - `user`: Indicates the message is sent by an actual user and should be used in\n       *   most cases to represent user-generated messages.\n       * - `assistant`: Indicates the message is generated by the assistant. Use this\n       *   value to insert messages from the assistant into the conversation.\n       */\n      role: 'user' | 'assistant';\n\n      /**\n       * A list of files attached to the message, and the tools they should be added to.\n       */\n      attachments?: Array<Message.Attachment> | null;\n\n      /**\n       * Set of 16 key-value pairs that can be attached to an object. This can be useful\n       * for storing additional information about the object in a structured format. Keys\n       * can be a maximum of 64 characters long and values can be a maxium of 512\n       * characters long.\n       */\n      metadata?: unknown | null;\n    }\n\n    export namespace Message {\n      export interface Attachment {\n        /**\n         * The ID of the file to attach to the message.\n         */\n        file_id?: string;\n\n        /**\n         * The tools to add this file to.\n         */\n        tools?: Array<AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool>;\n      }\n    }\n\n    /**\n     * A set of resources that are made available to the assistant's tools in this\n     * thread. The resources are specific to the type of tool. For example, the\n     * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n     * tool requires a list of vector store IDs.\n     */\n    export interface ToolResources {\n      code_interpreter?: ToolResources.CodeInterpreter;\n\n      file_search?: ToolResources.FileSearch;\n    }\n\n    export namespace ToolResources {\n      export interface CodeInterpreter {\n        /**\n         * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n         * available to the `code_interpreter` tool. There can be a maximum of 20 files\n         * associated with the tool.\n         */\n        file_ids?: Array<string>;\n      }\n\n      export interface FileSearch {\n        /**\n         * The\n         * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n         * attached to this thread. There can be a maximum of 1 vector store attached to\n         * the thread.\n         */\n        vector_store_ids?: Array<string>;\n\n        /**\n         * A helper to create a\n         * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n         * with file_ids and attach it to this thread. There can be a maximum of 1 vector\n         * store attached to the thread.\n         */\n        vector_stores?: Array<FileSearch.VectorStore>;\n      }\n\n      export namespace FileSearch {\n        export interface VectorStore {\n          /**\n           * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs to\n           * add to the vector store. There can be a maximum of 10000 files in a vector\n           * store.\n           */\n          file_ids?: Array<string>;\n\n          /**\n           * Set of 16 key-value pairs that can be attached to a vector store. This can be\n           * useful for storing additional information about the vector store in a structured\n           * format. Keys can be a maximum of 64 characters long and values can be a maxium\n           * of 512 characters long.\n           */\n          metadata?: unknown;\n        }\n      }\n    }\n  }\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The ID of the\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n}\n\nexport type ThreadCreateAndRunStreamParams = ThreadCreateAndRunParamsBaseStream;\n\nThreads.Runs = Runs;\nThreads.Messages = Messages;\n\nexport declare namespace Threads {\n  export {\n    type AssistantResponseFormatOption as AssistantResponseFormatOption,\n    type AssistantToolChoice as AssistantToolChoice,\n    type AssistantToolChoiceFunction as AssistantToolChoiceFunction,\n    type AssistantToolChoiceOption as AssistantToolChoiceOption,\n    type Thread as Thread,\n    type ThreadDeleted as ThreadDeleted,\n    type ThreadCreateParams as ThreadCreateParams,\n    type ThreadUpdateParams as ThreadUpdateParams,\n    type ThreadCreateAndRunParams as ThreadCreateAndRunParams,\n    type ThreadCreateAndRunParamsNonStreaming as ThreadCreateAndRunParamsNonStreaming,\n    type ThreadCreateAndRunParamsStreaming as ThreadCreateAndRunParamsStreaming,\n    type ThreadCreateAndRunPollParams,\n    type ThreadCreateAndRunStreamParams,\n  };\n\n  export {\n    Runs as Runs,\n    type RequiredActionFunctionToolCall as RequiredActionFunctionToolCall,\n    type Run as Run,\n    type RunStatus as RunStatus,\n    type RunsPage as RunsPage,\n    type RunCreateParams as RunCreateParams,\n    type RunCreateParamsNonStreaming as RunCreateParamsNonStreaming,\n    type RunCreateParamsStreaming as RunCreateParamsStreaming,\n    type RunRetrieveParams as RunRetrieveParams,\n    type RunUpdateParams as RunUpdateParams,\n    type RunListParams as RunListParams,\n    type RunCancelParams as RunCancelParams,\n    type RunCreateAndPollParams,\n    type RunCreateAndStreamParams,\n    type RunStreamParams,\n    type RunSubmitToolOutputsParams as RunSubmitToolOutputsParams,\n    type RunSubmitToolOutputsParamsNonStreaming as RunSubmitToolOutputsParamsNonStreaming,\n    type RunSubmitToolOutputsParamsStreaming as RunSubmitToolOutputsParamsStreaming,\n    type RunSubmitToolOutputsAndPollParams,\n    type RunSubmitToolOutputsStreamParams,\n  };\n\n  export {\n    Messages as Messages,\n    type Annotation as Annotation,\n    type AnnotationDelta as AnnotationDelta,\n    type FileCitationAnnotation as FileCitationAnnotation,\n    type FileCitationDeltaAnnotation as FileCitationDeltaAnnotation,\n    type FilePathAnnotation as FilePathAnnotation,\n    type FilePathDeltaAnnotation as FilePathDeltaAnnotation,\n    type ImageFile as ImageFile,\n    type ImageFileContentBlock as ImageFileContentBlock,\n    type ImageFileDelta as ImageFileDelta,\n    type ImageFileDeltaBlock as ImageFileDeltaBlock,\n    type ImageURL as ImageURL,\n    type ImageURLContentBlock as ImageURLContentBlock,\n    type ImageURLDelta as ImageURLDelta,\n    type ImageURLDeltaBlock as ImageURLDeltaBlock,\n    type MessagesAPIMessage as Message,\n    type MessageContent as MessageContent,\n    type MessageContentDelta as MessageContentDelta,\n    type MessageContentPartParam as MessageContentPartParam,\n    type MessageDeleted as MessageDeleted,\n    type MessageDelta as MessageDelta,\n    type MessageDeltaEvent as MessageDeltaEvent,\n    type RefusalContentBlock as RefusalContentBlock,\n    type RefusalDeltaBlock as RefusalDeltaBlock,\n    type Text as Text,\n    type TextContentBlock as TextContentBlock,\n    type TextContentBlockParam as TextContentBlockParam,\n    type TextDelta as TextDelta,\n    type TextDeltaBlock as TextDeltaBlock,\n    type MessagesPage as MessagesPage,\n    type MessageCreateParams as MessageCreateParams,\n    type MessageRetrieveParams as MessageRetrieveParams,\n    type MessageUpdateParams as MessageUpdateParams,\n    type MessageListParams as MessageListParams,\n    type MessageDeleteParams as MessageDeleteParams,\n  };\n\n  export { AssistantStream };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as AssistantsAPI from './assistants';\nimport {\n  Assistant,\n  AssistantCreateParams,\n  AssistantDeleted,\n  AssistantListParams,\n  AssistantStreamEvent,\n  AssistantTool,\n  AssistantUpdateParams,\n  Assistants,\n  AssistantsPage,\n  CodeInterpreterTool,\n  FileSearchTool,\n  FunctionTool,\n  MessageStreamEvent,\n  RunStepStreamEvent,\n  RunStreamEvent,\n  ThreadStreamEvent,\n} from './assistants';\nimport * as RealtimeAPI from './realtime/realtime';\nimport {\n  ConversationCreatedEvent,\n  ConversationItem,\n  ConversationItemContent,\n  ConversationItemCreateEvent,\n  ConversationItemCreatedEvent,\n  ConversationItemDeleteEvent,\n  ConversationItemDeletedEvent,\n  ConversationItemInputAudioTranscriptionCompletedEvent,\n  ConversationItemInputAudioTranscriptionDeltaEvent,\n  ConversationItemInputAudioTranscriptionFailedEvent,\n  ConversationItemRetrieveEvent,\n  ConversationItemTruncateEvent,\n  ConversationItemTruncatedEvent,\n  ConversationItemWithReference,\n  ErrorEvent,\n  InputAudioBufferAppendEvent,\n  InputAudioBufferClearEvent,\n  InputAudioBufferClearedEvent,\n  InputAudioBufferCommitEvent,\n  InputAudioBufferCommittedEvent,\n  InputAudioBufferSpeechStartedEvent,\n  InputAudioBufferSpeechStoppedEvent,\n  RateLimitsUpdatedEvent,\n  Realtime,\n  RealtimeClientEvent,\n  RealtimeResponse,\n  RealtimeResponseStatus,\n  RealtimeResponseUsage,\n  RealtimeServerEvent,\n  ResponseAudioDeltaEvent,\n  ResponseAudioDoneEvent,\n  ResponseAudioTranscriptDeltaEvent,\n  ResponseAudioTranscriptDoneEvent,\n  ResponseCancelEvent,\n  ResponseContentPartAddedEvent,\n  ResponseContentPartDoneEvent,\n  ResponseCreateEvent,\n  ResponseCreatedEvent,\n  ResponseDoneEvent,\n  ResponseFunctionCallArgumentsDeltaEvent,\n  ResponseFunctionCallArgumentsDoneEvent,\n  ResponseOutputItemAddedEvent,\n  ResponseOutputItemDoneEvent,\n  ResponseTextDeltaEvent,\n  ResponseTextDoneEvent,\n  SessionCreatedEvent,\n  SessionUpdateEvent,\n  SessionUpdatedEvent,\n  TranscriptionSessionUpdate,\n  TranscriptionSessionUpdatedEvent,\n} from './realtime/realtime';\nimport * as ChatKitAPI from './chatkit/chatkit';\nimport { ChatKit, ChatKitWorkflow } from './chatkit/chatkit';\nimport * as ThreadsAPI from './threads/threads';\nimport {\n  AssistantResponseFormatOption,\n  AssistantToolChoice,\n  AssistantToolChoiceFunction,\n  AssistantToolChoiceOption,\n  Thread,\n  ThreadCreateAndRunParams,\n  ThreadCreateAndRunParamsNonStreaming,\n  ThreadCreateAndRunParamsStreaming,\n  ThreadCreateAndRunPollParams,\n  ThreadCreateAndRunStreamParams,\n  ThreadCreateParams,\n  ThreadDeleted,\n  ThreadUpdateParams,\n  Threads,\n} from './threads/threads';\n\nexport class Beta extends APIResource {\n  realtime: RealtimeAPI.Realtime = new RealtimeAPI.Realtime(this._client);\n  chatkit: ChatKitAPI.ChatKit = new ChatKitAPI.ChatKit(this._client);\n  assistants: AssistantsAPI.Assistants = new AssistantsAPI.Assistants(this._client);\n  threads: ThreadsAPI.Threads = new ThreadsAPI.Threads(this._client);\n}\n\nBeta.Realtime = Realtime;\nBeta.ChatKit = ChatKit;\nBeta.Assistants = Assistants;\nBeta.Threads = Threads;\n\nexport declare namespace Beta {\n  export {\n    Realtime as Realtime,\n    type ConversationCreatedEvent as ConversationCreatedEvent,\n    type ConversationItem as ConversationItem,\n    type ConversationItemContent as ConversationItemContent,\n    type ConversationItemCreateEvent as ConversationItemCreateEvent,\n    type ConversationItemCreatedEvent as ConversationItemCreatedEvent,\n    type ConversationItemDeleteEvent as ConversationItemDeleteEvent,\n    type ConversationItemDeletedEvent as ConversationItemDeletedEvent,\n    type ConversationItemInputAudioTranscriptionCompletedEvent as ConversationItemInputAudioTranscriptionCompletedEvent,\n    type ConversationItemInputAudioTranscriptionDeltaEvent as ConversationItemInputAudioTranscriptionDeltaEvent,\n    type ConversationItemInputAudioTranscriptionFailedEvent as ConversationItemInputAudioTranscriptionFailedEvent,\n    type ConversationItemRetrieveEvent as ConversationItemRetrieveEvent,\n    type ConversationItemTruncateEvent as ConversationItemTruncateEvent,\n    type ConversationItemTruncatedEvent as ConversationItemTruncatedEvent,\n    type ConversationItemWithReference as ConversationItemWithReference,\n    type ErrorEvent as ErrorEvent,\n    type InputAudioBufferAppendEvent as InputAudioBufferAppendEvent,\n    type InputAudioBufferClearEvent as InputAudioBufferClearEvent,\n    type InputAudioBufferClearedEvent as InputAudioBufferClearedEvent,\n    type InputAudioBufferCommitEvent as InputAudioBufferCommitEvent,\n    type InputAudioBufferCommittedEvent as InputAudioBufferCommittedEvent,\n    type InputAudioBufferSpeechStartedEvent as InputAudioBufferSpeechStartedEvent,\n    type InputAudioBufferSpeechStoppedEvent as InputAudioBufferSpeechStoppedEvent,\n    type RateLimitsUpdatedEvent as RateLimitsUpdatedEvent,\n    type RealtimeClientEvent as RealtimeClientEvent,\n    type RealtimeResponse as RealtimeResponse,\n    type RealtimeResponseStatus as RealtimeResponseStatus,\n    type RealtimeResponseUsage as RealtimeResponseUsage,\n    type RealtimeServerEvent as RealtimeServerEvent,\n    type ResponseAudioDeltaEvent as ResponseAudioDeltaEvent,\n    type ResponseAudioDoneEvent as ResponseAudioDoneEvent,\n    type ResponseAudioTranscriptDeltaEvent as ResponseAudioTranscriptDeltaEvent,\n    type ResponseAudioTranscriptDoneEvent as ResponseAudioTranscriptDoneEvent,\n    type ResponseCancelEvent as ResponseCancelEvent,\n    type ResponseContentPartAddedEvent as ResponseContentPartAddedEvent,\n    type ResponseContentPartDoneEvent as ResponseContentPartDoneEvent,\n    type ResponseCreateEvent as ResponseCreateEvent,\n    type ResponseCreatedEvent as ResponseCreatedEvent,\n    type ResponseDoneEvent as ResponseDoneEvent,\n    type ResponseFunctionCallArgumentsDeltaEvent as ResponseFunctionCallArgumentsDeltaEvent,\n    type ResponseFunctionCallArgumentsDoneEvent as ResponseFunctionCallArgumentsDoneEvent,\n    type ResponseOutputItemAddedEvent as ResponseOutputItemAddedEvent,\n    type ResponseOutputItemDoneEvent as ResponseOutputItemDoneEvent,\n    type ResponseTextDeltaEvent as ResponseTextDeltaEvent,\n    type ResponseTextDoneEvent as ResponseTextDoneEvent,\n    type SessionCreatedEvent as SessionCreatedEvent,\n    type SessionUpdateEvent as SessionUpdateEvent,\n    type SessionUpdatedEvent as SessionUpdatedEvent,\n    type TranscriptionSessionUpdate as TranscriptionSessionUpdate,\n    type TranscriptionSessionUpdatedEvent as TranscriptionSessionUpdatedEvent,\n    ChatKit as ChatKit,\n    type ChatKitWorkflow as ChatKitWorkflow,\n  };\n\n  export {\n    Assistants as Assistants,\n    type Assistant as Assistant,\n    type AssistantDeleted as AssistantDeleted,\n    type AssistantStreamEvent as AssistantStreamEvent,\n    type AssistantTool as AssistantTool,\n    type CodeInterpreterTool as CodeInterpreterTool,\n    type FileSearchTool as FileSearchTool,\n    type FunctionTool as FunctionTool,\n    type MessageStreamEvent as MessageStreamEvent,\n    type RunStepStreamEvent as RunStepStreamEvent,\n    type RunStreamEvent as RunStreamEvent,\n    type ThreadStreamEvent as ThreadStreamEvent,\n    type AssistantsPage as AssistantsPage,\n    type AssistantCreateParams as AssistantCreateParams,\n    type AssistantUpdateParams as AssistantUpdateParams,\n    type AssistantListParams as AssistantListParams,\n  };\n\n  export {\n    Threads as Threads,\n    type AssistantResponseFormatOption as AssistantResponseFormatOption,\n    type AssistantToolChoice as AssistantToolChoice,\n    type AssistantToolChoiceFunction as AssistantToolChoiceFunction,\n    type AssistantToolChoiceOption as AssistantToolChoiceOption,\n    type Thread as Thread,\n    type ThreadDeleted as ThreadDeleted,\n    type ThreadCreateParams as ThreadCreateParams,\n    type ThreadUpdateParams as ThreadUpdateParams,\n    type ThreadCreateAndRunParams as ThreadCreateAndRunParams,\n    type ThreadCreateAndRunParamsNonStreaming as ThreadCreateAndRunParamsNonStreaming,\n    type ThreadCreateAndRunParamsStreaming as ThreadCreateAndRunParamsStreaming,\n    type ThreadCreateAndRunPollParams,\n    type ThreadCreateAndRunStreamParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport { APIPromise } from '../../core/api-promise';\nimport { buildHeaders } from '../../internal/headers';\nimport { RequestOptions } from '../../internal/request-options';\n\nexport class Speech extends APIResource {\n  /**\n   * Generates audio from the input text.\n   *\n   * @example\n   * ```ts\n   * const speech = await client.audio.speech.create({\n   *   input: 'input',\n   *   model: 'string',\n   *   voice: 'ash',\n   * });\n   *\n   * const content = await speech.blob();\n   * console.log(content);\n   * ```\n   */\n  create(body: SpeechCreateParams, options?: RequestOptions): APIPromise<Response> {\n    return this._client.post('/audio/speech', {\n      body,\n      ...options,\n      headers: buildHeaders([{ Accept: 'application/octet-stream' }, options?.headers]),\n      __binaryResponse: true,\n    });\n  }\n}\n\nexport type SpeechModel = 'tts-1' | 'tts-1-hd' | 'gpt-4o-mini-tts';\n\nexport interface SpeechCreateParams {\n  /**\n   * The text to generate audio for. The maximum length is 4096 characters.\n   */\n  input: string;\n\n  /**\n   * One of the available [TTS models](https://platform.openai.com/docs/models#tts):\n   * `tts-1`, `tts-1-hd` or `gpt-4o-mini-tts`.\n   */\n  model: (string & {}) | SpeechModel;\n\n  /**\n   * The voice to use when generating the audio. Supported voices are `alloy`, `ash`,\n   * `ballad`, `coral`, `echo`, `fable`, `onyx`, `nova`, `sage`, `shimmer`, and\n   * `verse`. Previews of the voices are available in the\n   * [Text to speech guide](https://platform.openai.com/docs/guides/text-to-speech#voice-options).\n   */\n  voice:\n    | (string & {})\n    | 'alloy'\n    | 'ash'\n    | 'ballad'\n    | 'coral'\n    | 'echo'\n    | 'sage'\n    | 'shimmer'\n    | 'verse'\n    | 'marin'\n    | 'cedar';\n\n  /**\n   * Control the voice of your generated audio with additional instructions. Does not\n   * work with `tts-1` or `tts-1-hd`.\n   */\n  instructions?: string;\n\n  /**\n   * The format to audio in. Supported formats are `mp3`, `opus`, `aac`, `flac`,\n   * `wav`, and `pcm`.\n   */\n  response_format?: 'mp3' | 'opus' | 'aac' | 'flac' | 'wav' | 'pcm';\n\n  /**\n   * The speed of the generated audio. Select a value from `0.25` to `4.0`. `1.0` is\n   * the default.\n   */\n  speed?: number;\n\n  /**\n   * The format to stream the audio in. Supported formats are `sse` and `audio`.\n   * `sse` is not supported for `tts-1` or `tts-1-hd`.\n   */\n  stream_format?: 'sse' | 'audio';\n}\n\nexport declare namespace Speech {\n  export { type SpeechModel as SpeechModel, type SpeechCreateParams as SpeechCreateParams };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../core/resource';\nimport * as CompletionsAPI from './completions';\nimport * as CompletionsCompletionsAPI from './chat/completions/completions';\nimport { APIPromise } from '../core/api-promise';\nimport { Stream } from '../core/streaming';\nimport { RequestOptions } from '../internal/request-options';\n\nexport class Completions extends APIResource {\n  /**\n   * Creates a completion for the provided prompt and parameters.\n   *\n   * @example\n   * ```ts\n   * const completion = await client.completions.create({\n   *   model: 'string',\n   *   prompt: 'This is a test.',\n   * });\n   * ```\n   */\n  create(body: CompletionCreateParamsNonStreaming, options?: RequestOptions): APIPromise<Completion>;\n  create(body: CompletionCreateParamsStreaming, options?: RequestOptions): APIPromise<Stream<Completion>>;\n  create(\n    body: CompletionCreateParamsBase,\n    options?: RequestOptions,\n  ): APIPromise<Stream<Completion> | Completion>;\n  create(\n    body: CompletionCreateParams,\n    options?: RequestOptions,\n  ): APIPromise<Completion> | APIPromise<Stream<Completion>> {\n    return this._client.post('/completions', { body, ...options, stream: body.stream ?? false }) as\n      | APIPromise<Completion>\n      | APIPromise<Stream<Completion>>;\n  }\n}\n\n/**\n * Represents a completion response from the API. Note: both the streamed and\n * non-streamed response objects share the same shape (unlike the chat endpoint).\n */\nexport interface Completion {\n  /**\n   * A unique identifier for the completion.\n   */\n  id: string;\n\n  /**\n   * The list of completion choices the model generated for the input prompt.\n   */\n  choices: Array<CompletionChoice>;\n\n  /**\n   * The Unix timestamp (in seconds) of when the completion was created.\n   */\n  created: number;\n\n  /**\n   * The model used for completion.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always \"text_completion\"\n   */\n  object: 'text_completion';\n\n  /**\n   * This fingerprint represents the backend configuration that the model runs with.\n   *\n   * Can be used in conjunction with the `seed` request parameter to understand when\n   * backend changes have been made that might impact determinism.\n   */\n  system_fingerprint?: string;\n\n  /**\n   * Usage statistics for the completion request.\n   */\n  usage?: CompletionUsage;\n}\n\nexport interface CompletionChoice {\n  /**\n   * The reason the model stopped generating tokens. This will be `stop` if the model\n   * hit a natural stop point or a provided stop sequence, `length` if the maximum\n   * number of tokens specified in the request was reached, or `content_filter` if\n   * content was omitted due to a flag from our content filters.\n   */\n  finish_reason: 'stop' | 'length' | 'content_filter';\n\n  index: number;\n\n  logprobs: CompletionChoice.Logprobs | null;\n\n  text: string;\n}\n\nexport namespace CompletionChoice {\n  export interface Logprobs {\n    text_offset?: Array<number>;\n\n    token_logprobs?: Array<number>;\n\n    tokens?: Array<string>;\n\n    top_logprobs?: Array<{ [key: string]: number }>;\n  }\n}\n\n/**\n * Usage statistics for the completion request.\n */\nexport interface CompletionUsage {\n  /**\n   * Number of tokens in the generated completion.\n   */\n  completion_tokens: number;\n\n  /**\n   * Number of tokens in the prompt.\n   */\n  prompt_tokens: number;\n\n  /**\n   * Total number of tokens used in the request (prompt + completion).\n   */\n  total_tokens: number;\n\n  /**\n   * Breakdown of tokens used in a completion.\n   */\n  completion_tokens_details?: CompletionUsage.CompletionTokensDetails;\n\n  /**\n   * Breakdown of tokens used in the prompt.\n   */\n  prompt_tokens_details?: CompletionUsage.PromptTokensDetails;\n}\n\nexport namespace CompletionUsage {\n  /**\n   * Breakdown of tokens used in a completion.\n   */\n  export interface CompletionTokensDetails {\n    /**\n     * When using Predicted Outputs, the number of tokens in the prediction that\n     * appeared in the completion.\n     */\n    accepted_prediction_tokens?: number;\n\n    /**\n     * Audio input tokens generated by the model.\n     */\n    audio_tokens?: number;\n\n    /**\n     * Tokens generated by the model for reasoning.\n     */\n    reasoning_tokens?: number;\n\n    /**\n     * When using Predicted Outputs, the number of tokens in the prediction that did\n     * not appear in the completion. However, like reasoning tokens, these tokens are\n     * still counted in the total completion tokens for purposes of billing, output,\n     * and context window limits.\n     */\n    rejected_prediction_tokens?: number;\n  }\n\n  /**\n   * Breakdown of tokens used in the prompt.\n   */\n  export interface PromptTokensDetails {\n    /**\n     * Audio input tokens present in the prompt.\n     */\n    audio_tokens?: number;\n\n    /**\n     * Cached tokens present in the prompt.\n     */\n    cached_tokens?: number;\n  }\n}\n\nexport type CompletionCreateParams = CompletionCreateParamsNonStreaming | CompletionCreateParamsStreaming;\n\nexport interface CompletionCreateParamsBase {\n  /**\n   * ID of the model to use. You can use the\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n   * see all of your available models, or see our\n   * [Model overview](https://platform.openai.com/docs/models) for descriptions of\n   * them.\n   */\n  model: (string & {}) | 'gpt-3.5-turbo-instruct' | 'davinci-002' | 'babbage-002';\n\n  /**\n   * The prompt(s) to generate completions for, encoded as a string, array of\n   * strings, array of tokens, or array of token arrays.\n   *\n   * Note that <|endoftext|> is the document separator that the model sees during\n   * training, so if a prompt is not specified the model will generate as if from the\n   * beginning of a new document.\n   */\n  prompt: string | Array<string> | Array<number> | Array<Array<number>> | null;\n\n  /**\n   * Generates `best_of` completions server-side and returns the \"best\" (the one with\n   * the highest log probability per token). Results cannot be streamed.\n   *\n   * When used with `n`, `best_of` controls the number of candidate completions and\n   * `n` specifies how many to return  `best_of` must be greater than `n`.\n   *\n   * **Note:** Because this parameter generates many completions, it can quickly\n   * consume your token quota. Use carefully and ensure that you have reasonable\n   * settings for `max_tokens` and `stop`.\n   */\n  best_of?: number | null;\n\n  /**\n   * Echo back the prompt in addition to the completion\n   */\n  echo?: boolean | null;\n\n  /**\n   * Number between -2.0 and 2.0. Positive values penalize new tokens based on their\n   * existing frequency in the text so far, decreasing the model's likelihood to\n   * repeat the same line verbatim.\n   *\n   * [See more information about frequency and presence penalties.](https://platform.openai.com/docs/guides/text-generation)\n   */\n  frequency_penalty?: number | null;\n\n  /**\n   * Modify the likelihood of specified tokens appearing in the completion.\n   *\n   * Accepts a JSON object that maps tokens (specified by their token ID in the GPT\n   * tokenizer) to an associated bias value from -100 to 100. You can use this\n   * [tokenizer tool](/tokenizer?view=bpe) to convert text to token IDs.\n   * Mathematically, the bias is added to the logits generated by the model prior to\n   * sampling. The exact effect will vary per model, but values between -1 and 1\n   * should decrease or increase likelihood of selection; values like -100 or 100\n   * should result in a ban or exclusive selection of the relevant token.\n   *\n   * As an example, you can pass `{\"50256\": -100}` to prevent the <|endoftext|> token\n   * from being generated.\n   */\n  logit_bias?: { [key: string]: number } | null;\n\n  /**\n   * Include the log probabilities on the `logprobs` most likely output tokens, as\n   * well the chosen tokens. For example, if `logprobs` is 5, the API will return a\n   * list of the 5 most likely tokens. The API will always return the `logprob` of\n   * the sampled token, so there may be up to `logprobs+1` elements in the response.\n   *\n   * The maximum value for `logprobs` is 5.\n   */\n  logprobs?: number | null;\n\n  /**\n   * The maximum number of [tokens](/tokenizer) that can be generated in the\n   * completion.\n   *\n   * The token count of your prompt plus `max_tokens` cannot exceed the model's\n   * context length.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)\n   * for counting tokens.\n   */\n  max_tokens?: number | null;\n\n  /**\n   * How many completions to generate for each prompt.\n   *\n   * **Note:** Because this parameter generates many completions, it can quickly\n   * consume your token quota. Use carefully and ensure that you have reasonable\n   * settings for `max_tokens` and `stop`.\n   */\n  n?: number | null;\n\n  /**\n   * Number between -2.0 and 2.0. Positive values penalize new tokens based on\n   * whether they appear in the text so far, increasing the model's likelihood to\n   * talk about new topics.\n   *\n   * [See more information about frequency and presence penalties.](https://platform.openai.com/docs/guides/text-generation)\n   */\n  presence_penalty?: number | null;\n\n  /**\n   * If specified, our system will make a best effort to sample deterministically,\n   * such that repeated requests with the same `seed` and parameters should return\n   * the same result.\n   *\n   * Determinism is not guaranteed, and you should refer to the `system_fingerprint`\n   * response parameter to monitor changes in the backend.\n   */\n  seed?: number | null;\n\n  /**\n   * Not supported with latest reasoning models `o3` and `o4-mini`.\n   *\n   * Up to 4 sequences where the API will stop generating further tokens. The\n   * returned text will not contain the stop sequence.\n   */\n  stop?: string | null | Array<string>;\n\n  /**\n   * Whether to stream back partial progress. If set, tokens will be sent as\n   * data-only\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\n   * as they become available, with the stream terminated by a `data: [DONE]`\n   * message.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\n   */\n  stream?: boolean | null;\n\n  /**\n   * Options for streaming response. Only set this when you set `stream: true`.\n   */\n  stream_options?: CompletionsCompletionsAPI.ChatCompletionStreamOptions | null;\n\n  /**\n   * The suffix that comes after a completion of inserted text.\n   *\n   * This parameter is only supported for `gpt-3.5-turbo-instruct`.\n   */\n  suffix?: string | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   *\n   * We generally recommend altering this or `top_p` but not both.\n   */\n  temperature?: number | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or `temperature` but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n   */\n  user?: string;\n}\n\nexport namespace CompletionCreateParams {\n  export type CompletionCreateParamsNonStreaming = CompletionsAPI.CompletionCreateParamsNonStreaming;\n  export type CompletionCreateParamsStreaming = CompletionsAPI.CompletionCreateParamsStreaming;\n}\n\nexport interface CompletionCreateParamsNonStreaming extends CompletionCreateParamsBase {\n  /**\n   * Whether to stream back partial progress. If set, tokens will be sent as\n   * data-only\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\n   * as they become available, with the stream terminated by a `data: [DONE]`\n   * message.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\n   */\n  stream?: false | null;\n}\n\nexport interface CompletionCreateParamsStreaming extends CompletionCreateParamsBase {\n  /**\n   * Whether to stream back partial progress. If set, tokens will be sent as\n   * data-only\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\n   * as they become available, with the stream terminated by a `data: [DONE]`\n   * message.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\n   */\n  stream: true;\n}\n\nexport declare namespace Completions {\n  export {\n    type Completion as Completion,\n    type CompletionChoice as CompletionChoice,\n    type CompletionUsage as CompletionUsage,\n    type CompletionCreateParams as CompletionCreateParams,\n    type CompletionCreateParamsNonStreaming as CompletionCreateParamsNonStreaming,\n    type CompletionCreateParamsStreaming as CompletionCreateParamsStreaming,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport { APIPromise } from '../../../core/api-promise';\nimport { buildHeaders } from '../../../internal/headers';\nimport { RequestOptions } from '../../../internal/request-options';\nimport { path } from '../../../internal/utils/path';\n\nexport class Content extends APIResource {\n  /**\n   * Retrieve Container File Content\n   */\n  retrieve(fileID: string, params: ContentRetrieveParams, options?: RequestOptions): APIPromise<Response> {\n    const { container_id } = params;\n    return this._client.get(path`/containers/${container_id}/files/${fileID}/content`, {\n      ...options,\n      headers: buildHeaders([{ Accept: 'application/binary' }, options?.headers]),\n      __binaryResponse: true,\n    });\n  }\n}\n\nexport interface ContentRetrieveParams {\n  container_id: string;\n}\n\nexport declare namespace Content {\n  export { type ContentRetrieveParams as ContentRetrieveParams };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport * as ContentAPI from './content';\nimport { Content, ContentRetrieveParams } from './content';\nimport { APIPromise } from '../../../core/api-promise';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../../../core/pagination';\nimport { type Uploadable } from '../../../core/uploads';\nimport { buildHeaders } from '../../../internal/headers';\nimport { RequestOptions } from '../../../internal/request-options';\nimport { multipartFormRequestOptions } from '../../../internal/uploads';\nimport { path } from '../../../internal/utils/path';\n\nexport class Files extends APIResource {\n  content: ContentAPI.Content = new ContentAPI.Content(this._client);\n\n  /**\n   * Create a Container File\n   *\n   * You can send either a multipart/form-data request with the raw file content, or\n   * a JSON request with a file ID.\n   */\n  create(\n    containerID: string,\n    body: FileCreateParams,\n    options?: RequestOptions,\n  ): APIPromise<FileCreateResponse> {\n    return this._client.post(\n      path`/containers/${containerID}/files`,\n      multipartFormRequestOptions({ body, ...options }, this._client),\n    );\n  }\n\n  /**\n   * Retrieve Container File\n   */\n  retrieve(\n    fileID: string,\n    params: FileRetrieveParams,\n    options?: RequestOptions,\n  ): APIPromise<FileRetrieveResponse> {\n    const { container_id } = params;\n    return this._client.get(path`/containers/${container_id}/files/${fileID}`, options);\n  }\n\n  /**\n   * List Container files\n   */\n  list(\n    containerID: string,\n    query: FileListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<FileListResponsesPage, FileListResponse> {\n    return this._client.getAPIList(path`/containers/${containerID}/files`, CursorPage<FileListResponse>, {\n      query,\n      ...options,\n    });\n  }\n\n  /**\n   * Delete Container File\n   */\n  delete(fileID: string, params: FileDeleteParams, options?: RequestOptions): APIPromise<void> {\n    const { container_id } = params;\n    return this._client.delete(path`/containers/${container_id}/files/${fileID}`, {\n      ...options,\n      headers: buildHeaders([{ Accept: '*/*' }, options?.headers]),\n    });\n  }\n}\n\nexport type FileListResponsesPage = CursorPage<FileListResponse>;\n\nexport interface FileCreateResponse {\n  /**\n   * Unique identifier for the file.\n   */\n  id: string;\n\n  /**\n   * Size of the file in bytes.\n   */\n  bytes: number;\n\n  /**\n   * The container this file belongs to.\n   */\n  container_id: string;\n\n  /**\n   * Unix timestamp (in seconds) when the file was created.\n   */\n  created_at: number;\n\n  /**\n   * The type of this object (`container.file`).\n   */\n  object: 'container.file';\n\n  /**\n   * Path of the file in the container.\n   */\n  path: string;\n\n  /**\n   * Source of the file (e.g., `user`, `assistant`).\n   */\n  source: string;\n}\n\nexport interface FileRetrieveResponse {\n  /**\n   * Unique identifier for the file.\n   */\n  id: string;\n\n  /**\n   * Size of the file in bytes.\n   */\n  bytes: number;\n\n  /**\n   * The container this file belongs to.\n   */\n  container_id: string;\n\n  /**\n   * Unix timestamp (in seconds) when the file was created.\n   */\n  created_at: number;\n\n  /**\n   * The type of this object (`container.file`).\n   */\n  object: 'container.file';\n\n  /**\n   * Path of the file in the container.\n   */\n  path: string;\n\n  /**\n   * Source of the file (e.g., `user`, `assistant`).\n   */\n  source: string;\n}\n\nexport interface FileListResponse {\n  /**\n   * Unique identifier for the file.\n   */\n  id: string;\n\n  /**\n   * Size of the file in bytes.\n   */\n  bytes: number;\n\n  /**\n   * The container this file belongs to.\n   */\n  container_id: string;\n\n  /**\n   * Unix timestamp (in seconds) when the file was created.\n   */\n  created_at: number;\n\n  /**\n   * The type of this object (`container.file`).\n   */\n  object: 'container.file';\n\n  /**\n   * Path of the file in the container.\n   */\n  path: string;\n\n  /**\n   * Source of the file (e.g., `user`, `assistant`).\n   */\n  source: string;\n}\n\nexport interface FileCreateParams {\n  /**\n   * The File object (not file name) to be uploaded.\n   */\n  file?: Uploadable;\n\n  /**\n   * Name of the file to create.\n   */\n  file_id?: string;\n}\n\nexport interface FileRetrieveParams {\n  container_id: string;\n}\n\nexport interface FileListParams extends CursorPageParams {\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport interface FileDeleteParams {\n  container_id: string;\n}\n\nFiles.Content = Content;\n\nexport declare namespace Files {\n  export {\n    type FileCreateResponse as FileCreateResponse,\n    type FileRetrieveResponse as FileRetrieveResponse,\n    type FileListResponse as FileListResponse,\n    type FileListResponsesPage as FileListResponsesPage,\n    type FileCreateParams as FileCreateParams,\n    type FileRetrieveParams as FileRetrieveParams,\n    type FileListParams as FileListParams,\n    type FileDeleteParams as FileDeleteParams,\n  };\n\n  export { Content as Content, type ContentRetrieveParams as ContentRetrieveParams };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as FilesAPI from './files/files';\nimport {\n  FileCreateParams,\n  FileCreateResponse,\n  FileDeleteParams,\n  FileListParams,\n  FileListResponse,\n  FileListResponsesPage,\n  FileRetrieveParams,\n  FileRetrieveResponse,\n  Files,\n} from './files/files';\nimport { APIPromise } from '../../core/api-promise';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../../core/pagination';\nimport { buildHeaders } from '../../internal/headers';\nimport { RequestOptions } from '../../internal/request-options';\nimport { path } from '../../internal/utils/path';\n\nexport class Containers extends APIResource {\n  files: FilesAPI.Files = new FilesAPI.Files(this._client);\n\n  /**\n   * Create Container\n   */\n  create(body: ContainerCreateParams, options?: RequestOptions): APIPromise<ContainerCreateResponse> {\n    return this._client.post('/containers', { body, ...options });\n  }\n\n  /**\n   * Retrieve Container\n   */\n  retrieve(containerID: string, options?: RequestOptions): APIPromise<ContainerRetrieveResponse> {\n    return this._client.get(path`/containers/${containerID}`, options);\n  }\n\n  /**\n   * List Containers\n   */\n  list(\n    query: ContainerListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<ContainerListResponsesPage, ContainerListResponse> {\n    return this._client.getAPIList('/containers', CursorPage<ContainerListResponse>, { query, ...options });\n  }\n\n  /**\n   * Delete Container\n   */\n  delete(containerID: string, options?: RequestOptions): APIPromise<void> {\n    return this._client.delete(path`/containers/${containerID}`, {\n      ...options,\n      headers: buildHeaders([{ Accept: '*/*' }, options?.headers]),\n    });\n  }\n}\n\nexport type ContainerListResponsesPage = CursorPage<ContainerListResponse>;\n\nexport interface ContainerCreateResponse {\n  /**\n   * Unique identifier for the container.\n   */\n  id: string;\n\n  /**\n   * Unix timestamp (in seconds) when the container was created.\n   */\n  created_at: number;\n\n  /**\n   * Name of the container.\n   */\n  name: string;\n\n  /**\n   * The type of this object.\n   */\n  object: string;\n\n  /**\n   * Status of the container (e.g., active, deleted).\n   */\n  status: string;\n\n  /**\n   * The container will expire after this time period. The anchor is the reference\n   * point for the expiration. The minutes is the number of minutes after the anchor\n   * before the container expires.\n   */\n  expires_after?: ContainerCreateResponse.ExpiresAfter;\n}\n\nexport namespace ContainerCreateResponse {\n  /**\n   * The container will expire after this time period. The anchor is the reference\n   * point for the expiration. The minutes is the number of minutes after the anchor\n   * before the container expires.\n   */\n  export interface ExpiresAfter {\n    /**\n     * The reference point for the expiration.\n     */\n    anchor?: 'last_active_at';\n\n    /**\n     * The number of minutes after the anchor before the container expires.\n     */\n    minutes?: number;\n  }\n}\n\nexport interface ContainerRetrieveResponse {\n  /**\n   * Unique identifier for the container.\n   */\n  id: string;\n\n  /**\n   * Unix timestamp (in seconds) when the container was created.\n   */\n  created_at: number;\n\n  /**\n   * Name of the container.\n   */\n  name: string;\n\n  /**\n   * The type of this object.\n   */\n  object: string;\n\n  /**\n   * Status of the container (e.g., active, deleted).\n   */\n  status: string;\n\n  /**\n   * The container will expire after this time period. The anchor is the reference\n   * point for the expiration. The minutes is the number of minutes after the anchor\n   * before the container expires.\n   */\n  expires_after?: ContainerRetrieveResponse.ExpiresAfter;\n}\n\nexport namespace ContainerRetrieveResponse {\n  /**\n   * The container will expire after this time period. The anchor is the reference\n   * point for the expiration. The minutes is the number of minutes after the anchor\n   * before the container expires.\n   */\n  export interface ExpiresAfter {\n    /**\n     * The reference point for the expiration.\n     */\n    anchor?: 'last_active_at';\n\n    /**\n     * The number of minutes after the anchor before the container expires.\n     */\n    minutes?: number;\n  }\n}\n\nexport interface ContainerListResponse {\n  /**\n   * Unique identifier for the container.\n   */\n  id: string;\n\n  /**\n   * Unix timestamp (in seconds) when the container was created.\n   */\n  created_at: number;\n\n  /**\n   * Name of the container.\n   */\n  name: string;\n\n  /**\n   * The type of this object.\n   */\n  object: string;\n\n  /**\n   * Status of the container (e.g., active, deleted).\n   */\n  status: string;\n\n  /**\n   * The container will expire after this time period. The anchor is the reference\n   * point for the expiration. The minutes is the number of minutes after the anchor\n   * before the container expires.\n   */\n  expires_after?: ContainerListResponse.ExpiresAfter;\n}\n\nexport namespace ContainerListResponse {\n  /**\n   * The container will expire after this time period. The anchor is the reference\n   * point for the expiration. The minutes is the number of minutes after the anchor\n   * before the container expires.\n   */\n  export interface ExpiresAfter {\n    /**\n     * The reference point for the expiration.\n     */\n    anchor?: 'last_active_at';\n\n    /**\n     * The number of minutes after the anchor before the container expires.\n     */\n    minutes?: number;\n  }\n}\n\nexport interface ContainerCreateParams {\n  /**\n   * Name of the container to create.\n   */\n  name: string;\n\n  /**\n   * Container expiration time in seconds relative to the 'anchor' time.\n   */\n  expires_after?: ContainerCreateParams.ExpiresAfter;\n\n  /**\n   * IDs of files to copy to the container.\n   */\n  file_ids?: Array<string>;\n}\n\nexport namespace ContainerCreateParams {\n  /**\n   * Container expiration time in seconds relative to the 'anchor' time.\n   */\n  export interface ExpiresAfter {\n    /**\n     * Time anchor for the expiration time. Currently only 'last_active_at' is\n     * supported.\n     */\n    anchor: 'last_active_at';\n\n    minutes: number;\n  }\n}\n\nexport interface ContainerListParams extends CursorPageParams {\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nContainers.Files = Files;\n\nexport declare namespace Containers {\n  export {\n    type ContainerCreateResponse as ContainerCreateResponse,\n    type ContainerRetrieveResponse as ContainerRetrieveResponse,\n    type ContainerListResponse as ContainerListResponse,\n    type ContainerListResponsesPage as ContainerListResponsesPage,\n    type ContainerCreateParams as ContainerCreateParams,\n    type ContainerListParams as ContainerListParams,\n  };\n\n  export {\n    Files as Files,\n    type FileCreateResponse as FileCreateResponse,\n    type FileRetrieveResponse as FileRetrieveResponse,\n    type FileListResponse as FileListResponse,\n    type FileListResponsesPage as FileListResponsesPage,\n    type FileCreateParams as FileCreateParams,\n    type FileRetrieveParams as FileRetrieveParams,\n    type FileListParams as FileListParams,\n    type FileDeleteParams as FileDeleteParams,\n  };\n}\n","import {\n  type ChatCompletionMessageParam,\n  type ChatCompletionCreateParamsNonStreaming,\n} from '../resources/chat/completions';\nimport { type BaseFunctionsArgs, RunnableTools } from './RunnableFunction';\nimport {\n  AbstractChatCompletionRunner,\n  AbstractChatCompletionRunnerEvents,\n  RunnerOptions,\n} from './AbstractChatCompletionRunner';\nimport { isAssistantMessage } from './chatCompletionUtils';\nimport OpenAI from '../index';\nimport { AutoParseableTool } from '../lib/parser';\n\nexport interface ChatCompletionRunnerEvents extends AbstractChatCompletionRunnerEvents {\n  content: (content: string) => void;\n}\n\nexport type ChatCompletionToolRunnerParams<FunctionsArgs extends BaseFunctionsArgs> = Omit<\n  ChatCompletionCreateParamsNonStreaming,\n  'tools'\n> & {\n  tools: RunnableTools<FunctionsArgs> | AutoParseableTool<any, true>[];\n};\n\nexport class ChatCompletionRunner<ParsedT = null> extends AbstractChatCompletionRunner<\n  ChatCompletionRunnerEvents,\n  ParsedT\n> {\n  static runTools<ParsedT>(\n    client: OpenAI,\n    params: ChatCompletionToolRunnerParams<any[]>,\n    options?: RunnerOptions,\n  ): ChatCompletionRunner<ParsedT> {\n    const runner = new ChatCompletionRunner<ParsedT>();\n    const opts = {\n      ...options,\n      headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'runTools' },\n    };\n    runner._run(() => runner._runTools(client, params, opts));\n    return runner;\n  }\n\n  override _addMessage(\n    this: ChatCompletionRunner<ParsedT>,\n    message: ChatCompletionMessageParam,\n    emit: boolean = true,\n  ) {\n    super._addMessage(message, emit);\n    if (isAssistantMessage(message) && message.content) {\n      this._emit('content', message.content as string);\n    }\n  }\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as ConversationsAPI from './conversations';\nimport * as ResponsesAPI from '../responses/responses';\nimport { APIPromise } from '../../core/api-promise';\nimport {\n  ConversationCursorPage,\n  type ConversationCursorPageParams,\n  PagePromise,\n} from '../../core/pagination';\nimport { RequestOptions } from '../../internal/request-options';\nimport { path } from '../../internal/utils/path';\n\nexport class Items extends APIResource {\n  /**\n   * Create items in a conversation with the given ID.\n   */\n  create(\n    conversationID: string,\n    params: ItemCreateParams,\n    options?: RequestOptions,\n  ): APIPromise<ConversationItemList> {\n    const { include, ...body } = params;\n    return this._client.post(path`/conversations/${conversationID}/items`, {\n      query: { include },\n      body,\n      ...options,\n    });\n  }\n\n  /**\n   * Get a single item from a conversation with the given IDs.\n   */\n  retrieve(\n    itemID: string,\n    params: ItemRetrieveParams,\n    options?: RequestOptions,\n  ): APIPromise<ConversationItem> {\n    const { conversation_id, ...query } = params;\n    return this._client.get(path`/conversations/${conversation_id}/items/${itemID}`, { query, ...options });\n  }\n\n  /**\n   * List all items for a conversation with the given ID.\n   */\n  list(\n    conversationID: string,\n    query: ItemListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<ConversationItemsPage, ConversationItem> {\n    return this._client.getAPIList(\n      path`/conversations/${conversationID}/items`,\n      ConversationCursorPage<ConversationItem>,\n      { query, ...options },\n    );\n  }\n\n  /**\n   * Delete an item from a conversation with the given IDs.\n   */\n  delete(\n    itemID: string,\n    params: ItemDeleteParams,\n    options?: RequestOptions,\n  ): APIPromise<ConversationsAPI.Conversation> {\n    const { conversation_id } = params;\n    return this._client.delete(path`/conversations/${conversation_id}/items/${itemID}`, options);\n  }\n}\n\nexport type ConversationItemsPage = ConversationCursorPage<ConversationItem>;\n\n/**\n * A single item within a conversation. The set of possible types are the same as\n * the `output` type of a\n * [Response object](https://platform.openai.com/docs/api-reference/responses/object#responses/object-output).\n */\nexport type ConversationItem =\n  | ConversationsAPI.Message\n  | ResponsesAPI.ResponseFunctionToolCallItem\n  | ResponsesAPI.ResponseFunctionToolCallOutputItem\n  | ResponsesAPI.ResponseFileSearchToolCall\n  | ResponsesAPI.ResponseFunctionWebSearch\n  | ConversationItem.ImageGenerationCall\n  | ResponsesAPI.ResponseComputerToolCall\n  | ResponsesAPI.ResponseComputerToolCallOutputItem\n  | ResponsesAPI.ResponseReasoningItem\n  | ResponsesAPI.ResponseCodeInterpreterToolCall\n  | ConversationItem.LocalShellCall\n  | ConversationItem.LocalShellCallOutput\n  | ConversationItem.McpListTools\n  | ConversationItem.McpApprovalRequest\n  | ConversationItem.McpApprovalResponse\n  | ConversationItem.McpCall\n  | ResponsesAPI.ResponseCustomToolCall\n  | ResponsesAPI.ResponseCustomToolCallOutput;\n\nexport namespace ConversationItem {\n  /**\n   * An image generation request made by the model.\n   */\n  export interface ImageGenerationCall {\n    /**\n     * The unique ID of the image generation call.\n     */\n    id: string;\n\n    /**\n     * The generated image encoded in base64.\n     */\n    result: string | null;\n\n    /**\n     * The status of the image generation call.\n     */\n    status: 'in_progress' | 'completed' | 'generating' | 'failed';\n\n    /**\n     * The type of the image generation call. Always `image_generation_call`.\n     */\n    type: 'image_generation_call';\n  }\n\n  /**\n   * A tool call to run a command on the local shell.\n   */\n  export interface LocalShellCall {\n    /**\n     * The unique ID of the local shell call.\n     */\n    id: string;\n\n    /**\n     * Execute a shell command on the server.\n     */\n    action: LocalShellCall.Action;\n\n    /**\n     * The unique ID of the local shell tool call generated by the model.\n     */\n    call_id: string;\n\n    /**\n     * The status of the local shell call.\n     */\n    status: 'in_progress' | 'completed' | 'incomplete';\n\n    /**\n     * The type of the local shell call. Always `local_shell_call`.\n     */\n    type: 'local_shell_call';\n  }\n\n  export namespace LocalShellCall {\n    /**\n     * Execute a shell command on the server.\n     */\n    export interface Action {\n      /**\n       * The command to run.\n       */\n      command: Array<string>;\n\n      /**\n       * Environment variables to set for the command.\n       */\n      env: { [key: string]: string };\n\n      /**\n       * The type of the local shell action. Always `exec`.\n       */\n      type: 'exec';\n\n      /**\n       * Optional timeout in milliseconds for the command.\n       */\n      timeout_ms?: number | null;\n\n      /**\n       * Optional user to run the command as.\n       */\n      user?: string | null;\n\n      /**\n       * Optional working directory to run the command in.\n       */\n      working_directory?: string | null;\n    }\n  }\n\n  /**\n   * The output of a local shell tool call.\n   */\n  export interface LocalShellCallOutput {\n    /**\n     * The unique ID of the local shell tool call generated by the model.\n     */\n    id: string;\n\n    /**\n     * A JSON string of the output of the local shell tool call.\n     */\n    output: string;\n\n    /**\n     * The type of the local shell tool call output. Always `local_shell_call_output`.\n     */\n    type: 'local_shell_call_output';\n\n    /**\n     * The status of the item. One of `in_progress`, `completed`, or `incomplete`.\n     */\n    status?: 'in_progress' | 'completed' | 'incomplete' | null;\n  }\n\n  /**\n   * A list of tools available on an MCP server.\n   */\n  export interface McpListTools {\n    /**\n     * The unique ID of the list.\n     */\n    id: string;\n\n    /**\n     * The label of the MCP server.\n     */\n    server_label: string;\n\n    /**\n     * The tools available on the server.\n     */\n    tools: Array<McpListTools.Tool>;\n\n    /**\n     * The type of the item. Always `mcp_list_tools`.\n     */\n    type: 'mcp_list_tools';\n\n    /**\n     * Error message if the server could not list tools.\n     */\n    error?: string | null;\n  }\n\n  export namespace McpListTools {\n    /**\n     * A tool available on an MCP server.\n     */\n    export interface Tool {\n      /**\n       * The JSON schema describing the tool's input.\n       */\n      input_schema: unknown;\n\n      /**\n       * The name of the tool.\n       */\n      name: string;\n\n      /**\n       * Additional annotations about the tool.\n       */\n      annotations?: unknown | null;\n\n      /**\n       * The description of the tool.\n       */\n      description?: string | null;\n    }\n  }\n\n  /**\n   * A request for human approval of a tool invocation.\n   */\n  export interface McpApprovalRequest {\n    /**\n     * The unique ID of the approval request.\n     */\n    id: string;\n\n    /**\n     * A JSON string of arguments for the tool.\n     */\n    arguments: string;\n\n    /**\n     * The name of the tool to run.\n     */\n    name: string;\n\n    /**\n     * The label of the MCP server making the request.\n     */\n    server_label: string;\n\n    /**\n     * The type of the item. Always `mcp_approval_request`.\n     */\n    type: 'mcp_approval_request';\n  }\n\n  /**\n   * A response to an MCP approval request.\n   */\n  export interface McpApprovalResponse {\n    /**\n     * The unique ID of the approval response\n     */\n    id: string;\n\n    /**\n     * The ID of the approval request being answered.\n     */\n    approval_request_id: string;\n\n    /**\n     * Whether the request was approved.\n     */\n    approve: boolean;\n\n    /**\n     * The type of the item. Always `mcp_approval_response`.\n     */\n    type: 'mcp_approval_response';\n\n    /**\n     * Optional reason for the decision.\n     */\n    reason?: string | null;\n  }\n\n  /**\n   * An invocation of a tool on an MCP server.\n   */\n  export interface McpCall {\n    /**\n     * The unique ID of the tool call.\n     */\n    id: string;\n\n    /**\n     * A JSON string of the arguments passed to the tool.\n     */\n    arguments: string;\n\n    /**\n     * The name of the tool that was run.\n     */\n    name: string;\n\n    /**\n     * The label of the MCP server running the tool.\n     */\n    server_label: string;\n\n    /**\n     * The type of the item. Always `mcp_call`.\n     */\n    type: 'mcp_call';\n\n    /**\n     * Unique identifier for the MCP tool call approval request. Include this value in\n     * a subsequent `mcp_approval_response` input to approve or reject the\n     * corresponding tool call.\n     */\n    approval_request_id?: string | null;\n\n    /**\n     * The error from the tool call, if any.\n     */\n    error?: string | null;\n\n    /**\n     * The output from the tool call.\n     */\n    output?: string | null;\n\n    /**\n     * The status of the tool call. One of `in_progress`, `completed`, `incomplete`,\n     * `calling`, or `failed`.\n     */\n    status?: 'in_progress' | 'completed' | 'incomplete' | 'calling' | 'failed';\n  }\n}\n\n/**\n * A list of Conversation items.\n */\nexport interface ConversationItemList {\n  /**\n   * A list of conversation items.\n   */\n  data: Array<ConversationItem>;\n\n  /**\n   * The ID of the first item in the list.\n   */\n  first_id: string;\n\n  /**\n   * Whether there are more items available.\n   */\n  has_more: boolean;\n\n  /**\n   * The ID of the last item in the list.\n   */\n  last_id: string;\n\n  /**\n   * The type of object returned, must be `list`.\n   */\n  object: 'list';\n}\n\nexport interface ItemCreateParams {\n  /**\n   * Body param: The items to add to the conversation. You may add up to 20 items at\n   * a time.\n   */\n  items: Array<ResponsesAPI.ResponseInputItem>;\n\n  /**\n   * Query param: Additional fields to include in the response. See the `include`\n   * parameter for\n   * [listing Conversation items above](https://platform.openai.com/docs/api-reference/conversations/list-items#conversations_list_items-include)\n   * for more information.\n   */\n  include?: Array<ResponsesAPI.ResponseIncludable>;\n}\n\nexport interface ItemRetrieveParams {\n  /**\n   * Path param: The ID of the conversation that contains the item.\n   */\n  conversation_id: string;\n\n  /**\n   * Query param: Additional fields to include in the response. See the `include`\n   * parameter for\n   * [listing Conversation items above](https://platform.openai.com/docs/api-reference/conversations/list-items#conversations_list_items-include)\n   * for more information.\n   */\n  include?: Array<ResponsesAPI.ResponseIncludable>;\n}\n\nexport interface ItemListParams extends ConversationCursorPageParams {\n  /**\n   * Specify additional output data to include in the model response. Currently\n   * supported values are:\n   *\n   * - `web_search_call.action.sources`: Include the sources of the web search tool\n   *   call.\n   * - `code_interpreter_call.outputs`: Includes the outputs of python code execution\n   *   in code interpreter tool call items.\n   * - `computer_call_output.output.image_url`: Include image urls from the computer\n   *   call output.\n   * - `file_search_call.results`: Include the search results of the file search tool\n   *   call.\n   * - `message.input_image.image_url`: Include image urls from the input message.\n   * - `message.output_text.logprobs`: Include logprobs with assistant messages.\n   * - `reasoning.encrypted_content`: Includes an encrypted version of reasoning\n   *   tokens in reasoning item outputs. This enables reasoning items to be used in\n   *   multi-turn conversations when using the Responses API statelessly (like when\n   *   the `store` parameter is set to `false`, or when an organization is enrolled\n   *   in the zero data retention program).\n   */\n  include?: Array<ResponsesAPI.ResponseIncludable>;\n\n  /**\n   * The order to return the input items in. Default is `desc`.\n   *\n   * - `asc`: Return the input items in ascending order.\n   * - `desc`: Return the input items in descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport interface ItemDeleteParams {\n  /**\n   * The ID of the conversation that contains the item.\n   */\n  conversation_id: string;\n}\n\nexport declare namespace Items {\n  export {\n    type ConversationItem as ConversationItem,\n    type ConversationItemList as ConversationItemList,\n    type ConversationItemsPage as ConversationItemsPage,\n    type ItemCreateParams as ItemCreateParams,\n    type ItemRetrieveParams as ItemRetrieveParams,\n    type ItemListParams as ItemListParams,\n    type ItemDeleteParams as ItemDeleteParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as TranscriptionsAPI from './transcriptions';\nimport * as AudioAPI from './audio';\nimport { APIPromise } from '../../core/api-promise';\nimport { Stream } from '../../core/streaming';\nimport { type Uploadable } from '../../core/uploads';\nimport { RequestOptions } from '../../internal/request-options';\nimport { multipartFormRequestOptions } from '../../internal/uploads';\n\nexport class Transcriptions extends APIResource {\n  /**\n   * Transcribes audio into the input language.\n   *\n   * @example\n   * ```ts\n   * const transcription =\n   *   await client.audio.transcriptions.create({\n   *     file: fs.createReadStream('speech.mp3'),\n   *     model: 'gpt-4o-transcribe',\n   *   });\n   * ```\n   */\n  create(\n    body: TranscriptionCreateParamsNonStreaming<'json' | undefined>,\n    options?: RequestOptions,\n  ): APIPromise<Transcription>;\n  create(\n    body: TranscriptionCreateParamsNonStreaming<'verbose_json'>,\n    options?: RequestOptions,\n  ): APIPromise<TranscriptionVerbose>;\n  create(\n    body: TranscriptionCreateParamsNonStreaming<'srt' | 'vtt' | 'text'>,\n    options?: RequestOptions,\n  ): APIPromise<string>;\n  create(body: TranscriptionCreateParamsNonStreaming, options?: RequestOptions): APIPromise<Transcription>;\n  create(\n    body: TranscriptionCreateParamsStreaming,\n    options?: RequestOptions,\n  ): APIPromise<Stream<TranscriptionStreamEvent>>;\n  create(\n    body: TranscriptionCreateParamsStreaming,\n    options?: RequestOptions,\n  ): APIPromise<TranscriptionCreateResponse | string | Stream<TranscriptionStreamEvent>>;\n  create(\n    body: TranscriptionCreateParams,\n    options?: RequestOptions,\n  ): APIPromise<TranscriptionCreateResponse | string | Stream<TranscriptionStreamEvent>> {\n    return this._client.post(\n      '/audio/transcriptions',\n      multipartFormRequestOptions(\n        {\n          body,\n          ...options,\n          stream: body.stream ?? false,\n          __metadata: { model: body.model },\n        },\n        this._client,\n      ),\n    );\n  }\n}\n\n/**\n * Represents a transcription response returned by model, based on the provided\n * input.\n */\nexport interface Transcription {\n  /**\n   * The transcribed text.\n   */\n  text: string;\n\n  /**\n   * The log probabilities of the tokens in the transcription. Only returned with the\n   * models `gpt-4o-transcribe` and `gpt-4o-mini-transcribe` if `logprobs` is added\n   * to the `include` array.\n   */\n  logprobs?: Array<Transcription.Logprob>;\n\n  /**\n   * Token usage statistics for the request.\n   */\n  usage?: Transcription.Tokens | Transcription.Duration;\n}\n\nexport namespace Transcription {\n  export interface Logprob {\n    /**\n     * The token in the transcription.\n     */\n    token?: string;\n\n    /**\n     * The bytes of the token.\n     */\n    bytes?: Array<number>;\n\n    /**\n     * The log probability of the token.\n     */\n    logprob?: number;\n  }\n\n  /**\n   * Usage statistics for models billed by token usage.\n   */\n  export interface Tokens {\n    /**\n     * Number of input tokens billed for this request.\n     */\n    input_tokens: number;\n\n    /**\n     * Number of output tokens generated.\n     */\n    output_tokens: number;\n\n    /**\n     * Total number of tokens used (input + output).\n     */\n    total_tokens: number;\n\n    /**\n     * The type of the usage object. Always `tokens` for this variant.\n     */\n    type: 'tokens';\n\n    /**\n     * Details about the input tokens billed for this request.\n     */\n    input_token_details?: Tokens.InputTokenDetails;\n  }\n\n  export namespace Tokens {\n    /**\n     * Details about the input tokens billed for this request.\n     */\n    export interface InputTokenDetails {\n      /**\n       * Number of audio tokens billed for this request.\n       */\n      audio_tokens?: number;\n\n      /**\n       * Number of text tokens billed for this request.\n       */\n      text_tokens?: number;\n    }\n  }\n\n  /**\n   * Usage statistics for models billed by audio input duration.\n   */\n  export interface Duration {\n    /**\n     * Duration of the input audio in seconds.\n     */\n    seconds: number;\n\n    /**\n     * The type of the usage object. Always `duration` for this variant.\n     */\n    type: 'duration';\n  }\n}\n\n/**\n * Represents a diarized transcription response returned by the model, including\n * the combined transcript and speaker-segment annotations.\n */\nexport interface TranscriptionDiarized {\n  /**\n   * Duration of the input audio in seconds.\n   */\n  duration: number;\n\n  /**\n   * Segments of the transcript annotated with timestamps and speaker labels.\n   */\n  segments: Array<TranscriptionDiarizedSegment>;\n\n  /**\n   * The type of task that was run. Always `transcribe`.\n   */\n  task: 'transcribe';\n\n  /**\n   * The concatenated transcript text for the entire audio input.\n   */\n  text: string;\n\n  /**\n   * Token or duration usage statistics for the request.\n   */\n  usage?: TranscriptionDiarized.Tokens | TranscriptionDiarized.Duration;\n}\n\nexport namespace TranscriptionDiarized {\n  /**\n   * Usage statistics for models billed by token usage.\n   */\n  export interface Tokens {\n    /**\n     * Number of input tokens billed for this request.\n     */\n    input_tokens: number;\n\n    /**\n     * Number of output tokens generated.\n     */\n    output_tokens: number;\n\n    /**\n     * Total number of tokens used (input + output).\n     */\n    total_tokens: number;\n\n    /**\n     * The type of the usage object. Always `tokens` for this variant.\n     */\n    type: 'tokens';\n\n    /**\n     * Details about the input tokens billed for this request.\n     */\n    input_token_details?: Tokens.InputTokenDetails;\n  }\n\n  export namespace Tokens {\n    /**\n     * Details about the input tokens billed for this request.\n     */\n    export interface InputTokenDetails {\n      /**\n       * Number of audio tokens billed for this request.\n       */\n      audio_tokens?: number;\n\n      /**\n       * Number of text tokens billed for this request.\n       */\n      text_tokens?: number;\n    }\n  }\n\n  /**\n   * Usage statistics for models billed by audio input duration.\n   */\n  export interface Duration {\n    /**\n     * Duration of the input audio in seconds.\n     */\n    seconds: number;\n\n    /**\n     * The type of the usage object. Always `duration` for this variant.\n     */\n    type: 'duration';\n  }\n}\n\n/**\n * A segment of diarized transcript text with speaker metadata.\n */\nexport interface TranscriptionDiarizedSegment {\n  /**\n   * Unique identifier for the segment.\n   */\n  id: string;\n\n  /**\n   * End timestamp of the segment in seconds.\n   */\n  end: number;\n\n  /**\n   * Speaker label for this segment. When known speakers are provided, the label\n   * matches `known_speaker_names[]`. Otherwise speakers are labeled sequentially\n   * using capital letters (`A`, `B`, ...).\n   */\n  speaker: string;\n\n  /**\n   * Start timestamp of the segment in seconds.\n   */\n  start: number;\n\n  /**\n   * Transcript text for this segment.\n   */\n  text: string;\n\n  /**\n   * The type of the segment. Always `transcript.text.segment`.\n   */\n  type: 'transcript.text.segment';\n}\n\nexport type TranscriptionInclude = 'logprobs';\n\nexport interface TranscriptionSegment {\n  /**\n   * Unique identifier of the segment.\n   */\n  id: number;\n\n  /**\n   * Average logprob of the segment. If the value is lower than -1, consider the\n   * logprobs failed.\n   */\n  avg_logprob: number;\n\n  /**\n   * Compression ratio of the segment. If the value is greater than 2.4, consider the\n   * compression failed.\n   */\n  compression_ratio: number;\n\n  /**\n   * End time of the segment in seconds.\n   */\n  end: number;\n\n  /**\n   * Probability of no speech in the segment. If the value is higher than 1.0 and the\n   * `avg_logprob` is below -1, consider this segment silent.\n   */\n  no_speech_prob: number;\n\n  /**\n   * Seek offset of the segment.\n   */\n  seek: number;\n\n  /**\n   * Start time of the segment in seconds.\n   */\n  start: number;\n\n  /**\n   * Temperature parameter used for generating the segment.\n   */\n  temperature: number;\n\n  /**\n   * Text content of the segment.\n   */\n  text: string;\n\n  /**\n   * Array of token IDs for the text content.\n   */\n  tokens: Array<number>;\n}\n\n/**\n * Emitted when a diarized transcription returns a completed segment with speaker\n * information. Only emitted when you\n * [create a transcription](https://platform.openai.com/docs/api-reference/audio/create-transcription)\n * with `stream` set to `true` and `response_format` set to `diarized_json`.\n */\nexport type TranscriptionStreamEvent =\n  | TranscriptionTextSegmentEvent\n  | TranscriptionTextDeltaEvent\n  | TranscriptionTextDoneEvent;\n\n/**\n * Emitted when there is an additional text delta. This is also the first event\n * emitted when the transcription starts. Only emitted when you\n * [create a transcription](https://platform.openai.com/docs/api-reference/audio/create-transcription)\n * with the `Stream` parameter set to `true`.\n */\nexport interface TranscriptionTextDeltaEvent {\n  /**\n   * The text delta that was additionally transcribed.\n   */\n  delta: string;\n\n  /**\n   * The type of the event. Always `transcript.text.delta`.\n   */\n  type: 'transcript.text.delta';\n\n  /**\n   * The log probabilities of the delta. Only included if you\n   * [create a transcription](https://platform.openai.com/docs/api-reference/audio/create-transcription)\n   * with the `include[]` parameter set to `logprobs`.\n   */\n  logprobs?: Array<TranscriptionTextDeltaEvent.Logprob>;\n\n  /**\n   * Identifier of the diarized segment that this delta belongs to. Only present when\n   * using `gpt-4o-transcribe-diarize`.\n   */\n  segment_id?: string;\n}\n\nexport namespace TranscriptionTextDeltaEvent {\n  export interface Logprob {\n    /**\n     * The token that was used to generate the log probability.\n     */\n    token?: string;\n\n    /**\n     * The bytes that were used to generate the log probability.\n     */\n    bytes?: Array<number>;\n\n    /**\n     * The log probability of the token.\n     */\n    logprob?: number;\n  }\n}\n\n/**\n * Emitted when the transcription is complete. Contains the complete transcription\n * text. Only emitted when you\n * [create a transcription](https://platform.openai.com/docs/api-reference/audio/create-transcription)\n * with the `Stream` parameter set to `true`.\n */\nexport interface TranscriptionTextDoneEvent {\n  /**\n   * The text that was transcribed.\n   */\n  text: string;\n\n  /**\n   * The type of the event. Always `transcript.text.done`.\n   */\n  type: 'transcript.text.done';\n\n  /**\n   * The log probabilities of the individual tokens in the transcription. Only\n   * included if you\n   * [create a transcription](https://platform.openai.com/docs/api-reference/audio/create-transcription)\n   * with the `include[]` parameter set to `logprobs`.\n   */\n  logprobs?: Array<TranscriptionTextDoneEvent.Logprob>;\n\n  /**\n   * Usage statistics for models billed by token usage.\n   */\n  usage?: TranscriptionTextDoneEvent.Usage;\n}\n\nexport namespace TranscriptionTextDoneEvent {\n  export interface Logprob {\n    /**\n     * The token that was used to generate the log probability.\n     */\n    token?: string;\n\n    /**\n     * The bytes that were used to generate the log probability.\n     */\n    bytes?: Array<number>;\n\n    /**\n     * The log probability of the token.\n     */\n    logprob?: number;\n  }\n\n  /**\n   * Usage statistics for models billed by token usage.\n   */\n  export interface Usage {\n    /**\n     * Number of input tokens billed for this request.\n     */\n    input_tokens: number;\n\n    /**\n     * Number of output tokens generated.\n     */\n    output_tokens: number;\n\n    /**\n     * Total number of tokens used (input + output).\n     */\n    total_tokens: number;\n\n    /**\n     * The type of the usage object. Always `tokens` for this variant.\n     */\n    type: 'tokens';\n\n    /**\n     * Details about the input tokens billed for this request.\n     */\n    input_token_details?: Usage.InputTokenDetails;\n  }\n\n  export namespace Usage {\n    /**\n     * Details about the input tokens billed for this request.\n     */\n    export interface InputTokenDetails {\n      /**\n       * Number of audio tokens billed for this request.\n       */\n      audio_tokens?: number;\n\n      /**\n       * Number of text tokens billed for this request.\n       */\n      text_tokens?: number;\n    }\n  }\n}\n\n/**\n * Emitted when a diarized transcription returns a completed segment with speaker\n * information. Only emitted when you\n * [create a transcription](https://platform.openai.com/docs/api-reference/audio/create-transcription)\n * with `stream` set to `true` and `response_format` set to `diarized_json`.\n */\nexport interface TranscriptionTextSegmentEvent {\n  /**\n   * Unique identifier for the segment.\n   */\n  id: string;\n\n  /**\n   * End timestamp of the segment in seconds.\n   */\n  end: number;\n\n  /**\n   * Speaker label for this segment.\n   */\n  speaker: string;\n\n  /**\n   * Start timestamp of the segment in seconds.\n   */\n  start: number;\n\n  /**\n   * Transcript text for this segment.\n   */\n  text: string;\n\n  /**\n   * The type of the event. Always `transcript.text.segment`.\n   */\n  type: 'transcript.text.segment';\n}\n\n/**\n * Represents a verbose json transcription response returned by model, based on the\n * provided input.\n */\nexport interface TranscriptionVerbose {\n  /**\n   * The duration of the input audio.\n   */\n  duration: number;\n\n  /**\n   * The language of the input audio.\n   */\n  language: string;\n\n  /**\n   * The transcribed text.\n   */\n  text: string;\n\n  /**\n   * Segments of the transcribed text and their corresponding details.\n   */\n  segments?: Array<TranscriptionSegment>;\n\n  /**\n   * Usage statistics for models billed by audio input duration.\n   */\n  usage?: TranscriptionVerbose.Usage;\n\n  /**\n   * Extracted words and their corresponding timestamps.\n   */\n  words?: Array<TranscriptionWord>;\n}\n\nexport namespace TranscriptionVerbose {\n  /**\n   * Usage statistics for models billed by audio input duration.\n   */\n  export interface Usage {\n    /**\n     * Duration of the input audio in seconds.\n     */\n    seconds: number;\n\n    /**\n     * The type of the usage object. Always `duration` for this variant.\n     */\n    type: 'duration';\n  }\n}\n\nexport interface TranscriptionWord {\n  /**\n   * End time of the word in seconds.\n   */\n  end: number;\n\n  /**\n   * Start time of the word in seconds.\n   */\n  start: number;\n\n  /**\n   * The text content of the word.\n   */\n  word: string;\n}\n\n/**\n * Represents a transcription response returned by model, based on the provided\n * input.\n */\nexport type TranscriptionCreateResponse = Transcription | TranscriptionDiarized | TranscriptionVerbose;\n\nexport type TranscriptionCreateParams<\n  ResponseFormat extends AudioAPI.AudioResponseFormat | undefined = AudioAPI.AudioResponseFormat | undefined,\n> = TranscriptionCreateParamsNonStreaming<ResponseFormat> | TranscriptionCreateParamsStreaming;\n\nexport interface TranscriptionCreateParamsBase<\n  ResponseFormat extends AudioAPI.AudioResponseFormat | undefined = AudioAPI.AudioResponseFormat | undefined,\n> {\n  /**\n   * The audio file object (not file name) to transcribe, in one of these formats:\n   * flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.\n   */\n  file: Uploadable;\n\n  /**\n   * ID of the model to use. The options are `gpt-4o-transcribe`,\n   * `gpt-4o-mini-transcribe`, `whisper-1` (which is powered by our open source\n   * Whisper V2 model), and `gpt-4o-transcribe-diarize`.\n   */\n  model: (string & {}) | AudioAPI.AudioModel;\n\n  /**\n   * Controls how the audio is cut into chunks. When set to `\"auto\"`, the server\n   * first normalizes loudness and then uses voice activity detection (VAD) to choose\n   * boundaries. `server_vad` object can be provided to tweak VAD detection\n   * parameters manually. If unset, the audio is transcribed as a single block.\n   * Required when using `gpt-4o-transcribe-diarize` for inputs longer than 30\n   * seconds.\n   */\n  chunking_strategy?: 'auto' | TranscriptionCreateParams.VadConfig | null;\n\n  /**\n   * Additional information to include in the transcription response. `logprobs` will\n   * return the log probabilities of the tokens in the response to understand the\n   * model's confidence in the transcription. `logprobs` only works with\n   * response_format set to `json` and only with the models `gpt-4o-transcribe` and\n   * `gpt-4o-mini-transcribe`. This field is not supported when using\n   * `gpt-4o-transcribe-diarize`.\n   */\n  include?: Array<TranscriptionInclude>;\n\n  /**\n   * Optional list of speaker names that correspond to the audio samples provided in\n   * `known_speaker_references[]`. Each entry should be a short identifier (for\n   * example `customer` or `agent`). Up to 4 speakers are supported.\n   */\n  known_speaker_names?: Array<string>;\n\n  /**\n   * Optional list of audio samples (as\n   * [data URLs](https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/Data_URLs))\n   * that contain known speaker references matching `known_speaker_names[]`. Each\n   * sample must be between 2 and 10 seconds, and can use any of the same input audio\n   * formats supported by `file`.\n   */\n  known_speaker_references?: Array<string>;\n\n  /**\n   * The language of the input audio. Supplying the input language in\n   * [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`)\n   * format will improve accuracy and latency.\n   */\n  language?: string;\n\n  /**\n   * An optional text to guide the model's style or continue a previous audio\n   * segment. The\n   * [prompt](https://platform.openai.com/docs/guides/speech-to-text#prompting)\n   * should match the audio language. This field is not supported when using\n   * `gpt-4o-transcribe-diarize`.\n   */\n  prompt?: string;\n\n  /**\n   * The format of the output, in one of these options: `json`, `text`, `srt`,\n   * `verbose_json`, `vtt`, or `diarized_json`. For `gpt-4o-transcribe` and\n   * `gpt-4o-mini-transcribe`, the only supported format is `json`. For\n   * `gpt-4o-transcribe-diarize`, the supported formats are `json`, `text`, and\n   * `diarized_json`, with `diarized_json` required to receive speaker annotations.\n   */\n  response_format?: ResponseFormat;\n\n  /**\n   * If set to true, the model response data will be streamed to the client as it is\n   * generated using\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\n   * See the\n   * [Streaming section of the Speech-to-Text guide](https://platform.openai.com/docs/guides/speech-to-text?lang=curl#streaming-transcriptions)\n   * for more information.\n   *\n   * Note: Streaming is not supported for the `whisper-1` model and will be ignored.\n   */\n  stream?: boolean | null;\n\n  /**\n   * The sampling temperature, between 0 and 1. Higher values like 0.8 will make the\n   * output more random, while lower values like 0.2 will make it more focused and\n   * deterministic. If set to 0, the model will use\n   * [log probability](https://en.wikipedia.org/wiki/Log_probability) to\n   * automatically increase the temperature until certain thresholds are hit.\n   */\n  temperature?: number;\n\n  /**\n   * The timestamp granularities to populate for this transcription.\n   * `response_format` must be set `verbose_json` to use timestamp granularities.\n   * Either or both of these options are supported: `word`, or `segment`. Note: There\n   * is no additional latency for segment timestamps, but generating word timestamps\n   * incurs additional latency. This option is not available for\n   * `gpt-4o-transcribe-diarize`.\n   */\n  timestamp_granularities?: Array<'word' | 'segment'>;\n}\n\nexport namespace TranscriptionCreateParams {\n  export interface VadConfig {\n    /**\n     * Must be set to `server_vad` to enable manual chunking using server side VAD.\n     */\n    type: 'server_vad';\n\n    /**\n     * Amount of audio to include before the VAD detected speech (in milliseconds).\n     */\n    prefix_padding_ms?: number;\n\n    /**\n     * Duration of silence to detect speech stop (in milliseconds). With shorter values\n     * the model will respond more quickly, but may jump in on short pauses from the\n     * user.\n     */\n    silence_duration_ms?: number;\n\n    /**\n     * Sensitivity threshold (0.0 to 1.0) for voice activity detection. A higher\n     * threshold will require louder audio to activate the model, and thus might\n     * perform better in noisy environments.\n     */\n    threshold?: number;\n  }\n\n  export type TranscriptionCreateParamsNonStreaming = TranscriptionsAPI.TranscriptionCreateParamsNonStreaming;\n  export type TranscriptionCreateParamsStreaming = TranscriptionsAPI.TranscriptionCreateParamsStreaming;\n}\n\nexport interface TranscriptionCreateParamsNonStreaming<\n  ResponseFormat extends AudioAPI.AudioResponseFormat | undefined = AudioAPI.AudioResponseFormat | undefined,\n> extends TranscriptionCreateParamsBase<ResponseFormat> {\n  /**\n   * If set to true, the model response data will be streamed to the client as it is\n   * generated using\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\n   * See the\n   * [Streaming section of the Speech-to-Text guide](https://platform.openai.com/docs/guides/speech-to-text?lang=curl#streaming-transcriptions)\n   * for more information.\n   *\n   * Note: Streaming is not supported for the `whisper-1` model and will be ignored.\n   */\n  stream?: false | null;\n}\n\nexport interface TranscriptionCreateParamsStreaming extends TranscriptionCreateParamsBase {\n  /**\n   * If set to true, the model response data will be streamed to the client as it is\n   * generated using\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\n   * See the\n   * [Streaming section of the Speech-to-Text guide](https://platform.openai.com/docs/guides/speech-to-text?lang=curl#streaming-transcriptions)\n   * for more information.\n   *\n   * Note: Streaming is not supported for the `whisper-1` model and will be ignored.\n   */\n  stream: true;\n}\n\nexport declare namespace Transcriptions {\n  export {\n    type Transcription as Transcription,\n    type TranscriptionDiarized as TranscriptionDiarized,\n    type TranscriptionDiarizedSegment as TranscriptionDiarizedSegment,\n    type TranscriptionInclude as TranscriptionInclude,\n    type TranscriptionSegment as TranscriptionSegment,\n    type TranscriptionStreamEvent as TranscriptionStreamEvent,\n    type TranscriptionTextDeltaEvent as TranscriptionTextDeltaEvent,\n    type TranscriptionTextDoneEvent as TranscriptionTextDoneEvent,\n    type TranscriptionTextSegmentEvent as TranscriptionTextSegmentEvent,\n    type TranscriptionVerbose as TranscriptionVerbose,\n    type TranscriptionWord as TranscriptionWord,\n    type TranscriptionCreateResponse as TranscriptionCreateResponse,\n    type TranscriptionCreateParams as TranscriptionCreateParams,\n    type TranscriptionCreateParamsNonStreaming as TranscriptionCreateParamsNonStreaming,\n    type TranscriptionCreateParamsStreaming as TranscriptionCreateParamsStreaming,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as Shared from '../shared';\nimport * as ItemsAPI from './items';\nimport {\n  ConversationItem,\n  ConversationItemList,\n  ConversationItemsPage,\n  ItemCreateParams,\n  ItemDeleteParams,\n  ItemListParams,\n  ItemRetrieveParams,\n  Items,\n} from './items';\nimport * as ResponsesAPI from '../responses/responses';\nimport { APIPromise } from '../../core/api-promise';\nimport { RequestOptions } from '../../internal/request-options';\nimport { path } from '../../internal/utils/path';\n\nexport class Conversations extends APIResource {\n  items: ItemsAPI.Items = new ItemsAPI.Items(this._client);\n\n  /**\n   * Create a conversation.\n   */\n  create(\n    body: ConversationCreateParams | null | undefined = {},\n    options?: RequestOptions,\n  ): APIPromise<Conversation> {\n    return this._client.post('/conversations', { body, ...options });\n  }\n\n  /**\n   * Get a conversation\n   */\n  retrieve(conversationID: string, options?: RequestOptions): APIPromise<Conversation> {\n    return this._client.get(path`/conversations/${conversationID}`, options);\n  }\n\n  /**\n   * Update a conversation\n   */\n  update(\n    conversationID: string,\n    body: ConversationUpdateParams,\n    options?: RequestOptions,\n  ): APIPromise<Conversation> {\n    return this._client.post(path`/conversations/${conversationID}`, { body, ...options });\n  }\n\n  /**\n   * Delete a conversation. Items in the conversation will not be deleted.\n   */\n  delete(conversationID: string, options?: RequestOptions): APIPromise<ConversationDeletedResource> {\n    return this._client.delete(path`/conversations/${conversationID}`, options);\n  }\n}\n\n/**\n * A screenshot of a computer.\n */\nexport interface ComputerScreenshotContent {\n  /**\n   * The identifier of an uploaded file that contains the screenshot.\n   */\n  file_id: string | null;\n\n  /**\n   * The URL of the screenshot image.\n   */\n  image_url: string | null;\n\n  /**\n   * Specifies the event type. For a computer screenshot, this property is always set\n   * to `computer_screenshot`.\n   */\n  type: 'computer_screenshot';\n}\n\nexport interface Conversation {\n  /**\n   * The unique ID of the conversation.\n   */\n  id: string;\n\n  /**\n   * The time at which the conversation was created, measured in seconds since the\n   * Unix epoch.\n   */\n  created_at: number;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard. Keys are strings with a maximum\n   * length of 64 characters. Values are strings with a maximum length of 512\n   * characters.\n   */\n  metadata: unknown;\n\n  /**\n   * The object type, which is always `conversation`.\n   */\n  object: 'conversation';\n}\n\nexport interface ConversationDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'conversation.deleted';\n}\n\nexport interface ConversationDeletedResource {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'conversation.deleted';\n}\n\n/**\n * A message to or from the model.\n */\nexport interface Message {\n  /**\n   * The unique ID of the message.\n   */\n  id: string;\n\n  /**\n   * The content of the message\n   */\n  content: Array<\n    | ResponsesAPI.ResponseInputText\n    | ResponsesAPI.ResponseOutputText\n    | TextContent\n    | SummaryTextContent\n    | Message.ReasoningText\n    | ResponsesAPI.ResponseOutputRefusal\n    | ResponsesAPI.ResponseInputImage\n    | ComputerScreenshotContent\n    | ResponsesAPI.ResponseInputFile\n  >;\n\n  /**\n   * The role of the message. One of `unknown`, `user`, `assistant`, `system`,\n   * `critic`, `discriminator`, `developer`, or `tool`.\n   */\n  role: 'unknown' | 'user' | 'assistant' | 'system' | 'critic' | 'discriminator' | 'developer' | 'tool';\n\n  /**\n   * The status of item. One of `in_progress`, `completed`, or `incomplete`.\n   * Populated when items are returned via API.\n   */\n  status: 'in_progress' | 'completed' | 'incomplete';\n\n  /**\n   * The type of the message. Always set to `message`.\n   */\n  type: 'message';\n}\n\nexport namespace Message {\n  /**\n   * Reasoning text from the model.\n   */\n  export interface ReasoningText {\n    /**\n     * The reasoning text from the model.\n     */\n    text: string;\n\n    /**\n     * The type of the reasoning text. Always `reasoning_text`.\n     */\n    type: 'reasoning_text';\n  }\n}\n\n/**\n * A summary text from the model.\n */\nexport interface SummaryTextContent {\n  /**\n   * A summary of the reasoning output from the model so far.\n   */\n  text: string;\n\n  /**\n   * The type of the object. Always `summary_text`.\n   */\n  type: 'summary_text';\n}\n\n/**\n * A text content.\n */\nexport interface TextContent {\n  text: string;\n\n  type: 'text';\n}\n\nexport type InputTextContent = ResponsesAPI.ResponseInputText;\n\nexport type OutputTextContent = ResponsesAPI.ResponseOutputText;\n\nexport type RefusalContent = ResponsesAPI.ResponseOutputRefusal;\n\nexport type InputImageContent = ResponsesAPI.ResponseInputImage;\n\nexport type InputFileContent = ResponsesAPI.ResponseInputFile;\n\nexport interface ConversationCreateParams {\n  /**\n   * Initial items to include in the conversation context. You may add up to 20 items\n   * at a time.\n   */\n  items?: Array<ResponsesAPI.ResponseInputItem> | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n}\n\nexport interface ConversationUpdateParams {\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n}\n\nConversations.Items = Items;\n\nexport declare namespace Conversations {\n  export {\n    type ComputerScreenshotContent as ComputerScreenshotContent,\n    type Conversation as Conversation,\n    type ConversationDeleted as ConversationDeleted,\n    type ConversationDeletedResource as ConversationDeletedResource,\n    type Message as Message,\n    type SummaryTextContent as SummaryTextContent,\n    type TextContent as TextContent,\n    type InputTextContent as InputTextContent,\n    type OutputTextContent as OutputTextContent,\n    type RefusalContent as RefusalContent,\n    type InputImageContent as InputImageContent,\n    type InputFileContent as InputFileContent,\n    type ConversationCreateParams as ConversationCreateParams,\n    type ConversationUpdateParams as ConversationUpdateParams,\n  };\n\n  export {\n    Items as Items,\n    type ConversationItem as ConversationItem,\n    type ConversationItemList as ConversationItemList,\n    type ConversationItemsPage as ConversationItemsPage,\n    type ItemCreateParams as ItemCreateParams,\n    type ItemRetrieveParams as ItemRetrieveParams,\n    type ItemListParams as ItemListParams,\n    type ItemDeleteParams as ItemDeleteParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../core/resource';\nimport { APIPromise } from '../core/api-promise';\nimport { RequestOptions } from '../internal/request-options';\nimport { loggerFor, toFloat32Array } from '../internal/utils';\n\nexport class Embeddings extends APIResource {\n  /**\n   * Creates an embedding vector representing the input text.\n   *\n   * @example\n   * ```ts\n   * const createEmbeddingResponse =\n   *   await client.embeddings.create({\n   *     input: 'The quick brown fox jumped over the lazy dog',\n   *     model: 'text-embedding-3-small',\n   *   });\n   * ```\n   */\n  create(body: EmbeddingCreateParams, options?: RequestOptions): APIPromise<CreateEmbeddingResponse> {\n    const hasUserProvidedEncodingFormat = !!body.encoding_format;\n    // No encoding_format specified, defaulting to base64 for performance reasons\n    // See https://github.com/openai/openai-node/pull/1312\n    let encoding_format: EmbeddingCreateParams['encoding_format'] =\n      hasUserProvidedEncodingFormat ? body.encoding_format : 'base64';\n\n    if (hasUserProvidedEncodingFormat) {\n      loggerFor(this._client).debug('embeddings/user defined encoding_format:', body.encoding_format);\n    }\n\n    const response: APIPromise<CreateEmbeddingResponse> = this._client.post('/embeddings', {\n      body: {\n        ...body,\n        encoding_format: encoding_format as EmbeddingCreateParams['encoding_format'],\n      },\n      ...options,\n    });\n\n    // if the user specified an encoding_format, return the response as-is\n    if (hasUserProvidedEncodingFormat) {\n      return response;\n    }\n\n    // in this stage, we are sure the user did not specify an encoding_format\n    // and we defaulted to base64 for performance reasons\n    // we are sure then that the response is base64 encoded, let's decode it\n    // the returned result will be a float32 array since this is OpenAI API's default encoding\n    loggerFor(this._client).debug('embeddings/decoding base64 embeddings from base64');\n\n    return (response as APIPromise<CreateEmbeddingResponse>)._thenUnwrap((response) => {\n      if (response && response.data) {\n        response.data.forEach((embeddingBase64Obj) => {\n          const embeddingBase64Str = embeddingBase64Obj.embedding as unknown as string;\n          embeddingBase64Obj.embedding = toFloat32Array(embeddingBase64Str);\n        });\n      }\n\n      return response;\n    });\n  }\n}\n\nexport interface CreateEmbeddingResponse {\n  /**\n   * The list of embeddings generated by the model.\n   */\n  data: Array<Embedding>;\n\n  /**\n   * The name of the model used to generate the embedding.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always \"list\".\n   */\n  object: 'list';\n\n  /**\n   * The usage information for the request.\n   */\n  usage: CreateEmbeddingResponse.Usage;\n}\n\nexport namespace CreateEmbeddingResponse {\n  /**\n   * The usage information for the request.\n   */\n  export interface Usage {\n    /**\n     * The number of tokens used by the prompt.\n     */\n    prompt_tokens: number;\n\n    /**\n     * The total number of tokens used by the request.\n     */\n    total_tokens: number;\n  }\n}\n\n/**\n * Represents an embedding vector returned by embedding endpoint.\n */\nexport interface Embedding {\n  /**\n   * The embedding vector, which is a list of floats. The length of vector depends on\n   * the model as listed in the\n   * [embedding guide](https://platform.openai.com/docs/guides/embeddings).\n   */\n  embedding: Array<number>;\n\n  /**\n   * The index of the embedding in the list of embeddings.\n   */\n  index: number;\n\n  /**\n   * The object type, which is always \"embedding\".\n   */\n  object: 'embedding';\n}\n\nexport type EmbeddingModel = 'text-embedding-ada-002' | 'text-embedding-3-small' | 'text-embedding-3-large';\n\nexport interface EmbeddingCreateParams {\n  /**\n   * Input text to embed, encoded as a string or array of tokens. To embed multiple\n   * inputs in a single request, pass an array of strings or array of token arrays.\n   * The input must not exceed the max input tokens for the model (8192 tokens for\n   * all embedding models), cannot be an empty string, and any array must be 2048\n   * dimensions or less.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)\n   * for counting tokens. In addition to the per-input token limit, all embedding\n   * models enforce a maximum of 300,000 tokens summed across all inputs in a single\n   * request.\n   */\n  input: string | Array<string> | Array<number> | Array<Array<number>>;\n\n  /**\n   * ID of the model to use. You can use the\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n   * see all of your available models, or see our\n   * [Model overview](https://platform.openai.com/docs/models) for descriptions of\n   * them.\n   */\n  model: (string & {}) | EmbeddingModel;\n\n  /**\n   * The number of dimensions the resulting output embeddings should have. Only\n   * supported in `text-embedding-3` and later models.\n   */\n  dimensions?: number;\n\n  /**\n   * The format to return the embeddings in. Can be either `float` or\n   * [`base64`](https://pypi.org/project/pybase64/).\n   */\n  encoding_format?: 'float' | 'base64';\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n   */\n  user?: string;\n}\n\nexport declare namespace Embeddings {\n  export {\n    type CreateEmbeddingResponse as CreateEmbeddingResponse,\n    type Embedding as Embedding,\n    type EmbeddingModel as EmbeddingModel,\n    type EmbeddingCreateParams as EmbeddingCreateParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { OpenAIError } from '../../core/error';\n\n// https://url.spec.whatwg.org/#url-scheme-string\nconst startsWithSchemeRegexp = /^[a-z][a-z0-9+.-]*:/i;\n\nexport const isAbsoluteURL = (url: string): boolean => {\n  return startsWithSchemeRegexp.test(url);\n};\n\nexport let isArray = (val: unknown): val is unknown[] => ((isArray = Array.isArray), isArray(val));\nexport let isReadonlyArray = isArray as (val: unknown) => val is readonly unknown[];\n\n/** Returns an object if the given value isn't an object, otherwise returns as-is */\nexport function maybeObj(x: unknown): object {\n  if (typeof x !== 'object') {\n    return {};\n  }\n\n  return x ?? {};\n}\n\n// https://stackoverflow.com/a/34491287\nexport function isEmptyObj(obj: Object | null | undefined): boolean {\n  if (!obj) return true;\n  for (const _k in obj) return false;\n  return true;\n}\n\n// https://eslint.org/docs/latest/rules/no-prototype-builtins\nexport function hasOwn<T extends object = object>(obj: T, key: PropertyKey): key is keyof T {\n  return Object.prototype.hasOwnProperty.call(obj, key);\n}\n\nexport function isObj(obj: unknown): obj is Record<string, unknown> {\n  return obj != null && typeof obj === 'object' && !Array.isArray(obj);\n}\n\nexport const ensurePresent = <T>(value: T | null | undefined): T => {\n  if (value == null) {\n    throw new OpenAIError(`Expected a value to be given but received ${value} instead.`);\n  }\n\n  return value;\n};\n\nexport const validatePositiveInteger = (name: string, n: unknown): number => {\n  if (typeof n !== 'number' || !Number.isInteger(n)) {\n    throw new OpenAIError(`${name} must be an integer`);\n  }\n  if (n < 0) {\n    throw new OpenAIError(`${name} must be a positive integer`);\n  }\n  return n;\n};\n\nexport const coerceInteger = (value: unknown): number => {\n  if (typeof value === 'number') return Math.round(value);\n  if (typeof value === 'string') return parseInt(value, 10);\n\n  throw new OpenAIError(`Could not coerce ${value} (type: ${typeof value}) into a number`);\n};\n\nexport const coerceFloat = (value: unknown): number => {\n  if (typeof value === 'number') return value;\n  if (typeof value === 'string') return parseFloat(value);\n\n  throw new OpenAIError(`Could not coerce ${value} (type: ${typeof value}) into a number`);\n};\n\nexport const coerceBoolean = (value: unknown): boolean => {\n  if (typeof value === 'boolean') return value;\n  if (typeof value === 'string') return value === 'true';\n  return Boolean(value);\n};\n\nexport const maybeCoerceInteger = (value: unknown): number | undefined => {\n  if (value == null) {\n    return undefined;\n  }\n  return coerceInteger(value);\n};\n\nexport const maybeCoerceFloat = (value: unknown): number | undefined => {\n  if (value == null) {\n    return undefined;\n  }\n  return coerceFloat(value);\n};\n\nexport const maybeCoerceBoolean = (value: unknown): boolean | undefined => {\n  if (value == null) {\n    return undefined;\n  }\n  return coerceBoolean(value);\n};\n\nexport const safeJSON = (text: string) => {\n  try {\n    return JSON.parse(text);\n  } catch (err) {\n    return undefined;\n  }\n};\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport * as RunsAPI from './runs';\nimport { APIPromise } from '../../../core/api-promise';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../../../core/pagination';\nimport { RequestOptions } from '../../../internal/request-options';\nimport { path } from '../../../internal/utils/path';\n\nexport class OutputItems extends APIResource {\n  /**\n   * Get an evaluation run output item by ID.\n   */\n  retrieve(\n    outputItemID: string,\n    params: OutputItemRetrieveParams,\n    options?: RequestOptions,\n  ): APIPromise<OutputItemRetrieveResponse> {\n    const { eval_id, run_id } = params;\n    return this._client.get(path`/evals/${eval_id}/runs/${run_id}/output_items/${outputItemID}`, options);\n  }\n\n  /**\n   * Get a list of output items for an evaluation run.\n   */\n  list(\n    runID: string,\n    params: OutputItemListParams,\n    options?: RequestOptions,\n  ): PagePromise<OutputItemListResponsesPage, OutputItemListResponse> {\n    const { eval_id, ...query } = params;\n    return this._client.getAPIList(\n      path`/evals/${eval_id}/runs/${runID}/output_items`,\n      CursorPage<OutputItemListResponse>,\n      { query, ...options },\n    );\n  }\n}\n\nexport type OutputItemListResponsesPage = CursorPage<OutputItemListResponse>;\n\n/**\n * A schema representing an evaluation run output item.\n */\nexport interface OutputItemRetrieveResponse {\n  /**\n   * Unique identifier for the evaluation run output item.\n   */\n  id: string;\n\n  /**\n   * Unix timestamp (in seconds) when the evaluation run was created.\n   */\n  created_at: number;\n\n  /**\n   * Details of the input data source item.\n   */\n  datasource_item: { [key: string]: unknown };\n\n  /**\n   * The identifier for the data source item.\n   */\n  datasource_item_id: number;\n\n  /**\n   * The identifier of the evaluation group.\n   */\n  eval_id: string;\n\n  /**\n   * The type of the object. Always \"eval.run.output_item\".\n   */\n  object: 'eval.run.output_item';\n\n  /**\n   * A list of grader results for this output item.\n   */\n  results: Array<OutputItemRetrieveResponse.Result>;\n\n  /**\n   * The identifier of the evaluation run associated with this output item.\n   */\n  run_id: string;\n\n  /**\n   * A sample containing the input and output of the evaluation run.\n   */\n  sample: OutputItemRetrieveResponse.Sample;\n\n  /**\n   * The status of the evaluation run.\n   */\n  status: string;\n}\n\nexport namespace OutputItemRetrieveResponse {\n  /**\n   * A single grader result for an evaluation run output item.\n   */\n  export interface Result {\n    /**\n     * The name of the grader.\n     */\n    name: string;\n\n    /**\n     * Whether the grader considered the output a pass.\n     */\n    passed: boolean;\n\n    /**\n     * The numeric score produced by the grader.\n     */\n    score: number;\n\n    /**\n     * Optional sample or intermediate data produced by the grader.\n     */\n    sample?: { [key: string]: unknown } | null;\n\n    /**\n     * The grader type (for example, \"string-check-grader\").\n     */\n    type?: string;\n\n    [k: string]: unknown;\n  }\n\n  /**\n   * A sample containing the input and output of the evaluation run.\n   */\n  export interface Sample {\n    /**\n     * An object representing an error response from the Eval API.\n     */\n    error: RunsAPI.EvalAPIError;\n\n    /**\n     * The reason why the sample generation was finished.\n     */\n    finish_reason: string;\n\n    /**\n     * An array of input messages.\n     */\n    input: Array<Sample.Input>;\n\n    /**\n     * The maximum number of tokens allowed for completion.\n     */\n    max_completion_tokens: number;\n\n    /**\n     * The model used for generating the sample.\n     */\n    model: string;\n\n    /**\n     * An array of output messages.\n     */\n    output: Array<Sample.Output>;\n\n    /**\n     * The seed used for generating the sample.\n     */\n    seed: number;\n\n    /**\n     * The sampling temperature used.\n     */\n    temperature: number;\n\n    /**\n     * The top_p value used for sampling.\n     */\n    top_p: number;\n\n    /**\n     * Token usage details for the sample.\n     */\n    usage: Sample.Usage;\n  }\n\n  export namespace Sample {\n    /**\n     * An input message.\n     */\n    export interface Input {\n      /**\n       * The content of the message.\n       */\n      content: string;\n\n      /**\n       * The role of the message sender (e.g., system, user, developer).\n       */\n      role: string;\n    }\n\n    export interface Output {\n      /**\n       * The content of the message.\n       */\n      content?: string;\n\n      /**\n       * The role of the message (e.g. \"system\", \"assistant\", \"user\").\n       */\n      role?: string;\n    }\n\n    /**\n     * Token usage details for the sample.\n     */\n    export interface Usage {\n      /**\n       * The number of tokens retrieved from cache.\n       */\n      cached_tokens: number;\n\n      /**\n       * The number of completion tokens generated.\n       */\n      completion_tokens: number;\n\n      /**\n       * The number of prompt tokens used.\n       */\n      prompt_tokens: number;\n\n      /**\n       * The total number of tokens used.\n       */\n      total_tokens: number;\n    }\n  }\n}\n\n/**\n * A schema representing an evaluation run output item.\n */\nexport interface OutputItemListResponse {\n  /**\n   * Unique identifier for the evaluation run output item.\n   */\n  id: string;\n\n  /**\n   * Unix timestamp (in seconds) when the evaluation run was created.\n   */\n  created_at: number;\n\n  /**\n   * Details of the input data source item.\n   */\n  datasource_item: { [key: string]: unknown };\n\n  /**\n   * The identifier for the data source item.\n   */\n  datasource_item_id: number;\n\n  /**\n   * The identifier of the evaluation group.\n   */\n  eval_id: string;\n\n  /**\n   * The type of the object. Always \"eval.run.output_item\".\n   */\n  object: 'eval.run.output_item';\n\n  /**\n   * A list of grader results for this output item.\n   */\n  results: Array<OutputItemListResponse.Result>;\n\n  /**\n   * The identifier of the evaluation run associated with this output item.\n   */\n  run_id: string;\n\n  /**\n   * A sample containing the input and output of the evaluation run.\n   */\n  sample: OutputItemListResponse.Sample;\n\n  /**\n   * The status of the evaluation run.\n   */\n  status: string;\n}\n\nexport namespace OutputItemListResponse {\n  /**\n   * A single grader result for an evaluation run output item.\n   */\n  export interface Result {\n    /**\n     * The name of the grader.\n     */\n    name: string;\n\n    /**\n     * Whether the grader considered the output a pass.\n     */\n    passed: boolean;\n\n    /**\n     * The numeric score produced by the grader.\n     */\n    score: number;\n\n    /**\n     * Optional sample or intermediate data produced by the grader.\n     */\n    sample?: { [key: string]: unknown } | null;\n\n    /**\n     * The grader type (for example, \"string-check-grader\").\n     */\n    type?: string;\n\n    [k: string]: unknown;\n  }\n\n  /**\n   * A sample containing the input and output of the evaluation run.\n   */\n  export interface Sample {\n    /**\n     * An object representing an error response from the Eval API.\n     */\n    error: RunsAPI.EvalAPIError;\n\n    /**\n     * The reason why the sample generation was finished.\n     */\n    finish_reason: string;\n\n    /**\n     * An array of input messages.\n     */\n    input: Array<Sample.Input>;\n\n    /**\n     * The maximum number of tokens allowed for completion.\n     */\n    max_completion_tokens: number;\n\n    /**\n     * The model used for generating the sample.\n     */\n    model: string;\n\n    /**\n     * An array of output messages.\n     */\n    output: Array<Sample.Output>;\n\n    /**\n     * The seed used for generating the sample.\n     */\n    seed: number;\n\n    /**\n     * The sampling temperature used.\n     */\n    temperature: number;\n\n    /**\n     * The top_p value used for sampling.\n     */\n    top_p: number;\n\n    /**\n     * Token usage details for the sample.\n     */\n    usage: Sample.Usage;\n  }\n\n  export namespace Sample {\n    /**\n     * An input message.\n     */\n    export interface Input {\n      /**\n       * The content of the message.\n       */\n      content: string;\n\n      /**\n       * The role of the message sender (e.g., system, user, developer).\n       */\n      role: string;\n    }\n\n    export interface Output {\n      /**\n       * The content of the message.\n       */\n      content?: string;\n\n      /**\n       * The role of the message (e.g. \"system\", \"assistant\", \"user\").\n       */\n      role?: string;\n    }\n\n    /**\n     * Token usage details for the sample.\n     */\n    export interface Usage {\n      /**\n       * The number of tokens retrieved from cache.\n       */\n      cached_tokens: number;\n\n      /**\n       * The number of completion tokens generated.\n       */\n      completion_tokens: number;\n\n      /**\n       * The number of prompt tokens used.\n       */\n      prompt_tokens: number;\n\n      /**\n       * The total number of tokens used.\n       */\n      total_tokens: number;\n    }\n  }\n}\n\nexport interface OutputItemRetrieveParams {\n  /**\n   * The ID of the evaluation to retrieve runs for.\n   */\n  eval_id: string;\n\n  /**\n   * The ID of the run to retrieve.\n   */\n  run_id: string;\n}\n\nexport interface OutputItemListParams extends CursorPageParams {\n  /**\n   * Path param: The ID of the evaluation to retrieve runs for.\n   */\n  eval_id: string;\n\n  /**\n   * Query param: Sort order for output items by timestamp. Use `asc` for ascending\n   * order or `desc` for descending order. Defaults to `asc`.\n   */\n  order?: 'asc' | 'desc';\n\n  /**\n   * Query param: Filter output items by status. Use `failed` to filter by failed\n   * output items or `pass` to filter by passed output items.\n   */\n  status?: 'fail' | 'pass';\n}\n\nexport declare namespace OutputItems {\n  export {\n    type OutputItemRetrieveResponse as OutputItemRetrieveResponse,\n    type OutputItemListResponse as OutputItemListResponse,\n    type OutputItemListResponsesPage as OutputItemListResponsesPage,\n    type OutputItemRetrieveParams as OutputItemRetrieveParams,\n    type OutputItemListParams as OutputItemListParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport * as Shared from '../../shared';\nimport * as ResponsesAPI from '../../responses/responses';\nimport * as CompletionsAPI from '../../chat/completions/completions';\nimport * as OutputItemsAPI from './output-items';\nimport {\n  OutputItemListParams,\n  OutputItemListResponse,\n  OutputItemListResponsesPage,\n  OutputItemRetrieveParams,\n  OutputItemRetrieveResponse,\n  OutputItems,\n} from './output-items';\nimport { APIPromise } from '../../../core/api-promise';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../../../core/pagination';\nimport { RequestOptions } from '../../../internal/request-options';\nimport { path } from '../../../internal/utils/path';\n\nexport class Runs extends APIResource {\n  outputItems: OutputItemsAPI.OutputItems = new OutputItemsAPI.OutputItems(this._client);\n\n  /**\n   * Kicks off a new run for a given evaluation, specifying the data source, and what\n   * model configuration to use to test. The datasource will be validated against the\n   * schema specified in the config of the evaluation.\n   */\n  create(evalID: string, body: RunCreateParams, options?: RequestOptions): APIPromise<RunCreateResponse> {\n    return this._client.post(path`/evals/${evalID}/runs`, { body, ...options });\n  }\n\n  /**\n   * Get an evaluation run by ID.\n   */\n  retrieve(\n    runID: string,\n    params: RunRetrieveParams,\n    options?: RequestOptions,\n  ): APIPromise<RunRetrieveResponse> {\n    const { eval_id } = params;\n    return this._client.get(path`/evals/${eval_id}/runs/${runID}`, options);\n  }\n\n  /**\n   * Get a list of runs for an evaluation.\n   */\n  list(\n    evalID: string,\n    query: RunListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<RunListResponsesPage, RunListResponse> {\n    return this._client.getAPIList(path`/evals/${evalID}/runs`, CursorPage<RunListResponse>, {\n      query,\n      ...options,\n    });\n  }\n\n  /**\n   * Delete an eval run.\n   */\n  delete(runID: string, params: RunDeleteParams, options?: RequestOptions): APIPromise<RunDeleteResponse> {\n    const { eval_id } = params;\n    return this._client.delete(path`/evals/${eval_id}/runs/${runID}`, options);\n  }\n\n  /**\n   * Cancel an ongoing evaluation run.\n   */\n  cancel(runID: string, params: RunCancelParams, options?: RequestOptions): APIPromise<RunCancelResponse> {\n    const { eval_id } = params;\n    return this._client.post(path`/evals/${eval_id}/runs/${runID}`, options);\n  }\n}\n\nexport type RunListResponsesPage = CursorPage<RunListResponse>;\n\n/**\n * A CompletionsRunDataSource object describing a model sampling configuration.\n */\nexport interface CreateEvalCompletionsRunDataSource {\n  /**\n   * Determines what populates the `item` namespace in this run's data source.\n   */\n  source:\n    | CreateEvalCompletionsRunDataSource.FileContent\n    | CreateEvalCompletionsRunDataSource.FileID\n    | CreateEvalCompletionsRunDataSource.StoredCompletions;\n\n  /**\n   * The type of run data source. Always `completions`.\n   */\n  type: 'completions';\n\n  /**\n   * Used when sampling from a model. Dictates the structure of the messages passed\n   * into the model. Can either be a reference to a prebuilt trajectory (ie,\n   * `item.input_trajectory`), or a template with variable references to the `item`\n   * namespace.\n   */\n  input_messages?:\n    | CreateEvalCompletionsRunDataSource.Template\n    | CreateEvalCompletionsRunDataSource.ItemReference;\n\n  /**\n   * The name of the model to use for generating completions (e.g. \"o3-mini\").\n   */\n  model?: string;\n\n  sampling_params?: CreateEvalCompletionsRunDataSource.SamplingParams;\n}\n\nexport namespace CreateEvalCompletionsRunDataSource {\n  export interface FileContent {\n    /**\n     * The content of the jsonl file.\n     */\n    content: Array<FileContent.Content>;\n\n    /**\n     * The type of jsonl source. Always `file_content`.\n     */\n    type: 'file_content';\n  }\n\n  export namespace FileContent {\n    export interface Content {\n      item: { [key: string]: unknown };\n\n      sample?: { [key: string]: unknown };\n    }\n  }\n\n  export interface FileID {\n    /**\n     * The identifier of the file.\n     */\n    id: string;\n\n    /**\n     * The type of jsonl source. Always `file_id`.\n     */\n    type: 'file_id';\n  }\n\n  /**\n   * A StoredCompletionsRunDataSource configuration describing a set of filters\n   */\n  export interface StoredCompletions {\n    /**\n     * The type of source. Always `stored_completions`.\n     */\n    type: 'stored_completions';\n\n    /**\n     * An optional Unix timestamp to filter items created after this time.\n     */\n    created_after?: number | null;\n\n    /**\n     * An optional Unix timestamp to filter items created before this time.\n     */\n    created_before?: number | null;\n\n    /**\n     * An optional maximum number of items to return.\n     */\n    limit?: number | null;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format, and\n     * querying for objects via API or the dashboard.\n     *\n     * Keys are strings with a maximum length of 64 characters. Values are strings with\n     * a maximum length of 512 characters.\n     */\n    metadata?: Shared.Metadata | null;\n\n    /**\n     * An optional model to filter by (e.g., 'gpt-4o').\n     */\n    model?: string | null;\n  }\n\n  export interface Template {\n    /**\n     * A list of chat messages forming the prompt or context. May include variable\n     * references to the `item` namespace, ie {{item.name}}.\n     */\n    template: Array<ResponsesAPI.EasyInputMessage | Template.EvalItem>;\n\n    /**\n     * The type of input messages. Always `template`.\n     */\n    type: 'template';\n  }\n\n  export namespace Template {\n    /**\n     * A message input to the model with a role indicating instruction following\n     * hierarchy. Instructions given with the `developer` or `system` role take\n     * precedence over instructions given with the `user` role. Messages with the\n     * `assistant` role are presumed to have been generated by the model in previous\n     * interactions.\n     */\n    export interface EvalItem {\n      /**\n       * Inputs to the model - can contain template strings.\n       */\n      content:\n        | string\n        | ResponsesAPI.ResponseInputText\n        | EvalItem.OutputText\n        | EvalItem.InputImage\n        | ResponsesAPI.ResponseInputAudio\n        | Array<unknown>;\n\n      /**\n       * The role of the message input. One of `user`, `assistant`, `system`, or\n       * `developer`.\n       */\n      role: 'user' | 'assistant' | 'system' | 'developer';\n\n      /**\n       * The type of the message input. Always `message`.\n       */\n      type?: 'message';\n    }\n\n    export namespace EvalItem {\n      /**\n       * A text output from the model.\n       */\n      export interface OutputText {\n        /**\n         * The text output from the model.\n         */\n        text: string;\n\n        /**\n         * The type of the output text. Always `output_text`.\n         */\n        type: 'output_text';\n      }\n\n      /**\n       * An image input to the model.\n       */\n      export interface InputImage {\n        /**\n         * The URL of the image input.\n         */\n        image_url: string;\n\n        /**\n         * The type of the image input. Always `input_image`.\n         */\n        type: 'input_image';\n\n        /**\n         * The detail level of the image to be sent to the model. One of `high`, `low`, or\n         * `auto`. Defaults to `auto`.\n         */\n        detail?: string;\n      }\n    }\n  }\n\n  export interface ItemReference {\n    /**\n     * A reference to a variable in the `item` namespace. Ie, \"item.input_trajectory\"\n     */\n    item_reference: string;\n\n    /**\n     * The type of input messages. Always `item_reference`.\n     */\n    type: 'item_reference';\n  }\n\n  export interface SamplingParams {\n    /**\n     * The maximum number of tokens in the generated output.\n     */\n    max_completion_tokens?: number;\n\n    /**\n     * Constrains effort on reasoning for\n     * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n     * supported values are `minimal`, `low`, `medium`, and `high`. Reducing reasoning\n     * effort can result in faster responses and fewer tokens used on reasoning in a\n     * response.\n     *\n     * Note: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning\n     * effort.\n     */\n    reasoning_effort?: Shared.ReasoningEffort | null;\n\n    /**\n     * An object specifying the format that the model must output.\n     *\n     * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n     * Outputs which ensures the model will match your supplied JSON schema. Learn more\n     * in the\n     * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n     *\n     * Setting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\n     * ensures the message the model generates is valid JSON. Using `json_schema` is\n     * preferred for models that support it.\n     */\n    response_format?:\n      | Shared.ResponseFormatText\n      | Shared.ResponseFormatJSONSchema\n      | Shared.ResponseFormatJSONObject;\n\n    /**\n     * A seed value to initialize the randomness, during sampling.\n     */\n    seed?: number;\n\n    /**\n     * A higher temperature increases randomness in the outputs.\n     */\n    temperature?: number;\n\n    /**\n     * A list of tools the model may call. Currently, only functions are supported as a\n     * tool. Use this to provide a list of functions the model may generate JSON inputs\n     * for. A max of 128 functions are supported.\n     */\n    tools?: Array<CompletionsAPI.ChatCompletionFunctionTool>;\n\n    /**\n     * An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n     */\n    top_p?: number;\n  }\n}\n\n/**\n * A JsonlRunDataSource object with that specifies a JSONL file that matches the\n * eval\n */\nexport interface CreateEvalJSONLRunDataSource {\n  /**\n   * Determines what populates the `item` namespace in the data source.\n   */\n  source: CreateEvalJSONLRunDataSource.FileContent | CreateEvalJSONLRunDataSource.FileID;\n\n  /**\n   * The type of data source. Always `jsonl`.\n   */\n  type: 'jsonl';\n}\n\nexport namespace CreateEvalJSONLRunDataSource {\n  export interface FileContent {\n    /**\n     * The content of the jsonl file.\n     */\n    content: Array<FileContent.Content>;\n\n    /**\n     * The type of jsonl source. Always `file_content`.\n     */\n    type: 'file_content';\n  }\n\n  export namespace FileContent {\n    export interface Content {\n      item: { [key: string]: unknown };\n\n      sample?: { [key: string]: unknown };\n    }\n  }\n\n  export interface FileID {\n    /**\n     * The identifier of the file.\n     */\n    id: string;\n\n    /**\n     * The type of jsonl source. Always `file_id`.\n     */\n    type: 'file_id';\n  }\n}\n\n/**\n * An object representing an error response from the Eval API.\n */\nexport interface EvalAPIError {\n  /**\n   * The error code.\n   */\n  code: string;\n\n  /**\n   * The error message.\n   */\n  message: string;\n}\n\n/**\n * A schema representing an evaluation run.\n */\nexport interface RunCreateResponse {\n  /**\n   * Unique identifier for the evaluation run.\n   */\n  id: string;\n\n  /**\n   * Unix timestamp (in seconds) when the evaluation run was created.\n   */\n  created_at: number;\n\n  /**\n   * Information about the run's data source.\n   */\n  data_source:\n    | CreateEvalJSONLRunDataSource\n    | CreateEvalCompletionsRunDataSource\n    | RunCreateResponse.Responses;\n\n  /**\n   * An object representing an error response from the Eval API.\n   */\n  error: EvalAPIError;\n\n  /**\n   * The identifier of the associated evaluation.\n   */\n  eval_id: string;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * The model that is evaluated, if applicable.\n   */\n  model: string;\n\n  /**\n   * The name of the evaluation run.\n   */\n  name: string;\n\n  /**\n   * The type of the object. Always \"eval.run\".\n   */\n  object: 'eval.run';\n\n  /**\n   * Usage statistics for each model during the evaluation run.\n   */\n  per_model_usage: Array<RunCreateResponse.PerModelUsage>;\n\n  /**\n   * Results per testing criteria applied during the evaluation run.\n   */\n  per_testing_criteria_results: Array<RunCreateResponse.PerTestingCriteriaResult>;\n\n  /**\n   * The URL to the rendered evaluation run report on the UI dashboard.\n   */\n  report_url: string;\n\n  /**\n   * Counters summarizing the outcomes of the evaluation run.\n   */\n  result_counts: RunCreateResponse.ResultCounts;\n\n  /**\n   * The status of the evaluation run.\n   */\n  status: string;\n}\n\nexport namespace RunCreateResponse {\n  /**\n   * A ResponsesRunDataSource object describing a model sampling configuration.\n   */\n  export interface Responses {\n    /**\n     * Determines what populates the `item` namespace in this run's data source.\n     */\n    source: Responses.FileContent | Responses.FileID | Responses.Responses;\n\n    /**\n     * The type of run data source. Always `responses`.\n     */\n    type: 'responses';\n\n    /**\n     * Used when sampling from a model. Dictates the structure of the messages passed\n     * into the model. Can either be a reference to a prebuilt trajectory (ie,\n     * `item.input_trajectory`), or a template with variable references to the `item`\n     * namespace.\n     */\n    input_messages?: Responses.Template | Responses.ItemReference;\n\n    /**\n     * The name of the model to use for generating completions (e.g. \"o3-mini\").\n     */\n    model?: string;\n\n    sampling_params?: Responses.SamplingParams;\n  }\n\n  export namespace Responses {\n    export interface FileContent {\n      /**\n       * The content of the jsonl file.\n       */\n      content: Array<FileContent.Content>;\n\n      /**\n       * The type of jsonl source. Always `file_content`.\n       */\n      type: 'file_content';\n    }\n\n    export namespace FileContent {\n      export interface Content {\n        item: { [key: string]: unknown };\n\n        sample?: { [key: string]: unknown };\n      }\n    }\n\n    export interface FileID {\n      /**\n       * The identifier of the file.\n       */\n      id: string;\n\n      /**\n       * The type of jsonl source. Always `file_id`.\n       */\n      type: 'file_id';\n    }\n\n    /**\n     * A EvalResponsesSource object describing a run data source configuration.\n     */\n    export interface Responses {\n      /**\n       * The type of run data source. Always `responses`.\n       */\n      type: 'responses';\n\n      /**\n       * Only include items created after this timestamp (inclusive). This is a query\n       * parameter used to select responses.\n       */\n      created_after?: number | null;\n\n      /**\n       * Only include items created before this timestamp (inclusive). This is a query\n       * parameter used to select responses.\n       */\n      created_before?: number | null;\n\n      /**\n       * Optional string to search the 'instructions' field. This is a query parameter\n       * used to select responses.\n       */\n      instructions_search?: string | null;\n\n      /**\n       * Metadata filter for the responses. This is a query parameter used to select\n       * responses.\n       */\n      metadata?: unknown | null;\n\n      /**\n       * The name of the model to find responses for. This is a query parameter used to\n       * select responses.\n       */\n      model?: string | null;\n\n      /**\n       * Constrains effort on reasoning for\n       * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n       * supported values are `minimal`, `low`, `medium`, and `high`. Reducing reasoning\n       * effort can result in faster responses and fewer tokens used on reasoning in a\n       * response.\n       *\n       * Note: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning\n       * effort.\n       */\n      reasoning_effort?: Shared.ReasoningEffort | null;\n\n      /**\n       * Sampling temperature. This is a query parameter used to select responses.\n       */\n      temperature?: number | null;\n\n      /**\n       * List of tool names. This is a query parameter used to select responses.\n       */\n      tools?: Array<string> | null;\n\n      /**\n       * Nucleus sampling parameter. This is a query parameter used to select responses.\n       */\n      top_p?: number | null;\n\n      /**\n       * List of user identifiers. This is a query parameter used to select responses.\n       */\n      users?: Array<string> | null;\n    }\n\n    export interface Template {\n      /**\n       * A list of chat messages forming the prompt or context. May include variable\n       * references to the `item` namespace, ie {{item.name}}.\n       */\n      template: Array<Template.ChatMessage | Template.EvalItem>;\n\n      /**\n       * The type of input messages. Always `template`.\n       */\n      type: 'template';\n    }\n\n    export namespace Template {\n      export interface ChatMessage {\n        /**\n         * The content of the message.\n         */\n        content: string;\n\n        /**\n         * The role of the message (e.g. \"system\", \"assistant\", \"user\").\n         */\n        role: string;\n      }\n\n      /**\n       * A message input to the model with a role indicating instruction following\n       * hierarchy. Instructions given with the `developer` or `system` role take\n       * precedence over instructions given with the `user` role. Messages with the\n       * `assistant` role are presumed to have been generated by the model in previous\n       * interactions.\n       */\n      export interface EvalItem {\n        /**\n         * Inputs to the model - can contain template strings.\n         */\n        content:\n          | string\n          | ResponsesAPI.ResponseInputText\n          | EvalItem.OutputText\n          | EvalItem.InputImage\n          | ResponsesAPI.ResponseInputAudio\n          | Array<unknown>;\n\n        /**\n         * The role of the message input. One of `user`, `assistant`, `system`, or\n         * `developer`.\n         */\n        role: 'user' | 'assistant' | 'system' | 'developer';\n\n        /**\n         * The type of the message input. Always `message`.\n         */\n        type?: 'message';\n      }\n\n      export namespace EvalItem {\n        /**\n         * A text output from the model.\n         */\n        export interface OutputText {\n          /**\n           * The text output from the model.\n           */\n          text: string;\n\n          /**\n           * The type of the output text. Always `output_text`.\n           */\n          type: 'output_text';\n        }\n\n        /**\n         * An image input to the model.\n         */\n        export interface InputImage {\n          /**\n           * The URL of the image input.\n           */\n          image_url: string;\n\n          /**\n           * The type of the image input. Always `input_image`.\n           */\n          type: 'input_image';\n\n          /**\n           * The detail level of the image to be sent to the model. One of `high`, `low`, or\n           * `auto`. Defaults to `auto`.\n           */\n          detail?: string;\n        }\n      }\n    }\n\n    export interface ItemReference {\n      /**\n       * A reference to a variable in the `item` namespace. Ie, \"item.name\"\n       */\n      item_reference: string;\n\n      /**\n       * The type of input messages. Always `item_reference`.\n       */\n      type: 'item_reference';\n    }\n\n    export interface SamplingParams {\n      /**\n       * The maximum number of tokens in the generated output.\n       */\n      max_completion_tokens?: number;\n\n      /**\n       * Constrains effort on reasoning for\n       * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n       * supported values are `minimal`, `low`, `medium`, and `high`. Reducing reasoning\n       * effort can result in faster responses and fewer tokens used on reasoning in a\n       * response.\n       *\n       * Note: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning\n       * effort.\n       */\n      reasoning_effort?: Shared.ReasoningEffort | null;\n\n      /**\n       * A seed value to initialize the randomness, during sampling.\n       */\n      seed?: number;\n\n      /**\n       * A higher temperature increases randomness in the outputs.\n       */\n      temperature?: number;\n\n      /**\n       * Configuration options for a text response from the model. Can be plain text or\n       * structured JSON data. Learn more:\n       *\n       * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n       * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n       */\n      text?: SamplingParams.Text;\n\n      /**\n       * An array of tools the model may call while generating a response. You can\n       * specify which tool to use by setting the `tool_choice` parameter.\n       *\n       * The two categories of tools you can provide the model are:\n       *\n       * - **Built-in tools**: Tools that are provided by OpenAI that extend the model's\n       *   capabilities, like\n       *   [web search](https://platform.openai.com/docs/guides/tools-web-search) or\n       *   [file search](https://platform.openai.com/docs/guides/tools-file-search).\n       *   Learn more about\n       *   [built-in tools](https://platform.openai.com/docs/guides/tools).\n       * - **Function calls (custom tools)**: Functions that are defined by you, enabling\n       *   the model to call your own code. Learn more about\n       *   [function calling](https://platform.openai.com/docs/guides/function-calling).\n       */\n      tools?: Array<ResponsesAPI.Tool>;\n\n      /**\n       * An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n       */\n      top_p?: number;\n    }\n\n    export namespace SamplingParams {\n      /**\n       * Configuration options for a text response from the model. Can be plain text or\n       * structured JSON data. Learn more:\n       *\n       * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n       * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n       */\n      export interface Text {\n        /**\n         * An object specifying the format that the model must output.\n         *\n         * Configuring `{ \"type\": \"json_schema\" }` enables Structured Outputs, which\n         * ensures the model will match your supplied JSON schema. Learn more in the\n         * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n         *\n         * The default format is `{ \"type\": \"text\" }` with no additional options.\n         *\n         * **Not recommended for gpt-4o and newer models:**\n         *\n         * Setting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\n         * ensures the message the model generates is valid JSON. Using `json_schema` is\n         * preferred for models that support it.\n         */\n        format?: ResponsesAPI.ResponseFormatTextConfig;\n      }\n    }\n  }\n\n  export interface PerModelUsage {\n    /**\n     * The number of tokens retrieved from cache.\n     */\n    cached_tokens: number;\n\n    /**\n     * The number of completion tokens generated.\n     */\n    completion_tokens: number;\n\n    /**\n     * The number of invocations.\n     */\n    invocation_count: number;\n\n    /**\n     * The name of the model.\n     */\n    model_name: string;\n\n    /**\n     * The number of prompt tokens used.\n     */\n    prompt_tokens: number;\n\n    /**\n     * The total number of tokens used.\n     */\n    total_tokens: number;\n  }\n\n  export interface PerTestingCriteriaResult {\n    /**\n     * Number of tests failed for this criteria.\n     */\n    failed: number;\n\n    /**\n     * Number of tests passed for this criteria.\n     */\n    passed: number;\n\n    /**\n     * A description of the testing criteria.\n     */\n    testing_criteria: string;\n  }\n\n  /**\n   * Counters summarizing the outcomes of the evaluation run.\n   */\n  export interface ResultCounts {\n    /**\n     * Number of output items that resulted in an error.\n     */\n    errored: number;\n\n    /**\n     * Number of output items that failed to pass the evaluation.\n     */\n    failed: number;\n\n    /**\n     * Number of output items that passed the evaluation.\n     */\n    passed: number;\n\n    /**\n     * Total number of executed output items.\n     */\n    total: number;\n  }\n}\n\n/**\n * A schema representing an evaluation run.\n */\nexport interface RunRetrieveResponse {\n  /**\n   * Unique identifier for the evaluation run.\n   */\n  id: string;\n\n  /**\n   * Unix timestamp (in seconds) when the evaluation run was created.\n   */\n  created_at: number;\n\n  /**\n   * Information about the run's data source.\n   */\n  data_source:\n    | CreateEvalJSONLRunDataSource\n    | CreateEvalCompletionsRunDataSource\n    | RunRetrieveResponse.Responses;\n\n  /**\n   * An object representing an error response from the Eval API.\n   */\n  error: EvalAPIError;\n\n  /**\n   * The identifier of the associated evaluation.\n   */\n  eval_id: string;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * The model that is evaluated, if applicable.\n   */\n  model: string;\n\n  /**\n   * The name of the evaluation run.\n   */\n  name: string;\n\n  /**\n   * The type of the object. Always \"eval.run\".\n   */\n  object: 'eval.run';\n\n  /**\n   * Usage statistics for each model during the evaluation run.\n   */\n  per_model_usage: Array<RunRetrieveResponse.PerModelUsage>;\n\n  /**\n   * Results per testing criteria applied during the evaluation run.\n   */\n  per_testing_criteria_results: Array<RunRetrieveResponse.PerTestingCriteriaResult>;\n\n  /**\n   * The URL to the rendered evaluation run report on the UI dashboard.\n   */\n  report_url: string;\n\n  /**\n   * Counters summarizing the outcomes of the evaluation run.\n   */\n  result_counts: RunRetrieveResponse.ResultCounts;\n\n  /**\n   * The status of the evaluation run.\n   */\n  status: string;\n}\n\nexport namespace RunRetrieveResponse {\n  /**\n   * A ResponsesRunDataSource object describing a model sampling configuration.\n   */\n  export interface Responses {\n    /**\n     * Determines what populates the `item` namespace in this run's data source.\n     */\n    source: Responses.FileContent | Responses.FileID | Responses.Responses;\n\n    /**\n     * The type of run data source. Always `responses`.\n     */\n    type: 'responses';\n\n    /**\n     * Used when sampling from a model. Dictates the structure of the messages passed\n     * into the model. Can either be a reference to a prebuilt trajectory (ie,\n     * `item.input_trajectory`), or a template with variable references to the `item`\n     * namespace.\n     */\n    input_messages?: Responses.Template | Responses.ItemReference;\n\n    /**\n     * The name of the model to use for generating completions (e.g. \"o3-mini\").\n     */\n    model?: string;\n\n    sampling_params?: Responses.SamplingParams;\n  }\n\n  export namespace Responses {\n    export interface FileContent {\n      /**\n       * The content of the jsonl file.\n       */\n      content: Array<FileContent.Content>;\n\n      /**\n       * The type of jsonl source. Always `file_content`.\n       */\n      type: 'file_content';\n    }\n\n    export namespace FileContent {\n      export interface Content {\n        item: { [key: string]: unknown };\n\n        sample?: { [key: string]: unknown };\n      }\n    }\n\n    export interface FileID {\n      /**\n       * The identifier of the file.\n       */\n      id: string;\n\n      /**\n       * The type of jsonl source. Always `file_id`.\n       */\n      type: 'file_id';\n    }\n\n    /**\n     * A EvalResponsesSource object describing a run data source configuration.\n     */\n    export interface Responses {\n      /**\n       * The type of run data source. Always `responses`.\n       */\n      type: 'responses';\n\n      /**\n       * Only include items created after this timestamp (inclusive). This is a query\n       * parameter used to select responses.\n       */\n      created_after?: number | null;\n\n      /**\n       * Only include items created before this timestamp (inclusive). This is a query\n       * parameter used to select responses.\n       */\n      created_before?: number | null;\n\n      /**\n       * Optional string to search the 'instructions' field. This is a query parameter\n       * used to select responses.\n       */\n      instructions_search?: string | null;\n\n      /**\n       * Metadata filter for the responses. This is a query parameter used to select\n       * responses.\n       */\n      metadata?: unknown | null;\n\n      /**\n       * The name of the model to find responses for. This is a query parameter used to\n       * select responses.\n       */\n      model?: string | null;\n\n      /**\n       * Constrains effort on reasoning for\n       * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n       * supported values are `minimal`, `low`, `medium`, and `high`. Reducing reasoning\n       * effort can result in faster responses and fewer tokens used on reasoning in a\n       * response.\n       *\n       * Note: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning\n       * effort.\n       */\n      reasoning_effort?: Shared.ReasoningEffort | null;\n\n      /**\n       * Sampling temperature. This is a query parameter used to select responses.\n       */\n      temperature?: number | null;\n\n      /**\n       * List of tool names. This is a query parameter used to select responses.\n       */\n      tools?: Array<string> | null;\n\n      /**\n       * Nucleus sampling parameter. This is a query parameter used to select responses.\n       */\n      top_p?: number | null;\n\n      /**\n       * List of user identifiers. This is a query parameter used to select responses.\n       */\n      users?: Array<string> | null;\n    }\n\n    export interface Template {\n      /**\n       * A list of chat messages forming the prompt or context. May include variable\n       * references to the `item` namespace, ie {{item.name}}.\n       */\n      template: Array<Template.ChatMessage | Template.EvalItem>;\n\n      /**\n       * The type of input messages. Always `template`.\n       */\n      type: 'template';\n    }\n\n    export namespace Template {\n      export interface ChatMessage {\n        /**\n         * The content of the message.\n         */\n        content: string;\n\n        /**\n         * The role of the message (e.g. \"system\", \"assistant\", \"user\").\n         */\n        role: string;\n      }\n\n      /**\n       * A message input to the model with a role indicating instruction following\n       * hierarchy. Instructions given with the `developer` or `system` role take\n       * precedence over instructions given with the `user` role. Messages with the\n       * `assistant` role are presumed to have been generated by the model in previous\n       * interactions.\n       */\n      export interface EvalItem {\n        /**\n         * Inputs to the model - can contain template strings.\n         */\n        content:\n          | string\n          | ResponsesAPI.ResponseInputText\n          | EvalItem.OutputText\n          | EvalItem.InputImage\n          | ResponsesAPI.ResponseInputAudio\n          | Array<unknown>;\n\n        /**\n         * The role of the message input. One of `user`, `assistant`, `system`, or\n         * `developer`.\n         */\n        role: 'user' | 'assistant' | 'system' | 'developer';\n\n        /**\n         * The type of the message input. Always `message`.\n         */\n        type?: 'message';\n      }\n\n      export namespace EvalItem {\n        /**\n         * A text output from the model.\n         */\n        export interface OutputText {\n          /**\n           * The text output from the model.\n           */\n          text: string;\n\n          /**\n           * The type of the output text. Always `output_text`.\n           */\n          type: 'output_text';\n        }\n\n        /**\n         * An image input to the model.\n         */\n        export interface InputImage {\n          /**\n           * The URL of the image input.\n           */\n          image_url: string;\n\n          /**\n           * The type of the image input. Always `input_image`.\n           */\n          type: 'input_image';\n\n          /**\n           * The detail level of the image to be sent to the model. One of `high`, `low`, or\n           * `auto`. Defaults to `auto`.\n           */\n          detail?: string;\n        }\n      }\n    }\n\n    export interface ItemReference {\n      /**\n       * A reference to a variable in the `item` namespace. Ie, \"item.name\"\n       */\n      item_reference: string;\n\n      /**\n       * The type of input messages. Always `item_reference`.\n       */\n      type: 'item_reference';\n    }\n\n    export interface SamplingParams {\n      /**\n       * The maximum number of tokens in the generated output.\n       */\n      max_completion_tokens?: number;\n\n      /**\n       * Constrains effort on reasoning for\n       * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n       * supported values are `minimal`, `low`, `medium`, and `high`. Reducing reasoning\n       * effort can result in faster responses and fewer tokens used on reasoning in a\n       * response.\n       *\n       * Note: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning\n       * effort.\n       */\n      reasoning_effort?: Shared.ReasoningEffort | null;\n\n      /**\n       * A seed value to initialize the randomness, during sampling.\n       */\n      seed?: number;\n\n      /**\n       * A higher temperature increases randomness in the outputs.\n       */\n      temperature?: number;\n\n      /**\n       * Configuration options for a text response from the model. Can be plain text or\n       * structured JSON data. Learn more:\n       *\n       * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n       * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n       */\n      text?: SamplingParams.Text;\n\n      /**\n       * An array of tools the model may call while generating a response. You can\n       * specify which tool to use by setting the `tool_choice` parameter.\n       *\n       * The two categories of tools you can provide the model are:\n       *\n       * - **Built-in tools**: Tools that are provided by OpenAI that extend the model's\n       *   capabilities, like\n       *   [web search](https://platform.openai.com/docs/guides/tools-web-search) or\n       *   [file search](https://platform.openai.com/docs/guides/tools-file-search).\n       *   Learn more about\n       *   [built-in tools](https://platform.openai.com/docs/guides/tools).\n       * - **Function calls (custom tools)**: Functions that are defined by you, enabling\n       *   the model to call your own code. Learn more about\n       *   [function calling](https://platform.openai.com/docs/guides/function-calling).\n       */\n      tools?: Array<ResponsesAPI.Tool>;\n\n      /**\n       * An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n       */\n      top_p?: number;\n    }\n\n    export namespace SamplingParams {\n      /**\n       * Configuration options for a text response from the model. Can be plain text or\n       * structured JSON data. Learn more:\n       *\n       * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n       * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n       */\n      export interface Text {\n        /**\n         * An object specifying the format that the model must output.\n         *\n         * Configuring `{ \"type\": \"json_schema\" }` enables Structured Outputs, which\n         * ensures the model will match your supplied JSON schema. Learn more in the\n         * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n         *\n         * The default format is `{ \"type\": \"text\" }` with no additional options.\n         *\n         * **Not recommended for gpt-4o and newer models:**\n         *\n         * Setting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\n         * ensures the message the model generates is valid JSON. Using `json_schema` is\n         * preferred for models that support it.\n         */\n        format?: ResponsesAPI.ResponseFormatTextConfig;\n      }\n    }\n  }\n\n  export interface PerModelUsage {\n    /**\n     * The number of tokens retrieved from cache.\n     */\n    cached_tokens: number;\n\n    /**\n     * The number of completion tokens generated.\n     */\n    completion_tokens: number;\n\n    /**\n     * The number of invocations.\n     */\n    invocation_count: number;\n\n    /**\n     * The name of the model.\n     */\n    model_name: string;\n\n    /**\n     * The number of prompt tokens used.\n     */\n    prompt_tokens: number;\n\n    /**\n     * The total number of tokens used.\n     */\n    total_tokens: number;\n  }\n\n  export interface PerTestingCriteriaResult {\n    /**\n     * Number of tests failed for this criteria.\n     */\n    failed: number;\n\n    /**\n     * Number of tests passed for this criteria.\n     */\n    passed: number;\n\n    /**\n     * A description of the testing criteria.\n     */\n    testing_criteria: string;\n  }\n\n  /**\n   * Counters summarizing the outcomes of the evaluation run.\n   */\n  export interface ResultCounts {\n    /**\n     * Number of output items that resulted in an error.\n     */\n    errored: number;\n\n    /**\n     * Number of output items that failed to pass the evaluation.\n     */\n    failed: number;\n\n    /**\n     * Number of output items that passed the evaluation.\n     */\n    passed: number;\n\n    /**\n     * Total number of executed output items.\n     */\n    total: number;\n  }\n}\n\n/**\n * A schema representing an evaluation run.\n */\nexport interface RunListResponse {\n  /**\n   * Unique identifier for the evaluation run.\n   */\n  id: string;\n\n  /**\n   * Unix timestamp (in seconds) when the evaluation run was created.\n   */\n  created_at: number;\n\n  /**\n   * Information about the run's data source.\n   */\n  data_source: CreateEvalJSONLRunDataSource | CreateEvalCompletionsRunDataSource | RunListResponse.Responses;\n\n  /**\n   * An object representing an error response from the Eval API.\n   */\n  error: EvalAPIError;\n\n  /**\n   * The identifier of the associated evaluation.\n   */\n  eval_id: string;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * The model that is evaluated, if applicable.\n   */\n  model: string;\n\n  /**\n   * The name of the evaluation run.\n   */\n  name: string;\n\n  /**\n   * The type of the object. Always \"eval.run\".\n   */\n  object: 'eval.run';\n\n  /**\n   * Usage statistics for each model during the evaluation run.\n   */\n  per_model_usage: Array<RunListResponse.PerModelUsage>;\n\n  /**\n   * Results per testing criteria applied during the evaluation run.\n   */\n  per_testing_criteria_results: Array<RunListResponse.PerTestingCriteriaResult>;\n\n  /**\n   * The URL to the rendered evaluation run report on the UI dashboard.\n   */\n  report_url: string;\n\n  /**\n   * Counters summarizing the outcomes of the evaluation run.\n   */\n  result_counts: RunListResponse.ResultCounts;\n\n  /**\n   * The status of the evaluation run.\n   */\n  status: string;\n}\n\nexport namespace RunListResponse {\n  /**\n   * A ResponsesRunDataSource object describing a model sampling configuration.\n   */\n  export interface Responses {\n    /**\n     * Determines what populates the `item` namespace in this run's data source.\n     */\n    source: Responses.FileContent | Responses.FileID | Responses.Responses;\n\n    /**\n     * The type of run data source. Always `responses`.\n     */\n    type: 'responses';\n\n    /**\n     * Used when sampling from a model. Dictates the structure of the messages passed\n     * into the model. Can either be a reference to a prebuilt trajectory (ie,\n     * `item.input_trajectory`), or a template with variable references to the `item`\n     * namespace.\n     */\n    input_messages?: Responses.Template | Responses.ItemReference;\n\n    /**\n     * The name of the model to use for generating completions (e.g. \"o3-mini\").\n     */\n    model?: string;\n\n    sampling_params?: Responses.SamplingParams;\n  }\n\n  export namespace Responses {\n    export interface FileContent {\n      /**\n       * The content of the jsonl file.\n       */\n      content: Array<FileContent.Content>;\n\n      /**\n       * The type of jsonl source. Always `file_content`.\n       */\n      type: 'file_content';\n    }\n\n    export namespace FileContent {\n      export interface Content {\n        item: { [key: string]: unknown };\n\n        sample?: { [key: string]: unknown };\n      }\n    }\n\n    export interface FileID {\n      /**\n       * The identifier of the file.\n       */\n      id: string;\n\n      /**\n       * The type of jsonl source. Always `file_id`.\n       */\n      type: 'file_id';\n    }\n\n    /**\n     * A EvalResponsesSource object describing a run data source configuration.\n     */\n    export interface Responses {\n      /**\n       * The type of run data source. Always `responses`.\n       */\n      type: 'responses';\n\n      /**\n       * Only include items created after this timestamp (inclusive). This is a query\n       * parameter used to select responses.\n       */\n      created_after?: number | null;\n\n      /**\n       * Only include items created before this timestamp (inclusive). This is a query\n       * parameter used to select responses.\n       */\n      created_before?: number | null;\n\n      /**\n       * Optional string to search the 'instructions' field. This is a query parameter\n       * used to select responses.\n       */\n      instructions_search?: string | null;\n\n      /**\n       * Metadata filter for the responses. This is a query parameter used to select\n       * responses.\n       */\n      metadata?: unknown | null;\n\n      /**\n       * The name of the model to find responses for. This is a query parameter used to\n       * select responses.\n       */\n      model?: string | null;\n\n      /**\n       * Constrains effort on reasoning for\n       * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n       * supported values are `minimal`, `low`, `medium`, and `high`. Reducing reasoning\n       * effort can result in faster responses and fewer tokens used on reasoning in a\n       * response.\n       *\n       * Note: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning\n       * effort.\n       */\n      reasoning_effort?: Shared.ReasoningEffort | null;\n\n      /**\n       * Sampling temperature. This is a query parameter used to select responses.\n       */\n      temperature?: number | null;\n\n      /**\n       * List of tool names. This is a query parameter used to select responses.\n       */\n      tools?: Array<string> | null;\n\n      /**\n       * Nucleus sampling parameter. This is a query parameter used to select responses.\n       */\n      top_p?: number | null;\n\n      /**\n       * List of user identifiers. This is a query parameter used to select responses.\n       */\n      users?: Array<string> | null;\n    }\n\n    export interface Template {\n      /**\n       * A list of chat messages forming the prompt or context. May include variable\n       * references to the `item` namespace, ie {{item.name}}.\n       */\n      template: Array<Template.ChatMessage | Template.EvalItem>;\n\n      /**\n       * The type of input messages. Always `template`.\n       */\n      type: 'template';\n    }\n\n    export namespace Template {\n      export interface ChatMessage {\n        /**\n         * The content of the message.\n         */\n        content: string;\n\n        /**\n         * The role of the message (e.g. \"system\", \"assistant\", \"user\").\n         */\n        role: string;\n      }\n\n      /**\n       * A message input to the model with a role indicating instruction following\n       * hierarchy. Instructions given with the `developer` or `system` role take\n       * precedence over instructions given with the `user` role. Messages with the\n       * `assistant` role are presumed to have been generated by the model in previous\n       * interactions.\n       */\n      export interface EvalItem {\n        /**\n         * Inputs to the model - can contain template strings.\n         */\n        content:\n          | string\n          | ResponsesAPI.ResponseInputText\n          | EvalItem.OutputText\n          | EvalItem.InputImage\n          | ResponsesAPI.ResponseInputAudio\n          | Array<unknown>;\n\n        /**\n         * The role of the message input. One of `user`, `assistant`, `system`, or\n         * `developer`.\n         */\n        role: 'user' | 'assistant' | 'system' | 'developer';\n\n        /**\n         * The type of the message input. Always `message`.\n         */\n        type?: 'message';\n      }\n\n      export namespace EvalItem {\n        /**\n         * A text output from the model.\n         */\n        export interface OutputText {\n          /**\n           * The text output from the model.\n           */\n          text: string;\n\n          /**\n           * The type of the output text. Always `output_text`.\n           */\n          type: 'output_text';\n        }\n\n        /**\n         * An image input to the model.\n         */\n        export interface InputImage {\n          /**\n           * The URL of the image input.\n           */\n          image_url: string;\n\n          /**\n           * The type of the image input. Always `input_image`.\n           */\n          type: 'input_image';\n\n          /**\n           * The detail level of the image to be sent to the model. One of `high`, `low`, or\n           * `auto`. Defaults to `auto`.\n           */\n          detail?: string;\n        }\n      }\n    }\n\n    export interface ItemReference {\n      /**\n       * A reference to a variable in the `item` namespace. Ie, \"item.name\"\n       */\n      item_reference: string;\n\n      /**\n       * The type of input messages. Always `item_reference`.\n       */\n      type: 'item_reference';\n    }\n\n    export interface SamplingParams {\n      /**\n       * The maximum number of tokens in the generated output.\n       */\n      max_completion_tokens?: number;\n\n      /**\n       * Constrains effort on reasoning for\n       * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n       * supported values are `minimal`, `low`, `medium`, and `high`. Reducing reasoning\n       * effort can result in faster responses and fewer tokens used on reasoning in a\n       * response.\n       *\n       * Note: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning\n       * effort.\n       */\n      reasoning_effort?: Shared.ReasoningEffort | null;\n\n      /**\n       * A seed value to initialize the randomness, during sampling.\n       */\n      seed?: number;\n\n      /**\n       * A higher temperature increases randomness in the outputs.\n       */\n      temperature?: number;\n\n      /**\n       * Configuration options for a text response from the model. Can be plain text or\n       * structured JSON data. Learn more:\n       *\n       * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n       * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n       */\n      text?: SamplingParams.Text;\n\n      /**\n       * An array of tools the model may call while generating a response. You can\n       * specify which tool to use by setting the `tool_choice` parameter.\n       *\n       * The two categories of tools you can provide the model are:\n       *\n       * - **Built-in tools**: Tools that are provided by OpenAI that extend the model's\n       *   capabilities, like\n       *   [web search](https://platform.openai.com/docs/guides/tools-web-search) or\n       *   [file search](https://platform.openai.com/docs/guides/tools-file-search).\n       *   Learn more about\n       *   [built-in tools](https://platform.openai.com/docs/guides/tools).\n       * - **Function calls (custom tools)**: Functions that are defined by you, enabling\n       *   the model to call your own code. Learn more about\n       *   [function calling](https://platform.openai.com/docs/guides/function-calling).\n       */\n      tools?: Array<ResponsesAPI.Tool>;\n\n      /**\n       * An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n       */\n      top_p?: number;\n    }\n\n    export namespace SamplingParams {\n      /**\n       * Configuration options for a text response from the model. Can be plain text or\n       * structured JSON data. Learn more:\n       *\n       * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n       * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n       */\n      export interface Text {\n        /**\n         * An object specifying the format that the model must output.\n         *\n         * Configuring `{ \"type\": \"json_schema\" }` enables Structured Outputs, which\n         * ensures the model will match your supplied JSON schema. Learn more in the\n         * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n         *\n         * The default format is `{ \"type\": \"text\" }` with no additional options.\n         *\n         * **Not recommended for gpt-4o and newer models:**\n         *\n         * Setting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\n         * ensures the message the model generates is valid JSON. Using `json_schema` is\n         * preferred for models that support it.\n         */\n        format?: ResponsesAPI.ResponseFormatTextConfig;\n      }\n    }\n  }\n\n  export interface PerModelUsage {\n    /**\n     * The number of tokens retrieved from cache.\n     */\n    cached_tokens: number;\n\n    /**\n     * The number of completion tokens generated.\n     */\n    completion_tokens: number;\n\n    /**\n     * The number of invocations.\n     */\n    invocation_count: number;\n\n    /**\n     * The name of the model.\n     */\n    model_name: string;\n\n    /**\n     * The number of prompt tokens used.\n     */\n    prompt_tokens: number;\n\n    /**\n     * The total number of tokens used.\n     */\n    total_tokens: number;\n  }\n\n  export interface PerTestingCriteriaResult {\n    /**\n     * Number of tests failed for this criteria.\n     */\n    failed: number;\n\n    /**\n     * Number of tests passed for this criteria.\n     */\n    passed: number;\n\n    /**\n     * A description of the testing criteria.\n     */\n    testing_criteria: string;\n  }\n\n  /**\n   * Counters summarizing the outcomes of the evaluation run.\n   */\n  export interface ResultCounts {\n    /**\n     * Number of output items that resulted in an error.\n     */\n    errored: number;\n\n    /**\n     * Number of output items that failed to pass the evaluation.\n     */\n    failed: number;\n\n    /**\n     * Number of output items that passed the evaluation.\n     */\n    passed: number;\n\n    /**\n     * Total number of executed output items.\n     */\n    total: number;\n  }\n}\n\nexport interface RunDeleteResponse {\n  deleted?: boolean;\n\n  object?: string;\n\n  run_id?: string;\n}\n\n/**\n * A schema representing an evaluation run.\n */\nexport interface RunCancelResponse {\n  /**\n   * Unique identifier for the evaluation run.\n   */\n  id: string;\n\n  /**\n   * Unix timestamp (in seconds) when the evaluation run was created.\n   */\n  created_at: number;\n\n  /**\n   * Information about the run's data source.\n   */\n  data_source:\n    | CreateEvalJSONLRunDataSource\n    | CreateEvalCompletionsRunDataSource\n    | RunCancelResponse.Responses;\n\n  /**\n   * An object representing an error response from the Eval API.\n   */\n  error: EvalAPIError;\n\n  /**\n   * The identifier of the associated evaluation.\n   */\n  eval_id: string;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * The model that is evaluated, if applicable.\n   */\n  model: string;\n\n  /**\n   * The name of the evaluation run.\n   */\n  name: string;\n\n  /**\n   * The type of the object. Always \"eval.run\".\n   */\n  object: 'eval.run';\n\n  /**\n   * Usage statistics for each model during the evaluation run.\n   */\n  per_model_usage: Array<RunCancelResponse.PerModelUsage>;\n\n  /**\n   * Results per testing criteria applied during the evaluation run.\n   */\n  per_testing_criteria_results: Array<RunCancelResponse.PerTestingCriteriaResult>;\n\n  /**\n   * The URL to the rendered evaluation run report on the UI dashboard.\n   */\n  report_url: string;\n\n  /**\n   * Counters summarizing the outcomes of the evaluation run.\n   */\n  result_counts: RunCancelResponse.ResultCounts;\n\n  /**\n   * The status of the evaluation run.\n   */\n  status: string;\n}\n\nexport namespace RunCancelResponse {\n  /**\n   * A ResponsesRunDataSource object describing a model sampling configuration.\n   */\n  export interface Responses {\n    /**\n     * Determines what populates the `item` namespace in this run's data source.\n     */\n    source: Responses.FileContent | Responses.FileID | Responses.Responses;\n\n    /**\n     * The type of run data source. Always `responses`.\n     */\n    type: 'responses';\n\n    /**\n     * Used when sampling from a model. Dictates the structure of the messages passed\n     * into the model. Can either be a reference to a prebuilt trajectory (ie,\n     * `item.input_trajectory`), or a template with variable references to the `item`\n     * namespace.\n     */\n    input_messages?: Responses.Template | Responses.ItemReference;\n\n    /**\n     * The name of the model to use for generating completions (e.g. \"o3-mini\").\n     */\n    model?: string;\n\n    sampling_params?: Responses.SamplingParams;\n  }\n\n  export namespace Responses {\n    export interface FileContent {\n      /**\n       * The content of the jsonl file.\n       */\n      content: Array<FileContent.Content>;\n\n      /**\n       * The type of jsonl source. Always `file_content`.\n       */\n      type: 'file_content';\n    }\n\n    export namespace FileContent {\n      export interface Content {\n        item: { [key: string]: unknown };\n\n        sample?: { [key: string]: unknown };\n      }\n    }\n\n    export interface FileID {\n      /**\n       * The identifier of the file.\n       */\n      id: string;\n\n      /**\n       * The type of jsonl source. Always `file_id`.\n       */\n      type: 'file_id';\n    }\n\n    /**\n     * A EvalResponsesSource object describing a run data source configuration.\n     */\n    export interface Responses {\n      /**\n       * The type of run data source. Always `responses`.\n       */\n      type: 'responses';\n\n      /**\n       * Only include items created after this timestamp (inclusive). This is a query\n       * parameter used to select responses.\n       */\n      created_after?: number | null;\n\n      /**\n       * Only include items created before this timestamp (inclusive). This is a query\n       * parameter used to select responses.\n       */\n      created_before?: number | null;\n\n      /**\n       * Optional string to search the 'instructions' field. This is a query parameter\n       * used to select responses.\n       */\n      instructions_search?: string | null;\n\n      /**\n       * Metadata filter for the responses. This is a query parameter used to select\n       * responses.\n       */\n      metadata?: unknown | null;\n\n      /**\n       * The name of the model to find responses for. This is a query parameter used to\n       * select responses.\n       */\n      model?: string | null;\n\n      /**\n       * Constrains effort on reasoning for\n       * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n       * supported values are `minimal`, `low`, `medium`, and `high`. Reducing reasoning\n       * effort can result in faster responses and fewer tokens used on reasoning in a\n       * response.\n       *\n       * Note: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning\n       * effort.\n       */\n      reasoning_effort?: Shared.ReasoningEffort | null;\n\n      /**\n       * Sampling temperature. This is a query parameter used to select responses.\n       */\n      temperature?: number | null;\n\n      /**\n       * List of tool names. This is a query parameter used to select responses.\n       */\n      tools?: Array<string> | null;\n\n      /**\n       * Nucleus sampling parameter. This is a query parameter used to select responses.\n       */\n      top_p?: number | null;\n\n      /**\n       * List of user identifiers. This is a query parameter used to select responses.\n       */\n      users?: Array<string> | null;\n    }\n\n    export interface Template {\n      /**\n       * A list of chat messages forming the prompt or context. May include variable\n       * references to the `item` namespace, ie {{item.name}}.\n       */\n      template: Array<Template.ChatMessage | Template.EvalItem>;\n\n      /**\n       * The type of input messages. Always `template`.\n       */\n      type: 'template';\n    }\n\n    export namespace Template {\n      export interface ChatMessage {\n        /**\n         * The content of the message.\n         */\n        content: string;\n\n        /**\n         * The role of the message (e.g. \"system\", \"assistant\", \"user\").\n         */\n        role: string;\n      }\n\n      /**\n       * A message input to the model with a role indicating instruction following\n       * hierarchy. Instructions given with the `developer` or `system` role take\n       * precedence over instructions given with the `user` role. Messages with the\n       * `assistant` role are presumed to have been generated by the model in previous\n       * interactions.\n       */\n      export interface EvalItem {\n        /**\n         * Inputs to the model - can contain template strings.\n         */\n        content:\n          | string\n          | ResponsesAPI.ResponseInputText\n          | EvalItem.OutputText\n          | EvalItem.InputImage\n          | ResponsesAPI.ResponseInputAudio\n          | Array<unknown>;\n\n        /**\n         * The role of the message input. One of `user`, `assistant`, `system`, or\n         * `developer`.\n         */\n        role: 'user' | 'assistant' | 'system' | 'developer';\n\n        /**\n         * The type of the message input. Always `message`.\n         */\n        type?: 'message';\n      }\n\n      export namespace EvalItem {\n        /**\n         * A text output from the model.\n         */\n        export interface OutputText {\n          /**\n           * The text output from the model.\n           */\n          text: string;\n\n          /**\n           * The type of the output text. Always `output_text`.\n           */\n          type: 'output_text';\n        }\n\n        /**\n         * An image input to the model.\n         */\n        export interface InputImage {\n          /**\n           * The URL of the image input.\n           */\n          image_url: string;\n\n          /**\n           * The type of the image input. Always `input_image`.\n           */\n          type: 'input_image';\n\n          /**\n           * The detail level of the image to be sent to the model. One of `high`, `low`, or\n           * `auto`. Defaults to `auto`.\n           */\n          detail?: string;\n        }\n      }\n    }\n\n    export interface ItemReference {\n      /**\n       * A reference to a variable in the `item` namespace. Ie, \"item.name\"\n       */\n      item_reference: string;\n\n      /**\n       * The type of input messages. Always `item_reference`.\n       */\n      type: 'item_reference';\n    }\n\n    export interface SamplingParams {\n      /**\n       * The maximum number of tokens in the generated output.\n       */\n      max_completion_tokens?: number;\n\n      /**\n       * Constrains effort on reasoning for\n       * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n       * supported values are `minimal`, `low`, `medium`, and `high`. Reducing reasoning\n       * effort can result in faster responses and fewer tokens used on reasoning in a\n       * response.\n       *\n       * Note: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning\n       * effort.\n       */\n      reasoning_effort?: Shared.ReasoningEffort | null;\n\n      /**\n       * A seed value to initialize the randomness, during sampling.\n       */\n      seed?: number;\n\n      /**\n       * A higher temperature increases randomness in the outputs.\n       */\n      temperature?: number;\n\n      /**\n       * Configuration options for a text response from the model. Can be plain text or\n       * structured JSON data. Learn more:\n       *\n       * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n       * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n       */\n      text?: SamplingParams.Text;\n\n      /**\n       * An array of tools the model may call while generating a response. You can\n       * specify which tool to use by setting the `tool_choice` parameter.\n       *\n       * The two categories of tools you can provide the model are:\n       *\n       * - **Built-in tools**: Tools that are provided by OpenAI that extend the model's\n       *   capabilities, like\n       *   [web search](https://platform.openai.com/docs/guides/tools-web-search) or\n       *   [file search](https://platform.openai.com/docs/guides/tools-file-search).\n       *   Learn more about\n       *   [built-in tools](https://platform.openai.com/docs/guides/tools).\n       * - **Function calls (custom tools)**: Functions that are defined by you, enabling\n       *   the model to call your own code. Learn more about\n       *   [function calling](https://platform.openai.com/docs/guides/function-calling).\n       */\n      tools?: Array<ResponsesAPI.Tool>;\n\n      /**\n       * An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n       */\n      top_p?: number;\n    }\n\n    export namespace SamplingParams {\n      /**\n       * Configuration options for a text response from the model. Can be plain text or\n       * structured JSON data. Learn more:\n       *\n       * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n       * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n       */\n      export interface Text {\n        /**\n         * An object specifying the format that the model must output.\n         *\n         * Configuring `{ \"type\": \"json_schema\" }` enables Structured Outputs, which\n         * ensures the model will match your supplied JSON schema. Learn more in the\n         * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n         *\n         * The default format is `{ \"type\": \"text\" }` with no additional options.\n         *\n         * **Not recommended for gpt-4o and newer models:**\n         *\n         * Setting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\n         * ensures the message the model generates is valid JSON. Using `json_schema` is\n         * preferred for models that support it.\n         */\n        format?: ResponsesAPI.ResponseFormatTextConfig;\n      }\n    }\n  }\n\n  export interface PerModelUsage {\n    /**\n     * The number of tokens retrieved from cache.\n     */\n    cached_tokens: number;\n\n    /**\n     * The number of completion tokens generated.\n     */\n    completion_tokens: number;\n\n    /**\n     * The number of invocations.\n     */\n    invocation_count: number;\n\n    /**\n     * The name of the model.\n     */\n    model_name: string;\n\n    /**\n     * The number of prompt tokens used.\n     */\n    prompt_tokens: number;\n\n    /**\n     * The total number of tokens used.\n     */\n    total_tokens: number;\n  }\n\n  export interface PerTestingCriteriaResult {\n    /**\n     * Number of tests failed for this criteria.\n     */\n    failed: number;\n\n    /**\n     * Number of tests passed for this criteria.\n     */\n    passed: number;\n\n    /**\n     * A description of the testing criteria.\n     */\n    testing_criteria: string;\n  }\n\n  /**\n   * Counters summarizing the outcomes of the evaluation run.\n   */\n  export interface ResultCounts {\n    /**\n     * Number of output items that resulted in an error.\n     */\n    errored: number;\n\n    /**\n     * Number of output items that failed to pass the evaluation.\n     */\n    failed: number;\n\n    /**\n     * Number of output items that passed the evaluation.\n     */\n    passed: number;\n\n    /**\n     * Total number of executed output items.\n     */\n    total: number;\n  }\n}\n\nexport interface RunCreateParams {\n  /**\n   * Details about the run's data source.\n   */\n  data_source:\n    | CreateEvalJSONLRunDataSource\n    | CreateEvalCompletionsRunDataSource\n    | RunCreateParams.CreateEvalResponsesRunDataSource;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The name of the run.\n   */\n  name?: string;\n}\n\nexport namespace RunCreateParams {\n  /**\n   * A ResponsesRunDataSource object describing a model sampling configuration.\n   */\n  export interface CreateEvalResponsesRunDataSource {\n    /**\n     * Determines what populates the `item` namespace in this run's data source.\n     */\n    source:\n      | CreateEvalResponsesRunDataSource.FileContent\n      | CreateEvalResponsesRunDataSource.FileID\n      | CreateEvalResponsesRunDataSource.Responses;\n\n    /**\n     * The type of run data source. Always `responses`.\n     */\n    type: 'responses';\n\n    /**\n     * Used when sampling from a model. Dictates the structure of the messages passed\n     * into the model. Can either be a reference to a prebuilt trajectory (ie,\n     * `item.input_trajectory`), or a template with variable references to the `item`\n     * namespace.\n     */\n    input_messages?:\n      | CreateEvalResponsesRunDataSource.Template\n      | CreateEvalResponsesRunDataSource.ItemReference;\n\n    /**\n     * The name of the model to use for generating completions (e.g. \"o3-mini\").\n     */\n    model?: string;\n\n    sampling_params?: CreateEvalResponsesRunDataSource.SamplingParams;\n  }\n\n  export namespace CreateEvalResponsesRunDataSource {\n    export interface FileContent {\n      /**\n       * The content of the jsonl file.\n       */\n      content: Array<FileContent.Content>;\n\n      /**\n       * The type of jsonl source. Always `file_content`.\n       */\n      type: 'file_content';\n    }\n\n    export namespace FileContent {\n      export interface Content {\n        item: { [key: string]: unknown };\n\n        sample?: { [key: string]: unknown };\n      }\n    }\n\n    export interface FileID {\n      /**\n       * The identifier of the file.\n       */\n      id: string;\n\n      /**\n       * The type of jsonl source. Always `file_id`.\n       */\n      type: 'file_id';\n    }\n\n    /**\n     * A EvalResponsesSource object describing a run data source configuration.\n     */\n    export interface Responses {\n      /**\n       * The type of run data source. Always `responses`.\n       */\n      type: 'responses';\n\n      /**\n       * Only include items created after this timestamp (inclusive). This is a query\n       * parameter used to select responses.\n       */\n      created_after?: number | null;\n\n      /**\n       * Only include items created before this timestamp (inclusive). This is a query\n       * parameter used to select responses.\n       */\n      created_before?: number | null;\n\n      /**\n       * Optional string to search the 'instructions' field. This is a query parameter\n       * used to select responses.\n       */\n      instructions_search?: string | null;\n\n      /**\n       * Metadata filter for the responses. This is a query parameter used to select\n       * responses.\n       */\n      metadata?: unknown | null;\n\n      /**\n       * The name of the model to find responses for. This is a query parameter used to\n       * select responses.\n       */\n      model?: string | null;\n\n      /**\n       * Constrains effort on reasoning for\n       * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n       * supported values are `minimal`, `low`, `medium`, and `high`. Reducing reasoning\n       * effort can result in faster responses and fewer tokens used on reasoning in a\n       * response.\n       *\n       * Note: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning\n       * effort.\n       */\n      reasoning_effort?: Shared.ReasoningEffort | null;\n\n      /**\n       * Sampling temperature. This is a query parameter used to select responses.\n       */\n      temperature?: number | null;\n\n      /**\n       * List of tool names. This is a query parameter used to select responses.\n       */\n      tools?: Array<string> | null;\n\n      /**\n       * Nucleus sampling parameter. This is a query parameter used to select responses.\n       */\n      top_p?: number | null;\n\n      /**\n       * List of user identifiers. This is a query parameter used to select responses.\n       */\n      users?: Array<string> | null;\n    }\n\n    export interface Template {\n      /**\n       * A list of chat messages forming the prompt or context. May include variable\n       * references to the `item` namespace, ie {{item.name}}.\n       */\n      template: Array<Template.ChatMessage | Template.EvalItem>;\n\n      /**\n       * The type of input messages. Always `template`.\n       */\n      type: 'template';\n    }\n\n    export namespace Template {\n      export interface ChatMessage {\n        /**\n         * The content of the message.\n         */\n        content: string;\n\n        /**\n         * The role of the message (e.g. \"system\", \"assistant\", \"user\").\n         */\n        role: string;\n      }\n\n      /**\n       * A message input to the model with a role indicating instruction following\n       * hierarchy. Instructions given with the `developer` or `system` role take\n       * precedence over instructions given with the `user` role. Messages with the\n       * `assistant` role are presumed to have been generated by the model in previous\n       * interactions.\n       */\n      export interface EvalItem {\n        /**\n         * Inputs to the model - can contain template strings.\n         */\n        content:\n          | string\n          | ResponsesAPI.ResponseInputText\n          | EvalItem.OutputText\n          | EvalItem.InputImage\n          | ResponsesAPI.ResponseInputAudio\n          | Array<unknown>;\n\n        /**\n         * The role of the message input. One of `user`, `assistant`, `system`, or\n         * `developer`.\n         */\n        role: 'user' | 'assistant' | 'system' | 'developer';\n\n        /**\n         * The type of the message input. Always `message`.\n         */\n        type?: 'message';\n      }\n\n      export namespace EvalItem {\n        /**\n         * A text output from the model.\n         */\n        export interface OutputText {\n          /**\n           * The text output from the model.\n           */\n          text: string;\n\n          /**\n           * The type of the output text. Always `output_text`.\n           */\n          type: 'output_text';\n        }\n\n        /**\n         * An image input to the model.\n         */\n        export interface InputImage {\n          /**\n           * The URL of the image input.\n           */\n          image_url: string;\n\n          /**\n           * The type of the image input. Always `input_image`.\n           */\n          type: 'input_image';\n\n          /**\n           * The detail level of the image to be sent to the model. One of `high`, `low`, or\n           * `auto`. Defaults to `auto`.\n           */\n          detail?: string;\n        }\n      }\n    }\n\n    export interface ItemReference {\n      /**\n       * A reference to a variable in the `item` namespace. Ie, \"item.name\"\n       */\n      item_reference: string;\n\n      /**\n       * The type of input messages. Always `item_reference`.\n       */\n      type: 'item_reference';\n    }\n\n    export interface SamplingParams {\n      /**\n       * The maximum number of tokens in the generated output.\n       */\n      max_completion_tokens?: number;\n\n      /**\n       * Constrains effort on reasoning for\n       * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n       * supported values are `minimal`, `low`, `medium`, and `high`. Reducing reasoning\n       * effort can result in faster responses and fewer tokens used on reasoning in a\n       * response.\n       *\n       * Note: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning\n       * effort.\n       */\n      reasoning_effort?: Shared.ReasoningEffort | null;\n\n      /**\n       * A seed value to initialize the randomness, during sampling.\n       */\n      seed?: number;\n\n      /**\n       * A higher temperature increases randomness in the outputs.\n       */\n      temperature?: number;\n\n      /**\n       * Configuration options for a text response from the model. Can be plain text or\n       * structured JSON data. Learn more:\n       *\n       * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n       * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n       */\n      text?: SamplingParams.Text;\n\n      /**\n       * An array of tools the model may call while generating a response. You can\n       * specify which tool to use by setting the `tool_choice` parameter.\n       *\n       * The two categories of tools you can provide the model are:\n       *\n       * - **Built-in tools**: Tools that are provided by OpenAI that extend the model's\n       *   capabilities, like\n       *   [web search](https://platform.openai.com/docs/guides/tools-web-search) or\n       *   [file search](https://platform.openai.com/docs/guides/tools-file-search).\n       *   Learn more about\n       *   [built-in tools](https://platform.openai.com/docs/guides/tools).\n       * - **Function calls (custom tools)**: Functions that are defined by you, enabling\n       *   the model to call your own code. Learn more about\n       *   [function calling](https://platform.openai.com/docs/guides/function-calling).\n       */\n      tools?: Array<ResponsesAPI.Tool>;\n\n      /**\n       * An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n       */\n      top_p?: number;\n    }\n\n    export namespace SamplingParams {\n      /**\n       * Configuration options for a text response from the model. Can be plain text or\n       * structured JSON data. Learn more:\n       *\n       * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n       * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n       */\n      export interface Text {\n        /**\n         * An object specifying the format that the model must output.\n         *\n         * Configuring `{ \"type\": \"json_schema\" }` enables Structured Outputs, which\n         * ensures the model will match your supplied JSON schema. Learn more in the\n         * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n         *\n         * The default format is `{ \"type\": \"text\" }` with no additional options.\n         *\n         * **Not recommended for gpt-4o and newer models:**\n         *\n         * Setting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\n         * ensures the message the model generates is valid JSON. Using `json_schema` is\n         * preferred for models that support it.\n         */\n        format?: ResponsesAPI.ResponseFormatTextConfig;\n      }\n    }\n  }\n}\n\nexport interface RunRetrieveParams {\n  /**\n   * The ID of the evaluation to retrieve runs for.\n   */\n  eval_id: string;\n}\n\nexport interface RunListParams extends CursorPageParams {\n  /**\n   * Sort order for runs by timestamp. Use `asc` for ascending order or `desc` for\n   * descending order. Defaults to `asc`.\n   */\n  order?: 'asc' | 'desc';\n\n  /**\n   * Filter runs by status. One of `queued` | `in_progress` | `failed` | `completed`\n   * | `canceled`.\n   */\n  status?: 'queued' | 'in_progress' | 'completed' | 'canceled' | 'failed';\n}\n\nexport interface RunDeleteParams {\n  /**\n   * The ID of the evaluation to delete the run from.\n   */\n  eval_id: string;\n}\n\nexport interface RunCancelParams {\n  /**\n   * The ID of the evaluation whose run you want to cancel.\n   */\n  eval_id: string;\n}\n\nRuns.OutputItems = OutputItems;\n\nexport declare namespace Runs {\n  export {\n    type CreateEvalCompletionsRunDataSource as CreateEvalCompletionsRunDataSource,\n    type CreateEvalJSONLRunDataSource as CreateEvalJSONLRunDataSource,\n    type EvalAPIError as EvalAPIError,\n    type RunCreateResponse as RunCreateResponse,\n    type RunRetrieveResponse as RunRetrieveResponse,\n    type RunListResponse as RunListResponse,\n    type RunDeleteResponse as RunDeleteResponse,\n    type RunCancelResponse as RunCancelResponse,\n    type RunListResponsesPage as RunListResponsesPage,\n    type RunCreateParams as RunCreateParams,\n    type RunRetrieveParams as RunRetrieveParams,\n    type RunListParams as RunListParams,\n    type RunDeleteParams as RunDeleteParams,\n    type RunCancelParams as RunCancelParams,\n  };\n\n  export {\n    OutputItems as OutputItems,\n    type OutputItemRetrieveResponse as OutputItemRetrieveResponse,\n    type OutputItemListResponse as OutputItemListResponse,\n    type OutputItemListResponsesPage as OutputItemListResponsesPage,\n    type OutputItemRetrieveParams as OutputItemRetrieveParams,\n    type OutputItemListParams as OutputItemListParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport * as CompletionsCompletionsAPI from './completions';\nimport * as CompletionsAPI from '../../completions';\nimport * as Shared from '../../shared';\nimport * as MessagesAPI from './messages';\nimport { MessageListParams, Messages } from './messages';\nimport { APIPromise } from '../../../core/api-promise';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../../../core/pagination';\nimport { Stream } from '../../../core/streaming';\nimport { RequestOptions } from '../../../internal/request-options';\nimport { path } from '../../../internal/utils/path';\n\nimport { ChatCompletionRunner } from '../../../lib/ChatCompletionRunner';\nimport { ChatCompletionStreamingRunner } from '../../../lib/ChatCompletionStreamingRunner';\nimport { RunnerOptions } from '../../../lib/AbstractChatCompletionRunner';\nimport { ChatCompletionToolRunnerParams } from '../../../lib/ChatCompletionRunner';\nimport { ChatCompletionStreamingToolRunnerParams } from '../../../lib/ChatCompletionStreamingRunner';\nimport { ChatCompletionStream, type ChatCompletionStreamParams } from '../../../lib/ChatCompletionStream';\nimport { ExtractParsedContentFromParams, parseChatCompletion, validateInputTools } from '../../../lib/parser';\n\nexport class Completions extends APIResource {\n  messages: MessagesAPI.Messages = new MessagesAPI.Messages(this._client);\n\n  /**\n   * **Starting a new project?** We recommend trying\n   * [Responses](https://platform.openai.com/docs/api-reference/responses) to take\n   * advantage of the latest OpenAI platform features. Compare\n   * [Chat Completions with Responses](https://platform.openai.com/docs/guides/responses-vs-chat-completions?api-mode=responses).\n   *\n   * ---\n   *\n   * Creates a model response for the given chat conversation. Learn more in the\n   * [text generation](https://platform.openai.com/docs/guides/text-generation),\n   * [vision](https://platform.openai.com/docs/guides/vision), and\n   * [audio](https://platform.openai.com/docs/guides/audio) guides.\n   *\n   * Parameter support can differ depending on the model used to generate the\n   * response, particularly for newer reasoning models. Parameters that are only\n   * supported for reasoning models are noted below. For the current state of\n   * unsupported parameters in reasoning models,\n   * [refer to the reasoning guide](https://platform.openai.com/docs/guides/reasoning).\n   *\n   * @example\n   * ```ts\n   * const chatCompletion = await client.chat.completions.create(\n   *   {\n   *     messages: [{ content: 'string', role: 'developer' }],\n   *     model: 'gpt-4o',\n   *   },\n   * );\n   * ```\n   */\n  create(body: ChatCompletionCreateParamsNonStreaming, options?: RequestOptions): APIPromise<ChatCompletion>;\n  create(\n    body: ChatCompletionCreateParamsStreaming,\n    options?: RequestOptions,\n  ): APIPromise<Stream<ChatCompletionChunk>>;\n  create(\n    body: ChatCompletionCreateParamsBase,\n    options?: RequestOptions,\n  ): APIPromise<Stream<ChatCompletionChunk> | ChatCompletion>;\n  create(\n    body: ChatCompletionCreateParams,\n    options?: RequestOptions,\n  ): APIPromise<ChatCompletion> | APIPromise<Stream<ChatCompletionChunk>> {\n    return this._client.post('/chat/completions', { body, ...options, stream: body.stream ?? false }) as\n      | APIPromise<ChatCompletion>\n      | APIPromise<Stream<ChatCompletionChunk>>;\n  }\n\n  /**\n   * Get a stored chat completion. Only Chat Completions that have been created with\n   * the `store` parameter set to `true` will be returned.\n   *\n   * @example\n   * ```ts\n   * const chatCompletion =\n   *   await client.chat.completions.retrieve('completion_id');\n   * ```\n   */\n  retrieve(completionID: string, options?: RequestOptions): APIPromise<ChatCompletion> {\n    return this._client.get(path`/chat/completions/${completionID}`, options);\n  }\n\n  /**\n   * Modify a stored chat completion. Only Chat Completions that have been created\n   * with the `store` parameter set to `true` can be modified. Currently, the only\n   * supported modification is to update the `metadata` field.\n   *\n   * @example\n   * ```ts\n   * const chatCompletion = await client.chat.completions.update(\n   *   'completion_id',\n   *   { metadata: { foo: 'string' } },\n   * );\n   * ```\n   */\n  update(\n    completionID: string,\n    body: ChatCompletionUpdateParams,\n    options?: RequestOptions,\n  ): APIPromise<ChatCompletion> {\n    return this._client.post(path`/chat/completions/${completionID}`, { body, ...options });\n  }\n\n  /**\n   * List stored Chat Completions. Only Chat Completions that have been stored with\n   * the `store` parameter set to `true` will be returned.\n   *\n   * @example\n   * ```ts\n   * // Automatically fetches more pages as needed.\n   * for await (const chatCompletion of client.chat.completions.list()) {\n   *   // ...\n   * }\n   * ```\n   */\n  list(\n    query: ChatCompletionListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<ChatCompletionsPage, ChatCompletion> {\n    return this._client.getAPIList('/chat/completions', CursorPage<ChatCompletion>, { query, ...options });\n  }\n\n  /**\n   * Delete a stored chat completion. Only Chat Completions that have been created\n   * with the `store` parameter set to `true` can be deleted.\n   *\n   * @example\n   * ```ts\n   * const chatCompletionDeleted =\n   *   await client.chat.completions.delete('completion_id');\n   * ```\n   */\n  delete(completionID: string, options?: RequestOptions): APIPromise<ChatCompletionDeleted> {\n    return this._client.delete(path`/chat/completions/${completionID}`, options);\n  }\n\n  parse<Params extends ChatCompletionParseParams, ParsedT = ExtractParsedContentFromParams<Params>>(\n    body: Params,\n    options?: RequestOptions,\n  ): APIPromise<ParsedChatCompletion<ParsedT>> {\n    validateInputTools(body.tools);\n\n    return this._client.chat.completions\n      .create(body, {\n        ...options,\n        headers: {\n          ...options?.headers,\n          'X-Stainless-Helper-Method': 'chat.completions.parse',\n        },\n      })\n      ._thenUnwrap((completion) => parseChatCompletion(completion, body));\n  }\n\n  /**\n   * A convenience helper for using tool calls with the /chat/completions endpoint\n   * which automatically calls the JavaScript functions you provide and sends their\n   * results back to the /chat/completions endpoint, looping as long as the model\n   * requests function calls.\n   *\n   * For more details and examples, see\n   * [the docs](https://github.com/openai/openai-node#automated-function-calls)\n   */\n  runTools<\n    Params extends ChatCompletionToolRunnerParams<any>,\n    ParsedT = ExtractParsedContentFromParams<Params>,\n  >(body: Params, options?: RunnerOptions): ChatCompletionRunner<ParsedT>;\n\n  runTools<\n    Params extends ChatCompletionStreamingToolRunnerParams<any>,\n    ParsedT = ExtractParsedContentFromParams<Params>,\n  >(body: Params, options?: RunnerOptions): ChatCompletionStreamingRunner<ParsedT>;\n\n  runTools<\n    Params extends ChatCompletionToolRunnerParams<any> | ChatCompletionStreamingToolRunnerParams<any>,\n    ParsedT = ExtractParsedContentFromParams<Params>,\n  >(\n    body: Params,\n    options?: RunnerOptions,\n  ): ChatCompletionRunner<ParsedT> | ChatCompletionStreamingRunner<ParsedT> {\n    if (body.stream) {\n      return ChatCompletionStreamingRunner.runTools(\n        this._client,\n        body as ChatCompletionStreamingToolRunnerParams<any>,\n        options,\n      );\n    }\n\n    return ChatCompletionRunner.runTools(this._client, body as ChatCompletionToolRunnerParams<any>, options);\n  }\n\n  /**\n   * Creates a chat completion stream\n   */\n  stream<Params extends ChatCompletionStreamParams, ParsedT = ExtractParsedContentFromParams<Params>>(\n    body: Params,\n    options?: RequestOptions,\n  ): ChatCompletionStream<ParsedT> {\n    return ChatCompletionStream.createChatCompletion(this._client, body, options);\n  }\n}\n\nexport interface ParsedFunction extends ChatCompletionMessageFunctionToolCall.Function {\n  parsed_arguments?: unknown;\n}\n\nexport interface ParsedFunctionToolCall extends ChatCompletionMessageFunctionToolCall {\n  function: ParsedFunction;\n}\n\nexport interface ParsedChatCompletionMessage<ParsedT> extends ChatCompletionMessage {\n  parsed: ParsedT | null;\n  tool_calls?: Array<ParsedFunctionToolCall>;\n}\n\nexport interface ParsedChoice<ParsedT> extends ChatCompletion.Choice {\n  message: ParsedChatCompletionMessage<ParsedT>;\n}\n\nexport interface ParsedChatCompletion<ParsedT> extends ChatCompletion {\n  choices: Array<ParsedChoice<ParsedT>>;\n}\n\nexport type ChatCompletionParseParams = ChatCompletionCreateParamsNonStreaming;\n\nexport { ChatCompletionStreamingRunner } from '../../../lib/ChatCompletionStreamingRunner';\nexport {\n  type RunnableFunctionWithParse,\n  type RunnableFunctionWithoutParse,\n  ParsingToolFunction,\n} from '../../../lib/RunnableFunction';\nexport { type ChatCompletionToolRunnerParams } from '../../../lib/ChatCompletionRunner';\nexport { type ChatCompletionStreamingToolRunnerParams } from '../../../lib/ChatCompletionStreamingRunner';\nexport { ChatCompletionStream, type ChatCompletionStreamParams } from '../../../lib/ChatCompletionStream';\nexport { ChatCompletionRunner } from '../../../lib/ChatCompletionRunner';\n\nexport type ChatCompletionsPage = CursorPage<ChatCompletion>;\n\nexport type ChatCompletionStoreMessagesPage = CursorPage<ChatCompletionStoreMessage>;\n\n/**\n * Represents a chat completion response returned by model, based on the provided\n * input.\n */\nexport interface ChatCompletion {\n  /**\n   * A unique identifier for the chat completion.\n   */\n  id: string;\n\n  /**\n   * A list of chat completion choices. Can be more than one if `n` is greater\n   * than 1.\n   */\n  choices: Array<ChatCompletion.Choice>;\n\n  /**\n   * The Unix timestamp (in seconds) of when the chat completion was created.\n   */\n  created: number;\n\n  /**\n   * The model used for the chat completion.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always `chat.completion`.\n   */\n  object: 'chat.completion';\n\n  /**\n   * Specifies the processing type used for serving the request.\n   *\n   * - If set to 'auto', then the request will be processed with the service tier\n   *   configured in the Project settings. Unless otherwise configured, the Project\n   *   will use 'default'.\n   * - If set to 'default', then the request will be processed with the standard\n   *   pricing and performance for the selected model.\n   * - If set to '[flex](https://platform.openai.com/docs/guides/flex-processing)' or\n   *   '[priority](https://openai.com/api-priority-processing/)', then the request\n   *   will be processed with the corresponding service tier.\n   * - When not set, the default behavior is 'auto'.\n   *\n   * When the `service_tier` parameter is set, the response body will include the\n   * `service_tier` value based on the processing mode actually used to serve the\n   * request. This response value may be different from the value set in the\n   * parameter.\n   */\n  service_tier?: 'auto' | 'default' | 'flex' | 'scale' | 'priority' | null;\n\n  /**\n   * @deprecated This fingerprint represents the backend configuration that the model\n   * runs with.\n   *\n   * Can be used in conjunction with the `seed` request parameter to understand when\n   * backend changes have been made that might impact determinism.\n   */\n  system_fingerprint?: string;\n\n  /**\n   * Usage statistics for the completion request.\n   */\n  usage?: CompletionsAPI.CompletionUsage;\n}\n\nexport namespace ChatCompletion {\n  export interface Choice {\n    /**\n     * The reason the model stopped generating tokens. This will be `stop` if the model\n     * hit a natural stop point or a provided stop sequence, `length` if the maximum\n     * number of tokens specified in the request was reached, `content_filter` if\n     * content was omitted due to a flag from our content filters, `tool_calls` if the\n     * model called a tool, or `function_call` (deprecated) if the model called a\n     * function.\n     */\n    finish_reason: 'stop' | 'length' | 'tool_calls' | 'content_filter' | 'function_call';\n\n    /**\n     * The index of the choice in the list of choices.\n     */\n    index: number;\n\n    /**\n     * Log probability information for the choice.\n     */\n    logprobs: Choice.Logprobs | null;\n\n    /**\n     * A chat completion message generated by the model.\n     */\n    message: CompletionsCompletionsAPI.ChatCompletionMessage;\n  }\n\n  export namespace Choice {\n    /**\n     * Log probability information for the choice.\n     */\n    export interface Logprobs {\n      /**\n       * A list of message content tokens with log probability information.\n       */\n      content: Array<CompletionsCompletionsAPI.ChatCompletionTokenLogprob> | null;\n\n      /**\n       * A list of message refusal tokens with log probability information.\n       */\n      refusal: Array<CompletionsCompletionsAPI.ChatCompletionTokenLogprob> | null;\n    }\n  }\n}\n\n/**\n * Constrains the tools available to the model to a pre-defined set.\n */\nexport interface ChatCompletionAllowedToolChoice {\n  /**\n   * Constrains the tools available to the model to a pre-defined set.\n   */\n  allowed_tools: ChatCompletionAllowedTools;\n\n  /**\n   * Allowed tool configuration type. Always `allowed_tools`.\n   */\n  type: 'allowed_tools';\n}\n\n/**\n * Messages sent by the model in response to user messages.\n */\nexport interface ChatCompletionAssistantMessageParam {\n  /**\n   * The role of the messages author, in this case `assistant`.\n   */\n  role: 'assistant';\n\n  /**\n   * Data about a previous audio response from the model.\n   * [Learn more](https://platform.openai.com/docs/guides/audio).\n   */\n  audio?: ChatCompletionAssistantMessageParam.Audio | null;\n\n  /**\n   * The contents of the assistant message. Required unless `tool_calls` or\n   * `function_call` is specified.\n   */\n  content?: string | Array<ChatCompletionContentPartText | ChatCompletionContentPartRefusal> | null;\n\n  /**\n   * @deprecated Deprecated and replaced by `tool_calls`. The name and arguments of a\n   * function that should be called, as generated by the model.\n   */\n  function_call?: ChatCompletionAssistantMessageParam.FunctionCall | null;\n\n  /**\n   * An optional name for the participant. Provides the model information to\n   * differentiate between participants of the same role.\n   */\n  name?: string;\n\n  /**\n   * The refusal message by the assistant.\n   */\n  refusal?: string | null;\n\n  /**\n   * The tool calls generated by the model, such as function calls.\n   */\n  tool_calls?: Array<ChatCompletionMessageToolCall>;\n}\n\nexport namespace ChatCompletionAssistantMessageParam {\n  /**\n   * Data about a previous audio response from the model.\n   * [Learn more](https://platform.openai.com/docs/guides/audio).\n   */\n  export interface Audio {\n    /**\n     * Unique identifier for a previous audio response from the model.\n     */\n    id: string;\n  }\n\n  /**\n   * @deprecated Deprecated and replaced by `tool_calls`. The name and arguments of a\n   * function that should be called, as generated by the model.\n   */\n  export interface FunctionCall {\n    /**\n     * The arguments to call the function with, as generated by the model in JSON\n     * format. Note that the model does not always generate valid JSON, and may\n     * hallucinate parameters not defined by your function schema. Validate the\n     * arguments in your code before calling your function.\n     */\n    arguments: string;\n\n    /**\n     * The name of the function to call.\n     */\n    name: string;\n  }\n}\n\n/**\n * If the audio output modality is requested, this object contains data about the\n * audio response from the model.\n * [Learn more](https://platform.openai.com/docs/guides/audio).\n */\nexport interface ChatCompletionAudio {\n  /**\n   * Unique identifier for this audio response.\n   */\n  id: string;\n\n  /**\n   * Base64 encoded audio bytes generated by the model, in the format specified in\n   * the request.\n   */\n  data: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when this audio response will no longer be\n   * accessible on the server for use in multi-turn conversations.\n   */\n  expires_at: number;\n\n  /**\n   * Transcript of the audio generated by the model.\n   */\n  transcript: string;\n}\n\n/**\n * Parameters for audio output. Required when audio output is requested with\n * `modalities: [\"audio\"]`.\n * [Learn more](https://platform.openai.com/docs/guides/audio).\n */\nexport interface ChatCompletionAudioParam {\n  /**\n   * Specifies the output audio format. Must be one of `wav`, `mp3`, `flac`, `opus`,\n   * or `pcm16`.\n   */\n  format: 'wav' | 'aac' | 'mp3' | 'flac' | 'opus' | 'pcm16';\n\n  /**\n   * The voice the model uses to respond. Supported voices are `alloy`, `ash`,\n   * `ballad`, `coral`, `echo`, `fable`, `nova`, `onyx`, `sage`, and `shimmer`.\n   */\n  voice:\n    | (string & {})\n    | 'alloy'\n    | 'ash'\n    | 'ballad'\n    | 'coral'\n    | 'echo'\n    | 'sage'\n    | 'shimmer'\n    | 'verse'\n    | 'marin'\n    | 'cedar';\n}\n\n/**\n * Represents a streamed chunk of a chat completion response returned by the model,\n * based on the provided input.\n * [Learn more](https://platform.openai.com/docs/guides/streaming-responses).\n */\nexport interface ChatCompletionChunk {\n  /**\n   * A unique identifier for the chat completion. Each chunk has the same ID.\n   */\n  id: string;\n\n  /**\n   * A list of chat completion choices. Can contain more than one elements if `n` is\n   * greater than 1. Can also be empty for the last chunk if you set\n   * `stream_options: {\"include_usage\": true}`.\n   */\n  choices: Array<ChatCompletionChunk.Choice>;\n\n  /**\n   * The Unix timestamp (in seconds) of when the chat completion was created. Each\n   * chunk has the same timestamp.\n   */\n  created: number;\n\n  /**\n   * The model to generate the completion.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always `chat.completion.chunk`.\n   */\n  object: 'chat.completion.chunk';\n\n  /**\n   * Specifies the processing type used for serving the request.\n   *\n   * - If set to 'auto', then the request will be processed with the service tier\n   *   configured in the Project settings. Unless otherwise configured, the Project\n   *   will use 'default'.\n   * - If set to 'default', then the request will be processed with the standard\n   *   pricing and performance for the selected model.\n   * - If set to '[flex](https://platform.openai.com/docs/guides/flex-processing)' or\n   *   '[priority](https://openai.com/api-priority-processing/)', then the request\n   *   will be processed with the corresponding service tier.\n   * - When not set, the default behavior is 'auto'.\n   *\n   * When the `service_tier` parameter is set, the response body will include the\n   * `service_tier` value based on the processing mode actually used to serve the\n   * request. This response value may be different from the value set in the\n   * parameter.\n   */\n  service_tier?: 'auto' | 'default' | 'flex' | 'scale' | 'priority' | null;\n\n  /**\n   * @deprecated This fingerprint represents the backend configuration that the model\n   * runs with. Can be used in conjunction with the `seed` request parameter to\n   * understand when backend changes have been made that might impact determinism.\n   */\n  system_fingerprint?: string;\n\n  /**\n   * An optional field that will only be present when you set\n   * `stream_options: {\"include_usage\": true}` in your request. When present, it\n   * contains a null value **except for the last chunk** which contains the token\n   * usage statistics for the entire request.\n   *\n   * **NOTE:** If the stream is interrupted or cancelled, you may not receive the\n   * final usage chunk which contains the total token usage for the request.\n   */\n  usage?: CompletionsAPI.CompletionUsage | null;\n}\n\nexport namespace ChatCompletionChunk {\n  export interface Choice {\n    /**\n     * A chat completion delta generated by streamed model responses.\n     */\n    delta: Choice.Delta;\n\n    /**\n     * The reason the model stopped generating tokens. This will be `stop` if the model\n     * hit a natural stop point or a provided stop sequence, `length` if the maximum\n     * number of tokens specified in the request was reached, `content_filter` if\n     * content was omitted due to a flag from our content filters, `tool_calls` if the\n     * model called a tool, or `function_call` (deprecated) if the model called a\n     * function.\n     */\n    finish_reason: 'stop' | 'length' | 'tool_calls' | 'content_filter' | 'function_call' | null;\n\n    /**\n     * The index of the choice in the list of choices.\n     */\n    index: number;\n\n    /**\n     * Log probability information for the choice.\n     */\n    logprobs?: Choice.Logprobs | null;\n  }\n\n  export namespace Choice {\n    /**\n     * A chat completion delta generated by streamed model responses.\n     */\n    export interface Delta {\n      /**\n       * The contents of the chunk message.\n       */\n      content?: string | null;\n\n      /**\n       * @deprecated Deprecated and replaced by `tool_calls`. The name and arguments of a\n       * function that should be called, as generated by the model.\n       */\n      function_call?: Delta.FunctionCall;\n\n      /**\n       * The refusal message generated by the model.\n       */\n      refusal?: string | null;\n\n      /**\n       * The role of the author of this message.\n       */\n      role?: 'developer' | 'system' | 'user' | 'assistant' | 'tool';\n\n      tool_calls?: Array<Delta.ToolCall>;\n    }\n\n    export namespace Delta {\n      /**\n       * @deprecated Deprecated and replaced by `tool_calls`. The name and arguments of a\n       * function that should be called, as generated by the model.\n       */\n      export interface FunctionCall {\n        /**\n         * The arguments to call the function with, as generated by the model in JSON\n         * format. Note that the model does not always generate valid JSON, and may\n         * hallucinate parameters not defined by your function schema. Validate the\n         * arguments in your code before calling your function.\n         */\n        arguments?: string;\n\n        /**\n         * The name of the function to call.\n         */\n        name?: string;\n      }\n\n      export interface ToolCall {\n        index: number;\n\n        /**\n         * The ID of the tool call.\n         */\n        id?: string;\n\n        function?: ToolCall.Function;\n\n        /**\n         * The type of the tool. Currently, only `function` is supported.\n         */\n        type?: 'function';\n      }\n\n      export namespace ToolCall {\n        export interface Function {\n          /**\n           * The arguments to call the function with, as generated by the model in JSON\n           * format. Note that the model does not always generate valid JSON, and may\n           * hallucinate parameters not defined by your function schema. Validate the\n           * arguments in your code before calling your function.\n           */\n          arguments?: string;\n\n          /**\n           * The name of the function to call.\n           */\n          name?: string;\n        }\n      }\n    }\n\n    /**\n     * Log probability information for the choice.\n     */\n    export interface Logprobs {\n      /**\n       * A list of message content tokens with log probability information.\n       */\n      content: Array<CompletionsCompletionsAPI.ChatCompletionTokenLogprob> | null;\n\n      /**\n       * A list of message refusal tokens with log probability information.\n       */\n      refusal: Array<CompletionsCompletionsAPI.ChatCompletionTokenLogprob> | null;\n    }\n  }\n}\n\n/**\n * Learn about\n * [text inputs](https://platform.openai.com/docs/guides/text-generation).\n */\nexport type ChatCompletionContentPart =\n  | ChatCompletionContentPartText\n  | ChatCompletionContentPartImage\n  | ChatCompletionContentPartInputAudio\n  | ChatCompletionContentPart.File;\n\nexport namespace ChatCompletionContentPart {\n  /**\n   * Learn about [file inputs](https://platform.openai.com/docs/guides/text) for text\n   * generation.\n   */\n  export interface File {\n    file: File.File;\n\n    /**\n     * The type of the content part. Always `file`.\n     */\n    type: 'file';\n  }\n\n  export namespace File {\n    export interface File {\n      /**\n       * The base64 encoded file data, used when passing the file to the model as a\n       * string.\n       */\n      file_data?: string;\n\n      /**\n       * The ID of an uploaded file to use as input.\n       */\n      file_id?: string;\n\n      /**\n       * The name of the file, used when passing the file to the model as a string.\n       */\n      filename?: string;\n    }\n  }\n}\n\n/**\n * Learn about [image inputs](https://platform.openai.com/docs/guides/vision).\n */\nexport interface ChatCompletionContentPartImage {\n  image_url: ChatCompletionContentPartImage.ImageURL;\n\n  /**\n   * The type of the content part.\n   */\n  type: 'image_url';\n}\n\nexport namespace ChatCompletionContentPartImage {\n  export interface ImageURL {\n    /**\n     * Either a URL of the image or the base64 encoded image data.\n     */\n    url: string;\n\n    /**\n     * Specifies the detail level of the image. Learn more in the\n     * [Vision guide](https://platform.openai.com/docs/guides/vision#low-or-high-fidelity-image-understanding).\n     */\n    detail?: 'auto' | 'low' | 'high';\n  }\n}\n\n/**\n * Learn about [audio inputs](https://platform.openai.com/docs/guides/audio).\n */\nexport interface ChatCompletionContentPartInputAudio {\n  input_audio: ChatCompletionContentPartInputAudio.InputAudio;\n\n  /**\n   * The type of the content part. Always `input_audio`.\n   */\n  type: 'input_audio';\n}\n\nexport namespace ChatCompletionContentPartInputAudio {\n  export interface InputAudio {\n    /**\n     * Base64 encoded audio data.\n     */\n    data: string;\n\n    /**\n     * The format of the encoded audio data. Currently supports \"wav\" and \"mp3\".\n     */\n    format: 'wav' | 'mp3';\n  }\n}\n\nexport interface ChatCompletionContentPartRefusal {\n  /**\n   * The refusal message generated by the model.\n   */\n  refusal: string;\n\n  /**\n   * The type of the content part.\n   */\n  type: 'refusal';\n}\n\n/**\n * Learn about\n * [text inputs](https://platform.openai.com/docs/guides/text-generation).\n */\nexport interface ChatCompletionContentPartText {\n  /**\n   * The text content.\n   */\n  text: string;\n\n  /**\n   * The type of the content part.\n   */\n  type: 'text';\n}\n\n/**\n * A custom tool that processes input using a specified format.\n */\nexport interface ChatCompletionCustomTool {\n  /**\n   * Properties of the custom tool.\n   */\n  custom: ChatCompletionCustomTool.Custom;\n\n  /**\n   * The type of the custom tool. Always `custom`.\n   */\n  type: 'custom';\n}\n\nexport namespace ChatCompletionCustomTool {\n  /**\n   * Properties of the custom tool.\n   */\n  export interface Custom {\n    /**\n     * The name of the custom tool, used to identify it in tool calls.\n     */\n    name: string;\n\n    /**\n     * Optional description of the custom tool, used to provide more context.\n     */\n    description?: string;\n\n    /**\n     * The input format for the custom tool. Default is unconstrained text.\n     */\n    format?: Custom.Text | Custom.Grammar;\n  }\n\n  export namespace Custom {\n    /**\n     * Unconstrained free-form text.\n     */\n    export interface Text {\n      /**\n       * Unconstrained text format. Always `text`.\n       */\n      type: 'text';\n    }\n\n    /**\n     * A grammar defined by the user.\n     */\n    export interface Grammar {\n      /**\n       * Your chosen grammar.\n       */\n      grammar: Grammar.Grammar;\n\n      /**\n       * Grammar format. Always `grammar`.\n       */\n      type: 'grammar';\n    }\n\n    export namespace Grammar {\n      /**\n       * Your chosen grammar.\n       */\n      export interface Grammar {\n        /**\n         * The grammar definition.\n         */\n        definition: string;\n\n        /**\n         * The syntax of the grammar definition. One of `lark` or `regex`.\n         */\n        syntax: 'lark' | 'regex';\n      }\n    }\n  }\n}\n\nexport interface ChatCompletionDeleted {\n  /**\n   * The ID of the chat completion that was deleted.\n   */\n  id: string;\n\n  /**\n   * Whether the chat completion was deleted.\n   */\n  deleted: boolean;\n\n  /**\n   * The type of object being deleted.\n   */\n  object: 'chat.completion.deleted';\n}\n\n/**\n * Developer-provided instructions that the model should follow, regardless of\n * messages sent by the user. With o1 models and newer, `developer` messages\n * replace the previous `system` messages.\n */\nexport interface ChatCompletionDeveloperMessageParam {\n  /**\n   * The contents of the developer message.\n   */\n  content: string | Array<ChatCompletionContentPartText>;\n\n  /**\n   * The role of the messages author, in this case `developer`.\n   */\n  role: 'developer';\n\n  /**\n   * An optional name for the participant. Provides the model information to\n   * differentiate between participants of the same role.\n   */\n  name?: string;\n}\n\n/**\n * Specifying a particular function via `{\"name\": \"my_function\"}` forces the model\n * to call that function.\n */\nexport interface ChatCompletionFunctionCallOption {\n  /**\n   * The name of the function to call.\n   */\n  name: string;\n}\n\n/**\n * @deprecated\n */\nexport interface ChatCompletionFunctionMessageParam {\n  /**\n   * The contents of the function message.\n   */\n  content: string | null;\n\n  /**\n   * The name of the function to call.\n   */\n  name: string;\n\n  /**\n   * The role of the messages author, in this case `function`.\n   */\n  role: 'function';\n}\n\n/**\n * A function tool that can be used to generate a response.\n */\nexport interface ChatCompletionFunctionTool {\n  function: Shared.FunctionDefinition;\n\n  /**\n   * The type of the tool. Currently, only `function` is supported.\n   */\n  type: 'function';\n}\n\n/**\n * A chat completion message generated by the model.\n */\nexport interface ChatCompletionMessage {\n  /**\n   * The contents of the message.\n   */\n  content: string | null;\n\n  /**\n   * The refusal message generated by the model.\n   */\n  refusal: string | null;\n\n  /**\n   * The role of the author of this message.\n   */\n  role: 'assistant';\n\n  /**\n   * Annotations for the message, when applicable, as when using the\n   * [web search tool](https://platform.openai.com/docs/guides/tools-web-search?api-mode=chat).\n   */\n  annotations?: Array<ChatCompletionMessage.Annotation>;\n\n  /**\n   * If the audio output modality is requested, this object contains data about the\n   * audio response from the model.\n   * [Learn more](https://platform.openai.com/docs/guides/audio).\n   */\n  audio?: ChatCompletionAudio | null;\n\n  /**\n   * @deprecated Deprecated and replaced by `tool_calls`. The name and arguments of a\n   * function that should be called, as generated by the model.\n   */\n  function_call?: ChatCompletionMessage.FunctionCall | null;\n\n  /**\n   * The tool calls generated by the model, such as function calls.\n   */\n  tool_calls?: Array<ChatCompletionMessageToolCall>;\n}\n\nexport namespace ChatCompletionMessage {\n  /**\n   * A URL citation when using web search.\n   */\n  export interface Annotation {\n    /**\n     * The type of the URL citation. Always `url_citation`.\n     */\n    type: 'url_citation';\n\n    /**\n     * A URL citation when using web search.\n     */\n    url_citation: Annotation.URLCitation;\n  }\n\n  export namespace Annotation {\n    /**\n     * A URL citation when using web search.\n     */\n    export interface URLCitation {\n      /**\n       * The index of the last character of the URL citation in the message.\n       */\n      end_index: number;\n\n      /**\n       * The index of the first character of the URL citation in the message.\n       */\n      start_index: number;\n\n      /**\n       * The title of the web resource.\n       */\n      title: string;\n\n      /**\n       * The URL of the web resource.\n       */\n      url: string;\n    }\n  }\n\n  /**\n   * @deprecated Deprecated and replaced by `tool_calls`. The name and arguments of a\n   * function that should be called, as generated by the model.\n   */\n  export interface FunctionCall {\n    /**\n     * The arguments to call the function with, as generated by the model in JSON\n     * format. Note that the model does not always generate valid JSON, and may\n     * hallucinate parameters not defined by your function schema. Validate the\n     * arguments in your code before calling your function.\n     */\n    arguments: string;\n\n    /**\n     * The name of the function to call.\n     */\n    name: string;\n  }\n}\n\n/**\n * A call to a custom tool created by the model.\n */\nexport interface ChatCompletionMessageCustomToolCall {\n  /**\n   * The ID of the tool call.\n   */\n  id: string;\n\n  /**\n   * The custom tool that the model called.\n   */\n  custom: ChatCompletionMessageCustomToolCall.Custom;\n\n  /**\n   * The type of the tool. Always `custom`.\n   */\n  type: 'custom';\n}\n\nexport namespace ChatCompletionMessageCustomToolCall {\n  /**\n   * The custom tool that the model called.\n   */\n  export interface Custom {\n    /**\n     * The input for the custom tool call generated by the model.\n     */\n    input: string;\n\n    /**\n     * The name of the custom tool to call.\n     */\n    name: string;\n  }\n}\n\n/**\n * A call to a function tool created by the model.\n */\nexport interface ChatCompletionMessageFunctionToolCall {\n  /**\n   * The ID of the tool call.\n   */\n  id: string;\n\n  /**\n   * The function that the model called.\n   */\n  function: ChatCompletionMessageFunctionToolCall.Function;\n\n  /**\n   * The type of the tool. Currently, only `function` is supported.\n   */\n  type: 'function';\n}\n\nexport namespace ChatCompletionMessageFunctionToolCall {\n  /**\n   * The function that the model called.\n   */\n  export interface Function {\n    /**\n     * The arguments to call the function with, as generated by the model in JSON\n     * format. Note that the model does not always generate valid JSON, and may\n     * hallucinate parameters not defined by your function schema. Validate the\n     * arguments in your code before calling your function.\n     */\n    arguments: string;\n\n    /**\n     * The name of the function to call.\n     */\n    name: string;\n  }\n}\n\n/**\n * Developer-provided instructions that the model should follow, regardless of\n * messages sent by the user. With o1 models and newer, `developer` messages\n * replace the previous `system` messages.\n */\nexport type ChatCompletionMessageParam =\n  | ChatCompletionDeveloperMessageParam\n  | ChatCompletionSystemMessageParam\n  | ChatCompletionUserMessageParam\n  | ChatCompletionAssistantMessageParam\n  | ChatCompletionToolMessageParam\n  | ChatCompletionFunctionMessageParam;\n\n/**\n * A call to a function tool created by the model.\n */\nexport type ChatCompletionMessageToolCall =\n  | ChatCompletionMessageFunctionToolCall\n  | ChatCompletionMessageCustomToolCall;\n\nexport type ChatCompletionModality = 'text' | 'audio';\n\n/**\n * Specifies a tool the model should use. Use to force the model to call a specific\n * function.\n */\nexport interface ChatCompletionNamedToolChoice {\n  function: ChatCompletionNamedToolChoice.Function;\n\n  /**\n   * For function calling, the type is always `function`.\n   */\n  type: 'function';\n}\n\nexport namespace ChatCompletionNamedToolChoice {\n  export interface Function {\n    /**\n     * The name of the function to call.\n     */\n    name: string;\n  }\n}\n\n/**\n * Specifies a tool the model should use. Use to force the model to call a specific\n * custom tool.\n */\nexport interface ChatCompletionNamedToolChoiceCustom {\n  custom: ChatCompletionNamedToolChoiceCustom.Custom;\n\n  /**\n   * For custom tool calling, the type is always `custom`.\n   */\n  type: 'custom';\n}\n\nexport namespace ChatCompletionNamedToolChoiceCustom {\n  export interface Custom {\n    /**\n     * The name of the custom tool to call.\n     */\n    name: string;\n  }\n}\n\n/**\n * Static predicted output content, such as the content of a text file that is\n * being regenerated.\n */\nexport interface ChatCompletionPredictionContent {\n  /**\n   * The content that should be matched when generating a model response. If\n   * generated tokens would match this content, the entire model response can be\n   * returned much more quickly.\n   */\n  content: string | Array<ChatCompletionContentPartText>;\n\n  /**\n   * The type of the predicted content you want to provide. This type is currently\n   * always `content`.\n   */\n  type: 'content';\n}\n\n/**\n * The role of the author of a message\n */\nexport type ChatCompletionRole = 'developer' | 'system' | 'user' | 'assistant' | 'tool' | 'function';\n\n/**\n * A chat completion message generated by the model.\n */\nexport interface ChatCompletionStoreMessage extends ChatCompletionMessage {\n  /**\n   * The identifier of the chat message.\n   */\n  id: string;\n\n  /**\n   * If a content parts array was provided, this is an array of `text` and\n   * `image_url` parts. Otherwise, null.\n   */\n  content_parts?: Array<ChatCompletionContentPartText | ChatCompletionContentPartImage> | null;\n}\n\n/**\n * Options for streaming response. Only set this when you set `stream: true`.\n */\nexport interface ChatCompletionStreamOptions {\n  /**\n   * When true, stream obfuscation will be enabled. Stream obfuscation adds random\n   * characters to an `obfuscation` field on streaming delta events to normalize\n   * payload sizes as a mitigation to certain side-channel attacks. These obfuscation\n   * fields are included by default, but add a small amount of overhead to the data\n   * stream. You can set `include_obfuscation` to false to optimize for bandwidth if\n   * you trust the network links between your application and the OpenAI API.\n   */\n  include_obfuscation?: boolean;\n\n  /**\n   * If set, an additional chunk will be streamed before the `data: [DONE]` message.\n   * The `usage` field on this chunk shows the token usage statistics for the entire\n   * request, and the `choices` field will always be an empty array.\n   *\n   * All other chunks will also include a `usage` field, but with a null value.\n   * **NOTE:** If the stream is interrupted, you may not receive the final usage\n   * chunk which contains the total token usage for the request.\n   */\n  include_usage?: boolean;\n}\n\n/**\n * Developer-provided instructions that the model should follow, regardless of\n * messages sent by the user. With o1 models and newer, use `developer` messages\n * for this purpose instead.\n */\nexport interface ChatCompletionSystemMessageParam {\n  /**\n   * The contents of the system message.\n   */\n  content: string | Array<ChatCompletionContentPartText>;\n\n  /**\n   * The role of the messages author, in this case `system`.\n   */\n  role: 'system';\n\n  /**\n   * An optional name for the participant. Provides the model information to\n   * differentiate between participants of the same role.\n   */\n  name?: string;\n}\n\nexport interface ChatCompletionTokenLogprob {\n  /**\n   * The token.\n   */\n  token: string;\n\n  /**\n   * A list of integers representing the UTF-8 bytes representation of the token.\n   * Useful in instances where characters are represented by multiple tokens and\n   * their byte representations must be combined to generate the correct text\n   * representation. Can be `null` if there is no bytes representation for the token.\n   */\n  bytes: Array<number> | null;\n\n  /**\n   * The log probability of this token, if it is within the top 20 most likely\n   * tokens. Otherwise, the value `-9999.0` is used to signify that the token is very\n   * unlikely.\n   */\n  logprob: number;\n\n  /**\n   * List of the most likely tokens and their log probability, at this token\n   * position. In rare cases, there may be fewer than the number of requested\n   * `top_logprobs` returned.\n   */\n  top_logprobs: Array<ChatCompletionTokenLogprob.TopLogprob>;\n}\n\nexport namespace ChatCompletionTokenLogprob {\n  export interface TopLogprob {\n    /**\n     * The token.\n     */\n    token: string;\n\n    /**\n     * A list of integers representing the UTF-8 bytes representation of the token.\n     * Useful in instances where characters are represented by multiple tokens and\n     * their byte representations must be combined to generate the correct text\n     * representation. Can be `null` if there is no bytes representation for the token.\n     */\n    bytes: Array<number> | null;\n\n    /**\n     * The log probability of this token, if it is within the top 20 most likely\n     * tokens. Otherwise, the value `-9999.0` is used to signify that the token is very\n     * unlikely.\n     */\n    logprob: number;\n  }\n}\n\n/**\n * A function tool that can be used to generate a response.\n */\nexport type ChatCompletionTool = ChatCompletionFunctionTool | ChatCompletionCustomTool;\n\n/**\n * Controls which (if any) tool is called by the model. `none` means the model will\n * not call any tool and instead generates a message. `auto` means the model can\n * pick between generating a message or calling one or more tools. `required` means\n * the model must call one or more tools. Specifying a particular tool via\n * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n * call that tool.\n *\n * `none` is the default when no tools are present. `auto` is the default if tools\n * are present.\n */\nexport type ChatCompletionToolChoiceOption =\n  | 'none'\n  | 'auto'\n  | 'required'\n  | ChatCompletionAllowedToolChoice\n  | ChatCompletionNamedToolChoice\n  | ChatCompletionNamedToolChoiceCustom;\n\nexport interface ChatCompletionToolMessageParam {\n  /**\n   * The contents of the tool message.\n   */\n  content: string | Array<ChatCompletionContentPartText>;\n\n  /**\n   * The role of the messages author, in this case `tool`.\n   */\n  role: 'tool';\n\n  /**\n   * Tool call that this message is responding to.\n   */\n  tool_call_id: string;\n}\n\n/**\n * Messages sent by an end user, containing prompts or additional context\n * information.\n */\nexport interface ChatCompletionUserMessageParam {\n  /**\n   * The contents of the user message.\n   */\n  content: string | Array<ChatCompletionContentPart>;\n\n  /**\n   * The role of the messages author, in this case `user`.\n   */\n  role: 'user';\n\n  /**\n   * An optional name for the participant. Provides the model information to\n   * differentiate between participants of the same role.\n   */\n  name?: string;\n}\n\n/**\n * Constrains the tools available to the model to a pre-defined set.\n */\nexport interface ChatCompletionAllowedTools {\n  /**\n   * Constrains the tools available to the model to a pre-defined set.\n   *\n   * `auto` allows the model to pick from among the allowed tools and generate a\n   * message.\n   *\n   * `required` requires the model to call one or more of the allowed tools.\n   */\n  mode: 'auto' | 'required';\n\n  /**\n   * A list of tool definitions that the model should be allowed to call.\n   *\n   * For the Chat Completions API, the list of tool definitions might look like:\n   *\n   * ```json\n   * [\n   *   { \"type\": \"function\", \"function\": { \"name\": \"get_weather\" } },\n   *   { \"type\": \"function\", \"function\": { \"name\": \"get_time\" } }\n   * ]\n   * ```\n   */\n  tools: Array<{ [key: string]: unknown }>;\n}\n\nexport type ChatCompletionReasoningEffort = Shared.ReasoningEffort | null;\n\nexport type ChatCompletionCreateParams =\n  | ChatCompletionCreateParamsNonStreaming\n  | ChatCompletionCreateParamsStreaming;\n\nexport interface ChatCompletionCreateParamsBase {\n  /**\n   * A list of messages comprising the conversation so far. Depending on the\n   * [model](https://platform.openai.com/docs/models) you use, different message\n   * types (modalities) are supported, like\n   * [text](https://platform.openai.com/docs/guides/text-generation),\n   * [images](https://platform.openai.com/docs/guides/vision), and\n   * [audio](https://platform.openai.com/docs/guides/audio).\n   */\n  messages: Array<ChatCompletionMessageParam>;\n\n  /**\n   * Model ID used to generate the response, like `gpt-4o` or `o3`. OpenAI offers a\n   * wide range of models with different capabilities, performance characteristics,\n   * and price points. Refer to the\n   * [model guide](https://platform.openai.com/docs/models) to browse and compare\n   * available models.\n   */\n  model: (string & {}) | Shared.ChatModel;\n\n  /**\n   * Parameters for audio output. Required when audio output is requested with\n   * `modalities: [\"audio\"]`.\n   * [Learn more](https://platform.openai.com/docs/guides/audio).\n   */\n  audio?: ChatCompletionAudioParam | null;\n\n  /**\n   * Number between -2.0 and 2.0. Positive values penalize new tokens based on their\n   * existing frequency in the text so far, decreasing the model's likelihood to\n   * repeat the same line verbatim.\n   */\n  frequency_penalty?: number | null;\n\n  /**\n   * @deprecated Deprecated in favor of `tool_choice`.\n   *\n   * Controls which (if any) function is called by the model.\n   *\n   * `none` means the model will not call a function and instead generates a message.\n   *\n   * `auto` means the model can pick between generating a message or calling a\n   * function.\n   *\n   * Specifying a particular function via `{\"name\": \"my_function\"}` forces the model\n   * to call that function.\n   *\n   * `none` is the default when no functions are present. `auto` is the default if\n   * functions are present.\n   */\n  function_call?: 'none' | 'auto' | ChatCompletionFunctionCallOption;\n\n  /**\n   * @deprecated Deprecated in favor of `tools`.\n   *\n   * A list of functions the model may generate JSON inputs for.\n   */\n  functions?: Array<ChatCompletionCreateParams.Function>;\n\n  /**\n   * Modify the likelihood of specified tokens appearing in the completion.\n   *\n   * Accepts a JSON object that maps tokens (specified by their token ID in the\n   * tokenizer) to an associated bias value from -100 to 100. Mathematically, the\n   * bias is added to the logits generated by the model prior to sampling. The exact\n   * effect will vary per model, but values between -1 and 1 should decrease or\n   * increase likelihood of selection; values like -100 or 100 should result in a ban\n   * or exclusive selection of the relevant token.\n   */\n  logit_bias?: { [key: string]: number } | null;\n\n  /**\n   * Whether to return log probabilities of the output tokens or not. If true,\n   * returns the log probabilities of each output token returned in the `content` of\n   * `message`.\n   */\n  logprobs?: boolean | null;\n\n  /**\n   * An upper bound for the number of tokens that can be generated for a completion,\n   * including visible output tokens and\n   * [reasoning tokens](https://platform.openai.com/docs/guides/reasoning).\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * @deprecated The maximum number of [tokens](/tokenizer) that can be generated in\n   * the chat completion. This value can be used to control\n   * [costs](https://openai.com/api/pricing/) for text generated via API.\n   *\n   * This value is now deprecated in favor of `max_completion_tokens`, and is not\n   * compatible with\n   * [o-series models](https://platform.openai.com/docs/guides/reasoning).\n   */\n  max_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * Output types that you would like the model to generate. Most models are capable\n   * of generating text, which is the default:\n   *\n   * `[\"text\"]`\n   *\n   * The `gpt-4o-audio-preview` model can also be used to\n   * [generate audio](https://platform.openai.com/docs/guides/audio). To request that\n   * this model generate both text and audio responses, you can use:\n   *\n   * `[\"text\", \"audio\"]`\n   */\n  modalities?: Array<'text' | 'audio'> | null;\n\n  /**\n   * How many chat completion choices to generate for each input message. Note that\n   * you will be charged based on the number of generated tokens across all of the\n   * choices. Keep `n` as `1` to minimize costs.\n   */\n  n?: number | null;\n\n  /**\n   * Whether to enable\n   * [parallel function calling](https://platform.openai.com/docs/guides/function-calling#configuring-parallel-function-calling)\n   * during tool use.\n   */\n  parallel_tool_calls?: boolean;\n\n  /**\n   * Static predicted output content, such as the content of a text file that is\n   * being regenerated.\n   */\n  prediction?: ChatCompletionPredictionContent | null;\n\n  /**\n   * Number between -2.0 and 2.0. Positive values penalize new tokens based on\n   * whether they appear in the text so far, increasing the model's likelihood to\n   * talk about new topics.\n   */\n  presence_penalty?: number | null;\n\n  /**\n   * Used by OpenAI to cache responses for similar requests to optimize your cache\n   * hit rates. Replaces the `user` field.\n   * [Learn more](https://platform.openai.com/docs/guides/prompt-caching).\n   */\n  prompt_cache_key?: string;\n\n  /**\n   * Constrains effort on reasoning for\n   * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n   * supported values are `minimal`, `low`, `medium`, and `high`. Reducing reasoning\n   * effort can result in faster responses and fewer tokens used on reasoning in a\n   * response.\n   *\n   * Note: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning\n   * effort.\n   */\n  reasoning_effort?: Shared.ReasoningEffort | null;\n\n  /**\n   * An object specifying the format that the model must output.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\n   * ensures the message the model generates is valid JSON. Using `json_schema` is\n   * preferred for models that support it.\n   */\n  response_format?:\n    | Shared.ResponseFormatText\n    | Shared.ResponseFormatJSONSchema\n    | Shared.ResponseFormatJSONObject;\n\n  /**\n   * A stable identifier used to help detect users of your application that may be\n   * violating OpenAI's usage policies. The IDs should be a string that uniquely\n   * identifies each user. We recommend hashing their username or email address, in\n   * order to avoid sending us any identifying information.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).\n   */\n  safety_identifier?: string;\n\n  /**\n   * @deprecated This feature is in Beta. If specified, our system will make a best\n   * effort to sample deterministically, such that repeated requests with the same\n   * `seed` and parameters should return the same result. Determinism is not\n   * guaranteed, and you should refer to the `system_fingerprint` response parameter\n   * to monitor changes in the backend.\n   */\n  seed?: number | null;\n\n  /**\n   * Specifies the processing type used for serving the request.\n   *\n   * - If set to 'auto', then the request will be processed with the service tier\n   *   configured in the Project settings. Unless otherwise configured, the Project\n   *   will use 'default'.\n   * - If set to 'default', then the request will be processed with the standard\n   *   pricing and performance for the selected model.\n   * - If set to '[flex](https://platform.openai.com/docs/guides/flex-processing)' or\n   *   '[priority](https://openai.com/api-priority-processing/)', then the request\n   *   will be processed with the corresponding service tier.\n   * - When not set, the default behavior is 'auto'.\n   *\n   * When the `service_tier` parameter is set, the response body will include the\n   * `service_tier` value based on the processing mode actually used to serve the\n   * request. This response value may be different from the value set in the\n   * parameter.\n   */\n  service_tier?: 'auto' | 'default' | 'flex' | 'scale' | 'priority' | null;\n\n  /**\n   * Not supported with latest reasoning models `o3` and `o4-mini`.\n   *\n   * Up to 4 sequences where the API will stop generating further tokens. The\n   * returned text will not contain the stop sequence.\n   */\n  stop?: string | null | Array<string>;\n\n  /**\n   * Whether or not to store the output of this chat completion request for use in\n   * our [model distillation](https://platform.openai.com/docs/guides/distillation)\n   * or [evals](https://platform.openai.com/docs/guides/evals) products.\n   *\n   * Supports text and image inputs. Note: image inputs over 8MB will be dropped.\n   */\n  store?: boolean | null;\n\n  /**\n   * If set to true, the model response data will be streamed to the client as it is\n   * generated using\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\n   * See the\n   * [Streaming section below](https://platform.openai.com/docs/api-reference/chat/streaming)\n   * for more information, along with the\n   * [streaming responses](https://platform.openai.com/docs/guides/streaming-responses)\n   * guide for more information on how to handle the streaming events.\n   */\n  stream?: boolean | null;\n\n  /**\n   * Options for streaming response. Only set this when you set `stream: true`.\n   */\n  stream_options?: ChatCompletionStreamOptions | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic. We generally recommend altering this or `top_p` but\n   * not both.\n   */\n  temperature?: number | null;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tool and instead generates a message. `auto` means the model can\n   * pick between generating a message or calling one or more tools. `required` means\n   * the model must call one or more tools. Specifying a particular tool via\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   *\n   * `none` is the default when no tools are present. `auto` is the default if tools\n   * are present.\n   */\n  tool_choice?: ChatCompletionToolChoiceOption;\n\n  /**\n   * A list of tools the model may call. You can provide either\n   * [custom tools](https://platform.openai.com/docs/guides/function-calling#custom-tools)\n   * or [function tools](https://platform.openai.com/docs/guides/function-calling).\n   */\n  tools?: Array<ChatCompletionTool>;\n\n  /**\n   * An integer between 0 and 20 specifying the number of most likely tokens to\n   * return at each token position, each with an associated log probability.\n   * `logprobs` must be set to `true` if this parameter is used.\n   */\n  top_logprobs?: number | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or `temperature` but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * @deprecated This field is being replaced by `safety_identifier` and\n   * `prompt_cache_key`. Use `prompt_cache_key` instead to maintain caching\n   * optimizations. A stable identifier for your end-users. Used to boost cache hit\n   * rates by better bucketing similar requests and to help OpenAI detect and prevent\n   * abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).\n   */\n  user?: string;\n\n  /**\n   * Constrains the verbosity of the model's response. Lower values will result in\n   * more concise responses, while higher values will result in more verbose\n   * responses. Currently supported values are `low`, `medium`, and `high`.\n   */\n  verbosity?: 'low' | 'medium' | 'high' | null;\n\n  /**\n   * This tool searches the web for relevant results to use in a response. Learn more\n   * about the\n   * [web search tool](https://platform.openai.com/docs/guides/tools-web-search?api-mode=chat).\n   */\n  web_search_options?: ChatCompletionCreateParams.WebSearchOptions;\n}\n\nexport namespace ChatCompletionCreateParams {\n  /**\n   * @deprecated\n   */\n  export interface Function {\n    /**\n     * The name of the function to be called. Must be a-z, A-Z, 0-9, or contain\n     * underscores and dashes, with a maximum length of 64.\n     */\n    name: string;\n\n    /**\n     * A description of what the function does, used by the model to choose when and\n     * how to call the function.\n     */\n    description?: string;\n\n    /**\n     * The parameters the functions accepts, described as a JSON Schema object. See the\n     * [guide](https://platform.openai.com/docs/guides/function-calling) for examples,\n     * and the\n     * [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for\n     * documentation about the format.\n     *\n     * Omitting `parameters` defines a function with an empty parameter list.\n     */\n    parameters?: Shared.FunctionParameters;\n  }\n\n  /**\n   * This tool searches the web for relevant results to use in a response. Learn more\n   * about the\n   * [web search tool](https://platform.openai.com/docs/guides/tools-web-search?api-mode=chat).\n   */\n  export interface WebSearchOptions {\n    /**\n     * High level guidance for the amount of context window space to use for the\n     * search. One of `low`, `medium`, or `high`. `medium` is the default.\n     */\n    search_context_size?: 'low' | 'medium' | 'high';\n\n    /**\n     * Approximate location parameters for the search.\n     */\n    user_location?: WebSearchOptions.UserLocation | null;\n  }\n\n  export namespace WebSearchOptions {\n    /**\n     * Approximate location parameters for the search.\n     */\n    export interface UserLocation {\n      /**\n       * Approximate location parameters for the search.\n       */\n      approximate: UserLocation.Approximate;\n\n      /**\n       * The type of location approximation. Always `approximate`.\n       */\n      type: 'approximate';\n    }\n\n    export namespace UserLocation {\n      /**\n       * Approximate location parameters for the search.\n       */\n      export interface Approximate {\n        /**\n         * Free text input for the city of the user, e.g. `San Francisco`.\n         */\n        city?: string;\n\n        /**\n         * The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of\n         * the user, e.g. `US`.\n         */\n        country?: string;\n\n        /**\n         * Free text input for the region of the user, e.g. `California`.\n         */\n        region?: string;\n\n        /**\n         * The [IANA timezone](https://timeapi.io/documentation/iana-timezones) of the\n         * user, e.g. `America/Los_Angeles`.\n         */\n        timezone?: string;\n      }\n    }\n  }\n\n  export type ChatCompletionCreateParamsNonStreaming =\n    CompletionsCompletionsAPI.ChatCompletionCreateParamsNonStreaming;\n  export type ChatCompletionCreateParamsStreaming =\n    CompletionsCompletionsAPI.ChatCompletionCreateParamsStreaming;\n}\n\nexport interface ChatCompletionCreateParamsNonStreaming extends ChatCompletionCreateParamsBase {\n  /**\n   * If set to true, the model response data will be streamed to the client as it is\n   * generated using\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\n   * See the\n   * [Streaming section below](https://platform.openai.com/docs/api-reference/chat/streaming)\n   * for more information, along with the\n   * [streaming responses](https://platform.openai.com/docs/guides/streaming-responses)\n   * guide for more information on how to handle the streaming events.\n   */\n  stream?: false | null;\n}\n\nexport interface ChatCompletionCreateParamsStreaming extends ChatCompletionCreateParamsBase {\n  /**\n   * If set to true, the model response data will be streamed to the client as it is\n   * generated using\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\n   * See the\n   * [Streaming section below](https://platform.openai.com/docs/api-reference/chat/streaming)\n   * for more information, along with the\n   * [streaming responses](https://platform.openai.com/docs/guides/streaming-responses)\n   * guide for more information on how to handle the streaming events.\n   */\n  stream: true;\n}\n\nexport interface ChatCompletionUpdateParams {\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n}\n\nexport interface ChatCompletionListParams extends CursorPageParams {\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The model used to generate the Chat Completions.\n   */\n  model?: string;\n\n  /**\n   * Sort order for Chat Completions by timestamp. Use `asc` for ascending order or\n   * `desc` for descending order. Defaults to `asc`.\n   */\n  order?: 'asc' | 'desc';\n}\n\nCompletions.Messages = Messages;\n\nexport declare namespace Completions {\n  export {\n    type ChatCompletion as ChatCompletion,\n    type ChatCompletionAllowedToolChoice as ChatCompletionAllowedToolChoice,\n    type ChatCompletionAssistantMessageParam as ChatCompletionAssistantMessageParam,\n    type ChatCompletionAudio as ChatCompletionAudio,\n    type ChatCompletionAudioParam as ChatCompletionAudioParam,\n    type ChatCompletionChunk as ChatCompletionChunk,\n    type ChatCompletionContentPart as ChatCompletionContentPart,\n    type ChatCompletionContentPartImage as ChatCompletionContentPartImage,\n    type ChatCompletionContentPartInputAudio as ChatCompletionContentPartInputAudio,\n    type ChatCompletionContentPartRefusal as ChatCompletionContentPartRefusal,\n    type ChatCompletionContentPartText as ChatCompletionContentPartText,\n    type ChatCompletionCustomTool as ChatCompletionCustomTool,\n    type ChatCompletionDeleted as ChatCompletionDeleted,\n    type ChatCompletionDeveloperMessageParam as ChatCompletionDeveloperMessageParam,\n    type ChatCompletionFunctionCallOption as ChatCompletionFunctionCallOption,\n    type ChatCompletionFunctionMessageParam as ChatCompletionFunctionMessageParam,\n    type ChatCompletionFunctionTool as ChatCompletionFunctionTool,\n    type ChatCompletionMessage as ChatCompletionMessage,\n    type ChatCompletionMessageCustomToolCall as ChatCompletionMessageCustomToolCall,\n    type ChatCompletionMessageFunctionToolCall as ChatCompletionMessageFunctionToolCall,\n    type ChatCompletionMessageParam as ChatCompletionMessageParam,\n    type ChatCompletionMessageToolCall as ChatCompletionMessageToolCall,\n    type ChatCompletionModality as ChatCompletionModality,\n    type ChatCompletionNamedToolChoice as ChatCompletionNamedToolChoice,\n    type ChatCompletionNamedToolChoiceCustom as ChatCompletionNamedToolChoiceCustom,\n    type ChatCompletionPredictionContent as ChatCompletionPredictionContent,\n    type ChatCompletionRole as ChatCompletionRole,\n    type ChatCompletionStoreMessage as ChatCompletionStoreMessage,\n    type ChatCompletionStreamOptions as ChatCompletionStreamOptions,\n    type ChatCompletionSystemMessageParam as ChatCompletionSystemMessageParam,\n    type ChatCompletionTokenLogprob as ChatCompletionTokenLogprob,\n    type ChatCompletionTool as ChatCompletionTool,\n    type ChatCompletionToolChoiceOption as ChatCompletionToolChoiceOption,\n    type ChatCompletionToolMessageParam as ChatCompletionToolMessageParam,\n    type ChatCompletionUserMessageParam as ChatCompletionUserMessageParam,\n    type ChatCompletionAllowedTools as ChatCompletionAllowedTools,\n    type ChatCompletionReasoningEffort as ChatCompletionReasoningEffort,\n    type ChatCompletionsPage as ChatCompletionsPage,\n    type ChatCompletionCreateParams as ChatCompletionCreateParams,\n    type ChatCompletionCreateParamsNonStreaming as ChatCompletionCreateParamsNonStreaming,\n    type ChatCompletionCreateParamsStreaming as ChatCompletionCreateParamsStreaming,\n    type ChatCompletionUpdateParams as ChatCompletionUpdateParams,\n    type ChatCompletionListParams as ChatCompletionListParams,\n  };\n\n  export { Messages as Messages, type MessageListParams as MessageListParams };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as Shared from '../shared';\nimport * as GraderModelsAPI from '../graders/grader-models';\nimport * as ResponsesAPI from '../responses/responses';\nimport * as RunsAPI from './runs/runs';\nimport {\n  CreateEvalCompletionsRunDataSource,\n  CreateEvalJSONLRunDataSource,\n  EvalAPIError,\n  RunCancelParams,\n  RunCancelResponse,\n  RunCreateParams,\n  RunCreateResponse,\n  RunDeleteParams,\n  RunDeleteResponse,\n  RunListParams,\n  RunListResponse,\n  RunListResponsesPage,\n  RunRetrieveParams,\n  RunRetrieveResponse,\n  Runs,\n} from './runs/runs';\nimport { APIPromise } from '../../core/api-promise';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../../core/pagination';\nimport { RequestOptions } from '../../internal/request-options';\nimport { path } from '../../internal/utils/path';\n\nexport class Evals extends APIResource {\n  runs: RunsAPI.Runs = new RunsAPI.Runs(this._client);\n\n  /**\n   * Create the structure of an evaluation that can be used to test a model's\n   * performance. An evaluation is a set of testing criteria and the config for a\n   * data source, which dictates the schema of the data used in the evaluation. After\n   * creating an evaluation, you can run it on different models and model parameters.\n   * We support several types of graders and datasources. For more information, see\n   * the [Evals guide](https://platform.openai.com/docs/guides/evals).\n   */\n  create(body: EvalCreateParams, options?: RequestOptions): APIPromise<EvalCreateResponse> {\n    return this._client.post('/evals', { body, ...options });\n  }\n\n  /**\n   * Get an evaluation by ID.\n   */\n  retrieve(evalID: string, options?: RequestOptions): APIPromise<EvalRetrieveResponse> {\n    return this._client.get(path`/evals/${evalID}`, options);\n  }\n\n  /**\n   * Update certain properties of an evaluation.\n   */\n  update(evalID: string, body: EvalUpdateParams, options?: RequestOptions): APIPromise<EvalUpdateResponse> {\n    return this._client.post(path`/evals/${evalID}`, { body, ...options });\n  }\n\n  /**\n   * List evaluations for a project.\n   */\n  list(\n    query: EvalListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<EvalListResponsesPage, EvalListResponse> {\n    return this._client.getAPIList('/evals', CursorPage<EvalListResponse>, { query, ...options });\n  }\n\n  /**\n   * Delete an evaluation.\n   */\n  delete(evalID: string, options?: RequestOptions): APIPromise<EvalDeleteResponse> {\n    return this._client.delete(path`/evals/${evalID}`, options);\n  }\n}\n\nexport type EvalListResponsesPage = CursorPage<EvalListResponse>;\n\n/**\n * A CustomDataSourceConfig which specifies the schema of your `item` and\n * optionally `sample` namespaces. The response schema defines the shape of the\n * data that will be:\n *\n * - Used to define your testing criteria and\n * - What data is required when creating a run\n */\nexport interface EvalCustomDataSourceConfig {\n  /**\n   * The json schema for the run data source items. Learn how to build JSON schemas\n   * [here](https://json-schema.org/).\n   */\n  schema: { [key: string]: unknown };\n\n  /**\n   * The type of data source. Always `custom`.\n   */\n  type: 'custom';\n}\n\n/**\n * @deprecated Deprecated in favor of LogsDataSourceConfig.\n */\nexport interface EvalStoredCompletionsDataSourceConfig {\n  /**\n   * The json schema for the run data source items. Learn how to build JSON schemas\n   * [here](https://json-schema.org/).\n   */\n  schema: { [key: string]: unknown };\n\n  /**\n   * The type of data source. Always `stored_completions`.\n   */\n  type: 'stored_completions';\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n}\n\n/**\n * An Eval object with a data source config and testing criteria. An Eval\n * represents a task to be done for your LLM integration. Like:\n *\n * - Improve the quality of my chatbot\n * - See how well my chatbot handles customer support\n * - Check if o4-mini is better at my usecase than gpt-4o\n */\nexport interface EvalCreateResponse {\n  /**\n   * Unique identifier for the evaluation.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the eval was created.\n   */\n  created_at: number;\n\n  /**\n   * Configuration of data sources used in runs of the evaluation.\n   */\n  data_source_config:\n    | EvalCustomDataSourceConfig\n    | EvalCreateResponse.Logs\n    | EvalStoredCompletionsDataSourceConfig;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * The name of the evaluation.\n   */\n  name: string;\n\n  /**\n   * The object type.\n   */\n  object: 'eval';\n\n  /**\n   * A list of testing criteria.\n   */\n  testing_criteria: Array<\n    | GraderModelsAPI.LabelModelGrader\n    | GraderModelsAPI.StringCheckGrader\n    | EvalCreateResponse.EvalGraderTextSimilarity\n    | EvalCreateResponse.EvalGraderPython\n    | EvalCreateResponse.EvalGraderScoreModel\n  >;\n}\n\nexport namespace EvalCreateResponse {\n  /**\n   * A LogsDataSourceConfig which specifies the metadata property of your logs query.\n   * This is usually metadata like `usecase=chatbot` or `prompt-version=v2`, etc. The\n   * schema returned by this data source config is used to defined what variables are\n   * available in your evals. `item` and `sample` are both defined when using this\n   * data source config.\n   */\n  export interface Logs {\n    /**\n     * The json schema for the run data source items. Learn how to build JSON schemas\n     * [here](https://json-schema.org/).\n     */\n    schema: { [key: string]: unknown };\n\n    /**\n     * The type of data source. Always `logs`.\n     */\n    type: 'logs';\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format, and\n     * querying for objects via API or the dashboard.\n     *\n     * Keys are strings with a maximum length of 64 characters. Values are strings with\n     * a maximum length of 512 characters.\n     */\n    metadata?: Shared.Metadata | null;\n  }\n\n  /**\n   * A TextSimilarityGrader object which grades text based on similarity metrics.\n   */\n  export interface EvalGraderTextSimilarity extends GraderModelsAPI.TextSimilarityGrader {\n    /**\n     * The threshold for the score.\n     */\n    pass_threshold: number;\n  }\n\n  /**\n   * A PythonGrader object that runs a python script on the input.\n   */\n  export interface EvalGraderPython extends GraderModelsAPI.PythonGrader {\n    /**\n     * The threshold for the score.\n     */\n    pass_threshold?: number;\n  }\n\n  /**\n   * A ScoreModelGrader object that uses a model to assign a score to the input.\n   */\n  export interface EvalGraderScoreModel extends GraderModelsAPI.ScoreModelGrader {\n    /**\n     * The threshold for the score.\n     */\n    pass_threshold?: number;\n  }\n}\n\n/**\n * An Eval object with a data source config and testing criteria. An Eval\n * represents a task to be done for your LLM integration. Like:\n *\n * - Improve the quality of my chatbot\n * - See how well my chatbot handles customer support\n * - Check if o4-mini is better at my usecase than gpt-4o\n */\nexport interface EvalRetrieveResponse {\n  /**\n   * Unique identifier for the evaluation.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the eval was created.\n   */\n  created_at: number;\n\n  /**\n   * Configuration of data sources used in runs of the evaluation.\n   */\n  data_source_config:\n    | EvalCustomDataSourceConfig\n    | EvalRetrieveResponse.Logs\n    | EvalStoredCompletionsDataSourceConfig;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * The name of the evaluation.\n   */\n  name: string;\n\n  /**\n   * The object type.\n   */\n  object: 'eval';\n\n  /**\n   * A list of testing criteria.\n   */\n  testing_criteria: Array<\n    | GraderModelsAPI.LabelModelGrader\n    | GraderModelsAPI.StringCheckGrader\n    | EvalRetrieveResponse.EvalGraderTextSimilarity\n    | EvalRetrieveResponse.EvalGraderPython\n    | EvalRetrieveResponse.EvalGraderScoreModel\n  >;\n}\n\nexport namespace EvalRetrieveResponse {\n  /**\n   * A LogsDataSourceConfig which specifies the metadata property of your logs query.\n   * This is usually metadata like `usecase=chatbot` or `prompt-version=v2`, etc. The\n   * schema returned by this data source config is used to defined what variables are\n   * available in your evals. `item` and `sample` are both defined when using this\n   * data source config.\n   */\n  export interface Logs {\n    /**\n     * The json schema for the run data source items. Learn how to build JSON schemas\n     * [here](https://json-schema.org/).\n     */\n    schema: { [key: string]: unknown };\n\n    /**\n     * The type of data source. Always `logs`.\n     */\n    type: 'logs';\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format, and\n     * querying for objects via API or the dashboard.\n     *\n     * Keys are strings with a maximum length of 64 characters. Values are strings with\n     * a maximum length of 512 characters.\n     */\n    metadata?: Shared.Metadata | null;\n  }\n\n  /**\n   * A TextSimilarityGrader object which grades text based on similarity metrics.\n   */\n  export interface EvalGraderTextSimilarity extends GraderModelsAPI.TextSimilarityGrader {\n    /**\n     * The threshold for the score.\n     */\n    pass_threshold: number;\n  }\n\n  /**\n   * A PythonGrader object that runs a python script on the input.\n   */\n  export interface EvalGraderPython extends GraderModelsAPI.PythonGrader {\n    /**\n     * The threshold for the score.\n     */\n    pass_threshold?: number;\n  }\n\n  /**\n   * A ScoreModelGrader object that uses a model to assign a score to the input.\n   */\n  export interface EvalGraderScoreModel extends GraderModelsAPI.ScoreModelGrader {\n    /**\n     * The threshold for the score.\n     */\n    pass_threshold?: number;\n  }\n}\n\n/**\n * An Eval object with a data source config and testing criteria. An Eval\n * represents a task to be done for your LLM integration. Like:\n *\n * - Improve the quality of my chatbot\n * - See how well my chatbot handles customer support\n * - Check if o4-mini is better at my usecase than gpt-4o\n */\nexport interface EvalUpdateResponse {\n  /**\n   * Unique identifier for the evaluation.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the eval was created.\n   */\n  created_at: number;\n\n  /**\n   * Configuration of data sources used in runs of the evaluation.\n   */\n  data_source_config:\n    | EvalCustomDataSourceConfig\n    | EvalUpdateResponse.Logs\n    | EvalStoredCompletionsDataSourceConfig;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * The name of the evaluation.\n   */\n  name: string;\n\n  /**\n   * The object type.\n   */\n  object: 'eval';\n\n  /**\n   * A list of testing criteria.\n   */\n  testing_criteria: Array<\n    | GraderModelsAPI.LabelModelGrader\n    | GraderModelsAPI.StringCheckGrader\n    | EvalUpdateResponse.EvalGraderTextSimilarity\n    | EvalUpdateResponse.EvalGraderPython\n    | EvalUpdateResponse.EvalGraderScoreModel\n  >;\n}\n\nexport namespace EvalUpdateResponse {\n  /**\n   * A LogsDataSourceConfig which specifies the metadata property of your logs query.\n   * This is usually metadata like `usecase=chatbot` or `prompt-version=v2`, etc. The\n   * schema returned by this data source config is used to defined what variables are\n   * available in your evals. `item` and `sample` are both defined when using this\n   * data source config.\n   */\n  export interface Logs {\n    /**\n     * The json schema for the run data source items. Learn how to build JSON schemas\n     * [here](https://json-schema.org/).\n     */\n    schema: { [key: string]: unknown };\n\n    /**\n     * The type of data source. Always `logs`.\n     */\n    type: 'logs';\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format, and\n     * querying for objects via API or the dashboard.\n     *\n     * Keys are strings with a maximum length of 64 characters. Values are strings with\n     * a maximum length of 512 characters.\n     */\n    metadata?: Shared.Metadata | null;\n  }\n\n  /**\n   * A TextSimilarityGrader object which grades text based on similarity metrics.\n   */\n  export interface EvalGraderTextSimilarity extends GraderModelsAPI.TextSimilarityGrader {\n    /**\n     * The threshold for the score.\n     */\n    pass_threshold: number;\n  }\n\n  /**\n   * A PythonGrader object that runs a python script on the input.\n   */\n  export interface EvalGraderPython extends GraderModelsAPI.PythonGrader {\n    /**\n     * The threshold for the score.\n     */\n    pass_threshold?: number;\n  }\n\n  /**\n   * A ScoreModelGrader object that uses a model to assign a score to the input.\n   */\n  export interface EvalGraderScoreModel extends GraderModelsAPI.ScoreModelGrader {\n    /**\n     * The threshold for the score.\n     */\n    pass_threshold?: number;\n  }\n}\n\n/**\n * An Eval object with a data source config and testing criteria. An Eval\n * represents a task to be done for your LLM integration. Like:\n *\n * - Improve the quality of my chatbot\n * - See how well my chatbot handles customer support\n * - Check if o4-mini is better at my usecase than gpt-4o\n */\nexport interface EvalListResponse {\n  /**\n   * Unique identifier for the evaluation.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the eval was created.\n   */\n  created_at: number;\n\n  /**\n   * Configuration of data sources used in runs of the evaluation.\n   */\n  data_source_config:\n    | EvalCustomDataSourceConfig\n    | EvalListResponse.Logs\n    | EvalStoredCompletionsDataSourceConfig;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * The name of the evaluation.\n   */\n  name: string;\n\n  /**\n   * The object type.\n   */\n  object: 'eval';\n\n  /**\n   * A list of testing criteria.\n   */\n  testing_criteria: Array<\n    | GraderModelsAPI.LabelModelGrader\n    | GraderModelsAPI.StringCheckGrader\n    | EvalListResponse.EvalGraderTextSimilarity\n    | EvalListResponse.EvalGraderPython\n    | EvalListResponse.EvalGraderScoreModel\n  >;\n}\n\nexport namespace EvalListResponse {\n  /**\n   * A LogsDataSourceConfig which specifies the metadata property of your logs query.\n   * This is usually metadata like `usecase=chatbot` or `prompt-version=v2`, etc. The\n   * schema returned by this data source config is used to defined what variables are\n   * available in your evals. `item` and `sample` are both defined when using this\n   * data source config.\n   */\n  export interface Logs {\n    /**\n     * The json schema for the run data source items. Learn how to build JSON schemas\n     * [here](https://json-schema.org/).\n     */\n    schema: { [key: string]: unknown };\n\n    /**\n     * The type of data source. Always `logs`.\n     */\n    type: 'logs';\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format, and\n     * querying for objects via API or the dashboard.\n     *\n     * Keys are strings with a maximum length of 64 characters. Values are strings with\n     * a maximum length of 512 characters.\n     */\n    metadata?: Shared.Metadata | null;\n  }\n\n  /**\n   * A TextSimilarityGrader object which grades text based on similarity metrics.\n   */\n  export interface EvalGraderTextSimilarity extends GraderModelsAPI.TextSimilarityGrader {\n    /**\n     * The threshold for the score.\n     */\n    pass_threshold: number;\n  }\n\n  /**\n   * A PythonGrader object that runs a python script on the input.\n   */\n  export interface EvalGraderPython extends GraderModelsAPI.PythonGrader {\n    /**\n     * The threshold for the score.\n     */\n    pass_threshold?: number;\n  }\n\n  /**\n   * A ScoreModelGrader object that uses a model to assign a score to the input.\n   */\n  export interface EvalGraderScoreModel extends GraderModelsAPI.ScoreModelGrader {\n    /**\n     * The threshold for the score.\n     */\n    pass_threshold?: number;\n  }\n}\n\nexport interface EvalDeleteResponse {\n  deleted: boolean;\n\n  eval_id: string;\n\n  object: string;\n}\n\nexport interface EvalCreateParams {\n  /**\n   * The configuration for the data source used for the evaluation runs. Dictates the\n   * schema of the data used in the evaluation.\n   */\n  data_source_config: EvalCreateParams.Custom | EvalCreateParams.Logs | EvalCreateParams.StoredCompletions;\n\n  /**\n   * A list of graders for all eval runs in this group. Graders can reference\n   * variables in the data source using double curly braces notation, like\n   * `{{item.variable_name}}`. To reference the model's output, use the `sample`\n   * namespace (ie, `{{sample.output_text}}`).\n   */\n  testing_criteria: Array<\n    | EvalCreateParams.LabelModel\n    | GraderModelsAPI.StringCheckGrader\n    | EvalCreateParams.TextSimilarity\n    | EvalCreateParams.Python\n    | EvalCreateParams.ScoreModel\n  >;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The name of the evaluation.\n   */\n  name?: string;\n}\n\nexport namespace EvalCreateParams {\n  /**\n   * A CustomDataSourceConfig object that defines the schema for the data source used\n   * for the evaluation runs. This schema is used to define the shape of the data\n   * that will be:\n   *\n   * - Used to define your testing criteria and\n   * - What data is required when creating a run\n   */\n  export interface Custom {\n    /**\n     * The json schema for each row in the data source.\n     */\n    item_schema: { [key: string]: unknown };\n\n    /**\n     * The type of data source. Always `custom`.\n     */\n    type: 'custom';\n\n    /**\n     * Whether the eval should expect you to populate the sample namespace (ie, by\n     * generating responses off of your data source)\n     */\n    include_sample_schema?: boolean;\n  }\n\n  /**\n   * A data source config which specifies the metadata property of your logs query.\n   * This is usually metadata like `usecase=chatbot` or `prompt-version=v2`, etc.\n   */\n  export interface Logs {\n    /**\n     * The type of data source. Always `logs`.\n     */\n    type: 'logs';\n\n    /**\n     * Metadata filters for the logs data source.\n     */\n    metadata?: { [key: string]: unknown };\n  }\n\n  /**\n   * @deprecated Deprecated in favor of LogsDataSourceConfig.\n   */\n  export interface StoredCompletions {\n    /**\n     * The type of data source. Always `stored_completions`.\n     */\n    type: 'stored_completions';\n\n    /**\n     * Metadata filters for the stored completions data source.\n     */\n    metadata?: { [key: string]: unknown };\n  }\n\n  /**\n   * A LabelModelGrader object which uses a model to assign labels to each item in\n   * the evaluation.\n   */\n  export interface LabelModel {\n    /**\n     * A list of chat messages forming the prompt or context. May include variable\n     * references to the `item` namespace, ie {{item.name}}.\n     */\n    input: Array<LabelModel.SimpleInputMessage | LabelModel.EvalItem>;\n\n    /**\n     * The labels to classify to each item in the evaluation.\n     */\n    labels: Array<string>;\n\n    /**\n     * The model to use for the evaluation. Must support structured outputs.\n     */\n    model: string;\n\n    /**\n     * The name of the grader.\n     */\n    name: string;\n\n    /**\n     * The labels that indicate a passing result. Must be a subset of labels.\n     */\n    passing_labels: Array<string>;\n\n    /**\n     * The object type, which is always `label_model`.\n     */\n    type: 'label_model';\n  }\n\n  export namespace LabelModel {\n    export interface SimpleInputMessage {\n      /**\n       * The content of the message.\n       */\n      content: string;\n\n      /**\n       * The role of the message (e.g. \"system\", \"assistant\", \"user\").\n       */\n      role: string;\n    }\n\n    /**\n     * A message input to the model with a role indicating instruction following\n     * hierarchy. Instructions given with the `developer` or `system` role take\n     * precedence over instructions given with the `user` role. Messages with the\n     * `assistant` role are presumed to have been generated by the model in previous\n     * interactions.\n     */\n    export interface EvalItem {\n      /**\n       * Inputs to the model - can contain template strings.\n       */\n      content:\n        | string\n        | ResponsesAPI.ResponseInputText\n        | EvalItem.OutputText\n        | EvalItem.InputImage\n        | ResponsesAPI.ResponseInputAudio\n        | Array<unknown>;\n\n      /**\n       * The role of the message input. One of `user`, `assistant`, `system`, or\n       * `developer`.\n       */\n      role: 'user' | 'assistant' | 'system' | 'developer';\n\n      /**\n       * The type of the message input. Always `message`.\n       */\n      type?: 'message';\n    }\n\n    export namespace EvalItem {\n      /**\n       * A text output from the model.\n       */\n      export interface OutputText {\n        /**\n         * The text output from the model.\n         */\n        text: string;\n\n        /**\n         * The type of the output text. Always `output_text`.\n         */\n        type: 'output_text';\n      }\n\n      /**\n       * An image input to the model.\n       */\n      export interface InputImage {\n        /**\n         * The URL of the image input.\n         */\n        image_url: string;\n\n        /**\n         * The type of the image input. Always `input_image`.\n         */\n        type: 'input_image';\n\n        /**\n         * The detail level of the image to be sent to the model. One of `high`, `low`, or\n         * `auto`. Defaults to `auto`.\n         */\n        detail?: string;\n      }\n    }\n  }\n\n  /**\n   * A TextSimilarityGrader object which grades text based on similarity metrics.\n   */\n  export interface TextSimilarity extends GraderModelsAPI.TextSimilarityGrader {\n    /**\n     * The threshold for the score.\n     */\n    pass_threshold: number;\n  }\n\n  /**\n   * A PythonGrader object that runs a python script on the input.\n   */\n  export interface Python extends GraderModelsAPI.PythonGrader {\n    /**\n     * The threshold for the score.\n     */\n    pass_threshold?: number;\n  }\n\n  /**\n   * A ScoreModelGrader object that uses a model to assign a score to the input.\n   */\n  export interface ScoreModel extends GraderModelsAPI.ScoreModelGrader {\n    /**\n     * The threshold for the score.\n     */\n    pass_threshold?: number;\n  }\n}\n\nexport interface EvalUpdateParams {\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * Rename the evaluation.\n   */\n  name?: string;\n}\n\nexport interface EvalListParams extends CursorPageParams {\n  /**\n   * Sort order for evals by timestamp. Use `asc` for ascending order or `desc` for\n   * descending order.\n   */\n  order?: 'asc' | 'desc';\n\n  /**\n   * Evals can be ordered by creation time or last updated time. Use `created_at` for\n   * creation time or `updated_at` for last updated time.\n   */\n  order_by?: 'created_at' | 'updated_at';\n}\n\nEvals.Runs = Runs;\n\nexport declare namespace Evals {\n  export {\n    type EvalCustomDataSourceConfig as EvalCustomDataSourceConfig,\n    type EvalStoredCompletionsDataSourceConfig as EvalStoredCompletionsDataSourceConfig,\n    type EvalCreateResponse as EvalCreateResponse,\n    type EvalRetrieveResponse as EvalRetrieveResponse,\n    type EvalUpdateResponse as EvalUpdateResponse,\n    type EvalListResponse as EvalListResponse,\n    type EvalDeleteResponse as EvalDeleteResponse,\n    type EvalListResponsesPage as EvalListResponsesPage,\n    type EvalCreateParams as EvalCreateParams,\n    type EvalUpdateParams as EvalUpdateParams,\n    type EvalListParams as EvalListParams,\n  };\n\n  export {\n    Runs as Runs,\n    type CreateEvalCompletionsRunDataSource as CreateEvalCompletionsRunDataSource,\n    type CreateEvalJSONLRunDataSource as CreateEvalJSONLRunDataSource,\n    type EvalAPIError as EvalAPIError,\n    type RunCreateResponse as RunCreateResponse,\n    type RunRetrieveResponse as RunRetrieveResponse,\n    type RunListResponse as RunListResponse,\n    type RunDeleteResponse as RunDeleteResponse,\n    type RunCancelResponse as RunCancelResponse,\n    type RunListResponsesPage as RunListResponsesPage,\n    type RunCreateParams as RunCreateParams,\n    type RunRetrieveParams as RunRetrieveParams,\n    type RunListParams as RunListParams,\n    type RunDeleteParams as RunDeleteParams,\n    type RunCancelParams as RunCancelParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as AudioAPI from './audio';\nimport * as TranscriptionsAPI from './transcriptions';\nimport { APIPromise } from '../../core/api-promise';\nimport { type Uploadable } from '../../core/uploads';\nimport { RequestOptions } from '../../internal/request-options';\nimport { multipartFormRequestOptions } from '../../internal/uploads';\n\nexport class Translations extends APIResource {\n  /**\n   * Translates audio into English.\n   *\n   * @example\n   * ```ts\n   * const translation = await client.audio.translations.create({\n   *   file: fs.createReadStream('speech.mp3'),\n   *   model: 'whisper-1',\n   * });\n   * ```\n   */\n  create(\n    body: TranslationCreateParams<'json' | undefined>,\n    options?: RequestOptions,\n  ): APIPromise<Translation>;\n  create(\n    body: TranslationCreateParams<'verbose_json'>,\n    options?: RequestOptions,\n  ): APIPromise<TranslationVerbose>;\n  create(body: TranslationCreateParams<'text' | 'srt' | 'vtt'>, options?: RequestOptions): APIPromise<string>;\n  create(body: TranslationCreateParams, options?: RequestOptions): APIPromise<Translation>;\n  create(\n    body: TranslationCreateParams,\n    options?: RequestOptions,\n  ): APIPromise<TranslationCreateResponse | string> {\n    return this._client.post(\n      '/audio/translations',\n      multipartFormRequestOptions({ body, ...options, __metadata: { model: body.model } }, this._client),\n    );\n  }\n}\n\nexport interface Translation {\n  text: string;\n}\n\nexport interface TranslationVerbose {\n  /**\n   * The duration of the input audio.\n   */\n  duration: number;\n\n  /**\n   * The language of the output translation (always `english`).\n   */\n  language: string;\n\n  /**\n   * The translated text.\n   */\n  text: string;\n\n  /**\n   * Segments of the translated text and their corresponding details.\n   */\n  segments?: Array<TranscriptionsAPI.TranscriptionSegment>;\n}\n\nexport type TranslationCreateResponse = Translation | TranslationVerbose;\n\nexport interface TranslationCreateParams<\n  ResponseFormat extends AudioAPI.AudioResponseFormat | undefined = AudioAPI.AudioResponseFormat | undefined,\n> {\n  /**\n   * The audio file object (not file name) translate, in one of these formats: flac,\n   * mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.\n   */\n  file: Uploadable;\n\n  /**\n   * ID of the model to use. Only `whisper-1` (which is powered by our open source\n   * Whisper V2 model) is currently available.\n   */\n  model: (string & {}) | AudioAPI.AudioModel;\n\n  /**\n   * An optional text to guide the model's style or continue a previous audio\n   * segment. The\n   * [prompt](https://platform.openai.com/docs/guides/speech-to-text#prompting)\n   * should be in English.\n   */\n  prompt?: string;\n\n  /**\n   * The format of the output, in one of these options: `json`, `text`, `srt`,\n   * `verbose_json`, or `vtt`.\n   */\n  response_format?: 'json' | 'text' | 'srt' | 'verbose_json' | 'vtt';\n\n  /**\n   * The sampling temperature, between 0 and 1. Higher values like 0.8 will make the\n   * output more random, while lower values like 0.2 will make it more focused and\n   * deterministic. If set to 0, the model will use\n   * [log probability](https://en.wikipedia.org/wiki/Log_probability) to\n   * automatically increase the temperature until certain thresholds are hit.\n   */\n  temperature?: number;\n}\n\nexport declare namespace Translations {\n  export {\n    type Translation as Translation,\n    type TranslationVerbose as TranslationVerbose,\n    type TranslationCreateResponse as TranslationCreateResponse,\n    type TranslationCreateParams as TranslationCreateParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../core/resource';\nimport { APIPromise } from '../core/api-promise';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../core/pagination';\nimport { type Uploadable } from '../core/uploads';\nimport { buildHeaders } from '../internal/headers';\nimport { RequestOptions } from '../internal/request-options';\nimport { sleep } from '../internal/utils/sleep';\nimport { APIConnectionTimeoutError } from '../error';\nimport { multipartFormRequestOptions } from '../internal/uploads';\nimport { path } from '../internal/utils/path';\n\nexport class Files extends APIResource {\n  /**\n   * Upload a file that can be used across various endpoints. Individual files can be\n   * up to 512 MB, and the size of all files uploaded by one organization can be up\n   * to 1 TB.\n   *\n   * - The Assistants API supports files up to 2 million tokens and of specific file\n   *   types. See the\n   *   [Assistants Tools guide](https://platform.openai.com/docs/assistants/tools)\n   *   for details.\n   * - The Fine-tuning API only supports `.jsonl` files. The input also has certain\n   *   required formats for fine-tuning\n   *   [chat](https://platform.openai.com/docs/api-reference/fine-tuning/chat-input)\n   *   or\n   *   [completions](https://platform.openai.com/docs/api-reference/fine-tuning/completions-input)\n   *   models.\n   * - The Batch API only supports `.jsonl` files up to 200 MB in size. The input\n   *   also has a specific required\n   *   [format](https://platform.openai.com/docs/api-reference/batch/request-input).\n   *\n   * Please [contact us](https://help.openai.com/) if you need to increase these\n   * storage limits.\n   */\n  create(body: FileCreateParams, options?: RequestOptions): APIPromise<FileObject> {\n    return this._client.post('/files', multipartFormRequestOptions({ body, ...options }, this._client));\n  }\n\n  /**\n   * Returns information about a specific file.\n   */\n  retrieve(fileID: string, options?: RequestOptions): APIPromise<FileObject> {\n    return this._client.get(path`/files/${fileID}`, options);\n  }\n\n  /**\n   * Returns a list of files.\n   */\n  list(\n    query: FileListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<FileObjectsPage, FileObject> {\n    return this._client.getAPIList('/files', CursorPage<FileObject>, { query, ...options });\n  }\n\n  /**\n   * Delete a file and remove it from all vector stores.\n   */\n  delete(fileID: string, options?: RequestOptions): APIPromise<FileDeleted> {\n    return this._client.delete(path`/files/${fileID}`, options);\n  }\n\n  /**\n   * Returns the contents of the specified file.\n   */\n  content(fileID: string, options?: RequestOptions): APIPromise<Response> {\n    return this._client.get(path`/files/${fileID}/content`, {\n      ...options,\n      headers: buildHeaders([{ Accept: 'application/binary' }, options?.headers]),\n      __binaryResponse: true,\n    });\n  }\n\n  /**\n   * Waits for the given file to be processed, default timeout is 30 mins.\n   */\n  async waitForProcessing(\n    id: string,\n    { pollInterval = 5000, maxWait = 30 * 60 * 1000 }: { pollInterval?: number; maxWait?: number } = {},\n  ): Promise<FileObject> {\n    const TERMINAL_STATES = new Set(['processed', 'error', 'deleted']);\n\n    const start = Date.now();\n    let file = await this.retrieve(id);\n\n    while (!file.status || !TERMINAL_STATES.has(file.status)) {\n      await sleep(pollInterval);\n\n      file = await this.retrieve(id);\n      if (Date.now() - start > maxWait) {\n        throw new APIConnectionTimeoutError({\n          message: `Giving up on waiting for file ${id} to finish processing after ${maxWait} milliseconds.`,\n        });\n      }\n    }\n\n    return file;\n  }\n}\n\nexport type FileObjectsPage = CursorPage<FileObject>;\n\nexport type FileContent = string;\n\nexport interface FileDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'file';\n}\n\n/**\n * The `File` object represents a document that has been uploaded to OpenAI.\n */\nexport interface FileObject {\n  /**\n   * The file identifier, which can be referenced in the API endpoints.\n   */\n  id: string;\n\n  /**\n   * The size of the file, in bytes.\n   */\n  bytes: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the file was created.\n   */\n  created_at: number;\n\n  /**\n   * The name of the file.\n   */\n  filename: string;\n\n  /**\n   * The object type, which is always `file`.\n   */\n  object: 'file';\n\n  /**\n   * The intended purpose of the file. Supported values are `assistants`,\n   * `assistants_output`, `batch`, `batch_output`, `fine-tune`, `fine-tune-results`,\n   * `vision`, and `user_data`.\n   */\n  purpose:\n    | 'assistants'\n    | 'assistants_output'\n    | 'batch'\n    | 'batch_output'\n    | 'fine-tune'\n    | 'fine-tune-results'\n    | 'vision'\n    | 'user_data';\n\n  /**\n   * @deprecated Deprecated. The current status of the file, which can be either\n   * `uploaded`, `processed`, or `error`.\n   */\n  status: 'uploaded' | 'processed' | 'error';\n\n  /**\n   * The Unix timestamp (in seconds) for when the file will expire.\n   */\n  expires_at?: number;\n\n  /**\n   * @deprecated Deprecated. For details on why a fine-tuning training file failed\n   * validation, see the `error` field on `fine_tuning.job`.\n   */\n  status_details?: string;\n}\n\n/**\n * The intended purpose of the uploaded file. One of: - `assistants`: Used in the\n * Assistants API - `batch`: Used in the Batch API - `fine-tune`: Used for\n * fine-tuning - `vision`: Images used for vision fine-tuning - `user_data`:\n * Flexible file type for any purpose - `evals`: Used for eval data sets\n */\nexport type FilePurpose = 'assistants' | 'batch' | 'fine-tune' | 'vision' | 'user_data' | 'evals';\n\nexport interface FileCreateParams {\n  /**\n   * The File object (not file name) to be uploaded.\n   */\n  file: Uploadable;\n\n  /**\n   * The intended purpose of the uploaded file. One of: - `assistants`: Used in the\n   * Assistants API - `batch`: Used in the Batch API - `fine-tune`: Used for\n   * fine-tuning - `vision`: Images used for vision fine-tuning - `user_data`:\n   * Flexible file type for any purpose - `evals`: Used for eval data sets\n   */\n  purpose: FilePurpose;\n\n  /**\n   * The expiration policy for a file. By default, files with `purpose=batch` expire\n   * after 30 days and all other files are persisted until they are manually deleted.\n   */\n  expires_after?: FileCreateParams.ExpiresAfter;\n}\n\nexport namespace FileCreateParams {\n  /**\n   * The expiration policy for a file. By default, files with `purpose=batch` expire\n   * after 30 days and all other files are persisted until they are manually deleted.\n   */\n  export interface ExpiresAfter {\n    /**\n     * Anchor timestamp after which the expiration policy applies. Supported anchors:\n     * `created_at`.\n     */\n    anchor: 'created_at';\n\n    /**\n     * The number of seconds after the anchor time that the file will expire. Must be\n     * between 3600 (1 hour) and 2592000 (30 days).\n     */\n    seconds: number;\n  }\n}\n\nexport interface FileListParams extends CursorPageParams {\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n\n  /**\n   * Only return files with the given purpose.\n   */\n  purpose?: string;\n}\n\nexport declare namespace Files {\n  export {\n    type FileContent as FileContent,\n    type FileDeleted as FileDeleted,\n    type FileObject as FileObject,\n    type FilePurpose as FilePurpose,\n    type FileObjectsPage as FileObjectsPage,\n    type FileCreateParams as FileCreateParams,\n    type FileListParams as FileListParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as GraderModelsAPI from '../graders/grader-models';\n\nexport class Methods extends APIResource {}\n\n/**\n * The hyperparameters used for the DPO fine-tuning job.\n */\nexport interface DpoHyperparameters {\n  /**\n   * Number of examples in each batch. A larger batch size means that model\n   * parameters are updated less frequently, but with lower variance.\n   */\n  batch_size?: 'auto' | number;\n\n  /**\n   * The beta value for the DPO method. A higher beta value will increase the weight\n   * of the penalty between the policy and reference model.\n   */\n  beta?: 'auto' | number;\n\n  /**\n   * Scaling factor for the learning rate. A smaller learning rate may be useful to\n   * avoid overfitting.\n   */\n  learning_rate_multiplier?: 'auto' | number;\n\n  /**\n   * The number of epochs to train the model for. An epoch refers to one full cycle\n   * through the training dataset.\n   */\n  n_epochs?: 'auto' | number;\n}\n\n/**\n * Configuration for the DPO fine-tuning method.\n */\nexport interface DpoMethod {\n  /**\n   * The hyperparameters used for the DPO fine-tuning job.\n   */\n  hyperparameters?: DpoHyperparameters;\n}\n\n/**\n * The hyperparameters used for the reinforcement fine-tuning job.\n */\nexport interface ReinforcementHyperparameters {\n  /**\n   * Number of examples in each batch. A larger batch size means that model\n   * parameters are updated less frequently, but with lower variance.\n   */\n  batch_size?: 'auto' | number;\n\n  /**\n   * Multiplier on amount of compute used for exploring search space during training.\n   */\n  compute_multiplier?: 'auto' | number;\n\n  /**\n   * The number of training steps between evaluation runs.\n   */\n  eval_interval?: 'auto' | number;\n\n  /**\n   * Number of evaluation samples to generate per training step.\n   */\n  eval_samples?: 'auto' | number;\n\n  /**\n   * Scaling factor for the learning rate. A smaller learning rate may be useful to\n   * avoid overfitting.\n   */\n  learning_rate_multiplier?: 'auto' | number;\n\n  /**\n   * The number of epochs to train the model for. An epoch refers to one full cycle\n   * through the training dataset.\n   */\n  n_epochs?: 'auto' | number;\n\n  /**\n   * Level of reasoning effort.\n   */\n  reasoning_effort?: 'default' | 'low' | 'medium' | 'high';\n}\n\n/**\n * Configuration for the reinforcement fine-tuning method.\n */\nexport interface ReinforcementMethod {\n  /**\n   * The grader used for the fine-tuning job.\n   */\n  grader:\n    | GraderModelsAPI.StringCheckGrader\n    | GraderModelsAPI.TextSimilarityGrader\n    | GraderModelsAPI.PythonGrader\n    | GraderModelsAPI.ScoreModelGrader\n    | GraderModelsAPI.MultiGrader;\n\n  /**\n   * The hyperparameters used for the reinforcement fine-tuning job.\n   */\n  hyperparameters?: ReinforcementHyperparameters;\n}\n\n/**\n * The hyperparameters used for the fine-tuning job.\n */\nexport interface SupervisedHyperparameters {\n  /**\n   * Number of examples in each batch. A larger batch size means that model\n   * parameters are updated less frequently, but with lower variance.\n   */\n  batch_size?: 'auto' | number;\n\n  /**\n   * Scaling factor for the learning rate. A smaller learning rate may be useful to\n   * avoid overfitting.\n   */\n  learning_rate_multiplier?: 'auto' | number;\n\n  /**\n   * The number of epochs to train the model for. An epoch refers to one full cycle\n   * through the training dataset.\n   */\n  n_epochs?: 'auto' | number;\n}\n\n/**\n * Configuration for the supervised fine-tuning method.\n */\nexport interface SupervisedMethod {\n  /**\n   * The hyperparameters used for the fine-tuning job.\n   */\n  hyperparameters?: SupervisedHyperparameters;\n}\n\nexport declare namespace Methods {\n  export {\n    type DpoHyperparameters as DpoHyperparameters,\n    type DpoMethod as DpoMethod,\n    type ReinforcementHyperparameters as ReinforcementHyperparameters,\n    type ReinforcementMethod as ReinforcementMethod,\n    type SupervisedHyperparameters as SupervisedHyperparameters,\n    type SupervisedMethod as SupervisedMethod,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport * as GraderModelsAPI from '../../graders/grader-models';\nimport { APIPromise } from '../../../core/api-promise';\nimport { RequestOptions } from '../../../internal/request-options';\n\nexport class Graders extends APIResource {\n  /**\n   * Run a grader.\n   *\n   * @example\n   * ```ts\n   * const response = await client.fineTuning.alpha.graders.run({\n   *   grader: {\n   *     input: 'input',\n   *     name: 'name',\n   *     operation: 'eq',\n   *     reference: 'reference',\n   *     type: 'string_check',\n   *   },\n   *   model_sample: 'model_sample',\n   * });\n   * ```\n   */\n  run(body: GraderRunParams, options?: RequestOptions): APIPromise<GraderRunResponse> {\n    return this._client.post('/fine_tuning/alpha/graders/run', { body, ...options });\n  }\n\n  /**\n   * Validate a grader.\n   *\n   * @example\n   * ```ts\n   * const response =\n   *   await client.fineTuning.alpha.graders.validate({\n   *     grader: {\n   *       input: 'input',\n   *       name: 'name',\n   *       operation: 'eq',\n   *       reference: 'reference',\n   *       type: 'string_check',\n   *     },\n   *   });\n   * ```\n   */\n  validate(body: GraderValidateParams, options?: RequestOptions): APIPromise<GraderValidateResponse> {\n    return this._client.post('/fine_tuning/alpha/graders/validate', { body, ...options });\n  }\n}\n\nexport interface GraderRunResponse {\n  metadata: GraderRunResponse.Metadata;\n\n  model_grader_token_usage_per_model: { [key: string]: unknown };\n\n  reward: number;\n\n  sub_rewards: { [key: string]: unknown };\n}\n\nexport namespace GraderRunResponse {\n  export interface Metadata {\n    errors: Metadata.Errors;\n\n    execution_time: number;\n\n    name: string;\n\n    sampled_model_name: string | null;\n\n    scores: { [key: string]: unknown };\n\n    token_usage: number | null;\n\n    type: string;\n  }\n\n  export namespace Metadata {\n    export interface Errors {\n      formula_parse_error: boolean;\n\n      invalid_variable_error: boolean;\n\n      model_grader_parse_error: boolean;\n\n      model_grader_refusal_error: boolean;\n\n      model_grader_server_error: boolean;\n\n      model_grader_server_error_details: string | null;\n\n      other_error: boolean;\n\n      python_grader_runtime_error: boolean;\n\n      python_grader_runtime_error_details: string | null;\n\n      python_grader_server_error: boolean;\n\n      python_grader_server_error_type: string | null;\n\n      sample_parse_error: boolean;\n\n      truncated_observation_error: boolean;\n\n      unresponsive_reward_error: boolean;\n    }\n  }\n}\n\nexport interface GraderValidateResponse {\n  /**\n   * The grader used for the fine-tuning job.\n   */\n  grader?:\n    | GraderModelsAPI.StringCheckGrader\n    | GraderModelsAPI.TextSimilarityGrader\n    | GraderModelsAPI.PythonGrader\n    | GraderModelsAPI.ScoreModelGrader\n    | GraderModelsAPI.MultiGrader;\n}\n\nexport interface GraderRunParams {\n  /**\n   * The grader used for the fine-tuning job.\n   */\n  grader:\n    | GraderModelsAPI.StringCheckGrader\n    | GraderModelsAPI.TextSimilarityGrader\n    | GraderModelsAPI.PythonGrader\n    | GraderModelsAPI.ScoreModelGrader\n    | GraderModelsAPI.MultiGrader;\n\n  /**\n   * The model sample to be evaluated. This value will be used to populate the\n   * `sample` namespace. See\n   * [the guide](https://platform.openai.com/docs/guides/graders) for more details.\n   * The `output_json` variable will be populated if the model sample is a valid JSON\n   * string.\n   */\n  model_sample: string;\n\n  /**\n   * The dataset item provided to the grader. This will be used to populate the\n   * `item` namespace. See\n   * [the guide](https://platform.openai.com/docs/guides/graders) for more details.\n   */\n  item?: unknown;\n}\n\nexport interface GraderValidateParams {\n  /**\n   * The grader used for the fine-tuning job.\n   */\n  grader:\n    | GraderModelsAPI.StringCheckGrader\n    | GraderModelsAPI.TextSimilarityGrader\n    | GraderModelsAPI.PythonGrader\n    | GraderModelsAPI.ScoreModelGrader\n    | GraderModelsAPI.MultiGrader;\n}\n\nexport declare namespace Graders {\n  export {\n    type GraderRunResponse as GraderRunResponse,\n    type GraderValidateResponse as GraderValidateResponse,\n    type GraderRunParams as GraderRunParams,\n    type GraderValidateParams as GraderValidateParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { VERSION } from '../version';\n\nexport const isRunningInBrowser = () => {\n  return (\n    // @ts-ignore\n    typeof window !== 'undefined' &&\n    // @ts-ignore\n    typeof window.document !== 'undefined' &&\n    // @ts-ignore\n    typeof navigator !== 'undefined'\n  );\n};\n\ntype DetectedPlatform = 'deno' | 'node' | 'edge' | 'unknown';\n\n/**\n * Note this does not detect 'browser'; for that, use getBrowserInfo().\n */\nfunction getDetectedPlatform(): DetectedPlatform {\n  if (typeof Deno !== 'undefined' && Deno.build != null) {\n    return 'deno';\n  }\n  if (typeof EdgeRuntime !== 'undefined') {\n    return 'edge';\n  }\n  if (\n    Object.prototype.toString.call(\n      typeof (globalThis as any).process !== 'undefined' ? (globalThis as any).process : 0,\n    ) === '[object process]'\n  ) {\n    return 'node';\n  }\n  return 'unknown';\n}\n\ndeclare const Deno: any;\ndeclare const EdgeRuntime: any;\ntype Arch = 'x32' | 'x64' | 'arm' | 'arm64' | `other:${string}` | 'unknown';\ntype PlatformName =\n  | 'MacOS'\n  | 'Linux'\n  | 'Windows'\n  | 'FreeBSD'\n  | 'OpenBSD'\n  | 'iOS'\n  | 'Android'\n  | `Other:${string}`\n  | 'Unknown';\ntype Browser = 'ie' | 'edge' | 'chrome' | 'firefox' | 'safari';\ntype PlatformProperties = {\n  'X-Stainless-Lang': 'js';\n  'X-Stainless-Package-Version': string;\n  'X-Stainless-OS': PlatformName;\n  'X-Stainless-Arch': Arch;\n  'X-Stainless-Runtime': 'node' | 'deno' | 'edge' | `browser:${Browser}` | 'unknown';\n  'X-Stainless-Runtime-Version': string;\n};\nconst getPlatformProperties = (): PlatformProperties => {\n  const detectedPlatform = getDetectedPlatform();\n  if (detectedPlatform === 'deno') {\n    return {\n      'X-Stainless-Lang': 'js',\n      'X-Stainless-Package-Version': VERSION,\n      'X-Stainless-OS': normalizePlatform(Deno.build.os),\n      'X-Stainless-Arch': normalizeArch(Deno.build.arch),\n      'X-Stainless-Runtime': 'deno',\n      'X-Stainless-Runtime-Version':\n        typeof Deno.version === 'string' ? Deno.version : Deno.version?.deno ?? 'unknown',\n    };\n  }\n  if (typeof EdgeRuntime !== 'undefined') {\n    return {\n      'X-Stainless-Lang': 'js',\n      'X-Stainless-Package-Version': VERSION,\n      'X-Stainless-OS': 'Unknown',\n      'X-Stainless-Arch': `other:${EdgeRuntime}`,\n      'X-Stainless-Runtime': 'edge',\n      'X-Stainless-Runtime-Version': (globalThis as any).process.version,\n    };\n  }\n  // Check if Node.js\n  if (detectedPlatform === 'node') {\n    return {\n      'X-Stainless-Lang': 'js',\n      'X-Stainless-Package-Version': VERSION,\n      'X-Stainless-OS': normalizePlatform((globalThis as any).process.platform ?? 'unknown'),\n      'X-Stainless-Arch': normalizeArch((globalThis as any).process.arch ?? 'unknown'),\n      'X-Stainless-Runtime': 'node',\n      'X-Stainless-Runtime-Version': (globalThis as any).process.version ?? 'unknown',\n    };\n  }\n\n  const browserInfo = getBrowserInfo();\n  if (browserInfo) {\n    return {\n      'X-Stainless-Lang': 'js',\n      'X-Stainless-Package-Version': VERSION,\n      'X-Stainless-OS': 'Unknown',\n      'X-Stainless-Arch': 'unknown',\n      'X-Stainless-Runtime': `browser:${browserInfo.browser}`,\n      'X-Stainless-Runtime-Version': browserInfo.version,\n    };\n  }\n\n  // TODO add support for Cloudflare workers, etc.\n  return {\n    'X-Stainless-Lang': 'js',\n    'X-Stainless-Package-Version': VERSION,\n    'X-Stainless-OS': 'Unknown',\n    'X-Stainless-Arch': 'unknown',\n    'X-Stainless-Runtime': 'unknown',\n    'X-Stainless-Runtime-Version': 'unknown',\n  };\n};\n\ntype BrowserInfo = {\n  browser: Browser;\n  version: string;\n};\n\ndeclare const navigator: { userAgent: string } | undefined;\n\n// Note: modified from https://github.com/JS-DevTools/host-environment/blob/b1ab79ecde37db5d6e163c050e54fe7d287d7c92/src/isomorphic.browser.ts\nfunction getBrowserInfo(): BrowserInfo | null {\n  if (typeof navigator === 'undefined' || !navigator) {\n    return null;\n  }\n\n  // NOTE: The order matters here!\n  const browserPatterns = [\n    { key: 'edge' as const, pattern: /Edge(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n    { key: 'ie' as const, pattern: /MSIE(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n    { key: 'ie' as const, pattern: /Trident(?:.*rv\\:(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n    { key: 'chrome' as const, pattern: /Chrome(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n    { key: 'firefox' as const, pattern: /Firefox(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n    { key: 'safari' as const, pattern: /(?:Version\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?(?:\\W+Mobile\\S*)?\\W+Safari/ },\n  ];\n\n  // Find the FIRST matching browser\n  for (const { key, pattern } of browserPatterns) {\n    const match = pattern.exec(navigator.userAgent);\n    if (match) {\n      const major = match[1] || 0;\n      const minor = match[2] || 0;\n      const patch = match[3] || 0;\n\n      return { browser: key, version: `${major}.${minor}.${patch}` };\n    }\n  }\n\n  return null;\n}\n\nconst normalizeArch = (arch: string): Arch => {\n  // Node docs:\n  // - https://nodejs.org/api/process.html#processarch\n  // Deno docs:\n  // - https://doc.deno.land/deno/stable/~/Deno.build\n  if (arch === 'x32') return 'x32';\n  if (arch === 'x86_64' || arch === 'x64') return 'x64';\n  if (arch === 'arm') return 'arm';\n  if (arch === 'aarch64' || arch === 'arm64') return 'arm64';\n  if (arch) return `other:${arch}`;\n  return 'unknown';\n};\n\nconst normalizePlatform = (platform: string): PlatformName => {\n  // Node platforms:\n  // - https://nodejs.org/api/process.html#processplatform\n  // Deno platforms:\n  // - https://doc.deno.land/deno/stable/~/Deno.build\n  // - https://github.com/denoland/deno/issues/14799\n\n  platform = platform.toLowerCase();\n\n  // NOTE: this iOS check is untested and may not work\n  // Node does not work natively on IOS, there is a fork at\n  // https://github.com/nodejs-mobile/nodejs-mobile\n  // however it is unknown at the time of writing how to detect if it is running\n  if (platform.includes('ios')) return 'iOS';\n  if (platform === 'android') return 'Android';\n  if (platform === 'darwin') return 'MacOS';\n  if (platform === 'win32') return 'Windows';\n  if (platform === 'freebsd') return 'FreeBSD';\n  if (platform === 'openbsd') return 'OpenBSD';\n  if (platform === 'linux') return 'Linux';\n  if (platform) return `Other:${platform}`;\n  return 'Unknown';\n};\n\nlet _platformHeaders: PlatformProperties;\nexport const getPlatformHeaders = () => {\n  return (_platformHeaders ??= getPlatformProperties());\n};\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport * as GradersAPI from './graders';\nimport {\n  GraderRunParams,\n  GraderRunResponse,\n  GraderValidateParams,\n  GraderValidateResponse,\n  Graders,\n} from './graders';\n\nexport class Alpha extends APIResource {\n  graders: GradersAPI.Graders = new GradersAPI.Graders(this._client);\n}\n\nAlpha.Graders = Graders;\n\nexport declare namespace Alpha {\n  export {\n    Graders as Graders,\n    type GraderRunResponse as GraderRunResponse,\n    type GraderValidateResponse as GraderValidateResponse,\n    type GraderRunParams as GraderRunParams,\n    type GraderValidateParams as GraderValidateParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport { APIPromise } from '../../../core/api-promise';\nimport { Page, PagePromise } from '../../../core/pagination';\nimport { RequestOptions } from '../../../internal/request-options';\nimport { path } from '../../../internal/utils/path';\n\nexport class Permissions extends APIResource {\n  /**\n   * **NOTE:** Calling this endpoint requires an [admin API key](../admin-api-keys).\n   *\n   * This enables organization owners to share fine-tuned models with other projects\n   * in their organization.\n   *\n   * @example\n   * ```ts\n   * // Automatically fetches more pages as needed.\n   * for await (const permissionCreateResponse of client.fineTuning.checkpoints.permissions.create(\n   *   'ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd',\n   *   { project_ids: ['string'] },\n   * )) {\n   *   // ...\n   * }\n   * ```\n   */\n  create(\n    fineTunedModelCheckpoint: string,\n    body: PermissionCreateParams,\n    options?: RequestOptions,\n  ): PagePromise<PermissionCreateResponsesPage, PermissionCreateResponse> {\n    return this._client.getAPIList(\n      path`/fine_tuning/checkpoints/${fineTunedModelCheckpoint}/permissions`,\n      Page<PermissionCreateResponse>,\n      { body, method: 'post', ...options },\n    );\n  }\n\n  /**\n   * **NOTE:** This endpoint requires an [admin API key](../admin-api-keys).\n   *\n   * Organization owners can use this endpoint to view all permissions for a\n   * fine-tuned model checkpoint.\n   *\n   * @example\n   * ```ts\n   * const permission =\n   *   await client.fineTuning.checkpoints.permissions.retrieve(\n   *     'ft-AF1WoRqd3aJAHsqc9NY7iL8F',\n   *   );\n   * ```\n   */\n  retrieve(\n    fineTunedModelCheckpoint: string,\n    query: PermissionRetrieveParams | null | undefined = {},\n    options?: RequestOptions,\n  ): APIPromise<PermissionRetrieveResponse> {\n    return this._client.get(path`/fine_tuning/checkpoints/${fineTunedModelCheckpoint}/permissions`, {\n      query,\n      ...options,\n    });\n  }\n\n  /**\n   * **NOTE:** This endpoint requires an [admin API key](../admin-api-keys).\n   *\n   * Organization owners can use this endpoint to delete a permission for a\n   * fine-tuned model checkpoint.\n   *\n   * @example\n   * ```ts\n   * const permission =\n   *   await client.fineTuning.checkpoints.permissions.delete(\n   *     'cp_zc4Q7MP6XxulcVzj4MZdwsAB',\n   *     {\n   *       fine_tuned_model_checkpoint:\n   *         'ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd',\n   *     },\n   *   );\n   * ```\n   */\n  delete(\n    permissionID: string,\n    params: PermissionDeleteParams,\n    options?: RequestOptions,\n  ): APIPromise<PermissionDeleteResponse> {\n    const { fine_tuned_model_checkpoint } = params;\n    return this._client.delete(\n      path`/fine_tuning/checkpoints/${fine_tuned_model_checkpoint}/permissions/${permissionID}`,\n      options,\n    );\n  }\n}\n\n// Note: no pagination actually occurs yet, this is for forwards-compatibility.\nexport type PermissionCreateResponsesPage = Page<PermissionCreateResponse>;\n\n/**\n * The `checkpoint.permission` object represents a permission for a fine-tuned\n * model checkpoint.\n */\nexport interface PermissionCreateResponse {\n  /**\n   * The permission identifier, which can be referenced in the API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the permission was created.\n   */\n  created_at: number;\n\n  /**\n   * The object type, which is always \"checkpoint.permission\".\n   */\n  object: 'checkpoint.permission';\n\n  /**\n   * The project identifier that the permission is for.\n   */\n  project_id: string;\n}\n\nexport interface PermissionRetrieveResponse {\n  data: Array<PermissionRetrieveResponse.Data>;\n\n  has_more: boolean;\n\n  object: 'list';\n\n  first_id?: string | null;\n\n  last_id?: string | null;\n}\n\nexport namespace PermissionRetrieveResponse {\n  /**\n   * The `checkpoint.permission` object represents a permission for a fine-tuned\n   * model checkpoint.\n   */\n  export interface Data {\n    /**\n     * The permission identifier, which can be referenced in the API endpoints.\n     */\n    id: string;\n\n    /**\n     * The Unix timestamp (in seconds) for when the permission was created.\n     */\n    created_at: number;\n\n    /**\n     * The object type, which is always \"checkpoint.permission\".\n     */\n    object: 'checkpoint.permission';\n\n    /**\n     * The project identifier that the permission is for.\n     */\n    project_id: string;\n  }\n}\n\nexport interface PermissionDeleteResponse {\n  /**\n   * The ID of the fine-tuned model checkpoint permission that was deleted.\n   */\n  id: string;\n\n  /**\n   * Whether the fine-tuned model checkpoint permission was successfully deleted.\n   */\n  deleted: boolean;\n\n  /**\n   * The object type, which is always \"checkpoint.permission\".\n   */\n  object: 'checkpoint.permission';\n}\n\nexport interface PermissionCreateParams {\n  /**\n   * The project identifiers to grant access to.\n   */\n  project_ids: Array<string>;\n}\n\nexport interface PermissionRetrieveParams {\n  /**\n   * Identifier for the last permission ID from the previous pagination request.\n   */\n  after?: string;\n\n  /**\n   * Number of permissions to retrieve.\n   */\n  limit?: number;\n\n  /**\n   * The order in which to retrieve permissions.\n   */\n  order?: 'ascending' | 'descending';\n\n  /**\n   * The ID of the project to get permissions for.\n   */\n  project_id?: string;\n}\n\nexport interface PermissionDeleteParams {\n  /**\n   * The ID of the fine-tuned model checkpoint to delete a permission for.\n   */\n  fine_tuned_model_checkpoint: string;\n}\n\nexport declare namespace Permissions {\n  export {\n    type PermissionCreateResponse as PermissionCreateResponse,\n    type PermissionRetrieveResponse as PermissionRetrieveResponse,\n    type PermissionDeleteResponse as PermissionDeleteResponse,\n    type PermissionCreateResponsesPage as PermissionCreateResponsesPage,\n    type PermissionCreateParams as PermissionCreateParams,\n    type PermissionRetrieveParams as PermissionRetrieveParams,\n    type PermissionDeleteParams as PermissionDeleteParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as SpeechAPI from './speech';\nimport { Speech, SpeechCreateParams, SpeechModel } from './speech';\nimport * as TranscriptionsAPI from './transcriptions';\nimport {\n  Transcription,\n  TranscriptionCreateParams,\n  TranscriptionCreateParamsNonStreaming,\n  TranscriptionCreateParamsStreaming,\n  TranscriptionCreateResponse,\n  TranscriptionDiarized,\n  TranscriptionDiarizedSegment,\n  TranscriptionInclude,\n  TranscriptionSegment,\n  TranscriptionStreamEvent,\n  TranscriptionTextDeltaEvent,\n  TranscriptionTextDoneEvent,\n  TranscriptionTextSegmentEvent,\n  TranscriptionVerbose,\n  TranscriptionWord,\n  Transcriptions,\n} from './transcriptions';\nimport * as TranslationsAPI from './translations';\nimport {\n  Translation,\n  TranslationCreateParams,\n  TranslationCreateResponse,\n  TranslationVerbose,\n  Translations,\n} from './translations';\n\nexport class Audio extends APIResource {\n  transcriptions: TranscriptionsAPI.Transcriptions = new TranscriptionsAPI.Transcriptions(this._client);\n  translations: TranslationsAPI.Translations = new TranslationsAPI.Translations(this._client);\n  speech: SpeechAPI.Speech = new SpeechAPI.Speech(this._client);\n}\n\nexport type AudioModel =\n  | 'whisper-1'\n  | 'gpt-4o-transcribe'\n  | 'gpt-4o-mini-transcribe'\n  | 'gpt-4o-transcribe-diarize';\n\n/**\n * The format of the output, in one of these options: `json`, `text`, `srt`,\n * `verbose_json`, `vtt`, or `diarized_json`. For `gpt-4o-transcribe` and\n * `gpt-4o-mini-transcribe`, the only supported format is `json`. For\n * `gpt-4o-transcribe-diarize`, the supported formats are `json`, `text`, and\n * `diarized_json`, with `diarized_json` required to receive speaker annotations.\n */\nexport type AudioResponseFormat = 'json' | 'text' | 'srt' | 'verbose_json' | 'vtt' | 'diarized_json';\n\nAudio.Transcriptions = Transcriptions;\nAudio.Translations = Translations;\nAudio.Speech = Speech;\n\nexport declare namespace Audio {\n  export { type AudioModel as AudioModel, type AudioResponseFormat as AudioResponseFormat };\n\n  export {\n    Transcriptions as Transcriptions,\n    type Transcription as Transcription,\n    type TranscriptionDiarized as TranscriptionDiarized,\n    type TranscriptionDiarizedSegment as TranscriptionDiarizedSegment,\n    type TranscriptionInclude as TranscriptionInclude,\n    type TranscriptionSegment as TranscriptionSegment,\n    type TranscriptionStreamEvent as TranscriptionStreamEvent,\n    type TranscriptionTextDeltaEvent as TranscriptionTextDeltaEvent,\n    type TranscriptionTextDoneEvent as TranscriptionTextDoneEvent,\n    type TranscriptionTextSegmentEvent as TranscriptionTextSegmentEvent,\n    type TranscriptionVerbose as TranscriptionVerbose,\n    type TranscriptionWord as TranscriptionWord,\n    type TranscriptionCreateResponse as TranscriptionCreateResponse,\n    type TranscriptionCreateParams as TranscriptionCreateParams,\n    type TranscriptionCreateParamsNonStreaming as TranscriptionCreateParamsNonStreaming,\n    type TranscriptionCreateParamsStreaming as TranscriptionCreateParamsStreaming,\n  };\n\n  export {\n    Translations as Translations,\n    type Translation as Translation,\n    type TranslationVerbose as TranslationVerbose,\n    type TranslationCreateResponse as TranslationCreateResponse,\n    type TranslationCreateParams as TranslationCreateParams,\n  };\n\n  export { Speech as Speech, type SpeechModel as SpeechModel, type SpeechCreateParams as SpeechCreateParams };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { castToError } from '../internal/errors';\n\nexport class OpenAIError extends Error {}\n\nexport class APIError<\n  TStatus extends number | undefined = number | undefined,\n  THeaders extends Headers | undefined = Headers | undefined,\n  TError extends Object | undefined = Object | undefined,\n> extends OpenAIError {\n  /** HTTP status for the response that caused the error */\n  readonly status: TStatus;\n  /** HTTP headers for the response that caused the error */\n  readonly headers: THeaders;\n  /** JSON body of the response that caused the error */\n  readonly error: TError;\n\n  readonly code: string | null | undefined;\n  readonly param: string | null | undefined;\n  readonly type: string | undefined;\n\n  readonly requestID: string | null | undefined;\n\n  constructor(status: TStatus, error: TError, message: string | undefined, headers: THeaders) {\n    super(`${APIError.makeMessage(status, error, message)}`);\n    this.status = status;\n    this.headers = headers;\n    this.requestID = headers?.get('x-request-id');\n    this.error = error;\n\n    const data = error as Record<string, any>;\n    this.code = data?.['code'];\n    this.param = data?.['param'];\n    this.type = data?.['type'];\n  }\n\n  private static makeMessage(status: number | undefined, error: any, message: string | undefined) {\n    const msg =\n      error?.message ?\n        typeof error.message === 'string' ?\n          error.message\n        : JSON.stringify(error.message)\n      : error ? JSON.stringify(error)\n      : message;\n\n    if (status && msg) {\n      return `${status} ${msg}`;\n    }\n    if (status) {\n      return `${status} status code (no body)`;\n    }\n    if (msg) {\n      return msg;\n    }\n    return '(no status code or body)';\n  }\n\n  static generate(\n    status: number | undefined,\n    errorResponse: Object | undefined,\n    message: string | undefined,\n    headers: Headers | undefined,\n  ): APIError {\n    if (!status || !headers) {\n      return new APIConnectionError({ message, cause: castToError(errorResponse) });\n    }\n\n    const error = (errorResponse as Record<string, any>)?.['error'];\n\n    if (status === 400) {\n      return new BadRequestError(status, error, message, headers);\n    }\n\n    if (status === 401) {\n      return new AuthenticationError(status, error, message, headers);\n    }\n\n    if (status === 403) {\n      return new PermissionDeniedError(status, error, message, headers);\n    }\n\n    if (status === 404) {\n      return new NotFoundError(status, error, message, headers);\n    }\n\n    if (status === 409) {\n      return new ConflictError(status, error, message, headers);\n    }\n\n    if (status === 422) {\n      return new UnprocessableEntityError(status, error, message, headers);\n    }\n\n    if (status === 429) {\n      return new RateLimitError(status, error, message, headers);\n    }\n\n    if (status >= 500) {\n      return new InternalServerError(status, error, message, headers);\n    }\n\n    return new APIError(status, error, message, headers);\n  }\n}\n\nexport class APIUserAbortError extends APIError<undefined, undefined, undefined> {\n  constructor({ message }: { message?: string } = {}) {\n    super(undefined, undefined, message || 'Request was aborted.', undefined);\n  }\n}\n\nexport class APIConnectionError extends APIError<undefined, undefined, undefined> {\n  constructor({ message, cause }: { message?: string | undefined; cause?: Error | undefined }) {\n    super(undefined, undefined, message || 'Connection error.', undefined);\n    // in some environments the 'cause' property is already declared\n    // @ts-ignore\n    if (cause) this.cause = cause;\n  }\n}\n\nexport class APIConnectionTimeoutError extends APIConnectionError {\n  constructor({ message }: { message?: string } = {}) {\n    super({ message: message ?? 'Request timed out.' });\n  }\n}\n\nexport class BadRequestError extends APIError<400, Headers> {}\n\nexport class AuthenticationError extends APIError<401, Headers> {}\n\nexport class PermissionDeniedError extends APIError<403, Headers> {}\n\nexport class NotFoundError extends APIError<404, Headers> {}\n\nexport class ConflictError extends APIError<409, Headers> {}\n\nexport class UnprocessableEntityError extends APIError<422, Headers> {}\n\nexport class RateLimitError extends APIError<429, Headers> {}\n\nexport class InternalServerError extends APIError<number, Headers> {}\n\nexport class LengthFinishReasonError extends OpenAIError {\n  constructor() {\n    super(`Could not parse response content as the length limit was reached`);\n  }\n}\n\nexport class ContentFilterFinishReasonError extends OpenAIError {\n  constructor() {\n    super(`Could not parse response content as the request was rejected by the content filter`);\n  }\n}\n\nexport class InvalidWebhookSignatureError extends Error {\n  constructor(message: string) {\n    super(message);\n  }\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../../../core/pagination';\nimport { RequestOptions } from '../../../internal/request-options';\nimport { path } from '../../../internal/utils/path';\n\nexport class Checkpoints extends APIResource {\n  /**\n   * List checkpoints for a fine-tuning job.\n   *\n   * @example\n   * ```ts\n   * // Automatically fetches more pages as needed.\n   * for await (const fineTuningJobCheckpoint of client.fineTuning.jobs.checkpoints.list(\n   *   'ft-AF1WoRqd3aJAHsqc9NY7iL8F',\n   * )) {\n   *   // ...\n   * }\n   * ```\n   */\n  list(\n    fineTuningJobID: string,\n    query: CheckpointListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<FineTuningJobCheckpointsPage, FineTuningJobCheckpoint> {\n    return this._client.getAPIList(\n      path`/fine_tuning/jobs/${fineTuningJobID}/checkpoints`,\n      CursorPage<FineTuningJobCheckpoint>,\n      { query, ...options },\n    );\n  }\n}\n\nexport type FineTuningJobCheckpointsPage = CursorPage<FineTuningJobCheckpoint>;\n\n/**\n * The `fine_tuning.job.checkpoint` object represents a model checkpoint for a\n * fine-tuning job that is ready to use.\n */\nexport interface FineTuningJobCheckpoint {\n  /**\n   * The checkpoint identifier, which can be referenced in the API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the checkpoint was created.\n   */\n  created_at: number;\n\n  /**\n   * The name of the fine-tuned checkpoint model that is created.\n   */\n  fine_tuned_model_checkpoint: string;\n\n  /**\n   * The name of the fine-tuning job that this checkpoint was created from.\n   */\n  fine_tuning_job_id: string;\n\n  /**\n   * Metrics at the step number during the fine-tuning job.\n   */\n  metrics: FineTuningJobCheckpoint.Metrics;\n\n  /**\n   * The object type, which is always \"fine_tuning.job.checkpoint\".\n   */\n  object: 'fine_tuning.job.checkpoint';\n\n  /**\n   * The step number that the checkpoint was created at.\n   */\n  step_number: number;\n}\n\nexport namespace FineTuningJobCheckpoint {\n  /**\n   * Metrics at the step number during the fine-tuning job.\n   */\n  export interface Metrics {\n    full_valid_loss?: number;\n\n    full_valid_mean_token_accuracy?: number;\n\n    step?: number;\n\n    train_loss?: number;\n\n    train_mean_token_accuracy?: number;\n\n    valid_loss?: number;\n\n    valid_mean_token_accuracy?: number;\n  }\n}\n\nexport interface CheckpointListParams extends CursorPageParams {}\n\nexport declare namespace Checkpoints {\n  export {\n    type FineTuningJobCheckpoint as FineTuningJobCheckpoint,\n    type FineTuningJobCheckpointsPage as FineTuningJobCheckpointsPage,\n    type CheckpointListParams as CheckpointListParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport * as Shared from '../../shared';\nimport * as MethodsAPI from '../methods';\nimport * as CheckpointsAPI from './checkpoints';\nimport {\n  CheckpointListParams,\n  Checkpoints,\n  FineTuningJobCheckpoint,\n  FineTuningJobCheckpointsPage,\n} from './checkpoints';\nimport { APIPromise } from '../../../core/api-promise';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../../../core/pagination';\nimport { RequestOptions } from '../../../internal/request-options';\nimport { path } from '../../../internal/utils/path';\n\nexport class Jobs extends APIResource {\n  checkpoints: CheckpointsAPI.Checkpoints = new CheckpointsAPI.Checkpoints(this._client);\n\n  /**\n   * Creates a fine-tuning job which begins the process of creating a new model from\n   * a given dataset.\n   *\n   * Response includes details of the enqueued job including job status and the name\n   * of the fine-tuned models once complete.\n   *\n   * [Learn more about fine-tuning](https://platform.openai.com/docs/guides/model-optimization)\n   *\n   * @example\n   * ```ts\n   * const fineTuningJob = await client.fineTuning.jobs.create({\n   *   model: 'gpt-4o-mini',\n   *   training_file: 'file-abc123',\n   * });\n   * ```\n   */\n  create(body: JobCreateParams, options?: RequestOptions): APIPromise<FineTuningJob> {\n    return this._client.post('/fine_tuning/jobs', { body, ...options });\n  }\n\n  /**\n   * Get info about a fine-tuning job.\n   *\n   * [Learn more about fine-tuning](https://platform.openai.com/docs/guides/model-optimization)\n   *\n   * @example\n   * ```ts\n   * const fineTuningJob = await client.fineTuning.jobs.retrieve(\n   *   'ft-AF1WoRqd3aJAHsqc9NY7iL8F',\n   * );\n   * ```\n   */\n  retrieve(fineTuningJobID: string, options?: RequestOptions): APIPromise<FineTuningJob> {\n    return this._client.get(path`/fine_tuning/jobs/${fineTuningJobID}`, options);\n  }\n\n  /**\n   * List your organization's fine-tuning jobs\n   *\n   * @example\n   * ```ts\n   * // Automatically fetches more pages as needed.\n   * for await (const fineTuningJob of client.fineTuning.jobs.list()) {\n   *   // ...\n   * }\n   * ```\n   */\n  list(\n    query: JobListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<FineTuningJobsPage, FineTuningJob> {\n    return this._client.getAPIList('/fine_tuning/jobs', CursorPage<FineTuningJob>, { query, ...options });\n  }\n\n  /**\n   * Immediately cancel a fine-tune job.\n   *\n   * @example\n   * ```ts\n   * const fineTuningJob = await client.fineTuning.jobs.cancel(\n   *   'ft-AF1WoRqd3aJAHsqc9NY7iL8F',\n   * );\n   * ```\n   */\n  cancel(fineTuningJobID: string, options?: RequestOptions): APIPromise<FineTuningJob> {\n    return this._client.post(path`/fine_tuning/jobs/${fineTuningJobID}/cancel`, options);\n  }\n\n  /**\n   * Get status updates for a fine-tuning job.\n   *\n   * @example\n   * ```ts\n   * // Automatically fetches more pages as needed.\n   * for await (const fineTuningJobEvent of client.fineTuning.jobs.listEvents(\n   *   'ft-AF1WoRqd3aJAHsqc9NY7iL8F',\n   * )) {\n   *   // ...\n   * }\n   * ```\n   */\n  listEvents(\n    fineTuningJobID: string,\n    query: JobListEventsParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<FineTuningJobEventsPage, FineTuningJobEvent> {\n    return this._client.getAPIList(\n      path`/fine_tuning/jobs/${fineTuningJobID}/events`,\n      CursorPage<FineTuningJobEvent>,\n      { query, ...options },\n    );\n  }\n\n  /**\n   * Pause a fine-tune job.\n   *\n   * @example\n   * ```ts\n   * const fineTuningJob = await client.fineTuning.jobs.pause(\n   *   'ft-AF1WoRqd3aJAHsqc9NY7iL8F',\n   * );\n   * ```\n   */\n  pause(fineTuningJobID: string, options?: RequestOptions): APIPromise<FineTuningJob> {\n    return this._client.post(path`/fine_tuning/jobs/${fineTuningJobID}/pause`, options);\n  }\n\n  /**\n   * Resume a fine-tune job.\n   *\n   * @example\n   * ```ts\n   * const fineTuningJob = await client.fineTuning.jobs.resume(\n   *   'ft-AF1WoRqd3aJAHsqc9NY7iL8F',\n   * );\n   * ```\n   */\n  resume(fineTuningJobID: string, options?: RequestOptions): APIPromise<FineTuningJob> {\n    return this._client.post(path`/fine_tuning/jobs/${fineTuningJobID}/resume`, options);\n  }\n}\n\nexport type FineTuningJobsPage = CursorPage<FineTuningJob>;\n\nexport type FineTuningJobEventsPage = CursorPage<FineTuningJobEvent>;\n\n/**\n * The `fine_tuning.job` object represents a fine-tuning job that has been created\n * through the API.\n */\nexport interface FineTuningJob {\n  /**\n   * The object identifier, which can be referenced in the API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the fine-tuning job was created.\n   */\n  created_at: number;\n\n  /**\n   * For fine-tuning jobs that have `failed`, this will contain more information on\n   * the cause of the failure.\n   */\n  error: FineTuningJob.Error | null;\n\n  /**\n   * The name of the fine-tuned model that is being created. The value will be null\n   * if the fine-tuning job is still running.\n   */\n  fine_tuned_model: string | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the fine-tuning job was finished. The\n   * value will be null if the fine-tuning job is still running.\n   */\n  finished_at: number | null;\n\n  /**\n   * The hyperparameters used for the fine-tuning job. This value will only be\n   * returned when running `supervised` jobs.\n   */\n  hyperparameters: FineTuningJob.Hyperparameters;\n\n  /**\n   * The base model that is being fine-tuned.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always \"fine_tuning.job\".\n   */\n  object: 'fine_tuning.job';\n\n  /**\n   * The organization that owns the fine-tuning job.\n   */\n  organization_id: string;\n\n  /**\n   * The compiled results file ID(s) for the fine-tuning job. You can retrieve the\n   * results with the\n   * [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).\n   */\n  result_files: Array<string>;\n\n  /**\n   * The seed used for the fine-tuning job.\n   */\n  seed: number;\n\n  /**\n   * The current status of the fine-tuning job, which can be either\n   * `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`.\n   */\n  status: 'validating_files' | 'queued' | 'running' | 'succeeded' | 'failed' | 'cancelled';\n\n  /**\n   * The total number of billable tokens processed by this fine-tuning job. The value\n   * will be null if the fine-tuning job is still running.\n   */\n  trained_tokens: number | null;\n\n  /**\n   * The file ID used for training. You can retrieve the training data with the\n   * [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).\n   */\n  training_file: string;\n\n  /**\n   * The file ID used for validation. You can retrieve the validation results with\n   * the\n   * [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).\n   */\n  validation_file: string | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the fine-tuning job is estimated to\n   * finish. The value will be null if the fine-tuning job is not running.\n   */\n  estimated_finish?: number | null;\n\n  /**\n   * A list of integrations to enable for this fine-tuning job.\n   */\n  integrations?: Array<FineTuningJobWandbIntegrationObject> | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The method used for fine-tuning.\n   */\n  method?: FineTuningJob.Method;\n}\n\nexport namespace FineTuningJob {\n  /**\n   * For fine-tuning jobs that have `failed`, this will contain more information on\n   * the cause of the failure.\n   */\n  export interface Error {\n    /**\n     * A machine-readable error code.\n     */\n    code: string;\n\n    /**\n     * A human-readable error message.\n     */\n    message: string;\n\n    /**\n     * The parameter that was invalid, usually `training_file` or `validation_file`.\n     * This field will be null if the failure was not parameter-specific.\n     */\n    param: string | null;\n  }\n\n  /**\n   * The hyperparameters used for the fine-tuning job. This value will only be\n   * returned when running `supervised` jobs.\n   */\n  export interface Hyperparameters {\n    /**\n     * Number of examples in each batch. A larger batch size means that model\n     * parameters are updated less frequently, but with lower variance.\n     */\n    batch_size?: 'auto' | number | null;\n\n    /**\n     * Scaling factor for the learning rate. A smaller learning rate may be useful to\n     * avoid overfitting.\n     */\n    learning_rate_multiplier?: 'auto' | number;\n\n    /**\n     * The number of epochs to train the model for. An epoch refers to one full cycle\n     * through the training dataset.\n     */\n    n_epochs?: 'auto' | number;\n  }\n\n  /**\n   * The method used for fine-tuning.\n   */\n  export interface Method {\n    /**\n     * The type of method. Is either `supervised`, `dpo`, or `reinforcement`.\n     */\n    type: 'supervised' | 'dpo' | 'reinforcement';\n\n    /**\n     * Configuration for the DPO fine-tuning method.\n     */\n    dpo?: MethodsAPI.DpoMethod;\n\n    /**\n     * Configuration for the reinforcement fine-tuning method.\n     */\n    reinforcement?: MethodsAPI.ReinforcementMethod;\n\n    /**\n     * Configuration for the supervised fine-tuning method.\n     */\n    supervised?: MethodsAPI.SupervisedMethod;\n  }\n}\n\n/**\n * Fine-tuning job event object\n */\nexport interface FineTuningJobEvent {\n  /**\n   * The object identifier.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the fine-tuning job was created.\n   */\n  created_at: number;\n\n  /**\n   * The log level of the event.\n   */\n  level: 'info' | 'warn' | 'error';\n\n  /**\n   * The message of the event.\n   */\n  message: string;\n\n  /**\n   * The object type, which is always \"fine_tuning.job.event\".\n   */\n  object: 'fine_tuning.job.event';\n\n  /**\n   * The data associated with the event.\n   */\n  data?: unknown;\n\n  /**\n   * The type of event.\n   */\n  type?: 'message' | 'metrics';\n}\n\n/**\n * The settings for your integration with Weights and Biases. This payload\n * specifies the project that metrics will be sent to. Optionally, you can set an\n * explicit display name for your run, add tags to your run, and set a default\n * entity (team, username, etc) to be associated with your run.\n */\nexport interface FineTuningJobWandbIntegration {\n  /**\n   * The name of the project that the new run will be created under.\n   */\n  project: string;\n\n  /**\n   * The entity to use for the run. This allows you to set the team or username of\n   * the WandB user that you would like associated with the run. If not set, the\n   * default entity for the registered WandB API key is used.\n   */\n  entity?: string | null;\n\n  /**\n   * A display name to set for the run. If not set, we will use the Job ID as the\n   * name.\n   */\n  name?: string | null;\n\n  /**\n   * A list of tags to be attached to the newly created run. These tags are passed\n   * through directly to WandB. Some default tags are generated by OpenAI:\n   * \"openai/finetune\", \"openai/{base-model}\", \"openai/{ftjob-abcdef}\".\n   */\n  tags?: Array<string>;\n}\n\nexport interface FineTuningJobWandbIntegrationObject {\n  /**\n   * The type of the integration being enabled for the fine-tuning job\n   */\n  type: 'wandb';\n\n  /**\n   * The settings for your integration with Weights and Biases. This payload\n   * specifies the project that metrics will be sent to. Optionally, you can set an\n   * explicit display name for your run, add tags to your run, and set a default\n   * entity (team, username, etc) to be associated with your run.\n   */\n  wandb: FineTuningJobWandbIntegration;\n}\n\nexport type FineTuningJobIntegration = FineTuningJobWandbIntegrationObject;\n\nexport interface JobCreateParams {\n  /**\n   * The name of the model to fine-tune. You can select one of the\n   * [supported models](https://platform.openai.com/docs/guides/fine-tuning#which-models-can-be-fine-tuned).\n   */\n  model: (string & {}) | 'babbage-002' | 'davinci-002' | 'gpt-3.5-turbo' | 'gpt-4o-mini';\n\n  /**\n   * The ID of an uploaded file that contains training data.\n   *\n   * See [upload file](https://platform.openai.com/docs/api-reference/files/create)\n   * for how to upload a file.\n   *\n   * Your dataset must be formatted as a JSONL file. Additionally, you must upload\n   * your file with the purpose `fine-tune`.\n   *\n   * The contents of the file should differ depending on if the model uses the\n   * [chat](https://platform.openai.com/docs/api-reference/fine-tuning/chat-input),\n   * [completions](https://platform.openai.com/docs/api-reference/fine-tuning/completions-input)\n   * format, or if the fine-tuning method uses the\n   * [preference](https://platform.openai.com/docs/api-reference/fine-tuning/preference-input)\n   * format.\n   *\n   * See the\n   * [fine-tuning guide](https://platform.openai.com/docs/guides/model-optimization)\n   * for more details.\n   */\n  training_file: string;\n\n  /**\n   * @deprecated The hyperparameters used for the fine-tuning job. This value is now\n   * deprecated in favor of `method`, and should be passed in under the `method`\n   * parameter.\n   */\n  hyperparameters?: JobCreateParams.Hyperparameters;\n\n  /**\n   * A list of integrations to enable for your fine-tuning job.\n   */\n  integrations?: Array<JobCreateParams.Integration> | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The method used for fine-tuning.\n   */\n  method?: JobCreateParams.Method;\n\n  /**\n   * The seed controls the reproducibility of the job. Passing in the same seed and\n   * job parameters should produce the same results, but may differ in rare cases. If\n   * a seed is not specified, one will be generated for you.\n   */\n  seed?: number | null;\n\n  /**\n   * A string of up to 64 characters that will be added to your fine-tuned model\n   * name.\n   *\n   * For example, a `suffix` of \"custom-model-name\" would produce a model name like\n   * `ft:gpt-4o-mini:openai:custom-model-name:7p4lURel`.\n   */\n  suffix?: string | null;\n\n  /**\n   * The ID of an uploaded file that contains validation data.\n   *\n   * If you provide this file, the data is used to generate validation metrics\n   * periodically during fine-tuning. These metrics can be viewed in the fine-tuning\n   * results file. The same data should not be present in both train and validation\n   * files.\n   *\n   * Your dataset must be formatted as a JSONL file. You must upload your file with\n   * the purpose `fine-tune`.\n   *\n   * See the\n   * [fine-tuning guide](https://platform.openai.com/docs/guides/model-optimization)\n   * for more details.\n   */\n  validation_file?: string | null;\n}\n\nexport namespace JobCreateParams {\n  /**\n   * @deprecated The hyperparameters used for the fine-tuning job. This value is now\n   * deprecated in favor of `method`, and should be passed in under the `method`\n   * parameter.\n   */\n  export interface Hyperparameters {\n    /**\n     * Number of examples in each batch. A larger batch size means that model\n     * parameters are updated less frequently, but with lower variance.\n     */\n    batch_size?: 'auto' | number;\n\n    /**\n     * Scaling factor for the learning rate. A smaller learning rate may be useful to\n     * avoid overfitting.\n     */\n    learning_rate_multiplier?: 'auto' | number;\n\n    /**\n     * The number of epochs to train the model for. An epoch refers to one full cycle\n     * through the training dataset.\n     */\n    n_epochs?: 'auto' | number;\n  }\n\n  export interface Integration {\n    /**\n     * The type of integration to enable. Currently, only \"wandb\" (Weights and Biases)\n     * is supported.\n     */\n    type: 'wandb';\n\n    /**\n     * The settings for your integration with Weights and Biases. This payload\n     * specifies the project that metrics will be sent to. Optionally, you can set an\n     * explicit display name for your run, add tags to your run, and set a default\n     * entity (team, username, etc) to be associated with your run.\n     */\n    wandb: Integration.Wandb;\n  }\n\n  export namespace Integration {\n    /**\n     * The settings for your integration with Weights and Biases. This payload\n     * specifies the project that metrics will be sent to. Optionally, you can set an\n     * explicit display name for your run, add tags to your run, and set a default\n     * entity (team, username, etc) to be associated with your run.\n     */\n    export interface Wandb {\n      /**\n       * The name of the project that the new run will be created under.\n       */\n      project: string;\n\n      /**\n       * The entity to use for the run. This allows you to set the team or username of\n       * the WandB user that you would like associated with the run. If not set, the\n       * default entity for the registered WandB API key is used.\n       */\n      entity?: string | null;\n\n      /**\n       * A display name to set for the run. If not set, we will use the Job ID as the\n       * name.\n       */\n      name?: string | null;\n\n      /**\n       * A list of tags to be attached to the newly created run. These tags are passed\n       * through directly to WandB. Some default tags are generated by OpenAI:\n       * \"openai/finetune\", \"openai/{base-model}\", \"openai/{ftjob-abcdef}\".\n       */\n      tags?: Array<string>;\n    }\n  }\n\n  /**\n   * The method used for fine-tuning.\n   */\n  export interface Method {\n    /**\n     * The type of method. Is either `supervised`, `dpo`, or `reinforcement`.\n     */\n    type: 'supervised' | 'dpo' | 'reinforcement';\n\n    /**\n     * Configuration for the DPO fine-tuning method.\n     */\n    dpo?: MethodsAPI.DpoMethod;\n\n    /**\n     * Configuration for the reinforcement fine-tuning method.\n     */\n    reinforcement?: MethodsAPI.ReinforcementMethod;\n\n    /**\n     * Configuration for the supervised fine-tuning method.\n     */\n    supervised?: MethodsAPI.SupervisedMethod;\n  }\n}\n\nexport interface JobListParams extends CursorPageParams {\n  /**\n   * Optional metadata filter. To filter, use the syntax `metadata[k]=v`.\n   * Alternatively, set `metadata=null` to indicate no metadata.\n   */\n  metadata?: { [key: string]: string } | null;\n}\n\nexport interface JobListEventsParams extends CursorPageParams {}\n\nJobs.Checkpoints = Checkpoints;\n\nexport declare namespace Jobs {\n  export {\n    type FineTuningJob as FineTuningJob,\n    type FineTuningJobEvent as FineTuningJobEvent,\n    type FineTuningJobWandbIntegration as FineTuningJobWandbIntegration,\n    type FineTuningJobWandbIntegrationObject as FineTuningJobWandbIntegrationObject,\n    type FineTuningJobIntegration as FineTuningJobIntegration,\n    type FineTuningJobsPage as FineTuningJobsPage,\n    type FineTuningJobEventsPage as FineTuningJobEventsPage,\n    type JobCreateParams as JobCreateParams,\n    type JobListParams as JobListParams,\n    type JobListEventsParams as JobListEventsParams,\n  };\n\n  export {\n    Checkpoints as Checkpoints,\n    type FineTuningJobCheckpoint as FineTuningJobCheckpoint,\n    type FineTuningJobCheckpointsPage as FineTuningJobCheckpointsPage,\n    type CheckpointListParams as CheckpointListParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as MethodsAPI from './methods';\nimport {\n  DpoHyperparameters,\n  DpoMethod,\n  Methods,\n  ReinforcementHyperparameters,\n  ReinforcementMethod,\n  SupervisedHyperparameters,\n  SupervisedMethod,\n} from './methods';\nimport * as AlphaAPI from './alpha/alpha';\nimport { Alpha } from './alpha/alpha';\nimport * as CheckpointsAPI from './checkpoints/checkpoints';\nimport { Checkpoints } from './checkpoints/checkpoints';\nimport * as JobsAPI from './jobs/jobs';\nimport {\n  FineTuningJob,\n  FineTuningJobEvent,\n  FineTuningJobEventsPage,\n  FineTuningJobIntegration,\n  FineTuningJobWandbIntegration,\n  FineTuningJobWandbIntegrationObject,\n  FineTuningJobsPage,\n  JobCreateParams,\n  JobListEventsParams,\n  JobListParams,\n  Jobs,\n} from './jobs/jobs';\n\nexport class FineTuning extends APIResource {\n  methods: MethodsAPI.Methods = new MethodsAPI.Methods(this._client);\n  jobs: JobsAPI.Jobs = new JobsAPI.Jobs(this._client);\n  checkpoints: CheckpointsAPI.Checkpoints = new CheckpointsAPI.Checkpoints(this._client);\n  alpha: AlphaAPI.Alpha = new AlphaAPI.Alpha(this._client);\n}\n\nFineTuning.Methods = Methods;\nFineTuning.Jobs = Jobs;\nFineTuning.Checkpoints = Checkpoints;\nFineTuning.Alpha = Alpha;\n\nexport declare namespace FineTuning {\n  export {\n    Methods as Methods,\n    type DpoHyperparameters as DpoHyperparameters,\n    type DpoMethod as DpoMethod,\n    type ReinforcementHyperparameters as ReinforcementHyperparameters,\n    type ReinforcementMethod as ReinforcementMethod,\n    type SupervisedHyperparameters as SupervisedHyperparameters,\n    type SupervisedMethod as SupervisedMethod,\n  };\n\n  export {\n    Jobs as Jobs,\n    type FineTuningJob as FineTuningJob,\n    type FineTuningJobEvent as FineTuningJobEvent,\n    type FineTuningJobWandbIntegration as FineTuningJobWandbIntegration,\n    type FineTuningJobWandbIntegrationObject as FineTuningJobWandbIntegrationObject,\n    type FineTuningJobIntegration as FineTuningJobIntegration,\n    type FineTuningJobsPage as FineTuningJobsPage,\n    type FineTuningJobEventsPage as FineTuningJobEventsPage,\n    type JobCreateParams as JobCreateParams,\n    type JobListParams as JobListParams,\n    type JobListEventsParams as JobListEventsParams,\n  };\n\n  export { Checkpoints as Checkpoints };\n\n  export { Alpha as Alpha };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport * as CompletionsAPI from './completions';\nimport { ChatCompletionStoreMessagesPage } from './completions';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../../../core/pagination';\nimport { RequestOptions } from '../../../internal/request-options';\nimport { path } from '../../../internal/utils/path';\n\nexport class Messages extends APIResource {\n  /**\n   * Get the messages in a stored chat completion. Only Chat Completions that have\n   * been created with the `store` parameter set to `true` will be returned.\n   *\n   * @example\n   * ```ts\n   * // Automatically fetches more pages as needed.\n   * for await (const chatCompletionStoreMessage of client.chat.completions.messages.list(\n   *   'completion_id',\n   * )) {\n   *   // ...\n   * }\n   * ```\n   */\n  list(\n    completionID: string,\n    query: MessageListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<ChatCompletionStoreMessagesPage, CompletionsAPI.ChatCompletionStoreMessage> {\n    return this._client.getAPIList(\n      path`/chat/completions/${completionID}/messages`,\n      CursorPage<CompletionsAPI.ChatCompletionStoreMessage>,\n      { query, ...options },\n    );\n  }\n}\n\nexport interface MessageListParams extends CursorPageParams {\n  /**\n   * Sort order for messages by timestamp. Use `asc` for ascending order or `desc`\n   * for descending order. Defaults to `asc`.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport declare namespace Messages {\n  export { type MessageListParams as MessageListParams };\n}\n\nexport { type ChatCompletionStoreMessagesPage };\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../core/resource';\nimport * as BatchesAPI from './batches';\nimport * as Shared from './shared';\nimport { APIPromise } from '../core/api-promise';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../core/pagination';\nimport { RequestOptions } from '../internal/request-options';\nimport { path } from '../internal/utils/path';\n\nexport class Batches extends APIResource {\n  /**\n   * Creates and executes a batch from an uploaded file of requests\n   */\n  create(body: BatchCreateParams, options?: RequestOptions): APIPromise<Batch> {\n    return this._client.post('/batches', { body, ...options });\n  }\n\n  /**\n   * Retrieves a batch.\n   */\n  retrieve(batchID: string, options?: RequestOptions): APIPromise<Batch> {\n    return this._client.get(path`/batches/${batchID}`, options);\n  }\n\n  /**\n   * List your organization's batches.\n   */\n  list(\n    query: BatchListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<BatchesPage, Batch> {\n    return this._client.getAPIList('/batches', CursorPage<Batch>, { query, ...options });\n  }\n\n  /**\n   * Cancels an in-progress batch. The batch will be in status `cancelling` for up to\n   * 10 minutes, before changing to `cancelled`, where it will have partial results\n   * (if any) available in the output file.\n   */\n  cancel(batchID: string, options?: RequestOptions): APIPromise<Batch> {\n    return this._client.post(path`/batches/${batchID}/cancel`, options);\n  }\n}\n\nexport type BatchesPage = CursorPage<Batch>;\n\nexport interface Batch {\n  id: string;\n\n  /**\n   * The time frame within which the batch should be processed.\n   */\n  completion_window: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch was created.\n   */\n  created_at: number;\n\n  /**\n   * The OpenAI API endpoint used by the batch.\n   */\n  endpoint: string;\n\n  /**\n   * The ID of the input file for the batch.\n   */\n  input_file_id: string;\n\n  /**\n   * The object type, which is always `batch`.\n   */\n  object: 'batch';\n\n  /**\n   * The current status of the batch.\n   */\n  status:\n    | 'validating'\n    | 'failed'\n    | 'in_progress'\n    | 'finalizing'\n    | 'completed'\n    | 'expired'\n    | 'cancelling'\n    | 'cancelled';\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch was cancelled.\n   */\n  cancelled_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch started cancelling.\n   */\n  cancelling_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch was completed.\n   */\n  completed_at?: number;\n\n  /**\n   * The ID of the file containing the outputs of requests with errors.\n   */\n  error_file_id?: string;\n\n  errors?: Batch.Errors;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch expired.\n   */\n  expired_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch will expire.\n   */\n  expires_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch failed.\n   */\n  failed_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch started finalizing.\n   */\n  finalizing_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch started processing.\n   */\n  in_progress_at?: number;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * Model ID used to process the batch, like `gpt-5-2025-08-07`. OpenAI offers a\n   * wide range of models with different capabilities, performance characteristics,\n   * and price points. Refer to the\n   * [model guide](https://platform.openai.com/docs/models) to browse and compare\n   * available models.\n   */\n  model?: string;\n\n  /**\n   * The ID of the file containing the outputs of successfully executed requests.\n   */\n  output_file_id?: string;\n\n  /**\n   * The request counts for different statuses within the batch.\n   */\n  request_counts?: BatchRequestCounts;\n\n  /**\n   * Represents token usage details including input tokens, output tokens, a\n   * breakdown of output tokens, and the total tokens used. Only populated on batches\n   * created after September 7, 2025.\n   */\n  usage?: BatchUsage;\n}\n\nexport namespace Batch {\n  export interface Errors {\n    data?: Array<BatchesAPI.BatchError>;\n\n    /**\n     * The object type, which is always `list`.\n     */\n    object?: string;\n  }\n}\n\nexport interface BatchError {\n  /**\n   * An error code identifying the error type.\n   */\n  code?: string;\n\n  /**\n   * The line number of the input file where the error occurred, if applicable.\n   */\n  line?: number | null;\n\n  /**\n   * A human-readable message providing more details about the error.\n   */\n  message?: string;\n\n  /**\n   * The name of the parameter that caused the error, if applicable.\n   */\n  param?: string | null;\n}\n\n/**\n * The request counts for different statuses within the batch.\n */\nexport interface BatchRequestCounts {\n  /**\n   * Number of requests that have been completed successfully.\n   */\n  completed: number;\n\n  /**\n   * Number of requests that have failed.\n   */\n  failed: number;\n\n  /**\n   * Total number of requests in the batch.\n   */\n  total: number;\n}\n\n/**\n * Represents token usage details including input tokens, output tokens, a\n * breakdown of output tokens, and the total tokens used. Only populated on batches\n * created after September 7, 2025.\n */\nexport interface BatchUsage {\n  /**\n   * The number of input tokens.\n   */\n  input_tokens: number;\n\n  /**\n   * A detailed breakdown of the input tokens.\n   */\n  input_tokens_details: BatchUsage.InputTokensDetails;\n\n  /**\n   * The number of output tokens.\n   */\n  output_tokens: number;\n\n  /**\n   * A detailed breakdown of the output tokens.\n   */\n  output_tokens_details: BatchUsage.OutputTokensDetails;\n\n  /**\n   * The total number of tokens used.\n   */\n  total_tokens: number;\n}\n\nexport namespace BatchUsage {\n  /**\n   * A detailed breakdown of the input tokens.\n   */\n  export interface InputTokensDetails {\n    /**\n     * The number of tokens that were retrieved from the cache.\n     * [More on prompt caching](https://platform.openai.com/docs/guides/prompt-caching).\n     */\n    cached_tokens: number;\n  }\n\n  /**\n   * A detailed breakdown of the output tokens.\n   */\n  export interface OutputTokensDetails {\n    /**\n     * The number of reasoning tokens.\n     */\n    reasoning_tokens: number;\n  }\n}\n\nexport interface BatchCreateParams {\n  /**\n   * The time frame within which the batch should be processed. Currently only `24h`\n   * is supported.\n   */\n  completion_window: '24h';\n\n  /**\n   * The endpoint to be used for all requests in the batch. Currently\n   * `/v1/responses`, `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions`\n   * are supported. Note that `/v1/embeddings` batches are also restricted to a\n   * maximum of 50,000 embedding inputs across all requests in the batch.\n   */\n  endpoint: '/v1/responses' | '/v1/chat/completions' | '/v1/embeddings' | '/v1/completions';\n\n  /**\n   * The ID of an uploaded file that contains requests for the new batch.\n   *\n   * See [upload file](https://platform.openai.com/docs/api-reference/files/create)\n   * for how to upload a file.\n   *\n   * Your input file must be formatted as a\n   * [JSONL file](https://platform.openai.com/docs/api-reference/batch/request-input),\n   * and must be uploaded with the purpose `batch`. The file can contain up to 50,000\n   * requests, and can be up to 200 MB in size.\n   */\n  input_file_id: string;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The expiration policy for the output and/or error file that are generated for a\n   * batch.\n   */\n  output_expires_after?: BatchCreateParams.OutputExpiresAfter;\n}\n\nexport namespace BatchCreateParams {\n  /**\n   * The expiration policy for the output and/or error file that are generated for a\n   * batch.\n   */\n  export interface OutputExpiresAfter {\n    /**\n     * Anchor timestamp after which the expiration policy applies. Supported anchors:\n     * `created_at`. Note that the anchor is the file creation time, not the time the\n     * batch is created.\n     */\n    anchor: 'created_at';\n\n    /**\n     * The number of seconds after the anchor time that the file will expire. Must be\n     * between 3600 (1 hour) and 2592000 (30 days).\n     */\n    seconds: number;\n  }\n}\n\nexport interface BatchListParams extends CursorPageParams {}\n\nexport declare namespace Batches {\n  export {\n    type Batch as Batch,\n    type BatchError as BatchError,\n    type BatchRequestCounts as BatchRequestCounts,\n    type BatchUsage as BatchUsage,\n    type BatchesPage as BatchesPage,\n    type BatchCreateParams as BatchCreateParams,\n    type BatchListParams as BatchListParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as Shared from '../shared';\nimport * as ResponsesAPI from '../responses/responses';\n\nexport class GraderModels extends APIResource {}\n\n/**\n * A LabelModelGrader object which uses a model to assign labels to each item in\n * the evaluation.\n */\nexport interface LabelModelGrader {\n  input: Array<LabelModelGrader.Input>;\n\n  /**\n   * The labels to assign to each item in the evaluation.\n   */\n  labels: Array<string>;\n\n  /**\n   * The model to use for the evaluation. Must support structured outputs.\n   */\n  model: string;\n\n  /**\n   * The name of the grader.\n   */\n  name: string;\n\n  /**\n   * The labels that indicate a passing result. Must be a subset of labels.\n   */\n  passing_labels: Array<string>;\n\n  /**\n   * The object type, which is always `label_model`.\n   */\n  type: 'label_model';\n}\n\nexport namespace LabelModelGrader {\n  /**\n   * A message input to the model with a role indicating instruction following\n   * hierarchy. Instructions given with the `developer` or `system` role take\n   * precedence over instructions given with the `user` role. Messages with the\n   * `assistant` role are presumed to have been generated by the model in previous\n   * interactions.\n   */\n  export interface Input {\n    /**\n     * Inputs to the model - can contain template strings.\n     */\n    content:\n      | string\n      | ResponsesAPI.ResponseInputText\n      | Input.OutputText\n      | Input.InputImage\n      | ResponsesAPI.ResponseInputAudio\n      | Array<unknown>;\n\n    /**\n     * The role of the message input. One of `user`, `assistant`, `system`, or\n     * `developer`.\n     */\n    role: 'user' | 'assistant' | 'system' | 'developer';\n\n    /**\n     * The type of the message input. Always `message`.\n     */\n    type?: 'message';\n  }\n\n  export namespace Input {\n    /**\n     * A text output from the model.\n     */\n    export interface OutputText {\n      /**\n       * The text output from the model.\n       */\n      text: string;\n\n      /**\n       * The type of the output text. Always `output_text`.\n       */\n      type: 'output_text';\n    }\n\n    /**\n     * An image input to the model.\n     */\n    export interface InputImage {\n      /**\n       * The URL of the image input.\n       */\n      image_url: string;\n\n      /**\n       * The type of the image input. Always `input_image`.\n       */\n      type: 'input_image';\n\n      /**\n       * The detail level of the image to be sent to the model. One of `high`, `low`, or\n       * `auto`. Defaults to `auto`.\n       */\n      detail?: string;\n    }\n  }\n}\n\n/**\n * A MultiGrader object combines the output of multiple graders to produce a single\n * score.\n */\nexport interface MultiGrader {\n  /**\n   * A formula to calculate the output based on grader results.\n   */\n  calculate_output: string;\n\n  /**\n   * A StringCheckGrader object that performs a string comparison between input and\n   * reference using a specified operation.\n   */\n  graders: StringCheckGrader | TextSimilarityGrader | PythonGrader | ScoreModelGrader | LabelModelGrader;\n\n  /**\n   * The name of the grader.\n   */\n  name: string;\n\n  /**\n   * The object type, which is always `multi`.\n   */\n  type: 'multi';\n}\n\n/**\n * A PythonGrader object that runs a python script on the input.\n */\nexport interface PythonGrader {\n  /**\n   * The name of the grader.\n   */\n  name: string;\n\n  /**\n   * The source code of the python script.\n   */\n  source: string;\n\n  /**\n   * The object type, which is always `python`.\n   */\n  type: 'python';\n\n  /**\n   * The image tag to use for the python script.\n   */\n  image_tag?: string;\n}\n\n/**\n * A ScoreModelGrader object that uses a model to assign a score to the input.\n */\nexport interface ScoreModelGrader {\n  /**\n   * The input text. This may include template strings.\n   */\n  input: Array<ScoreModelGrader.Input>;\n\n  /**\n   * The model to use for the evaluation.\n   */\n  model: string;\n\n  /**\n   * The name of the grader.\n   */\n  name: string;\n\n  /**\n   * The object type, which is always `score_model`.\n   */\n  type: 'score_model';\n\n  /**\n   * The range of the score. Defaults to `[0, 1]`.\n   */\n  range?: Array<number>;\n\n  /**\n   * The sampling parameters for the model.\n   */\n  sampling_params?: ScoreModelGrader.SamplingParams;\n}\n\nexport namespace ScoreModelGrader {\n  /**\n   * A message input to the model with a role indicating instruction following\n   * hierarchy. Instructions given with the `developer` or `system` role take\n   * precedence over instructions given with the `user` role. Messages with the\n   * `assistant` role are presumed to have been generated by the model in previous\n   * interactions.\n   */\n  export interface Input {\n    /**\n     * Inputs to the model - can contain template strings.\n     */\n    content:\n      | string\n      | ResponsesAPI.ResponseInputText\n      | Input.OutputText\n      | Input.InputImage\n      | ResponsesAPI.ResponseInputAudio\n      | Array<unknown>;\n\n    /**\n     * The role of the message input. One of `user`, `assistant`, `system`, or\n     * `developer`.\n     */\n    role: 'user' | 'assistant' | 'system' | 'developer';\n\n    /**\n     * The type of the message input. Always `message`.\n     */\n    type?: 'message';\n  }\n\n  export namespace Input {\n    /**\n     * A text output from the model.\n     */\n    export interface OutputText {\n      /**\n       * The text output from the model.\n       */\n      text: string;\n\n      /**\n       * The type of the output text. Always `output_text`.\n       */\n      type: 'output_text';\n    }\n\n    /**\n     * An image input to the model.\n     */\n    export interface InputImage {\n      /**\n       * The URL of the image input.\n       */\n      image_url: string;\n\n      /**\n       * The type of the image input. Always `input_image`.\n       */\n      type: 'input_image';\n\n      /**\n       * The detail level of the image to be sent to the model. One of `high`, `low`, or\n       * `auto`. Defaults to `auto`.\n       */\n      detail?: string;\n    }\n  }\n\n  /**\n   * The sampling parameters for the model.\n   */\n  export interface SamplingParams {\n    /**\n     * The maximum number of tokens the grader model may generate in its response.\n     */\n    max_completions_tokens?: number | null;\n\n    /**\n     * Constrains effort on reasoning for\n     * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n     * supported values are `minimal`, `low`, `medium`, and `high`. Reducing reasoning\n     * effort can result in faster responses and fewer tokens used on reasoning in a\n     * response.\n     *\n     * Note: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning\n     * effort.\n     */\n    reasoning_effort?: Shared.ReasoningEffort | null;\n\n    /**\n     * A seed value to initialize the randomness, during sampling.\n     */\n    seed?: number | null;\n\n    /**\n     * A higher temperature increases randomness in the outputs.\n     */\n    temperature?: number | null;\n\n    /**\n     * An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n     */\n    top_p?: number | null;\n  }\n}\n\n/**\n * A StringCheckGrader object that performs a string comparison between input and\n * reference using a specified operation.\n */\nexport interface StringCheckGrader {\n  /**\n   * The input text. This may include template strings.\n   */\n  input: string;\n\n  /**\n   * The name of the grader.\n   */\n  name: string;\n\n  /**\n   * The string check operation to perform. One of `eq`, `ne`, `like`, or `ilike`.\n   */\n  operation: 'eq' | 'ne' | 'like' | 'ilike';\n\n  /**\n   * The reference text. This may include template strings.\n   */\n  reference: string;\n\n  /**\n   * The object type, which is always `string_check`.\n   */\n  type: 'string_check';\n}\n\n/**\n * A TextSimilarityGrader object which grades text based on similarity metrics.\n */\nexport interface TextSimilarityGrader {\n  /**\n   * The evaluation metric to use. One of `cosine`, `fuzzy_match`, `bleu`, `gleu`,\n   * `meteor`, `rouge_1`, `rouge_2`, `rouge_3`, `rouge_4`, `rouge_5`, or `rouge_l`.\n   */\n  evaluation_metric:\n    | 'cosine'\n    | 'fuzzy_match'\n    | 'bleu'\n    | 'gleu'\n    | 'meteor'\n    | 'rouge_1'\n    | 'rouge_2'\n    | 'rouge_3'\n    | 'rouge_4'\n    | 'rouge_5'\n    | 'rouge_l';\n\n  /**\n   * The text being graded.\n   */\n  input: string;\n\n  /**\n   * The name of the grader.\n   */\n  name: string;\n\n  /**\n   * The text being graded against.\n   */\n  reference: string;\n\n  /**\n   * The type of grader.\n   */\n  type: 'text_similarity';\n}\n\nexport declare namespace GraderModels {\n  export {\n    type LabelModelGrader as LabelModelGrader,\n    type MultiGrader as MultiGrader,\n    type PythonGrader as PythonGrader,\n    type ScoreModelGrader as ScoreModelGrader,\n    type StringCheckGrader as StringCheckGrader,\n    type TextSimilarityGrader as TextSimilarityGrader,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as GraderModelsAPI from './grader-models';\nimport {\n  GraderModels,\n  LabelModelGrader,\n  MultiGrader,\n  PythonGrader,\n  ScoreModelGrader,\n  StringCheckGrader,\n  TextSimilarityGrader,\n} from './grader-models';\n\nexport class Graders extends APIResource {\n  graderModels: GraderModelsAPI.GraderModels = new GraderModelsAPI.GraderModels(this._client);\n}\n\nGraders.GraderModels = GraderModels;\n\nexport declare namespace Graders {\n  export {\n    GraderModels as GraderModels,\n    type LabelModelGrader as LabelModelGrader,\n    type MultiGrader as MultiGrader,\n    type PythonGrader as PythonGrader,\n    type ScoreModelGrader as ScoreModelGrader,\n    type StringCheckGrader as StringCheckGrader,\n    type TextSimilarityGrader as TextSimilarityGrader,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../core/resource';\nimport * as ImagesAPI from './images';\nimport { APIPromise } from '../core/api-promise';\nimport { Stream } from '../core/streaming';\nimport { type Uploadable } from '../core/uploads';\nimport { RequestOptions } from '../internal/request-options';\nimport { multipartFormRequestOptions } from '../internal/uploads';\n\nexport class Images extends APIResource {\n  /**\n   * Creates a variation of a given image. This endpoint only supports `dall-e-2`.\n   *\n   * @example\n   * ```ts\n   * const imagesResponse = await client.images.createVariation({\n   *   image: fs.createReadStream('otter.png'),\n   * });\n   * ```\n   */\n  createVariation(body: ImageCreateVariationParams, options?: RequestOptions): APIPromise<ImagesResponse> {\n    return this._client.post(\n      '/images/variations',\n      multipartFormRequestOptions({ body, ...options }, this._client),\n    );\n  }\n\n  /**\n   * Creates an edited or extended image given one or more source images and a\n   * prompt. This endpoint only supports `gpt-image-1` and `dall-e-2`.\n   *\n   * @example\n   * ```ts\n   * const imagesResponse = await client.images.edit({\n   *   image: fs.createReadStream('path/to/file'),\n   *   prompt: 'A cute baby sea otter wearing a beret',\n   * });\n   * ```\n   */\n  edit(body: ImageEditParamsNonStreaming, options?: RequestOptions): APIPromise<ImagesResponse>;\n  edit(body: ImageEditParamsStreaming, options?: RequestOptions): APIPromise<Stream<ImageEditStreamEvent>>;\n  edit(\n    body: ImageEditParamsBase,\n    options?: RequestOptions,\n  ): APIPromise<Stream<ImageEditStreamEvent> | ImagesResponse>;\n  edit(\n    body: ImageEditParams,\n    options?: RequestOptions,\n  ): APIPromise<ImagesResponse> | APIPromise<Stream<ImageEditStreamEvent>> {\n    return this._client.post(\n      '/images/edits',\n      multipartFormRequestOptions({ body, ...options, stream: body.stream ?? false }, this._client),\n    ) as APIPromise<ImagesResponse> | APIPromise<Stream<ImageEditStreamEvent>>;\n  }\n\n  /**\n   * Creates an image given a prompt.\n   * [Learn more](https://platform.openai.com/docs/guides/images).\n   *\n   * @example\n   * ```ts\n   * const imagesResponse = await client.images.generate({\n   *   prompt: 'A cute baby sea otter',\n   * });\n   * ```\n   */\n  generate(body: ImageGenerateParamsNonStreaming, options?: RequestOptions): APIPromise<ImagesResponse>;\n  generate(\n    body: ImageGenerateParamsStreaming,\n    options?: RequestOptions,\n  ): APIPromise<Stream<ImageGenStreamEvent>>;\n  generate(\n    body: ImageGenerateParamsBase,\n    options?: RequestOptions,\n  ): APIPromise<Stream<ImageGenStreamEvent> | ImagesResponse>;\n  generate(\n    body: ImageGenerateParams,\n    options?: RequestOptions,\n  ): APIPromise<ImagesResponse> | APIPromise<Stream<ImageGenStreamEvent>> {\n    return this._client.post('/images/generations', { body, ...options, stream: body.stream ?? false }) as\n      | APIPromise<ImagesResponse>\n      | APIPromise<Stream<ImageGenStreamEvent>>;\n  }\n}\n\n/**\n * Represents the content or the URL of an image generated by the OpenAI API.\n */\nexport interface Image {\n  /**\n   * The base64-encoded JSON of the generated image. Default value for `gpt-image-1`,\n   * and only present if `response_format` is set to `b64_json` for `dall-e-2` and\n   * `dall-e-3`.\n   */\n  b64_json?: string;\n\n  /**\n   * For `dall-e-3` only, the revised prompt that was used to generate the image.\n   */\n  revised_prompt?: string;\n\n  /**\n   * When using `dall-e-2` or `dall-e-3`, the URL of the generated image if\n   * `response_format` is set to `url` (default value). Unsupported for\n   * `gpt-image-1`.\n   */\n  url?: string;\n}\n\n/**\n * Emitted when image editing has completed and the final image is available.\n */\nexport interface ImageEditCompletedEvent {\n  /**\n   * Base64-encoded final edited image data, suitable for rendering as an image.\n   */\n  b64_json: string;\n\n  /**\n   * The background setting for the edited image.\n   */\n  background: 'transparent' | 'opaque' | 'auto';\n\n  /**\n   * The Unix timestamp when the event was created.\n   */\n  created_at: number;\n\n  /**\n   * The output format for the edited image.\n   */\n  output_format: 'png' | 'webp' | 'jpeg';\n\n  /**\n   * The quality setting for the edited image.\n   */\n  quality: 'low' | 'medium' | 'high' | 'auto';\n\n  /**\n   * The size of the edited image.\n   */\n  size: '1024x1024' | '1024x1536' | '1536x1024' | 'auto';\n\n  /**\n   * The type of the event. Always `image_edit.completed`.\n   */\n  type: 'image_edit.completed';\n\n  /**\n   * For `gpt-image-1` only, the token usage information for the image generation.\n   */\n  usage: ImageEditCompletedEvent.Usage;\n}\n\nexport namespace ImageEditCompletedEvent {\n  /**\n   * For `gpt-image-1` only, the token usage information for the image generation.\n   */\n  export interface Usage {\n    /**\n     * The number of tokens (images and text) in the input prompt.\n     */\n    input_tokens: number;\n\n    /**\n     * The input tokens detailed information for the image generation.\n     */\n    input_tokens_details: Usage.InputTokensDetails;\n\n    /**\n     * The number of image tokens in the output image.\n     */\n    output_tokens: number;\n\n    /**\n     * The total number of tokens (images and text) used for the image generation.\n     */\n    total_tokens: number;\n  }\n\n  export namespace Usage {\n    /**\n     * The input tokens detailed information for the image generation.\n     */\n    export interface InputTokensDetails {\n      /**\n       * The number of image tokens in the input prompt.\n       */\n      image_tokens: number;\n\n      /**\n       * The number of text tokens in the input prompt.\n       */\n      text_tokens: number;\n    }\n  }\n}\n\n/**\n * Emitted when a partial image is available during image editing streaming.\n */\nexport interface ImageEditPartialImageEvent {\n  /**\n   * Base64-encoded partial image data, suitable for rendering as an image.\n   */\n  b64_json: string;\n\n  /**\n   * The background setting for the requested edited image.\n   */\n  background: 'transparent' | 'opaque' | 'auto';\n\n  /**\n   * The Unix timestamp when the event was created.\n   */\n  created_at: number;\n\n  /**\n   * The output format for the requested edited image.\n   */\n  output_format: 'png' | 'webp' | 'jpeg';\n\n  /**\n   * 0-based index for the partial image (streaming).\n   */\n  partial_image_index: number;\n\n  /**\n   * The quality setting for the requested edited image.\n   */\n  quality: 'low' | 'medium' | 'high' | 'auto';\n\n  /**\n   * The size of the requested edited image.\n   */\n  size: '1024x1024' | '1024x1536' | '1536x1024' | 'auto';\n\n  /**\n   * The type of the event. Always `image_edit.partial_image`.\n   */\n  type: 'image_edit.partial_image';\n}\n\n/**\n * Emitted when a partial image is available during image editing streaming.\n */\nexport type ImageEditStreamEvent = ImageEditPartialImageEvent | ImageEditCompletedEvent;\n\n/**\n * Emitted when image generation has completed and the final image is available.\n */\nexport interface ImageGenCompletedEvent {\n  /**\n   * Base64-encoded image data, suitable for rendering as an image.\n   */\n  b64_json: string;\n\n  /**\n   * The background setting for the generated image.\n   */\n  background: 'transparent' | 'opaque' | 'auto';\n\n  /**\n   * The Unix timestamp when the event was created.\n   */\n  created_at: number;\n\n  /**\n   * The output format for the generated image.\n   */\n  output_format: 'png' | 'webp' | 'jpeg';\n\n  /**\n   * The quality setting for the generated image.\n   */\n  quality: 'low' | 'medium' | 'high' | 'auto';\n\n  /**\n   * The size of the generated image.\n   */\n  size: '1024x1024' | '1024x1536' | '1536x1024' | 'auto';\n\n  /**\n   * The type of the event. Always `image_generation.completed`.\n   */\n  type: 'image_generation.completed';\n\n  /**\n   * For `gpt-image-1` only, the token usage information for the image generation.\n   */\n  usage: ImageGenCompletedEvent.Usage;\n}\n\nexport namespace ImageGenCompletedEvent {\n  /**\n   * For `gpt-image-1` only, the token usage information for the image generation.\n   */\n  export interface Usage {\n    /**\n     * The number of tokens (images and text) in the input prompt.\n     */\n    input_tokens: number;\n\n    /**\n     * The input tokens detailed information for the image generation.\n     */\n    input_tokens_details: Usage.InputTokensDetails;\n\n    /**\n     * The number of image tokens in the output image.\n     */\n    output_tokens: number;\n\n    /**\n     * The total number of tokens (images and text) used for the image generation.\n     */\n    total_tokens: number;\n  }\n\n  export namespace Usage {\n    /**\n     * The input tokens detailed information for the image generation.\n     */\n    export interface InputTokensDetails {\n      /**\n       * The number of image tokens in the input prompt.\n       */\n      image_tokens: number;\n\n      /**\n       * The number of text tokens in the input prompt.\n       */\n      text_tokens: number;\n    }\n  }\n}\n\n/**\n * Emitted when a partial image is available during image generation streaming.\n */\nexport interface ImageGenPartialImageEvent {\n  /**\n   * Base64-encoded partial image data, suitable for rendering as an image.\n   */\n  b64_json: string;\n\n  /**\n   * The background setting for the requested image.\n   */\n  background: 'transparent' | 'opaque' | 'auto';\n\n  /**\n   * The Unix timestamp when the event was created.\n   */\n  created_at: number;\n\n  /**\n   * The output format for the requested image.\n   */\n  output_format: 'png' | 'webp' | 'jpeg';\n\n  /**\n   * 0-based index for the partial image (streaming).\n   */\n  partial_image_index: number;\n\n  /**\n   * The quality setting for the requested image.\n   */\n  quality: 'low' | 'medium' | 'high' | 'auto';\n\n  /**\n   * The size of the requested image.\n   */\n  size: '1024x1024' | '1024x1536' | '1536x1024' | 'auto';\n\n  /**\n   * The type of the event. Always `image_generation.partial_image`.\n   */\n  type: 'image_generation.partial_image';\n}\n\n/**\n * Emitted when a partial image is available during image generation streaming.\n */\nexport type ImageGenStreamEvent = ImageGenPartialImageEvent | ImageGenCompletedEvent;\n\nexport type ImageModel = 'dall-e-2' | 'dall-e-3' | 'gpt-image-1' | 'gpt-image-1-mini';\n\n/**\n * The response from the image generation endpoint.\n */\nexport interface ImagesResponse {\n  /**\n   * The Unix timestamp (in seconds) of when the image was created.\n   */\n  created: number;\n\n  /**\n   * The background parameter used for the image generation. Either `transparent` or\n   * `opaque`.\n   */\n  background?: 'transparent' | 'opaque';\n\n  /**\n   * The list of generated images.\n   */\n  data?: Array<Image>;\n\n  /**\n   * The output format of the image generation. Either `png`, `webp`, or `jpeg`.\n   */\n  output_format?: 'png' | 'webp' | 'jpeg';\n\n  /**\n   * The quality of the image generated. Either `low`, `medium`, or `high`.\n   */\n  quality?: 'low' | 'medium' | 'high';\n\n  /**\n   * The size of the image generated. Either `1024x1024`, `1024x1536`, or\n   * `1536x1024`.\n   */\n  size?: '1024x1024' | '1024x1536' | '1536x1024';\n\n  /**\n   * For `gpt-image-1` only, the token usage information for the image generation.\n   */\n  usage?: ImagesResponse.Usage;\n}\n\nexport namespace ImagesResponse {\n  /**\n   * For `gpt-image-1` only, the token usage information for the image generation.\n   */\n  export interface Usage {\n    /**\n     * The number of tokens (images and text) in the input prompt.\n     */\n    input_tokens: number;\n\n    /**\n     * The input tokens detailed information for the image generation.\n     */\n    input_tokens_details: Usage.InputTokensDetails;\n\n    /**\n     * The number of output tokens generated by the model.\n     */\n    output_tokens: number;\n\n    /**\n     * The total number of tokens (images and text) used for the image generation.\n     */\n    total_tokens: number;\n  }\n\n  export namespace Usage {\n    /**\n     * The input tokens detailed information for the image generation.\n     */\n    export interface InputTokensDetails {\n      /**\n       * The number of image tokens in the input prompt.\n       */\n      image_tokens: number;\n\n      /**\n       * The number of text tokens in the input prompt.\n       */\n      text_tokens: number;\n    }\n  }\n}\n\nexport interface ImageCreateVariationParams {\n  /**\n   * The image to use as the basis for the variation(s). Must be a valid PNG file,\n   * less than 4MB, and square.\n   */\n  image: Uploadable;\n\n  /**\n   * The model to use for image generation. Only `dall-e-2` is supported at this\n   * time.\n   */\n  model?: (string & {}) | ImageModel | null;\n\n  /**\n   * The number of images to generate. Must be between 1 and 10.\n   */\n  n?: number | null;\n\n  /**\n   * The format in which the generated images are returned. Must be one of `url` or\n   * `b64_json`. URLs are only valid for 60 minutes after the image has been\n   * generated.\n   */\n  response_format?: 'url' | 'b64_json' | null;\n\n  /**\n   * The size of the generated images. Must be one of `256x256`, `512x512`, or\n   * `1024x1024`.\n   */\n  size?: '256x256' | '512x512' | '1024x1024' | null;\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n   */\n  user?: string;\n}\n\nexport type ImageEditParams = ImageEditParamsNonStreaming | ImageEditParamsStreaming;\n\nexport interface ImageEditParamsBase {\n  /**\n   * The image(s) to edit. Must be a supported image file or an array of images.\n   *\n   * For `gpt-image-1`, each image should be a `png`, `webp`, or `jpg` file less than\n   * 50MB. You can provide up to 16 images.\n   *\n   * For `dall-e-2`, you can only provide one image, and it should be a square `png`\n   * file less than 4MB.\n   */\n  image: Uploadable | Array<Uploadable>;\n\n  /**\n   * A text description of the desired image(s). The maximum length is 1000\n   * characters for `dall-e-2`, and 32000 characters for `gpt-image-1`.\n   */\n  prompt: string;\n\n  /**\n   * Allows to set transparency for the background of the generated image(s). This\n   * parameter is only supported for `gpt-image-1`. Must be one of `transparent`,\n   * `opaque` or `auto` (default value). When `auto` is used, the model will\n   * automatically determine the best background for the image.\n   *\n   * If `transparent`, the output format needs to support transparency, so it should\n   * be set to either `png` (default value) or `webp`.\n   */\n  background?: 'transparent' | 'opaque' | 'auto' | null;\n\n  /**\n   * Control how much effort the model will exert to match the style and features,\n   * especially facial features, of input images. This parameter is only supported\n   * for `gpt-image-1`. Unsupported for `gpt-image-1-mini`. Supports `high` and\n   * `low`. Defaults to `low`.\n   */\n  input_fidelity?: 'high' | 'low' | null;\n\n  /**\n   * An additional image whose fully transparent areas (e.g. where alpha is zero)\n   * indicate where `image` should be edited. If there are multiple images provided,\n   * the mask will be applied on the first image. Must be a valid PNG file, less than\n   * 4MB, and have the same dimensions as `image`.\n   */\n  mask?: Uploadable;\n\n  /**\n   * The model to use for image generation. Only `dall-e-2` and `gpt-image-1` are\n   * supported. Defaults to `dall-e-2` unless a parameter specific to `gpt-image-1`\n   * is used.\n   */\n  model?: (string & {}) | ImageModel | null;\n\n  /**\n   * The number of images to generate. Must be between 1 and 10.\n   */\n  n?: number | null;\n\n  /**\n   * The compression level (0-100%) for the generated images. This parameter is only\n   * supported for `gpt-image-1` with the `webp` or `jpeg` output formats, and\n   * defaults to 100.\n   */\n  output_compression?: number | null;\n\n  /**\n   * The format in which the generated images are returned. This parameter is only\n   * supported for `gpt-image-1`. Must be one of `png`, `jpeg`, or `webp`. The\n   * default value is `png`.\n   */\n  output_format?: 'png' | 'jpeg' | 'webp' | null;\n\n  /**\n   * The number of partial images to generate. This parameter is used for streaming\n   * responses that return partial images. Value must be between 0 and 3. When set to\n   * 0, the response will be a single image sent in one streaming event.\n   *\n   * Note that the final image may be sent before the full number of partial images\n   * are generated if the full image is generated more quickly.\n   */\n  partial_images?: number | null;\n\n  /**\n   * The quality of the image that will be generated. `high`, `medium` and `low` are\n   * only supported for `gpt-image-1`. `dall-e-2` only supports `standard` quality.\n   * Defaults to `auto`.\n   */\n  quality?: 'standard' | 'low' | 'medium' | 'high' | 'auto' | null;\n\n  /**\n   * The format in which the generated images are returned. Must be one of `url` or\n   * `b64_json`. URLs are only valid for 60 minutes after the image has been\n   * generated. This parameter is only supported for `dall-e-2`, as `gpt-image-1`\n   * will always return base64-encoded images.\n   */\n  response_format?: 'url' | 'b64_json' | null;\n\n  /**\n   * The size of the generated images. Must be one of `1024x1024`, `1536x1024`\n   * (landscape), `1024x1536` (portrait), or `auto` (default value) for\n   * `gpt-image-1`, and one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`.\n   */\n  size?: '256x256' | '512x512' | '1024x1024' | '1536x1024' | '1024x1536' | 'auto' | null;\n\n  /**\n   * Edit the image in streaming mode. Defaults to `false`. See the\n   * [Image generation guide](https://platform.openai.com/docs/guides/image-generation)\n   * for more information.\n   */\n  stream?: boolean | null;\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n   */\n  user?: string;\n}\n\nexport namespace ImageEditParams {\n  export type ImageEditParamsNonStreaming = ImagesAPI.ImageEditParamsNonStreaming;\n  export type ImageEditParamsStreaming = ImagesAPI.ImageEditParamsStreaming;\n}\n\nexport interface ImageEditParamsNonStreaming extends ImageEditParamsBase {\n  /**\n   * Edit the image in streaming mode. Defaults to `false`. See the\n   * [Image generation guide](https://platform.openai.com/docs/guides/image-generation)\n   * for more information.\n   */\n  stream?: false | null;\n}\n\nexport interface ImageEditParamsStreaming extends ImageEditParamsBase {\n  /**\n   * Edit the image in streaming mode. Defaults to `false`. See the\n   * [Image generation guide](https://platform.openai.com/docs/guides/image-generation)\n   * for more information.\n   */\n  stream: true;\n}\n\nexport type ImageGenerateParams = ImageGenerateParamsNonStreaming | ImageGenerateParamsStreaming;\n\nexport interface ImageGenerateParamsBase {\n  /**\n   * A text description of the desired image(s). The maximum length is 32000\n   * characters for `gpt-image-1`, 1000 characters for `dall-e-2` and 4000 characters\n   * for `dall-e-3`.\n   */\n  prompt: string;\n\n  /**\n   * Allows to set transparency for the background of the generated image(s). This\n   * parameter is only supported for `gpt-image-1`. Must be one of `transparent`,\n   * `opaque` or `auto` (default value). When `auto` is used, the model will\n   * automatically determine the best background for the image.\n   *\n   * If `transparent`, the output format needs to support transparency, so it should\n   * be set to either `png` (default value) or `webp`.\n   */\n  background?: 'transparent' | 'opaque' | 'auto' | null;\n\n  /**\n   * The model to use for image generation. One of `dall-e-2`, `dall-e-3`, or\n   * `gpt-image-1`. Defaults to `dall-e-2` unless a parameter specific to\n   * `gpt-image-1` is used.\n   */\n  model?: (string & {}) | ImageModel | null;\n\n  /**\n   * Control the content-moderation level for images generated by `gpt-image-1`. Must\n   * be either `low` for less restrictive filtering or `auto` (default value).\n   */\n  moderation?: 'low' | 'auto' | null;\n\n  /**\n   * The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only\n   * `n=1` is supported.\n   */\n  n?: number | null;\n\n  /**\n   * The compression level (0-100%) for the generated images. This parameter is only\n   * supported for `gpt-image-1` with the `webp` or `jpeg` output formats, and\n   * defaults to 100.\n   */\n  output_compression?: number | null;\n\n  /**\n   * The format in which the generated images are returned. This parameter is only\n   * supported for `gpt-image-1`. Must be one of `png`, `jpeg`, or `webp`.\n   */\n  output_format?: 'png' | 'jpeg' | 'webp' | null;\n\n  /**\n   * The number of partial images to generate. This parameter is used for streaming\n   * responses that return partial images. Value must be between 0 and 3. When set to\n   * 0, the response will be a single image sent in one streaming event.\n   *\n   * Note that the final image may be sent before the full number of partial images\n   * are generated if the full image is generated more quickly.\n   */\n  partial_images?: number | null;\n\n  /**\n   * The quality of the image that will be generated.\n   *\n   * - `auto` (default value) will automatically select the best quality for the\n   *   given model.\n   * - `high`, `medium` and `low` are supported for `gpt-image-1`.\n   * - `hd` and `standard` are supported for `dall-e-3`.\n   * - `standard` is the only option for `dall-e-2`.\n   */\n  quality?: 'standard' | 'hd' | 'low' | 'medium' | 'high' | 'auto' | null;\n\n  /**\n   * The format in which generated images with `dall-e-2` and `dall-e-3` are\n   * returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes\n   * after the image has been generated. This parameter isn't supported for\n   * `gpt-image-1` which will always return base64-encoded images.\n   */\n  response_format?: 'url' | 'b64_json' | null;\n\n  /**\n   * The size of the generated images. Must be one of `1024x1024`, `1536x1024`\n   * (landscape), `1024x1536` (portrait), or `auto` (default value) for\n   * `gpt-image-1`, one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`, and\n   * one of `1024x1024`, `1792x1024`, or `1024x1792` for `dall-e-3`.\n   */\n  size?:\n    | 'auto'\n    | '1024x1024'\n    | '1536x1024'\n    | '1024x1536'\n    | '256x256'\n    | '512x512'\n    | '1792x1024'\n    | '1024x1792'\n    | null;\n\n  /**\n   * Generate the image in streaming mode. Defaults to `false`. See the\n   * [Image generation guide](https://platform.openai.com/docs/guides/image-generation)\n   * for more information. This parameter is only supported for `gpt-image-1`.\n   */\n  stream?: boolean | null;\n\n  /**\n   * The style of the generated images. This parameter is only supported for\n   * `dall-e-3`. Must be one of `vivid` or `natural`. Vivid causes the model to lean\n   * towards generating hyper-real and dramatic images. Natural causes the model to\n   * produce more natural, less hyper-real looking images.\n   */\n  style?: 'vivid' | 'natural' | null;\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n   */\n  user?: string;\n}\n\nexport namespace ImageGenerateParams {\n  export type ImageGenerateParamsNonStreaming = ImagesAPI.ImageGenerateParamsNonStreaming;\n  export type ImageGenerateParamsStreaming = ImagesAPI.ImageGenerateParamsStreaming;\n}\n\nexport interface ImageGenerateParamsNonStreaming extends ImageGenerateParamsBase {\n  /**\n   * Generate the image in streaming mode. Defaults to `false`. See the\n   * [Image generation guide](https://platform.openai.com/docs/guides/image-generation)\n   * for more information. This parameter is only supported for `gpt-image-1`.\n   */\n  stream?: false | null;\n}\n\nexport interface ImageGenerateParamsStreaming extends ImageGenerateParamsBase {\n  /**\n   * Generate the image in streaming mode. Defaults to `false`. See the\n   * [Image generation guide](https://platform.openai.com/docs/guides/image-generation)\n   * for more information. This parameter is only supported for `gpt-image-1`.\n   */\n  stream: true;\n}\n\nexport declare namespace Images {\n  export {\n    type Image as Image,\n    type ImageEditCompletedEvent as ImageEditCompletedEvent,\n    type ImageEditPartialImageEvent as ImageEditPartialImageEvent,\n    type ImageEditStreamEvent as ImageEditStreamEvent,\n    type ImageGenCompletedEvent as ImageGenCompletedEvent,\n    type ImageGenPartialImageEvent as ImageGenPartialImageEvent,\n    type ImageGenStreamEvent as ImageGenStreamEvent,\n    type ImageModel as ImageModel,\n    type ImagesResponse as ImagesResponse,\n    type ImageCreateVariationParams as ImageCreateVariationParams,\n    type ImageEditParams as ImageEditParams,\n    type ImageEditParamsNonStreaming as ImageEditParamsNonStreaming,\n    type ImageEditParamsStreaming as ImageEditParamsStreaming,\n    type ImageGenerateParams as ImageGenerateParams,\n    type ImageGenerateParamsNonStreaming as ImageGenerateParamsNonStreaming,\n    type ImageGenerateParamsStreaming as ImageGenerateParamsStreaming,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../core/resource';\nimport { APIPromise } from '../core/api-promise';\nimport { Page, PagePromise } from '../core/pagination';\nimport { RequestOptions } from '../internal/request-options';\nimport { path } from '../internal/utils/path';\n\nexport class Models extends APIResource {\n  /**\n   * Retrieves a model instance, providing basic information about the model such as\n   * the owner and permissioning.\n   */\n  retrieve(model: string, options?: RequestOptions): APIPromise<Model> {\n    return this._client.get(path`/models/${model}`, options);\n  }\n\n  /**\n   * Lists the currently available models, and provides basic information about each\n   * one such as the owner and availability.\n   */\n  list(options?: RequestOptions): PagePromise<ModelsPage, Model> {\n    return this._client.getAPIList('/models', Page<Model>, options);\n  }\n\n  /**\n   * Delete a fine-tuned model. You must have the Owner role in your organization to\n   * delete a model.\n   */\n  delete(model: string, options?: RequestOptions): APIPromise<ModelDeleted> {\n    return this._client.delete(path`/models/${model}`, options);\n  }\n}\n\n// Note: no pagination actually occurs yet, this is for forwards-compatibility.\nexport type ModelsPage = Page<Model>;\n\n/**\n * Describes an OpenAI model offering that can be used with the API.\n */\nexport interface Model {\n  /**\n   * The model identifier, which can be referenced in the API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) when the model was created.\n   */\n  created: number;\n\n  /**\n   * The object type, which is always \"model\".\n   */\n  object: 'model';\n\n  /**\n   * The organization that owns the model.\n   */\n  owned_by: string;\n}\n\nexport interface ModelDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: string;\n}\n\nexport declare namespace Models {\n  export { type Model as Model, type ModelDeleted as ModelDeleted, type ModelsPage as ModelsPage };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as Shared from '../shared';\nimport * as MessagesAPI from './threads/messages';\nimport * as ThreadsAPI from './threads/threads';\nimport * as RunsAPI from './threads/runs/runs';\nimport * as StepsAPI from './threads/runs/steps';\nimport { APIPromise } from '../../core/api-promise';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../../core/pagination';\nimport { buildHeaders } from '../../internal/headers';\nimport { RequestOptions } from '../../internal/request-options';\nimport { path } from '../../internal/utils/path';\nimport { AssistantStream } from '../../lib/AssistantStream';\n\nexport class Assistants extends APIResource {\n  /**\n   * Create an assistant with a model and instructions.\n   *\n   * @example\n   * ```ts\n   * const assistant = await client.beta.assistants.create({\n   *   model: 'gpt-4o',\n   * });\n   * ```\n   */\n  create(body: AssistantCreateParams, options?: RequestOptions): APIPromise<Assistant> {\n    return this._client.post('/assistants', {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Retrieves an assistant.\n   *\n   * @example\n   * ```ts\n   * const assistant = await client.beta.assistants.retrieve(\n   *   'assistant_id',\n   * );\n   * ```\n   */\n  retrieve(assistantID: string, options?: RequestOptions): APIPromise<Assistant> {\n    return this._client.get(path`/assistants/${assistantID}`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Modifies an assistant.\n   *\n   * @example\n   * ```ts\n   * const assistant = await client.beta.assistants.update(\n   *   'assistant_id',\n   * );\n   * ```\n   */\n  update(assistantID: string, body: AssistantUpdateParams, options?: RequestOptions): APIPromise<Assistant> {\n    return this._client.post(path`/assistants/${assistantID}`, {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Returns a list of assistants.\n   *\n   * @example\n   * ```ts\n   * // Automatically fetches more pages as needed.\n   * for await (const assistant of client.beta.assistants.list()) {\n   *   // ...\n   * }\n   * ```\n   */\n  list(\n    query: AssistantListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<AssistantsPage, Assistant> {\n    return this._client.getAPIList('/assistants', CursorPage<Assistant>, {\n      query,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Delete an assistant.\n   *\n   * @example\n   * ```ts\n   * const assistantDeleted =\n   *   await client.beta.assistants.delete('assistant_id');\n   * ```\n   */\n  delete(assistantID: string, options?: RequestOptions): APIPromise<AssistantDeleted> {\n    return this._client.delete(path`/assistants/${assistantID}`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n}\n\nexport type AssistantsPage = CursorPage<Assistant>;\n\n/**\n * Represents an `assistant` that can call the model and use tools.\n */\nexport interface Assistant {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the assistant was created.\n   */\n  created_at: number;\n\n  /**\n   * The description of the assistant. The maximum length is 512 characters.\n   */\n  description: string | null;\n\n  /**\n   * The system instructions that the assistant uses. The maximum length is 256,000\n   * characters.\n   */\n  instructions: string | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * ID of the model to use. You can use the\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n   * see all of your available models, or see our\n   * [Model overview](https://platform.openai.com/docs/models) for descriptions of\n   * them.\n   */\n  model: string;\n\n  /**\n   * The name of the assistant. The maximum length is 256 characters.\n   */\n  name: string | null;\n\n  /**\n   * The object type, which is always `assistant`.\n   */\n  object: 'assistant';\n\n  /**\n   * A list of tool enabled on the assistant. There can be a maximum of 128 tools per\n   * assistant. Tools can be of types `code_interpreter`, `file_search`, or\n   * `function`.\n   */\n  tools: Array<AssistantTool>;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models#gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: Assistant.ToolResources | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n}\n\nexport namespace Assistant {\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter`` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The ID of the\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n}\n\nexport interface AssistantDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'assistant.deleted';\n}\n\n/**\n * Represents an event emitted when streaming a Run.\n *\n * Each event in a server-sent events stream has an `event` and `data` property:\n *\n * ```\n * event: thread.created\n * data: {\"id\": \"thread_123\", \"object\": \"thread\", ...}\n * ```\n *\n * We emit events whenever a new object is created, transitions to a new state, or\n * is being streamed in parts (deltas). For example, we emit `thread.run.created`\n * when a new run is created, `thread.run.completed` when a run completes, and so\n * on. When an Assistant chooses to create a message during a run, we emit a\n * `thread.message.created event`, a `thread.message.in_progress` event, many\n * `thread.message.delta` events, and finally a `thread.message.completed` event.\n *\n * We may add additional events over time, so we recommend handling unknown events\n * gracefully in your code. See the\n * [Assistants API quickstart](https://platform.openai.com/docs/assistants/overview)\n * to learn how to integrate the Assistants API with streaming.\n */\nexport type AssistantStreamEvent =\n  | AssistantStreamEvent.ThreadCreated\n  | AssistantStreamEvent.ThreadRunCreated\n  | AssistantStreamEvent.ThreadRunQueued\n  | AssistantStreamEvent.ThreadRunInProgress\n  | AssistantStreamEvent.ThreadRunRequiresAction\n  | AssistantStreamEvent.ThreadRunCompleted\n  | AssistantStreamEvent.ThreadRunIncomplete\n  | AssistantStreamEvent.ThreadRunFailed\n  | AssistantStreamEvent.ThreadRunCancelling\n  | AssistantStreamEvent.ThreadRunCancelled\n  | AssistantStreamEvent.ThreadRunExpired\n  | AssistantStreamEvent.ThreadRunStepCreated\n  | AssistantStreamEvent.ThreadRunStepInProgress\n  | AssistantStreamEvent.ThreadRunStepDelta\n  | AssistantStreamEvent.ThreadRunStepCompleted\n  | AssistantStreamEvent.ThreadRunStepFailed\n  | AssistantStreamEvent.ThreadRunStepCancelled\n  | AssistantStreamEvent.ThreadRunStepExpired\n  | AssistantStreamEvent.ThreadMessageCreated\n  | AssistantStreamEvent.ThreadMessageInProgress\n  | AssistantStreamEvent.ThreadMessageDelta\n  | AssistantStreamEvent.ThreadMessageCompleted\n  | AssistantStreamEvent.ThreadMessageIncomplete\n  | AssistantStreamEvent.ErrorEvent;\n\nexport namespace AssistantStreamEvent {\n  /**\n   * Occurs when a new\n   * [thread](https://platform.openai.com/docs/api-reference/threads/object) is\n   * created.\n   */\n  export interface ThreadCreated {\n    /**\n     * Represents a thread that contains\n     * [messages](https://platform.openai.com/docs/api-reference/messages).\n     */\n    data: ThreadsAPI.Thread;\n\n    event: 'thread.created';\n\n    /**\n     * Whether to enable input audio transcription.\n     */\n    enabled?: boolean;\n  }\n\n  /**\n   * Occurs when a new\n   * [run](https://platform.openai.com/docs/api-reference/runs/object) is created.\n   */\n  export interface ThreadRunCreated {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.created';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `queued` status.\n   */\n  export interface ThreadRunQueued {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.queued';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to an `in_progress` status.\n   */\n  export interface ThreadRunInProgress {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.in_progress';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `requires_action` status.\n   */\n  export interface ThreadRunRequiresAction {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.requires_action';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * is completed.\n   */\n  export interface ThreadRunCompleted {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.completed';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * ends with status `incomplete`.\n   */\n  export interface ThreadRunIncomplete {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.incomplete';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * fails.\n   */\n  export interface ThreadRunFailed {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.failed';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `cancelling` status.\n   */\n  export interface ThreadRunCancelling {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.cancelling';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * is cancelled.\n   */\n  export interface ThreadRunCancelled {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.cancelled';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * expires.\n   */\n  export interface ThreadRunExpired {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.expired';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * is created.\n   */\n  export interface ThreadRunStepCreated {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.created';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * moves to an `in_progress` state.\n   */\n  export interface ThreadRunStepInProgress {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.in_progress';\n  }\n\n  /**\n   * Occurs when parts of a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * are being streamed.\n   */\n  export interface ThreadRunStepDelta {\n    /**\n     * Represents a run step delta i.e. any changed fields on a run step during\n     * streaming.\n     */\n    data: StepsAPI.RunStepDeltaEvent;\n\n    event: 'thread.run.step.delta';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * is completed.\n   */\n  export interface ThreadRunStepCompleted {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.completed';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * fails.\n   */\n  export interface ThreadRunStepFailed {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.failed';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * is cancelled.\n   */\n  export interface ThreadRunStepCancelled {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.cancelled';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * expires.\n   */\n  export interface ThreadRunStepExpired {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.expired';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) is\n   * created.\n   */\n  export interface ThreadMessageCreated {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.created';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) moves\n   * to an `in_progress` state.\n   */\n  export interface ThreadMessageInProgress {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.in_progress';\n  }\n\n  /**\n   * Occurs when parts of a\n   * [Message](https://platform.openai.com/docs/api-reference/messages/object) are\n   * being streamed.\n   */\n  export interface ThreadMessageDelta {\n    /**\n     * Represents a message delta i.e. any changed fields on a message during\n     * streaming.\n     */\n    data: MessagesAPI.MessageDeltaEvent;\n\n    event: 'thread.message.delta';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) is\n   * completed.\n   */\n  export interface ThreadMessageCompleted {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.completed';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) ends\n   * before it is completed.\n   */\n  export interface ThreadMessageIncomplete {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.incomplete';\n  }\n\n  /**\n   * Occurs when an\n   * [error](https://platform.openai.com/docs/guides/error-codes#api-errors) occurs.\n   * This can happen due to an internal server error or a timeout.\n   */\n  export interface ErrorEvent {\n    data: Shared.ErrorObject;\n\n    event: 'error';\n  }\n}\n\nexport type AssistantTool = CodeInterpreterTool | FileSearchTool | FunctionTool;\n\nexport interface CodeInterpreterTool {\n  /**\n   * The type of tool being defined: `code_interpreter`\n   */\n  type: 'code_interpreter';\n}\n\nexport interface FileSearchTool {\n  /**\n   * The type of tool being defined: `file_search`\n   */\n  type: 'file_search';\n\n  /**\n   * Overrides for the file search tool.\n   */\n  file_search?: FileSearchTool.FileSearch;\n}\n\nexport namespace FileSearchTool {\n  /**\n   * Overrides for the file search tool.\n   */\n  export interface FileSearch {\n    /**\n     * The maximum number of results the file search tool should output. The default is\n     * 20 for `gpt-4*` models and 5 for `gpt-3.5-turbo`. This number should be between\n     * 1 and 50 inclusive.\n     *\n     * Note that the file search tool may output fewer than `max_num_results` results.\n     * See the\n     * [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings)\n     * for more information.\n     */\n    max_num_results?: number;\n\n    /**\n     * The ranking options for the file search. If not specified, the file search tool\n     * will use the `auto` ranker and a score_threshold of 0.\n     *\n     * See the\n     * [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings)\n     * for more information.\n     */\n    ranking_options?: FileSearch.RankingOptions;\n  }\n\n  export namespace FileSearch {\n    /**\n     * The ranking options for the file search. If not specified, the file search tool\n     * will use the `auto` ranker and a score_threshold of 0.\n     *\n     * See the\n     * [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings)\n     * for more information.\n     */\n    export interface RankingOptions {\n      /**\n       * The score threshold for the file search. All values must be a floating point\n       * number between 0 and 1.\n       */\n      score_threshold: number;\n\n      /**\n       * The ranker to use for the file search. If not specified will use the `auto`\n       * ranker.\n       */\n      ranker?: 'auto' | 'default_2024_08_21';\n    }\n  }\n}\n\nexport interface FunctionTool {\n  function: Shared.FunctionDefinition;\n\n  /**\n   * The type of tool being defined: `function`\n   */\n  type: 'function';\n}\n\n/**\n * Occurs when a\n * [message](https://platform.openai.com/docs/api-reference/messages/object) is\n * created.\n */\nexport type MessageStreamEvent =\n  | MessageStreamEvent.ThreadMessageCreated\n  | MessageStreamEvent.ThreadMessageInProgress\n  | MessageStreamEvent.ThreadMessageDelta\n  | MessageStreamEvent.ThreadMessageCompleted\n  | MessageStreamEvent.ThreadMessageIncomplete;\n\nexport namespace MessageStreamEvent {\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) is\n   * created.\n   */\n  export interface ThreadMessageCreated {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.created';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) moves\n   * to an `in_progress` state.\n   */\n  export interface ThreadMessageInProgress {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.in_progress';\n  }\n\n  /**\n   * Occurs when parts of a\n   * [Message](https://platform.openai.com/docs/api-reference/messages/object) are\n   * being streamed.\n   */\n  export interface ThreadMessageDelta {\n    /**\n     * Represents a message delta i.e. any changed fields on a message during\n     * streaming.\n     */\n    data: MessagesAPI.MessageDeltaEvent;\n\n    event: 'thread.message.delta';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) is\n   * completed.\n   */\n  export interface ThreadMessageCompleted {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.completed';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) ends\n   * before it is completed.\n   */\n  export interface ThreadMessageIncomplete {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.incomplete';\n  }\n}\n\n/**\n * Occurs when a\n * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n * is created.\n */\nexport type RunStepStreamEvent =\n  | RunStepStreamEvent.ThreadRunStepCreated\n  | RunStepStreamEvent.ThreadRunStepInProgress\n  | RunStepStreamEvent.ThreadRunStepDelta\n  | RunStepStreamEvent.ThreadRunStepCompleted\n  | RunStepStreamEvent.ThreadRunStepFailed\n  | RunStepStreamEvent.ThreadRunStepCancelled\n  | RunStepStreamEvent.ThreadRunStepExpired;\n\nexport namespace RunStepStreamEvent {\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * is created.\n   */\n  export interface ThreadRunStepCreated {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.created';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * moves to an `in_progress` state.\n   */\n  export interface ThreadRunStepInProgress {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.in_progress';\n  }\n\n  /**\n   * Occurs when parts of a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * are being streamed.\n   */\n  export interface ThreadRunStepDelta {\n    /**\n     * Represents a run step delta i.e. any changed fields on a run step during\n     * streaming.\n     */\n    data: StepsAPI.RunStepDeltaEvent;\n\n    event: 'thread.run.step.delta';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * is completed.\n   */\n  export interface ThreadRunStepCompleted {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.completed';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * fails.\n   */\n  export interface ThreadRunStepFailed {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.failed';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * is cancelled.\n   */\n  export interface ThreadRunStepCancelled {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.cancelled';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * expires.\n   */\n  export interface ThreadRunStepExpired {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.expired';\n  }\n}\n\n/**\n * Occurs when a new\n * [run](https://platform.openai.com/docs/api-reference/runs/object) is created.\n */\nexport type RunStreamEvent =\n  | RunStreamEvent.ThreadRunCreated\n  | RunStreamEvent.ThreadRunQueued\n  | RunStreamEvent.ThreadRunInProgress\n  | RunStreamEvent.ThreadRunRequiresAction\n  | RunStreamEvent.ThreadRunCompleted\n  | RunStreamEvent.ThreadRunIncomplete\n  | RunStreamEvent.ThreadRunFailed\n  | RunStreamEvent.ThreadRunCancelling\n  | RunStreamEvent.ThreadRunCancelled\n  | RunStreamEvent.ThreadRunExpired;\n\nexport namespace RunStreamEvent {\n  /**\n   * Occurs when a new\n   * [run](https://platform.openai.com/docs/api-reference/runs/object) is created.\n   */\n  export interface ThreadRunCreated {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.created';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `queued` status.\n   */\n  export interface ThreadRunQueued {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.queued';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to an `in_progress` status.\n   */\n  export interface ThreadRunInProgress {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.in_progress';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `requires_action` status.\n   */\n  export interface ThreadRunRequiresAction {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.requires_action';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * is completed.\n   */\n  export interface ThreadRunCompleted {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.completed';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * ends with status `incomplete`.\n   */\n  export interface ThreadRunIncomplete {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.incomplete';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * fails.\n   */\n  export interface ThreadRunFailed {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.failed';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `cancelling` status.\n   */\n  export interface ThreadRunCancelling {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.cancelling';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * is cancelled.\n   */\n  export interface ThreadRunCancelled {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.cancelled';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * expires.\n   */\n  export interface ThreadRunExpired {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.expired';\n  }\n}\n\n/**\n * Occurs when a new\n * [thread](https://platform.openai.com/docs/api-reference/threads/object) is\n * created.\n */\nexport interface ThreadStreamEvent {\n  /**\n   * Represents a thread that contains\n   * [messages](https://platform.openai.com/docs/api-reference/messages).\n   */\n  data: ThreadsAPI.Thread;\n\n  event: 'thread.created';\n\n  /**\n   * Whether to enable input audio transcription.\n   */\n  enabled?: boolean;\n}\n\nexport interface AssistantCreateParams {\n  /**\n   * ID of the model to use. You can use the\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n   * see all of your available models, or see our\n   * [Model overview](https://platform.openai.com/docs/models) for descriptions of\n   * them.\n   */\n  model: (string & {}) | Shared.ChatModel;\n\n  /**\n   * The description of the assistant. The maximum length is 512 characters.\n   */\n  description?: string | null;\n\n  /**\n   * The system instructions that the assistant uses. The maximum length is 256,000\n   * characters.\n   */\n  instructions?: string | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The name of the assistant. The maximum length is 256 characters.\n   */\n  name?: string | null;\n\n  /**\n   * Constrains effort on reasoning for\n   * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n   * supported values are `minimal`, `low`, `medium`, and `high`. Reducing reasoning\n   * effort can result in faster responses and fewer tokens used on reasoning in a\n   * response.\n   *\n   * Note: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning\n   * effort.\n   */\n  reasoning_effort?: Shared.ReasoningEffort | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models#gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: AssistantCreateParams.ToolResources | null;\n\n  /**\n   * A list of tool enabled on the assistant. There can be a maximum of 128 tools per\n   * assistant. Tools can be of types `code_interpreter`, `file_search`, or\n   * `function`.\n   */\n  tools?: Array<AssistantTool>;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n}\n\nexport namespace AssistantCreateParams {\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n\n      /**\n       * A helper to create a\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * with file_ids and attach it to this assistant. There can be a maximum of 1\n       * vector store attached to the assistant.\n       */\n      vector_stores?: Array<FileSearch.VectorStore>;\n    }\n\n    export namespace FileSearch {\n      export interface VectorStore {\n        /**\n         * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n         * strategy.\n         */\n        chunking_strategy?: VectorStore.Auto | VectorStore.Static;\n\n        /**\n         * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs to\n         * add to the vector store. There can be a maximum of 10000 files in a vector\n         * store.\n         */\n        file_ids?: Array<string>;\n\n        /**\n         * Set of 16 key-value pairs that can be attached to an object. This can be useful\n         * for storing additional information about the object in a structured format, and\n         * querying for objects via API or the dashboard.\n         *\n         * Keys are strings with a maximum length of 64 characters. Values are strings with\n         * a maximum length of 512 characters.\n         */\n        metadata?: Shared.Metadata | null;\n      }\n\n      export namespace VectorStore {\n        /**\n         * The default strategy. This strategy currently uses a `max_chunk_size_tokens` of\n         * `800` and `chunk_overlap_tokens` of `400`.\n         */\n        export interface Auto {\n          /**\n           * Always `auto`.\n           */\n          type: 'auto';\n        }\n\n        export interface Static {\n          static: Static.Static;\n\n          /**\n           * Always `static`.\n           */\n          type: 'static';\n        }\n\n        export namespace Static {\n          export interface Static {\n            /**\n             * The number of tokens that overlap between chunks. The default value is `400`.\n             *\n             * Note that the overlap must not exceed half of `max_chunk_size_tokens`.\n             */\n            chunk_overlap_tokens: number;\n\n            /**\n             * The maximum number of tokens in each chunk. The default value is `800`. The\n             * minimum value is `100` and the maximum value is `4096`.\n             */\n            max_chunk_size_tokens: number;\n          }\n        }\n      }\n    }\n  }\n}\n\nexport interface AssistantUpdateParams {\n  /**\n   * The description of the assistant. The maximum length is 512 characters.\n   */\n  description?: string | null;\n\n  /**\n   * The system instructions that the assistant uses. The maximum length is 256,000\n   * characters.\n   */\n  instructions?: string | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * ID of the model to use. You can use the\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n   * see all of your available models, or see our\n   * [Model overview](https://platform.openai.com/docs/models) for descriptions of\n   * them.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-5'\n    | 'gpt-5-mini'\n    | 'gpt-5-nano'\n    | 'gpt-5-2025-08-07'\n    | 'gpt-5-mini-2025-08-07'\n    | 'gpt-5-nano-2025-08-07'\n    | 'gpt-4.1'\n    | 'gpt-4.1-mini'\n    | 'gpt-4.1-nano'\n    | 'gpt-4.1-2025-04-14'\n    | 'gpt-4.1-mini-2025-04-14'\n    | 'gpt-4.1-nano-2025-04-14'\n    | 'o3-mini'\n    | 'o3-mini-2025-01-31'\n    | 'o1'\n    | 'o1-2024-12-17'\n    | 'gpt-4o'\n    | 'gpt-4o-2024-11-20'\n    | 'gpt-4o-2024-08-06'\n    | 'gpt-4o-2024-05-13'\n    | 'gpt-4o-mini'\n    | 'gpt-4o-mini-2024-07-18'\n    | 'gpt-4.5-preview'\n    | 'gpt-4.5-preview-2025-02-27'\n    | 'gpt-4-turbo'\n    | 'gpt-4-turbo-2024-04-09'\n    | 'gpt-4-0125-preview'\n    | 'gpt-4-turbo-preview'\n    | 'gpt-4-1106-preview'\n    | 'gpt-4-vision-preview'\n    | 'gpt-4'\n    | 'gpt-4-0314'\n    | 'gpt-4-0613'\n    | 'gpt-4-32k'\n    | 'gpt-4-32k-0314'\n    | 'gpt-4-32k-0613'\n    | 'gpt-3.5-turbo'\n    | 'gpt-3.5-turbo-16k'\n    | 'gpt-3.5-turbo-0613'\n    | 'gpt-3.5-turbo-1106'\n    | 'gpt-3.5-turbo-0125'\n    | 'gpt-3.5-turbo-16k-0613';\n\n  /**\n   * The name of the assistant. The maximum length is 256 characters.\n   */\n  name?: string | null;\n\n  /**\n   * Constrains effort on reasoning for\n   * [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently\n   * supported values are `minimal`, `low`, `medium`, and `high`. Reducing reasoning\n   * effort can result in faster responses and fewer tokens used on reasoning in a\n   * response.\n   *\n   * Note: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning\n   * effort.\n   */\n  reasoning_effort?: Shared.ReasoningEffort | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models#gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: AssistantUpdateParams.ToolResources | null;\n\n  /**\n   * A list of tool enabled on the assistant. There can be a maximum of 128 tools per\n   * assistant. Tools can be of types `code_interpreter`, `file_search`, or\n   * `function`.\n   */\n  tools?: Array<AssistantTool>;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n}\n\nexport namespace AssistantUpdateParams {\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * Overrides the list of\n       * [file](https://platform.openai.com/docs/api-reference/files) IDs made available\n       * to the `code_interpreter` tool. There can be a maximum of 20 files associated\n       * with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * Overrides the\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n}\n\nexport interface AssistantListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * starting with obj_foo, your subsequent call can include before=obj_foo in order\n   * to fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport declare namespace Assistants {\n  export {\n    type Assistant as Assistant,\n    type AssistantDeleted as AssistantDeleted,\n    type AssistantStreamEvent as AssistantStreamEvent,\n    type AssistantTool as AssistantTool,\n    type CodeInterpreterTool as CodeInterpreterTool,\n    type FileSearchTool as FileSearchTool,\n    type FunctionTool as FunctionTool,\n    type MessageStreamEvent as MessageStreamEvent,\n    type RunStepStreamEvent as RunStepStreamEvent,\n    type RunStreamEvent as RunStreamEvent,\n    type ThreadStreamEvent as ThreadStreamEvent,\n    type AssistantsPage as AssistantsPage,\n    type AssistantCreateParams as AssistantCreateParams,\n    type AssistantUpdateParams as AssistantUpdateParams,\n    type AssistantListParams as AssistantListParams,\n  };\n\n  export { AssistantStream };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../core/resource';\nimport { APIPromise } from '../core/api-promise';\nimport { RequestOptions } from '../internal/request-options';\n\nexport class Moderations extends APIResource {\n  /**\n   * Classifies if text and/or image inputs are potentially harmful. Learn more in\n   * the [moderation guide](https://platform.openai.com/docs/guides/moderation).\n   */\n  create(body: ModerationCreateParams, options?: RequestOptions): APIPromise<ModerationCreateResponse> {\n    return this._client.post('/moderations', { body, ...options });\n  }\n}\n\nexport interface Moderation {\n  /**\n   * A list of the categories, and whether they are flagged or not.\n   */\n  categories: Moderation.Categories;\n\n  /**\n   * A list of the categories along with the input type(s) that the score applies to.\n   */\n  category_applied_input_types: Moderation.CategoryAppliedInputTypes;\n\n  /**\n   * A list of the categories along with their scores as predicted by model.\n   */\n  category_scores: Moderation.CategoryScores;\n\n  /**\n   * Whether any of the below categories are flagged.\n   */\n  flagged: boolean;\n}\n\nexport namespace Moderation {\n  /**\n   * A list of the categories, and whether they are flagged or not.\n   */\n  export interface Categories {\n    /**\n     * Content that expresses, incites, or promotes harassing language towards any\n     * target.\n     */\n    harassment: boolean;\n\n    /**\n     * Harassment content that also includes violence or serious harm towards any\n     * target.\n     */\n    'harassment/threatening': boolean;\n\n    /**\n     * Content that expresses, incites, or promotes hate based on race, gender,\n     * ethnicity, religion, nationality, sexual orientation, disability status, or\n     * caste. Hateful content aimed at non-protected groups (e.g., chess players) is\n     * harassment.\n     */\n    hate: boolean;\n\n    /**\n     * Hateful content that also includes violence or serious harm towards the targeted\n     * group based on race, gender, ethnicity, religion, nationality, sexual\n     * orientation, disability status, or caste.\n     */\n    'hate/threatening': boolean;\n\n    /**\n     * Content that includes instructions or advice that facilitate the planning or\n     * execution of wrongdoing, or that gives advice or instruction on how to commit\n     * illicit acts. For example, \"how to shoplift\" would fit this category.\n     */\n    illicit: boolean | null;\n\n    /**\n     * Content that includes instructions or advice that facilitate the planning or\n     * execution of wrongdoing that also includes violence, or that gives advice or\n     * instruction on the procurement of any weapon.\n     */\n    'illicit/violent': boolean | null;\n\n    /**\n     * Content that promotes, encourages, or depicts acts of self-harm, such as\n     * suicide, cutting, and eating disorders.\n     */\n    'self-harm': boolean;\n\n    /**\n     * Content that encourages performing acts of self-harm, such as suicide, cutting,\n     * and eating disorders, or that gives instructions or advice on how to commit such\n     * acts.\n     */\n    'self-harm/instructions': boolean;\n\n    /**\n     * Content where the speaker expresses that they are engaging or intend to engage\n     * in acts of self-harm, such as suicide, cutting, and eating disorders.\n     */\n    'self-harm/intent': boolean;\n\n    /**\n     * Content meant to arouse sexual excitement, such as the description of sexual\n     * activity, or that promotes sexual services (excluding sex education and\n     * wellness).\n     */\n    sexual: boolean;\n\n    /**\n     * Sexual content that includes an individual who is under 18 years old.\n     */\n    'sexual/minors': boolean;\n\n    /**\n     * Content that depicts death, violence, or physical injury.\n     */\n    violence: boolean;\n\n    /**\n     * Content that depicts death, violence, or physical injury in graphic detail.\n     */\n    'violence/graphic': boolean;\n  }\n\n  /**\n   * A list of the categories along with the input type(s) that the score applies to.\n   */\n  export interface CategoryAppliedInputTypes {\n    /**\n     * The applied input type(s) for the category 'harassment'.\n     */\n    harassment: Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'harassment/threatening'.\n     */\n    'harassment/threatening': Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'hate'.\n     */\n    hate: Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'hate/threatening'.\n     */\n    'hate/threatening': Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'illicit'.\n     */\n    illicit: Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'illicit/violent'.\n     */\n    'illicit/violent': Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'self-harm'.\n     */\n    'self-harm': Array<'text' | 'image'>;\n\n    /**\n     * The applied input type(s) for the category 'self-harm/instructions'.\n     */\n    'self-harm/instructions': Array<'text' | 'image'>;\n\n    /**\n     * The applied input type(s) for the category 'self-harm/intent'.\n     */\n    'self-harm/intent': Array<'text' | 'image'>;\n\n    /**\n     * The applied input type(s) for the category 'sexual'.\n     */\n    sexual: Array<'text' | 'image'>;\n\n    /**\n     * The applied input type(s) for the category 'sexual/minors'.\n     */\n    'sexual/minors': Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'violence'.\n     */\n    violence: Array<'text' | 'image'>;\n\n    /**\n     * The applied input type(s) for the category 'violence/graphic'.\n     */\n    'violence/graphic': Array<'text' | 'image'>;\n  }\n\n  /**\n   * A list of the categories along with their scores as predicted by model.\n   */\n  export interface CategoryScores {\n    /**\n     * The score for the category 'harassment'.\n     */\n    harassment: number;\n\n    /**\n     * The score for the category 'harassment/threatening'.\n     */\n    'harassment/threatening': number;\n\n    /**\n     * The score for the category 'hate'.\n     */\n    hate: number;\n\n    /**\n     * The score for the category 'hate/threatening'.\n     */\n    'hate/threatening': number;\n\n    /**\n     * The score for the category 'illicit'.\n     */\n    illicit: number;\n\n    /**\n     * The score for the category 'illicit/violent'.\n     */\n    'illicit/violent': number;\n\n    /**\n     * The score for the category 'self-harm'.\n     */\n    'self-harm': number;\n\n    /**\n     * The score for the category 'self-harm/instructions'.\n     */\n    'self-harm/instructions': number;\n\n    /**\n     * The score for the category 'self-harm/intent'.\n     */\n    'self-harm/intent': number;\n\n    /**\n     * The score for the category 'sexual'.\n     */\n    sexual: number;\n\n    /**\n     * The score for the category 'sexual/minors'.\n     */\n    'sexual/minors': number;\n\n    /**\n     * The score for the category 'violence'.\n     */\n    violence: number;\n\n    /**\n     * The score for the category 'violence/graphic'.\n     */\n    'violence/graphic': number;\n  }\n}\n\n/**\n * An object describing an image to classify.\n */\nexport interface ModerationImageURLInput {\n  /**\n   * Contains either an image URL or a data URL for a base64 encoded image.\n   */\n  image_url: ModerationImageURLInput.ImageURL;\n\n  /**\n   * Always `image_url`.\n   */\n  type: 'image_url';\n}\n\nexport namespace ModerationImageURLInput {\n  /**\n   * Contains either an image URL or a data URL for a base64 encoded image.\n   */\n  export interface ImageURL {\n    /**\n     * Either a URL of the image or the base64 encoded image data.\n     */\n    url: string;\n  }\n}\n\nexport type ModerationModel =\n  | 'omni-moderation-latest'\n  | 'omni-moderation-2024-09-26'\n  | 'text-moderation-latest'\n  | 'text-moderation-stable';\n\n/**\n * An object describing an image to classify.\n */\nexport type ModerationMultiModalInput = ModerationImageURLInput | ModerationTextInput;\n\n/**\n * An object describing text to classify.\n */\nexport interface ModerationTextInput {\n  /**\n   * A string of text to classify.\n   */\n  text: string;\n\n  /**\n   * Always `text`.\n   */\n  type: 'text';\n}\n\n/**\n * Represents if a given text input is potentially harmful.\n */\nexport interface ModerationCreateResponse {\n  /**\n   * The unique identifier for the moderation request.\n   */\n  id: string;\n\n  /**\n   * The model used to generate the moderation results.\n   */\n  model: string;\n\n  /**\n   * A list of moderation objects.\n   */\n  results: Array<Moderation>;\n}\n\nexport interface ModerationCreateParams {\n  /**\n   * Input (or inputs) to classify. Can be a single string, an array of strings, or\n   * an array of multi-modal input objects similar to other models.\n   */\n  input: string | Array<string> | Array<ModerationMultiModalInput>;\n\n  /**\n   * The content moderation model you would like to use. Learn more in\n   * [the moderation guide](https://platform.openai.com/docs/guides/moderation), and\n   * learn about available models\n   * [here](https://platform.openai.com/docs/models#moderation).\n   */\n  model?: (string & {}) | ModerationModel;\n}\n\nexport declare namespace Moderations {\n  export {\n    type Moderation as Moderation,\n    type ModerationImageURLInput as ModerationImageURLInput,\n    type ModerationModel as ModerationModel,\n    type ModerationMultiModalInput as ModerationMultiModalInput,\n    type ModerationTextInput as ModerationTextInput,\n    type ModerationCreateResponse as ModerationCreateResponse,\n    type ModerationCreateParams as ModerationCreateParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as RealtimeAPI from './realtime';\nimport * as ResponsesAPI from '../responses/responses';\nimport { APIPromise } from '../../core/api-promise';\nimport { buildHeaders } from '../../internal/headers';\nimport { RequestOptions } from '../../internal/request-options';\nimport { path } from '../../internal/utils/path';\n\nexport class Calls extends APIResource {\n  /**\n   * Accept an incoming SIP call and configure the realtime session that will handle\n   * it.\n   *\n   * @example\n   * ```ts\n   * await client.realtime.calls.accept('call_id', {\n   *   type: 'realtime',\n   * });\n   * ```\n   */\n  accept(callID: string, body: CallAcceptParams, options?: RequestOptions): APIPromise<void> {\n    return this._client.post(path`/realtime/calls/${callID}/accept`, {\n      body,\n      ...options,\n      headers: buildHeaders([{ Accept: '*/*' }, options?.headers]),\n    });\n  }\n\n  /**\n   * End an active Realtime API call, whether it was initiated over SIP or WebRTC.\n   *\n   * @example\n   * ```ts\n   * await client.realtime.calls.hangup('call_id');\n   * ```\n   */\n  hangup(callID: string, options?: RequestOptions): APIPromise<void> {\n    return this._client.post(path`/realtime/calls/${callID}/hangup`, {\n      ...options,\n      headers: buildHeaders([{ Accept: '*/*' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Transfer an active SIP call to a new destination using the SIP REFER verb.\n   *\n   * @example\n   * ```ts\n   * await client.realtime.calls.refer('call_id', {\n   *   target_uri: 'tel:+14155550123',\n   * });\n   * ```\n   */\n  refer(callID: string, body: CallReferParams, options?: RequestOptions): APIPromise<void> {\n    return this._client.post(path`/realtime/calls/${callID}/refer`, {\n      body,\n      ...options,\n      headers: buildHeaders([{ Accept: '*/*' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Decline an incoming SIP call by returning a SIP status code to the caller.\n   *\n   * @example\n   * ```ts\n   * await client.realtime.calls.reject('call_id');\n   * ```\n   */\n  reject(\n    callID: string,\n    body: CallRejectParams | null | undefined = {},\n    options?: RequestOptions,\n  ): APIPromise<void> {\n    return this._client.post(path`/realtime/calls/${callID}/reject`, {\n      body,\n      ...options,\n      headers: buildHeaders([{ Accept: '*/*' }, options?.headers]),\n    });\n  }\n}\n\nexport interface CallAcceptParams {\n  /**\n   * The type of session to create. Always `realtime` for the Realtime API.\n   */\n  type: 'realtime';\n\n  /**\n   * Configuration for input and output audio.\n   */\n  audio?: RealtimeAPI.RealtimeAudioConfig;\n\n  /**\n   * Additional fields to include in server outputs.\n   *\n   * `item.input_audio_transcription.logprobs`: Include logprobs for input audio\n   * transcription.\n   */\n  include?: Array<'item.input_audio_transcription.logprobs'>;\n\n  /**\n   * The default system instructions (i.e. system message) prepended to model calls.\n   * This field allows the client to guide the model on desired responses. The model\n   * can be instructed on response content and format, (e.g. \"be extremely succinct\",\n   * \"act friendly\", \"here are examples of good responses\") and on audio behavior\n   * (e.g. \"talk quickly\", \"inject emotion into your voice\", \"laugh frequently\"). The\n   * instructions are not guaranteed to be followed by the model, but they provide\n   * guidance to the model on the desired behavior.\n   *\n   * Note that the server sets default instructions which will be used if this field\n   * is not set and are visible in the `session.created` event at the start of the\n   * session.\n   */\n  instructions?: string;\n\n  /**\n   * Maximum number of output tokens for a single assistant response, inclusive of\n   * tool calls. Provide an integer between 1 and 4096 to limit output tokens, or\n   * `inf` for the maximum available tokens for a given model. Defaults to `inf`.\n   */\n  max_output_tokens?: number | 'inf';\n\n  /**\n   * The Realtime model used for this session.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-realtime'\n    | 'gpt-realtime-2025-08-28'\n    | 'gpt-4o-realtime-preview'\n    | 'gpt-4o-realtime-preview-2024-10-01'\n    | 'gpt-4o-realtime-preview-2024-12-17'\n    | 'gpt-4o-realtime-preview-2025-06-03'\n    | 'gpt-4o-mini-realtime-preview'\n    | 'gpt-4o-mini-realtime-preview-2024-12-17'\n    | 'gpt-realtime-mini'\n    | 'gpt-realtime-mini-2025-10-06'\n    | 'gpt-audio-mini'\n    | 'gpt-audio-mini-2025-10-06';\n\n  /**\n   * The set of modalities the model can respond with. It defaults to `[\"audio\"]`,\n   * indicating that the model will respond with audio plus a transcript. `[\"text\"]`\n   * can be used to make the model respond with text only. It is not possible to\n   * request both `text` and `audio` at the same time.\n   */\n  output_modalities?: Array<'text' | 'audio'>;\n\n  /**\n   * Reference to a prompt template and its variables.\n   * [Learn more](https://platform.openai.com/docs/guides/text?api-mode=responses#reusable-prompts).\n   */\n  prompt?: ResponsesAPI.ResponsePrompt | null;\n\n  /**\n   * How the model chooses tools. Provide one of the string modes or force a specific\n   * function/MCP tool.\n   */\n  tool_choice?: RealtimeAPI.RealtimeToolChoiceConfig;\n\n  /**\n   * Tools available to the model.\n   */\n  tools?: RealtimeAPI.RealtimeToolsConfig;\n\n  /**\n   * Realtime API can write session traces to the\n   * [Traces Dashboard](/logs?api=traces). Set to null to disable tracing. Once\n   * tracing is enabled for a session, the configuration cannot be modified.\n   *\n   * `auto` will create a trace for the session with default values for the workflow\n   * name, group id, and metadata.\n   */\n  tracing?: RealtimeAPI.RealtimeTracingConfig | null;\n\n  /**\n   * When the number of tokens in a conversation exceeds the model's input token\n   * limit, the conversation be truncated, meaning messages (starting from the\n   * oldest) will not be included in the model's context. A 32k context model with\n   * 4,096 max output tokens can only include 28,224 tokens in the context before\n   * truncation occurs. Clients can configure truncation behavior to truncate with a\n   * lower max token limit, which is an effective way to control token usage and\n   * cost. Truncation will reduce the number of cached tokens on the next turn\n   * (busting the cache), since messages are dropped from the beginning of the\n   * context. However, clients can also configure truncation to retain messages up to\n   * a fraction of the maximum context size, which will reduce the need for future\n   * truncations and thus improve the cache rate. Truncation can be disabled\n   * entirely, which means the server will never truncate but would instead return an\n   * error if the conversation exceeds the model's input token limit.\n   */\n  truncation?: RealtimeAPI.RealtimeTruncation;\n}\n\nexport interface CallReferParams {\n  /**\n   * URI that should appear in the SIP Refer-To header. Supports values like\n   * `tel:+14155550123` or `sip:agent@example.com`.\n   */\n  target_uri: string;\n}\n\nexport interface CallRejectParams {\n  /**\n   * SIP response code to send back to the caller. Defaults to `603` (Decline) when\n   * omitted.\n   */\n  status_code?: number;\n}\n\nexport declare namespace Calls {\n  export {\n    type CallAcceptParams as CallAcceptParams,\n    type CallReferParams as CallReferParams,\n    type CallRejectParams as CallRejectParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as ClientSecretsAPI from './client-secrets';\nimport * as RealtimeAPI from './realtime';\nimport * as ResponsesAPI from '../responses/responses';\nimport { APIPromise } from '../../core/api-promise';\nimport { RequestOptions } from '../../internal/request-options';\n\nexport class ClientSecrets extends APIResource {\n  /**\n   * Create a Realtime client secret with an associated session configuration.\n   *\n   * @example\n   * ```ts\n   * const clientSecret =\n   *   await client.realtime.clientSecrets.create();\n   * ```\n   */\n  create(body: ClientSecretCreateParams, options?: RequestOptions): APIPromise<ClientSecretCreateResponse> {\n    return this._client.post('/realtime/client_secrets', { body, ...options });\n  }\n}\n\n/**\n * Ephemeral key returned by the API.\n */\nexport interface RealtimeSessionClientSecret {\n  /**\n   * Timestamp for when the token expires. Currently, all tokens expire after one\n   * minute.\n   */\n  expires_at: number;\n\n  /**\n   * Ephemeral key usable in client environments to authenticate connections to the\n   * Realtime API. Use this in client-side environments rather than a standard API\n   * token, which should only be used server-side.\n   */\n  value: string;\n}\n\n/**\n * A new Realtime session configuration, with an ephemeral key. Default TTL for\n * keys is one minute.\n */\nexport interface RealtimeSessionCreateResponse {\n  /**\n   * Ephemeral key returned by the API.\n   */\n  client_secret: RealtimeSessionClientSecret;\n\n  /**\n   * The type of session to create. Always `realtime` for the Realtime API.\n   */\n  type: 'realtime';\n\n  /**\n   * Configuration for input and output audio.\n   */\n  audio?: RealtimeSessionCreateResponse.Audio;\n\n  /**\n   * Additional fields to include in server outputs.\n   *\n   * `item.input_audio_transcription.logprobs`: Include logprobs for input audio\n   * transcription.\n   */\n  include?: Array<'item.input_audio_transcription.logprobs'>;\n\n  /**\n   * The default system instructions (i.e. system message) prepended to model calls.\n   * This field allows the client to guide the model on desired responses. The model\n   * can be instructed on response content and format, (e.g. \"be extremely succinct\",\n   * \"act friendly\", \"here are examples of good responses\") and on audio behavior\n   * (e.g. \"talk quickly\", \"inject emotion into your voice\", \"laugh frequently\"). The\n   * instructions are not guaranteed to be followed by the model, but they provide\n   * guidance to the model on the desired behavior.\n   *\n   * Note that the server sets default instructions which will be used if this field\n   * is not set and are visible in the `session.created` event at the start of the\n   * session.\n   */\n  instructions?: string;\n\n  /**\n   * Maximum number of output tokens for a single assistant response, inclusive of\n   * tool calls. Provide an integer between 1 and 4096 to limit output tokens, or\n   * `inf` for the maximum available tokens for a given model. Defaults to `inf`.\n   */\n  max_output_tokens?: number | 'inf';\n\n  /**\n   * The Realtime model used for this session.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-realtime'\n    | 'gpt-realtime-2025-08-28'\n    | 'gpt-4o-realtime-preview'\n    | 'gpt-4o-realtime-preview-2024-10-01'\n    | 'gpt-4o-realtime-preview-2024-12-17'\n    | 'gpt-4o-realtime-preview-2025-06-03'\n    | 'gpt-4o-mini-realtime-preview'\n    | 'gpt-4o-mini-realtime-preview-2024-12-17'\n    | 'gpt-realtime-mini'\n    | 'gpt-realtime-mini-2025-10-06'\n    | 'gpt-audio-mini'\n    | 'gpt-audio-mini-2025-10-06';\n\n  /**\n   * The set of modalities the model can respond with. It defaults to `[\"audio\"]`,\n   * indicating that the model will respond with audio plus a transcript. `[\"text\"]`\n   * can be used to make the model respond with text only. It is not possible to\n   * request both `text` and `audio` at the same time.\n   */\n  output_modalities?: Array<'text' | 'audio'>;\n\n  /**\n   * Reference to a prompt template and its variables.\n   * [Learn more](https://platform.openai.com/docs/guides/text?api-mode=responses#reusable-prompts).\n   */\n  prompt?: ResponsesAPI.ResponsePrompt | null;\n\n  /**\n   * How the model chooses tools. Provide one of the string modes or force a specific\n   * function/MCP tool.\n   */\n  tool_choice?: ResponsesAPI.ToolChoiceOptions | ResponsesAPI.ToolChoiceFunction | ResponsesAPI.ToolChoiceMcp;\n\n  /**\n   * Tools available to the model.\n   */\n  tools?: Array<RealtimeAPI.RealtimeFunctionTool | RealtimeSessionCreateResponse.McpTool>;\n\n  /**\n   * Realtime API can write session traces to the\n   * [Traces Dashboard](/logs?api=traces). Set to null to disable tracing. Once\n   * tracing is enabled for a session, the configuration cannot be modified.\n   *\n   * `auto` will create a trace for the session with default values for the workflow\n   * name, group id, and metadata.\n   */\n  tracing?: 'auto' | RealtimeSessionCreateResponse.TracingConfiguration | null;\n\n  /**\n   * When the number of tokens in a conversation exceeds the model's input token\n   * limit, the conversation be truncated, meaning messages (starting from the\n   * oldest) will not be included in the model's context. A 32k context model with\n   * 4,096 max output tokens can only include 28,224 tokens in the context before\n   * truncation occurs. Clients can configure truncation behavior to truncate with a\n   * lower max token limit, which is an effective way to control token usage and\n   * cost. Truncation will reduce the number of cached tokens on the next turn\n   * (busting the cache), since messages are dropped from the beginning of the\n   * context. However, clients can also configure truncation to retain messages up to\n   * a fraction of the maximum context size, which will reduce the need for future\n   * truncations and thus improve the cache rate. Truncation can be disabled\n   * entirely, which means the server will never truncate but would instead return an\n   * error if the conversation exceeds the model's input token limit.\n   */\n  truncation?: RealtimeAPI.RealtimeTruncation;\n}\n\nexport namespace RealtimeSessionCreateResponse {\n  /**\n   * Configuration for input and output audio.\n   */\n  export interface Audio {\n    input?: Audio.Input;\n\n    output?: Audio.Output;\n  }\n\n  export namespace Audio {\n    export interface Input {\n      /**\n       * The format of the input audio.\n       */\n      format?: RealtimeAPI.RealtimeAudioFormats;\n\n      /**\n       * Configuration for input audio noise reduction. This can be set to `null` to turn\n       * off. Noise reduction filters audio added to the input audio buffer before it is\n       * sent to VAD and the model. Filtering the audio can improve VAD and turn\n       * detection accuracy (reducing false positives) and model performance by improving\n       * perception of the input audio.\n       */\n      noise_reduction?: Input.NoiseReduction;\n\n      /**\n       * Configuration for input audio transcription, defaults to off and can be set to\n       * `null` to turn off once on. Input audio transcription is not native to the\n       * model, since the model consumes audio directly. Transcription runs\n       * asynchronously through\n       * [the /audio/transcriptions endpoint](https://platform.openai.com/docs/api-reference/audio/createTranscription)\n       * and should be treated as guidance of input audio content rather than precisely\n       * what the model heard. The client can optionally set the language and prompt for\n       * transcription, these offer additional guidance to the transcription service.\n       */\n      transcription?: RealtimeAPI.AudioTranscription;\n\n      /**\n       * Configuration for turn detection, ether Server VAD or Semantic VAD. This can be\n       * set to `null` to turn off, in which case the client must manually trigger model\n       * response.\n       *\n       * Server VAD means that the model will detect the start and end of speech based on\n       * audio volume and respond at the end of user speech.\n       *\n       * Semantic VAD is more advanced and uses a turn detection model (in conjunction\n       * with VAD) to semantically estimate whether the user has finished speaking, then\n       * dynamically sets a timeout based on this probability. For example, if user audio\n       * trails off with \"uhhm\", the model will score a low probability of turn end and\n       * wait longer for the user to continue speaking. This can be useful for more\n       * natural conversations, but may have a higher latency.\n       */\n      turn_detection?: Input.ServerVad | Input.SemanticVad | null;\n    }\n\n    export namespace Input {\n      /**\n       * Configuration for input audio noise reduction. This can be set to `null` to turn\n       * off. Noise reduction filters audio added to the input audio buffer before it is\n       * sent to VAD and the model. Filtering the audio can improve VAD and turn\n       * detection accuracy (reducing false positives) and model performance by improving\n       * perception of the input audio.\n       */\n      export interface NoiseReduction {\n        /**\n         * Type of noise reduction. `near_field` is for close-talking microphones such as\n         * headphones, `far_field` is for far-field microphones such as laptop or\n         * conference room microphones.\n         */\n        type?: RealtimeAPI.NoiseReductionType;\n      }\n\n      /**\n       * Server-side voice activity detection (VAD) which flips on when user speech is\n       * detected and off after a period of silence.\n       */\n      export interface ServerVad {\n        /**\n         * Type of turn detection, `server_vad` to turn on simple Server VAD.\n         */\n        type: 'server_vad';\n\n        /**\n         * Whether or not to automatically generate a response when a VAD stop event\n         * occurs.\n         */\n        create_response?: boolean;\n\n        /**\n         * Optional timeout after which a model response will be triggered automatically.\n         * This is useful for situations in which a long pause from the user is unexpected,\n         * such as a phone call. The model will effectively prompt the user to continue the\n         * conversation based on the current context.\n         *\n         * The timeout value will be applied after the last model response's audio has\n         * finished playing, i.e. it's set to the `response.done` time plus audio playback\n         * duration.\n         *\n         * An `input_audio_buffer.timeout_triggered` event (plus events associated with the\n         * Response) will be emitted when the timeout is reached. Idle timeout is currently\n         * only supported for `server_vad` mode.\n         */\n        idle_timeout_ms?: number | null;\n\n        /**\n         * Whether or not to automatically interrupt any ongoing response with output to\n         * the default conversation (i.e. `conversation` of `auto`) when a VAD start event\n         * occurs.\n         */\n        interrupt_response?: boolean;\n\n        /**\n         * Used only for `server_vad` mode. Amount of audio to include before the VAD\n         * detected speech (in milliseconds). Defaults to 300ms.\n         */\n        prefix_padding_ms?: number;\n\n        /**\n         * Used only for `server_vad` mode. Duration of silence to detect speech stop (in\n         * milliseconds). Defaults to 500ms. With shorter values the model will respond\n         * more quickly, but may jump in on short pauses from the user.\n         */\n        silence_duration_ms?: number;\n\n        /**\n         * Used only for `server_vad` mode. Activation threshold for VAD (0.0 to 1.0), this\n         * defaults to 0.5. A higher threshold will require louder audio to activate the\n         * model, and thus might perform better in noisy environments.\n         */\n        threshold?: number;\n      }\n\n      /**\n       * Server-side semantic turn detection which uses a model to determine when the\n       * user has finished speaking.\n       */\n      export interface SemanticVad {\n        /**\n         * Type of turn detection, `semantic_vad` to turn on Semantic VAD.\n         */\n        type: 'semantic_vad';\n\n        /**\n         * Whether or not to automatically generate a response when a VAD stop event\n         * occurs.\n         */\n        create_response?: boolean;\n\n        /**\n         * Used only for `semantic_vad` mode. The eagerness of the model to respond. `low`\n         * will wait longer for the user to continue speaking, `high` will respond more\n         * quickly. `auto` is the default and is equivalent to `medium`. `low`, `medium`,\n         * and `high` have max timeouts of 8s, 4s, and 2s respectively.\n         */\n        eagerness?: 'low' | 'medium' | 'high' | 'auto';\n\n        /**\n         * Whether or not to automatically interrupt any ongoing response with output to\n         * the default conversation (i.e. `conversation` of `auto`) when a VAD start event\n         * occurs.\n         */\n        interrupt_response?: boolean;\n      }\n    }\n\n    export interface Output {\n      /**\n       * The format of the output audio.\n       */\n      format?: RealtimeAPI.RealtimeAudioFormats;\n\n      /**\n       * The speed of the model's spoken response as a multiple of the original speed.\n       * 1.0 is the default speed. 0.25 is the minimum speed. 1.5 is the maximum speed.\n       * This value can only be changed in between model turns, not while a response is\n       * in progress.\n       *\n       * This parameter is a post-processing adjustment to the audio after it is\n       * generated, it's also possible to prompt the model to speak faster or slower.\n       */\n      speed?: number;\n\n      /**\n       * The voice the model uses to respond. Voice cannot be changed during the session\n       * once the model has responded with audio at least once. Current voice options are\n       * `alloy`, `ash`, `ballad`, `coral`, `echo`, `sage`, `shimmer`, `verse`, `marin`,\n       * and `cedar`. We recommend `marin` and `cedar` for best quality.\n       */\n      voice?:\n        | (string & {})\n        | 'alloy'\n        | 'ash'\n        | 'ballad'\n        | 'coral'\n        | 'echo'\n        | 'sage'\n        | 'shimmer'\n        | 'verse'\n        | 'marin'\n        | 'cedar';\n    }\n  }\n\n  /**\n   * Give the model access to additional tools via remote Model Context Protocol\n   * (MCP) servers.\n   * [Learn more about MCP](https://platform.openai.com/docs/guides/tools-remote-mcp).\n   */\n  export interface McpTool {\n    /**\n     * A label for this MCP server, used to identify it in tool calls.\n     */\n    server_label: string;\n\n    /**\n     * The type of the MCP tool. Always `mcp`.\n     */\n    type: 'mcp';\n\n    /**\n     * List of allowed tool names or a filter object.\n     */\n    allowed_tools?: Array<string> | McpTool.McpToolFilter | null;\n\n    /**\n     * An OAuth access token that can be used with a remote MCP server, either with a\n     * custom MCP server URL or a service connector. Your application must handle the\n     * OAuth authorization flow and provide the token here.\n     */\n    authorization?: string;\n\n    /**\n     * Identifier for service connectors, like those available in ChatGPT. One of\n     * `server_url` or `connector_id` must be provided. Learn more about service\n     * connectors\n     * [here](https://platform.openai.com/docs/guides/tools-remote-mcp#connectors).\n     *\n     * Currently supported `connector_id` values are:\n     *\n     * - Dropbox: `connector_dropbox`\n     * - Gmail: `connector_gmail`\n     * - Google Calendar: `connector_googlecalendar`\n     * - Google Drive: `connector_googledrive`\n     * - Microsoft Teams: `connector_microsoftteams`\n     * - Outlook Calendar: `connector_outlookcalendar`\n     * - Outlook Email: `connector_outlookemail`\n     * - SharePoint: `connector_sharepoint`\n     */\n    connector_id?:\n      | 'connector_dropbox'\n      | 'connector_gmail'\n      | 'connector_googlecalendar'\n      | 'connector_googledrive'\n      | 'connector_microsoftteams'\n      | 'connector_outlookcalendar'\n      | 'connector_outlookemail'\n      | 'connector_sharepoint';\n\n    /**\n     * Optional HTTP headers to send to the MCP server. Use for authentication or other\n     * purposes.\n     */\n    headers?: { [key: string]: string } | null;\n\n    /**\n     * Specify which of the MCP server's tools require approval.\n     */\n    require_approval?: McpTool.McpToolApprovalFilter | 'always' | 'never' | null;\n\n    /**\n     * Optional description of the MCP server, used to provide more context.\n     */\n    server_description?: string;\n\n    /**\n     * The URL for the MCP server. One of `server_url` or `connector_id` must be\n     * provided.\n     */\n    server_url?: string;\n  }\n\n  export namespace McpTool {\n    /**\n     * A filter object to specify which tools are allowed.\n     */\n    export interface McpToolFilter {\n      /**\n       * Indicates whether or not a tool modifies data or is read-only. If an MCP server\n       * is\n       * [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\n       * it will match this filter.\n       */\n      read_only?: boolean;\n\n      /**\n       * List of allowed tool names.\n       */\n      tool_names?: Array<string>;\n    }\n\n    /**\n     * Specify which of the MCP server's tools require approval. Can be `always`,\n     * `never`, or a filter object associated with tools that require approval.\n     */\n    export interface McpToolApprovalFilter {\n      /**\n       * A filter object to specify which tools are allowed.\n       */\n      always?: McpToolApprovalFilter.Always;\n\n      /**\n       * A filter object to specify which tools are allowed.\n       */\n      never?: McpToolApprovalFilter.Never;\n    }\n\n    export namespace McpToolApprovalFilter {\n      /**\n       * A filter object to specify which tools are allowed.\n       */\n      export interface Always {\n        /**\n         * Indicates whether or not a tool modifies data or is read-only. If an MCP server\n         * is\n         * [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\n         * it will match this filter.\n         */\n        read_only?: boolean;\n\n        /**\n         * List of allowed tool names.\n         */\n        tool_names?: Array<string>;\n      }\n\n      /**\n       * A filter object to specify which tools are allowed.\n       */\n      export interface Never {\n        /**\n         * Indicates whether or not a tool modifies data or is read-only. If an MCP server\n         * is\n         * [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\n         * it will match this filter.\n         */\n        read_only?: boolean;\n\n        /**\n         * List of allowed tool names.\n         */\n        tool_names?: Array<string>;\n      }\n    }\n  }\n\n  /**\n   * Granular configuration for tracing.\n   */\n  export interface TracingConfiguration {\n    /**\n     * The group id to attach to this trace to enable filtering and grouping in the\n     * Traces Dashboard.\n     */\n    group_id?: string;\n\n    /**\n     * The arbitrary metadata to attach to this trace to enable filtering in the Traces\n     * Dashboard.\n     */\n    metadata?: unknown;\n\n    /**\n     * The name of the workflow to attach to this trace. This is used to name the trace\n     * in the Traces Dashboard.\n     */\n    workflow_name?: string;\n  }\n}\n\n/**\n * A Realtime transcription session configuration object.\n */\nexport interface RealtimeTranscriptionSessionCreateResponse {\n  /**\n   * Unique identifier for the session that looks like `sess_1234567890abcdef`.\n   */\n  id: string;\n\n  /**\n   * The object type. Always `realtime.transcription_session`.\n   */\n  object: string;\n\n  /**\n   * The type of session. Always `transcription` for transcription sessions.\n   */\n  type: 'transcription';\n\n  /**\n   * Configuration for input audio for the session.\n   */\n  audio?: RealtimeTranscriptionSessionCreateResponse.Audio;\n\n  /**\n   * Expiration timestamp for the session, in seconds since epoch.\n   */\n  expires_at?: number;\n\n  /**\n   * Additional fields to include in server outputs.\n   *\n   * - `item.input_audio_transcription.logprobs`: Include logprobs for input audio\n   *   transcription.\n   */\n  include?: Array<'item.input_audio_transcription.logprobs'>;\n}\n\nexport namespace RealtimeTranscriptionSessionCreateResponse {\n  /**\n   * Configuration for input audio for the session.\n   */\n  export interface Audio {\n    input?: Audio.Input;\n  }\n\n  export namespace Audio {\n    export interface Input {\n      /**\n       * The PCM audio format. Only a 24kHz sample rate is supported.\n       */\n      format?: RealtimeAPI.RealtimeAudioFormats;\n\n      /**\n       * Configuration for input audio noise reduction.\n       */\n      noise_reduction?: Input.NoiseReduction;\n\n      /**\n       * Configuration of the transcription model.\n       */\n      transcription?: RealtimeAPI.AudioTranscription;\n\n      /**\n       * Configuration for turn detection. Can be set to `null` to turn off. Server VAD\n       * means that the model will detect the start and end of speech based on audio\n       * volume and respond at the end of user speech.\n       */\n      turn_detection?: ClientSecretsAPI.RealtimeTranscriptionSessionTurnDetection;\n    }\n\n    export namespace Input {\n      /**\n       * Configuration for input audio noise reduction.\n       */\n      export interface NoiseReduction {\n        /**\n         * Type of noise reduction. `near_field` is for close-talking microphones such as\n         * headphones, `far_field` is for far-field microphones such as laptop or\n         * conference room microphones.\n         */\n        type?: RealtimeAPI.NoiseReductionType;\n      }\n    }\n  }\n}\n\n/**\n * Configuration for turn detection. Can be set to `null` to turn off. Server VAD\n * means that the model will detect the start and end of speech based on audio\n * volume and respond at the end of user speech.\n */\nexport interface RealtimeTranscriptionSessionTurnDetection {\n  /**\n   * Amount of audio to include before the VAD detected speech (in milliseconds).\n   * Defaults to 300ms.\n   */\n  prefix_padding_ms?: number;\n\n  /**\n   * Duration of silence to detect speech stop (in milliseconds). Defaults to 500ms.\n   * With shorter values the model will respond more quickly, but may jump in on\n   * short pauses from the user.\n   */\n  silence_duration_ms?: number;\n\n  /**\n   * Activation threshold for VAD (0.0 to 1.0), this defaults to 0.5. A higher\n   * threshold will require louder audio to activate the model, and thus might\n   * perform better in noisy environments.\n   */\n  threshold?: number;\n\n  /**\n   * Type of turn detection, only `server_vad` is currently supported.\n   */\n  type?: string;\n}\n\n/**\n * Response from creating a session and client secret for the Realtime API.\n */\nexport interface ClientSecretCreateResponse {\n  /**\n   * Expiration timestamp for the client secret, in seconds since epoch.\n   */\n  expires_at: number;\n\n  /**\n   * The session configuration for either a realtime or transcription session.\n   */\n  session: RealtimeSessionCreateResponse | RealtimeTranscriptionSessionCreateResponse;\n\n  /**\n   * The generated client secret value.\n   */\n  value: string;\n}\n\nexport interface ClientSecretCreateParams {\n  /**\n   * Configuration for the client secret expiration. Expiration refers to the time\n   * after which a client secret will no longer be valid for creating sessions. The\n   * session itself may continue after that time once started. A secret can be used\n   * to create multiple sessions until it expires.\n   */\n  expires_after?: ClientSecretCreateParams.ExpiresAfter;\n\n  /**\n   * Session configuration to use for the client secret. Choose either a realtime\n   * session or a transcription session.\n   */\n  session?: RealtimeAPI.RealtimeSessionCreateRequest | RealtimeAPI.RealtimeTranscriptionSessionCreateRequest;\n}\n\nexport namespace ClientSecretCreateParams {\n  /**\n   * Configuration for the client secret expiration. Expiration refers to the time\n   * after which a client secret will no longer be valid for creating sessions. The\n   * session itself may continue after that time once started. A secret can be used\n   * to create multiple sessions until it expires.\n   */\n  export interface ExpiresAfter {\n    /**\n     * The anchor point for the client secret expiration, meaning that `seconds` will\n     * be added to the `created_at` time of the client secret to produce an expiration\n     * timestamp. Only `created_at` is currently supported.\n     */\n    anchor?: 'created_at';\n\n    /**\n     * The number of seconds from the anchor point to the expiration. Select a value\n     * between `10` and `7200` (2 hours). This default to 600 seconds (10 minutes) if\n     * not specified.\n     */\n    seconds?: number;\n  }\n}\n\nexport declare namespace ClientSecrets {\n  export {\n    type RealtimeSessionClientSecret as RealtimeSessionClientSecret,\n    type RealtimeSessionCreateResponse as RealtimeSessionCreateResponse,\n    type RealtimeTranscriptionSessionCreateResponse as RealtimeTranscriptionSessionCreateResponse,\n    type RealtimeTranscriptionSessionTurnDetection as RealtimeTranscriptionSessionTurnDetection,\n    type ClientSecretCreateResponse as ClientSecretCreateResponse,\n    type ClientSecretCreateParams as ClientSecretCreateParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as RealtimeAPI from './realtime';\nimport * as Shared from '../shared';\nimport * as CallsAPI from './calls';\nimport { CallAcceptParams, CallReferParams, CallRejectParams, Calls } from './calls';\nimport * as ClientSecretsAPI from './client-secrets';\nimport {\n  ClientSecretCreateParams,\n  ClientSecretCreateResponse,\n  ClientSecrets,\n  RealtimeSessionClientSecret,\n  RealtimeSessionCreateResponse,\n  RealtimeTranscriptionSessionCreateResponse,\n  RealtimeTranscriptionSessionTurnDetection,\n} from './client-secrets';\nimport * as ResponsesAPI from '../responses/responses';\n\nexport class Realtime extends APIResource {\n  clientSecrets: ClientSecretsAPI.ClientSecrets = new ClientSecretsAPI.ClientSecrets(this._client);\n  calls: CallsAPI.Calls = new CallsAPI.Calls(this._client);\n}\n\nexport interface AudioTranscription {\n  /**\n   * The language of the input audio. Supplying the input language in\n   * [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`)\n   * format will improve accuracy and latency.\n   */\n  language?: string;\n\n  /**\n   * The model to use for transcription. Current options are `whisper-1`,\n   * `gpt-4o-mini-transcribe`, `gpt-4o-transcribe`, and `gpt-4o-transcribe-diarize`.\n   * Use `gpt-4o-transcribe-diarize` when you need diarization with speaker labels.\n   */\n  model?: 'whisper-1' | 'gpt-4o-mini-transcribe' | 'gpt-4o-transcribe' | 'gpt-4o-transcribe-diarize';\n\n  /**\n   * An optional text to guide the model's style or continue a previous audio\n   * segment. For `whisper-1`, the\n   * [prompt is a list of keywords](https://platform.openai.com/docs/guides/speech-to-text#prompting).\n   * For `gpt-4o-transcribe` models (excluding `gpt-4o-transcribe-diarize`), the\n   * prompt is a free text string, for example \"expect words related to technology\".\n   */\n  prompt?: string;\n}\n\n/**\n * Returned when a conversation is created. Emitted right after session creation.\n */\nexport interface ConversationCreatedEvent {\n  /**\n   * The conversation resource.\n   */\n  conversation: ConversationCreatedEvent.Conversation;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The event type, must be `conversation.created`.\n   */\n  type: 'conversation.created';\n}\n\nexport namespace ConversationCreatedEvent {\n  /**\n   * The conversation resource.\n   */\n  export interface Conversation {\n    /**\n     * The unique ID of the conversation.\n     */\n    id?: string;\n\n    /**\n     * The object type, must be `realtime.conversation`.\n     */\n    object?: 'realtime.conversation';\n  }\n}\n\n/**\n * A single item within a Realtime conversation.\n */\nexport type ConversationItem =\n  | RealtimeConversationItemSystemMessage\n  | RealtimeConversationItemUserMessage\n  | RealtimeConversationItemAssistantMessage\n  | RealtimeConversationItemFunctionCall\n  | RealtimeConversationItemFunctionCallOutput\n  | RealtimeMcpApprovalResponse\n  | RealtimeMcpListTools\n  | RealtimeMcpToolCall\n  | RealtimeMcpApprovalRequest;\n\n/**\n * Sent by the server when an Item is added to the default Conversation. This can\n * happen in several cases:\n *\n * - When the client sends a `conversation.item.create` event.\n * - When the input audio buffer is committed. In this case the item will be a user\n *   message containing the audio from the buffer.\n * - When the model is generating a Response. In this case the\n *   `conversation.item.added` event will be sent when the model starts generating\n *   a specific Item, and thus it will not yet have any content (and `status` will\n *   be `in_progress`).\n *\n * The event will include the full content of the Item (except when model is\n * generating a Response) except for audio data, which can be retrieved separately\n * with a `conversation.item.retrieve` event if necessary.\n */\nexport interface ConversationItemAdded {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * A single item within a Realtime conversation.\n   */\n  item: ConversationItem;\n\n  /**\n   * The event type, must be `conversation.item.added`.\n   */\n  type: 'conversation.item.added';\n\n  /**\n   * The ID of the item that precedes this one, if any. This is used to maintain\n   * ordering when items are inserted.\n   */\n  previous_item_id?: string | null;\n}\n\n/**\n * Add a new Item to the Conversation's context, including messages, function\n * calls, and function call responses. This event can be used both to populate a\n * \"history\" of the conversation and to add new items mid-stream, but has the\n * current limitation that it cannot populate assistant audio messages.\n *\n * If successful, the server will respond with a `conversation.item.created` event,\n * otherwise an `error` event will be sent.\n */\nexport interface ConversationItemCreateEvent {\n  /**\n   * A single item within a Realtime conversation.\n   */\n  item: ConversationItem;\n\n  /**\n   * The event type, must be `conversation.item.create`.\n   */\n  type: 'conversation.item.create';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n\n  /**\n   * The ID of the preceding item after which the new item will be inserted. If not\n   * set, the new item will be appended to the end of the conversation. If set to\n   * `root`, the new item will be added to the beginning of the conversation. If set\n   * to an existing ID, it allows an item to be inserted mid-conversation. If the ID\n   * cannot be found, an error will be returned and the item will not be added.\n   */\n  previous_item_id?: string;\n}\n\n/**\n * Returned when a conversation item is created. There are several scenarios that\n * produce this event:\n *\n * - The server is generating a Response, which if successful will produce either\n *   one or two Items, which will be of type `message` (role `assistant`) or type\n *   `function_call`.\n * - The input audio buffer has been committed, either by the client or the server\n *   (in `server_vad` mode). The server will take the content of the input audio\n *   buffer and add it to a new user message Item.\n * - The client has sent a `conversation.item.create` event to add a new Item to\n *   the Conversation.\n */\nexport interface ConversationItemCreatedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * A single item within a Realtime conversation.\n   */\n  item: ConversationItem;\n\n  /**\n   * The event type, must be `conversation.item.created`.\n   */\n  type: 'conversation.item.created';\n\n  /**\n   * The ID of the preceding item in the Conversation context, allows the client to\n   * understand the order of the conversation. Can be `null` if the item has no\n   * predecessor.\n   */\n  previous_item_id?: string | null;\n}\n\n/**\n * Send this event when you want to remove any item from the conversation history.\n * The server will respond with a `conversation.item.deleted` event, unless the\n * item does not exist in the conversation history, in which case the server will\n * respond with an error.\n */\nexport interface ConversationItemDeleteEvent {\n  /**\n   * The ID of the item to delete.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.delete`.\n   */\n  type: 'conversation.item.delete';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\n/**\n * Returned when an item in the conversation is deleted by the client with a\n * `conversation.item.delete` event. This event is used to synchronize the server's\n * understanding of the conversation history with the client's view.\n */\nexport interface ConversationItemDeletedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item that was deleted.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.deleted`.\n   */\n  type: 'conversation.item.deleted';\n}\n\n/**\n * Returned when a conversation item is finalized.\n *\n * The event will include the full content of the Item except for audio data, which\n * can be retrieved separately with a `conversation.item.retrieve` event if needed.\n */\nexport interface ConversationItemDone {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * A single item within a Realtime conversation.\n   */\n  item: ConversationItem;\n\n  /**\n   * The event type, must be `conversation.item.done`.\n   */\n  type: 'conversation.item.done';\n\n  /**\n   * The ID of the item that precedes this one, if any. This is used to maintain\n   * ordering when items are inserted.\n   */\n  previous_item_id?: string | null;\n}\n\n/**\n * This event is the output of audio transcription for user audio written to the\n * user audio buffer. Transcription begins when the input audio buffer is committed\n * by the client or server (when VAD is enabled). Transcription runs asynchronously\n * with Response creation, so this event may come before or after the Response\n * events.\n *\n * Realtime API models accept audio natively, and thus input transcription is a\n * separate process run on a separate ASR (Automatic Speech Recognition) model. The\n * transcript may diverge somewhat from the model's interpretation, and should be\n * treated as a rough guide.\n */\nexport interface ConversationItemInputAudioTranscriptionCompletedEvent {\n  /**\n   * The index of the content part containing the audio.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item containing the audio that is being transcribed.\n   */\n  item_id: string;\n\n  /**\n   * The transcribed text.\n   */\n  transcript: string;\n\n  /**\n   * The event type, must be `conversation.item.input_audio_transcription.completed`.\n   */\n  type: 'conversation.item.input_audio_transcription.completed';\n\n  /**\n   * Usage statistics for the transcription, this is billed according to the ASR\n   * model's pricing rather than the realtime model's pricing.\n   */\n  usage:\n    | ConversationItemInputAudioTranscriptionCompletedEvent.TranscriptTextUsageTokens\n    | ConversationItemInputAudioTranscriptionCompletedEvent.TranscriptTextUsageDuration;\n\n  /**\n   * The log probabilities of the transcription.\n   */\n  logprobs?: Array<LogProbProperties> | null;\n}\n\nexport namespace ConversationItemInputAudioTranscriptionCompletedEvent {\n  /**\n   * Usage statistics for models billed by token usage.\n   */\n  export interface TranscriptTextUsageTokens {\n    /**\n     * Number of input tokens billed for this request.\n     */\n    input_tokens: number;\n\n    /**\n     * Number of output tokens generated.\n     */\n    output_tokens: number;\n\n    /**\n     * Total number of tokens used (input + output).\n     */\n    total_tokens: number;\n\n    /**\n     * The type of the usage object. Always `tokens` for this variant.\n     */\n    type: 'tokens';\n\n    /**\n     * Details about the input tokens billed for this request.\n     */\n    input_token_details?: TranscriptTextUsageTokens.InputTokenDetails;\n  }\n\n  export namespace TranscriptTextUsageTokens {\n    /**\n     * Details about the input tokens billed for this request.\n     */\n    export interface InputTokenDetails {\n      /**\n       * Number of audio tokens billed for this request.\n       */\n      audio_tokens?: number;\n\n      /**\n       * Number of text tokens billed for this request.\n       */\n      text_tokens?: number;\n    }\n  }\n\n  /**\n   * Usage statistics for models billed by audio input duration.\n   */\n  export interface TranscriptTextUsageDuration {\n    /**\n     * Duration of the input audio in seconds.\n     */\n    seconds: number;\n\n    /**\n     * The type of the usage object. Always `duration` for this variant.\n     */\n    type: 'duration';\n  }\n}\n\n/**\n * Returned when the text value of an input audio transcription content part is\n * updated with incremental transcription results.\n */\nexport interface ConversationItemInputAudioTranscriptionDeltaEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item containing the audio that is being transcribed.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.input_audio_transcription.delta`.\n   */\n  type: 'conversation.item.input_audio_transcription.delta';\n\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index?: number;\n\n  /**\n   * The text delta.\n   */\n  delta?: string;\n\n  /**\n   * The log probabilities of the transcription. These can be enabled by\n   * configurating the session with\n   * `\"include\": [\"item.input_audio_transcription.logprobs\"]`. Each entry in the\n   * array corresponds a log probability of which token would be selected for this\n   * chunk of transcription. This can help to identify if it was possible there were\n   * multiple valid options for a given chunk of transcription.\n   */\n  logprobs?: Array<LogProbProperties> | null;\n}\n\n/**\n * Returned when input audio transcription is configured, and a transcription\n * request for a user message failed. These events are separate from other `error`\n * events so that the client can identify the related Item.\n */\nexport interface ConversationItemInputAudioTranscriptionFailedEvent {\n  /**\n   * The index of the content part containing the audio.\n   */\n  content_index: number;\n\n  /**\n   * Details of the transcription error.\n   */\n  error: ConversationItemInputAudioTranscriptionFailedEvent.Error;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the user message item.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.input_audio_transcription.failed`.\n   */\n  type: 'conversation.item.input_audio_transcription.failed';\n}\n\nexport namespace ConversationItemInputAudioTranscriptionFailedEvent {\n  /**\n   * Details of the transcription error.\n   */\n  export interface Error {\n    /**\n     * Error code, if any.\n     */\n    code?: string;\n\n    /**\n     * A human-readable error message.\n     */\n    message?: string;\n\n    /**\n     * Parameter related to the error, if any.\n     */\n    param?: string;\n\n    /**\n     * The type of error.\n     */\n    type?: string;\n  }\n}\n\n/**\n * Returned when an input audio transcription segment is identified for an item.\n */\nexport interface ConversationItemInputAudioTranscriptionSegment {\n  /**\n   * The segment identifier.\n   */\n  id: string;\n\n  /**\n   * The index of the input audio content part within the item.\n   */\n  content_index: number;\n\n  /**\n   * End time of the segment in seconds.\n   */\n  end: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item containing the input audio content.\n   */\n  item_id: string;\n\n  /**\n   * The detected speaker label for this segment.\n   */\n  speaker: string;\n\n  /**\n   * Start time of the segment in seconds.\n   */\n  start: number;\n\n  /**\n   * The text for this segment.\n   */\n  text: string;\n\n  /**\n   * The event type, must be `conversation.item.input_audio_transcription.segment`.\n   */\n  type: 'conversation.item.input_audio_transcription.segment';\n}\n\n/**\n * Send this event when you want to retrieve the server's representation of a\n * specific item in the conversation history. This is useful, for example, to\n * inspect user audio after noise cancellation and VAD. The server will respond\n * with a `conversation.item.retrieved` event, unless the item does not exist in\n * the conversation history, in which case the server will respond with an error.\n */\nexport interface ConversationItemRetrieveEvent {\n  /**\n   * The ID of the item to retrieve.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.retrieve`.\n   */\n  type: 'conversation.item.retrieve';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\n/**\n * Send this event to truncate a previous assistant messages audio. The server\n * will produce audio faster than realtime, so this event is useful when the user\n * interrupts to truncate audio that has already been sent to the client but not\n * yet played. This will synchronize the server's understanding of the audio with\n * the client's playback.\n *\n * Truncating audio will delete the server-side text transcript to ensure there is\n * not text in the context that hasn't been heard by the user.\n *\n * If successful, the server will respond with a `conversation.item.truncated`\n * event.\n */\nexport interface ConversationItemTruncateEvent {\n  /**\n   * Inclusive duration up to which audio is truncated, in milliseconds. If the\n   * audio_end_ms is greater than the actual audio duration, the server will respond\n   * with an error.\n   */\n  audio_end_ms: number;\n\n  /**\n   * The index of the content part to truncate. Set this to `0`.\n   */\n  content_index: number;\n\n  /**\n   * The ID of the assistant message item to truncate. Only assistant message items\n   * can be truncated.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.truncate`.\n   */\n  type: 'conversation.item.truncate';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\n/**\n * Returned when an earlier assistant audio message item is truncated by the client\n * with a `conversation.item.truncate` event. This event is used to synchronize the\n * server's understanding of the audio with the client's playback.\n *\n * This action will truncate the audio and remove the server-side text transcript\n * to ensure there is no text in the context that hasn't been heard by the user.\n */\nexport interface ConversationItemTruncatedEvent {\n  /**\n   * The duration up to which the audio was truncated, in milliseconds.\n   */\n  audio_end_ms: number;\n\n  /**\n   * The index of the content part that was truncated.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the assistant message item that was truncated.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.truncated`.\n   */\n  type: 'conversation.item.truncated';\n}\n\n/**\n * The item to add to the conversation.\n */\nexport interface ConversationItemWithReference {\n  /**\n   * For an item of type (`message` | `function_call` | `function_call_output`) this\n   * field allows the client to assign the unique ID of the item. It is not required\n   * because the server will generate one if not provided.\n   *\n   * For an item of type `item_reference`, this field is required and is a reference\n   * to any item that has previously existed in the conversation.\n   */\n  id?: string;\n\n  /**\n   * The arguments of the function call (for `function_call` items).\n   */\n  arguments?: string;\n\n  /**\n   * The ID of the function call (for `function_call` and `function_call_output`\n   * items). If passed on a `function_call_output` item, the server will check that a\n   * `function_call` item with the same ID exists in the conversation history.\n   */\n  call_id?: string;\n\n  /**\n   * The content of the message, applicable for `message` items.\n   *\n   * - Message items of role `system` support only `input_text` content\n   * - Message items of role `user` support `input_text` and `input_audio` content\n   * - Message items of role `assistant` support `text` content.\n   */\n  content?: Array<ConversationItemWithReference.Content>;\n\n  /**\n   * The name of the function being called (for `function_call` items).\n   */\n  name?: string;\n\n  /**\n   * Identifier for the API object being returned - always `realtime.item`.\n   */\n  object?: 'realtime.item';\n\n  /**\n   * The output of the function call (for `function_call_output` items).\n   */\n  output?: string;\n\n  /**\n   * The role of the message sender (`user`, `assistant`, `system`), only applicable\n   * for `message` items.\n   */\n  role?: 'user' | 'assistant' | 'system';\n\n  /**\n   * The status of the item (`completed`, `incomplete`, `in_progress`). These have no\n   * effect on the conversation, but are accepted for consistency with the\n   * `conversation.item.created` event.\n   */\n  status?: 'completed' | 'incomplete' | 'in_progress';\n\n  /**\n   * The type of the item (`message`, `function_call`, `function_call_output`,\n   * `item_reference`).\n   */\n  type?: 'message' | 'function_call' | 'function_call_output' | 'item_reference';\n}\n\nexport namespace ConversationItemWithReference {\n  export interface Content {\n    /**\n     * ID of a previous conversation item to reference (for `item_reference` content\n     * types in `response.create` events). These can reference both client and server\n     * created items.\n     */\n    id?: string;\n\n    /**\n     * Base64-encoded audio bytes, used for `input_audio` content type.\n     */\n    audio?: string;\n\n    /**\n     * The text content, used for `input_text` and `text` content types.\n     */\n    text?: string;\n\n    /**\n     * The transcript of the audio, used for `input_audio` content type.\n     */\n    transcript?: string;\n\n    /**\n     * The content type (`input_text`, `input_audio`, `item_reference`, `text`).\n     */\n    type?: 'input_text' | 'input_audio' | 'item_reference' | 'text';\n  }\n}\n\n/**\n * Send this event to append audio bytes to the input audio buffer. The audio\n * buffer is temporary storage you can write to and later commit. A \"commit\" will\n * create a new user message item in the conversation history from the buffer\n * content and clear the buffer. Input audio transcription (if enabled) will be\n * generated when the buffer is committed.\n *\n * If VAD is enabled the audio buffer is used to detect speech and the server will\n * decide when to commit. When Server VAD is disabled, you must commit the audio\n * buffer manually. Input audio noise reduction operates on writes to the audio\n * buffer.\n *\n * The client may choose how much audio to place in each event up to a maximum of\n * 15 MiB, for example streaming smaller chunks from the client may allow the VAD\n * to be more responsive. Unlike most other client events, the server will not send\n * a confirmation response to this event.\n */\nexport interface InputAudioBufferAppendEvent {\n  /**\n   * Base64-encoded audio bytes. This must be in the format specified by the\n   * `input_audio_format` field in the session configuration.\n   */\n  audio: string;\n\n  /**\n   * The event type, must be `input_audio_buffer.append`.\n   */\n  type: 'input_audio_buffer.append';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\n/**\n * Send this event to clear the audio bytes in the buffer. The server will respond\n * with an `input_audio_buffer.cleared` event.\n */\nexport interface InputAudioBufferClearEvent {\n  /**\n   * The event type, must be `input_audio_buffer.clear`.\n   */\n  type: 'input_audio_buffer.clear';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\n/**\n * Returned when the input audio buffer is cleared by the client with a\n * `input_audio_buffer.clear` event.\n */\nexport interface InputAudioBufferClearedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The event type, must be `input_audio_buffer.cleared`.\n   */\n  type: 'input_audio_buffer.cleared';\n}\n\n/**\n * Send this event to commit the user input audio buffer, which will create a new\n * user message item in the conversation. This event will produce an error if the\n * input audio buffer is empty. When in Server VAD mode, the client does not need\n * to send this event, the server will commit the audio buffer automatically.\n *\n * Committing the input audio buffer will trigger input audio transcription (if\n * enabled in session configuration), but it will not create a response from the\n * model. The server will respond with an `input_audio_buffer.committed` event.\n */\nexport interface InputAudioBufferCommitEvent {\n  /**\n   * The event type, must be `input_audio_buffer.commit`.\n   */\n  type: 'input_audio_buffer.commit';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\n/**\n * Returned when an input audio buffer is committed, either by the client or\n * automatically in server VAD mode. The `item_id` property is the ID of the user\n * message item that will be created, thus a `conversation.item.created` event will\n * also be sent to the client.\n */\nexport interface InputAudioBufferCommittedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the user message item that will be created.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `input_audio_buffer.committed`.\n   */\n  type: 'input_audio_buffer.committed';\n\n  /**\n   * The ID of the preceding item after which the new item will be inserted. Can be\n   * `null` if the item has no predecessor.\n   */\n  previous_item_id?: string | null;\n}\n\n/**\n * Sent by the server when in `server_vad` mode to indicate that speech has been\n * detected in the audio buffer. This can happen any time audio is added to the\n * buffer (unless speech is already detected). The client may want to use this\n * event to interrupt audio playback or provide visual feedback to the user.\n *\n * The client should expect to receive a `input_audio_buffer.speech_stopped` event\n * when speech stops. The `item_id` property is the ID of the user message item\n * that will be created when speech stops and will also be included in the\n * `input_audio_buffer.speech_stopped` event (unless the client manually commits\n * the audio buffer during VAD activation).\n */\nexport interface InputAudioBufferSpeechStartedEvent {\n  /**\n   * Milliseconds from the start of all audio written to the buffer during the\n   * session when speech was first detected. This will correspond to the beginning of\n   * audio sent to the model, and thus includes the `prefix_padding_ms` configured in\n   * the Session.\n   */\n  audio_start_ms: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the user message item that will be created when speech stops.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `input_audio_buffer.speech_started`.\n   */\n  type: 'input_audio_buffer.speech_started';\n}\n\n/**\n * Returned in `server_vad` mode when the server detects the end of speech in the\n * audio buffer. The server will also send an `conversation.item.created` event\n * with the user message item that is created from the audio buffer.\n */\nexport interface InputAudioBufferSpeechStoppedEvent {\n  /**\n   * Milliseconds since the session started when speech stopped. This will correspond\n   * to the end of audio sent to the model, and thus includes the\n   * `min_silence_duration_ms` configured in the Session.\n   */\n  audio_end_ms: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the user message item that will be created.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `input_audio_buffer.speech_stopped`.\n   */\n  type: 'input_audio_buffer.speech_stopped';\n}\n\n/**\n * Returned when the Server VAD timeout is triggered for the input audio buffer.\n * This is configured with `idle_timeout_ms` in the `turn_detection` settings of\n * the session, and it indicates that there hasn't been any speech detected for the\n * configured duration.\n *\n * The `audio_start_ms` and `audio_end_ms` fields indicate the segment of audio\n * after the last model response up to the triggering time, as an offset from the\n * beginning of audio written to the input audio buffer. This means it demarcates\n * the segment of audio that was silent and the difference between the start and\n * end values will roughly match the configured timeout.\n *\n * The empty audio will be committed to the conversation as an `input_audio` item\n * (there will be a `input_audio_buffer.committed` event) and a model response will\n * be generated. There may be speech that didn't trigger VAD but is still detected\n * by the model, so the model may respond with something relevant to the\n * conversation or a prompt to continue speaking.\n */\nexport interface InputAudioBufferTimeoutTriggered {\n  /**\n   * Millisecond offset of audio written to the input audio buffer at the time the\n   * timeout was triggered.\n   */\n  audio_end_ms: number;\n\n  /**\n   * Millisecond offset of audio written to the input audio buffer that was after the\n   * playback time of the last model response.\n   */\n  audio_start_ms: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item associated with this segment.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `input_audio_buffer.timeout_triggered`.\n   */\n  type: 'input_audio_buffer.timeout_triggered';\n}\n\n/**\n * A log probability object.\n */\nexport interface LogProbProperties {\n  /**\n   * The token that was used to generate the log probability.\n   */\n  token: string;\n\n  /**\n   * The bytes that were used to generate the log probability.\n   */\n  bytes: Array<number>;\n\n  /**\n   * The log probability of the token.\n   */\n  logprob: number;\n}\n\n/**\n * Returned when listing MCP tools has completed for an item.\n */\nexport interface McpListToolsCompleted {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the MCP list tools item.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `mcp_list_tools.completed`.\n   */\n  type: 'mcp_list_tools.completed';\n}\n\n/**\n * Returned when listing MCP tools has failed for an item.\n */\nexport interface McpListToolsFailed {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the MCP list tools item.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `mcp_list_tools.failed`.\n   */\n  type: 'mcp_list_tools.failed';\n}\n\n/**\n * Returned when listing MCP tools is in progress for an item.\n */\nexport interface McpListToolsInProgress {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the MCP list tools item.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `mcp_list_tools.in_progress`.\n   */\n  type: 'mcp_list_tools.in_progress';\n}\n\n/**\n * Type of noise reduction. `near_field` is for close-talking microphones such as\n * headphones, `far_field` is for far-field microphones such as laptop or\n * conference room microphones.\n */\nexport type NoiseReductionType = 'near_field' | 'far_field';\n\n/**\n * **WebRTC Only:** Emit to cut off the current audio response. This will trigger\n * the server to stop generating audio and emit a `output_audio_buffer.cleared`\n * event. This event should be preceded by a `response.cancel` client event to stop\n * the generation of the current response.\n * [Learn more](https://platform.openai.com/docs/guides/realtime-conversations#client-and-server-events-for-audio-in-webrtc).\n */\nexport interface OutputAudioBufferClearEvent {\n  /**\n   * The event type, must be `output_audio_buffer.clear`.\n   */\n  type: 'output_audio_buffer.clear';\n\n  /**\n   * The unique ID of the client event used for error handling.\n   */\n  event_id?: string;\n}\n\n/**\n * Emitted at the beginning of a Response to indicate the updated rate limits. When\n * a Response is created some tokens will be \"reserved\" for the output tokens, the\n * rate limits shown here reflect that reservation, which is then adjusted\n * accordingly once the Response is completed.\n */\nexport interface RateLimitsUpdatedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * List of rate limit information.\n   */\n  rate_limits: Array<RateLimitsUpdatedEvent.RateLimit>;\n\n  /**\n   * The event type, must be `rate_limits.updated`.\n   */\n  type: 'rate_limits.updated';\n}\n\nexport namespace RateLimitsUpdatedEvent {\n  export interface RateLimit {\n    /**\n     * The maximum allowed value for the rate limit.\n     */\n    limit?: number;\n\n    /**\n     * The name of the rate limit (`requests`, `tokens`).\n     */\n    name?: 'requests' | 'tokens';\n\n    /**\n     * The remaining value before the limit is reached.\n     */\n    remaining?: number;\n\n    /**\n     * Seconds until the rate limit resets.\n     */\n    reset_seconds?: number;\n  }\n}\n\n/**\n * Configuration for input and output audio.\n */\nexport interface RealtimeAudioConfig {\n  input?: RealtimeAudioConfigInput;\n\n  output?: RealtimeAudioConfigOutput;\n}\n\nexport interface RealtimeAudioConfigInput {\n  /**\n   * The format of the input audio.\n   */\n  format?: RealtimeAudioFormats;\n\n  /**\n   * Configuration for input audio noise reduction. This can be set to `null` to turn\n   * off. Noise reduction filters audio added to the input audio buffer before it is\n   * sent to VAD and the model. Filtering the audio can improve VAD and turn\n   * detection accuracy (reducing false positives) and model performance by improving\n   * perception of the input audio.\n   */\n  noise_reduction?: RealtimeAudioConfigInput.NoiseReduction;\n\n  /**\n   * Configuration for input audio transcription, defaults to off and can be set to\n   * `null` to turn off once on. Input audio transcription is not native to the\n   * model, since the model consumes audio directly. Transcription runs\n   * asynchronously through\n   * [the /audio/transcriptions endpoint](https://platform.openai.com/docs/api-reference/audio/createTranscription)\n   * and should be treated as guidance of input audio content rather than precisely\n   * what the model heard. The client can optionally set the language and prompt for\n   * transcription, these offer additional guidance to the transcription service.\n   */\n  transcription?: AudioTranscription;\n\n  /**\n   * Configuration for turn detection, ether Server VAD or Semantic VAD. This can be\n   * set to `null` to turn off, in which case the client must manually trigger model\n   * response.\n   *\n   * Server VAD means that the model will detect the start and end of speech based on\n   * audio volume and respond at the end of user speech.\n   *\n   * Semantic VAD is more advanced and uses a turn detection model (in conjunction\n   * with VAD) to semantically estimate whether the user has finished speaking, then\n   * dynamically sets a timeout based on this probability. For example, if user audio\n   * trails off with \"uhhm\", the model will score a low probability of turn end and\n   * wait longer for the user to continue speaking. This can be useful for more\n   * natural conversations, but may have a higher latency.\n   */\n  turn_detection?: RealtimeAudioInputTurnDetection | null;\n}\n\nexport namespace RealtimeAudioConfigInput {\n  /**\n   * Configuration for input audio noise reduction. This can be set to `null` to turn\n   * off. Noise reduction filters audio added to the input audio buffer before it is\n   * sent to VAD and the model. Filtering the audio can improve VAD and turn\n   * detection accuracy (reducing false positives) and model performance by improving\n   * perception of the input audio.\n   */\n  export interface NoiseReduction {\n    /**\n     * Type of noise reduction. `near_field` is for close-talking microphones such as\n     * headphones, `far_field` is for far-field microphones such as laptop or\n     * conference room microphones.\n     */\n    type?: RealtimeAPI.NoiseReductionType;\n  }\n}\n\nexport interface RealtimeAudioConfigOutput {\n  /**\n   * The format of the output audio.\n   */\n  format?: RealtimeAudioFormats;\n\n  /**\n   * The speed of the model's spoken response as a multiple of the original speed.\n   * 1.0 is the default speed. 0.25 is the minimum speed. 1.5 is the maximum speed.\n   * This value can only be changed in between model turns, not while a response is\n   * in progress.\n   *\n   * This parameter is a post-processing adjustment to the audio after it is\n   * generated, it's also possible to prompt the model to speak faster or slower.\n   */\n  speed?: number;\n\n  /**\n   * The voice the model uses to respond. Voice cannot be changed during the session\n   * once the model has responded with audio at least once. Current voice options are\n   * `alloy`, `ash`, `ballad`, `coral`, `echo`, `sage`, `shimmer`, `verse`, `marin`,\n   * and `cedar`. We recommend `marin` and `cedar` for best quality.\n   */\n  voice?:\n    | (string & {})\n    | 'alloy'\n    | 'ash'\n    | 'ballad'\n    | 'coral'\n    | 'echo'\n    | 'sage'\n    | 'shimmer'\n    | 'verse'\n    | 'marin'\n    | 'cedar';\n}\n\n/**\n * The PCM audio format. Only a 24kHz sample rate is supported.\n */\nexport type RealtimeAudioFormats =\n  | RealtimeAudioFormats.AudioPCM\n  | RealtimeAudioFormats.AudioPCMU\n  | RealtimeAudioFormats.AudioPCMA;\n\nexport namespace RealtimeAudioFormats {\n  /**\n   * The PCM audio format. Only a 24kHz sample rate is supported.\n   */\n  export interface AudioPCM {\n    /**\n     * The sample rate of the audio. Always `24000`.\n     */\n    rate?: 24000;\n\n    /**\n     * The audio format. Always `audio/pcm`.\n     */\n    type?: 'audio/pcm';\n  }\n\n  /**\n   * The G.711 -law format.\n   */\n  export interface AudioPCMU {\n    /**\n     * The audio format. Always `audio/pcmu`.\n     */\n    type?: 'audio/pcmu';\n  }\n\n  /**\n   * The G.711 A-law format.\n   */\n  export interface AudioPCMA {\n    /**\n     * The audio format. Always `audio/pcma`.\n     */\n    type?: 'audio/pcma';\n  }\n}\n\n/**\n * Configuration for turn detection, ether Server VAD or Semantic VAD. This can be\n * set to `null` to turn off, in which case the client must manually trigger model\n * response.\n *\n * Server VAD means that the model will detect the start and end of speech based on\n * audio volume and respond at the end of user speech.\n *\n * Semantic VAD is more advanced and uses a turn detection model (in conjunction\n * with VAD) to semantically estimate whether the user has finished speaking, then\n * dynamically sets a timeout based on this probability. For example, if user audio\n * trails off with \"uhhm\", the model will score a low probability of turn end and\n * wait longer for the user to continue speaking. This can be useful for more\n * natural conversations, but may have a higher latency.\n */\nexport type RealtimeAudioInputTurnDetection =\n  | RealtimeAudioInputTurnDetection.ServerVad\n  | RealtimeAudioInputTurnDetection.SemanticVad;\n\nexport namespace RealtimeAudioInputTurnDetection {\n  /**\n   * Server-side voice activity detection (VAD) which flips on when user speech is\n   * detected and off after a period of silence.\n   */\n  export interface ServerVad {\n    /**\n     * Type of turn detection, `server_vad` to turn on simple Server VAD.\n     */\n    type: 'server_vad';\n\n    /**\n     * Whether or not to automatically generate a response when a VAD stop event\n     * occurs.\n     */\n    create_response?: boolean;\n\n    /**\n     * Optional timeout after which a model response will be triggered automatically.\n     * This is useful for situations in which a long pause from the user is unexpected,\n     * such as a phone call. The model will effectively prompt the user to continue the\n     * conversation based on the current context.\n     *\n     * The timeout value will be applied after the last model response's audio has\n     * finished playing, i.e. it's set to the `response.done` time plus audio playback\n     * duration.\n     *\n     * An `input_audio_buffer.timeout_triggered` event (plus events associated with the\n     * Response) will be emitted when the timeout is reached. Idle timeout is currently\n     * only supported for `server_vad` mode.\n     */\n    idle_timeout_ms?: number | null;\n\n    /**\n     * Whether or not to automatically interrupt any ongoing response with output to\n     * the default conversation (i.e. `conversation` of `auto`) when a VAD start event\n     * occurs.\n     */\n    interrupt_response?: boolean;\n\n    /**\n     * Used only for `server_vad` mode. Amount of audio to include before the VAD\n     * detected speech (in milliseconds). Defaults to 300ms.\n     */\n    prefix_padding_ms?: number;\n\n    /**\n     * Used only for `server_vad` mode. Duration of silence to detect speech stop (in\n     * milliseconds). Defaults to 500ms. With shorter values the model will respond\n     * more quickly, but may jump in on short pauses from the user.\n     */\n    silence_duration_ms?: number;\n\n    /**\n     * Used only for `server_vad` mode. Activation threshold for VAD (0.0 to 1.0), this\n     * defaults to 0.5. A higher threshold will require louder audio to activate the\n     * model, and thus might perform better in noisy environments.\n     */\n    threshold?: number;\n  }\n\n  /**\n   * Server-side semantic turn detection which uses a model to determine when the\n   * user has finished speaking.\n   */\n  export interface SemanticVad {\n    /**\n     * Type of turn detection, `semantic_vad` to turn on Semantic VAD.\n     */\n    type: 'semantic_vad';\n\n    /**\n     * Whether or not to automatically generate a response when a VAD stop event\n     * occurs.\n     */\n    create_response?: boolean;\n\n    /**\n     * Used only for `semantic_vad` mode. The eagerness of the model to respond. `low`\n     * will wait longer for the user to continue speaking, `high` will respond more\n     * quickly. `auto` is the default and is equivalent to `medium`. `low`, `medium`,\n     * and `high` have max timeouts of 8s, 4s, and 2s respectively.\n     */\n    eagerness?: 'low' | 'medium' | 'high' | 'auto';\n\n    /**\n     * Whether or not to automatically interrupt any ongoing response with output to\n     * the default conversation (i.e. `conversation` of `auto`) when a VAD start event\n     * occurs.\n     */\n    interrupt_response?: boolean;\n  }\n}\n\n/**\n * A realtime client event.\n */\nexport type RealtimeClientEvent =\n  | ConversationItemCreateEvent\n  | ConversationItemDeleteEvent\n  | ConversationItemRetrieveEvent\n  | ConversationItemTruncateEvent\n  | InputAudioBufferAppendEvent\n  | InputAudioBufferClearEvent\n  | OutputAudioBufferClearEvent\n  | InputAudioBufferCommitEvent\n  | ResponseCancelEvent\n  | ResponseCreateEvent\n  | SessionUpdateEvent;\n\n/**\n * An assistant message item in a Realtime conversation.\n */\nexport interface RealtimeConversationItemAssistantMessage {\n  /**\n   * The content of the message.\n   */\n  content: Array<RealtimeConversationItemAssistantMessage.Content>;\n\n  /**\n   * The role of the message sender. Always `assistant`.\n   */\n  role: 'assistant';\n\n  /**\n   * The type of the item. Always `message`.\n   */\n  type: 'message';\n\n  /**\n   * The unique ID of the item. This may be provided by the client or generated by\n   * the server.\n   */\n  id?: string;\n\n  /**\n   * Identifier for the API object being returned - always `realtime.item`. Optional\n   * when creating a new item.\n   */\n  object?: 'realtime.item';\n\n  /**\n   * The status of the item. Has no effect on the conversation.\n   */\n  status?: 'completed' | 'incomplete' | 'in_progress';\n}\n\nexport namespace RealtimeConversationItemAssistantMessage {\n  export interface Content {\n    /**\n     * Base64-encoded audio bytes, these will be parsed as the format specified in the\n     * session output audio type configuration. This defaults to PCM 16-bit 24kHz mono\n     * if not specified.\n     */\n    audio?: string;\n\n    /**\n     * The text content.\n     */\n    text?: string;\n\n    /**\n     * The transcript of the audio content, this will always be present if the output\n     * type is `audio`.\n     */\n    transcript?: string;\n\n    /**\n     * The content type, `output_text` or `output_audio` depending on the session\n     * `output_modalities` configuration.\n     */\n    type?: 'output_text' | 'output_audio';\n  }\n}\n\n/**\n * A function call item in a Realtime conversation.\n */\nexport interface RealtimeConversationItemFunctionCall {\n  /**\n   * The arguments of the function call. This is a JSON-encoded string representing\n   * the arguments passed to the function, for example\n   * `{\"arg1\": \"value1\", \"arg2\": 42}`.\n   */\n  arguments: string;\n\n  /**\n   * The name of the function being called.\n   */\n  name: string;\n\n  /**\n   * The type of the item. Always `function_call`.\n   */\n  type: 'function_call';\n\n  /**\n   * The unique ID of the item. This may be provided by the client or generated by\n   * the server.\n   */\n  id?: string;\n\n  /**\n   * The ID of the function call.\n   */\n  call_id?: string;\n\n  /**\n   * Identifier for the API object being returned - always `realtime.item`. Optional\n   * when creating a new item.\n   */\n  object?: 'realtime.item';\n\n  /**\n   * The status of the item. Has no effect on the conversation.\n   */\n  status?: 'completed' | 'incomplete' | 'in_progress';\n}\n\n/**\n * A function call output item in a Realtime conversation.\n */\nexport interface RealtimeConversationItemFunctionCallOutput {\n  /**\n   * The ID of the function call this output is for.\n   */\n  call_id: string;\n\n  /**\n   * The output of the function call, this is free text and can contain any\n   * information or simply be empty.\n   */\n  output: string;\n\n  /**\n   * The type of the item. Always `function_call_output`.\n   */\n  type: 'function_call_output';\n\n  /**\n   * The unique ID of the item. This may be provided by the client or generated by\n   * the server.\n   */\n  id?: string;\n\n  /**\n   * Identifier for the API object being returned - always `realtime.item`. Optional\n   * when creating a new item.\n   */\n  object?: 'realtime.item';\n\n  /**\n   * The status of the item. Has no effect on the conversation.\n   */\n  status?: 'completed' | 'incomplete' | 'in_progress';\n}\n\n/**\n * A system message in a Realtime conversation can be used to provide additional\n * context or instructions to the model. This is similar but distinct from the\n * instruction prompt provided at the start of a conversation, as system messages\n * can be added at any point in the conversation. For major changes to the\n * conversation's behavior, use instructions, but for smaller updates (e.g. \"the\n * user is now asking about a different topic\"), use system messages.\n */\nexport interface RealtimeConversationItemSystemMessage {\n  /**\n   * The content of the message.\n   */\n  content: Array<RealtimeConversationItemSystemMessage.Content>;\n\n  /**\n   * The role of the message sender. Always `system`.\n   */\n  role: 'system';\n\n  /**\n   * The type of the item. Always `message`.\n   */\n  type: 'message';\n\n  /**\n   * The unique ID of the item. This may be provided by the client or generated by\n   * the server.\n   */\n  id?: string;\n\n  /**\n   * Identifier for the API object being returned - always `realtime.item`. Optional\n   * when creating a new item.\n   */\n  object?: 'realtime.item';\n\n  /**\n   * The status of the item. Has no effect on the conversation.\n   */\n  status?: 'completed' | 'incomplete' | 'in_progress';\n}\n\nexport namespace RealtimeConversationItemSystemMessage {\n  export interface Content {\n    /**\n     * The text content.\n     */\n    text?: string;\n\n    /**\n     * The content type. Always `input_text` for system messages.\n     */\n    type?: 'input_text';\n  }\n}\n\n/**\n * A user message item in a Realtime conversation.\n */\nexport interface RealtimeConversationItemUserMessage {\n  /**\n   * The content of the message.\n   */\n  content: Array<RealtimeConversationItemUserMessage.Content>;\n\n  /**\n   * The role of the message sender. Always `user`.\n   */\n  role: 'user';\n\n  /**\n   * The type of the item. Always `message`.\n   */\n  type: 'message';\n\n  /**\n   * The unique ID of the item. This may be provided by the client or generated by\n   * the server.\n   */\n  id?: string;\n\n  /**\n   * Identifier for the API object being returned - always `realtime.item`. Optional\n   * when creating a new item.\n   */\n  object?: 'realtime.item';\n\n  /**\n   * The status of the item. Has no effect on the conversation.\n   */\n  status?: 'completed' | 'incomplete' | 'in_progress';\n}\n\nexport namespace RealtimeConversationItemUserMessage {\n  export interface Content {\n    /**\n     * Base64-encoded audio bytes (for `input_audio`), these will be parsed as the\n     * format specified in the session input audio type configuration. This defaults to\n     * PCM 16-bit 24kHz mono if not specified.\n     */\n    audio?: string;\n\n    /**\n     * The detail level of the image (for `input_image`). `auto` will default to\n     * `high`.\n     */\n    detail?: 'auto' | 'low' | 'high';\n\n    /**\n     * Base64-encoded image bytes (for `input_image`) as a data URI. For example\n     * `data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...`. Supported formats are PNG\n     * and JPEG.\n     */\n    image_url?: string;\n\n    /**\n     * The text content (for `input_text`).\n     */\n    text?: string;\n\n    /**\n     * Transcript of the audio (for `input_audio`). This is not sent to the model, but\n     * will be attached to the message item for reference.\n     */\n    transcript?: string;\n\n    /**\n     * The content type (`input_text`, `input_audio`, or `input_image`).\n     */\n    type?: 'input_text' | 'input_audio' | 'input_image';\n  }\n}\n\n/**\n * Details of the error.\n */\nexport interface RealtimeError {\n  /**\n   * A human-readable error message.\n   */\n  message: string;\n\n  /**\n   * The type of error (e.g., \"invalid_request_error\", \"server_error\").\n   */\n  type: string;\n\n  /**\n   * Error code, if any.\n   */\n  code?: string | null;\n\n  /**\n   * The event_id of the client event that caused the error, if applicable.\n   */\n  event_id?: string | null;\n\n  /**\n   * Parameter related to the error, if any.\n   */\n  param?: string | null;\n}\n\n/**\n * Returned when an error occurs, which could be a client problem or a server\n * problem. Most errors are recoverable and the session will stay open, we\n * recommend to implementors to monitor and log error messages by default.\n */\nexport interface RealtimeErrorEvent {\n  /**\n   * Details of the error.\n   */\n  error: RealtimeError;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The event type, must be `error`.\n   */\n  type: 'error';\n}\n\nexport interface RealtimeFunctionTool {\n  /**\n   * The description of the function, including guidance on when and how to call it,\n   * and guidance about what to tell the user when calling (if anything).\n   */\n  description?: string;\n\n  /**\n   * The name of the function.\n   */\n  name?: string;\n\n  /**\n   * Parameters of the function in JSON Schema.\n   */\n  parameters?: unknown;\n\n  /**\n   * The type of the tool, i.e. `function`.\n   */\n  type?: 'function';\n}\n\n/**\n * A Realtime item requesting human approval of a tool invocation.\n */\nexport interface RealtimeMcpApprovalRequest {\n  /**\n   * The unique ID of the approval request.\n   */\n  id: string;\n\n  /**\n   * A JSON string of arguments for the tool.\n   */\n  arguments: string;\n\n  /**\n   * The name of the tool to run.\n   */\n  name: string;\n\n  /**\n   * The label of the MCP server making the request.\n   */\n  server_label: string;\n\n  /**\n   * The type of the item. Always `mcp_approval_request`.\n   */\n  type: 'mcp_approval_request';\n}\n\n/**\n * A Realtime item responding to an MCP approval request.\n */\nexport interface RealtimeMcpApprovalResponse {\n  /**\n   * The unique ID of the approval response.\n   */\n  id: string;\n\n  /**\n   * The ID of the approval request being answered.\n   */\n  approval_request_id: string;\n\n  /**\n   * Whether the request was approved.\n   */\n  approve: boolean;\n\n  /**\n   * The type of the item. Always `mcp_approval_response`.\n   */\n  type: 'mcp_approval_response';\n\n  /**\n   * Optional reason for the decision.\n   */\n  reason?: string | null;\n}\n\n/**\n * A Realtime item listing tools available on an MCP server.\n */\nexport interface RealtimeMcpListTools {\n  /**\n   * The label of the MCP server.\n   */\n  server_label: string;\n\n  /**\n   * The tools available on the server.\n   */\n  tools: Array<RealtimeMcpListTools.Tool>;\n\n  /**\n   * The type of the item. Always `mcp_list_tools`.\n   */\n  type: 'mcp_list_tools';\n\n  /**\n   * The unique ID of the list.\n   */\n  id?: string;\n}\n\nexport namespace RealtimeMcpListTools {\n  /**\n   * A tool available on an MCP server.\n   */\n  export interface Tool {\n    /**\n     * The JSON schema describing the tool's input.\n     */\n    input_schema: unknown;\n\n    /**\n     * The name of the tool.\n     */\n    name: string;\n\n    /**\n     * Additional annotations about the tool.\n     */\n    annotations?: unknown | null;\n\n    /**\n     * The description of the tool.\n     */\n    description?: string | null;\n  }\n}\n\nexport interface RealtimeMcpProtocolError {\n  code: number;\n\n  message: string;\n\n  type: 'protocol_error';\n}\n\n/**\n * A Realtime item representing an invocation of a tool on an MCP server.\n */\nexport interface RealtimeMcpToolCall {\n  /**\n   * The unique ID of the tool call.\n   */\n  id: string;\n\n  /**\n   * A JSON string of the arguments passed to the tool.\n   */\n  arguments: string;\n\n  /**\n   * The name of the tool that was run.\n   */\n  name: string;\n\n  /**\n   * The label of the MCP server running the tool.\n   */\n  server_label: string;\n\n  /**\n   * The type of the item. Always `mcp_call`.\n   */\n  type: 'mcp_call';\n\n  /**\n   * The ID of an associated approval request, if any.\n   */\n  approval_request_id?: string | null;\n\n  /**\n   * The error from the tool call, if any.\n   */\n  error?: RealtimeMcpProtocolError | RealtimeMcpToolExecutionError | RealtimeMcphttpError | null;\n\n  /**\n   * The output from the tool call.\n   */\n  output?: string | null;\n}\n\nexport interface RealtimeMcpToolExecutionError {\n  message: string;\n\n  type: 'tool_execution_error';\n}\n\nexport interface RealtimeMcphttpError {\n  code: number;\n\n  message: string;\n\n  type: 'http_error';\n}\n\n/**\n * The response resource.\n */\nexport interface RealtimeResponse {\n  /**\n   * The unique ID of the response, will look like `resp_1234`.\n   */\n  id?: string;\n\n  /**\n   * Configuration for audio output.\n   */\n  audio?: RealtimeResponse.Audio;\n\n  /**\n   * Which conversation the response is added to, determined by the `conversation`\n   * field in the `response.create` event. If `auto`, the response will be added to\n   * the default conversation and the value of `conversation_id` will be an id like\n   * `conv_1234`. If `none`, the response will not be added to any conversation and\n   * the value of `conversation_id` will be `null`. If responses are being triggered\n   * automatically by VAD the response will be added to the default conversation\n   */\n  conversation_id?: string;\n\n  /**\n   * Maximum number of output tokens for a single assistant response, inclusive of\n   * tool calls, that was used in this response.\n   */\n  max_output_tokens?: number | 'inf';\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The object type, must be `realtime.response`.\n   */\n  object?: 'realtime.response';\n\n  /**\n   * The list of output items generated by the response.\n   */\n  output?: Array<ConversationItem>;\n\n  /**\n   * The set of modalities the model used to respond, currently the only possible\n   * values are `[\\\"audio\\\"]`, `[\\\"text\\\"]`. Audio output always include a text\n   * transcript. Setting the output to mode `text` will disable audio output from the\n   * model.\n   */\n  output_modalities?: Array<'text' | 'audio'>;\n\n  /**\n   * The final status of the response (`completed`, `cancelled`, `failed`, or\n   * `incomplete`, `in_progress`).\n   */\n  status?: 'completed' | 'cancelled' | 'failed' | 'incomplete' | 'in_progress';\n\n  /**\n   * Additional details about the status.\n   */\n  status_details?: RealtimeResponseStatus;\n\n  /**\n   * Usage statistics for the Response, this will correspond to billing. A Realtime\n   * API session will maintain a conversation context and append new Items to the\n   * Conversation, thus output from previous turns (text and audio tokens) will\n   * become the input for later turns.\n   */\n  usage?: RealtimeResponseUsage;\n}\n\nexport namespace RealtimeResponse {\n  /**\n   * Configuration for audio output.\n   */\n  export interface Audio {\n    output?: Audio.Output;\n  }\n\n  export namespace Audio {\n    export interface Output {\n      /**\n       * The format of the output audio.\n       */\n      format?: RealtimeAPI.RealtimeAudioFormats;\n\n      /**\n       * The voice the model uses to respond. Voice cannot be changed during the session\n       * once the model has responded with audio at least once. Current voice options are\n       * `alloy`, `ash`, `ballad`, `coral`, `echo`, `sage`, `shimmer`, `verse`, `marin`,\n       * and `cedar`. We recommend `marin` and `cedar` for best quality.\n       */\n      voice?:\n        | (string & {})\n        | 'alloy'\n        | 'ash'\n        | 'ballad'\n        | 'coral'\n        | 'echo'\n        | 'sage'\n        | 'shimmer'\n        | 'verse'\n        | 'marin'\n        | 'cedar';\n    }\n  }\n}\n\n/**\n * Configuration for audio input and output.\n */\nexport interface RealtimeResponseCreateAudioOutput {\n  output?: RealtimeResponseCreateAudioOutput.Output;\n}\n\nexport namespace RealtimeResponseCreateAudioOutput {\n  export interface Output {\n    /**\n     * The format of the output audio.\n     */\n    format?: RealtimeAPI.RealtimeAudioFormats;\n\n    /**\n     * The voice the model uses to respond. Voice cannot be changed during the session\n     * once the model has responded with audio at least once. Current voice options are\n     * `alloy`, `ash`, `ballad`, `coral`, `echo`, `sage`, `shimmer`, `verse`, `marin`,\n     * and `cedar`. We recommend `marin` and `cedar` for best quality.\n     */\n    voice?:\n      | (string & {})\n      | 'alloy'\n      | 'ash'\n      | 'ballad'\n      | 'coral'\n      | 'echo'\n      | 'sage'\n      | 'shimmer'\n      | 'verse'\n      | 'marin'\n      | 'cedar';\n  }\n}\n\n/**\n * Give the model access to additional tools via remote Model Context Protocol\n * (MCP) servers.\n * [Learn more about MCP](https://platform.openai.com/docs/guides/tools-remote-mcp).\n */\nexport interface RealtimeResponseCreateMcpTool {\n  /**\n   * A label for this MCP server, used to identify it in tool calls.\n   */\n  server_label: string;\n\n  /**\n   * The type of the MCP tool. Always `mcp`.\n   */\n  type: 'mcp';\n\n  /**\n   * List of allowed tool names or a filter object.\n   */\n  allowed_tools?: Array<string> | RealtimeResponseCreateMcpTool.McpToolFilter | null;\n\n  /**\n   * An OAuth access token that can be used with a remote MCP server, either with a\n   * custom MCP server URL or a service connector. Your application must handle the\n   * OAuth authorization flow and provide the token here.\n   */\n  authorization?: string;\n\n  /**\n   * Identifier for service connectors, like those available in ChatGPT. One of\n   * `server_url` or `connector_id` must be provided. Learn more about service\n   * connectors\n   * [here](https://platform.openai.com/docs/guides/tools-remote-mcp#connectors).\n   *\n   * Currently supported `connector_id` values are:\n   *\n   * - Dropbox: `connector_dropbox`\n   * - Gmail: `connector_gmail`\n   * - Google Calendar: `connector_googlecalendar`\n   * - Google Drive: `connector_googledrive`\n   * - Microsoft Teams: `connector_microsoftteams`\n   * - Outlook Calendar: `connector_outlookcalendar`\n   * - Outlook Email: `connector_outlookemail`\n   * - SharePoint: `connector_sharepoint`\n   */\n  connector_id?:\n    | 'connector_dropbox'\n    | 'connector_gmail'\n    | 'connector_googlecalendar'\n    | 'connector_googledrive'\n    | 'connector_microsoftteams'\n    | 'connector_outlookcalendar'\n    | 'connector_outlookemail'\n    | 'connector_sharepoint';\n\n  /**\n   * Optional HTTP headers to send to the MCP server. Use for authentication or other\n   * purposes.\n   */\n  headers?: { [key: string]: string } | null;\n\n  /**\n   * Specify which of the MCP server's tools require approval.\n   */\n  require_approval?: RealtimeResponseCreateMcpTool.McpToolApprovalFilter | 'always' | 'never' | null;\n\n  /**\n   * Optional description of the MCP server, used to provide more context.\n   */\n  server_description?: string;\n\n  /**\n   * The URL for the MCP server. One of `server_url` or `connector_id` must be\n   * provided.\n   */\n  server_url?: string;\n}\n\nexport namespace RealtimeResponseCreateMcpTool {\n  /**\n   * A filter object to specify which tools are allowed.\n   */\n  export interface McpToolFilter {\n    /**\n     * Indicates whether or not a tool modifies data or is read-only. If an MCP server\n     * is\n     * [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\n     * it will match this filter.\n     */\n    read_only?: boolean;\n\n    /**\n     * List of allowed tool names.\n     */\n    tool_names?: Array<string>;\n  }\n\n  /**\n   * Specify which of the MCP server's tools require approval. Can be `always`,\n   * `never`, or a filter object associated with tools that require approval.\n   */\n  export interface McpToolApprovalFilter {\n    /**\n     * A filter object to specify which tools are allowed.\n     */\n    always?: McpToolApprovalFilter.Always;\n\n    /**\n     * A filter object to specify which tools are allowed.\n     */\n    never?: McpToolApprovalFilter.Never;\n  }\n\n  export namespace McpToolApprovalFilter {\n    /**\n     * A filter object to specify which tools are allowed.\n     */\n    export interface Always {\n      /**\n       * Indicates whether or not a tool modifies data or is read-only. If an MCP server\n       * is\n       * [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\n       * it will match this filter.\n       */\n      read_only?: boolean;\n\n      /**\n       * List of allowed tool names.\n       */\n      tool_names?: Array<string>;\n    }\n\n    /**\n     * A filter object to specify which tools are allowed.\n     */\n    export interface Never {\n      /**\n       * Indicates whether or not a tool modifies data or is read-only. If an MCP server\n       * is\n       * [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\n       * it will match this filter.\n       */\n      read_only?: boolean;\n\n      /**\n       * List of allowed tool names.\n       */\n      tool_names?: Array<string>;\n    }\n  }\n}\n\n/**\n * Create a new Realtime response with these parameters\n */\nexport interface RealtimeResponseCreateParams {\n  /**\n   * Configuration for audio input and output.\n   */\n  audio?: RealtimeResponseCreateAudioOutput;\n\n  /**\n   * Controls which conversation the response is added to. Currently supports `auto`\n   * and `none`, with `auto` as the default value. The `auto` value means that the\n   * contents of the response will be added to the default conversation. Set this to\n   * `none` to create an out-of-band response which will not add items to default\n   * conversation.\n   */\n  conversation?: (string & {}) | 'auto' | 'none';\n\n  /**\n   * Input items to include in the prompt for the model. Using this field creates a\n   * new context for this Response instead of using the default conversation. An\n   * empty array `[]` will clear the context for this Response. Note that this can\n   * include references to items that previously appeared in the session using their\n   * id.\n   */\n  input?: Array<ConversationItem>;\n\n  /**\n   * The default system instructions (i.e. system message) prepended to model calls.\n   * This field allows the client to guide the model on desired responses. The model\n   * can be instructed on response content and format, (e.g. \"be extremely succinct\",\n   * \"act friendly\", \"here are examples of good responses\") and on audio behavior\n   * (e.g. \"talk quickly\", \"inject emotion into your voice\", \"laugh frequently\"). The\n   * instructions are not guaranteed to be followed by the model, but they provide\n   * guidance to the model on the desired behavior. Note that the server sets default\n   * instructions which will be used if this field is not set and are visible in the\n   * `session.created` event at the start of the session.\n   */\n  instructions?: string;\n\n  /**\n   * Maximum number of output tokens for a single assistant response, inclusive of\n   * tool calls. Provide an integer between 1 and 4096 to limit output tokens, or\n   * `inf` for the maximum available tokens for a given model. Defaults to `inf`.\n   */\n  max_output_tokens?: number | 'inf';\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The set of modalities the model used to respond, currently the only possible\n   * values are `[\\\"audio\\\"]`, `[\\\"text\\\"]`. Audio output always include a text\n   * transcript. Setting the output to mode `text` will disable audio output from the\n   * model.\n   */\n  output_modalities?: Array<'text' | 'audio'>;\n\n  /**\n   * Reference to a prompt template and its variables.\n   * [Learn more](https://platform.openai.com/docs/guides/text?api-mode=responses#reusable-prompts).\n   */\n  prompt?: ResponsesAPI.ResponsePrompt | null;\n\n  /**\n   * How the model chooses tools. Provide one of the string modes or force a specific\n   * function/MCP tool.\n   */\n  tool_choice?: ResponsesAPI.ToolChoiceOptions | ResponsesAPI.ToolChoiceFunction | ResponsesAPI.ToolChoiceMcp;\n\n  /**\n   * Tools available to the model.\n   */\n  tools?: Array<RealtimeFunctionTool | RealtimeResponseCreateMcpTool>;\n}\n\n/**\n * Additional details about the status.\n */\nexport interface RealtimeResponseStatus {\n  /**\n   * A description of the error that caused the response to fail, populated when the\n   * `status` is `failed`.\n   */\n  error?: RealtimeResponseStatus.Error;\n\n  /**\n   * The reason the Response did not complete. For a `cancelled` Response, one of\n   * `turn_detected` (the server VAD detected a new start of speech) or\n   * `client_cancelled` (the client sent a cancel event). For an `incomplete`\n   * Response, one of `max_output_tokens` or `content_filter` (the server-side safety\n   * filter activated and cut off the response).\n   */\n  reason?: 'turn_detected' | 'client_cancelled' | 'max_output_tokens' | 'content_filter';\n\n  /**\n   * The type of error that caused the response to fail, corresponding with the\n   * `status` field (`completed`, `cancelled`, `incomplete`, `failed`).\n   */\n  type?: 'completed' | 'cancelled' | 'incomplete' | 'failed';\n}\n\nexport namespace RealtimeResponseStatus {\n  /**\n   * A description of the error that caused the response to fail, populated when the\n   * `status` is `failed`.\n   */\n  export interface Error {\n    /**\n     * Error code, if any.\n     */\n    code?: string;\n\n    /**\n     * The type of error.\n     */\n    type?: string;\n  }\n}\n\n/**\n * Usage statistics for the Response, this will correspond to billing. A Realtime\n * API session will maintain a conversation context and append new Items to the\n * Conversation, thus output from previous turns (text and audio tokens) will\n * become the input for later turns.\n */\nexport interface RealtimeResponseUsage {\n  /**\n   * Details about the input tokens used in the Response. Cached tokens are tokens\n   * from previous turns in the conversation that are included as context for the\n   * current response. Cached tokens here are counted as a subset of input tokens,\n   * meaning input tokens will include cached and uncached tokens.\n   */\n  input_token_details?: RealtimeResponseUsageInputTokenDetails;\n\n  /**\n   * The number of input tokens used in the Response, including text and audio\n   * tokens.\n   */\n  input_tokens?: number;\n\n  /**\n   * Details about the output tokens used in the Response.\n   */\n  output_token_details?: RealtimeResponseUsageOutputTokenDetails;\n\n  /**\n   * The number of output tokens sent in the Response, including text and audio\n   * tokens.\n   */\n  output_tokens?: number;\n\n  /**\n   * The total number of tokens in the Response including input and output text and\n   * audio tokens.\n   */\n  total_tokens?: number;\n}\n\n/**\n * Details about the input tokens used in the Response. Cached tokens are tokens\n * from previous turns in the conversation that are included as context for the\n * current response. Cached tokens here are counted as a subset of input tokens,\n * meaning input tokens will include cached and uncached tokens.\n */\nexport interface RealtimeResponseUsageInputTokenDetails {\n  /**\n   * The number of audio tokens used as input for the Response.\n   */\n  audio_tokens?: number;\n\n  /**\n   * The number of cached tokens used as input for the Response.\n   */\n  cached_tokens?: number;\n\n  /**\n   * Details about the cached tokens used as input for the Response.\n   */\n  cached_tokens_details?: RealtimeResponseUsageInputTokenDetails.CachedTokensDetails;\n\n  /**\n   * The number of image tokens used as input for the Response.\n   */\n  image_tokens?: number;\n\n  /**\n   * The number of text tokens used as input for the Response.\n   */\n  text_tokens?: number;\n}\n\nexport namespace RealtimeResponseUsageInputTokenDetails {\n  /**\n   * Details about the cached tokens used as input for the Response.\n   */\n  export interface CachedTokensDetails {\n    /**\n     * The number of cached audio tokens used as input for the Response.\n     */\n    audio_tokens?: number;\n\n    /**\n     * The number of cached image tokens used as input for the Response.\n     */\n    image_tokens?: number;\n\n    /**\n     * The number of cached text tokens used as input for the Response.\n     */\n    text_tokens?: number;\n  }\n}\n\n/**\n * Details about the output tokens used in the Response.\n */\nexport interface RealtimeResponseUsageOutputTokenDetails {\n  /**\n   * The number of audio tokens used in the Response.\n   */\n  audio_tokens?: number;\n\n  /**\n   * The number of text tokens used in the Response.\n   */\n  text_tokens?: number;\n}\n\n/**\n * A realtime server event.\n */\nexport type RealtimeServerEvent =\n  | ConversationCreatedEvent\n  | ConversationItemCreatedEvent\n  | ConversationItemDeletedEvent\n  | ConversationItemInputAudioTranscriptionCompletedEvent\n  | ConversationItemInputAudioTranscriptionDeltaEvent\n  | ConversationItemInputAudioTranscriptionFailedEvent\n  | RealtimeServerEvent.ConversationItemRetrieved\n  | ConversationItemTruncatedEvent\n  | RealtimeErrorEvent\n  | InputAudioBufferClearedEvent\n  | InputAudioBufferCommittedEvent\n  | InputAudioBufferSpeechStartedEvent\n  | InputAudioBufferSpeechStoppedEvent\n  | RateLimitsUpdatedEvent\n  | ResponseAudioDeltaEvent\n  | ResponseAudioDoneEvent\n  | ResponseAudioTranscriptDeltaEvent\n  | ResponseAudioTranscriptDoneEvent\n  | ResponseContentPartAddedEvent\n  | ResponseContentPartDoneEvent\n  | ResponseCreatedEvent\n  | ResponseDoneEvent\n  | ResponseFunctionCallArgumentsDeltaEvent\n  | ResponseFunctionCallArgumentsDoneEvent\n  | ResponseOutputItemAddedEvent\n  | ResponseOutputItemDoneEvent\n  | ResponseTextDeltaEvent\n  | ResponseTextDoneEvent\n  | SessionCreatedEvent\n  | SessionUpdatedEvent\n  | RealtimeServerEvent.OutputAudioBufferStarted\n  | RealtimeServerEvent.OutputAudioBufferStopped\n  | RealtimeServerEvent.OutputAudioBufferCleared\n  | ConversationItemAdded\n  | ConversationItemDone\n  | InputAudioBufferTimeoutTriggered\n  | ConversationItemInputAudioTranscriptionSegment\n  | McpListToolsInProgress\n  | McpListToolsCompleted\n  | McpListToolsFailed\n  | ResponseMcpCallArgumentsDelta\n  | ResponseMcpCallArgumentsDone\n  | ResponseMcpCallInProgress\n  | ResponseMcpCallCompleted\n  | ResponseMcpCallFailed;\n\nexport namespace RealtimeServerEvent {\n  /**\n   * Returned when a conversation item is retrieved with\n   * `conversation.item.retrieve`. This is provided as a way to fetch the server's\n   * representation of an item, for example to get access to the post-processed audio\n   * data after noise cancellation and VAD. It includes the full content of the Item,\n   * including audio data.\n   */\n  export interface ConversationItemRetrieved {\n    /**\n     * The unique ID of the server event.\n     */\n    event_id: string;\n\n    /**\n     * A single item within a Realtime conversation.\n     */\n    item: RealtimeAPI.ConversationItem;\n\n    /**\n     * The event type, must be `conversation.item.retrieved`.\n     */\n    type: 'conversation.item.retrieved';\n  }\n\n  /**\n   * **WebRTC Only:** Emitted when the server begins streaming audio to the client.\n   * This event is emitted after an audio content part has been added\n   * (`response.content_part.added`) to the response.\n   * [Learn more](https://platform.openai.com/docs/guides/realtime-conversations#client-and-server-events-for-audio-in-webrtc).\n   */\n  export interface OutputAudioBufferStarted {\n    /**\n     * The unique ID of the server event.\n     */\n    event_id: string;\n\n    /**\n     * The unique ID of the response that produced the audio.\n     */\n    response_id: string;\n\n    /**\n     * The event type, must be `output_audio_buffer.started`.\n     */\n    type: 'output_audio_buffer.started';\n  }\n\n  /**\n   * **WebRTC Only:** Emitted when the output audio buffer has been completely\n   * drained on the server, and no more audio is forthcoming. This event is emitted\n   * after the full response data has been sent to the client (`response.done`).\n   * [Learn more](https://platform.openai.com/docs/guides/realtime-conversations#client-and-server-events-for-audio-in-webrtc).\n   */\n  export interface OutputAudioBufferStopped {\n    /**\n     * The unique ID of the server event.\n     */\n    event_id: string;\n\n    /**\n     * The unique ID of the response that produced the audio.\n     */\n    response_id: string;\n\n    /**\n     * The event type, must be `output_audio_buffer.stopped`.\n     */\n    type: 'output_audio_buffer.stopped';\n  }\n\n  /**\n   * **WebRTC Only:** Emitted when the output audio buffer is cleared. This happens\n   * either in VAD mode when the user has interrupted\n   * (`input_audio_buffer.speech_started`), or when the client has emitted the\n   * `output_audio_buffer.clear` event to manually cut off the current audio\n   * response.\n   * [Learn more](https://platform.openai.com/docs/guides/realtime-conversations#client-and-server-events-for-audio-in-webrtc).\n   */\n  export interface OutputAudioBufferCleared {\n    /**\n     * The unique ID of the server event.\n     */\n    event_id: string;\n\n    /**\n     * The unique ID of the response that produced the audio.\n     */\n    response_id: string;\n\n    /**\n     * The event type, must be `output_audio_buffer.cleared`.\n     */\n    type: 'output_audio_buffer.cleared';\n  }\n}\n\n/**\n * Realtime session object for the beta interface.\n */\nexport interface RealtimeSession {\n  /**\n   * Unique identifier for the session that looks like `sess_1234567890abcdef`.\n   */\n  id?: string;\n\n  /**\n   * Expiration timestamp for the session, in seconds since epoch.\n   */\n  expires_at?: number;\n\n  /**\n   * Additional fields to include in server outputs.\n   *\n   * - `item.input_audio_transcription.logprobs`: Include logprobs for input audio\n   *   transcription.\n   */\n  include?: Array<'item.input_audio_transcription.logprobs'> | null;\n\n  /**\n   * The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`. For\n   * `pcm16`, input audio must be 16-bit PCM at a 24kHz sample rate, single channel\n   * (mono), and little-endian byte order.\n   */\n  input_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n  /**\n   * Configuration for input audio noise reduction. This can be set to `null` to turn\n   * off. Noise reduction filters audio added to the input audio buffer before it is\n   * sent to VAD and the model. Filtering the audio can improve VAD and turn\n   * detection accuracy (reducing false positives) and model performance by improving\n   * perception of the input audio.\n   */\n  input_audio_noise_reduction?: RealtimeSession.InputAudioNoiseReduction;\n\n  /**\n   * Configuration for input audio transcription, defaults to off and can be set to\n   * `null` to turn off once on. Input audio transcription is not native to the\n   * model, since the model consumes audio directly. Transcription runs\n   * asynchronously through\n   * [the /audio/transcriptions endpoint](https://platform.openai.com/docs/api-reference/audio/createTranscription)\n   * and should be treated as guidance of input audio content rather than precisely\n   * what the model heard. The client can optionally set the language and prompt for\n   * transcription, these offer additional guidance to the transcription service.\n   */\n  input_audio_transcription?: AudioTranscription | null;\n\n  /**\n   * The default system instructions (i.e. system message) prepended to model calls.\n   * This field allows the client to guide the model on desired responses. The model\n   * can be instructed on response content and format, (e.g. \"be extremely succinct\",\n   * \"act friendly\", \"here are examples of good responses\") and on audio behavior\n   * (e.g. \"talk quickly\", \"inject emotion into your voice\", \"laugh frequently\"). The\n   * instructions are not guaranteed to be followed by the model, but they provide\n   * guidance to the model on the desired behavior.\n   *\n   * Note that the server sets default instructions which will be used if this field\n   * is not set and are visible in the `session.created` event at the start of the\n   * session.\n   */\n  instructions?: string;\n\n  /**\n   * Maximum number of output tokens for a single assistant response, inclusive of\n   * tool calls. Provide an integer between 1 and 4096 to limit output tokens, or\n   * `inf` for the maximum available tokens for a given model. Defaults to `inf`.\n   */\n  max_response_output_tokens?: number | 'inf';\n\n  /**\n   * The set of modalities the model can respond with. To disable audio, set this to\n   * [\"text\"].\n   */\n  modalities?: Array<'text' | 'audio'>;\n\n  /**\n   * The Realtime model used for this session.\n   */\n  model?:\n    | 'gpt-realtime'\n    | 'gpt-realtime-2025-08-28'\n    | 'gpt-4o-realtime-preview'\n    | 'gpt-4o-realtime-preview-2024-10-01'\n    | 'gpt-4o-realtime-preview-2024-12-17'\n    | 'gpt-4o-realtime-preview-2025-06-03'\n    | 'gpt-4o-mini-realtime-preview'\n    | 'gpt-4o-mini-realtime-preview-2024-12-17'\n    | 'gpt-realtime-mini'\n    | 'gpt-realtime-mini-2025-10-06'\n    | 'gpt-audio-mini'\n    | 'gpt-audio-mini-2025-10-06';\n\n  /**\n   * The object type. Always `realtime.session`.\n   */\n  object?: 'realtime.session';\n\n  /**\n   * The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n   * For `pcm16`, output audio is sampled at a rate of 24kHz.\n   */\n  output_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n  /**\n   * Reference to a prompt template and its variables.\n   * [Learn more](https://platform.openai.com/docs/guides/text?api-mode=responses#reusable-prompts).\n   */\n  prompt?: ResponsesAPI.ResponsePrompt | null;\n\n  /**\n   * The speed of the model's spoken response. 1.0 is the default speed. 0.25 is the\n   * minimum speed. 1.5 is the maximum speed. This value can only be changed in\n   * between model turns, not while a response is in progress.\n   */\n  speed?: number;\n\n  /**\n   * Sampling temperature for the model, limited to [0.6, 1.2]. For audio models a\n   * temperature of 0.8 is highly recommended for best performance.\n   */\n  temperature?: number;\n\n  /**\n   * How the model chooses tools. Options are `auto`, `none`, `required`, or specify\n   * a function.\n   */\n  tool_choice?: string;\n\n  /**\n   * Tools (functions) available to the model.\n   */\n  tools?: Array<RealtimeFunctionTool>;\n\n  /**\n   * Configuration options for tracing. Set to null to disable tracing. Once tracing\n   * is enabled for a session, the configuration cannot be modified.\n   *\n   * `auto` will create a trace for the session with default values for the workflow\n   * name, group id, and metadata.\n   */\n  tracing?: 'auto' | RealtimeSession.TracingConfiguration | null;\n\n  /**\n   * Configuration for turn detection, ether Server VAD or Semantic VAD. This can be\n   * set to `null` to turn off, in which case the client must manually trigger model\n   * response.\n   *\n   * Server VAD means that the model will detect the start and end of speech based on\n   * audio volume and respond at the end of user speech.\n   *\n   * Semantic VAD is more advanced and uses a turn detection model (in conjunction\n   * with VAD) to semantically estimate whether the user has finished speaking, then\n   * dynamically sets a timeout based on this probability. For example, if user audio\n   * trails off with \"uhhm\", the model will score a low probability of turn end and\n   * wait longer for the user to continue speaking. This can be useful for more\n   * natural conversations, but may have a higher latency.\n   */\n  turn_detection?: RealtimeSession.ServerVad | RealtimeSession.SemanticVad | null;\n\n  /**\n   * The voice the model uses to respond. Voice cannot be changed during the session\n   * once the model has responded with audio at least once. Current voice options are\n   * `alloy`, `ash`, `ballad`, `coral`, `echo`, `sage`, `shimmer`, and `verse`.\n   */\n  voice?:\n    | (string & {})\n    | 'alloy'\n    | 'ash'\n    | 'ballad'\n    | 'coral'\n    | 'echo'\n    | 'sage'\n    | 'shimmer'\n    | 'verse'\n    | 'marin'\n    | 'cedar';\n}\n\nexport namespace RealtimeSession {\n  /**\n   * Configuration for input audio noise reduction. This can be set to `null` to turn\n   * off. Noise reduction filters audio added to the input audio buffer before it is\n   * sent to VAD and the model. Filtering the audio can improve VAD and turn\n   * detection accuracy (reducing false positives) and model performance by improving\n   * perception of the input audio.\n   */\n  export interface InputAudioNoiseReduction {\n    /**\n     * Type of noise reduction. `near_field` is for close-talking microphones such as\n     * headphones, `far_field` is for far-field microphones such as laptop or\n     * conference room microphones.\n     */\n    type?: RealtimeAPI.NoiseReductionType;\n  }\n\n  /**\n   * Granular configuration for tracing.\n   */\n  export interface TracingConfiguration {\n    /**\n     * The group id to attach to this trace to enable filtering and grouping in the\n     * traces dashboard.\n     */\n    group_id?: string;\n\n    /**\n     * The arbitrary metadata to attach to this trace to enable filtering in the traces\n     * dashboard.\n     */\n    metadata?: unknown;\n\n    /**\n     * The name of the workflow to attach to this trace. This is used to name the trace\n     * in the traces dashboard.\n     */\n    workflow_name?: string;\n  }\n\n  /**\n   * Server-side voice activity detection (VAD) which flips on when user speech is\n   * detected and off after a period of silence.\n   */\n  export interface ServerVad {\n    /**\n     * Type of turn detection, `server_vad` to turn on simple Server VAD.\n     */\n    type: 'server_vad';\n\n    /**\n     * Whether or not to automatically generate a response when a VAD stop event\n     * occurs.\n     */\n    create_response?: boolean;\n\n    /**\n     * Optional timeout after which a model response will be triggered automatically.\n     * This is useful for situations in which a long pause from the user is unexpected,\n     * such as a phone call. The model will effectively prompt the user to continue the\n     * conversation based on the current context.\n     *\n     * The timeout value will be applied after the last model response's audio has\n     * finished playing, i.e. it's set to the `response.done` time plus audio playback\n     * duration.\n     *\n     * An `input_audio_buffer.timeout_triggered` event (plus events associated with the\n     * Response) will be emitted when the timeout is reached. Idle timeout is currently\n     * only supported for `server_vad` mode.\n     */\n    idle_timeout_ms?: number | null;\n\n    /**\n     * Whether or not to automatically interrupt any ongoing response with output to\n     * the default conversation (i.e. `conversation` of `auto`) when a VAD start event\n     * occurs.\n     */\n    interrupt_response?: boolean;\n\n    /**\n     * Used only for `server_vad` mode. Amount of audio to include before the VAD\n     * detected speech (in milliseconds). Defaults to 300ms.\n     */\n    prefix_padding_ms?: number;\n\n    /**\n     * Used only for `server_vad` mode. Duration of silence to detect speech stop (in\n     * milliseconds). Defaults to 500ms. With shorter values the model will respond\n     * more quickly, but may jump in on short pauses from the user.\n     */\n    silence_duration_ms?: number;\n\n    /**\n     * Used only for `server_vad` mode. Activation threshold for VAD (0.0 to 1.0), this\n     * defaults to 0.5. A higher threshold will require louder audio to activate the\n     * model, and thus might perform better in noisy environments.\n     */\n    threshold?: number;\n  }\n\n  /**\n   * Server-side semantic turn detection which uses a model to determine when the\n   * user has finished speaking.\n   */\n  export interface SemanticVad {\n    /**\n     * Type of turn detection, `semantic_vad` to turn on Semantic VAD.\n     */\n    type: 'semantic_vad';\n\n    /**\n     * Whether or not to automatically generate a response when a VAD stop event\n     * occurs.\n     */\n    create_response?: boolean;\n\n    /**\n     * Used only for `semantic_vad` mode. The eagerness of the model to respond. `low`\n     * will wait longer for the user to continue speaking, `high` will respond more\n     * quickly. `auto` is the default and is equivalent to `medium`. `low`, `medium`,\n     * and `high` have max timeouts of 8s, 4s, and 2s respectively.\n     */\n    eagerness?: 'low' | 'medium' | 'high' | 'auto';\n\n    /**\n     * Whether or not to automatically interrupt any ongoing response with output to\n     * the default conversation (i.e. `conversation` of `auto`) when a VAD start event\n     * occurs.\n     */\n    interrupt_response?: boolean;\n  }\n}\n\n/**\n * Realtime session object configuration.\n */\nexport interface RealtimeSessionCreateRequest {\n  /**\n   * The type of session to create. Always `realtime` for the Realtime API.\n   */\n  type: 'realtime';\n\n  /**\n   * Configuration for input and output audio.\n   */\n  audio?: RealtimeAudioConfig;\n\n  /**\n   * Additional fields to include in server outputs.\n   *\n   * `item.input_audio_transcription.logprobs`: Include logprobs for input audio\n   * transcription.\n   */\n  include?: Array<'item.input_audio_transcription.logprobs'>;\n\n  /**\n   * The default system instructions (i.e. system message) prepended to model calls.\n   * This field allows the client to guide the model on desired responses. The model\n   * can be instructed on response content and format, (e.g. \"be extremely succinct\",\n   * \"act friendly\", \"here are examples of good responses\") and on audio behavior\n   * (e.g. \"talk quickly\", \"inject emotion into your voice\", \"laugh frequently\"). The\n   * instructions are not guaranteed to be followed by the model, but they provide\n   * guidance to the model on the desired behavior.\n   *\n   * Note that the server sets default instructions which will be used if this field\n   * is not set and are visible in the `session.created` event at the start of the\n   * session.\n   */\n  instructions?: string;\n\n  /**\n   * Maximum number of output tokens for a single assistant response, inclusive of\n   * tool calls. Provide an integer between 1 and 4096 to limit output tokens, or\n   * `inf` for the maximum available tokens for a given model. Defaults to `inf`.\n   */\n  max_output_tokens?: number | 'inf';\n\n  /**\n   * The Realtime model used for this session.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-realtime'\n    | 'gpt-realtime-2025-08-28'\n    | 'gpt-4o-realtime-preview'\n    | 'gpt-4o-realtime-preview-2024-10-01'\n    | 'gpt-4o-realtime-preview-2024-12-17'\n    | 'gpt-4o-realtime-preview-2025-06-03'\n    | 'gpt-4o-mini-realtime-preview'\n    | 'gpt-4o-mini-realtime-preview-2024-12-17'\n    | 'gpt-realtime-mini'\n    | 'gpt-realtime-mini-2025-10-06'\n    | 'gpt-audio-mini'\n    | 'gpt-audio-mini-2025-10-06';\n\n  /**\n   * The set of modalities the model can respond with. It defaults to `[\"audio\"]`,\n   * indicating that the model will respond with audio plus a transcript. `[\"text\"]`\n   * can be used to make the model respond with text only. It is not possible to\n   * request both `text` and `audio` at the same time.\n   */\n  output_modalities?: Array<'text' | 'audio'>;\n\n  /**\n   * Reference to a prompt template and its variables.\n   * [Learn more](https://platform.openai.com/docs/guides/text?api-mode=responses#reusable-prompts).\n   */\n  prompt?: ResponsesAPI.ResponsePrompt | null;\n\n  /**\n   * How the model chooses tools. Provide one of the string modes or force a specific\n   * function/MCP tool.\n   */\n  tool_choice?: RealtimeToolChoiceConfig;\n\n  /**\n   * Tools available to the model.\n   */\n  tools?: RealtimeToolsConfig;\n\n  /**\n   * Realtime API can write session traces to the\n   * [Traces Dashboard](/logs?api=traces). Set to null to disable tracing. Once\n   * tracing is enabled for a session, the configuration cannot be modified.\n   *\n   * `auto` will create a trace for the session with default values for the workflow\n   * name, group id, and metadata.\n   */\n  tracing?: RealtimeTracingConfig | null;\n\n  /**\n   * When the number of tokens in a conversation exceeds the model's input token\n   * limit, the conversation be truncated, meaning messages (starting from the\n   * oldest) will not be included in the model's context. A 32k context model with\n   * 4,096 max output tokens can only include 28,224 tokens in the context before\n   * truncation occurs. Clients can configure truncation behavior to truncate with a\n   * lower max token limit, which is an effective way to control token usage and\n   * cost. Truncation will reduce the number of cached tokens on the next turn\n   * (busting the cache), since messages are dropped from the beginning of the\n   * context. However, clients can also configure truncation to retain messages up to\n   * a fraction of the maximum context size, which will reduce the need for future\n   * truncations and thus improve the cache rate. Truncation can be disabled\n   * entirely, which means the server will never truncate but would instead return an\n   * error if the conversation exceeds the model's input token limit.\n   */\n  truncation?: RealtimeTruncation;\n}\n\n/**\n * How the model chooses tools. Provide one of the string modes or force a specific\n * function/MCP tool.\n */\nexport type RealtimeToolChoiceConfig =\n  | ResponsesAPI.ToolChoiceOptions\n  | ResponsesAPI.ToolChoiceFunction\n  | ResponsesAPI.ToolChoiceMcp;\n\n/**\n * Tools available to the model.\n */\nexport type RealtimeToolsConfig = Array<RealtimeToolsConfigUnion>;\n\n/**\n * Give the model access to additional tools via remote Model Context Protocol\n * (MCP) servers.\n * [Learn more about MCP](https://platform.openai.com/docs/guides/tools-remote-mcp).\n */\nexport type RealtimeToolsConfigUnion = RealtimeFunctionTool | RealtimeToolsConfigUnion.Mcp;\n\nexport namespace RealtimeToolsConfigUnion {\n  /**\n   * Give the model access to additional tools via remote Model Context Protocol\n   * (MCP) servers.\n   * [Learn more about MCP](https://platform.openai.com/docs/guides/tools-remote-mcp).\n   */\n  export interface Mcp {\n    /**\n     * A label for this MCP server, used to identify it in tool calls.\n     */\n    server_label: string;\n\n    /**\n     * The type of the MCP tool. Always `mcp`.\n     */\n    type: 'mcp';\n\n    /**\n     * List of allowed tool names or a filter object.\n     */\n    allowed_tools?: Array<string> | Mcp.McpToolFilter | null;\n\n    /**\n     * An OAuth access token that can be used with a remote MCP server, either with a\n     * custom MCP server URL or a service connector. Your application must handle the\n     * OAuth authorization flow and provide the token here.\n     */\n    authorization?: string;\n\n    /**\n     * Identifier for service connectors, like those available in ChatGPT. One of\n     * `server_url` or `connector_id` must be provided. Learn more about service\n     * connectors\n     * [here](https://platform.openai.com/docs/guides/tools-remote-mcp#connectors).\n     *\n     * Currently supported `connector_id` values are:\n     *\n     * - Dropbox: `connector_dropbox`\n     * - Gmail: `connector_gmail`\n     * - Google Calendar: `connector_googlecalendar`\n     * - Google Drive: `connector_googledrive`\n     * - Microsoft Teams: `connector_microsoftteams`\n     * - Outlook Calendar: `connector_outlookcalendar`\n     * - Outlook Email: `connector_outlookemail`\n     * - SharePoint: `connector_sharepoint`\n     */\n    connector_id?:\n      | 'connector_dropbox'\n      | 'connector_gmail'\n      | 'connector_googlecalendar'\n      | 'connector_googledrive'\n      | 'connector_microsoftteams'\n      | 'connector_outlookcalendar'\n      | 'connector_outlookemail'\n      | 'connector_sharepoint';\n\n    /**\n     * Optional HTTP headers to send to the MCP server. Use for authentication or other\n     * purposes.\n     */\n    headers?: { [key: string]: string } | null;\n\n    /**\n     * Specify which of the MCP server's tools require approval.\n     */\n    require_approval?: Mcp.McpToolApprovalFilter | 'always' | 'never' | null;\n\n    /**\n     * Optional description of the MCP server, used to provide more context.\n     */\n    server_description?: string;\n\n    /**\n     * The URL for the MCP server. One of `server_url` or `connector_id` must be\n     * provided.\n     */\n    server_url?: string;\n  }\n\n  export namespace Mcp {\n    /**\n     * A filter object to specify which tools are allowed.\n     */\n    export interface McpToolFilter {\n      /**\n       * Indicates whether or not a tool modifies data or is read-only. If an MCP server\n       * is\n       * [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\n       * it will match this filter.\n       */\n      read_only?: boolean;\n\n      /**\n       * List of allowed tool names.\n       */\n      tool_names?: Array<string>;\n    }\n\n    /**\n     * Specify which of the MCP server's tools require approval. Can be `always`,\n     * `never`, or a filter object associated with tools that require approval.\n     */\n    export interface McpToolApprovalFilter {\n      /**\n       * A filter object to specify which tools are allowed.\n       */\n      always?: McpToolApprovalFilter.Always;\n\n      /**\n       * A filter object to specify which tools are allowed.\n       */\n      never?: McpToolApprovalFilter.Never;\n    }\n\n    export namespace McpToolApprovalFilter {\n      /**\n       * A filter object to specify which tools are allowed.\n       */\n      export interface Always {\n        /**\n         * Indicates whether or not a tool modifies data or is read-only. If an MCP server\n         * is\n         * [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\n         * it will match this filter.\n         */\n        read_only?: boolean;\n\n        /**\n         * List of allowed tool names.\n         */\n        tool_names?: Array<string>;\n      }\n\n      /**\n       * A filter object to specify which tools are allowed.\n       */\n      export interface Never {\n        /**\n         * Indicates whether or not a tool modifies data or is read-only. If an MCP server\n         * is\n         * [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\n         * it will match this filter.\n         */\n        read_only?: boolean;\n\n        /**\n         * List of allowed tool names.\n         */\n        tool_names?: Array<string>;\n      }\n    }\n  }\n}\n\n/**\n * Realtime API can write session traces to the\n * [Traces Dashboard](/logs?api=traces). Set to null to disable tracing. Once\n * tracing is enabled for a session, the configuration cannot be modified.\n *\n * `auto` will create a trace for the session with default values for the workflow\n * name, group id, and metadata.\n */\nexport type RealtimeTracingConfig = 'auto' | RealtimeTracingConfig.TracingConfiguration;\n\nexport namespace RealtimeTracingConfig {\n  /**\n   * Granular configuration for tracing.\n   */\n  export interface TracingConfiguration {\n    /**\n     * The group id to attach to this trace to enable filtering and grouping in the\n     * Traces Dashboard.\n     */\n    group_id?: string;\n\n    /**\n     * The arbitrary metadata to attach to this trace to enable filtering in the Traces\n     * Dashboard.\n     */\n    metadata?: unknown;\n\n    /**\n     * The name of the workflow to attach to this trace. This is used to name the trace\n     * in the Traces Dashboard.\n     */\n    workflow_name?: string;\n  }\n}\n\n/**\n * Configuration for input and output audio.\n */\nexport interface RealtimeTranscriptionSessionAudio {\n  input?: RealtimeTranscriptionSessionAudioInput;\n}\n\nexport interface RealtimeTranscriptionSessionAudioInput {\n  /**\n   * The PCM audio format. Only a 24kHz sample rate is supported.\n   */\n  format?: RealtimeAudioFormats;\n\n  /**\n   * Configuration for input audio noise reduction. This can be set to `null` to turn\n   * off. Noise reduction filters audio added to the input audio buffer before it is\n   * sent to VAD and the model. Filtering the audio can improve VAD and turn\n   * detection accuracy (reducing false positives) and model performance by improving\n   * perception of the input audio.\n   */\n  noise_reduction?: RealtimeTranscriptionSessionAudioInput.NoiseReduction;\n\n  /**\n   * Configuration for input audio transcription, defaults to off and can be set to\n   * `null` to turn off once on. Input audio transcription is not native to the\n   * model, since the model consumes audio directly. Transcription runs\n   * asynchronously through\n   * [the /audio/transcriptions endpoint](https://platform.openai.com/docs/api-reference/audio/createTranscription)\n   * and should be treated as guidance of input audio content rather than precisely\n   * what the model heard. The client can optionally set the language and prompt for\n   * transcription, these offer additional guidance to the transcription service.\n   */\n  transcription?: AudioTranscription;\n\n  /**\n   * Configuration for turn detection, ether Server VAD or Semantic VAD. This can be\n   * set to `null` to turn off, in which case the client must manually trigger model\n   * response.\n   *\n   * Server VAD means that the model will detect the start and end of speech based on\n   * audio volume and respond at the end of user speech.\n   *\n   * Semantic VAD is more advanced and uses a turn detection model (in conjunction\n   * with VAD) to semantically estimate whether the user has finished speaking, then\n   * dynamically sets a timeout based on this probability. For example, if user audio\n   * trails off with \"uhhm\", the model will score a low probability of turn end and\n   * wait longer for the user to continue speaking. This can be useful for more\n   * natural conversations, but may have a higher latency.\n   */\n  turn_detection?: RealtimeTranscriptionSessionAudioInputTurnDetection | null;\n}\n\nexport namespace RealtimeTranscriptionSessionAudioInput {\n  /**\n   * Configuration for input audio noise reduction. This can be set to `null` to turn\n   * off. Noise reduction filters audio added to the input audio buffer before it is\n   * sent to VAD and the model. Filtering the audio can improve VAD and turn\n   * detection accuracy (reducing false positives) and model performance by improving\n   * perception of the input audio.\n   */\n  export interface NoiseReduction {\n    /**\n     * Type of noise reduction. `near_field` is for close-talking microphones such as\n     * headphones, `far_field` is for far-field microphones such as laptop or\n     * conference room microphones.\n     */\n    type?: RealtimeAPI.NoiseReductionType;\n  }\n}\n\n/**\n * Configuration for turn detection, ether Server VAD or Semantic VAD. This can be\n * set to `null` to turn off, in which case the client must manually trigger model\n * response.\n *\n * Server VAD means that the model will detect the start and end of speech based on\n * audio volume and respond at the end of user speech.\n *\n * Semantic VAD is more advanced and uses a turn detection model (in conjunction\n * with VAD) to semantically estimate whether the user has finished speaking, then\n * dynamically sets a timeout based on this probability. For example, if user audio\n * trails off with \"uhhm\", the model will score a low probability of turn end and\n * wait longer for the user to continue speaking. This can be useful for more\n * natural conversations, but may have a higher latency.\n */\nexport type RealtimeTranscriptionSessionAudioInputTurnDetection =\n  | RealtimeTranscriptionSessionAudioInputTurnDetection.ServerVad\n  | RealtimeTranscriptionSessionAudioInputTurnDetection.SemanticVad;\n\nexport namespace RealtimeTranscriptionSessionAudioInputTurnDetection {\n  /**\n   * Server-side voice activity detection (VAD) which flips on when user speech is\n   * detected and off after a period of silence.\n   */\n  export interface ServerVad {\n    /**\n     * Type of turn detection, `server_vad` to turn on simple Server VAD.\n     */\n    type: 'server_vad';\n\n    /**\n     * Whether or not to automatically generate a response when a VAD stop event\n     * occurs.\n     */\n    create_response?: boolean;\n\n    /**\n     * Optional timeout after which a model response will be triggered automatically.\n     * This is useful for situations in which a long pause from the user is unexpected,\n     * such as a phone call. The model will effectively prompt the user to continue the\n     * conversation based on the current context.\n     *\n     * The timeout value will be applied after the last model response's audio has\n     * finished playing, i.e. it's set to the `response.done` time plus audio playback\n     * duration.\n     *\n     * An `input_audio_buffer.timeout_triggered` event (plus events associated with the\n     * Response) will be emitted when the timeout is reached. Idle timeout is currently\n     * only supported for `server_vad` mode.\n     */\n    idle_timeout_ms?: number | null;\n\n    /**\n     * Whether or not to automatically interrupt any ongoing response with output to\n     * the default conversation (i.e. `conversation` of `auto`) when a VAD start event\n     * occurs.\n     */\n    interrupt_response?: boolean;\n\n    /**\n     * Used only for `server_vad` mode. Amount of audio to include before the VAD\n     * detected speech (in milliseconds). Defaults to 300ms.\n     */\n    prefix_padding_ms?: number;\n\n    /**\n     * Used only for `server_vad` mode. Duration of silence to detect speech stop (in\n     * milliseconds). Defaults to 500ms. With shorter values the model will respond\n     * more quickly, but may jump in on short pauses from the user.\n     */\n    silence_duration_ms?: number;\n\n    /**\n     * Used only for `server_vad` mode. Activation threshold for VAD (0.0 to 1.0), this\n     * defaults to 0.5. A higher threshold will require louder audio to activate the\n     * model, and thus might perform better in noisy environments.\n     */\n    threshold?: number;\n  }\n\n  /**\n   * Server-side semantic turn detection which uses a model to determine when the\n   * user has finished speaking.\n   */\n  export interface SemanticVad {\n    /**\n     * Type of turn detection, `semantic_vad` to turn on Semantic VAD.\n     */\n    type: 'semantic_vad';\n\n    /**\n     * Whether or not to automatically generate a response when a VAD stop event\n     * occurs.\n     */\n    create_response?: boolean;\n\n    /**\n     * Used only for `semantic_vad` mode. The eagerness of the model to respond. `low`\n     * will wait longer for the user to continue speaking, `high` will respond more\n     * quickly. `auto` is the default and is equivalent to `medium`. `low`, `medium`,\n     * and `high` have max timeouts of 8s, 4s, and 2s respectively.\n     */\n    eagerness?: 'low' | 'medium' | 'high' | 'auto';\n\n    /**\n     * Whether or not to automatically interrupt any ongoing response with output to\n     * the default conversation (i.e. `conversation` of `auto`) when a VAD start event\n     * occurs.\n     */\n    interrupt_response?: boolean;\n  }\n}\n\n/**\n * Realtime transcription session object configuration.\n */\nexport interface RealtimeTranscriptionSessionCreateRequest {\n  /**\n   * The type of session to create. Always `transcription` for transcription\n   * sessions.\n   */\n  type: 'transcription';\n\n  /**\n   * Configuration for input and output audio.\n   */\n  audio?: RealtimeTranscriptionSessionAudio;\n\n  /**\n   * Additional fields to include in server outputs.\n   *\n   * `item.input_audio_transcription.logprobs`: Include logprobs for input audio\n   * transcription.\n   */\n  include?: Array<'item.input_audio_transcription.logprobs'>;\n}\n\n/**\n * When the number of tokens in a conversation exceeds the model's input token\n * limit, the conversation be truncated, meaning messages (starting from the\n * oldest) will not be included in the model's context. A 32k context model with\n * 4,096 max output tokens can only include 28,224 tokens in the context before\n * truncation occurs. Clients can configure truncation behavior to truncate with a\n * lower max token limit, which is an effective way to control token usage and\n * cost. Truncation will reduce the number of cached tokens on the next turn\n * (busting the cache), since messages are dropped from the beginning of the\n * context. However, clients can also configure truncation to retain messages up to\n * a fraction of the maximum context size, which will reduce the need for future\n * truncations and thus improve the cache rate. Truncation can be disabled\n * entirely, which means the server will never truncate but would instead return an\n * error if the conversation exceeds the model's input token limit.\n */\nexport type RealtimeTruncation = 'auto' | 'disabled' | RealtimeTruncationRetentionRatio;\n\n/**\n * Retain a fraction of the conversation tokens when the conversation exceeds the\n * input token limit. This allows you to amortize truncations across multiple\n * turns, which can help improve cached token usage.\n */\nexport interface RealtimeTruncationRetentionRatio {\n  /**\n   * Fraction of post-instruction conversation tokens to retain (`0.0` - `1.0`) when\n   * the conversation exceeds the input token limit. Setting this to `0.8` means that\n   * messages will be dropped until 80% of the maximum allowed tokens are used. This\n   * helps reduce the frequency of truncations and improve cache rates.\n   */\n  retention_ratio: number;\n\n  /**\n   * Use retention ratio truncation.\n   */\n  type: 'retention_ratio';\n\n  /**\n   * Optional custom token limits for this truncation strategy. If not provided, the\n   * model's default token limits will be used.\n   */\n  token_limits?: RealtimeTruncationRetentionRatio.TokenLimits;\n}\n\nexport namespace RealtimeTruncationRetentionRatio {\n  /**\n   * Optional custom token limits for this truncation strategy. If not provided, the\n   * model's default token limits will be used.\n   */\n  export interface TokenLimits {\n    /**\n     * Maximum tokens allowed in the conversation after instructions (which including\n     * tool definitions). For example, setting this to 5,000 would mean that truncation\n     * would occur when the conversation exceeds 5,000 tokens after instructions. This\n     * cannot be higher than the model's context window size minus the maximum output\n     * tokens.\n     */\n    post_instructions?: number;\n  }\n}\n\n/**\n * Returned when the model-generated audio is updated.\n */\nexport interface ResponseAudioDeltaEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * Base64-encoded audio data delta.\n   */\n  delta: string;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.output_audio.delta`.\n   */\n  type: 'response.output_audio.delta';\n}\n\n/**\n * Returned when the model-generated audio is done. Also emitted when a Response is\n * interrupted, incomplete, or cancelled.\n */\nexport interface ResponseAudioDoneEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.output_audio.done`.\n   */\n  type: 'response.output_audio.done';\n}\n\n/**\n * Returned when the model-generated transcription of audio output is updated.\n */\nexport interface ResponseAudioTranscriptDeltaEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The transcript delta.\n   */\n  delta: string;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.output_audio_transcript.delta`.\n   */\n  type: 'response.output_audio_transcript.delta';\n}\n\n/**\n * Returned when the model-generated transcription of audio output is done\n * streaming. Also emitted when a Response is interrupted, incomplete, or\n * cancelled.\n */\nexport interface ResponseAudioTranscriptDoneEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The final transcript of the audio.\n   */\n  transcript: string;\n\n  /**\n   * The event type, must be `response.output_audio_transcript.done`.\n   */\n  type: 'response.output_audio_transcript.done';\n}\n\n/**\n * Send this event to cancel an in-progress response. The server will respond with\n * a `response.done` event with a status of `response.status=cancelled`. If there\n * is no response to cancel, the server will respond with an error. It's safe to\n * call `response.cancel` even if no response is in progress, an error will be\n * returned the session will remain unaffected.\n */\nexport interface ResponseCancelEvent {\n  /**\n   * The event type, must be `response.cancel`.\n   */\n  type: 'response.cancel';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n\n  /**\n   * A specific response ID to cancel - if not provided, will cancel an in-progress\n   * response in the default conversation.\n   */\n  response_id?: string;\n}\n\n/**\n * Returned when a new content part is added to an assistant message item during\n * response generation.\n */\nexport interface ResponseContentPartAddedEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item to which the content part was added.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The content part that was added.\n   */\n  part: ResponseContentPartAddedEvent.Part;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.content_part.added`.\n   */\n  type: 'response.content_part.added';\n}\n\nexport namespace ResponseContentPartAddedEvent {\n  /**\n   * The content part that was added.\n   */\n  export interface Part {\n    /**\n     * Base64-encoded audio data (if type is \"audio\").\n     */\n    audio?: string;\n\n    /**\n     * The text content (if type is \"text\").\n     */\n    text?: string;\n\n    /**\n     * The transcript of the audio (if type is \"audio\").\n     */\n    transcript?: string;\n\n    /**\n     * The content type (\"text\", \"audio\").\n     */\n    type?: 'text' | 'audio';\n  }\n}\n\n/**\n * Returned when a content part is done streaming in an assistant message item.\n * Also emitted when a Response is interrupted, incomplete, or cancelled.\n */\nexport interface ResponseContentPartDoneEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The content part that is done.\n   */\n  part: ResponseContentPartDoneEvent.Part;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.content_part.done`.\n   */\n  type: 'response.content_part.done';\n}\n\nexport namespace ResponseContentPartDoneEvent {\n  /**\n   * The content part that is done.\n   */\n  export interface Part {\n    /**\n     * Base64-encoded audio data (if type is \"audio\").\n     */\n    audio?: string;\n\n    /**\n     * The text content (if type is \"text\").\n     */\n    text?: string;\n\n    /**\n     * The transcript of the audio (if type is \"audio\").\n     */\n    transcript?: string;\n\n    /**\n     * The content type (\"text\", \"audio\").\n     */\n    type?: 'text' | 'audio';\n  }\n}\n\n/**\n * This event instructs the server to create a Response, which means triggering\n * model inference. When in Server VAD mode, the server will create Responses\n * automatically.\n *\n * A Response will include at least one Item, and may have two, in which case the\n * second will be a function call. These Items will be appended to the conversation\n * history by default.\n *\n * The server will respond with a `response.created` event, events for Items and\n * content created, and finally a `response.done` event to indicate the Response is\n * complete.\n *\n * The `response.create` event includes inference configuration like `instructions`\n * and `tools`. If these are set, they will override the Session's configuration\n * for this Response only.\n *\n * Responses can be created out-of-band of the default Conversation, meaning that\n * they can have arbitrary input, and it's possible to disable writing the output\n * to the Conversation. Only one Response can write to the default Conversation at\n * a time, but otherwise multiple Responses can be created in parallel. The\n * `metadata` field is a good way to disambiguate multiple simultaneous Responses.\n *\n * Clients can set `conversation` to `none` to create a Response that does not\n * write to the default Conversation. Arbitrary input can be provided with the\n * `input` field, which is an array accepting raw Items and references to existing\n * Items.\n */\nexport interface ResponseCreateEvent {\n  /**\n   * The event type, must be `response.create`.\n   */\n  type: 'response.create';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n\n  /**\n   * Create a new Realtime response with these parameters\n   */\n  response?: RealtimeResponseCreateParams;\n}\n\n/**\n * Returned when a new Response is created. The first event of response creation,\n * where the response is in an initial state of `in_progress`.\n */\nexport interface ResponseCreatedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The response resource.\n   */\n  response: RealtimeResponse;\n\n  /**\n   * The event type, must be `response.created`.\n   */\n  type: 'response.created';\n}\n\n/**\n * Returned when a Response is done streaming. Always emitted, no matter the final\n * state. The Response object included in the `response.done` event will include\n * all output Items in the Response but will omit the raw audio data.\n *\n * Clients should check the `status` field of the Response to determine if it was\n * successful (`completed`) or if there was another outcome: `cancelled`, `failed`,\n * or `incomplete`.\n *\n * A response will contain all output items that were generated during the\n * response, excluding any audio content.\n */\nexport interface ResponseDoneEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The response resource.\n   */\n  response: RealtimeResponse;\n\n  /**\n   * The event type, must be `response.done`.\n   */\n  type: 'response.done';\n}\n\n/**\n * Returned when the model-generated function call arguments are updated.\n */\nexport interface ResponseFunctionCallArgumentsDeltaEvent {\n  /**\n   * The ID of the function call.\n   */\n  call_id: string;\n\n  /**\n   * The arguments delta as a JSON string.\n   */\n  delta: string;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the function call item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.function_call_arguments.delta`.\n   */\n  type: 'response.function_call_arguments.delta';\n}\n\n/**\n * Returned when the model-generated function call arguments are done streaming.\n * Also emitted when a Response is interrupted, incomplete, or cancelled.\n */\nexport interface ResponseFunctionCallArgumentsDoneEvent {\n  /**\n   * The final arguments as a JSON string.\n   */\n  arguments: string;\n\n  /**\n   * The ID of the function call.\n   */\n  call_id: string;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the function call item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.function_call_arguments.done`.\n   */\n  type: 'response.function_call_arguments.done';\n}\n\n/**\n * Returned when MCP tool call arguments are updated during response generation.\n */\nexport interface ResponseMcpCallArgumentsDelta {\n  /**\n   * The JSON-encoded arguments delta.\n   */\n  delta: string;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the MCP tool call item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.mcp_call_arguments.delta`.\n   */\n  type: 'response.mcp_call_arguments.delta';\n\n  /**\n   * If present, indicates the delta text was obfuscated.\n   */\n  obfuscation?: string | null;\n}\n\n/**\n * Returned when MCP tool call arguments are finalized during response generation.\n */\nexport interface ResponseMcpCallArgumentsDone {\n  /**\n   * The final JSON-encoded arguments string.\n   */\n  arguments: string;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the MCP tool call item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.mcp_call_arguments.done`.\n   */\n  type: 'response.mcp_call_arguments.done';\n}\n\n/**\n * Returned when an MCP tool call has completed successfully.\n */\nexport interface ResponseMcpCallCompleted {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the MCP tool call item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The event type, must be `response.mcp_call.completed`.\n   */\n  type: 'response.mcp_call.completed';\n}\n\n/**\n * Returned when an MCP tool call has failed.\n */\nexport interface ResponseMcpCallFailed {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the MCP tool call item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The event type, must be `response.mcp_call.failed`.\n   */\n  type: 'response.mcp_call.failed';\n}\n\n/**\n * Returned when an MCP tool call has started and is in progress.\n */\nexport interface ResponseMcpCallInProgress {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the MCP tool call item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The event type, must be `response.mcp_call.in_progress`.\n   */\n  type: 'response.mcp_call.in_progress';\n}\n\n/**\n * Returned when a new Item is created during Response generation.\n */\nexport interface ResponseOutputItemAddedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * A single item within a Realtime conversation.\n   */\n  item: ConversationItem;\n\n  /**\n   * The index of the output item in the Response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the Response to which the item belongs.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.output_item.added`.\n   */\n  type: 'response.output_item.added';\n}\n\n/**\n * Returned when an Item is done streaming. Also emitted when a Response is\n * interrupted, incomplete, or cancelled.\n */\nexport interface ResponseOutputItemDoneEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * A single item within a Realtime conversation.\n   */\n  item: ConversationItem;\n\n  /**\n   * The index of the output item in the Response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the Response to which the item belongs.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.output_item.done`.\n   */\n  type: 'response.output_item.done';\n}\n\n/**\n * Returned when the text value of an \"output_text\" content part is updated.\n */\nexport interface ResponseTextDeltaEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The text delta.\n   */\n  delta: string;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.output_text.delta`.\n   */\n  type: 'response.output_text.delta';\n}\n\n/**\n * Returned when the text value of an \"output_text\" content part is done streaming.\n * Also emitted when a Response is interrupted, incomplete, or cancelled.\n */\nexport interface ResponseTextDoneEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The final text content.\n   */\n  text: string;\n\n  /**\n   * The event type, must be `response.output_text.done`.\n   */\n  type: 'response.output_text.done';\n}\n\n/**\n * Returned when a Session is created. Emitted automatically when a new connection\n * is established as the first server event. This event will contain the default\n * Session configuration.\n */\nexport interface SessionCreatedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The session configuration.\n   */\n  session: RealtimeSessionCreateRequest | RealtimeTranscriptionSessionCreateRequest;\n\n  /**\n   * The event type, must be `session.created`.\n   */\n  type: 'session.created';\n}\n\n/**\n * Send this event to update the sessions configuration. The client may send this\n * event at any time to update any field except for `voice` and `model`. `voice`\n * can be updated only if there have been no other audio outputs yet.\n *\n * When the server receives a `session.update`, it will respond with a\n * `session.updated` event showing the full, effective configuration. Only the\n * fields that are present in the `session.update` are updated. To clear a field\n * like `instructions`, pass an empty string. To clear a field like `tools`, pass\n * an empty array. To clear a field like `turn_detection`, pass `null`.\n */\nexport interface SessionUpdateEvent {\n  /**\n   * Update the Realtime session. Choose either a realtime session or a transcription\n   * session.\n   */\n  session: RealtimeSessionCreateRequest | RealtimeTranscriptionSessionCreateRequest;\n\n  /**\n   * The event type, must be `session.update`.\n   */\n  type: 'session.update';\n\n  /**\n   * Optional client-generated ID used to identify this event. This is an arbitrary\n   * string that a client may assign. It will be passed back if there is an error\n   * with the event, but the corresponding `session.updated` event will not include\n   * it.\n   */\n  event_id?: string;\n}\n\n/**\n * Returned when a session is updated with a `session.update` event, unless there\n * is an error.\n */\nexport interface SessionUpdatedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The session configuration.\n   */\n  session: RealtimeSessionCreateRequest | RealtimeTranscriptionSessionCreateRequest;\n\n  /**\n   * The event type, must be `session.updated`.\n   */\n  type: 'session.updated';\n}\n\n/**\n * Send this event to update a transcription session.\n */\nexport interface TranscriptionSessionUpdate {\n  /**\n   * Realtime transcription session object configuration.\n   */\n  session: TranscriptionSessionUpdate.Session;\n\n  /**\n   * The event type, must be `transcription_session.update`.\n   */\n  type: 'transcription_session.update';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\nexport namespace TranscriptionSessionUpdate {\n  /**\n   * Realtime transcription session object configuration.\n   */\n  export interface Session {\n    /**\n     * The set of items to include in the transcription. Current available items are:\n     * `item.input_audio_transcription.logprobs`\n     */\n    include?: Array<'item.input_audio_transcription.logprobs'>;\n\n    /**\n     * The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`. For\n     * `pcm16`, input audio must be 16-bit PCM at a 24kHz sample rate, single channel\n     * (mono), and little-endian byte order.\n     */\n    input_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n    /**\n     * Configuration for input audio noise reduction. This can be set to `null` to turn\n     * off. Noise reduction filters audio added to the input audio buffer before it is\n     * sent to VAD and the model. Filtering the audio can improve VAD and turn\n     * detection accuracy (reducing false positives) and model performance by improving\n     * perception of the input audio.\n     */\n    input_audio_noise_reduction?: Session.InputAudioNoiseReduction;\n\n    /**\n     * Configuration for input audio transcription. The client can optionally set the\n     * language and prompt for transcription, these offer additional guidance to the\n     * transcription service.\n     */\n    input_audio_transcription?: RealtimeAPI.AudioTranscription;\n\n    /**\n     * Configuration for turn detection. Can be set to `null` to turn off. Server VAD\n     * means that the model will detect the start and end of speech based on audio\n     * volume and respond at the end of user speech.\n     */\n    turn_detection?: Session.TurnDetection;\n  }\n\n  export namespace Session {\n    /**\n     * Configuration for input audio noise reduction. This can be set to `null` to turn\n     * off. Noise reduction filters audio added to the input audio buffer before it is\n     * sent to VAD and the model. Filtering the audio can improve VAD and turn\n     * detection accuracy (reducing false positives) and model performance by improving\n     * perception of the input audio.\n     */\n    export interface InputAudioNoiseReduction {\n      /**\n       * Type of noise reduction. `near_field` is for close-talking microphones such as\n       * headphones, `far_field` is for far-field microphones such as laptop or\n       * conference room microphones.\n       */\n      type?: RealtimeAPI.NoiseReductionType;\n    }\n\n    /**\n     * Configuration for turn detection. Can be set to `null` to turn off. Server VAD\n     * means that the model will detect the start and end of speech based on audio\n     * volume and respond at the end of user speech.\n     */\n    export interface TurnDetection {\n      /**\n       * Amount of audio to include before the VAD detected speech (in milliseconds).\n       * Defaults to 300ms.\n       */\n      prefix_padding_ms?: number;\n\n      /**\n       * Duration of silence to detect speech stop (in milliseconds). Defaults to 500ms.\n       * With shorter values the model will respond more quickly, but may jump in on\n       * short pauses from the user.\n       */\n      silence_duration_ms?: number;\n\n      /**\n       * Activation threshold for VAD (0.0 to 1.0), this defaults to 0.5. A higher\n       * threshold will require louder audio to activate the model, and thus might\n       * perform better in noisy environments.\n       */\n      threshold?: number;\n\n      /**\n       * Type of turn detection. Only `server_vad` is currently supported for\n       * transcription sessions.\n       */\n      type?: 'server_vad';\n    }\n  }\n}\n\n/**\n * Returned when a transcription session is updated with a\n * `transcription_session.update` event, unless there is an error.\n */\nexport interface TranscriptionSessionUpdatedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * A new Realtime transcription session configuration.\n   *\n   * When a session is created on the server via REST API, the session object also\n   * contains an ephemeral key. Default TTL for keys is 10 minutes. This property is\n   * not present when a session is updated via the WebSocket API.\n   */\n  session: TranscriptionSessionUpdatedEvent.Session;\n\n  /**\n   * The event type, must be `transcription_session.updated`.\n   */\n  type: 'transcription_session.updated';\n}\n\nexport namespace TranscriptionSessionUpdatedEvent {\n  /**\n   * A new Realtime transcription session configuration.\n   *\n   * When a session is created on the server via REST API, the session object also\n   * contains an ephemeral key. Default TTL for keys is 10 minutes. This property is\n   * not present when a session is updated via the WebSocket API.\n   */\n  export interface Session {\n    /**\n     * Ephemeral key returned by the API. Only present when the session is created on\n     * the server via REST API.\n     */\n    client_secret: Session.ClientSecret;\n\n    /**\n     * The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n     */\n    input_audio_format?: string;\n\n    /**\n     * Configuration of the transcription model.\n     */\n    input_audio_transcription?: RealtimeAPI.AudioTranscription;\n\n    /**\n     * The set of modalities the model can respond with. To disable audio, set this to\n     * [\"text\"].\n     */\n    modalities?: Array<'text' | 'audio'>;\n\n    /**\n     * Configuration for turn detection. Can be set to `null` to turn off. Server VAD\n     * means that the model will detect the start and end of speech based on audio\n     * volume and respond at the end of user speech.\n     */\n    turn_detection?: Session.TurnDetection;\n  }\n\n  export namespace Session {\n    /**\n     * Ephemeral key returned by the API. Only present when the session is created on\n     * the server via REST API.\n     */\n    export interface ClientSecret {\n      /**\n       * Timestamp for when the token expires. Currently, all tokens expire after one\n       * minute.\n       */\n      expires_at: number;\n\n      /**\n       * Ephemeral key usable in client environments to authenticate connections to the\n       * Realtime API. Use this in client-side environments rather than a standard API\n       * token, which should only be used server-side.\n       */\n      value: string;\n    }\n\n    /**\n     * Configuration for turn detection. Can be set to `null` to turn off. Server VAD\n     * means that the model will detect the start and end of speech based on audio\n     * volume and respond at the end of user speech.\n     */\n    export interface TurnDetection {\n      /**\n       * Amount of audio to include before the VAD detected speech (in milliseconds).\n       * Defaults to 300ms.\n       */\n      prefix_padding_ms?: number;\n\n      /**\n       * Duration of silence to detect speech stop (in milliseconds). Defaults to 500ms.\n       * With shorter values the model will respond more quickly, but may jump in on\n       * short pauses from the user.\n       */\n      silence_duration_ms?: number;\n\n      /**\n       * Activation threshold for VAD (0.0 to 1.0), this defaults to 0.5. A higher\n       * threshold will require louder audio to activate the model, and thus might\n       * perform better in noisy environments.\n       */\n      threshold?: number;\n\n      /**\n       * Type of turn detection, only `server_vad` is currently supported.\n       */\n      type?: string;\n    }\n  }\n}\n\nRealtime.ClientSecrets = ClientSecrets;\nRealtime.Calls = Calls;\n\nexport declare namespace Realtime {\n  export {\n    type AudioTranscription as AudioTranscription,\n    type ConversationCreatedEvent as ConversationCreatedEvent,\n    type ConversationItem as ConversationItem,\n    type ConversationItemAdded as ConversationItemAdded,\n    type ConversationItemCreateEvent as ConversationItemCreateEvent,\n    type ConversationItemCreatedEvent as ConversationItemCreatedEvent,\n    type ConversationItemDeleteEvent as ConversationItemDeleteEvent,\n    type ConversationItemDeletedEvent as ConversationItemDeletedEvent,\n    type ConversationItemDone as ConversationItemDone,\n    type ConversationItemInputAudioTranscriptionCompletedEvent as ConversationItemInputAudioTranscriptionCompletedEvent,\n    type ConversationItemInputAudioTranscriptionDeltaEvent as ConversationItemInputAudioTranscriptionDeltaEvent,\n    type ConversationItemInputAudioTranscriptionFailedEvent as ConversationItemInputAudioTranscriptionFailedEvent,\n    type ConversationItemInputAudioTranscriptionSegment as ConversationItemInputAudioTranscriptionSegment,\n    type ConversationItemRetrieveEvent as ConversationItemRetrieveEvent,\n    type ConversationItemTruncateEvent as ConversationItemTruncateEvent,\n    type ConversationItemTruncatedEvent as ConversationItemTruncatedEvent,\n    type ConversationItemWithReference as ConversationItemWithReference,\n    type InputAudioBufferAppendEvent as InputAudioBufferAppendEvent,\n    type InputAudioBufferClearEvent as InputAudioBufferClearEvent,\n    type InputAudioBufferClearedEvent as InputAudioBufferClearedEvent,\n    type InputAudioBufferCommitEvent as InputAudioBufferCommitEvent,\n    type InputAudioBufferCommittedEvent as InputAudioBufferCommittedEvent,\n    type InputAudioBufferSpeechStartedEvent as InputAudioBufferSpeechStartedEvent,\n    type InputAudioBufferSpeechStoppedEvent as InputAudioBufferSpeechStoppedEvent,\n    type InputAudioBufferTimeoutTriggered as InputAudioBufferTimeoutTriggered,\n    type LogProbProperties as LogProbProperties,\n    type McpListToolsCompleted as McpListToolsCompleted,\n    type McpListToolsFailed as McpListToolsFailed,\n    type McpListToolsInProgress as McpListToolsInProgress,\n    type NoiseReductionType as NoiseReductionType,\n    type OutputAudioBufferClearEvent as OutputAudioBufferClearEvent,\n    type RateLimitsUpdatedEvent as RateLimitsUpdatedEvent,\n    type RealtimeAudioConfig as RealtimeAudioConfig,\n    type RealtimeAudioConfigInput as RealtimeAudioConfigInput,\n    type RealtimeAudioConfigOutput as RealtimeAudioConfigOutput,\n    type RealtimeAudioFormats as RealtimeAudioFormats,\n    type RealtimeAudioInputTurnDetection as RealtimeAudioInputTurnDetection,\n    type RealtimeClientEvent as RealtimeClientEvent,\n    type RealtimeConversationItemAssistantMessage as RealtimeConversationItemAssistantMessage,\n    type RealtimeConversationItemFunctionCall as RealtimeConversationItemFunctionCall,\n    type RealtimeConversationItemFunctionCallOutput as RealtimeConversationItemFunctionCallOutput,\n    type RealtimeConversationItemSystemMessage as RealtimeConversationItemSystemMessage,\n    type RealtimeConversationItemUserMessage as RealtimeConversationItemUserMessage,\n    type RealtimeError as RealtimeError,\n    type RealtimeErrorEvent as RealtimeErrorEvent,\n    type RealtimeFunctionTool as RealtimeFunctionTool,\n    type RealtimeMcpApprovalRequest as RealtimeMcpApprovalRequest,\n    type RealtimeMcpApprovalResponse as RealtimeMcpApprovalResponse,\n    type RealtimeMcpListTools as RealtimeMcpListTools,\n    type RealtimeMcpProtocolError as RealtimeMcpProtocolError,\n    type RealtimeMcpToolCall as RealtimeMcpToolCall,\n    type RealtimeMcpToolExecutionError as RealtimeMcpToolExecutionError,\n    type RealtimeMcphttpError as RealtimeMcphttpError,\n    type RealtimeResponse as RealtimeResponse,\n    type RealtimeResponseCreateAudioOutput as RealtimeResponseCreateAudioOutput,\n    type RealtimeResponseCreateMcpTool as RealtimeResponseCreateMcpTool,\n    type RealtimeResponseCreateParams as RealtimeResponseCreateParams,\n    type RealtimeResponseStatus as RealtimeResponseStatus,\n    type RealtimeResponseUsage as RealtimeResponseUsage,\n    type RealtimeResponseUsageInputTokenDetails as RealtimeResponseUsageInputTokenDetails,\n    type RealtimeResponseUsageOutputTokenDetails as RealtimeResponseUsageOutputTokenDetails,\n    type RealtimeServerEvent as RealtimeServerEvent,\n    type RealtimeSession as RealtimeSession,\n    type RealtimeSessionCreateRequest as RealtimeSessionCreateRequest,\n    type RealtimeToolChoiceConfig as RealtimeToolChoiceConfig,\n    type RealtimeToolsConfig as RealtimeToolsConfig,\n    type RealtimeToolsConfigUnion as RealtimeToolsConfigUnion,\n    type RealtimeTracingConfig as RealtimeTracingConfig,\n    type RealtimeTranscriptionSessionAudio as RealtimeTranscriptionSessionAudio,\n    type RealtimeTranscriptionSessionAudioInput as RealtimeTranscriptionSessionAudioInput,\n    type RealtimeTranscriptionSessionAudioInputTurnDetection as RealtimeTranscriptionSessionAudioInputTurnDetection,\n    type RealtimeTranscriptionSessionCreateRequest as RealtimeTranscriptionSessionCreateRequest,\n    type RealtimeTruncation as RealtimeTruncation,\n    type RealtimeTruncationRetentionRatio as RealtimeTruncationRetentionRatio,\n    type ResponseAudioDeltaEvent as ResponseAudioDeltaEvent,\n    type ResponseAudioDoneEvent as ResponseAudioDoneEvent,\n    type ResponseAudioTranscriptDeltaEvent as ResponseAudioTranscriptDeltaEvent,\n    type ResponseAudioTranscriptDoneEvent as ResponseAudioTranscriptDoneEvent,\n    type ResponseCancelEvent as ResponseCancelEvent,\n    type ResponseContentPartAddedEvent as ResponseContentPartAddedEvent,\n    type ResponseContentPartDoneEvent as ResponseContentPartDoneEvent,\n    type ResponseCreateEvent as ResponseCreateEvent,\n    type ResponseCreatedEvent as ResponseCreatedEvent,\n    type ResponseDoneEvent as ResponseDoneEvent,\n    type ResponseFunctionCallArgumentsDeltaEvent as ResponseFunctionCallArgumentsDeltaEvent,\n    type ResponseFunctionCallArgumentsDoneEvent as ResponseFunctionCallArgumentsDoneEvent,\n    type ResponseMcpCallArgumentsDelta as ResponseMcpCallArgumentsDelta,\n    type ResponseMcpCallArgumentsDone as ResponseMcpCallArgumentsDone,\n    type ResponseMcpCallCompleted as ResponseMcpCallCompleted,\n    type ResponseMcpCallFailed as ResponseMcpCallFailed,\n    type ResponseMcpCallInProgress as ResponseMcpCallInProgress,\n    type ResponseOutputItemAddedEvent as ResponseOutputItemAddedEvent,\n    type ResponseOutputItemDoneEvent as ResponseOutputItemDoneEvent,\n    type ResponseTextDeltaEvent as ResponseTextDeltaEvent,\n    type ResponseTextDoneEvent as ResponseTextDoneEvent,\n    type SessionCreatedEvent as SessionCreatedEvent,\n    type SessionUpdateEvent as SessionUpdateEvent,\n    type SessionUpdatedEvent as SessionUpdatedEvent,\n    type TranscriptionSessionUpdate as TranscriptionSessionUpdate,\n    type TranscriptionSessionUpdatedEvent as TranscriptionSessionUpdatedEvent,\n  };\n\n  export {\n    ClientSecrets as ClientSecrets,\n    type RealtimeSessionClientSecret as RealtimeSessionClientSecret,\n    type RealtimeSessionCreateResponse as RealtimeSessionCreateResponse,\n    type RealtimeTranscriptionSessionCreateResponse as RealtimeTranscriptionSessionCreateResponse,\n    type RealtimeTranscriptionSessionTurnDetection as RealtimeTranscriptionSessionTurnDetection,\n    type ClientSecretCreateResponse as ClientSecretCreateResponse,\n    type ClientSecretCreateParams as ClientSecretCreateParams,\n  };\n\n  export {\n    Calls as Calls,\n    type CallAcceptParams as CallAcceptParams,\n    type CallReferParams as CallReferParams,\n    type CallRejectParams as CallRejectParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as Shared from '../shared';\nimport * as CompletionsAPI from './completions/completions';\nimport {\n  ChatCompletion,\n  ChatCompletionAllowedToolChoice,\n  ChatCompletionAllowedTools,\n  ChatCompletionAssistantMessageParam,\n  ChatCompletionAudio,\n  ChatCompletionAudioParam,\n  ChatCompletionChunk,\n  ChatCompletionContentPart,\n  ChatCompletionContentPartImage,\n  ChatCompletionContentPartInputAudio,\n  ChatCompletionContentPartRefusal,\n  ChatCompletionContentPartText,\n  ChatCompletionCreateParams,\n  ChatCompletionCreateParamsNonStreaming,\n  ChatCompletionCreateParamsStreaming,\n  ChatCompletionCustomTool,\n  ChatCompletionDeleted,\n  ChatCompletionDeveloperMessageParam,\n  ChatCompletionFunctionCallOption,\n  ChatCompletionFunctionMessageParam,\n  ChatCompletionFunctionTool,\n  ChatCompletionListParams,\n  ChatCompletionMessage,\n  ChatCompletionMessageCustomToolCall,\n  ChatCompletionMessageFunctionToolCall,\n  ChatCompletionMessageParam,\n  ChatCompletionMessageToolCall,\n  ChatCompletionModality,\n  ChatCompletionNamedToolChoice,\n  ChatCompletionNamedToolChoiceCustom,\n  ChatCompletionPredictionContent,\n  ChatCompletionReasoningEffort,\n  ChatCompletionRole,\n  ChatCompletionStoreMessage,\n  ChatCompletionStreamOptions,\n  ChatCompletionSystemMessageParam,\n  ChatCompletionTokenLogprob,\n  ChatCompletionTool,\n  ChatCompletionToolChoiceOption,\n  ChatCompletionToolMessageParam,\n  ChatCompletionUpdateParams,\n  ChatCompletionUserMessageParam,\n  ChatCompletionsPage,\n  Completions,\n} from './completions/completions';\n\nexport class Chat extends APIResource {\n  completions: CompletionsAPI.Completions = new CompletionsAPI.Completions(this._client);\n}\n\nexport type ChatModel = Shared.ChatModel;\n\nChat.Completions = Completions;\n\nexport declare namespace Chat {\n  export { type ChatModel as ChatModel };\n\n  export {\n    Completions as Completions,\n    type ChatCompletion as ChatCompletion,\n    type ChatCompletionAllowedToolChoice as ChatCompletionAllowedToolChoice,\n    type ChatCompletionAssistantMessageParam as ChatCompletionAssistantMessageParam,\n    type ChatCompletionAudio as ChatCompletionAudio,\n    type ChatCompletionAudioParam as ChatCompletionAudioParam,\n    type ChatCompletionChunk as ChatCompletionChunk,\n    type ChatCompletionContentPart as ChatCompletionContentPart,\n    type ChatCompletionContentPartImage as ChatCompletionContentPartImage,\n    type ChatCompletionContentPartInputAudio as ChatCompletionContentPartInputAudio,\n    type ChatCompletionContentPartRefusal as ChatCompletionContentPartRefusal,\n    type ChatCompletionContentPartText as ChatCompletionContentPartText,\n    type ChatCompletionCustomTool as ChatCompletionCustomTool,\n    type ChatCompletionDeleted as ChatCompletionDeleted,\n    type ChatCompletionDeveloperMessageParam as ChatCompletionDeveloperMessageParam,\n    type ChatCompletionFunctionCallOption as ChatCompletionFunctionCallOption,\n    type ChatCompletionFunctionMessageParam as ChatCompletionFunctionMessageParam,\n    type ChatCompletionFunctionTool as ChatCompletionFunctionTool,\n    type ChatCompletionMessage as ChatCompletionMessage,\n    type ChatCompletionMessageCustomToolCall as ChatCompletionMessageCustomToolCall,\n    type ChatCompletionMessageFunctionToolCall as ChatCompletionMessageFunctionToolCall,\n    type ChatCompletionMessageParam as ChatCompletionMessageParam,\n    type ChatCompletionMessageToolCall as ChatCompletionMessageToolCall,\n    type ChatCompletionModality as ChatCompletionModality,\n    type ChatCompletionNamedToolChoice as ChatCompletionNamedToolChoice,\n    type ChatCompletionNamedToolChoiceCustom as ChatCompletionNamedToolChoiceCustom,\n    type ChatCompletionPredictionContent as ChatCompletionPredictionContent,\n    type ChatCompletionRole as ChatCompletionRole,\n    type ChatCompletionStoreMessage as ChatCompletionStoreMessage,\n    type ChatCompletionStreamOptions as ChatCompletionStreamOptions,\n    type ChatCompletionSystemMessageParam as ChatCompletionSystemMessageParam,\n    type ChatCompletionTokenLogprob as ChatCompletionTokenLogprob,\n    type ChatCompletionTool as ChatCompletionTool,\n    type ChatCompletionToolChoiceOption as ChatCompletionToolChoiceOption,\n    type ChatCompletionToolMessageParam as ChatCompletionToolMessageParam,\n    type ChatCompletionUserMessageParam as ChatCompletionUserMessageParam,\n    type ChatCompletionAllowedTools as ChatCompletionAllowedTools,\n    type ChatCompletionReasoningEffort as ChatCompletionReasoningEffort,\n    type ChatCompletionsPage as ChatCompletionsPage,\n    type ChatCompletionCreateParams as ChatCompletionCreateParams,\n    type ChatCompletionCreateParamsNonStreaming as ChatCompletionCreateParamsNonStreaming,\n    type ChatCompletionCreateParamsStreaming as ChatCompletionCreateParamsStreaming,\n    type ChatCompletionUpdateParams as ChatCompletionUpdateParams,\n    type ChatCompletionListParams as ChatCompletionListParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport { APIPromise } from '../../../core/api-promise';\nimport { buildHeaders } from '../../../internal/headers';\nimport { RequestOptions } from '../../../internal/request-options';\n\nexport class Sessions extends APIResource {\n  /**\n   * Create an ephemeral API token for use in client-side applications with the\n   * Realtime API. Can be configured with the same session parameters as the\n   * `session.update` client event.\n   *\n   * It responds with a session object, plus a `client_secret` key which contains a\n   * usable ephemeral API token that can be used to authenticate browser clients for\n   * the Realtime API.\n   *\n   * @example\n   * ```ts\n   * const session =\n   *   await client.beta.realtime.sessions.create();\n   * ```\n   */\n  create(body: SessionCreateParams, options?: RequestOptions): APIPromise<SessionCreateResponse> {\n    return this._client.post('/realtime/sessions', {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n}\n\n/**\n * Realtime session object configuration.\n */\nexport interface Session {\n  /**\n   * Unique identifier for the session that looks like `sess_1234567890abcdef`.\n   */\n  id?: string;\n\n  /**\n   * The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`. For\n   * `pcm16`, input audio must be 16-bit PCM at a 24kHz sample rate, single channel\n   * (mono), and little-endian byte order.\n   */\n  input_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n  /**\n   * Configuration for input audio noise reduction. This can be set to `null` to turn\n   * off. Noise reduction filters audio added to the input audio buffer before it is\n   * sent to VAD and the model. Filtering the audio can improve VAD and turn\n   * detection accuracy (reducing false positives) and model performance by improving\n   * perception of the input audio.\n   */\n  input_audio_noise_reduction?: Session.InputAudioNoiseReduction;\n\n  /**\n   * Configuration for input audio transcription, defaults to off and can be set to\n   * `null` to turn off once on. Input audio transcription is not native to the\n   * model, since the model consumes audio directly. Transcription runs\n   * asynchronously through\n   * [the /audio/transcriptions endpoint](https://platform.openai.com/docs/api-reference/audio/createTranscription)\n   * and should be treated as guidance of input audio content rather than precisely\n   * what the model heard. The client can optionally set the language and prompt for\n   * transcription, these offer additional guidance to the transcription service.\n   */\n  input_audio_transcription?: Session.InputAudioTranscription;\n\n  /**\n   * The default system instructions (i.e. system message) prepended to model calls.\n   * This field allows the client to guide the model on desired responses. The model\n   * can be instructed on response content and format, (e.g. \"be extremely succinct\",\n   * \"act friendly\", \"here are examples of good responses\") and on audio behavior\n   * (e.g. \"talk quickly\", \"inject emotion into your voice\", \"laugh frequently\"). The\n   * instructions are not guaranteed to be followed by the model, but they provide\n   * guidance to the model on the desired behavior.\n   *\n   * Note that the server sets default instructions which will be used if this field\n   * is not set and are visible in the `session.created` event at the start of the\n   * session.\n   */\n  instructions?: string;\n\n  /**\n   * Maximum number of output tokens for a single assistant response, inclusive of\n   * tool calls. Provide an integer between 1 and 4096 to limit output tokens, or\n   * `inf` for the maximum available tokens for a given model. Defaults to `inf`.\n   */\n  max_response_output_tokens?: number | 'inf';\n\n  /**\n   * The set of modalities the model can respond with. To disable audio, set this to\n   * [\"text\"].\n   */\n  modalities?: Array<'text' | 'audio'>;\n\n  /**\n   * The Realtime model used for this session.\n   */\n  model?:\n    | 'gpt-4o-realtime-preview'\n    | 'gpt-4o-realtime-preview-2024-10-01'\n    | 'gpt-4o-realtime-preview-2024-12-17'\n    | 'gpt-4o-realtime-preview-2025-06-03'\n    | 'gpt-4o-mini-realtime-preview'\n    | 'gpt-4o-mini-realtime-preview-2024-12-17';\n\n  /**\n   * The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n   * For `pcm16`, output audio is sampled at a rate of 24kHz.\n   */\n  output_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n  /**\n   * The speed of the model's spoken response. 1.0 is the default speed. 0.25 is the\n   * minimum speed. 1.5 is the maximum speed. This value can only be changed in\n   * between model turns, not while a response is in progress.\n   */\n  speed?: number;\n\n  /**\n   * Sampling temperature for the model, limited to [0.6, 1.2]. For audio models a\n   * temperature of 0.8 is highly recommended for best performance.\n   */\n  temperature?: number;\n\n  /**\n   * How the model chooses tools. Options are `auto`, `none`, `required`, or specify\n   * a function.\n   */\n  tool_choice?: string;\n\n  /**\n   * Tools (functions) available to the model.\n   */\n  tools?: Array<Session.Tool>;\n\n  /**\n   * Configuration options for tracing. Set to null to disable tracing. Once tracing\n   * is enabled for a session, the configuration cannot be modified.\n   *\n   * `auto` will create a trace for the session with default values for the workflow\n   * name, group id, and metadata.\n   */\n  tracing?: 'auto' | Session.TracingConfiguration;\n\n  /**\n   * Configuration for turn detection, ether Server VAD or Semantic VAD. This can be\n   * set to `null` to turn off, in which case the client must manually trigger model\n   * response. Server VAD means that the model will detect the start and end of\n   * speech based on audio volume and respond at the end of user speech. Semantic VAD\n   * is more advanced and uses a turn detection model (in conjunction with VAD) to\n   * semantically estimate whether the user has finished speaking, then dynamically\n   * sets a timeout based on this probability. For example, if user audio trails off\n   * with \"uhhm\", the model will score a low probability of turn end and wait longer\n   * for the user to continue speaking. This can be useful for more natural\n   * conversations, but may have a higher latency.\n   */\n  turn_detection?: Session.TurnDetection;\n\n  /**\n   * The voice the model uses to respond. Voice cannot be changed during the session\n   * once the model has responded with audio at least once. Current voice options are\n   * `alloy`, `ash`, `ballad`, `coral`, `echo`, `sage`, `shimmer`, and `verse`.\n   */\n  voice?: (string & {}) | 'alloy' | 'ash' | 'ballad' | 'coral' | 'echo' | 'sage' | 'shimmer' | 'verse';\n}\n\nexport namespace Session {\n  /**\n   * Configuration for input audio noise reduction. This can be set to `null` to turn\n   * off. Noise reduction filters audio added to the input audio buffer before it is\n   * sent to VAD and the model. Filtering the audio can improve VAD and turn\n   * detection accuracy (reducing false positives) and model performance by improving\n   * perception of the input audio.\n   */\n  export interface InputAudioNoiseReduction {\n    /**\n     * Type of noise reduction. `near_field` is for close-talking microphones such as\n     * headphones, `far_field` is for far-field microphones such as laptop or\n     * conference room microphones.\n     */\n    type?: 'near_field' | 'far_field';\n  }\n\n  /**\n   * Configuration for input audio transcription, defaults to off and can be set to\n   * `null` to turn off once on. Input audio transcription is not native to the\n   * model, since the model consumes audio directly. Transcription runs\n   * asynchronously through\n   * [the /audio/transcriptions endpoint](https://platform.openai.com/docs/api-reference/audio/createTranscription)\n   * and should be treated as guidance of input audio content rather than precisely\n   * what the model heard. The client can optionally set the language and prompt for\n   * transcription, these offer additional guidance to the transcription service.\n   */\n  export interface InputAudioTranscription {\n    /**\n     * The language of the input audio. Supplying the input language in\n     * [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`)\n     * format will improve accuracy and latency.\n     */\n    language?: string;\n\n    /**\n     * The model to use for transcription, current options are `gpt-4o-transcribe`,\n     * `gpt-4o-mini-transcribe`, and `whisper-1`.\n     */\n    model?: string;\n\n    /**\n     * An optional text to guide the model's style or continue a previous audio\n     * segment. For `whisper-1`, the\n     * [prompt is a list of keywords](https://platform.openai.com/docs/guides/speech-to-text#prompting).\n     * For `gpt-4o-transcribe` models, the prompt is a free text string, for example\n     * \"expect words related to technology\".\n     */\n    prompt?: string;\n  }\n\n  export interface Tool {\n    /**\n     * The description of the function, including guidance on when and how to call it,\n     * and guidance about what to tell the user when calling (if anything).\n     */\n    description?: string;\n\n    /**\n     * The name of the function.\n     */\n    name?: string;\n\n    /**\n     * Parameters of the function in JSON Schema.\n     */\n    parameters?: unknown;\n\n    /**\n     * The type of the tool, i.e. `function`.\n     */\n    type?: 'function';\n  }\n\n  /**\n   * Granular configuration for tracing.\n   */\n  export interface TracingConfiguration {\n    /**\n     * The group id to attach to this trace to enable filtering and grouping in the\n     * traces dashboard.\n     */\n    group_id?: string;\n\n    /**\n     * The arbitrary metadata to attach to this trace to enable filtering in the traces\n     * dashboard.\n     */\n    metadata?: unknown;\n\n    /**\n     * The name of the workflow to attach to this trace. This is used to name the trace\n     * in the traces dashboard.\n     */\n    workflow_name?: string;\n  }\n\n  /**\n   * Configuration for turn detection, ether Server VAD or Semantic VAD. This can be\n   * set to `null` to turn off, in which case the client must manually trigger model\n   * response. Server VAD means that the model will detect the start and end of\n   * speech based on audio volume and respond at the end of user speech. Semantic VAD\n   * is more advanced and uses a turn detection model (in conjunction with VAD) to\n   * semantically estimate whether the user has finished speaking, then dynamically\n   * sets a timeout based on this probability. For example, if user audio trails off\n   * with \"uhhm\", the model will score a low probability of turn end and wait longer\n   * for the user to continue speaking. This can be useful for more natural\n   * conversations, but may have a higher latency.\n   */\n  export interface TurnDetection {\n    /**\n     * Whether or not to automatically generate a response when a VAD stop event\n     * occurs.\n     */\n    create_response?: boolean;\n\n    /**\n     * Used only for `semantic_vad` mode. The eagerness of the model to respond. `low`\n     * will wait longer for the user to continue speaking, `high` will respond more\n     * quickly. `auto` is the default and is equivalent to `medium`.\n     */\n    eagerness?: 'low' | 'medium' | 'high' | 'auto';\n\n    /**\n     * Whether or not to automatically interrupt any ongoing response with output to\n     * the default conversation (i.e. `conversation` of `auto`) when a VAD start event\n     * occurs.\n     */\n    interrupt_response?: boolean;\n\n    /**\n     * Used only for `server_vad` mode. Amount of audio to include before the VAD\n     * detected speech (in milliseconds). Defaults to 300ms.\n     */\n    prefix_padding_ms?: number;\n\n    /**\n     * Used only for `server_vad` mode. Duration of silence to detect speech stop (in\n     * milliseconds). Defaults to 500ms. With shorter values the model will respond\n     * more quickly, but may jump in on short pauses from the user.\n     */\n    silence_duration_ms?: number;\n\n    /**\n     * Used only for `server_vad` mode. Activation threshold for VAD (0.0 to 1.0), this\n     * defaults to 0.5. A higher threshold will require louder audio to activate the\n     * model, and thus might perform better in noisy environments.\n     */\n    threshold?: number;\n\n    /**\n     * Type of turn detection.\n     */\n    type?: 'server_vad' | 'semantic_vad';\n  }\n}\n\n/**\n * A new Realtime session configuration, with an ephemeral key. Default TTL for\n * keys is one minute.\n */\nexport interface SessionCreateResponse {\n  /**\n   * Ephemeral key returned by the API.\n   */\n  client_secret: SessionCreateResponse.ClientSecret;\n\n  /**\n   * The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n   */\n  input_audio_format?: string;\n\n  /**\n   * Configuration for input audio transcription, defaults to off and can be set to\n   * `null` to turn off once on. Input audio transcription is not native to the\n   * model, since the model consumes audio directly. Transcription runs\n   * asynchronously and should be treated as rough guidance rather than the\n   * representation understood by the model.\n   */\n  input_audio_transcription?: SessionCreateResponse.InputAudioTranscription;\n\n  /**\n   * The default system instructions (i.e. system message) prepended to model calls.\n   * This field allows the client to guide the model on desired responses. The model\n   * can be instructed on response content and format, (e.g. \"be extremely succinct\",\n   * \"act friendly\", \"here are examples of good responses\") and on audio behavior\n   * (e.g. \"talk quickly\", \"inject emotion into your voice\", \"laugh frequently\"). The\n   * instructions are not guaranteed to be followed by the model, but they provide\n   * guidance to the model on the desired behavior.\n   *\n   * Note that the server sets default instructions which will be used if this field\n   * is not set and are visible in the `session.created` event at the start of the\n   * session.\n   */\n  instructions?: string;\n\n  /**\n   * Maximum number of output tokens for a single assistant response, inclusive of\n   * tool calls. Provide an integer between 1 and 4096 to limit output tokens, or\n   * `inf` for the maximum available tokens for a given model. Defaults to `inf`.\n   */\n  max_response_output_tokens?: number | 'inf';\n\n  /**\n   * The set of modalities the model can respond with. To disable audio, set this to\n   * [\"text\"].\n   */\n  modalities?: Array<'text' | 'audio'>;\n\n  /**\n   * The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n   */\n  output_audio_format?: string;\n\n  /**\n   * The speed of the model's spoken response. 1.0 is the default speed. 0.25 is the\n   * minimum speed. 1.5 is the maximum speed. This value can only be changed in\n   * between model turns, not while a response is in progress.\n   */\n  speed?: number;\n\n  /**\n   * Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8.\n   */\n  temperature?: number;\n\n  /**\n   * How the model chooses tools. Options are `auto`, `none`, `required`, or specify\n   * a function.\n   */\n  tool_choice?: string;\n\n  /**\n   * Tools (functions) available to the model.\n   */\n  tools?: Array<SessionCreateResponse.Tool>;\n\n  /**\n   * Configuration options for tracing. Set to null to disable tracing. Once tracing\n   * is enabled for a session, the configuration cannot be modified.\n   *\n   * `auto` will create a trace for the session with default values for the workflow\n   * name, group id, and metadata.\n   */\n  tracing?: 'auto' | SessionCreateResponse.TracingConfiguration;\n\n  /**\n   * Configuration for turn detection. Can be set to `null` to turn off. Server VAD\n   * means that the model will detect the start and end of speech based on audio\n   * volume and respond at the end of user speech.\n   */\n  turn_detection?: SessionCreateResponse.TurnDetection;\n\n  /**\n   * The voice the model uses to respond. Voice cannot be changed during the session\n   * once the model has responded with audio at least once. Current voice options are\n   * `alloy`, `ash`, `ballad`, `coral`, `echo`, `sage`, `shimmer`, and `verse`.\n   */\n  voice?: (string & {}) | 'alloy' | 'ash' | 'ballad' | 'coral' | 'echo' | 'sage' | 'shimmer' | 'verse';\n}\n\nexport namespace SessionCreateResponse {\n  /**\n   * Ephemeral key returned by the API.\n   */\n  export interface ClientSecret {\n    /**\n     * Timestamp for when the token expires. Currently, all tokens expire after one\n     * minute.\n     */\n    expires_at: number;\n\n    /**\n     * Ephemeral key usable in client environments to authenticate connections to the\n     * Realtime API. Use this in client-side environments rather than a standard API\n     * token, which should only be used server-side.\n     */\n    value: string;\n  }\n\n  /**\n   * Configuration for input audio transcription, defaults to off and can be set to\n   * `null` to turn off once on. Input audio transcription is not native to the\n   * model, since the model consumes audio directly. Transcription runs\n   * asynchronously and should be treated as rough guidance rather than the\n   * representation understood by the model.\n   */\n  export interface InputAudioTranscription {\n    /**\n     * The model to use for transcription.\n     */\n    model?: string;\n  }\n\n  export interface Tool {\n    /**\n     * The description of the function, including guidance on when and how to call it,\n     * and guidance about what to tell the user when calling (if anything).\n     */\n    description?: string;\n\n    /**\n     * The name of the function.\n     */\n    name?: string;\n\n    /**\n     * Parameters of the function in JSON Schema.\n     */\n    parameters?: unknown;\n\n    /**\n     * The type of the tool, i.e. `function`.\n     */\n    type?: 'function';\n  }\n\n  /**\n   * Granular configuration for tracing.\n   */\n  export interface TracingConfiguration {\n    /**\n     * The group id to attach to this trace to enable filtering and grouping in the\n     * traces dashboard.\n     */\n    group_id?: string;\n\n    /**\n     * The arbitrary metadata to attach to this trace to enable filtering in the traces\n     * dashboard.\n     */\n    metadata?: unknown;\n\n    /**\n     * The name of the workflow to attach to this trace. This is used to name the trace\n     * in the traces dashboard.\n     */\n    workflow_name?: string;\n  }\n\n  /**\n   * Configuration for turn detection. Can be set to `null` to turn off. Server VAD\n   * means that the model will detect the start and end of speech based on audio\n   * volume and respond at the end of user speech.\n   */\n  export interface TurnDetection {\n    /**\n     * Amount of audio to include before the VAD detected speech (in milliseconds).\n     * Defaults to 300ms.\n     */\n    prefix_padding_ms?: number;\n\n    /**\n     * Duration of silence to detect speech stop (in milliseconds). Defaults to 500ms.\n     * With shorter values the model will respond more quickly, but may jump in on\n     * short pauses from the user.\n     */\n    silence_duration_ms?: number;\n\n    /**\n     * Activation threshold for VAD (0.0 to 1.0), this defaults to 0.5. A higher\n     * threshold will require louder audio to activate the model, and thus might\n     * perform better in noisy environments.\n     */\n    threshold?: number;\n\n    /**\n     * Type of turn detection, only `server_vad` is currently supported.\n     */\n    type?: string;\n  }\n}\n\nexport interface SessionCreateParams {\n  /**\n   * Configuration options for the generated client secret.\n   */\n  client_secret?: SessionCreateParams.ClientSecret;\n\n  /**\n   * The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`. For\n   * `pcm16`, input audio must be 16-bit PCM at a 24kHz sample rate, single channel\n   * (mono), and little-endian byte order.\n   */\n  input_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n  /**\n   * Configuration for input audio noise reduction. This can be set to `null` to turn\n   * off. Noise reduction filters audio added to the input audio buffer before it is\n   * sent to VAD and the model. Filtering the audio can improve VAD and turn\n   * detection accuracy (reducing false positives) and model performance by improving\n   * perception of the input audio.\n   */\n  input_audio_noise_reduction?: SessionCreateParams.InputAudioNoiseReduction;\n\n  /**\n   * Configuration for input audio transcription, defaults to off and can be set to\n   * `null` to turn off once on. Input audio transcription is not native to the\n   * model, since the model consumes audio directly. Transcription runs\n   * asynchronously through\n   * [the /audio/transcriptions endpoint](https://platform.openai.com/docs/api-reference/audio/createTranscription)\n   * and should be treated as guidance of input audio content rather than precisely\n   * what the model heard. The client can optionally set the language and prompt for\n   * transcription, these offer additional guidance to the transcription service.\n   */\n  input_audio_transcription?: SessionCreateParams.InputAudioTranscription;\n\n  /**\n   * The default system instructions (i.e. system message) prepended to model calls.\n   * This field allows the client to guide the model on desired responses. The model\n   * can be instructed on response content and format, (e.g. \"be extremely succinct\",\n   * \"act friendly\", \"here are examples of good responses\") and on audio behavior\n   * (e.g. \"talk quickly\", \"inject emotion into your voice\", \"laugh frequently\"). The\n   * instructions are not guaranteed to be followed by the model, but they provide\n   * guidance to the model on the desired behavior.\n   *\n   * Note that the server sets default instructions which will be used if this field\n   * is not set and are visible in the `session.created` event at the start of the\n   * session.\n   */\n  instructions?: string;\n\n  /**\n   * Maximum number of output tokens for a single assistant response, inclusive of\n   * tool calls. Provide an integer between 1 and 4096 to limit output tokens, or\n   * `inf` for the maximum available tokens for a given model. Defaults to `inf`.\n   */\n  max_response_output_tokens?: number | 'inf';\n\n  /**\n   * The set of modalities the model can respond with. To disable audio, set this to\n   * [\"text\"].\n   */\n  modalities?: Array<'text' | 'audio'>;\n\n  /**\n   * The Realtime model used for this session.\n   */\n  model?:\n    | 'gpt-4o-realtime-preview'\n    | 'gpt-4o-realtime-preview-2024-10-01'\n    | 'gpt-4o-realtime-preview-2024-12-17'\n    | 'gpt-4o-realtime-preview-2025-06-03'\n    | 'gpt-4o-mini-realtime-preview'\n    | 'gpt-4o-mini-realtime-preview-2024-12-17';\n\n  /**\n   * The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n   * For `pcm16`, output audio is sampled at a rate of 24kHz.\n   */\n  output_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n  /**\n   * The speed of the model's spoken response. 1.0 is the default speed. 0.25 is the\n   * minimum speed. 1.5 is the maximum speed. This value can only be changed in\n   * between model turns, not while a response is in progress.\n   */\n  speed?: number;\n\n  /**\n   * Sampling temperature for the model, limited to [0.6, 1.2]. For audio models a\n   * temperature of 0.8 is highly recommended for best performance.\n   */\n  temperature?: number;\n\n  /**\n   * How the model chooses tools. Options are `auto`, `none`, `required`, or specify\n   * a function.\n   */\n  tool_choice?: string;\n\n  /**\n   * Tools (functions) available to the model.\n   */\n  tools?: Array<SessionCreateParams.Tool>;\n\n  /**\n   * Configuration options for tracing. Set to null to disable tracing. Once tracing\n   * is enabled for a session, the configuration cannot be modified.\n   *\n   * `auto` will create a trace for the session with default values for the workflow\n   * name, group id, and metadata.\n   */\n  tracing?: 'auto' | SessionCreateParams.TracingConfiguration;\n\n  /**\n   * Configuration for turn detection, ether Server VAD or Semantic VAD. This can be\n   * set to `null` to turn off, in which case the client must manually trigger model\n   * response. Server VAD means that the model will detect the start and end of\n   * speech based on audio volume and respond at the end of user speech. Semantic VAD\n   * is more advanced and uses a turn detection model (in conjunction with VAD) to\n   * semantically estimate whether the user has finished speaking, then dynamically\n   * sets a timeout based on this probability. For example, if user audio trails off\n   * with \"uhhm\", the model will score a low probability of turn end and wait longer\n   * for the user to continue speaking. This can be useful for more natural\n   * conversations, but may have a higher latency.\n   */\n  turn_detection?: SessionCreateParams.TurnDetection;\n\n  /**\n   * The voice the model uses to respond. Voice cannot be changed during the session\n   * once the model has responded with audio at least once. Current voice options are\n   * `alloy`, `ash`, `ballad`, `coral`, `echo`, `sage`, `shimmer`, and `verse`.\n   */\n  voice?: (string & {}) | 'alloy' | 'ash' | 'ballad' | 'coral' | 'echo' | 'sage' | 'shimmer' | 'verse';\n}\n\nexport namespace SessionCreateParams {\n  /**\n   * Configuration options for the generated client secret.\n   */\n  export interface ClientSecret {\n    /**\n     * Configuration for the ephemeral token expiration.\n     */\n    expires_after?: ClientSecret.ExpiresAfter;\n  }\n\n  export namespace ClientSecret {\n    /**\n     * Configuration for the ephemeral token expiration.\n     */\n    export interface ExpiresAfter {\n      /**\n       * The anchor point for the ephemeral token expiration. Only `created_at` is\n       * currently supported.\n       */\n      anchor: 'created_at';\n\n      /**\n       * The number of seconds from the anchor point to the expiration. Select a value\n       * between `10` and `7200`.\n       */\n      seconds?: number;\n    }\n  }\n\n  /**\n   * Configuration for input audio noise reduction. This can be set to `null` to turn\n   * off. Noise reduction filters audio added to the input audio buffer before it is\n   * sent to VAD and the model. Filtering the audio can improve VAD and turn\n   * detection accuracy (reducing false positives) and model performance by improving\n   * perception of the input audio.\n   */\n  export interface InputAudioNoiseReduction {\n    /**\n     * Type of noise reduction. `near_field` is for close-talking microphones such as\n     * headphones, `far_field` is for far-field microphones such as laptop or\n     * conference room microphones.\n     */\n    type?: 'near_field' | 'far_field';\n  }\n\n  /**\n   * Configuration for input audio transcription, defaults to off and can be set to\n   * `null` to turn off once on. Input audio transcription is not native to the\n   * model, since the model consumes audio directly. Transcription runs\n   * asynchronously through\n   * [the /audio/transcriptions endpoint](https://platform.openai.com/docs/api-reference/audio/createTranscription)\n   * and should be treated as guidance of input audio content rather than precisely\n   * what the model heard. The client can optionally set the language and prompt for\n   * transcription, these offer additional guidance to the transcription service.\n   */\n  export interface InputAudioTranscription {\n    /**\n     * The language of the input audio. Supplying the input language in\n     * [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`)\n     * format will improve accuracy and latency.\n     */\n    language?: string;\n\n    /**\n     * The model to use for transcription, current options are `gpt-4o-transcribe`,\n     * `gpt-4o-mini-transcribe`, and `whisper-1`.\n     */\n    model?: string;\n\n    /**\n     * An optional text to guide the model's style or continue a previous audio\n     * segment. For `whisper-1`, the\n     * [prompt is a list of keywords](https://platform.openai.com/docs/guides/speech-to-text#prompting).\n     * For `gpt-4o-transcribe` models, the prompt is a free text string, for example\n     * \"expect words related to technology\".\n     */\n    prompt?: string;\n  }\n\n  export interface Tool {\n    /**\n     * The description of the function, including guidance on when and how to call it,\n     * and guidance about what to tell the user when calling (if anything).\n     */\n    description?: string;\n\n    /**\n     * The name of the function.\n     */\n    name?: string;\n\n    /**\n     * Parameters of the function in JSON Schema.\n     */\n    parameters?: unknown;\n\n    /**\n     * The type of the tool, i.e. `function`.\n     */\n    type?: 'function';\n  }\n\n  /**\n   * Granular configuration for tracing.\n   */\n  export interface TracingConfiguration {\n    /**\n     * The group id to attach to this trace to enable filtering and grouping in the\n     * traces dashboard.\n     */\n    group_id?: string;\n\n    /**\n     * The arbitrary metadata to attach to this trace to enable filtering in the traces\n     * dashboard.\n     */\n    metadata?: unknown;\n\n    /**\n     * The name of the workflow to attach to this trace. This is used to name the trace\n     * in the traces dashboard.\n     */\n    workflow_name?: string;\n  }\n\n  /**\n   * Configuration for turn detection, ether Server VAD or Semantic VAD. This can be\n   * set to `null` to turn off, in which case the client must manually trigger model\n   * response. Server VAD means that the model will detect the start and end of\n   * speech based on audio volume and respond at the end of user speech. Semantic VAD\n   * is more advanced and uses a turn detection model (in conjunction with VAD) to\n   * semantically estimate whether the user has finished speaking, then dynamically\n   * sets a timeout based on this probability. For example, if user audio trails off\n   * with \"uhhm\", the model will score a low probability of turn end and wait longer\n   * for the user to continue speaking. This can be useful for more natural\n   * conversations, but may have a higher latency.\n   */\n  export interface TurnDetection {\n    /**\n     * Whether or not to automatically generate a response when a VAD stop event\n     * occurs.\n     */\n    create_response?: boolean;\n\n    /**\n     * Used only for `semantic_vad` mode. The eagerness of the model to respond. `low`\n     * will wait longer for the user to continue speaking, `high` will respond more\n     * quickly. `auto` is the default and is equivalent to `medium`.\n     */\n    eagerness?: 'low' | 'medium' | 'high' | 'auto';\n\n    /**\n     * Whether or not to automatically interrupt any ongoing response with output to\n     * the default conversation (i.e. `conversation` of `auto`) when a VAD start event\n     * occurs.\n     */\n    interrupt_response?: boolean;\n\n    /**\n     * Used only for `server_vad` mode. Amount of audio to include before the VAD\n     * detected speech (in milliseconds). Defaults to 300ms.\n     */\n    prefix_padding_ms?: number;\n\n    /**\n     * Used only for `server_vad` mode. Duration of silence to detect speech stop (in\n     * milliseconds). Defaults to 500ms. With shorter values the model will respond\n     * more quickly, but may jump in on short pauses from the user.\n     */\n    silence_duration_ms?: number;\n\n    /**\n     * Used only for `server_vad` mode. Activation threshold for VAD (0.0 to 1.0), this\n     * defaults to 0.5. A higher threshold will require louder audio to activate the\n     * model, and thus might perform better in noisy environments.\n     */\n    threshold?: number;\n\n    /**\n     * Type of turn detection.\n     */\n    type?: 'server_vad' | 'semantic_vad';\n  }\n}\n\nexport declare namespace Sessions {\n  export {\n    type Session as Session,\n    type SessionCreateResponse as SessionCreateResponse,\n    type SessionCreateParams as SessionCreateParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as ResponsesAPI from './responses';\nimport { ResponseItemsPage } from './responses';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../../core/pagination';\nimport { RequestOptions } from '../../internal/request-options';\nimport { path } from '../../internal/utils/path';\n\nexport class InputItems extends APIResource {\n  /**\n   * Returns a list of input items for a given response.\n   *\n   * @example\n   * ```ts\n   * // Automatically fetches more pages as needed.\n   * for await (const responseItem of client.responses.inputItems.list(\n   *   'response_id',\n   * )) {\n   *   // ...\n   * }\n   * ```\n   */\n  list(\n    responseID: string,\n    query: InputItemListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<ResponseItemsPage, ResponsesAPI.ResponseItem> {\n    return this._client.getAPIList(\n      path`/responses/${responseID}/input_items`,\n      CursorPage<ResponsesAPI.ResponseItem>,\n      { query, ...options },\n    );\n  }\n}\n\n/**\n * A list of Response items.\n */\nexport interface ResponseItemList {\n  /**\n   * A list of items used to generate this response.\n   */\n  data: Array<ResponsesAPI.ResponseItem>;\n\n  /**\n   * The ID of the first item in the list.\n   */\n  first_id: string;\n\n  /**\n   * Whether there are more items available.\n   */\n  has_more: boolean;\n\n  /**\n   * The ID of the last item in the list.\n   */\n  last_id: string;\n\n  /**\n   * The type of object returned, must be `list`.\n   */\n  object: 'list';\n}\n\nexport interface InputItemListParams extends CursorPageParams {\n  /**\n   * Additional fields to include in the response. See the `include` parameter for\n   * Response creation above for more information.\n   */\n  include?: Array<ResponsesAPI.ResponseIncludable>;\n\n  /**\n   * The order to return the input items in. Default is `desc`.\n   *\n   * - `asc`: Return the input items in ascending order.\n   * - `desc`: Return the input items in descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport declare namespace InputItems {\n  export { type ResponseItemList as ResponseItemList, type InputItemListParams as InputItemListParams };\n}\n\nexport { type ResponseItemsPage };\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as Shared from '../shared';\nimport * as ResponsesAPI from './responses';\nimport { APIPromise } from '../../core/api-promise';\nimport { RequestOptions } from '../../internal/request-options';\n\nexport class InputTokens extends APIResource {\n  /**\n   * Get input token counts\n   *\n   * @example\n   * ```ts\n   * const response = await client.responses.inputTokens.count();\n   * ```\n   */\n  count(\n    body: InputTokenCountParams | null | undefined = {},\n    options?: RequestOptions,\n  ): APIPromise<InputTokenCountResponse> {\n    return this._client.post('/responses/input_tokens', { body, ...options });\n  }\n}\n\nexport interface InputTokenCountResponse {\n  input_tokens: number;\n\n  object: 'response.input_tokens';\n}\n\nexport interface InputTokenCountParams {\n  /**\n   * The conversation that this response belongs to. Items from this conversation are\n   * prepended to `input_items` for this response request. Input items and output\n   * items from this response are automatically added to this conversation after this\n   * response completes.\n   */\n  conversation?: string | ResponsesAPI.ResponseConversationParam | null;\n\n  /**\n   * Text, image, or file inputs to the model, used to generate a response\n   */\n  input?: string | Array<ResponsesAPI.ResponseInputItem> | null;\n\n  /**\n   * A system (or developer) message inserted into the model's context. When used\n   * along with `previous_response_id`, the instructions from a previous response\n   * will not be carried over to the next response. This makes it simple to swap out\n   * system (or developer) messages in new responses.\n   */\n  instructions?: string | null;\n\n  /**\n   * Model ID used to generate the response, like `gpt-4o` or `o3`. OpenAI offers a\n   * wide range of models with different capabilities, performance characteristics,\n   * and price points. Refer to the\n   * [model guide](https://platform.openai.com/docs/models) to browse and compare\n   * available models.\n   */\n  model?: string | null;\n\n  /**\n   * Whether to allow the model to run tool calls in parallel.\n   */\n  parallel_tool_calls?: boolean | null;\n\n  /**\n   * The unique ID of the previous response to the model. Use this to create\n   * multi-turn conversations. Learn more about\n   * [conversation state](https://platform.openai.com/docs/guides/conversation-state).\n   * Cannot be used in conjunction with `conversation`.\n   */\n  previous_response_id?: string | null;\n\n  /**\n   * **gpt-5 and o-series models only** Configuration options for\n   * [reasoning models](https://platform.openai.com/docs/guides/reasoning).\n   */\n  reasoning?: Shared.Reasoning | null;\n\n  /**\n   * Configuration options for a text response from the model. Can be plain text or\n   * structured JSON data. Learn more:\n   *\n   * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n   * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n   */\n  text?: InputTokenCountParams.Text | null;\n\n  /**\n   * How the model should select which tool (or tools) to use when generating a\n   * response. See the `tools` parameter to see how to specify which tools the model\n   * can call.\n   */\n  tool_choice?:\n    | ResponsesAPI.ToolChoiceOptions\n    | ResponsesAPI.ToolChoiceAllowed\n    | ResponsesAPI.ToolChoiceTypes\n    | ResponsesAPI.ToolChoiceFunction\n    | ResponsesAPI.ToolChoiceMcp\n    | ResponsesAPI.ToolChoiceCustom\n    | null;\n\n  /**\n   * An array of tools the model may call while generating a response. You can\n   * specify which tool to use by setting the `tool_choice` parameter.\n   */\n  tools?: Array<ResponsesAPI.Tool> | null;\n\n  /**\n   * The truncation strategy to use for the model response. - `auto`: If the input to\n   * this Response exceeds the model's context window size, the model will truncate\n   * the response to fit the context window by dropping items from the beginning of\n   * the conversation. - `disabled` (default): If the input size will exceed the\n   * context window size for a model, the request will fail with a 400 error.\n   */\n  truncation?: 'auto' | 'disabled';\n}\n\nexport namespace InputTokenCountParams {\n  /**\n   * Configuration options for a text response from the model. Can be plain text or\n   * structured JSON data. Learn more:\n   *\n   * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n   * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n   */\n  export interface Text {\n    /**\n     * An object specifying the format that the model must output.\n     *\n     * Configuring `{ \"type\": \"json_schema\" }` enables Structured Outputs, which\n     * ensures the model will match your supplied JSON schema. Learn more in the\n     * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n     *\n     * The default format is `{ \"type\": \"text\" }` with no additional options.\n     *\n     * **Not recommended for gpt-4o and newer models:**\n     *\n     * Setting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\n     * ensures the message the model generates is valid JSON. Using `json_schema` is\n     * preferred for models that support it.\n     */\n    format?: ResponsesAPI.ResponseFormatTextConfig;\n\n    /**\n     * Constrains the verbosity of the model's response. Lower values will result in\n     * more concise responses, while higher values will result in more verbose\n     * responses. Currently supported values are `low`, `medium`, and `high`.\n     */\n    verbosity?: 'low' | 'medium' | 'high' | null;\n  }\n}\n\nexport declare namespace InputTokens {\n  export {\n    type InputTokenCountResponse as InputTokenCountResponse,\n    type InputTokenCountParams as InputTokenCountParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport {\n  type ExtractParsedContentFromParams,\n  parseResponse,\n  type ResponseCreateParamsWithTools,\n  addOutputText,\n} from '../../lib/ResponsesParser';\nimport { ResponseStream, ResponseStreamParams } from '../../lib/responses/ResponseStream';\nimport { APIResource } from '../../core/resource';\nimport * as ResponsesAPI from './responses';\nimport * as Shared from '../shared';\nimport * as InputItemsAPI from './input-items';\nimport { InputItemListParams, InputItems, ResponseItemList } from './input-items';\nimport * as InputTokensAPI from './input-tokens';\nimport { InputTokenCountParams, InputTokenCountResponse, InputTokens } from './input-tokens';\nimport { APIPromise } from '../../core/api-promise';\nimport { CursorPage } from '../../core/pagination';\nimport { Stream } from '../../core/streaming';\nimport { buildHeaders } from '../../internal/headers';\nimport { RequestOptions } from '../../internal/request-options';\nimport { path } from '../../internal/utils/path';\n\nexport interface ParsedResponseOutputText<ParsedT> extends ResponseOutputText {\n  parsed: ParsedT | null;\n}\n\nexport type ParsedContent<ParsedT> = ParsedResponseOutputText<ParsedT> | ResponseOutputRefusal;\n\nexport interface ParsedResponseOutputMessage<ParsedT> extends ResponseOutputMessage {\n  content: ParsedContent<ParsedT>[];\n}\n\nexport interface ParsedResponseFunctionToolCall extends ResponseFunctionToolCall {\n  parsed_arguments: any;\n}\n\nexport type ParsedResponseOutputItem<ParsedT> =\n  | ParsedResponseOutputMessage<ParsedT>\n  | ParsedResponseFunctionToolCall\n  | ResponseFileSearchToolCall\n  | ResponseFunctionWebSearch\n  | ResponseComputerToolCall\n  | ResponseReasoningItem\n  | ResponseOutputItem.ImageGenerationCall\n  | ResponseCodeInterpreterToolCall\n  | ResponseOutputItem.LocalShellCall\n  | ResponseOutputItem.McpCall\n  | ResponseOutputItem.McpListTools\n  | ResponseOutputItem.McpApprovalRequest\n  | ResponseCustomToolCall;\n\nexport interface ParsedResponse<ParsedT> extends Response {\n  output: Array<ParsedResponseOutputItem<ParsedT>>;\n\n  output_parsed: ParsedT | null;\n}\n\nexport type ResponseParseParams = ResponseCreateParamsNonStreaming;\n\nexport class Responses extends APIResource {\n  inputItems: InputItemsAPI.InputItems = new InputItemsAPI.InputItems(this._client);\n  inputTokens: InputTokensAPI.InputTokens = new InputTokensAPI.InputTokens(this._client);\n\n  /**\n   * Creates a model response. Provide\n   * [text](https://platform.openai.com/docs/guides/text) or\n   * [image](https://platform.openai.com/docs/guides/images) inputs to generate\n   * [text](https://platform.openai.com/docs/guides/text) or\n   * [JSON](https://platform.openai.com/docs/guides/structured-outputs) outputs. Have\n   * the model call your own\n   * [custom code](https://platform.openai.com/docs/guides/function-calling) or use\n   * built-in [tools](https://platform.openai.com/docs/guides/tools) like\n   * [web search](https://platform.openai.com/docs/guides/tools-web-search) or\n   * [file search](https://platform.openai.com/docs/guides/tools-file-search) to use\n   * your own data as input for the model's response.\n   *\n   * @example\n   * ```ts\n   * const response = await client.responses.create();\n   * ```\n   */\n  create(body: ResponseCreateParamsNonStreaming, options?: RequestOptions): APIPromise<Response>;\n  create(\n    body: ResponseCreateParamsStreaming,\n    options?: RequestOptions,\n  ): APIPromise<Stream<ResponseStreamEvent>>;\n  create(\n    body: ResponseCreateParamsBase,\n    options?: RequestOptions,\n  ): APIPromise<Stream<ResponseStreamEvent> | Response>;\n  create(\n    body: ResponseCreateParams,\n    options?: RequestOptions,\n  ): APIPromise<Response> | APIPromise<Stream<ResponseStreamEvent>> {\n    return (\n      this._client.post('/responses', { body, ...options, stream: body.stream ?? false }) as\n        | APIPromise<Response>\n        | APIPromise<Stream<ResponseStreamEvent>>\n    )._thenUnwrap((rsp) => {\n      if ('object' in rsp && rsp.object === 'response') {\n        addOutputText(rsp as Response);\n      }\n\n      return rsp;\n    }) as APIPromise<Response> | APIPromise<Stream<ResponseStreamEvent>>;\n  }\n\n  /**\n   * Retrieves a model response with the given ID.\n   *\n   * @example\n   * ```ts\n   * const response = await client.responses.retrieve(\n   *   'resp_677efb5139a88190b512bc3fef8e535d',\n   * );\n   * ```\n   */\n  retrieve(\n    responseID: string,\n    query?: ResponseRetrieveParamsNonStreaming,\n    options?: RequestOptions,\n  ): APIPromise<Response>;\n  retrieve(\n    responseID: string,\n    query: ResponseRetrieveParamsStreaming,\n    options?: RequestOptions,\n  ): APIPromise<Stream<ResponseStreamEvent>>;\n  retrieve(\n    responseID: string,\n    query?: ResponseRetrieveParamsBase | undefined,\n    options?: RequestOptions,\n  ): APIPromise<Stream<ResponseStreamEvent> | Response>;\n  retrieve(\n    responseID: string,\n    query: ResponseRetrieveParams | undefined = {},\n    options?: RequestOptions,\n  ): APIPromise<Response> | APIPromise<Stream<ResponseStreamEvent>> {\n    return (\n      this._client.get(path`/responses/${responseID}`, {\n        query,\n        ...options,\n        stream: query?.stream ?? false,\n      }) as APIPromise<Response> | APIPromise<Stream<ResponseStreamEvent>>\n    )._thenUnwrap((rsp) => {\n      if ('object' in rsp && rsp.object === 'response') {\n        addOutputText(rsp as Response);\n      }\n\n      return rsp;\n    }) as APIPromise<Response> | APIPromise<Stream<ResponseStreamEvent>>;\n  }\n\n  /**\n   * Deletes a model response with the given ID.\n   *\n   * @example\n   * ```ts\n   * await client.responses.delete(\n   *   'resp_677efb5139a88190b512bc3fef8e535d',\n   * );\n   * ```\n   */\n  delete(responseID: string, options?: RequestOptions): APIPromise<void> {\n    return this._client.delete(path`/responses/${responseID}`, {\n      ...options,\n      headers: buildHeaders([{ Accept: '*/*' }, options?.headers]),\n    });\n  }\n\n  parse<Params extends ResponseCreateParamsWithTools, ParsedT = ExtractParsedContentFromParams<Params>>(\n    body: Params,\n    options?: RequestOptions,\n  ): APIPromise<ParsedResponse<ParsedT>> {\n    return this._client.responses\n      .create(body, options)\n      ._thenUnwrap((response) => parseResponse(response as Response, body));\n  }\n\n  /**\n   * Creates a model response stream\n   */\n  stream<Params extends ResponseStreamParams, ParsedT = ExtractParsedContentFromParams<Params>>(\n    body: Params,\n    options?: RequestOptions,\n  ): ResponseStream<ParsedT> {\n    return ResponseStream.createResponse<ParsedT>(this._client, body, options);\n  }\n\n  /**\n   * Cancels a model response with the given ID. Only responses created with the\n   * `background` parameter set to `true` can be cancelled.\n   * [Learn more](https://platform.openai.com/docs/guides/background).\n   *\n   * @example\n   * ```ts\n   * const response = await client.responses.cancel(\n   *   'resp_677efb5139a88190b512bc3fef8e535d',\n   * );\n   * ```\n   */\n  cancel(responseID: string, options?: RequestOptions): APIPromise<Response> {\n    return this._client.post(path`/responses/${responseID}/cancel`, options);\n  }\n}\n\nexport type ResponseItemsPage = CursorPage<ResponseItem>;\n\n/**\n * A tool that controls a virtual computer. Learn more about the\n * [computer tool](https://platform.openai.com/docs/guides/tools-computer-use).\n */\nexport interface ComputerTool {\n  /**\n   * The height of the computer display.\n   */\n  display_height: number;\n\n  /**\n   * The width of the computer display.\n   */\n  display_width: number;\n\n  /**\n   * The type of computer environment to control.\n   */\n  environment: 'windows' | 'mac' | 'linux' | 'ubuntu' | 'browser';\n\n  /**\n   * The type of the computer use tool. Always `computer_use_preview`.\n   */\n  type: 'computer_use_preview';\n}\n\n/**\n * A custom tool that processes input using a specified format. Learn more about\n * [custom tools](https://platform.openai.com/docs/guides/function-calling#custom-tools)\n */\nexport interface CustomTool {\n  /**\n   * The name of the custom tool, used to identify it in tool calls.\n   */\n  name: string;\n\n  /**\n   * The type of the custom tool. Always `custom`.\n   */\n  type: 'custom';\n\n  /**\n   * Optional description of the custom tool, used to provide more context.\n   */\n  description?: string;\n\n  /**\n   * The input format for the custom tool. Default is unconstrained text.\n   */\n  format?: Shared.CustomToolInputFormat;\n}\n\n/**\n * A message input to the model with a role indicating instruction following\n * hierarchy. Instructions given with the `developer` or `system` role take\n * precedence over instructions given with the `user` role. Messages with the\n * `assistant` role are presumed to have been generated by the model in previous\n * interactions.\n */\nexport interface EasyInputMessage {\n  /**\n   * Text, image, or audio input to the model, used to generate a response. Can also\n   * contain previous assistant responses.\n   */\n  content: string | ResponseInputMessageContentList;\n\n  /**\n   * The role of the message input. One of `user`, `assistant`, `system`, or\n   * `developer`.\n   */\n  role: 'user' | 'assistant' | 'system' | 'developer';\n\n  /**\n   * The type of the message input. Always `message`.\n   */\n  type?: 'message';\n}\n\n/**\n * A tool that searches for relevant content from uploaded files. Learn more about\n * the\n * [file search tool](https://platform.openai.com/docs/guides/tools-file-search).\n */\nexport interface FileSearchTool {\n  /**\n   * The type of the file search tool. Always `file_search`.\n   */\n  type: 'file_search';\n\n  /**\n   * The IDs of the vector stores to search.\n   */\n  vector_store_ids: Array<string>;\n\n  /**\n   * A filter to apply.\n   */\n  filters?: Shared.ComparisonFilter | Shared.CompoundFilter | null;\n\n  /**\n   * The maximum number of results to return. This number should be between 1 and 50\n   * inclusive.\n   */\n  max_num_results?: number;\n\n  /**\n   * Ranking options for search.\n   */\n  ranking_options?: FileSearchTool.RankingOptions;\n}\n\nexport namespace FileSearchTool {\n  /**\n   * Ranking options for search.\n   */\n  export interface RankingOptions {\n    /**\n     * Weights that control how reciprocal rank fusion balances semantic embedding\n     * matches versus sparse keyword matches when hybrid search is enabled.\n     */\n    hybrid_search?: RankingOptions.HybridSearch;\n\n    /**\n     * The ranker to use for the file search.\n     */\n    ranker?: 'auto' | 'default-2024-11-15';\n\n    /**\n     * The score threshold for the file search, a number between 0 and 1. Numbers\n     * closer to 1 will attempt to return only the most relevant results, but may\n     * return fewer results.\n     */\n    score_threshold?: number;\n  }\n\n  export namespace RankingOptions {\n    /**\n     * Weights that control how reciprocal rank fusion balances semantic embedding\n     * matches versus sparse keyword matches when hybrid search is enabled.\n     */\n    export interface HybridSearch {\n      /**\n       * The weight of the embedding in the reciprocal ranking fusion.\n       */\n      embedding_weight: number;\n\n      /**\n       * The weight of the text in the reciprocal ranking fusion.\n       */\n      text_weight: number;\n    }\n  }\n}\n\n/**\n * Defines a function in your own code the model can choose to call. Learn more\n * about\n * [function calling](https://platform.openai.com/docs/guides/function-calling).\n */\nexport interface FunctionTool {\n  /**\n   * The name of the function to call.\n   */\n  name: string;\n\n  /**\n   * A JSON schema object describing the parameters of the function.\n   */\n  parameters: { [key: string]: unknown } | null;\n\n  /**\n   * Whether to enforce strict parameter validation. Default `true`.\n   */\n  strict: boolean | null;\n\n  /**\n   * The type of the function tool. Always `function`.\n   */\n  type: 'function';\n\n  /**\n   * A description of the function. Used by the model to determine whether or not to\n   * call the function.\n   */\n  description?: string | null;\n}\n\nexport interface Response {\n  /**\n   * Unique identifier for this Response.\n   */\n  id: string;\n\n  /**\n   * Unix timestamp (in seconds) of when this Response was created.\n   */\n  created_at: number;\n\n  output_text: string;\n\n  /**\n   * An error object returned when the model fails to generate a Response.\n   */\n  error: ResponseError | null;\n\n  /**\n   * Details about why the response is incomplete.\n   */\n  incomplete_details: Response.IncompleteDetails | null;\n\n  /**\n   * A system (or developer) message inserted into the model's context.\n   *\n   * When using along with `previous_response_id`, the instructions from a previous\n   * response will not be carried over to the next response. This makes it simple to\n   * swap out system (or developer) messages in new responses.\n   */\n  instructions: string | Array<ResponseInputItem> | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * Model ID used to generate the response, like `gpt-4o` or `o3`. OpenAI offers a\n   * wide range of models with different capabilities, performance characteristics,\n   * and price points. Refer to the\n   * [model guide](https://platform.openai.com/docs/models) to browse and compare\n   * available models.\n   */\n  model: Shared.ResponsesModel;\n\n  /**\n   * The object type of this resource - always set to `response`.\n   */\n  object: 'response';\n\n  /**\n   * An array of content items generated by the model.\n   *\n   * - The length and order of items in the `output` array is dependent on the\n   *   model's response.\n   * - Rather than accessing the first item in the `output` array and assuming it's\n   *   an `assistant` message with the content generated by the model, you might\n   *   consider using the `output_text` property where supported in SDKs.\n   */\n  output: Array<ResponseOutputItem>;\n\n  /**\n   * Whether to allow the model to run tool calls in parallel.\n   */\n  parallel_tool_calls: boolean;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic. We generally recommend altering this or `top_p` but\n   * not both.\n   */\n  temperature: number | null;\n\n  /**\n   * How the model should select which tool (or tools) to use when generating a\n   * response. See the `tools` parameter to see how to specify which tools the model\n   * can call.\n   */\n  tool_choice:\n    | ToolChoiceOptions\n    | ToolChoiceAllowed\n    | ToolChoiceTypes\n    | ToolChoiceFunction\n    | ToolChoiceMcp\n    | ToolChoiceCustom;\n\n  /**\n   * An array of tools the model may call while generating a response. You can\n   * specify which tool to use by setting the `tool_choice` parameter.\n   *\n   * We support the following categories of tools:\n   *\n   * - **Built-in tools**: Tools that are provided by OpenAI that extend the model's\n   *   capabilities, like\n   *   [web search](https://platform.openai.com/docs/guides/tools-web-search) or\n   *   [file search](https://platform.openai.com/docs/guides/tools-file-search).\n   *   Learn more about\n   *   [built-in tools](https://platform.openai.com/docs/guides/tools).\n   * - **MCP Tools**: Integrations with third-party systems via custom MCP servers or\n   *   predefined connectors such as Google Drive and SharePoint. Learn more about\n   *   [MCP Tools](https://platform.openai.com/docs/guides/tools-connectors-mcp).\n   * - **Function calls (custom tools)**: Functions that are defined by you, enabling\n   *   the model to call your own code with strongly typed arguments and outputs.\n   *   Learn more about\n   *   [function calling](https://platform.openai.com/docs/guides/function-calling).\n   *   You can also use custom tools to call your own code.\n   */\n  tools: Array<Tool>;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or `temperature` but not both.\n   */\n  top_p: number | null;\n\n  /**\n   * Whether to run the model response in the background.\n   * [Learn more](https://platform.openai.com/docs/guides/background).\n   */\n  background?: boolean | null;\n\n  /**\n   * The conversation that this response belongs to. Input items and output items\n   * from this response are automatically added to this conversation.\n   */\n  conversation?: Response.Conversation | null;\n\n  /**\n   * An upper bound for the number of tokens that can be generated for a response,\n   * including visible output tokens and\n   * [reasoning tokens](https://platform.openai.com/docs/guides/reasoning).\n   */\n  max_output_tokens?: number | null;\n\n  /**\n   * The unique ID of the previous response to the model. Use this to create\n   * multi-turn conversations. Learn more about\n   * [conversation state](https://platform.openai.com/docs/guides/conversation-state).\n   * Cannot be used in conjunction with `conversation`.\n   */\n  previous_response_id?: string | null;\n\n  /**\n   * Reference to a prompt template and its variables.\n   * [Learn more](https://platform.openai.com/docs/guides/text?api-mode=responses#reusable-prompts).\n   */\n  prompt?: ResponsePrompt | null;\n\n  /**\n   * Used by OpenAI to cache responses for similar requests to optimize your cache\n   * hit rates. Replaces the `user` field.\n   * [Learn more](https://platform.openai.com/docs/guides/prompt-caching).\n   */\n  prompt_cache_key?: string;\n\n  /**\n   * **gpt-5 and o-series models only**\n   *\n   * Configuration options for\n   * [reasoning models](https://platform.openai.com/docs/guides/reasoning).\n   */\n  reasoning?: Shared.Reasoning | null;\n\n  /**\n   * A stable identifier used to help detect users of your application that may be\n   * violating OpenAI's usage policies. The IDs should be a string that uniquely\n   * identifies each user. We recommend hashing their username or email address, in\n   * order to avoid sending us any identifying information.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).\n   */\n  safety_identifier?: string;\n\n  /**\n   * Specifies the latency tier to use for processing the request. This parameter is\n   * relevant for customers subscribed to the scale tier service:\n   *\n   * - If set to 'auto', then the request will be processed with the service tier\n   *   configured in the Project settings. Unless otherwise configured, the Project\n   *   will use 'default'.\n   * - If set to 'default', then the request will be processed with the standard\n   *   pricing and performance for the selected model.\n   * - If set to '[flex](https://platform.openai.com/docs/guides/flex-processing)' or\n   *   '[priority](https://openai.com/api-priority-processing/)', then the request\n   *   will be processed with the corresponding service tier.\n   * - When not set, the default behavior is 'auto'.\n   *\n   * When this parameter is set, the response body will include the `service_tier`\n   * utilized.\n   */\n  service_tier?: 'auto' | 'default' | 'flex' | 'scale' | 'priority' | null;\n\n  /**\n   * The status of the response generation. One of `completed`, `failed`,\n   * `in_progress`, `cancelled`, `queued`, or `incomplete`.\n   */\n  status?: ResponseStatus;\n\n  /**\n   * Configuration options for a text response from the model. Can be plain text or\n   * structured JSON data. Learn more:\n   *\n   * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n   * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n   */\n  text?: ResponseTextConfig;\n\n  /**\n   * The truncation strategy to use for the model response.\n   *\n   * - `auto`: If the input to this Response exceeds the model's context window size,\n   *   the model will truncate the response to fit the context window by dropping\n   *   items from the beginning of the conversation.\n   * - `disabled` (default): If the input size will exceed the context window size\n   *   for a model, the request will fail with a 400 error.\n   */\n  truncation?: 'auto' | 'disabled' | null;\n\n  /**\n   * Represents token usage details including input tokens, output tokens, a\n   * breakdown of output tokens, and the total tokens used.\n   */\n  usage?: ResponseUsage;\n\n  /**\n   * @deprecated This field is being replaced by `safety_identifier` and\n   * `prompt_cache_key`. Use `prompt_cache_key` instead to maintain caching\n   * optimizations. A stable identifier for your end-users. Used to boost cache hit\n   * rates by better bucketing similar requests and to help OpenAI detect and prevent\n   * abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).\n   */\n  user?: string;\n}\n\nexport namespace Response {\n  /**\n   * Details about why the response is incomplete.\n   */\n  export interface IncompleteDetails {\n    /**\n     * The reason why the response is incomplete.\n     */\n    reason?: 'max_output_tokens' | 'content_filter';\n  }\n\n  /**\n   * The conversation that this response belongs to. Input items and output items\n   * from this response are automatically added to this conversation.\n   */\n  export interface Conversation {\n    /**\n     * The unique ID of the conversation.\n     */\n    id: string;\n  }\n}\n\n/**\n * Emitted when there is a partial audio response.\n */\nexport interface ResponseAudioDeltaEvent {\n  /**\n   * A chunk of Base64 encoded response audio bytes.\n   */\n  delta: string;\n\n  /**\n   * A sequence number for this chunk of the stream response.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.audio.delta`.\n   */\n  type: 'response.audio.delta';\n}\n\n/**\n * Emitted when the audio response is complete.\n */\nexport interface ResponseAudioDoneEvent {\n  /**\n   * The sequence number of the delta.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.audio.done`.\n   */\n  type: 'response.audio.done';\n}\n\n/**\n * Emitted when there is a partial transcript of audio.\n */\nexport interface ResponseAudioTranscriptDeltaEvent {\n  /**\n   * The partial transcript of the audio response.\n   */\n  delta: string;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.audio.transcript.delta`.\n   */\n  type: 'response.audio.transcript.delta';\n}\n\n/**\n * Emitted when the full audio transcript is completed.\n */\nexport interface ResponseAudioTranscriptDoneEvent {\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.audio.transcript.done`.\n   */\n  type: 'response.audio.transcript.done';\n}\n\n/**\n * Emitted when a partial code snippet is streamed by the code interpreter.\n */\nexport interface ResponseCodeInterpreterCallCodeDeltaEvent {\n  /**\n   * The partial code snippet being streamed by the code interpreter.\n   */\n  delta: string;\n\n  /**\n   * The unique identifier of the code interpreter tool call item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response for which the code is being\n   * streamed.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event, used to order streaming events.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.code_interpreter_call_code.delta`.\n   */\n  type: 'response.code_interpreter_call_code.delta';\n}\n\n/**\n * Emitted when the code snippet is finalized by the code interpreter.\n */\nexport interface ResponseCodeInterpreterCallCodeDoneEvent {\n  /**\n   * The final code snippet output by the code interpreter.\n   */\n  code: string;\n\n  /**\n   * The unique identifier of the code interpreter tool call item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response for which the code is finalized.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event, used to order streaming events.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.code_interpreter_call_code.done`.\n   */\n  type: 'response.code_interpreter_call_code.done';\n}\n\n/**\n * Emitted when the code interpreter call is completed.\n */\nexport interface ResponseCodeInterpreterCallCompletedEvent {\n  /**\n   * The unique identifier of the code interpreter tool call item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response for which the code interpreter call\n   * is completed.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event, used to order streaming events.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.code_interpreter_call.completed`.\n   */\n  type: 'response.code_interpreter_call.completed';\n}\n\n/**\n * Emitted when a code interpreter call is in progress.\n */\nexport interface ResponseCodeInterpreterCallInProgressEvent {\n  /**\n   * The unique identifier of the code interpreter tool call item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response for which the code interpreter call\n   * is in progress.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event, used to order streaming events.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.code_interpreter_call.in_progress`.\n   */\n  type: 'response.code_interpreter_call.in_progress';\n}\n\n/**\n * Emitted when the code interpreter is actively interpreting the code snippet.\n */\nexport interface ResponseCodeInterpreterCallInterpretingEvent {\n  /**\n   * The unique identifier of the code interpreter tool call item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response for which the code interpreter is\n   * interpreting code.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event, used to order streaming events.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.code_interpreter_call.interpreting`.\n   */\n  type: 'response.code_interpreter_call.interpreting';\n}\n\n/**\n * A tool call to run code.\n */\nexport interface ResponseCodeInterpreterToolCall {\n  /**\n   * The unique ID of the code interpreter tool call.\n   */\n  id: string;\n\n  /**\n   * The code to run, or null if not available.\n   */\n  code: string | null;\n\n  /**\n   * The ID of the container used to run the code.\n   */\n  container_id: string;\n\n  /**\n   * The outputs generated by the code interpreter, such as logs or images. Can be\n   * null if no outputs are available.\n   */\n  outputs: Array<ResponseCodeInterpreterToolCall.Logs | ResponseCodeInterpreterToolCall.Image> | null;\n\n  /**\n   * The status of the code interpreter tool call. Valid values are `in_progress`,\n   * `completed`, `incomplete`, `interpreting`, and `failed`.\n   */\n  status: 'in_progress' | 'completed' | 'incomplete' | 'interpreting' | 'failed';\n\n  /**\n   * The type of the code interpreter tool call. Always `code_interpreter_call`.\n   */\n  type: 'code_interpreter_call';\n}\n\nexport namespace ResponseCodeInterpreterToolCall {\n  /**\n   * The logs output from the code interpreter.\n   */\n  export interface Logs {\n    /**\n     * The logs output from the code interpreter.\n     */\n    logs: string;\n\n    /**\n     * The type of the output. Always `logs`.\n     */\n    type: 'logs';\n  }\n\n  /**\n   * The image output from the code interpreter.\n   */\n  export interface Image {\n    /**\n     * The type of the output. Always `image`.\n     */\n    type: 'image';\n\n    /**\n     * The URL of the image output from the code interpreter.\n     */\n    url: string;\n  }\n}\n\n/**\n * Emitted when the model response is complete.\n */\nexport interface ResponseCompletedEvent {\n  /**\n   * Properties of the completed response.\n   */\n  response: Response;\n\n  /**\n   * The sequence number for this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.completed`.\n   */\n  type: 'response.completed';\n}\n\n/**\n * A tool call to a computer use tool. See the\n * [computer use guide](https://platform.openai.com/docs/guides/tools-computer-use)\n * for more information.\n */\nexport interface ResponseComputerToolCall {\n  /**\n   * The unique ID of the computer call.\n   */\n  id: string;\n\n  /**\n   * A click action.\n   */\n  action:\n    | ResponseComputerToolCall.Click\n    | ResponseComputerToolCall.DoubleClick\n    | ResponseComputerToolCall.Drag\n    | ResponseComputerToolCall.Keypress\n    | ResponseComputerToolCall.Move\n    | ResponseComputerToolCall.Screenshot\n    | ResponseComputerToolCall.Scroll\n    | ResponseComputerToolCall.Type\n    | ResponseComputerToolCall.Wait;\n\n  /**\n   * An identifier used when responding to the tool call with output.\n   */\n  call_id: string;\n\n  /**\n   * The pending safety checks for the computer call.\n   */\n  pending_safety_checks: Array<ResponseComputerToolCall.PendingSafetyCheck>;\n\n  /**\n   * The status of the item. One of `in_progress`, `completed`, or `incomplete`.\n   * Populated when items are returned via API.\n   */\n  status: 'in_progress' | 'completed' | 'incomplete';\n\n  /**\n   * The type of the computer call. Always `computer_call`.\n   */\n  type: 'computer_call';\n}\n\nexport namespace ResponseComputerToolCall {\n  /**\n   * A click action.\n   */\n  export interface Click {\n    /**\n     * Indicates which mouse button was pressed during the click. One of `left`,\n     * `right`, `wheel`, `back`, or `forward`.\n     */\n    button: 'left' | 'right' | 'wheel' | 'back' | 'forward';\n\n    /**\n     * Specifies the event type. For a click action, this property is always `click`.\n     */\n    type: 'click';\n\n    /**\n     * The x-coordinate where the click occurred.\n     */\n    x: number;\n\n    /**\n     * The y-coordinate where the click occurred.\n     */\n    y: number;\n  }\n\n  /**\n   * A double click action.\n   */\n  export interface DoubleClick {\n    /**\n     * Specifies the event type. For a double click action, this property is always set\n     * to `double_click`.\n     */\n    type: 'double_click';\n\n    /**\n     * The x-coordinate where the double click occurred.\n     */\n    x: number;\n\n    /**\n     * The y-coordinate where the double click occurred.\n     */\n    y: number;\n  }\n\n  /**\n   * A drag action.\n   */\n  export interface Drag {\n    /**\n     * An array of coordinates representing the path of the drag action. Coordinates\n     * will appear as an array of objects, eg\n     *\n     * ```\n     * [\n     *   { x: 100, y: 200 },\n     *   { x: 200, y: 300 }\n     * ]\n     * ```\n     */\n    path: Array<Drag.Path>;\n\n    /**\n     * Specifies the event type. For a drag action, this property is always set to\n     * `drag`.\n     */\n    type: 'drag';\n  }\n\n  export namespace Drag {\n    /**\n     * An x/y coordinate pair, e.g. `{ x: 100, y: 200 }`.\n     */\n    export interface Path {\n      /**\n       * The x-coordinate.\n       */\n      x: number;\n\n      /**\n       * The y-coordinate.\n       */\n      y: number;\n    }\n  }\n\n  /**\n   * A collection of keypresses the model would like to perform.\n   */\n  export interface Keypress {\n    /**\n     * The combination of keys the model is requesting to be pressed. This is an array\n     * of strings, each representing a key.\n     */\n    keys: Array<string>;\n\n    /**\n     * Specifies the event type. For a keypress action, this property is always set to\n     * `keypress`.\n     */\n    type: 'keypress';\n  }\n\n  /**\n   * A mouse move action.\n   */\n  export interface Move {\n    /**\n     * Specifies the event type. For a move action, this property is always set to\n     * `move`.\n     */\n    type: 'move';\n\n    /**\n     * The x-coordinate to move to.\n     */\n    x: number;\n\n    /**\n     * The y-coordinate to move to.\n     */\n    y: number;\n  }\n\n  /**\n   * A screenshot action.\n   */\n  export interface Screenshot {\n    /**\n     * Specifies the event type. For a screenshot action, this property is always set\n     * to `screenshot`.\n     */\n    type: 'screenshot';\n  }\n\n  /**\n   * A scroll action.\n   */\n  export interface Scroll {\n    /**\n     * The horizontal scroll distance.\n     */\n    scroll_x: number;\n\n    /**\n     * The vertical scroll distance.\n     */\n    scroll_y: number;\n\n    /**\n     * Specifies the event type. For a scroll action, this property is always set to\n     * `scroll`.\n     */\n    type: 'scroll';\n\n    /**\n     * The x-coordinate where the scroll occurred.\n     */\n    x: number;\n\n    /**\n     * The y-coordinate where the scroll occurred.\n     */\n    y: number;\n  }\n\n  /**\n   * An action to type in text.\n   */\n  export interface Type {\n    /**\n     * The text to type.\n     */\n    text: string;\n\n    /**\n     * Specifies the event type. For a type action, this property is always set to\n     * `type`.\n     */\n    type: 'type';\n  }\n\n  /**\n   * A wait action.\n   */\n  export interface Wait {\n    /**\n     * Specifies the event type. For a wait action, this property is always set to\n     * `wait`.\n     */\n    type: 'wait';\n  }\n\n  /**\n   * A pending safety check for the computer call.\n   */\n  export interface PendingSafetyCheck {\n    /**\n     * The ID of the pending safety check.\n     */\n    id: string;\n\n    /**\n     * The type of the pending safety check.\n     */\n    code?: string | null;\n\n    /**\n     * Details about the pending safety check.\n     */\n    message?: string | null;\n  }\n}\n\nexport interface ResponseComputerToolCallOutputItem {\n  /**\n   * The unique ID of the computer call tool output.\n   */\n  id: string;\n\n  /**\n   * The ID of the computer tool call that produced the output.\n   */\n  call_id: string;\n\n  /**\n   * A computer screenshot image used with the computer use tool.\n   */\n  output: ResponseComputerToolCallOutputScreenshot;\n\n  /**\n   * The type of the computer tool call output. Always `computer_call_output`.\n   */\n  type: 'computer_call_output';\n\n  /**\n   * The safety checks reported by the API that have been acknowledged by the\n   * developer.\n   */\n  acknowledged_safety_checks?: Array<ResponseComputerToolCallOutputItem.AcknowledgedSafetyCheck>;\n\n  /**\n   * The status of the message input. One of `in_progress`, `completed`, or\n   * `incomplete`. Populated when input items are returned via API.\n   */\n  status?: 'in_progress' | 'completed' | 'incomplete';\n}\n\nexport namespace ResponseComputerToolCallOutputItem {\n  /**\n   * A pending safety check for the computer call.\n   */\n  export interface AcknowledgedSafetyCheck {\n    /**\n     * The ID of the pending safety check.\n     */\n    id: string;\n\n    /**\n     * The type of the pending safety check.\n     */\n    code?: string | null;\n\n    /**\n     * Details about the pending safety check.\n     */\n    message?: string | null;\n  }\n}\n\n/**\n * A computer screenshot image used with the computer use tool.\n */\nexport interface ResponseComputerToolCallOutputScreenshot {\n  /**\n   * Specifies the event type. For a computer screenshot, this property is always set\n   * to `computer_screenshot`.\n   */\n  type: 'computer_screenshot';\n\n  /**\n   * The identifier of an uploaded file that contains the screenshot.\n   */\n  file_id?: string;\n\n  /**\n   * The URL of the screenshot image.\n   */\n  image_url?: string;\n}\n\n/**\n * Multi-modal input and output contents.\n */\nexport type ResponseContent =\n  | ResponseInputText\n  | ResponseInputImage\n  | ResponseInputFile\n  | ResponseOutputText\n  | ResponseOutputRefusal\n  | ResponseContent.ReasoningTextContent;\n\nexport namespace ResponseContent {\n  /**\n   * Reasoning text from the model.\n   */\n  export interface ReasoningTextContent {\n    /**\n     * The reasoning text from the model.\n     */\n    text: string;\n\n    /**\n     * The type of the reasoning text. Always `reasoning_text`.\n     */\n    type: 'reasoning_text';\n  }\n}\n\n/**\n * Emitted when a new content part is added.\n */\nexport interface ResponseContentPartAddedEvent {\n  /**\n   * The index of the content part that was added.\n   */\n  content_index: number;\n\n  /**\n   * The ID of the output item that the content part was added to.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the content part was added to.\n   */\n  output_index: number;\n\n  /**\n   * The content part that was added.\n   */\n  part: ResponseOutputText | ResponseOutputRefusal | ResponseContentPartAddedEvent.ReasoningText;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.content_part.added`.\n   */\n  type: 'response.content_part.added';\n}\n\nexport namespace ResponseContentPartAddedEvent {\n  /**\n   * Reasoning text from the model.\n   */\n  export interface ReasoningText {\n    /**\n     * The reasoning text from the model.\n     */\n    text: string;\n\n    /**\n     * The type of the reasoning text. Always `reasoning_text`.\n     */\n    type: 'reasoning_text';\n  }\n}\n\n/**\n * Emitted when a content part is done.\n */\nexport interface ResponseContentPartDoneEvent {\n  /**\n   * The index of the content part that is done.\n   */\n  content_index: number;\n\n  /**\n   * The ID of the output item that the content part was added to.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the content part was added to.\n   */\n  output_index: number;\n\n  /**\n   * The content part that is done.\n   */\n  part: ResponseOutputText | ResponseOutputRefusal | ResponseContentPartDoneEvent.ReasoningText;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.content_part.done`.\n   */\n  type: 'response.content_part.done';\n}\n\nexport namespace ResponseContentPartDoneEvent {\n  /**\n   * Reasoning text from the model.\n   */\n  export interface ReasoningText {\n    /**\n     * The reasoning text from the model.\n     */\n    text: string;\n\n    /**\n     * The type of the reasoning text. Always `reasoning_text`.\n     */\n    type: 'reasoning_text';\n  }\n}\n\n/**\n * The conversation that this response belongs to.\n */\nexport interface ResponseConversationParam {\n  /**\n   * The unique ID of the conversation.\n   */\n  id: string;\n}\n\n/**\n * An event that is emitted when a response is created.\n */\nexport interface ResponseCreatedEvent {\n  /**\n   * The response that was created.\n   */\n  response: Response;\n\n  /**\n   * The sequence number for this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.created`.\n   */\n  type: 'response.created';\n}\n\n/**\n * A call to a custom tool created by the model.\n */\nexport interface ResponseCustomToolCall {\n  /**\n   * An identifier used to map this custom tool call to a tool call output.\n   */\n  call_id: string;\n\n  /**\n   * The input for the custom tool call generated by the model.\n   */\n  input: string;\n\n  /**\n   * The name of the custom tool being called.\n   */\n  name: string;\n\n  /**\n   * The type of the custom tool call. Always `custom_tool_call`.\n   */\n  type: 'custom_tool_call';\n\n  /**\n   * The unique ID of the custom tool call in the OpenAI platform.\n   */\n  id?: string;\n}\n\n/**\n * Event representing a delta (partial update) to the input of a custom tool call.\n */\nexport interface ResponseCustomToolCallInputDeltaEvent {\n  /**\n   * The incremental input data (delta) for the custom tool call.\n   */\n  delta: string;\n\n  /**\n   * Unique identifier for the API item associated with this event.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output this delta applies to.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The event type identifier.\n   */\n  type: 'response.custom_tool_call_input.delta';\n}\n\n/**\n * Event indicating that input for a custom tool call is complete.\n */\nexport interface ResponseCustomToolCallInputDoneEvent {\n  /**\n   * The complete input data for the custom tool call.\n   */\n  input: string;\n\n  /**\n   * Unique identifier for the API item associated with this event.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output this event applies to.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The event type identifier.\n   */\n  type: 'response.custom_tool_call_input.done';\n}\n\n/**\n * The output of a custom tool call from your code, being sent back to the model.\n */\nexport interface ResponseCustomToolCallOutput {\n  /**\n   * The call ID, used to map this custom tool call output to a custom tool call.\n   */\n  call_id: string;\n\n  /**\n   * The output from the custom tool call generated by your code. Can be a string or\n   * an list of output content.\n   */\n  output: string | Array<ResponseInputText | ResponseInputImage | ResponseInputFile>;\n\n  /**\n   * The type of the custom tool call output. Always `custom_tool_call_output`.\n   */\n  type: 'custom_tool_call_output';\n\n  /**\n   * The unique ID of the custom tool call output in the OpenAI platform.\n   */\n  id?: string;\n}\n\n/**\n * An error object returned when the model fails to generate a Response.\n */\nexport interface ResponseError {\n  /**\n   * The error code for the response.\n   */\n  code:\n    | 'server_error'\n    | 'rate_limit_exceeded'\n    | 'invalid_prompt'\n    | 'vector_store_timeout'\n    | 'invalid_image'\n    | 'invalid_image_format'\n    | 'invalid_base64_image'\n    | 'invalid_image_url'\n    | 'image_too_large'\n    | 'image_too_small'\n    | 'image_parse_error'\n    | 'image_content_policy_violation'\n    | 'invalid_image_mode'\n    | 'image_file_too_large'\n    | 'unsupported_image_media_type'\n    | 'empty_image_file'\n    | 'failed_to_download_image'\n    | 'image_file_not_found';\n\n  /**\n   * A human-readable description of the error.\n   */\n  message: string;\n}\n\n/**\n * Emitted when an error occurs.\n */\nexport interface ResponseErrorEvent {\n  /**\n   * The error code.\n   */\n  code: string | null;\n\n  /**\n   * The error message.\n   */\n  message: string;\n\n  /**\n   * The error parameter.\n   */\n  param: string | null;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `error`.\n   */\n  type: 'error';\n}\n\n/**\n * An event that is emitted when a response fails.\n */\nexport interface ResponseFailedEvent {\n  /**\n   * The response that failed.\n   */\n  response: Response;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.failed`.\n   */\n  type: 'response.failed';\n}\n\n/**\n * Emitted when a file search call is completed (results found).\n */\nexport interface ResponseFileSearchCallCompletedEvent {\n  /**\n   * The ID of the output item that the file search call is initiated.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the file search call is initiated.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.file_search_call.completed`.\n   */\n  type: 'response.file_search_call.completed';\n}\n\n/**\n * Emitted when a file search call is initiated.\n */\nexport interface ResponseFileSearchCallInProgressEvent {\n  /**\n   * The ID of the output item that the file search call is initiated.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the file search call is initiated.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.file_search_call.in_progress`.\n   */\n  type: 'response.file_search_call.in_progress';\n}\n\n/**\n * Emitted when a file search is currently searching.\n */\nexport interface ResponseFileSearchCallSearchingEvent {\n  /**\n   * The ID of the output item that the file search call is initiated.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the file search call is searching.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.file_search_call.searching`.\n   */\n  type: 'response.file_search_call.searching';\n}\n\n/**\n * The results of a file search tool call. See the\n * [file search guide](https://platform.openai.com/docs/guides/tools-file-search)\n * for more information.\n */\nexport interface ResponseFileSearchToolCall {\n  /**\n   * The unique ID of the file search tool call.\n   */\n  id: string;\n\n  /**\n   * The queries used to search for files.\n   */\n  queries: Array<string>;\n\n  /**\n   * The status of the file search tool call. One of `in_progress`, `searching`,\n   * `incomplete` or `failed`,\n   */\n  status: 'in_progress' | 'searching' | 'completed' | 'incomplete' | 'failed';\n\n  /**\n   * The type of the file search tool call. Always `file_search_call`.\n   */\n  type: 'file_search_call';\n\n  /**\n   * The results of the file search tool call.\n   */\n  results?: Array<ResponseFileSearchToolCall.Result> | null;\n}\n\nexport namespace ResponseFileSearchToolCall {\n  export interface Result {\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format, and\n     * querying for objects via API or the dashboard. Keys are strings with a maximum\n     * length of 64 characters. Values are strings with a maximum length of 512\n     * characters, booleans, or numbers.\n     */\n    attributes?: { [key: string]: string | number | boolean } | null;\n\n    /**\n     * The unique ID of the file.\n     */\n    file_id?: string;\n\n    /**\n     * The name of the file.\n     */\n    filename?: string;\n\n    /**\n     * The relevance score of the file - a value between 0 and 1.\n     */\n    score?: number;\n\n    /**\n     * The text that was retrieved from the file.\n     */\n    text?: string;\n  }\n}\n\n/**\n * An object specifying the format that the model must output.\n *\n * Configuring `{ \"type\": \"json_schema\" }` enables Structured Outputs, which\n * ensures the model will match your supplied JSON schema. Learn more in the\n * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n *\n * The default format is `{ \"type\": \"text\" }` with no additional options.\n *\n * **Not recommended for gpt-4o and newer models:**\n *\n * Setting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\n * ensures the message the model generates is valid JSON. Using `json_schema` is\n * preferred for models that support it.\n */\nexport type ResponseFormatTextConfig =\n  | Shared.ResponseFormatText\n  | ResponseFormatTextJSONSchemaConfig\n  | Shared.ResponseFormatJSONObject;\n\n/**\n * JSON Schema response format. Used to generate structured JSON responses. Learn\n * more about\n * [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).\n */\nexport interface ResponseFormatTextJSONSchemaConfig {\n  /**\n   * The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores\n   * and dashes, with a maximum length of 64.\n   */\n  name: string;\n\n  /**\n   * The schema for the response format, described as a JSON Schema object. Learn how\n   * to build JSON schemas [here](https://json-schema.org/).\n   */\n  schema: { [key: string]: unknown };\n\n  /**\n   * The type of response format being defined. Always `json_schema`.\n   */\n  type: 'json_schema';\n\n  /**\n   * A description of what the response format is for, used by the model to determine\n   * how to respond in the format.\n   */\n  description?: string;\n\n  /**\n   * Whether to enable strict schema adherence when generating the output. If set to\n   * true, the model will always follow the exact schema defined in the `schema`\n   * field. Only a subset of JSON Schema is supported when `strict` is `true`. To\n   * learn more, read the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   */\n  strict?: boolean | null;\n}\n\n/**\n * Emitted when there is a partial function-call arguments delta.\n */\nexport interface ResponseFunctionCallArgumentsDeltaEvent {\n  /**\n   * The function-call arguments delta that is added.\n   */\n  delta: string;\n\n  /**\n   * The ID of the output item that the function-call arguments delta is added to.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the function-call arguments delta is added to.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.function_call_arguments.delta`.\n   */\n  type: 'response.function_call_arguments.delta';\n}\n\n/**\n * Emitted when function-call arguments are finalized.\n */\nexport interface ResponseFunctionCallArgumentsDoneEvent {\n  /**\n   * The function-call arguments.\n   */\n  arguments: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The name of the function that was called.\n   */\n  name: string;\n\n  /**\n   * The index of the output item.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  type: 'response.function_call_arguments.done';\n}\n\n/**\n * A text input to the model.\n */\nexport type ResponseFunctionCallOutputItem =\n  | ResponseInputTextContent\n  | ResponseInputImageContent\n  | ResponseInputFileContent;\n\nexport type ResponseFunctionCallOutputItemList = Array<ResponseFunctionCallOutputItem>;\n\n/**\n * A tool call to run a function. See the\n * [function calling guide](https://platform.openai.com/docs/guides/function-calling)\n * for more information.\n */\nexport interface ResponseFunctionToolCall {\n  /**\n   * A JSON string of the arguments to pass to the function.\n   */\n  arguments: string;\n\n  /**\n   * The unique ID of the function tool call generated by the model.\n   */\n  call_id: string;\n\n  /**\n   * The name of the function to run.\n   */\n  name: string;\n\n  /**\n   * The type of the function tool call. Always `function_call`.\n   */\n  type: 'function_call';\n\n  /**\n   * The unique ID of the function tool call.\n   */\n  id?: string;\n\n  /**\n   * The status of the item. One of `in_progress`, `completed`, or `incomplete`.\n   * Populated when items are returned via API.\n   */\n  status?: 'in_progress' | 'completed' | 'incomplete';\n}\n\n/**\n * A tool call to run a function. See the\n * [function calling guide](https://platform.openai.com/docs/guides/function-calling)\n * for more information.\n */\nexport interface ResponseFunctionToolCallItem extends ResponseFunctionToolCall {\n  /**\n   * The unique ID of the function tool call.\n   */\n  id: string;\n}\n\nexport interface ResponseFunctionToolCallOutputItem {\n  /**\n   * The unique ID of the function call tool output.\n   */\n  id: string;\n\n  /**\n   * The unique ID of the function tool call generated by the model.\n   */\n  call_id: string;\n\n  /**\n   * The output from the function call generated by your code. Can be a string or an\n   * list of output content.\n   */\n  output: string | Array<ResponseInputText | ResponseInputImage | ResponseInputFile>;\n\n  /**\n   * The type of the function tool call output. Always `function_call_output`.\n   */\n  type: 'function_call_output';\n\n  /**\n   * The status of the item. One of `in_progress`, `completed`, or `incomplete`.\n   * Populated when items are returned via API.\n   */\n  status?: 'in_progress' | 'completed' | 'incomplete';\n}\n\n/**\n * The results of a web search tool call. See the\n * [web search guide](https://platform.openai.com/docs/guides/tools-web-search) for\n * more information.\n */\nexport interface ResponseFunctionWebSearch {\n  /**\n   * The unique ID of the web search tool call.\n   */\n  id: string;\n\n  /**\n   * The status of the web search tool call.\n   */\n  status: 'in_progress' | 'searching' | 'completed' | 'failed';\n\n  /**\n   * The type of the web search tool call. Always `web_search_call`.\n   */\n  type: 'web_search_call';\n}\n\nexport namespace ResponseFunctionWebSearch {\n  /**\n   * Action type \"search\" - Performs a web search query.\n   */\n  export interface Search {\n    /**\n     * The search query.\n     */\n    query: string;\n\n    /**\n     * The action type.\n     */\n    type: 'search';\n\n    /**\n     * The sources used in the search.\n     */\n    sources?: Array<Search.Source>;\n  }\n\n  export namespace Search {\n    /**\n     * A source used in the search.\n     */\n    export interface Source {\n      /**\n       * The type of source. Always `url`.\n       */\n      type: 'url';\n\n      /**\n       * The URL of the source.\n       */\n      url: string;\n    }\n  }\n\n  /**\n   * Action type \"open_page\" - Opens a specific URL from search results.\n   */\n  export interface OpenPage {\n    /**\n     * The action type.\n     */\n    type: 'open_page';\n\n    /**\n     * The URL opened by the model.\n     */\n    url: string;\n  }\n\n  /**\n   * Action type \"find\": Searches for a pattern within a loaded page.\n   */\n  export interface Find {\n    /**\n     * The pattern or text to search for within the page.\n     */\n    pattern: string;\n\n    /**\n     * The action type.\n     */\n    type: 'find';\n\n    /**\n     * The URL of the page searched for the pattern.\n     */\n    url: string;\n  }\n}\n\n/**\n * Emitted when an image generation tool call has completed and the final image is\n * available.\n */\nexport interface ResponseImageGenCallCompletedEvent {\n  /**\n   * The unique identifier of the image generation item being processed.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response's output array.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always 'response.image_generation_call.completed'.\n   */\n  type: 'response.image_generation_call.completed';\n}\n\n/**\n * Emitted when an image generation tool call is actively generating an image\n * (intermediate state).\n */\nexport interface ResponseImageGenCallGeneratingEvent {\n  /**\n   * The unique identifier of the image generation item being processed.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response's output array.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of the image generation item being processed.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always 'response.image_generation_call.generating'.\n   */\n  type: 'response.image_generation_call.generating';\n}\n\n/**\n * Emitted when an image generation tool call is in progress.\n */\nexport interface ResponseImageGenCallInProgressEvent {\n  /**\n   * The unique identifier of the image generation item being processed.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response's output array.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of the image generation item being processed.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always 'response.image_generation_call.in_progress'.\n   */\n  type: 'response.image_generation_call.in_progress';\n}\n\n/**\n * Emitted when a partial image is available during image generation streaming.\n */\nexport interface ResponseImageGenCallPartialImageEvent {\n  /**\n   * The unique identifier of the image generation item being processed.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response's output array.\n   */\n  output_index: number;\n\n  /**\n   * Base64-encoded partial image data, suitable for rendering as an image.\n   */\n  partial_image_b64: string;\n\n  /**\n   * 0-based index for the partial image (backend is 1-based, but this is 0-based for\n   * the user).\n   */\n  partial_image_index: number;\n\n  /**\n   * The sequence number of the image generation item being processed.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always 'response.image_generation_call.partial_image'.\n   */\n  type: 'response.image_generation_call.partial_image';\n}\n\n/**\n * Emitted when the response is in progress.\n */\nexport interface ResponseInProgressEvent {\n  /**\n   * The response that is in progress.\n   */\n  response: Response;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.in_progress`.\n   */\n  type: 'response.in_progress';\n}\n\n/**\n * Specify additional output data to include in the model response. Currently\n * supported values are:\n *\n * - `web_search_call.action.sources`: Include the sources of the web search tool\n *   call.\n * - `code_interpreter_call.outputs`: Includes the outputs of python code execution\n *   in code interpreter tool call items.\n * - `computer_call_output.output.image_url`: Include image urls from the computer\n *   call output.\n * - `file_search_call.results`: Include the search results of the file search tool\n *   call.\n * - `message.input_image.image_url`: Include image urls from the input message.\n * - `computer_call_output.output.image_url`: Include image urls from the computer\n *   call output.\n * - `reasoning.encrypted_content`: Includes an encrypted version of reasoning\n *   tokens in reasoning item outputs. This enables reasoning items to be used in\n *   multi-turn conversations when using the Responses API statelessly (like when\n *   the `store` parameter is set to `false`, or when an organization is enrolled\n *   in the zero data retention program).\n * - `code_interpreter_call.outputs`: Includes the outputs of python code execution\n *   in code interpreter tool call items.\n */\nexport type ResponseIncludable =\n  | 'file_search_call.results'\n  | 'web_search_call.results'\n  | 'web_search_call.action.sources'\n  | 'message.input_image.image_url'\n  | 'computer_call_output.output.image_url'\n  | 'code_interpreter_call.outputs'\n  | 'reasoning.encrypted_content'\n  | 'message.output_text.logprobs';\n\n/**\n * An event that is emitted when a response finishes as incomplete.\n */\nexport interface ResponseIncompleteEvent {\n  /**\n   * The response that was incomplete.\n   */\n  response: Response;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.incomplete`.\n   */\n  type: 'response.incomplete';\n}\n\n/**\n * A list of one or many input items to the model, containing different content\n * types.\n */\nexport type ResponseInput = Array<ResponseInputItem>;\n\n/**\n * An audio input to the model.\n */\nexport interface ResponseInputAudio {\n  input_audio: ResponseInputAudio.InputAudio;\n\n  /**\n   * The type of the input item. Always `input_audio`.\n   */\n  type: 'input_audio';\n}\n\nexport namespace ResponseInputAudio {\n  export interface InputAudio {\n    /**\n     * Base64-encoded audio data.\n     */\n    data: string;\n\n    /**\n     * The format of the audio data. Currently supported formats are `mp3` and `wav`.\n     */\n    format: 'mp3' | 'wav';\n  }\n}\n\n/**\n * A text input to the model.\n */\nexport type ResponseInputContent = ResponseInputText | ResponseInputImage | ResponseInputFile;\n\n/**\n * A file input to the model.\n */\nexport interface ResponseInputFile {\n  /**\n   * The type of the input item. Always `input_file`.\n   */\n  type: 'input_file';\n\n  /**\n   * The content of the file to be sent to the model.\n   */\n  file_data?: string;\n\n  /**\n   * The ID of the file to be sent to the model.\n   */\n  file_id?: string | null;\n\n  /**\n   * The URL of the file to be sent to the model.\n   */\n  file_url?: string;\n\n  /**\n   * The name of the file to be sent to the model.\n   */\n  filename?: string;\n}\n\n/**\n * A file input to the model.\n */\nexport interface ResponseInputFileContent {\n  /**\n   * The type of the input item. Always `input_file`.\n   */\n  type: 'input_file';\n\n  /**\n   * The base64-encoded data of the file to be sent to the model.\n   */\n  file_data?: string | null;\n\n  /**\n   * The ID of the file to be sent to the model.\n   */\n  file_id?: string | null;\n\n  /**\n   * The URL of the file to be sent to the model.\n   */\n  file_url?: string | null;\n\n  /**\n   * The name of the file to be sent to the model.\n   */\n  filename?: string | null;\n}\n\n/**\n * An image input to the model. Learn about\n * [image inputs](https://platform.openai.com/docs/guides/vision).\n */\nexport interface ResponseInputImage {\n  /**\n   * The detail level of the image to be sent to the model. One of `high`, `low`, or\n   * `auto`. Defaults to `auto`.\n   */\n  detail: 'low' | 'high' | 'auto';\n\n  /**\n   * The type of the input item. Always `input_image`.\n   */\n  type: 'input_image';\n\n  /**\n   * The ID of the file to be sent to the model.\n   */\n  file_id?: string | null;\n\n  /**\n   * The URL of the image to be sent to the model. A fully qualified URL or base64\n   * encoded image in a data URL.\n   */\n  image_url?: string | null;\n}\n\n/**\n * An image input to the model. Learn about\n * [image inputs](https://platform.openai.com/docs/guides/vision)\n */\nexport interface ResponseInputImageContent {\n  /**\n   * The type of the input item. Always `input_image`.\n   */\n  type: 'input_image';\n\n  /**\n   * The detail level of the image to be sent to the model. One of `high`, `low`, or\n   * `auto`. Defaults to `auto`.\n   */\n  detail?: 'low' | 'high' | 'auto' | null;\n\n  /**\n   * The ID of the file to be sent to the model.\n   */\n  file_id?: string | null;\n\n  /**\n   * The URL of the image to be sent to the model. A fully qualified URL or base64\n   * encoded image in a data URL.\n   */\n  image_url?: string | null;\n}\n\n/**\n * A message input to the model with a role indicating instruction following\n * hierarchy. Instructions given with the `developer` or `system` role take\n * precedence over instructions given with the `user` role. Messages with the\n * `assistant` role are presumed to have been generated by the model in previous\n * interactions.\n */\nexport type ResponseInputItem =\n  | EasyInputMessage\n  | ResponseInputItem.Message\n  | ResponseOutputMessage\n  | ResponseFileSearchToolCall\n  | ResponseComputerToolCall\n  | ResponseInputItem.ComputerCallOutput\n  | ResponseFunctionWebSearch\n  | ResponseFunctionToolCall\n  | ResponseInputItem.FunctionCallOutput\n  | ResponseReasoningItem\n  | ResponseInputItem.ImageGenerationCall\n  | ResponseCodeInterpreterToolCall\n  | ResponseInputItem.LocalShellCall\n  | ResponseInputItem.LocalShellCallOutput\n  | ResponseInputItem.McpListTools\n  | ResponseInputItem.McpApprovalRequest\n  | ResponseInputItem.McpApprovalResponse\n  | ResponseInputItem.McpCall\n  | ResponseCustomToolCallOutput\n  | ResponseCustomToolCall\n  | ResponseInputItem.ItemReference;\n\nexport namespace ResponseInputItem {\n  /**\n   * A message input to the model with a role indicating instruction following\n   * hierarchy. Instructions given with the `developer` or `system` role take\n   * precedence over instructions given with the `user` role.\n   */\n  export interface Message {\n    /**\n     * A list of one or many input items to the model, containing different content\n     * types.\n     */\n    content: ResponsesAPI.ResponseInputMessageContentList;\n\n    /**\n     * The role of the message input. One of `user`, `system`, or `developer`.\n     */\n    role: 'user' | 'system' | 'developer';\n\n    /**\n     * The status of item. One of `in_progress`, `completed`, or `incomplete`.\n     * Populated when items are returned via API.\n     */\n    status?: 'in_progress' | 'completed' | 'incomplete';\n\n    /**\n     * The type of the message input. Always set to `message`.\n     */\n    type?: 'message';\n  }\n\n  /**\n   * The output of a computer tool call.\n   */\n  export interface ComputerCallOutput {\n    /**\n     * The ID of the computer tool call that produced the output.\n     */\n    call_id: string;\n\n    /**\n     * A computer screenshot image used with the computer use tool.\n     */\n    output: ResponsesAPI.ResponseComputerToolCallOutputScreenshot;\n\n    /**\n     * The type of the computer tool call output. Always `computer_call_output`.\n     */\n    type: 'computer_call_output';\n\n    /**\n     * The ID of the computer tool call output.\n     */\n    id?: string | null;\n\n    /**\n     * The safety checks reported by the API that have been acknowledged by the\n     * developer.\n     */\n    acknowledged_safety_checks?: Array<ComputerCallOutput.AcknowledgedSafetyCheck> | null;\n\n    /**\n     * The status of the message input. One of `in_progress`, `completed`, or\n     * `incomplete`. Populated when input items are returned via API.\n     */\n    status?: 'in_progress' | 'completed' | 'incomplete' | null;\n  }\n\n  export namespace ComputerCallOutput {\n    /**\n     * A pending safety check for the computer call.\n     */\n    export interface AcknowledgedSafetyCheck {\n      /**\n       * The ID of the pending safety check.\n       */\n      id: string;\n\n      /**\n       * The type of the pending safety check.\n       */\n      code?: string | null;\n\n      /**\n       * Details about the pending safety check.\n       */\n      message?: string | null;\n    }\n  }\n\n  /**\n   * The output of a function tool call.\n   */\n  export interface FunctionCallOutput {\n    /**\n     * The unique ID of the function tool call generated by the model.\n     */\n    call_id: string;\n\n    /**\n     * Text, image, or file output of the function tool call.\n     */\n    output: string | ResponsesAPI.ResponseFunctionCallOutputItemList;\n\n    /**\n     * The type of the function tool call output. Always `function_call_output`.\n     */\n    type: 'function_call_output';\n\n    /**\n     * The unique ID of the function tool call output. Populated when this item is\n     * returned via API.\n     */\n    id?: string | null;\n\n    /**\n     * The status of the item. One of `in_progress`, `completed`, or `incomplete`.\n     * Populated when items are returned via API.\n     */\n    status?: 'in_progress' | 'completed' | 'incomplete' | null;\n  }\n\n  /**\n   * An image generation request made by the model.\n   */\n  export interface ImageGenerationCall {\n    /**\n     * The unique ID of the image generation call.\n     */\n    id: string;\n\n    /**\n     * The generated image encoded in base64.\n     */\n    result: string | null;\n\n    /**\n     * The status of the image generation call.\n     */\n    status: 'in_progress' | 'completed' | 'generating' | 'failed';\n\n    /**\n     * The type of the image generation call. Always `image_generation_call`.\n     */\n    type: 'image_generation_call';\n  }\n\n  /**\n   * A tool call to run a command on the local shell.\n   */\n  export interface LocalShellCall {\n    /**\n     * The unique ID of the local shell call.\n     */\n    id: string;\n\n    /**\n     * Execute a shell command on the server.\n     */\n    action: LocalShellCall.Action;\n\n    /**\n     * The unique ID of the local shell tool call generated by the model.\n     */\n    call_id: string;\n\n    /**\n     * The status of the local shell call.\n     */\n    status: 'in_progress' | 'completed' | 'incomplete';\n\n    /**\n     * The type of the local shell call. Always `local_shell_call`.\n     */\n    type: 'local_shell_call';\n  }\n\n  export namespace LocalShellCall {\n    /**\n     * Execute a shell command on the server.\n     */\n    export interface Action {\n      /**\n       * The command to run.\n       */\n      command: Array<string>;\n\n      /**\n       * Environment variables to set for the command.\n       */\n      env: { [key: string]: string };\n\n      /**\n       * The type of the local shell action. Always `exec`.\n       */\n      type: 'exec';\n\n      /**\n       * Optional timeout in milliseconds for the command.\n       */\n      timeout_ms?: number | null;\n\n      /**\n       * Optional user to run the command as.\n       */\n      user?: string | null;\n\n      /**\n       * Optional working directory to run the command in.\n       */\n      working_directory?: string | null;\n    }\n  }\n\n  /**\n   * The output of a local shell tool call.\n   */\n  export interface LocalShellCallOutput {\n    /**\n     * The unique ID of the local shell tool call generated by the model.\n     */\n    id: string;\n\n    /**\n     * A JSON string of the output of the local shell tool call.\n     */\n    output: string;\n\n    /**\n     * The type of the local shell tool call output. Always `local_shell_call_output`.\n     */\n    type: 'local_shell_call_output';\n\n    /**\n     * The status of the item. One of `in_progress`, `completed`, or `incomplete`.\n     */\n    status?: 'in_progress' | 'completed' | 'incomplete' | null;\n  }\n\n  /**\n   * A list of tools available on an MCP server.\n   */\n  export interface McpListTools {\n    /**\n     * The unique ID of the list.\n     */\n    id: string;\n\n    /**\n     * The label of the MCP server.\n     */\n    server_label: string;\n\n    /**\n     * The tools available on the server.\n     */\n    tools: Array<McpListTools.Tool>;\n\n    /**\n     * The type of the item. Always `mcp_list_tools`.\n     */\n    type: 'mcp_list_tools';\n\n    /**\n     * Error message if the server could not list tools.\n     */\n    error?: string | null;\n  }\n\n  export namespace McpListTools {\n    /**\n     * A tool available on an MCP server.\n     */\n    export interface Tool {\n      /**\n       * The JSON schema describing the tool's input.\n       */\n      input_schema: unknown;\n\n      /**\n       * The name of the tool.\n       */\n      name: string;\n\n      /**\n       * Additional annotations about the tool.\n       */\n      annotations?: unknown | null;\n\n      /**\n       * The description of the tool.\n       */\n      description?: string | null;\n    }\n  }\n\n  /**\n   * A request for human approval of a tool invocation.\n   */\n  export interface McpApprovalRequest {\n    /**\n     * The unique ID of the approval request.\n     */\n    id: string;\n\n    /**\n     * A JSON string of arguments for the tool.\n     */\n    arguments: string;\n\n    /**\n     * The name of the tool to run.\n     */\n    name: string;\n\n    /**\n     * The label of the MCP server making the request.\n     */\n    server_label: string;\n\n    /**\n     * The type of the item. Always `mcp_approval_request`.\n     */\n    type: 'mcp_approval_request';\n  }\n\n  /**\n   * A response to an MCP approval request.\n   */\n  export interface McpApprovalResponse {\n    /**\n     * The ID of the approval request being answered.\n     */\n    approval_request_id: string;\n\n    /**\n     * Whether the request was approved.\n     */\n    approve: boolean;\n\n    /**\n     * The type of the item. Always `mcp_approval_response`.\n     */\n    type: 'mcp_approval_response';\n\n    /**\n     * The unique ID of the approval response\n     */\n    id?: string | null;\n\n    /**\n     * Optional reason for the decision.\n     */\n    reason?: string | null;\n  }\n\n  /**\n   * An invocation of a tool on an MCP server.\n   */\n  export interface McpCall {\n    /**\n     * The unique ID of the tool call.\n     */\n    id: string;\n\n    /**\n     * A JSON string of the arguments passed to the tool.\n     */\n    arguments: string;\n\n    /**\n     * The name of the tool that was run.\n     */\n    name: string;\n\n    /**\n     * The label of the MCP server running the tool.\n     */\n    server_label: string;\n\n    /**\n     * The type of the item. Always `mcp_call`.\n     */\n    type: 'mcp_call';\n\n    /**\n     * Unique identifier for the MCP tool call approval request. Include this value in\n     * a subsequent `mcp_approval_response` input to approve or reject the\n     * corresponding tool call.\n     */\n    approval_request_id?: string | null;\n\n    /**\n     * The error from the tool call, if any.\n     */\n    error?: string | null;\n\n    /**\n     * The output from the tool call.\n     */\n    output?: string | null;\n\n    /**\n     * The status of the tool call. One of `in_progress`, `completed`, `incomplete`,\n     * `calling`, or `failed`.\n     */\n    status?: 'in_progress' | 'completed' | 'incomplete' | 'calling' | 'failed';\n  }\n\n  /**\n   * An internal identifier for an item to reference.\n   */\n  export interface ItemReference {\n    /**\n     * The ID of the item to reference.\n     */\n    id: string;\n\n    /**\n     * The type of item to reference. Always `item_reference`.\n     */\n    type?: 'item_reference' | null;\n  }\n}\n\n/**\n * A list of one or many input items to the model, containing different content\n * types.\n */\nexport type ResponseInputMessageContentList = Array<ResponseInputContent>;\n\nexport interface ResponseInputMessageItem {\n  /**\n   * The unique ID of the message input.\n   */\n  id: string;\n\n  /**\n   * A list of one or many input items to the model, containing different content\n   * types.\n   */\n  content: ResponseInputMessageContentList;\n\n  /**\n   * The role of the message input. One of `user`, `system`, or `developer`.\n   */\n  role: 'user' | 'system' | 'developer';\n\n  /**\n   * The status of item. One of `in_progress`, `completed`, or `incomplete`.\n   * Populated when items are returned via API.\n   */\n  status?: 'in_progress' | 'completed' | 'incomplete';\n\n  /**\n   * The type of the message input. Always set to `message`.\n   */\n  type?: 'message';\n}\n\n/**\n * A text input to the model.\n */\nexport interface ResponseInputText {\n  /**\n   * The text input to the model.\n   */\n  text: string;\n\n  /**\n   * The type of the input item. Always `input_text`.\n   */\n  type: 'input_text';\n}\n\n/**\n * A text input to the model.\n */\nexport interface ResponseInputTextContent {\n  /**\n   * The text input to the model.\n   */\n  text: string;\n\n  /**\n   * The type of the input item. Always `input_text`.\n   */\n  type: 'input_text';\n}\n\n/**\n * Content item used to generate a response.\n */\nexport type ResponseItem =\n  | ResponseInputMessageItem\n  | ResponseOutputMessage\n  | ResponseFileSearchToolCall\n  | ResponseComputerToolCall\n  | ResponseComputerToolCallOutputItem\n  | ResponseFunctionWebSearch\n  | ResponseFunctionToolCallItem\n  | ResponseFunctionToolCallOutputItem\n  | ResponseItem.ImageGenerationCall\n  | ResponseCodeInterpreterToolCall\n  | ResponseItem.LocalShellCall\n  | ResponseItem.LocalShellCallOutput\n  | ResponseItem.McpListTools\n  | ResponseItem.McpApprovalRequest\n  | ResponseItem.McpApprovalResponse\n  | ResponseItem.McpCall;\n\nexport namespace ResponseItem {\n  /**\n   * An image generation request made by the model.\n   */\n  export interface ImageGenerationCall {\n    /**\n     * The unique ID of the image generation call.\n     */\n    id: string;\n\n    /**\n     * The generated image encoded in base64.\n     */\n    result: string | null;\n\n    /**\n     * The status of the image generation call.\n     */\n    status: 'in_progress' | 'completed' | 'generating' | 'failed';\n\n    /**\n     * The type of the image generation call. Always `image_generation_call`.\n     */\n    type: 'image_generation_call';\n  }\n\n  /**\n   * A tool call to run a command on the local shell.\n   */\n  export interface LocalShellCall {\n    /**\n     * The unique ID of the local shell call.\n     */\n    id: string;\n\n    /**\n     * Execute a shell command on the server.\n     */\n    action: LocalShellCall.Action;\n\n    /**\n     * The unique ID of the local shell tool call generated by the model.\n     */\n    call_id: string;\n\n    /**\n     * The status of the local shell call.\n     */\n    status: 'in_progress' | 'completed' | 'incomplete';\n\n    /**\n     * The type of the local shell call. Always `local_shell_call`.\n     */\n    type: 'local_shell_call';\n  }\n\n  export namespace LocalShellCall {\n    /**\n     * Execute a shell command on the server.\n     */\n    export interface Action {\n      /**\n       * The command to run.\n       */\n      command: Array<string>;\n\n      /**\n       * Environment variables to set for the command.\n       */\n      env: { [key: string]: string };\n\n      /**\n       * The type of the local shell action. Always `exec`.\n       */\n      type: 'exec';\n\n      /**\n       * Optional timeout in milliseconds for the command.\n       */\n      timeout_ms?: number | null;\n\n      /**\n       * Optional user to run the command as.\n       */\n      user?: string | null;\n\n      /**\n       * Optional working directory to run the command in.\n       */\n      working_directory?: string | null;\n    }\n  }\n\n  /**\n   * The output of a local shell tool call.\n   */\n  export interface LocalShellCallOutput {\n    /**\n     * The unique ID of the local shell tool call generated by the model.\n     */\n    id: string;\n\n    /**\n     * A JSON string of the output of the local shell tool call.\n     */\n    output: string;\n\n    /**\n     * The type of the local shell tool call output. Always `local_shell_call_output`.\n     */\n    type: 'local_shell_call_output';\n\n    /**\n     * The status of the item. One of `in_progress`, `completed`, or `incomplete`.\n     */\n    status?: 'in_progress' | 'completed' | 'incomplete' | null;\n  }\n\n  /**\n   * A list of tools available on an MCP server.\n   */\n  export interface McpListTools {\n    /**\n     * The unique ID of the list.\n     */\n    id: string;\n\n    /**\n     * The label of the MCP server.\n     */\n    server_label: string;\n\n    /**\n     * The tools available on the server.\n     */\n    tools: Array<McpListTools.Tool>;\n\n    /**\n     * The type of the item. Always `mcp_list_tools`.\n     */\n    type: 'mcp_list_tools';\n\n    /**\n     * Error message if the server could not list tools.\n     */\n    error?: string | null;\n  }\n\n  export namespace McpListTools {\n    /**\n     * A tool available on an MCP server.\n     */\n    export interface Tool {\n      /**\n       * The JSON schema describing the tool's input.\n       */\n      input_schema: unknown;\n\n      /**\n       * The name of the tool.\n       */\n      name: string;\n\n      /**\n       * Additional annotations about the tool.\n       */\n      annotations?: unknown | null;\n\n      /**\n       * The description of the tool.\n       */\n      description?: string | null;\n    }\n  }\n\n  /**\n   * A request for human approval of a tool invocation.\n   */\n  export interface McpApprovalRequest {\n    /**\n     * The unique ID of the approval request.\n     */\n    id: string;\n\n    /**\n     * A JSON string of arguments for the tool.\n     */\n    arguments: string;\n\n    /**\n     * The name of the tool to run.\n     */\n    name: string;\n\n    /**\n     * The label of the MCP server making the request.\n     */\n    server_label: string;\n\n    /**\n     * The type of the item. Always `mcp_approval_request`.\n     */\n    type: 'mcp_approval_request';\n  }\n\n  /**\n   * A response to an MCP approval request.\n   */\n  export interface McpApprovalResponse {\n    /**\n     * The unique ID of the approval response\n     */\n    id: string;\n\n    /**\n     * The ID of the approval request being answered.\n     */\n    approval_request_id: string;\n\n    /**\n     * Whether the request was approved.\n     */\n    approve: boolean;\n\n    /**\n     * The type of the item. Always `mcp_approval_response`.\n     */\n    type: 'mcp_approval_response';\n\n    /**\n     * Optional reason for the decision.\n     */\n    reason?: string | null;\n  }\n\n  /**\n   * An invocation of a tool on an MCP server.\n   */\n  export interface McpCall {\n    /**\n     * The unique ID of the tool call.\n     */\n    id: string;\n\n    /**\n     * A JSON string of the arguments passed to the tool.\n     */\n    arguments: string;\n\n    /**\n     * The name of the tool that was run.\n     */\n    name: string;\n\n    /**\n     * The label of the MCP server running the tool.\n     */\n    server_label: string;\n\n    /**\n     * The type of the item. Always `mcp_call`.\n     */\n    type: 'mcp_call';\n\n    /**\n     * Unique identifier for the MCP tool call approval request. Include this value in\n     * a subsequent `mcp_approval_response` input to approve or reject the\n     * corresponding tool call.\n     */\n    approval_request_id?: string | null;\n\n    /**\n     * The error from the tool call, if any.\n     */\n    error?: string | null;\n\n    /**\n     * The output from the tool call.\n     */\n    output?: string | null;\n\n    /**\n     * The status of the tool call. One of `in_progress`, `completed`, `incomplete`,\n     * `calling`, or `failed`.\n     */\n    status?: 'in_progress' | 'completed' | 'incomplete' | 'calling' | 'failed';\n  }\n}\n\n/**\n * Emitted when there is a delta (partial update) to the arguments of an MCP tool\n * call.\n */\nexport interface ResponseMcpCallArgumentsDeltaEvent {\n  /**\n   * A JSON string containing the partial update to the arguments for the MCP tool\n   * call.\n   */\n  delta: string;\n\n  /**\n   * The unique identifier of the MCP tool call item being processed.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response's output array.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always 'response.mcp_call_arguments.delta'.\n   */\n  type: 'response.mcp_call_arguments.delta';\n}\n\n/**\n * Emitted when the arguments for an MCP tool call are finalized.\n */\nexport interface ResponseMcpCallArgumentsDoneEvent {\n  /**\n   * A JSON string containing the finalized arguments for the MCP tool call.\n   */\n  arguments: string;\n\n  /**\n   * The unique identifier of the MCP tool call item being processed.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response's output array.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always 'response.mcp_call_arguments.done'.\n   */\n  type: 'response.mcp_call_arguments.done';\n}\n\n/**\n * Emitted when an MCP tool call has completed successfully.\n */\nexport interface ResponseMcpCallCompletedEvent {\n  /**\n   * The ID of the MCP tool call item that completed.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that completed.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always 'response.mcp_call.completed'.\n   */\n  type: 'response.mcp_call.completed';\n}\n\n/**\n * Emitted when an MCP tool call has failed.\n */\nexport interface ResponseMcpCallFailedEvent {\n  /**\n   * The ID of the MCP tool call item that failed.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that failed.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always 'response.mcp_call.failed'.\n   */\n  type: 'response.mcp_call.failed';\n}\n\n/**\n * Emitted when an MCP tool call is in progress.\n */\nexport interface ResponseMcpCallInProgressEvent {\n  /**\n   * The unique identifier of the MCP tool call item being processed.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response's output array.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always 'response.mcp_call.in_progress'.\n   */\n  type: 'response.mcp_call.in_progress';\n}\n\n/**\n * Emitted when the list of available MCP tools has been successfully retrieved.\n */\nexport interface ResponseMcpListToolsCompletedEvent {\n  /**\n   * The ID of the MCP tool call item that produced this output.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that was processed.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always 'response.mcp_list_tools.completed'.\n   */\n  type: 'response.mcp_list_tools.completed';\n}\n\n/**\n * Emitted when the attempt to list available MCP tools has failed.\n */\nexport interface ResponseMcpListToolsFailedEvent {\n  /**\n   * The ID of the MCP tool call item that failed.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that failed.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always 'response.mcp_list_tools.failed'.\n   */\n  type: 'response.mcp_list_tools.failed';\n}\n\n/**\n * Emitted when the system is in the process of retrieving the list of available\n * MCP tools.\n */\nexport interface ResponseMcpListToolsInProgressEvent {\n  /**\n   * The ID of the MCP tool call item that is being processed.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that is being processed.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always 'response.mcp_list_tools.in_progress'.\n   */\n  type: 'response.mcp_list_tools.in_progress';\n}\n\n/**\n * An audio output from the model.\n */\nexport interface ResponseOutputAudio {\n  /**\n   * Base64-encoded audio data from the model.\n   */\n  data: string;\n\n  /**\n   * The transcript of the audio data from the model.\n   */\n  transcript: string;\n\n  /**\n   * The type of the output audio. Always `output_audio`.\n   */\n  type: 'output_audio';\n}\n\n/**\n * An output message from the model.\n */\nexport type ResponseOutputItem =\n  | ResponseOutputMessage\n  | ResponseFileSearchToolCall\n  | ResponseFunctionToolCall\n  | ResponseFunctionWebSearch\n  | ResponseComputerToolCall\n  | ResponseReasoningItem\n  | ResponseOutputItem.ImageGenerationCall\n  | ResponseCodeInterpreterToolCall\n  | ResponseOutputItem.LocalShellCall\n  | ResponseOutputItem.McpCall\n  | ResponseOutputItem.McpListTools\n  | ResponseOutputItem.McpApprovalRequest\n  | ResponseCustomToolCall;\n\nexport namespace ResponseOutputItem {\n  /**\n   * An image generation request made by the model.\n   */\n  export interface ImageGenerationCall {\n    /**\n     * The unique ID of the image generation call.\n     */\n    id: string;\n\n    /**\n     * The generated image encoded in base64.\n     */\n    result: string | null;\n\n    /**\n     * The status of the image generation call.\n     */\n    status: 'in_progress' | 'completed' | 'generating' | 'failed';\n\n    /**\n     * The type of the image generation call. Always `image_generation_call`.\n     */\n    type: 'image_generation_call';\n  }\n\n  /**\n   * A tool call to run a command on the local shell.\n   */\n  export interface LocalShellCall {\n    /**\n     * The unique ID of the local shell call.\n     */\n    id: string;\n\n    /**\n     * Execute a shell command on the server.\n     */\n    action: LocalShellCall.Action;\n\n    /**\n     * The unique ID of the local shell tool call generated by the model.\n     */\n    call_id: string;\n\n    /**\n     * The status of the local shell call.\n     */\n    status: 'in_progress' | 'completed' | 'incomplete';\n\n    /**\n     * The type of the local shell call. Always `local_shell_call`.\n     */\n    type: 'local_shell_call';\n  }\n\n  export namespace LocalShellCall {\n    /**\n     * Execute a shell command on the server.\n     */\n    export interface Action {\n      /**\n       * The command to run.\n       */\n      command: Array<string>;\n\n      /**\n       * Environment variables to set for the command.\n       */\n      env: { [key: string]: string };\n\n      /**\n       * The type of the local shell action. Always `exec`.\n       */\n      type: 'exec';\n\n      /**\n       * Optional timeout in milliseconds for the command.\n       */\n      timeout_ms?: number | null;\n\n      /**\n       * Optional user to run the command as.\n       */\n      user?: string | null;\n\n      /**\n       * Optional working directory to run the command in.\n       */\n      working_directory?: string | null;\n    }\n  }\n\n  /**\n   * An invocation of a tool on an MCP server.\n   */\n  export interface McpCall {\n    /**\n     * The unique ID of the tool call.\n     */\n    id: string;\n\n    /**\n     * A JSON string of the arguments passed to the tool.\n     */\n    arguments: string;\n\n    /**\n     * The name of the tool that was run.\n     */\n    name: string;\n\n    /**\n     * The label of the MCP server running the tool.\n     */\n    server_label: string;\n\n    /**\n     * The type of the item. Always `mcp_call`.\n     */\n    type: 'mcp_call';\n\n    /**\n     * Unique identifier for the MCP tool call approval request. Include this value in\n     * a subsequent `mcp_approval_response` input to approve or reject the\n     * corresponding tool call.\n     */\n    approval_request_id?: string | null;\n\n    /**\n     * The error from the tool call, if any.\n     */\n    error?: string | null;\n\n    /**\n     * The output from the tool call.\n     */\n    output?: string | null;\n\n    /**\n     * The status of the tool call. One of `in_progress`, `completed`, `incomplete`,\n     * `calling`, or `failed`.\n     */\n    status?: 'in_progress' | 'completed' | 'incomplete' | 'calling' | 'failed';\n  }\n\n  /**\n   * A list of tools available on an MCP server.\n   */\n  export interface McpListTools {\n    /**\n     * The unique ID of the list.\n     */\n    id: string;\n\n    /**\n     * The label of the MCP server.\n     */\n    server_label: string;\n\n    /**\n     * The tools available on the server.\n     */\n    tools: Array<McpListTools.Tool>;\n\n    /**\n     * The type of the item. Always `mcp_list_tools`.\n     */\n    type: 'mcp_list_tools';\n\n    /**\n     * Error message if the server could not list tools.\n     */\n    error?: string | null;\n  }\n\n  export namespace McpListTools {\n    /**\n     * A tool available on an MCP server.\n     */\n    export interface Tool {\n      /**\n       * The JSON schema describing the tool's input.\n       */\n      input_schema: unknown;\n\n      /**\n       * The name of the tool.\n       */\n      name: string;\n\n      /**\n       * Additional annotations about the tool.\n       */\n      annotations?: unknown | null;\n\n      /**\n       * The description of the tool.\n       */\n      description?: string | null;\n    }\n  }\n\n  /**\n   * A request for human approval of a tool invocation.\n   */\n  export interface McpApprovalRequest {\n    /**\n     * The unique ID of the approval request.\n     */\n    id: string;\n\n    /**\n     * A JSON string of arguments for the tool.\n     */\n    arguments: string;\n\n    /**\n     * The name of the tool to run.\n     */\n    name: string;\n\n    /**\n     * The label of the MCP server making the request.\n     */\n    server_label: string;\n\n    /**\n     * The type of the item. Always `mcp_approval_request`.\n     */\n    type: 'mcp_approval_request';\n  }\n}\n\n/**\n * Emitted when a new output item is added.\n */\nexport interface ResponseOutputItemAddedEvent {\n  /**\n   * The output item that was added.\n   */\n  item: ResponseOutputItem;\n\n  /**\n   * The index of the output item that was added.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.output_item.added`.\n   */\n  type: 'response.output_item.added';\n}\n\n/**\n * Emitted when an output item is marked done.\n */\nexport interface ResponseOutputItemDoneEvent {\n  /**\n   * The output item that was marked done.\n   */\n  item: ResponseOutputItem;\n\n  /**\n   * The index of the output item that was marked done.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.output_item.done`.\n   */\n  type: 'response.output_item.done';\n}\n\n/**\n * An output message from the model.\n */\nexport interface ResponseOutputMessage {\n  /**\n   * The unique ID of the output message.\n   */\n  id: string;\n\n  /**\n   * The content of the output message.\n   */\n  content: Array<ResponseOutputText | ResponseOutputRefusal>;\n\n  /**\n   * The role of the output message. Always `assistant`.\n   */\n  role: 'assistant';\n\n  /**\n   * The status of the message input. One of `in_progress`, `completed`, or\n   * `incomplete`. Populated when input items are returned via API.\n   */\n  status: 'in_progress' | 'completed' | 'incomplete';\n\n  /**\n   * The type of the output message. Always `message`.\n   */\n  type: 'message';\n}\n\n/**\n * A refusal from the model.\n */\nexport interface ResponseOutputRefusal {\n  /**\n   * The refusal explanation from the model.\n   */\n  refusal: string;\n\n  /**\n   * The type of the refusal. Always `refusal`.\n   */\n  type: 'refusal';\n}\n\n/**\n * A text output from the model.\n */\nexport interface ResponseOutputText {\n  /**\n   * The annotations of the text output.\n   */\n  annotations: Array<\n    | ResponseOutputText.FileCitation\n    | ResponseOutputText.URLCitation\n    | ResponseOutputText.ContainerFileCitation\n    | ResponseOutputText.FilePath\n  >;\n\n  /**\n   * The text output from the model.\n   */\n  text: string;\n\n  /**\n   * The type of the output text. Always `output_text`.\n   */\n  type: 'output_text';\n\n  logprobs?: Array<ResponseOutputText.Logprob>;\n}\n\nexport namespace ResponseOutputText {\n  /**\n   * A citation to a file.\n   */\n  export interface FileCitation {\n    /**\n     * The ID of the file.\n     */\n    file_id: string;\n\n    /**\n     * The filename of the file cited.\n     */\n    filename: string;\n\n    /**\n     * The index of the file in the list of files.\n     */\n    index: number;\n\n    /**\n     * The type of the file citation. Always `file_citation`.\n     */\n    type: 'file_citation';\n  }\n\n  /**\n   * A citation for a web resource used to generate a model response.\n   */\n  export interface URLCitation {\n    /**\n     * The index of the last character of the URL citation in the message.\n     */\n    end_index: number;\n\n    /**\n     * The index of the first character of the URL citation in the message.\n     */\n    start_index: number;\n\n    /**\n     * The title of the web resource.\n     */\n    title: string;\n\n    /**\n     * The type of the URL citation. Always `url_citation`.\n     */\n    type: 'url_citation';\n\n    /**\n     * The URL of the web resource.\n     */\n    url: string;\n  }\n\n  /**\n   * A citation for a container file used to generate a model response.\n   */\n  export interface ContainerFileCitation {\n    /**\n     * The ID of the container file.\n     */\n    container_id: string;\n\n    /**\n     * The index of the last character of the container file citation in the message.\n     */\n    end_index: number;\n\n    /**\n     * The ID of the file.\n     */\n    file_id: string;\n\n    /**\n     * The filename of the container file cited.\n     */\n    filename: string;\n\n    /**\n     * The index of the first character of the container file citation in the message.\n     */\n    start_index: number;\n\n    /**\n     * The type of the container file citation. Always `container_file_citation`.\n     */\n    type: 'container_file_citation';\n  }\n\n  /**\n   * A path to a file.\n   */\n  export interface FilePath {\n    /**\n     * The ID of the file.\n     */\n    file_id: string;\n\n    /**\n     * The index of the file in the list of files.\n     */\n    index: number;\n\n    /**\n     * The type of the file path. Always `file_path`.\n     */\n    type: 'file_path';\n  }\n\n  /**\n   * The log probability of a token.\n   */\n  export interface Logprob {\n    token: string;\n\n    bytes: Array<number>;\n\n    logprob: number;\n\n    top_logprobs: Array<Logprob.TopLogprob>;\n  }\n\n  export namespace Logprob {\n    /**\n     * The top log probability of a token.\n     */\n    export interface TopLogprob {\n      token: string;\n\n      bytes: Array<number>;\n\n      logprob: number;\n    }\n  }\n}\n\n/**\n * Emitted when an annotation is added to output text content.\n */\nexport interface ResponseOutputTextAnnotationAddedEvent {\n  /**\n   * The annotation object being added. (See annotation schema for details.)\n   */\n  annotation: unknown;\n\n  /**\n   * The index of the annotation within the content part.\n   */\n  annotation_index: number;\n\n  /**\n   * The index of the content part within the output item.\n   */\n  content_index: number;\n\n  /**\n   * The unique identifier of the item to which the annotation is being added.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response's output array.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always 'response.output_text.annotation.added'.\n   */\n  type: 'response.output_text.annotation.added';\n}\n\n/**\n * Reference to a prompt template and its variables.\n * [Learn more](https://platform.openai.com/docs/guides/text?api-mode=responses#reusable-prompts).\n */\nexport interface ResponsePrompt {\n  /**\n   * The unique identifier of the prompt template to use.\n   */\n  id: string;\n\n  /**\n   * Optional map of values to substitute in for variables in your prompt. The\n   * substitution values can either be strings, or other Response input types like\n   * images or files.\n   */\n  variables?: { [key: string]: string | ResponseInputText | ResponseInputImage | ResponseInputFile } | null;\n\n  /**\n   * Optional version of the prompt template.\n   */\n  version?: string | null;\n}\n\n/**\n * Emitted when a response is queued and waiting to be processed.\n */\nexport interface ResponseQueuedEvent {\n  /**\n   * The full response object that is queued.\n   */\n  response: Response;\n\n  /**\n   * The sequence number for this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always 'response.queued'.\n   */\n  type: 'response.queued';\n}\n\n/**\n * A description of the chain of thought used by a reasoning model while generating\n * a response. Be sure to include these items in your `input` to the Responses API\n * for subsequent turns of a conversation if you are manually\n * [managing context](https://platform.openai.com/docs/guides/conversation-state).\n */\nexport interface ResponseReasoningItem {\n  /**\n   * The unique identifier of the reasoning content.\n   */\n  id: string;\n\n  /**\n   * Reasoning summary content.\n   */\n  summary: Array<ResponseReasoningItem.Summary>;\n\n  /**\n   * The type of the object. Always `reasoning`.\n   */\n  type: 'reasoning';\n\n  /**\n   * Reasoning text content.\n   */\n  content?: Array<ResponseReasoningItem.Content>;\n\n  /**\n   * The encrypted content of the reasoning item - populated when a response is\n   * generated with `reasoning.encrypted_content` in the `include` parameter.\n   */\n  encrypted_content?: string | null;\n\n  /**\n   * The status of the item. One of `in_progress`, `completed`, or `incomplete`.\n   * Populated when items are returned via API.\n   */\n  status?: 'in_progress' | 'completed' | 'incomplete';\n}\n\nexport namespace ResponseReasoningItem {\n  /**\n   * A summary text from the model.\n   */\n  export interface Summary {\n    /**\n     * A summary of the reasoning output from the model so far.\n     */\n    text: string;\n\n    /**\n     * The type of the object. Always `summary_text`.\n     */\n    type: 'summary_text';\n  }\n\n  /**\n   * Reasoning text from the model.\n   */\n  export interface Content {\n    /**\n     * The reasoning text from the model.\n     */\n    text: string;\n\n    /**\n     * The type of the reasoning text. Always `reasoning_text`.\n     */\n    type: 'reasoning_text';\n  }\n}\n\n/**\n * Emitted when a new reasoning summary part is added.\n */\nexport interface ResponseReasoningSummaryPartAddedEvent {\n  /**\n   * The ID of the item this summary part is associated with.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item this summary part is associated with.\n   */\n  output_index: number;\n\n  /**\n   * The summary part that was added.\n   */\n  part: ResponseReasoningSummaryPartAddedEvent.Part;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The index of the summary part within the reasoning summary.\n   */\n  summary_index: number;\n\n  /**\n   * The type of the event. Always `response.reasoning_summary_part.added`.\n   */\n  type: 'response.reasoning_summary_part.added';\n}\n\nexport namespace ResponseReasoningSummaryPartAddedEvent {\n  /**\n   * The summary part that was added.\n   */\n  export interface Part {\n    /**\n     * The text of the summary part.\n     */\n    text: string;\n\n    /**\n     * The type of the summary part. Always `summary_text`.\n     */\n    type: 'summary_text';\n  }\n}\n\n/**\n * Emitted when a reasoning summary part is completed.\n */\nexport interface ResponseReasoningSummaryPartDoneEvent {\n  /**\n   * The ID of the item this summary part is associated with.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item this summary part is associated with.\n   */\n  output_index: number;\n\n  /**\n   * The completed summary part.\n   */\n  part: ResponseReasoningSummaryPartDoneEvent.Part;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The index of the summary part within the reasoning summary.\n   */\n  summary_index: number;\n\n  /**\n   * The type of the event. Always `response.reasoning_summary_part.done`.\n   */\n  type: 'response.reasoning_summary_part.done';\n}\n\nexport namespace ResponseReasoningSummaryPartDoneEvent {\n  /**\n   * The completed summary part.\n   */\n  export interface Part {\n    /**\n     * The text of the summary part.\n     */\n    text: string;\n\n    /**\n     * The type of the summary part. Always `summary_text`.\n     */\n    type: 'summary_text';\n  }\n}\n\n/**\n * Emitted when a delta is added to a reasoning summary text.\n */\nexport interface ResponseReasoningSummaryTextDeltaEvent {\n  /**\n   * The text delta that was added to the summary.\n   */\n  delta: string;\n\n  /**\n   * The ID of the item this summary text delta is associated with.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item this summary text delta is associated with.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The index of the summary part within the reasoning summary.\n   */\n  summary_index: number;\n\n  /**\n   * The type of the event. Always `response.reasoning_summary_text.delta`.\n   */\n  type: 'response.reasoning_summary_text.delta';\n}\n\n/**\n * Emitted when a reasoning summary text is completed.\n */\nexport interface ResponseReasoningSummaryTextDoneEvent {\n  /**\n   * The ID of the item this summary text is associated with.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item this summary text is associated with.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The index of the summary part within the reasoning summary.\n   */\n  summary_index: number;\n\n  /**\n   * The full text of the completed reasoning summary.\n   */\n  text: string;\n\n  /**\n   * The type of the event. Always `response.reasoning_summary_text.done`.\n   */\n  type: 'response.reasoning_summary_text.done';\n}\n\n/**\n * Emitted when a delta is added to a reasoning text.\n */\nexport interface ResponseReasoningTextDeltaEvent {\n  /**\n   * The index of the reasoning content part this delta is associated with.\n   */\n  content_index: number;\n\n  /**\n   * The text delta that was added to the reasoning content.\n   */\n  delta: string;\n\n  /**\n   * The ID of the item this reasoning text delta is associated with.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item this reasoning text delta is associated with.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.reasoning_text.delta`.\n   */\n  type: 'response.reasoning_text.delta';\n}\n\n/**\n * Emitted when a reasoning text is completed.\n */\nexport interface ResponseReasoningTextDoneEvent {\n  /**\n   * The index of the reasoning content part.\n   */\n  content_index: number;\n\n  /**\n   * The ID of the item this reasoning text is associated with.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item this reasoning text is associated with.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The full text of the completed reasoning content.\n   */\n  text: string;\n\n  /**\n   * The type of the event. Always `response.reasoning_text.done`.\n   */\n  type: 'response.reasoning_text.done';\n}\n\n/**\n * Emitted when there is a partial refusal text.\n */\nexport interface ResponseRefusalDeltaEvent {\n  /**\n   * The index of the content part that the refusal text is added to.\n   */\n  content_index: number;\n\n  /**\n   * The refusal text that is added.\n   */\n  delta: string;\n\n  /**\n   * The ID of the output item that the refusal text is added to.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the refusal text is added to.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.refusal.delta`.\n   */\n  type: 'response.refusal.delta';\n}\n\n/**\n * Emitted when refusal text is finalized.\n */\nexport interface ResponseRefusalDoneEvent {\n  /**\n   * The index of the content part that the refusal text is finalized.\n   */\n  content_index: number;\n\n  /**\n   * The ID of the output item that the refusal text is finalized.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the refusal text is finalized.\n   */\n  output_index: number;\n\n  /**\n   * The refusal text that is finalized.\n   */\n  refusal: string;\n\n  /**\n   * The sequence number of this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.refusal.done`.\n   */\n  type: 'response.refusal.done';\n}\n\n/**\n * The status of the response generation. One of `completed`, `failed`,\n * `in_progress`, `cancelled`, `queued`, or `incomplete`.\n */\nexport type ResponseStatus = 'completed' | 'failed' | 'in_progress' | 'cancelled' | 'queued' | 'incomplete';\n\n/**\n * Emitted when there is a partial audio response.\n */\nexport type ResponseStreamEvent =\n  | ResponseAudioDeltaEvent\n  | ResponseAudioDoneEvent\n  | ResponseAudioTranscriptDeltaEvent\n  | ResponseAudioTranscriptDoneEvent\n  | ResponseCodeInterpreterCallCodeDeltaEvent\n  | ResponseCodeInterpreterCallCodeDoneEvent\n  | ResponseCodeInterpreterCallCompletedEvent\n  | ResponseCodeInterpreterCallInProgressEvent\n  | ResponseCodeInterpreterCallInterpretingEvent\n  | ResponseCompletedEvent\n  | ResponseContentPartAddedEvent\n  | ResponseContentPartDoneEvent\n  | ResponseCreatedEvent\n  | ResponseErrorEvent\n  | ResponseFileSearchCallCompletedEvent\n  | ResponseFileSearchCallInProgressEvent\n  | ResponseFileSearchCallSearchingEvent\n  | ResponseFunctionCallArgumentsDeltaEvent\n  | ResponseFunctionCallArgumentsDoneEvent\n  | ResponseInProgressEvent\n  | ResponseFailedEvent\n  | ResponseIncompleteEvent\n  | ResponseOutputItemAddedEvent\n  | ResponseOutputItemDoneEvent\n  | ResponseReasoningSummaryPartAddedEvent\n  | ResponseReasoningSummaryPartDoneEvent\n  | ResponseReasoningSummaryTextDeltaEvent\n  | ResponseReasoningSummaryTextDoneEvent\n  | ResponseReasoningTextDeltaEvent\n  | ResponseReasoningTextDoneEvent\n  | ResponseRefusalDeltaEvent\n  | ResponseRefusalDoneEvent\n  | ResponseTextDeltaEvent\n  | ResponseTextDoneEvent\n  | ResponseWebSearchCallCompletedEvent\n  | ResponseWebSearchCallInProgressEvent\n  | ResponseWebSearchCallSearchingEvent\n  | ResponseImageGenCallCompletedEvent\n  | ResponseImageGenCallGeneratingEvent\n  | ResponseImageGenCallInProgressEvent\n  | ResponseImageGenCallPartialImageEvent\n  | ResponseMcpCallArgumentsDeltaEvent\n  | ResponseMcpCallArgumentsDoneEvent\n  | ResponseMcpCallCompletedEvent\n  | ResponseMcpCallFailedEvent\n  | ResponseMcpCallInProgressEvent\n  | ResponseMcpListToolsCompletedEvent\n  | ResponseMcpListToolsFailedEvent\n  | ResponseMcpListToolsInProgressEvent\n  | ResponseOutputTextAnnotationAddedEvent\n  | ResponseQueuedEvent\n  | ResponseCustomToolCallInputDeltaEvent\n  | ResponseCustomToolCallInputDoneEvent;\n\n/**\n * Configuration options for a text response from the model. Can be plain text or\n * structured JSON data. Learn more:\n *\n * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n */\nexport interface ResponseTextConfig {\n  /**\n   * An object specifying the format that the model must output.\n   *\n   * Configuring `{ \"type\": \"json_schema\" }` enables Structured Outputs, which\n   * ensures the model will match your supplied JSON schema. Learn more in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * The default format is `{ \"type\": \"text\" }` with no additional options.\n   *\n   * **Not recommended for gpt-4o and newer models:**\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\n   * ensures the message the model generates is valid JSON. Using `json_schema` is\n   * preferred for models that support it.\n   */\n  format?: ResponseFormatTextConfig;\n\n  /**\n   * Constrains the verbosity of the model's response. Lower values will result in\n   * more concise responses, while higher values will result in more verbose\n   * responses. Currently supported values are `low`, `medium`, and `high`.\n   */\n  verbosity?: 'low' | 'medium' | 'high' | null;\n}\n\n/**\n * Emitted when there is an additional text delta.\n */\nexport interface ResponseTextDeltaEvent {\n  /**\n   * The index of the content part that the text delta was added to.\n   */\n  content_index: number;\n\n  /**\n   * The text delta that was added.\n   */\n  delta: string;\n\n  /**\n   * The ID of the output item that the text delta was added to.\n   */\n  item_id: string;\n\n  /**\n   * The log probabilities of the tokens in the delta.\n   */\n  logprobs: Array<ResponseTextDeltaEvent.Logprob>;\n\n  /**\n   * The index of the output item that the text delta was added to.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number for this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.output_text.delta`.\n   */\n  type: 'response.output_text.delta';\n}\n\nexport namespace ResponseTextDeltaEvent {\n  /**\n   * A logprob is the logarithmic probability that the model assigns to producing a\n   * particular token at a given position in the sequence. Less-negative (higher)\n   * logprob values indicate greater model confidence in that token choice.\n   */\n  export interface Logprob {\n    /**\n     * A possible text token.\n     */\n    token: string;\n\n    /**\n     * The log probability of this token.\n     */\n    logprob: number;\n\n    /**\n     * The log probability of the top 20 most likely tokens.\n     */\n    top_logprobs?: Array<Logprob.TopLogprob>;\n  }\n\n  export namespace Logprob {\n    export interface TopLogprob {\n      /**\n       * A possible text token.\n       */\n      token?: string;\n\n      /**\n       * The log probability of this token.\n       */\n      logprob?: number;\n    }\n  }\n}\n\n/**\n * Emitted when text content is finalized.\n */\nexport interface ResponseTextDoneEvent {\n  /**\n   * The index of the content part that the text content is finalized.\n   */\n  content_index: number;\n\n  /**\n   * The ID of the output item that the text content is finalized.\n   */\n  item_id: string;\n\n  /**\n   * The log probabilities of the tokens in the delta.\n   */\n  logprobs: Array<ResponseTextDoneEvent.Logprob>;\n\n  /**\n   * The index of the output item that the text content is finalized.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number for this event.\n   */\n  sequence_number: number;\n\n  /**\n   * The text content that is finalized.\n   */\n  text: string;\n\n  /**\n   * The type of the event. Always `response.output_text.done`.\n   */\n  type: 'response.output_text.done';\n}\n\nexport namespace ResponseTextDoneEvent {\n  /**\n   * A logprob is the logarithmic probability that the model assigns to producing a\n   * particular token at a given position in the sequence. Less-negative (higher)\n   * logprob values indicate greater model confidence in that token choice.\n   */\n  export interface Logprob {\n    /**\n     * A possible text token.\n     */\n    token: string;\n\n    /**\n     * The log probability of this token.\n     */\n    logprob: number;\n\n    /**\n     * The log probability of the top 20 most likely tokens.\n     */\n    top_logprobs?: Array<Logprob.TopLogprob>;\n  }\n\n  export namespace Logprob {\n    export interface TopLogprob {\n      /**\n       * A possible text token.\n       */\n      token?: string;\n\n      /**\n       * The log probability of this token.\n       */\n      logprob?: number;\n    }\n  }\n}\n\n/**\n * Represents token usage details including input tokens, output tokens, a\n * breakdown of output tokens, and the total tokens used.\n */\nexport interface ResponseUsage {\n  /**\n   * The number of input tokens.\n   */\n  input_tokens: number;\n\n  /**\n   * A detailed breakdown of the input tokens.\n   */\n  input_tokens_details: ResponseUsage.InputTokensDetails;\n\n  /**\n   * The number of output tokens.\n   */\n  output_tokens: number;\n\n  /**\n   * A detailed breakdown of the output tokens.\n   */\n  output_tokens_details: ResponseUsage.OutputTokensDetails;\n\n  /**\n   * The total number of tokens used.\n   */\n  total_tokens: number;\n}\n\nexport namespace ResponseUsage {\n  /**\n   * A detailed breakdown of the input tokens.\n   */\n  export interface InputTokensDetails {\n    /**\n     * The number of tokens that were retrieved from the cache.\n     * [More on prompt caching](https://platform.openai.com/docs/guides/prompt-caching).\n     */\n    cached_tokens: number;\n  }\n\n  /**\n   * A detailed breakdown of the output tokens.\n   */\n  export interface OutputTokensDetails {\n    /**\n     * The number of reasoning tokens.\n     */\n    reasoning_tokens: number;\n  }\n}\n\n/**\n * Emitted when a web search call is completed.\n */\nexport interface ResponseWebSearchCallCompletedEvent {\n  /**\n   * Unique ID for the output item associated with the web search call.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the web search call is associated with.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of the web search call being processed.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.web_search_call.completed`.\n   */\n  type: 'response.web_search_call.completed';\n}\n\n/**\n * Emitted when a web search call is initiated.\n */\nexport interface ResponseWebSearchCallInProgressEvent {\n  /**\n   * Unique ID for the output item associated with the web search call.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the web search call is associated with.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of the web search call being processed.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.web_search_call.in_progress`.\n   */\n  type: 'response.web_search_call.in_progress';\n}\n\n/**\n * Emitted when a web search call is executing.\n */\nexport interface ResponseWebSearchCallSearchingEvent {\n  /**\n   * Unique ID for the output item associated with the web search call.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item that the web search call is associated with.\n   */\n  output_index: number;\n\n  /**\n   * The sequence number of the web search call being processed.\n   */\n  sequence_number: number;\n\n  /**\n   * The type of the event. Always `response.web_search_call.searching`.\n   */\n  type: 'response.web_search_call.searching';\n}\n\n/**\n * A tool that can be used to generate a response.\n */\nexport type Tool =\n  | FunctionTool\n  | FileSearchTool\n  | ComputerTool\n  | WebSearchTool\n  | Tool.Mcp\n  | Tool.CodeInterpreter\n  | Tool.ImageGeneration\n  | Tool.LocalShell\n  | CustomTool\n  | WebSearchPreviewTool;\n\nexport namespace Tool {\n  /**\n   * Give the model access to additional tools via remote Model Context Protocol\n   * (MCP) servers.\n   * [Learn more about MCP](https://platform.openai.com/docs/guides/tools-remote-mcp).\n   */\n  export interface Mcp {\n    /**\n     * A label for this MCP server, used to identify it in tool calls.\n     */\n    server_label: string;\n\n    /**\n     * The type of the MCP tool. Always `mcp`.\n     */\n    type: 'mcp';\n\n    /**\n     * List of allowed tool names or a filter object.\n     */\n    allowed_tools?: Array<string> | Mcp.McpToolFilter | null;\n\n    /**\n     * An OAuth access token that can be used with a remote MCP server, either with a\n     * custom MCP server URL or a service connector. Your application must handle the\n     * OAuth authorization flow and provide the token here.\n     */\n    authorization?: string;\n\n    /**\n     * Identifier for service connectors, like those available in ChatGPT. One of\n     * `server_url` or `connector_id` must be provided. Learn more about service\n     * connectors\n     * [here](https://platform.openai.com/docs/guides/tools-remote-mcp#connectors).\n     *\n     * Currently supported `connector_id` values are:\n     *\n     * - Dropbox: `connector_dropbox`\n     * - Gmail: `connector_gmail`\n     * - Google Calendar: `connector_googlecalendar`\n     * - Google Drive: `connector_googledrive`\n     * - Microsoft Teams: `connector_microsoftteams`\n     * - Outlook Calendar: `connector_outlookcalendar`\n     * - Outlook Email: `connector_outlookemail`\n     * - SharePoint: `connector_sharepoint`\n     */\n    connector_id?:\n      | 'connector_dropbox'\n      | 'connector_gmail'\n      | 'connector_googlecalendar'\n      | 'connector_googledrive'\n      | 'connector_microsoftteams'\n      | 'connector_outlookcalendar'\n      | 'connector_outlookemail'\n      | 'connector_sharepoint';\n\n    /**\n     * Optional HTTP headers to send to the MCP server. Use for authentication or other\n     * purposes.\n     */\n    headers?: { [key: string]: string } | null;\n\n    /**\n     * Specify which of the MCP server's tools require approval.\n     */\n    require_approval?: Mcp.McpToolApprovalFilter | 'always' | 'never' | null;\n\n    /**\n     * Optional description of the MCP server, used to provide more context.\n     */\n    server_description?: string;\n\n    /**\n     * The URL for the MCP server. One of `server_url` or `connector_id` must be\n     * provided.\n     */\n    server_url?: string;\n  }\n\n  export namespace Mcp {\n    /**\n     * A filter object to specify which tools are allowed.\n     */\n    export interface McpToolFilter {\n      /**\n       * Indicates whether or not a tool modifies data or is read-only. If an MCP server\n       * is\n       * [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\n       * it will match this filter.\n       */\n      read_only?: boolean;\n\n      /**\n       * List of allowed tool names.\n       */\n      tool_names?: Array<string>;\n    }\n\n    /**\n     * Specify which of the MCP server's tools require approval. Can be `always`,\n     * `never`, or a filter object associated with tools that require approval.\n     */\n    export interface McpToolApprovalFilter {\n      /**\n       * A filter object to specify which tools are allowed.\n       */\n      always?: McpToolApprovalFilter.Always;\n\n      /**\n       * A filter object to specify which tools are allowed.\n       */\n      never?: McpToolApprovalFilter.Never;\n    }\n\n    export namespace McpToolApprovalFilter {\n      /**\n       * A filter object to specify which tools are allowed.\n       */\n      export interface Always {\n        /**\n         * Indicates whether or not a tool modifies data or is read-only. If an MCP server\n         * is\n         * [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\n         * it will match this filter.\n         */\n        read_only?: boolean;\n\n        /**\n         * List of allowed tool names.\n         */\n        tool_names?: Array<string>;\n      }\n\n      /**\n       * A filter object to specify which tools are allowed.\n       */\n      export interface Never {\n        /**\n         * Indicates whether or not a tool modifies data or is read-only. If an MCP server\n         * is\n         * [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\n         * it will match this filter.\n         */\n        read_only?: boolean;\n\n        /**\n         * List of allowed tool names.\n         */\n        tool_names?: Array<string>;\n      }\n    }\n  }\n\n  /**\n   * A tool that runs Python code to help generate a response to a prompt.\n   */\n  export interface CodeInterpreter {\n    /**\n     * The code interpreter container. Can be a container ID or an object that\n     * specifies uploaded file IDs to make available to your code.\n     */\n    container: string | CodeInterpreter.CodeInterpreterToolAuto;\n\n    /**\n     * The type of the code interpreter tool. Always `code_interpreter`.\n     */\n    type: 'code_interpreter';\n  }\n\n  export namespace CodeInterpreter {\n    /**\n     * Configuration for a code interpreter container. Optionally specify the IDs of\n     * the files to run the code on.\n     */\n    export interface CodeInterpreterToolAuto {\n      /**\n       * Always `auto`.\n       */\n      type: 'auto';\n\n      /**\n       * An optional list of uploaded files to make available to your code.\n       */\n      file_ids?: Array<string>;\n\n      memory_limit?: '1g' | '4g' | '16g' | '64g' | null;\n    }\n  }\n\n  /**\n   * A tool that generates images using a model like `gpt-image-1`.\n   */\n  export interface ImageGeneration {\n    /**\n     * The type of the image generation tool. Always `image_generation`.\n     */\n    type: 'image_generation';\n\n    /**\n     * Background type for the generated image. One of `transparent`, `opaque`, or\n     * `auto`. Default: `auto`.\n     */\n    background?: 'transparent' | 'opaque' | 'auto';\n\n    /**\n     * Control how much effort the model will exert to match the style and features,\n     * especially facial features, of input images. This parameter is only supported\n     * for `gpt-image-1`. Unsupported for `gpt-image-1-mini`. Supports `high` and\n     * `low`. Defaults to `low`.\n     */\n    input_fidelity?: 'high' | 'low' | null;\n\n    /**\n     * Optional mask for inpainting. Contains `image_url` (string, optional) and\n     * `file_id` (string, optional).\n     */\n    input_image_mask?: ImageGeneration.InputImageMask;\n\n    /**\n     * The image generation model to use. Default: `gpt-image-1`.\n     */\n    model?: 'gpt-image-1' | 'gpt-image-1-mini';\n\n    /**\n     * Moderation level for the generated image. Default: `auto`.\n     */\n    moderation?: 'auto' | 'low';\n\n    /**\n     * Compression level for the output image. Default: 100.\n     */\n    output_compression?: number;\n\n    /**\n     * The output format of the generated image. One of `png`, `webp`, or `jpeg`.\n     * Default: `png`.\n     */\n    output_format?: 'png' | 'webp' | 'jpeg';\n\n    /**\n     * Number of partial images to generate in streaming mode, from 0 (default value)\n     * to 3.\n     */\n    partial_images?: number;\n\n    /**\n     * The quality of the generated image. One of `low`, `medium`, `high`, or `auto`.\n     * Default: `auto`.\n     */\n    quality?: 'low' | 'medium' | 'high' | 'auto';\n\n    /**\n     * The size of the generated image. One of `1024x1024`, `1024x1536`, `1536x1024`,\n     * or `auto`. Default: `auto`.\n     */\n    size?: '1024x1024' | '1024x1536' | '1536x1024' | 'auto';\n  }\n\n  export namespace ImageGeneration {\n    /**\n     * Optional mask for inpainting. Contains `image_url` (string, optional) and\n     * `file_id` (string, optional).\n     */\n    export interface InputImageMask {\n      /**\n       * File ID for the mask image.\n       */\n      file_id?: string;\n\n      /**\n       * Base64-encoded mask image.\n       */\n      image_url?: string;\n    }\n  }\n\n  /**\n   * A tool that allows the model to execute shell commands in a local environment.\n   */\n  export interface LocalShell {\n    /**\n     * The type of the local shell tool. Always `local_shell`.\n     */\n    type: 'local_shell';\n  }\n}\n\n/**\n * Constrains the tools available to the model to a pre-defined set.\n */\nexport interface ToolChoiceAllowed {\n  /**\n   * Constrains the tools available to the model to a pre-defined set.\n   *\n   * `auto` allows the model to pick from among the allowed tools and generate a\n   * message.\n   *\n   * `required` requires the model to call one or more of the allowed tools.\n   */\n  mode: 'auto' | 'required';\n\n  /**\n   * A list of tool definitions that the model should be allowed to call.\n   *\n   * For the Responses API, the list of tool definitions might look like:\n   *\n   * ```json\n   * [\n   *   { \"type\": \"function\", \"name\": \"get_weather\" },\n   *   { \"type\": \"mcp\", \"server_label\": \"deepwiki\" },\n   *   { \"type\": \"image_generation\" }\n   * ]\n   * ```\n   */\n  tools: Array<{ [key: string]: unknown }>;\n\n  /**\n   * Allowed tool configuration type. Always `allowed_tools`.\n   */\n  type: 'allowed_tools';\n}\n\n/**\n * Use this option to force the model to call a specific custom tool.\n */\nexport interface ToolChoiceCustom {\n  /**\n   * The name of the custom tool to call.\n   */\n  name: string;\n\n  /**\n   * For custom tool calling, the type is always `custom`.\n   */\n  type: 'custom';\n}\n\n/**\n * Use this option to force the model to call a specific function.\n */\nexport interface ToolChoiceFunction {\n  /**\n   * The name of the function to call.\n   */\n  name: string;\n\n  /**\n   * For function calling, the type is always `function`.\n   */\n  type: 'function';\n}\n\n/**\n * Use this option to force the model to call a specific tool on a remote MCP\n * server.\n */\nexport interface ToolChoiceMcp {\n  /**\n   * The label of the MCP server to use.\n   */\n  server_label: string;\n\n  /**\n   * For MCP tools, the type is always `mcp`.\n   */\n  type: 'mcp';\n\n  /**\n   * The name of the tool to call on the server.\n   */\n  name?: string | null;\n}\n\n/**\n * Controls which (if any) tool is called by the model.\n *\n * `none` means the model will not call any tool and instead generates a message.\n *\n * `auto` means the model can pick between generating a message or calling one or\n * more tools.\n *\n * `required` means the model must call one or more tools.\n */\nexport type ToolChoiceOptions = 'none' | 'auto' | 'required';\n\n/**\n * Indicates that the model should use a built-in tool to generate a response.\n * [Learn more about built-in tools](https://platform.openai.com/docs/guides/tools).\n */\nexport interface ToolChoiceTypes {\n  /**\n   * The type of hosted tool the model should to use. Learn more about\n   * [built-in tools](https://platform.openai.com/docs/guides/tools).\n   *\n   * Allowed values are:\n   *\n   * - `file_search`\n   * - `web_search_preview`\n   * - `computer_use_preview`\n   * - `code_interpreter`\n   * - `mcp`\n   * - `image_generation`\n   */\n  type:\n    | 'file_search'\n    | 'web_search_preview'\n    | 'computer_use_preview'\n    | 'web_search_preview_2025_03_11'\n    | 'image_generation'\n    | 'code_interpreter'\n    | 'mcp';\n}\n\n/**\n * This tool searches the web for relevant results to use in a response. Learn more\n * about the\n * [web search tool](https://platform.openai.com/docs/guides/tools-web-search).\n */\nexport interface WebSearchPreviewTool {\n  /**\n   * The type of the web search tool. One of `web_search_preview` or\n   * `web_search_preview_2025_03_11`.\n   */\n  type: 'web_search_preview' | 'web_search_preview_2025_03_11';\n\n  /**\n   * High level guidance for the amount of context window space to use for the\n   * search. One of `low`, `medium`, or `high`. `medium` is the default.\n   */\n  search_context_size?: 'low' | 'medium' | 'high';\n\n  /**\n   * The user's location.\n   */\n  user_location?: WebSearchPreviewTool.UserLocation | null;\n}\n\nexport namespace WebSearchPreviewTool {\n  /**\n   * The user's location.\n   */\n  export interface UserLocation {\n    /**\n     * The type of location approximation. Always `approximate`.\n     */\n    type: 'approximate';\n\n    /**\n     * Free text input for the city of the user, e.g. `San Francisco`.\n     */\n    city?: string | null;\n\n    /**\n     * The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of\n     * the user, e.g. `US`.\n     */\n    country?: string | null;\n\n    /**\n     * Free text input for the region of the user, e.g. `California`.\n     */\n    region?: string | null;\n\n    /**\n     * The [IANA timezone](https://timeapi.io/documentation/iana-timezones) of the\n     * user, e.g. `America/Los_Angeles`.\n     */\n    timezone?: string | null;\n  }\n}\n\n/**\n * Search the Internet for sources related to the prompt. Learn more about the\n * [web search tool](https://platform.openai.com/docs/guides/tools-web-search).\n */\nexport interface WebSearchTool {\n  /**\n   * The type of the web search tool. One of `web_search` or `web_search_2025_08_26`.\n   */\n  type: 'web_search' | 'web_search_2025_08_26';\n\n  /**\n   * Filters for the search.\n   */\n  filters?: WebSearchTool.Filters | null;\n\n  /**\n   * High level guidance for the amount of context window space to use for the\n   * search. One of `low`, `medium`, or `high`. `medium` is the default.\n   */\n  search_context_size?: 'low' | 'medium' | 'high';\n\n  /**\n   * The approximate location of the user.\n   */\n  user_location?: WebSearchTool.UserLocation | null;\n}\n\nexport namespace WebSearchTool {\n  /**\n   * Filters for the search.\n   */\n  export interface Filters {\n    /**\n     * Allowed domains for the search. If not provided, all domains are allowed.\n     * Subdomains of the provided domains are allowed as well.\n     *\n     * Example: `[\"pubmed.ncbi.nlm.nih.gov\"]`\n     */\n    allowed_domains?: Array<string> | null;\n  }\n\n  /**\n   * The approximate location of the user.\n   */\n  export interface UserLocation {\n    /**\n     * Free text input for the city of the user, e.g. `San Francisco`.\n     */\n    city?: string | null;\n\n    /**\n     * The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of\n     * the user, e.g. `US`.\n     */\n    country?: string | null;\n\n    /**\n     * Free text input for the region of the user, e.g. `California`.\n     */\n    region?: string | null;\n\n    /**\n     * The [IANA timezone](https://timeapi.io/documentation/iana-timezones) of the\n     * user, e.g. `America/Los_Angeles`.\n     */\n    timezone?: string | null;\n\n    /**\n     * The type of location approximation. Always `approximate`.\n     */\n    type?: 'approximate';\n  }\n}\n\nexport type ResponseCreateParams = ResponseCreateParamsNonStreaming | ResponseCreateParamsStreaming;\n\nexport interface ResponseCreateParamsBase {\n  /**\n   * Whether to run the model response in the background.\n   * [Learn more](https://platform.openai.com/docs/guides/background).\n   */\n  background?: boolean | null;\n\n  /**\n   * The conversation that this response belongs to. Items from this conversation are\n   * prepended to `input_items` for this response request. Input items and output\n   * items from this response are automatically added to this conversation after this\n   * response completes.\n   */\n  conversation?: string | ResponseConversationParam | null;\n\n  /**\n   * Specify additional output data to include in the model response. Currently\n   * supported values are:\n   *\n   * - `web_search_call.action.sources`: Include the sources of the web search tool\n   *   call.\n   * - `code_interpreter_call.outputs`: Includes the outputs of python code execution\n   *   in code interpreter tool call items.\n   * - `computer_call_output.output.image_url`: Include image urls from the computer\n   *   call output.\n   * - `file_search_call.results`: Include the search results of the file search tool\n   *   call.\n   * - `message.input_image.image_url`: Include image urls from the input message.\n   * - `computer_call_output.output.image_url`: Include image urls from the computer\n   *   call output.\n   * - `reasoning.encrypted_content`: Includes an encrypted version of reasoning\n   *   tokens in reasoning item outputs. This enables reasoning items to be used in\n   *   multi-turn conversations when using the Responses API statelessly (like when\n   *   the `store` parameter is set to `false`, or when an organization is enrolled\n   *   in the zero data retention program).\n   * - `code_interpreter_call.outputs`: Includes the outputs of python code execution\n   *   in code interpreter tool call items.\n   */\n  include?: Array<ResponseIncludable> | null;\n\n  /**\n   * Text, image, or file inputs to the model, used to generate a response.\n   *\n   * Learn more:\n   *\n   * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n   * - [Image inputs](https://platform.openai.com/docs/guides/images)\n   * - [File inputs](https://platform.openai.com/docs/guides/pdf-files)\n   * - [Conversation state](https://platform.openai.com/docs/guides/conversation-state)\n   * - [Function calling](https://platform.openai.com/docs/guides/function-calling)\n   */\n  input?: string | ResponseInput;\n\n  /**\n   * A system (or developer) message inserted into the model's context.\n   *\n   * When using along with `previous_response_id`, the instructions from a previous\n   * response will not be carried over to the next response. This makes it simple to\n   * swap out system (or developer) messages in new responses.\n   */\n  instructions?: string | null;\n\n  /**\n   * An upper bound for the number of tokens that can be generated for a response,\n   * including visible output tokens and\n   * [reasoning tokens](https://platform.openai.com/docs/guides/reasoning).\n   */\n  max_output_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * Model ID used to generate the response, like `gpt-4o` or `o3`. OpenAI offers a\n   * wide range of models with different capabilities, performance characteristics,\n   * and price points. Refer to the\n   * [model guide](https://platform.openai.com/docs/models) to browse and compare\n   * available models.\n   */\n  model?: Shared.ResponsesModel;\n\n  /**\n   * Whether to allow the model to run tool calls in parallel.\n   */\n  parallel_tool_calls?: boolean | null;\n\n  /**\n   * The unique ID of the previous response to the model. Use this to create\n   * multi-turn conversations. Learn more about\n   * [conversation state](https://platform.openai.com/docs/guides/conversation-state).\n   * Cannot be used in conjunction with `conversation`.\n   */\n  previous_response_id?: string | null;\n\n  /**\n   * Reference to a prompt template and its variables.\n   * [Learn more](https://platform.openai.com/docs/guides/text?api-mode=responses#reusable-prompts).\n   */\n  prompt?: ResponsePrompt | null;\n\n  /**\n   * Used by OpenAI to cache responses for similar requests to optimize your cache\n   * hit rates. Replaces the `user` field.\n   * [Learn more](https://platform.openai.com/docs/guides/prompt-caching).\n   */\n  prompt_cache_key?: string;\n\n  /**\n   * **gpt-5 and o-series models only**\n   *\n   * Configuration options for\n   * [reasoning models](https://platform.openai.com/docs/guides/reasoning).\n   */\n  reasoning?: Shared.Reasoning | null;\n\n  /**\n   * A stable identifier used to help detect users of your application that may be\n   * violating OpenAI's usage policies. The IDs should be a string that uniquely\n   * identifies each user. We recommend hashing their username or email address, in\n   * order to avoid sending us any identifying information.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).\n   */\n  safety_identifier?: string;\n\n  /**\n   * Specifies the latency tier to use for processing the request. This parameter is\n   * relevant for customers subscribed to the scale tier service:\n   *\n   * - If set to 'auto', then the request will be processed with the service tier\n   *   configured in the Project settings. Unless otherwise configured, the Project\n   *   will use 'default'.\n   * - If set to 'default', then the request will be processed with the standard\n   *   pricing and performance for the selected model.\n   * - If set to '[flex](https://platform.openai.com/docs/guides/flex-processing)' or\n   *   '[priority](https://openai.com/api-priority-processing/)', then the request\n   *   will be processed with the corresponding service tier.\n   * - When not set, the default behavior is 'auto'.\n   *\n   * When this parameter is set, the response body will include the `service_tier`\n   * utilized.\n   */\n  service_tier?: 'auto' | 'default' | 'flex' | 'scale' | 'priority' | null;\n\n  /**\n   * Whether to store the generated model response for later retrieval via API.\n   */\n  store?: boolean | null;\n\n  /**\n   * If set to true, the model response data will be streamed to the client as it is\n   * generated using\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\n   * See the\n   * [Streaming section below](https://platform.openai.com/docs/api-reference/responses-streaming)\n   * for more information.\n   */\n  stream?: boolean | null;\n\n  /**\n   * Options for streaming responses. Only set this when you set `stream: true`.\n   */\n  stream_options?: ResponseCreateParams.StreamOptions | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic. We generally recommend altering this or `top_p` but\n   * not both.\n   */\n  temperature?: number | null;\n\n  /**\n   * Configuration options for a text response from the model. Can be plain text or\n   * structured JSON data. Learn more:\n   *\n   * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n   * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n   */\n  text?: ResponseTextConfig;\n\n  /**\n   * How the model should select which tool (or tools) to use when generating a\n   * response. See the `tools` parameter to see how to specify which tools the model\n   * can call.\n   */\n  tool_choice?:\n    | ToolChoiceOptions\n    | ToolChoiceAllowed\n    | ToolChoiceTypes\n    | ToolChoiceFunction\n    | ToolChoiceMcp\n    | ToolChoiceCustom;\n\n  /**\n   * An array of tools the model may call while generating a response. You can\n   * specify which tool to use by setting the `tool_choice` parameter.\n   *\n   * We support the following categories of tools:\n   *\n   * - **Built-in tools**: Tools that are provided by OpenAI that extend the model's\n   *   capabilities, like\n   *   [web search](https://platform.openai.com/docs/guides/tools-web-search) or\n   *   [file search](https://platform.openai.com/docs/guides/tools-file-search).\n   *   Learn more about\n   *   [built-in tools](https://platform.openai.com/docs/guides/tools).\n   * - **MCP Tools**: Integrations with third-party systems via custom MCP servers or\n   *   predefined connectors such as Google Drive and SharePoint. Learn more about\n   *   [MCP Tools](https://platform.openai.com/docs/guides/tools-connectors-mcp).\n   * - **Function calls (custom tools)**: Functions that are defined by you, enabling\n   *   the model to call your own code with strongly typed arguments and outputs.\n   *   Learn more about\n   *   [function calling](https://platform.openai.com/docs/guides/function-calling).\n   *   You can also use custom tools to call your own code.\n   */\n  tools?: Array<Tool>;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or `temperature` but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * The truncation strategy to use for the model response.\n   *\n   * - `auto`: If the input to this Response exceeds the model's context window size,\n   *   the model will truncate the response to fit the context window by dropping\n   *   items from the beginning of the conversation.\n   * - `disabled` (default): If the input size will exceed the context window size\n   *   for a model, the request will fail with a 400 error.\n   */\n  truncation?: 'auto' | 'disabled' | null;\n\n  /**\n   * @deprecated This field is being replaced by `safety_identifier` and\n   * `prompt_cache_key`. Use `prompt_cache_key` instead to maintain caching\n   * optimizations. A stable identifier for your end-users. Used to boost cache hit\n   * rates by better bucketing similar requests and to help OpenAI detect and prevent\n   * abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).\n   */\n  user?: string;\n}\n\nexport namespace ResponseCreateParams {\n  /**\n   * Options for streaming responses. Only set this when you set `stream: true`.\n   */\n  export interface StreamOptions {\n    /**\n     * When true, stream obfuscation will be enabled. Stream obfuscation adds random\n     * characters to an `obfuscation` field on streaming delta events to normalize\n     * payload sizes as a mitigation to certain side-channel attacks. These obfuscation\n     * fields are included by default, but add a small amount of overhead to the data\n     * stream. You can set `include_obfuscation` to false to optimize for bandwidth if\n     * you trust the network links between your application and the OpenAI API.\n     */\n    include_obfuscation?: boolean;\n  }\n\n  export type ResponseCreateParamsNonStreaming = ResponsesAPI.ResponseCreateParamsNonStreaming;\n  export type ResponseCreateParamsStreaming = ResponsesAPI.ResponseCreateParamsStreaming;\n}\n\nexport interface ResponseCreateParamsNonStreaming extends ResponseCreateParamsBase {\n  /**\n   * If set to true, the model response data will be streamed to the client as it is\n   * generated using\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\n   * See the\n   * [Streaming section below](https://platform.openai.com/docs/api-reference/responses-streaming)\n   * for more information.\n   */\n  stream?: false | null;\n}\n\nexport interface ResponseCreateParamsStreaming extends ResponseCreateParamsBase {\n  /**\n   * If set to true, the model response data will be streamed to the client as it is\n   * generated using\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\n   * See the\n   * [Streaming section below](https://platform.openai.com/docs/api-reference/responses-streaming)\n   * for more information.\n   */\n  stream: true;\n}\n\nexport type ResponseRetrieveParams = ResponseRetrieveParamsNonStreaming | ResponseRetrieveParamsStreaming;\n\nexport interface ResponseRetrieveParamsBase {\n  /**\n   * Additional fields to include in the response. See the `include` parameter for\n   * Response creation above for more information.\n   */\n  include?: Array<ResponseIncludable>;\n\n  /**\n   * When true, stream obfuscation will be enabled. Stream obfuscation adds random\n   * characters to an `obfuscation` field on streaming delta events to normalize\n   * payload sizes as a mitigation to certain side-channel attacks. These obfuscation\n   * fields are included by default, but add a small amount of overhead to the data\n   * stream. You can set `include_obfuscation` to false to optimize for bandwidth if\n   * you trust the network links between your application and the OpenAI API.\n   */\n  include_obfuscation?: boolean;\n\n  /**\n   * The sequence number of the event after which to start streaming.\n   */\n  starting_after?: number;\n\n  /**\n   * If set to true, the model response data will be streamed to the client as it is\n   * generated using\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\n   * See the\n   * [Streaming section below](https://platform.openai.com/docs/api-reference/responses-streaming)\n   * for more information.\n   */\n  stream?: boolean;\n}\n\nexport namespace ResponseRetrieveParams {\n  export type ResponseRetrieveParamsNonStreaming = ResponsesAPI.ResponseRetrieveParamsNonStreaming;\n  export type ResponseRetrieveParamsStreaming = ResponsesAPI.ResponseRetrieveParamsStreaming;\n}\n\nexport interface ResponseRetrieveParamsNonStreaming extends ResponseRetrieveParamsBase {\n  /**\n   * If set to true, the model response data will be streamed to the client as it is\n   * generated using\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\n   * See the\n   * [Streaming section below](https://platform.openai.com/docs/api-reference/responses-streaming)\n   * for more information.\n   */\n  stream?: false;\n}\n\nexport interface ResponseRetrieveParamsStreaming extends ResponseRetrieveParamsBase {\n  /**\n   * If set to true, the model response data will be streamed to the client as it is\n   * generated using\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\n   * See the\n   * [Streaming section below](https://platform.openai.com/docs/api-reference/responses-streaming)\n   * for more information.\n   */\n  stream: true;\n}\n\nResponses.InputItems = InputItems;\nResponses.InputTokens = InputTokens;\n\nexport declare namespace Responses {\n  export {\n    type ComputerTool as ComputerTool,\n    type CustomTool as CustomTool,\n    type EasyInputMessage as EasyInputMessage,\n    type FileSearchTool as FileSearchTool,\n    type FunctionTool as FunctionTool,\n    type Response as Response,\n    type ResponseAudioDeltaEvent as ResponseAudioDeltaEvent,\n    type ResponseAudioDoneEvent as ResponseAudioDoneEvent,\n    type ResponseAudioTranscriptDeltaEvent as ResponseAudioTranscriptDeltaEvent,\n    type ResponseAudioTranscriptDoneEvent as ResponseAudioTranscriptDoneEvent,\n    type ResponseCodeInterpreterCallCodeDeltaEvent as ResponseCodeInterpreterCallCodeDeltaEvent,\n    type ResponseCodeInterpreterCallCodeDoneEvent as ResponseCodeInterpreterCallCodeDoneEvent,\n    type ResponseCodeInterpreterCallCompletedEvent as ResponseCodeInterpreterCallCompletedEvent,\n    type ResponseCodeInterpreterCallInProgressEvent as ResponseCodeInterpreterCallInProgressEvent,\n    type ResponseCodeInterpreterCallInterpretingEvent as ResponseCodeInterpreterCallInterpretingEvent,\n    type ResponseCodeInterpreterToolCall as ResponseCodeInterpreterToolCall,\n    type ResponseCompletedEvent as ResponseCompletedEvent,\n    type ResponseComputerToolCall as ResponseComputerToolCall,\n    type ResponseComputerToolCallOutputItem as ResponseComputerToolCallOutputItem,\n    type ResponseComputerToolCallOutputScreenshot as ResponseComputerToolCallOutputScreenshot,\n    type ResponseContent as ResponseContent,\n    type ResponseContentPartAddedEvent as ResponseContentPartAddedEvent,\n    type ResponseContentPartDoneEvent as ResponseContentPartDoneEvent,\n    type ResponseConversationParam as ResponseConversationParam,\n    type ResponseCreatedEvent as ResponseCreatedEvent,\n    type ResponseCustomToolCall as ResponseCustomToolCall,\n    type ResponseCustomToolCallInputDeltaEvent as ResponseCustomToolCallInputDeltaEvent,\n    type ResponseCustomToolCallInputDoneEvent as ResponseCustomToolCallInputDoneEvent,\n    type ResponseCustomToolCallOutput as ResponseCustomToolCallOutput,\n    type ResponseError as ResponseError,\n    type ResponseErrorEvent as ResponseErrorEvent,\n    type ResponseFailedEvent as ResponseFailedEvent,\n    type ResponseFileSearchCallCompletedEvent as ResponseFileSearchCallCompletedEvent,\n    type ResponseFileSearchCallInProgressEvent as ResponseFileSearchCallInProgressEvent,\n    type ResponseFileSearchCallSearchingEvent as ResponseFileSearchCallSearchingEvent,\n    type ResponseFileSearchToolCall as ResponseFileSearchToolCall,\n    type ResponseFormatTextConfig as ResponseFormatTextConfig,\n    type ResponseFormatTextJSONSchemaConfig as ResponseFormatTextJSONSchemaConfig,\n    type ResponseFunctionCallArgumentsDeltaEvent as ResponseFunctionCallArgumentsDeltaEvent,\n    type ResponseFunctionCallArgumentsDoneEvent as ResponseFunctionCallArgumentsDoneEvent,\n    type ResponseFunctionCallOutputItem as ResponseFunctionCallOutputItem,\n    type ResponseFunctionCallOutputItemList as ResponseFunctionCallOutputItemList,\n    type ResponseFunctionToolCall as ResponseFunctionToolCall,\n    type ResponseFunctionToolCallItem as ResponseFunctionToolCallItem,\n    type ResponseFunctionToolCallOutputItem as ResponseFunctionToolCallOutputItem,\n    type ResponseFunctionWebSearch as ResponseFunctionWebSearch,\n    type ResponseImageGenCallCompletedEvent as ResponseImageGenCallCompletedEvent,\n    type ResponseImageGenCallGeneratingEvent as ResponseImageGenCallGeneratingEvent,\n    type ResponseImageGenCallInProgressEvent as ResponseImageGenCallInProgressEvent,\n    type ResponseImageGenCallPartialImageEvent as ResponseImageGenCallPartialImageEvent,\n    type ResponseInProgressEvent as ResponseInProgressEvent,\n    type ResponseIncludable as ResponseIncludable,\n    type ResponseIncompleteEvent as ResponseIncompleteEvent,\n    type ResponseInput as ResponseInput,\n    type ResponseInputAudio as ResponseInputAudio,\n    type ResponseInputContent as ResponseInputContent,\n    type ResponseInputFile as ResponseInputFile,\n    type ResponseInputFileContent as ResponseInputFileContent,\n    type ResponseInputImage as ResponseInputImage,\n    type ResponseInputImageContent as ResponseInputImageContent,\n    type ResponseInputItem as ResponseInputItem,\n    type ResponseInputMessageContentList as ResponseInputMessageContentList,\n    type ResponseInputMessageItem as ResponseInputMessageItem,\n    type ResponseInputText as ResponseInputText,\n    type ResponseInputTextContent as ResponseInputTextContent,\n    type ResponseItem as ResponseItem,\n    type ResponseMcpCallArgumentsDeltaEvent as ResponseMcpCallArgumentsDeltaEvent,\n    type ResponseMcpCallArgumentsDoneEvent as ResponseMcpCallArgumentsDoneEvent,\n    type ResponseMcpCallCompletedEvent as ResponseMcpCallCompletedEvent,\n    type ResponseMcpCallFailedEvent as ResponseMcpCallFailedEvent,\n    type ResponseMcpCallInProgressEvent as ResponseMcpCallInProgressEvent,\n    type ResponseMcpListToolsCompletedEvent as ResponseMcpListToolsCompletedEvent,\n    type ResponseMcpListToolsFailedEvent as ResponseMcpListToolsFailedEvent,\n    type ResponseMcpListToolsInProgressEvent as ResponseMcpListToolsInProgressEvent,\n    type ResponseOutputAudio as ResponseOutputAudio,\n    type ResponseOutputItem as ResponseOutputItem,\n    type ResponseOutputItemAddedEvent as ResponseOutputItemAddedEvent,\n    type ResponseOutputItemDoneEvent as ResponseOutputItemDoneEvent,\n    type ResponseOutputMessage as ResponseOutputMessage,\n    type ResponseOutputRefusal as ResponseOutputRefusal,\n    type ResponseOutputText as ResponseOutputText,\n    type ResponseOutputTextAnnotationAddedEvent as ResponseOutputTextAnnotationAddedEvent,\n    type ResponsePrompt as ResponsePrompt,\n    type ResponseQueuedEvent as ResponseQueuedEvent,\n    type ResponseReasoningItem as ResponseReasoningItem,\n    type ResponseReasoningSummaryPartAddedEvent as ResponseReasoningSummaryPartAddedEvent,\n    type ResponseReasoningSummaryPartDoneEvent as ResponseReasoningSummaryPartDoneEvent,\n    type ResponseReasoningSummaryTextDeltaEvent as ResponseReasoningSummaryTextDeltaEvent,\n    type ResponseReasoningSummaryTextDoneEvent as ResponseReasoningSummaryTextDoneEvent,\n    type ResponseReasoningTextDeltaEvent as ResponseReasoningTextDeltaEvent,\n    type ResponseReasoningTextDoneEvent as ResponseReasoningTextDoneEvent,\n    type ResponseRefusalDeltaEvent as ResponseRefusalDeltaEvent,\n    type ResponseRefusalDoneEvent as ResponseRefusalDoneEvent,\n    type ResponseStatus as ResponseStatus,\n    type ResponseStreamEvent as ResponseStreamEvent,\n    type ResponseTextConfig as ResponseTextConfig,\n    type ResponseTextDeltaEvent as ResponseTextDeltaEvent,\n    type ResponseTextDoneEvent as ResponseTextDoneEvent,\n    type ResponseUsage as ResponseUsage,\n    type ResponseWebSearchCallCompletedEvent as ResponseWebSearchCallCompletedEvent,\n    type ResponseWebSearchCallInProgressEvent as ResponseWebSearchCallInProgressEvent,\n    type ResponseWebSearchCallSearchingEvent as ResponseWebSearchCallSearchingEvent,\n    type Tool as Tool,\n    type ToolChoiceAllowed as ToolChoiceAllowed,\n    type ToolChoiceCustom as ToolChoiceCustom,\n    type ToolChoiceFunction as ToolChoiceFunction,\n    type ToolChoiceMcp as ToolChoiceMcp,\n    type ToolChoiceOptions as ToolChoiceOptions,\n    type ToolChoiceTypes as ToolChoiceTypes,\n    type WebSearchPreviewTool as WebSearchPreviewTool,\n    type WebSearchTool as WebSearchTool,\n    type ResponseCreateParams as ResponseCreateParams,\n    type ResponseCreateParamsNonStreaming as ResponseCreateParamsNonStreaming,\n    type ResponseCreateParamsStreaming as ResponseCreateParamsStreaming,\n    type ResponseRetrieveParams as ResponseRetrieveParams,\n    type ResponseRetrieveParamsNonStreaming as ResponseRetrieveParamsNonStreaming,\n    type ResponseRetrieveParamsStreaming as ResponseRetrieveParamsStreaming,\n  };\n\n  export {\n    InputItems as InputItems,\n    type ResponseItemList as ResponseItemList,\n    type InputItemListParams as InputItemListParams,\n  };\n\n  export {\n    InputTokens as InputTokens,\n    type InputTokenCountResponse as InputTokenCountResponse,\n    type InputTokenCountParams as InputTokenCountParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as FilesAPI from '../files';\nimport * as PartsAPI from './parts';\nimport { PartCreateParams, Parts, UploadPart } from './parts';\nimport { APIPromise } from '../../core/api-promise';\nimport { RequestOptions } from '../../internal/request-options';\nimport { path } from '../../internal/utils/path';\n\nexport class Uploads extends APIResource {\n  parts: PartsAPI.Parts = new PartsAPI.Parts(this._client);\n\n  /**\n   * Creates an intermediate\n   * [Upload](https://platform.openai.com/docs/api-reference/uploads/object) object\n   * that you can add\n   * [Parts](https://platform.openai.com/docs/api-reference/uploads/part-object) to.\n   * Currently, an Upload can accept at most 8 GB in total and expires after an hour\n   * after you create it.\n   *\n   * Once you complete the Upload, we will create a\n   * [File](https://platform.openai.com/docs/api-reference/files/object) object that\n   * contains all the parts you uploaded. This File is usable in the rest of our\n   * platform as a regular File object.\n   *\n   * For certain `purpose` values, the correct `mime_type` must be specified. Please\n   * refer to documentation for the\n   * [supported MIME types for your use case](https://platform.openai.com/docs/assistants/tools/file-search#supported-files).\n   *\n   * For guidance on the proper filename extensions for each purpose, please follow\n   * the documentation on\n   * [creating a File](https://platform.openai.com/docs/api-reference/files/create).\n   */\n  create(body: UploadCreateParams, options?: RequestOptions): APIPromise<Upload> {\n    return this._client.post('/uploads', { body, ...options });\n  }\n\n  /**\n   * Cancels the Upload. No Parts may be added after an Upload is cancelled.\n   */\n  cancel(uploadID: string, options?: RequestOptions): APIPromise<Upload> {\n    return this._client.post(path`/uploads/${uploadID}/cancel`, options);\n  }\n\n  /**\n   * Completes the\n   * [Upload](https://platform.openai.com/docs/api-reference/uploads/object).\n   *\n   * Within the returned Upload object, there is a nested\n   * [File](https://platform.openai.com/docs/api-reference/files/object) object that\n   * is ready to use in the rest of the platform.\n   *\n   * You can specify the order of the Parts by passing in an ordered list of the Part\n   * IDs.\n   *\n   * The number of bytes uploaded upon completion must match the number of bytes\n   * initially specified when creating the Upload object. No Parts may be added after\n   * an Upload is completed.\n   */\n  complete(uploadID: string, body: UploadCompleteParams, options?: RequestOptions): APIPromise<Upload> {\n    return this._client.post(path`/uploads/${uploadID}/complete`, { body, ...options });\n  }\n}\n\n/**\n * The Upload object can accept byte chunks in the form of Parts.\n */\nexport interface Upload {\n  /**\n   * The Upload unique identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The intended number of bytes to be uploaded.\n   */\n  bytes: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the Upload was created.\n   */\n  created_at: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the Upload will expire.\n   */\n  expires_at: number;\n\n  /**\n   * The name of the file to be uploaded.\n   */\n  filename: string;\n\n  /**\n   * The object type, which is always \"upload\".\n   */\n  object: 'upload';\n\n  /**\n   * The intended purpose of the file.\n   * [Please refer here](https://platform.openai.com/docs/api-reference/files/object#files/object-purpose)\n   * for acceptable values.\n   */\n  purpose: string;\n\n  /**\n   * The status of the Upload.\n   */\n  status: 'pending' | 'completed' | 'cancelled' | 'expired';\n\n  /**\n   * The `File` object represents a document that has been uploaded to OpenAI.\n   */\n  file?: FilesAPI.FileObject | null;\n}\n\nexport interface UploadCreateParams {\n  /**\n   * The number of bytes in the file you are uploading.\n   */\n  bytes: number;\n\n  /**\n   * The name of the file to upload.\n   */\n  filename: string;\n\n  /**\n   * The MIME type of the file.\n   *\n   * This must fall within the supported MIME types for your file purpose. See the\n   * supported MIME types for assistants and vision.\n   */\n  mime_type: string;\n\n  /**\n   * The intended purpose of the uploaded file.\n   *\n   * See the\n   * [documentation on File purposes](https://platform.openai.com/docs/api-reference/files/create#files-create-purpose).\n   */\n  purpose: FilesAPI.FilePurpose;\n\n  /**\n   * The expiration policy for a file. By default, files with `purpose=batch` expire\n   * after 30 days and all other files are persisted until they are manually deleted.\n   */\n  expires_after?: UploadCreateParams.ExpiresAfter;\n}\n\nexport namespace UploadCreateParams {\n  /**\n   * The expiration policy for a file. By default, files with `purpose=batch` expire\n   * after 30 days and all other files are persisted until they are manually deleted.\n   */\n  export interface ExpiresAfter {\n    /**\n     * Anchor timestamp after which the expiration policy applies. Supported anchors:\n     * `created_at`.\n     */\n    anchor: 'created_at';\n\n    /**\n     * The number of seconds after the anchor time that the file will expire. Must be\n     * between 3600 (1 hour) and 2592000 (30 days).\n     */\n    seconds: number;\n  }\n}\n\nexport interface UploadCompleteParams {\n  /**\n   * The ordered list of Part IDs.\n   */\n  part_ids: Array<string>;\n\n  /**\n   * The optional md5 checksum for the file contents to verify if the bytes uploaded\n   * matches what you expect.\n   */\n  md5?: string;\n}\n\nUploads.Parts = Parts;\n\nexport declare namespace Uploads {\n  export {\n    type Upload as Upload,\n    type UploadCreateParams as UploadCreateParams,\n    type UploadCompleteParams as UploadCompleteParams,\n  };\n\n  export { Parts as Parts, type UploadPart as UploadPart, type PartCreateParams as PartCreateParams };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as FilesAPI from './files';\nimport { VectorStoreFilesPage } from './files';\nimport * as VectorStoresAPI from './vector-stores';\nimport { APIPromise } from '../../core/api-promise';\nimport { CursorPage, type CursorPageParams, PagePromise } from '../../core/pagination';\nimport { buildHeaders } from '../../internal/headers';\nimport { RequestOptions } from '../../internal/request-options';\nimport { sleep } from '../../internal/utils/sleep';\nimport { type Uploadable } from '../../uploads';\nimport { allSettledWithThrow } from '../../lib/Util';\nimport { path } from '../../internal/utils/path';\n\nexport class FileBatches extends APIResource {\n  /**\n   * Create a vector store file batch.\n   */\n  create(\n    vectorStoreID: string,\n    body: FileBatchCreateParams,\n    options?: RequestOptions,\n  ): APIPromise<VectorStoreFileBatch> {\n    return this._client.post(path`/vector_stores/${vectorStoreID}/file_batches`, {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Retrieves a vector store file batch.\n   */\n  retrieve(\n    batchID: string,\n    params: FileBatchRetrieveParams,\n    options?: RequestOptions,\n  ): APIPromise<VectorStoreFileBatch> {\n    const { vector_store_id } = params;\n    return this._client.get(path`/vector_stores/${vector_store_id}/file_batches/${batchID}`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Cancel a vector store file batch. This attempts to cancel the processing of\n   * files in this batch as soon as possible.\n   */\n  cancel(\n    batchID: string,\n    params: FileBatchCancelParams,\n    options?: RequestOptions,\n  ): APIPromise<VectorStoreFileBatch> {\n    const { vector_store_id } = params;\n    return this._client.post(path`/vector_stores/${vector_store_id}/file_batches/${batchID}/cancel`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Create a vector store batch and poll until all files have been processed.\n   */\n  async createAndPoll(\n    vectorStoreId: string,\n    body: FileBatchCreateParams,\n    options?: RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFileBatch> {\n    const batch = await this.create(vectorStoreId, body);\n    return await this.poll(vectorStoreId, batch.id, options);\n  }\n\n  /**\n   * Returns a list of vector store files in a batch.\n   */\n  listFiles(\n    batchID: string,\n    params: FileBatchListFilesParams,\n    options?: RequestOptions,\n  ): PagePromise<VectorStoreFilesPage, FilesAPI.VectorStoreFile> {\n    const { vector_store_id, ...query } = params;\n    return this._client.getAPIList(\n      path`/vector_stores/${vector_store_id}/file_batches/${batchID}/files`,\n      CursorPage<FilesAPI.VectorStoreFile>,\n      { query, ...options, headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]) },\n    );\n  }\n\n  /**\n   * Wait for the given file batch to be processed.\n   *\n   * Note: this will return even if one of the files failed to process, you need to\n   * check batch.file_counts.failed_count to handle this case.\n   */\n  async poll(\n    vectorStoreID: string,\n    batchID: string,\n    options?: RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFileBatch> {\n    const headers = buildHeaders([\n      options?.headers,\n      {\n        'X-Stainless-Poll-Helper': 'true',\n        'X-Stainless-Custom-Poll-Interval': options?.pollIntervalMs?.toString() ?? undefined,\n      },\n    ]);\n\n    while (true) {\n      const { data: batch, response } = await this.retrieve(\n        batchID,\n        { vector_store_id: vectorStoreID },\n        {\n          ...options,\n          headers,\n        },\n      ).withResponse();\n\n      switch (batch.status) {\n        case 'in_progress':\n          let sleepInterval = 5000;\n\n          if (options?.pollIntervalMs) {\n            sleepInterval = options.pollIntervalMs;\n          } else {\n            const headerInterval = response.headers.get('openai-poll-after-ms');\n            if (headerInterval) {\n              const headerIntervalMs = parseInt(headerInterval);\n              if (!isNaN(headerIntervalMs)) {\n                sleepInterval = headerIntervalMs;\n              }\n            }\n          }\n          await sleep(sleepInterval);\n          break;\n        case 'failed':\n        case 'cancelled':\n        case 'completed':\n          return batch;\n      }\n    }\n  }\n\n  /**\n   * Uploads the given files concurrently and then creates a vector store file batch.\n   *\n   * The concurrency limit is configurable using the `maxConcurrency` parameter.\n   */\n  async uploadAndPoll(\n    vectorStoreId: string,\n    { files, fileIds = [] }: { files: Uploadable[]; fileIds?: string[] },\n    options?: RequestOptions & { pollIntervalMs?: number; maxConcurrency?: number },\n  ): Promise<VectorStoreFileBatch> {\n    if (files == null || files.length == 0) {\n      throw new Error(\n        `No \\`files\\` provided to process. If you've already uploaded files you should use \\`.createAndPoll()\\` instead`,\n      );\n    }\n\n    const configuredConcurrency = options?.maxConcurrency ?? 5;\n\n    // We cap the number of workers at the number of files (so we don't start any unnecessary workers)\n    const concurrencyLimit = Math.min(configuredConcurrency, files.length);\n\n    const client = this._client;\n    const fileIterator = files.values();\n    const allFileIds: string[] = [...fileIds];\n\n    // This code is based on this design. The libraries don't accommodate our environment limits.\n    // https://stackoverflow.com/questions/40639432/what-is-the-best-way-to-limit-concurrency-when-using-es6s-promise-all\n    async function processFiles(iterator: IterableIterator<Uploadable>) {\n      for (let item of iterator) {\n        const fileObj = await client.files.create({ file: item, purpose: 'assistants' }, options);\n        allFileIds.push(fileObj.id);\n      }\n    }\n\n    // Start workers to process results\n    const workers = Array(concurrencyLimit).fill(fileIterator).map(processFiles);\n\n    // Wait for all processing to complete.\n    await allSettledWithThrow(workers);\n\n    return await this.createAndPoll(vectorStoreId, {\n      file_ids: allFileIds,\n    });\n  }\n}\n\n/**\n * A batch of files attached to a vector store.\n */\nexport interface VectorStoreFileBatch {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the vector store files batch was\n   * created.\n   */\n  created_at: number;\n\n  file_counts: VectorStoreFileBatch.FileCounts;\n\n  /**\n   * The object type, which is always `vector_store.file_batch`.\n   */\n  object: 'vector_store.files_batch';\n\n  /**\n   * The status of the vector store files batch, which can be either `in_progress`,\n   * `completed`, `cancelled` or `failed`.\n   */\n  status: 'in_progress' | 'completed' | 'cancelled' | 'failed';\n\n  /**\n   * The ID of the\n   * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n   * that the [File](https://platform.openai.com/docs/api-reference/files) is\n   * attached to.\n   */\n  vector_store_id: string;\n}\n\nexport namespace VectorStoreFileBatch {\n  export interface FileCounts {\n    /**\n     * The number of files that where cancelled.\n     */\n    cancelled: number;\n\n    /**\n     * The number of files that have been processed.\n     */\n    completed: number;\n\n    /**\n     * The number of files that have failed to process.\n     */\n    failed: number;\n\n    /**\n     * The number of files that are currently being processed.\n     */\n    in_progress: number;\n\n    /**\n     * The total number of files.\n     */\n    total: number;\n  }\n}\n\nexport interface FileBatchCreateParams {\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard. Keys are strings with a maximum\n   * length of 64 characters. Values are strings with a maximum length of 512\n   * characters, booleans, or numbers.\n   */\n  attributes?: { [key: string]: string | number | boolean } | null;\n\n  /**\n   * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n   * strategy. Only applicable if `file_ids` is non-empty.\n   */\n  chunking_strategy?: VectorStoresAPI.FileChunkingStrategyParam;\n\n  /**\n   * A list of [File](https://platform.openai.com/docs/api-reference/files) IDs that\n   * the vector store should use. Useful for tools like `file_search` that can access\n   * files. If `attributes` or `chunking_strategy` are provided, they will be applied\n   * to all files in the batch. Mutually exclusive with `files`.\n   */\n  file_ids?: Array<string>;\n\n  /**\n   * A list of objects that each include a `file_id` plus optional `attributes` or\n   * `chunking_strategy`. Use this when you need to override metadata for specific\n   * files. The global `attributes` or `chunking_strategy` will be ignored and must\n   * be specified for each file. Mutually exclusive with `file_ids`.\n   */\n  files?: Array<FileBatchCreateParams.File>;\n}\n\nexport namespace FileBatchCreateParams {\n  export interface File {\n    /**\n     * A [File](https://platform.openai.com/docs/api-reference/files) ID that the\n     * vector store should use. Useful for tools like `file_search` that can access\n     * files.\n     */\n    file_id: string;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format, and\n     * querying for objects via API or the dashboard. Keys are strings with a maximum\n     * length of 64 characters. Values are strings with a maximum length of 512\n     * characters, booleans, or numbers.\n     */\n    attributes?: { [key: string]: string | number | boolean } | null;\n\n    /**\n     * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n     * strategy. Only applicable if `file_ids` is non-empty.\n     */\n    chunking_strategy?: VectorStoresAPI.FileChunkingStrategyParam;\n  }\n}\n\nexport interface FileBatchRetrieveParams {\n  /**\n   * The ID of the vector store that the file batch belongs to.\n   */\n  vector_store_id: string;\n}\n\nexport interface FileBatchCancelParams {\n  /**\n   * The ID of the vector store that the file batch belongs to.\n   */\n  vector_store_id: string;\n}\n\nexport interface FileBatchListFilesParams extends CursorPageParams {\n  /**\n   * Path param: The ID of the vector store that the files belong to.\n   */\n  vector_store_id: string;\n\n  /**\n   * Query param: A cursor for use in pagination. `before` is an object ID that\n   * defines your place in the list. For instance, if you make a list request and\n   * receive 100 objects, starting with obj_foo, your subsequent call can include\n   * before=obj_foo in order to fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Query param: Filter by file status. One of `in_progress`, `completed`, `failed`,\n   * `cancelled`.\n   */\n  filter?: 'in_progress' | 'completed' | 'failed' | 'cancelled';\n\n  /**\n   * Query param: Sort order by the `created_at` timestamp of the objects. `asc` for\n   * ascending order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport declare namespace FileBatches {\n  export {\n    type VectorStoreFileBatch as VectorStoreFileBatch,\n    type FileBatchCreateParams as FileBatchCreateParams,\n    type FileBatchRetrieveParams as FileBatchRetrieveParams,\n    type FileBatchCancelParams as FileBatchCancelParams,\n    type FileBatchListFilesParams as FileBatchListFilesParams,\n  };\n}\n\nexport { type VectorStoreFilesPage };\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport { APIPromise } from '../../../core/api-promise';\nimport { buildHeaders } from '../../../internal/headers';\nimport { RequestOptions } from '../../../internal/request-options';\n\nexport class TranscriptionSessions extends APIResource {\n  /**\n   * Create an ephemeral API token for use in client-side applications with the\n   * Realtime API specifically for realtime transcriptions. Can be configured with\n   * the same session parameters as the `transcription_session.update` client event.\n   *\n   * It responds with a session object, plus a `client_secret` key which contains a\n   * usable ephemeral API token that can be used to authenticate browser clients for\n   * the Realtime API.\n   *\n   * @example\n   * ```ts\n   * const transcriptionSession =\n   *   await client.beta.realtime.transcriptionSessions.create();\n   * ```\n   */\n  create(body: TranscriptionSessionCreateParams, options?: RequestOptions): APIPromise<TranscriptionSession> {\n    return this._client.post('/realtime/transcription_sessions', {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n}\n\n/**\n * A new Realtime transcription session configuration.\n *\n * When a session is created on the server via REST API, the session object also\n * contains an ephemeral key. Default TTL for keys is 10 minutes. This property is\n * not present when a session is updated via the WebSocket API.\n */\nexport interface TranscriptionSession {\n  /**\n   * Ephemeral key returned by the API. Only present when the session is created on\n   * the server via REST API.\n   */\n  client_secret: TranscriptionSession.ClientSecret;\n\n  /**\n   * The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n   */\n  input_audio_format?: string;\n\n  /**\n   * Configuration of the transcription model.\n   */\n  input_audio_transcription?: TranscriptionSession.InputAudioTranscription;\n\n  /**\n   * The set of modalities the model can respond with. To disable audio, set this to\n   * [\"text\"].\n   */\n  modalities?: Array<'text' | 'audio'>;\n\n  /**\n   * Configuration for turn detection. Can be set to `null` to turn off. Server VAD\n   * means that the model will detect the start and end of speech based on audio\n   * volume and respond at the end of user speech.\n   */\n  turn_detection?: TranscriptionSession.TurnDetection;\n}\n\nexport namespace TranscriptionSession {\n  /**\n   * Ephemeral key returned by the API. Only present when the session is created on\n   * the server via REST API.\n   */\n  export interface ClientSecret {\n    /**\n     * Timestamp for when the token expires. Currently, all tokens expire after one\n     * minute.\n     */\n    expires_at: number;\n\n    /**\n     * Ephemeral key usable in client environments to authenticate connections to the\n     * Realtime API. Use this in client-side environments rather than a standard API\n     * token, which should only be used server-side.\n     */\n    value: string;\n  }\n\n  /**\n   * Configuration of the transcription model.\n   */\n  export interface InputAudioTranscription {\n    /**\n     * The language of the input audio. Supplying the input language in\n     * [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`)\n     * format will improve accuracy and latency.\n     */\n    language?: string;\n\n    /**\n     * The model to use for transcription. Can be `gpt-4o-transcribe`,\n     * `gpt-4o-mini-transcribe`, or `whisper-1`.\n     */\n    model?: 'gpt-4o-transcribe' | 'gpt-4o-mini-transcribe' | 'whisper-1';\n\n    /**\n     * An optional text to guide the model's style or continue a previous audio\n     * segment. The\n     * [prompt](https://platform.openai.com/docs/guides/speech-to-text#prompting)\n     * should match the audio language.\n     */\n    prompt?: string;\n  }\n\n  /**\n   * Configuration for turn detection. Can be set to `null` to turn off. Server VAD\n   * means that the model will detect the start and end of speech based on audio\n   * volume and respond at the end of user speech.\n   */\n  export interface TurnDetection {\n    /**\n     * Amount of audio to include before the VAD detected speech (in milliseconds).\n     * Defaults to 300ms.\n     */\n    prefix_padding_ms?: number;\n\n    /**\n     * Duration of silence to detect speech stop (in milliseconds). Defaults to 500ms.\n     * With shorter values the model will respond more quickly, but may jump in on\n     * short pauses from the user.\n     */\n    silence_duration_ms?: number;\n\n    /**\n     * Activation threshold for VAD (0.0 to 1.0), this defaults to 0.5. A higher\n     * threshold will require louder audio to activate the model, and thus might\n     * perform better in noisy environments.\n     */\n    threshold?: number;\n\n    /**\n     * Type of turn detection, only `server_vad` is currently supported.\n     */\n    type?: string;\n  }\n}\n\nexport interface TranscriptionSessionCreateParams {\n  /**\n   * Configuration options for the generated client secret.\n   */\n  client_secret?: TranscriptionSessionCreateParams.ClientSecret;\n\n  /**\n   * The set of items to include in the transcription. Current available items are:\n   *\n   * - `item.input_audio_transcription.logprobs`\n   */\n  include?: Array<string>;\n\n  /**\n   * The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`. For\n   * `pcm16`, input audio must be 16-bit PCM at a 24kHz sample rate, single channel\n   * (mono), and little-endian byte order.\n   */\n  input_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n  /**\n   * Configuration for input audio noise reduction. This can be set to `null` to turn\n   * off. Noise reduction filters audio added to the input audio buffer before it is\n   * sent to VAD and the model. Filtering the audio can improve VAD and turn\n   * detection accuracy (reducing false positives) and model performance by improving\n   * perception of the input audio.\n   */\n  input_audio_noise_reduction?: TranscriptionSessionCreateParams.InputAudioNoiseReduction;\n\n  /**\n   * Configuration for input audio transcription. The client can optionally set the\n   * language and prompt for transcription, these offer additional guidance to the\n   * transcription service.\n   */\n  input_audio_transcription?: TranscriptionSessionCreateParams.InputAudioTranscription;\n\n  /**\n   * The set of modalities the model can respond with. To disable audio, set this to\n   * [\"text\"].\n   */\n  modalities?: Array<'text' | 'audio'>;\n\n  /**\n   * Configuration for turn detection, ether Server VAD or Semantic VAD. This can be\n   * set to `null` to turn off, in which case the client must manually trigger model\n   * response. Server VAD means that the model will detect the start and end of\n   * speech based on audio volume and respond at the end of user speech. Semantic VAD\n   * is more advanced and uses a turn detection model (in conjunction with VAD) to\n   * semantically estimate whether the user has finished speaking, then dynamically\n   * sets a timeout based on this probability. For example, if user audio trails off\n   * with \"uhhm\", the model will score a low probability of turn end and wait longer\n   * for the user to continue speaking. This can be useful for more natural\n   * conversations, but may have a higher latency.\n   */\n  turn_detection?: TranscriptionSessionCreateParams.TurnDetection;\n}\n\nexport namespace TranscriptionSessionCreateParams {\n  /**\n   * Configuration options for the generated client secret.\n   */\n  export interface ClientSecret {\n    /**\n     * Configuration for the ephemeral token expiration.\n     */\n    expires_at?: ClientSecret.ExpiresAt;\n  }\n\n  export namespace ClientSecret {\n    /**\n     * Configuration for the ephemeral token expiration.\n     */\n    export interface ExpiresAt {\n      /**\n       * The anchor point for the ephemeral token expiration. Only `created_at` is\n       * currently supported.\n       */\n      anchor?: 'created_at';\n\n      /**\n       * The number of seconds from the anchor point to the expiration. Select a value\n       * between `10` and `7200`.\n       */\n      seconds?: number;\n    }\n  }\n\n  /**\n   * Configuration for input audio noise reduction. This can be set to `null` to turn\n   * off. Noise reduction filters audio added to the input audio buffer before it is\n   * sent to VAD and the model. Filtering the audio can improve VAD and turn\n   * detection accuracy (reducing false positives) and model performance by improving\n   * perception of the input audio.\n   */\n  export interface InputAudioNoiseReduction {\n    /**\n     * Type of noise reduction. `near_field` is for close-talking microphones such as\n     * headphones, `far_field` is for far-field microphones such as laptop or\n     * conference room microphones.\n     */\n    type?: 'near_field' | 'far_field';\n  }\n\n  /**\n   * Configuration for input audio transcription. The client can optionally set the\n   * language and prompt for transcription, these offer additional guidance to the\n   * transcription service.\n   */\n  export interface InputAudioTranscription {\n    /**\n     * The language of the input audio. Supplying the input language in\n     * [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`)\n     * format will improve accuracy and latency.\n     */\n    language?: string;\n\n    /**\n     * The model to use for transcription, current options are `gpt-4o-transcribe`,\n     * `gpt-4o-mini-transcribe`, and `whisper-1`.\n     */\n    model?: 'gpt-4o-transcribe' | 'gpt-4o-mini-transcribe' | 'whisper-1';\n\n    /**\n     * An optional text to guide the model's style or continue a previous audio\n     * segment. For `whisper-1`, the\n     * [prompt is a list of keywords](https://platform.openai.com/docs/guides/speech-to-text#prompting).\n     * For `gpt-4o-transcribe` models, the prompt is a free text string, for example\n     * \"expect words related to technology\".\n     */\n    prompt?: string;\n  }\n\n  /**\n   * Configuration for turn detection, ether Server VAD or Semantic VAD. This can be\n   * set to `null` to turn off, in which case the client must manually trigger model\n   * response. Server VAD means that the model will detect the start and end of\n   * speech based on audio volume and respond at the end of user speech. Semantic VAD\n   * is more advanced and uses a turn detection model (in conjunction with VAD) to\n   * semantically estimate whether the user has finished speaking, then dynamically\n   * sets a timeout based on this probability. For example, if user audio trails off\n   * with \"uhhm\", the model will score a low probability of turn end and wait longer\n   * for the user to continue speaking. This can be useful for more natural\n   * conversations, but may have a higher latency.\n   */\n  export interface TurnDetection {\n    /**\n     * Whether or not to automatically generate a response when a VAD stop event\n     * occurs. Not available for transcription sessions.\n     */\n    create_response?: boolean;\n\n    /**\n     * Used only for `semantic_vad` mode. The eagerness of the model to respond. `low`\n     * will wait longer for the user to continue speaking, `high` will respond more\n     * quickly. `auto` is the default and is equivalent to `medium`.\n     */\n    eagerness?: 'low' | 'medium' | 'high' | 'auto';\n\n    /**\n     * Whether or not to automatically interrupt any ongoing response with output to\n     * the default conversation (i.e. `conversation` of `auto`) when a VAD start event\n     * occurs. Not available for transcription sessions.\n     */\n    interrupt_response?: boolean;\n\n    /**\n     * Used only for `server_vad` mode. Amount of audio to include before the VAD\n     * detected speech (in milliseconds). Defaults to 300ms.\n     */\n    prefix_padding_ms?: number;\n\n    /**\n     * Used only for `server_vad` mode. Duration of silence to detect speech stop (in\n     * milliseconds). Defaults to 500ms. With shorter values the model will respond\n     * more quickly, but may jump in on short pauses from the user.\n     */\n    silence_duration_ms?: number;\n\n    /**\n     * Used only for `server_vad` mode. Activation threshold for VAD (0.0 to 1.0), this\n     * defaults to 0.5. A higher threshold will require louder audio to activate the\n     * model, and thus might perform better in noisy environments.\n     */\n    threshold?: number;\n\n    /**\n     * Type of turn detection.\n     */\n    type?: 'server_vad' | 'semantic_vad';\n  }\n}\n\nexport declare namespace TranscriptionSessions {\n  export {\n    type TranscriptionSession as TranscriptionSession,\n    type TranscriptionSessionCreateParams as TranscriptionSessionCreateParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as VectorStoresAPI from './vector-stores';\nimport { APIPromise } from '../../core/api-promise';\nimport { CursorPage, type CursorPageParams, PagePromise, Page } from '../../core/pagination';\nimport { buildHeaders } from '../../internal/headers';\nimport { RequestOptions } from '../../internal/request-options';\nimport { sleep } from '../../internal/utils';\nimport { Uploadable } from '../../uploads';\nimport { path } from '../../internal/utils/path';\n\nexport class Files extends APIResource {\n  /**\n   * Create a vector store file by attaching a\n   * [File](https://platform.openai.com/docs/api-reference/files) to a\n   * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object).\n   */\n  create(\n    vectorStoreID: string,\n    body: FileCreateParams,\n    options?: RequestOptions,\n  ): APIPromise<VectorStoreFile> {\n    return this._client.post(path`/vector_stores/${vectorStoreID}/files`, {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Retrieves a vector store file.\n   */\n  retrieve(\n    fileID: string,\n    params: FileRetrieveParams,\n    options?: RequestOptions,\n  ): APIPromise<VectorStoreFile> {\n    const { vector_store_id } = params;\n    return this._client.get(path`/vector_stores/${vector_store_id}/files/${fileID}`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Update attributes on a vector store file.\n   */\n  update(fileID: string, params: FileUpdateParams, options?: RequestOptions): APIPromise<VectorStoreFile> {\n    const { vector_store_id, ...body } = params;\n    return this._client.post(path`/vector_stores/${vector_store_id}/files/${fileID}`, {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Returns a list of vector store files.\n   */\n  list(\n    vectorStoreID: string,\n    query: FileListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<VectorStoreFilesPage, VectorStoreFile> {\n    return this._client.getAPIList(path`/vector_stores/${vectorStoreID}/files`, CursorPage<VectorStoreFile>, {\n      query,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Delete a vector store file. This will remove the file from the vector store but\n   * the file itself will not be deleted. To delete the file, use the\n   * [delete file](https://platform.openai.com/docs/api-reference/files/delete)\n   * endpoint.\n   */\n  delete(\n    fileID: string,\n    params: FileDeleteParams,\n    options?: RequestOptions,\n  ): APIPromise<VectorStoreFileDeleted> {\n    const { vector_store_id } = params;\n    return this._client.delete(path`/vector_stores/${vector_store_id}/files/${fileID}`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Attach a file to the given vector store and wait for it to be processed.\n   */\n  async createAndPoll(\n    vectorStoreId: string,\n    body: FileCreateParams,\n    options?: RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFile> {\n    const file = await this.create(vectorStoreId, body, options);\n    return await this.poll(vectorStoreId, file.id, options);\n  }\n  /**\n   * Wait for the vector store file to finish processing.\n   *\n   * Note: this will return even if the file failed to process, you need to check\n   * file.last_error and file.status to handle these cases\n   */\n  async poll(\n    vectorStoreID: string,\n    fileID: string,\n    options?: RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFile> {\n    const headers = buildHeaders([\n      options?.headers,\n      {\n        'X-Stainless-Poll-Helper': 'true',\n        'X-Stainless-Custom-Poll-Interval': options?.pollIntervalMs?.toString() ?? undefined,\n      },\n    ]);\n\n    while (true) {\n      const fileResponse = await this.retrieve(\n        fileID,\n        {\n          vector_store_id: vectorStoreID,\n        },\n        { ...options, headers },\n      ).withResponse();\n\n      const file = fileResponse.data;\n\n      switch (file.status) {\n        case 'in_progress':\n          let sleepInterval = 5000;\n\n          if (options?.pollIntervalMs) {\n            sleepInterval = options.pollIntervalMs;\n          } else {\n            const headerInterval = fileResponse.response.headers.get('openai-poll-after-ms');\n            if (headerInterval) {\n              const headerIntervalMs = parseInt(headerInterval);\n              if (!isNaN(headerIntervalMs)) {\n                sleepInterval = headerIntervalMs;\n              }\n            }\n          }\n          await sleep(sleepInterval);\n          break;\n        case 'failed':\n        case 'completed':\n          return file;\n      }\n    }\n  }\n  /**\n   * Upload a file to the `files` API and then attach it to the given vector store.\n   *\n   * Note the file will be asynchronously processed (you can use the alternative\n   * polling helper method to wait for processing to complete).\n   */\n  async upload(vectorStoreId: string, file: Uploadable, options?: RequestOptions): Promise<VectorStoreFile> {\n    const fileInfo = await this._client.files.create({ file: file, purpose: 'assistants' }, options);\n    return this.create(vectorStoreId, { file_id: fileInfo.id }, options);\n  }\n  /**\n   * Add a file to a vector store and poll until processing is complete.\n   */\n  async uploadAndPoll(\n    vectorStoreId: string,\n    file: Uploadable,\n    options?: RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFile> {\n    const fileInfo = await this.upload(vectorStoreId, file, options);\n    return await this.poll(vectorStoreId, fileInfo.id, options);\n  }\n\n  /**\n   * Retrieve the parsed contents of a vector store file.\n   */\n  content(\n    fileID: string,\n    params: FileContentParams,\n    options?: RequestOptions,\n  ): PagePromise<FileContentResponsesPage, FileContentResponse> {\n    const { vector_store_id } = params;\n    return this._client.getAPIList(\n      path`/vector_stores/${vector_store_id}/files/${fileID}/content`,\n      Page<FileContentResponse>,\n      { ...options, headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]) },\n    );\n  }\n}\n\nexport type VectorStoreFilesPage = CursorPage<VectorStoreFile>;\n\n// Note: no pagination actually occurs yet, this is for forwards-compatibility.\nexport type FileContentResponsesPage = Page<FileContentResponse>;\n\n/**\n * A list of files attached to a vector store.\n */\nexport interface VectorStoreFile {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the vector store file was created.\n   */\n  created_at: number;\n\n  /**\n   * The last error associated with this vector store file. Will be `null` if there\n   * are no errors.\n   */\n  last_error: VectorStoreFile.LastError | null;\n\n  /**\n   * The object type, which is always `vector_store.file`.\n   */\n  object: 'vector_store.file';\n\n  /**\n   * The status of the vector store file, which can be either `in_progress`,\n   * `completed`, `cancelled`, or `failed`. The status `completed` indicates that the\n   * vector store file is ready for use.\n   */\n  status: 'in_progress' | 'completed' | 'cancelled' | 'failed';\n\n  /**\n   * The total vector store usage in bytes. Note that this may be different from the\n   * original file size.\n   */\n  usage_bytes: number;\n\n  /**\n   * The ID of the\n   * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n   * that the [File](https://platform.openai.com/docs/api-reference/files) is\n   * attached to.\n   */\n  vector_store_id: string;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard. Keys are strings with a maximum\n   * length of 64 characters. Values are strings with a maximum length of 512\n   * characters, booleans, or numbers.\n   */\n  attributes?: { [key: string]: string | number | boolean } | null;\n\n  /**\n   * The strategy used to chunk the file.\n   */\n  chunking_strategy?: VectorStoresAPI.FileChunkingStrategy;\n}\n\nexport namespace VectorStoreFile {\n  /**\n   * The last error associated with this vector store file. Will be `null` if there\n   * are no errors.\n   */\n  export interface LastError {\n    /**\n     * One of `server_error`, `unsupported_file`, or `invalid_file`.\n     */\n    code: 'server_error' | 'unsupported_file' | 'invalid_file';\n\n    /**\n     * A human-readable description of the error.\n     */\n    message: string;\n  }\n}\n\nexport interface VectorStoreFileDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'vector_store.file.deleted';\n}\n\nexport interface FileContentResponse {\n  /**\n   * The text content\n   */\n  text?: string;\n\n  /**\n   * The content type (currently only `\"text\"`)\n   */\n  type?: string;\n}\n\nexport interface FileCreateParams {\n  /**\n   * A [File](https://platform.openai.com/docs/api-reference/files) ID that the\n   * vector store should use. Useful for tools like `file_search` that can access\n   * files.\n   */\n  file_id: string;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard. Keys are strings with a maximum\n   * length of 64 characters. Values are strings with a maximum length of 512\n   * characters, booleans, or numbers.\n   */\n  attributes?: { [key: string]: string | number | boolean } | null;\n\n  /**\n   * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n   * strategy. Only applicable if `file_ids` is non-empty.\n   */\n  chunking_strategy?: VectorStoresAPI.FileChunkingStrategyParam;\n}\n\nexport interface FileRetrieveParams {\n  /**\n   * The ID of the vector store that the file belongs to.\n   */\n  vector_store_id: string;\n}\n\nexport interface FileUpdateParams {\n  /**\n   * Path param: The ID of the vector store the file belongs to.\n   */\n  vector_store_id: string;\n\n  /**\n   * Body param: Set of 16 key-value pairs that can be attached to an object. This\n   * can be useful for storing additional information about the object in a\n   * structured format, and querying for objects via API or the dashboard. Keys are\n   * strings with a maximum length of 64 characters. Values are strings with a\n   * maximum length of 512 characters, booleans, or numbers.\n   */\n  attributes: { [key: string]: string | number | boolean } | null;\n}\n\nexport interface FileListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * starting with obj_foo, your subsequent call can include before=obj_foo in order\n   * to fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.\n   */\n  filter?: 'in_progress' | 'completed' | 'failed' | 'cancelled';\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport interface FileDeleteParams {\n  /**\n   * The ID of the vector store that the file belongs to.\n   */\n  vector_store_id: string;\n}\n\nexport interface FileContentParams {\n  /**\n   * The ID of the vector store.\n   */\n  vector_store_id: string;\n}\n\nexport declare namespace Files {\n  export {\n    type VectorStoreFile as VectorStoreFile,\n    type VectorStoreFileDeleted as VectorStoreFileDeleted,\n    type FileContentResponse as FileContentResponse,\n    type VectorStoreFilesPage as VectorStoreFilesPage,\n    type FileContentResponsesPage as FileContentResponsesPage,\n    type FileCreateParams as FileCreateParams,\n    type FileRetrieveParams as FileRetrieveParams,\n    type FileUpdateParams as FileUpdateParams,\n    type FileListParams as FileListParams,\n    type FileDeleteParams as FileDeleteParams,\n    type FileContentParams as FileContentParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../core/resource';\nimport * as Shared from '../shared';\nimport * as FileBatchesAPI from './file-batches';\nimport {\n  FileBatchCancelParams,\n  FileBatchCreateParams,\n  FileBatchListFilesParams,\n  FileBatchRetrieveParams,\n  FileBatches,\n  VectorStoreFileBatch,\n} from './file-batches';\nimport * as FilesAPI from './files';\nimport {\n  FileContentParams,\n  FileContentResponse,\n  FileContentResponsesPage,\n  FileCreateParams,\n  FileDeleteParams,\n  FileListParams,\n  FileRetrieveParams,\n  FileUpdateParams,\n  Files,\n  VectorStoreFile,\n  VectorStoreFileDeleted,\n  VectorStoreFilesPage,\n} from './files';\nimport { APIPromise } from '../../core/api-promise';\nimport { CursorPage, type CursorPageParams, Page, PagePromise } from '../../core/pagination';\nimport { buildHeaders } from '../../internal/headers';\nimport { RequestOptions } from '../../internal/request-options';\nimport { path } from '../../internal/utils/path';\n\nexport class VectorStores extends APIResource {\n  files: FilesAPI.Files = new FilesAPI.Files(this._client);\n  fileBatches: FileBatchesAPI.FileBatches = new FileBatchesAPI.FileBatches(this._client);\n\n  /**\n   * Create a vector store.\n   */\n  create(body: VectorStoreCreateParams, options?: RequestOptions): APIPromise<VectorStore> {\n    return this._client.post('/vector_stores', {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Retrieves a vector store.\n   */\n  retrieve(vectorStoreID: string, options?: RequestOptions): APIPromise<VectorStore> {\n    return this._client.get(path`/vector_stores/${vectorStoreID}`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Modifies a vector store.\n   */\n  update(\n    vectorStoreID: string,\n    body: VectorStoreUpdateParams,\n    options?: RequestOptions,\n  ): APIPromise<VectorStore> {\n    return this._client.post(path`/vector_stores/${vectorStoreID}`, {\n      body,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Returns a list of vector stores.\n   */\n  list(\n    query: VectorStoreListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<VectorStoresPage, VectorStore> {\n    return this._client.getAPIList('/vector_stores', CursorPage<VectorStore>, {\n      query,\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Delete a vector store.\n   */\n  delete(vectorStoreID: string, options?: RequestOptions): APIPromise<VectorStoreDeleted> {\n    return this._client.delete(path`/vector_stores/${vectorStoreID}`, {\n      ...options,\n      headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n    });\n  }\n\n  /**\n   * Search a vector store for relevant chunks based on a query and file attributes\n   * filter.\n   */\n  search(\n    vectorStoreID: string,\n    body: VectorStoreSearchParams,\n    options?: RequestOptions,\n  ): PagePromise<VectorStoreSearchResponsesPage, VectorStoreSearchResponse> {\n    return this._client.getAPIList(\n      path`/vector_stores/${vectorStoreID}/search`,\n      Page<VectorStoreSearchResponse>,\n      {\n        body,\n        method: 'post',\n        ...options,\n        headers: buildHeaders([{ 'OpenAI-Beta': 'assistants=v2' }, options?.headers]),\n      },\n    );\n  }\n}\n\nexport type VectorStoresPage = CursorPage<VectorStore>;\n\n// Note: no pagination actually occurs yet, this is for forwards-compatibility.\nexport type VectorStoreSearchResponsesPage = Page<VectorStoreSearchResponse>;\n\n/**\n * The default strategy. This strategy currently uses a `max_chunk_size_tokens` of\n * `800` and `chunk_overlap_tokens` of `400`.\n */\nexport interface AutoFileChunkingStrategyParam {\n  /**\n   * Always `auto`.\n   */\n  type: 'auto';\n}\n\n/**\n * The strategy used to chunk the file.\n */\nexport type FileChunkingStrategy = StaticFileChunkingStrategyObject | OtherFileChunkingStrategyObject;\n\n/**\n * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n * strategy. Only applicable if `file_ids` is non-empty.\n */\nexport type FileChunkingStrategyParam = AutoFileChunkingStrategyParam | StaticFileChunkingStrategyObjectParam;\n\n/**\n * This is returned when the chunking strategy is unknown. Typically, this is\n * because the file was indexed before the `chunking_strategy` concept was\n * introduced in the API.\n */\nexport interface OtherFileChunkingStrategyObject {\n  /**\n   * Always `other`.\n   */\n  type: 'other';\n}\n\nexport interface StaticFileChunkingStrategy {\n  /**\n   * The number of tokens that overlap between chunks. The default value is `400`.\n   *\n   * Note that the overlap must not exceed half of `max_chunk_size_tokens`.\n   */\n  chunk_overlap_tokens: number;\n\n  /**\n   * The maximum number of tokens in each chunk. The default value is `800`. The\n   * minimum value is `100` and the maximum value is `4096`.\n   */\n  max_chunk_size_tokens: number;\n}\n\nexport interface StaticFileChunkingStrategyObject {\n  static: StaticFileChunkingStrategy;\n\n  /**\n   * Always `static`.\n   */\n  type: 'static';\n}\n\n/**\n * Customize your own chunking strategy by setting chunk size and chunk overlap.\n */\nexport interface StaticFileChunkingStrategyObjectParam {\n  static: StaticFileChunkingStrategy;\n\n  /**\n   * Always `static`.\n   */\n  type: 'static';\n}\n\n/**\n * A vector store is a collection of processed files can be used by the\n * `file_search` tool.\n */\nexport interface VectorStore {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the vector store was created.\n   */\n  created_at: number;\n\n  file_counts: VectorStore.FileCounts;\n\n  /**\n   * The Unix timestamp (in seconds) for when the vector store was last active.\n   */\n  last_active_at: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata: Shared.Metadata | null;\n\n  /**\n   * The name of the vector store.\n   */\n  name: string;\n\n  /**\n   * The object type, which is always `vector_store`.\n   */\n  object: 'vector_store';\n\n  /**\n   * The status of the vector store, which can be either `expired`, `in_progress`, or\n   * `completed`. A status of `completed` indicates that the vector store is ready\n   * for use.\n   */\n  status: 'expired' | 'in_progress' | 'completed';\n\n  /**\n   * The total number of bytes used by the files in the vector store.\n   */\n  usage_bytes: number;\n\n  /**\n   * The expiration policy for a vector store.\n   */\n  expires_after?: VectorStore.ExpiresAfter;\n\n  /**\n   * The Unix timestamp (in seconds) for when the vector store will expire.\n   */\n  expires_at?: number | null;\n}\n\nexport namespace VectorStore {\n  export interface FileCounts {\n    /**\n     * The number of files that were cancelled.\n     */\n    cancelled: number;\n\n    /**\n     * The number of files that have been successfully processed.\n     */\n    completed: number;\n\n    /**\n     * The number of files that have failed to process.\n     */\n    failed: number;\n\n    /**\n     * The number of files that are currently being processed.\n     */\n    in_progress: number;\n\n    /**\n     * The total number of files.\n     */\n    total: number;\n  }\n\n  /**\n   * The expiration policy for a vector store.\n   */\n  export interface ExpiresAfter {\n    /**\n     * Anchor timestamp after which the expiration policy applies. Supported anchors:\n     * `last_active_at`.\n     */\n    anchor: 'last_active_at';\n\n    /**\n     * The number of days after the anchor time that the vector store will expire.\n     */\n    days: number;\n  }\n}\n\nexport interface VectorStoreDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'vector_store.deleted';\n}\n\nexport interface VectorStoreSearchResponse {\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard. Keys are strings with a maximum\n   * length of 64 characters. Values are strings with a maximum length of 512\n   * characters, booleans, or numbers.\n   */\n  attributes: { [key: string]: string | number | boolean } | null;\n\n  /**\n   * Content chunks from the file.\n   */\n  content: Array<VectorStoreSearchResponse.Content>;\n\n  /**\n   * The ID of the vector store file.\n   */\n  file_id: string;\n\n  /**\n   * The name of the vector store file.\n   */\n  filename: string;\n\n  /**\n   * The similarity score for the result.\n   */\n  score: number;\n}\n\nexport namespace VectorStoreSearchResponse {\n  export interface Content {\n    /**\n     * The text content returned from search.\n     */\n    text: string;\n\n    /**\n     * The type of content.\n     */\n    type: 'text';\n  }\n}\n\nexport interface VectorStoreCreateParams {\n  /**\n   * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n   * strategy. Only applicable if `file_ids` is non-empty.\n   */\n  chunking_strategy?: FileChunkingStrategyParam;\n\n  /**\n   * A description for the vector store. Can be used to describe the vector store's\n   * purpose.\n   */\n  description?: string;\n\n  /**\n   * The expiration policy for a vector store.\n   */\n  expires_after?: VectorStoreCreateParams.ExpiresAfter;\n\n  /**\n   * A list of [File](https://platform.openai.com/docs/api-reference/files) IDs that\n   * the vector store should use. Useful for tools like `file_search` that can access\n   * files.\n   */\n  file_ids?: Array<string>;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The name of the vector store.\n   */\n  name?: string;\n}\n\nexport namespace VectorStoreCreateParams {\n  /**\n   * The expiration policy for a vector store.\n   */\n  export interface ExpiresAfter {\n    /**\n     * Anchor timestamp after which the expiration policy applies. Supported anchors:\n     * `last_active_at`.\n     */\n    anchor: 'last_active_at';\n\n    /**\n     * The number of days after the anchor time that the vector store will expire.\n     */\n    days: number;\n  }\n}\n\nexport interface VectorStoreUpdateParams {\n  /**\n   * The expiration policy for a vector store.\n   */\n  expires_after?: VectorStoreUpdateParams.ExpiresAfter | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The name of the vector store.\n   */\n  name?: string | null;\n}\n\nexport namespace VectorStoreUpdateParams {\n  /**\n   * The expiration policy for a vector store.\n   */\n  export interface ExpiresAfter {\n    /**\n     * Anchor timestamp after which the expiration policy applies. Supported anchors:\n     * `last_active_at`.\n     */\n    anchor: 'last_active_at';\n\n    /**\n     * The number of days after the anchor time that the vector store will expire.\n     */\n    days: number;\n  }\n}\n\nexport interface VectorStoreListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * starting with obj_foo, your subsequent call can include before=obj_foo in order\n   * to fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport interface VectorStoreSearchParams {\n  /**\n   * A query string for a search\n   */\n  query: string | Array<string>;\n\n  /**\n   * A filter to apply based on file attributes.\n   */\n  filters?: Shared.ComparisonFilter | Shared.CompoundFilter;\n\n  /**\n   * The maximum number of results to return. This number should be between 1 and 50\n   * inclusive.\n   */\n  max_num_results?: number;\n\n  /**\n   * Ranking options for search.\n   */\n  ranking_options?: VectorStoreSearchParams.RankingOptions;\n\n  /**\n   * Whether to rewrite the natural language query for vector search.\n   */\n  rewrite_query?: boolean;\n}\n\nexport namespace VectorStoreSearchParams {\n  /**\n   * Ranking options for search.\n   */\n  export interface RankingOptions {\n    /**\n     * Enable re-ranking; set to `none` to disable, which can help reduce latency.\n     */\n    ranker?: 'none' | 'auto' | 'default-2024-11-15';\n\n    score_threshold?: number;\n  }\n}\n\nVectorStores.Files = Files;\nVectorStores.FileBatches = FileBatches;\n\nexport declare namespace VectorStores {\n  export {\n    type AutoFileChunkingStrategyParam as AutoFileChunkingStrategyParam,\n    type FileChunkingStrategy as FileChunkingStrategy,\n    type FileChunkingStrategyParam as FileChunkingStrategyParam,\n    type OtherFileChunkingStrategyObject as OtherFileChunkingStrategyObject,\n    type StaticFileChunkingStrategy as StaticFileChunkingStrategy,\n    type StaticFileChunkingStrategyObject as StaticFileChunkingStrategyObject,\n    type StaticFileChunkingStrategyObjectParam as StaticFileChunkingStrategyObjectParam,\n    type VectorStore as VectorStore,\n    type VectorStoreDeleted as VectorStoreDeleted,\n    type VectorStoreSearchResponse as VectorStoreSearchResponse,\n    type VectorStoresPage as VectorStoresPage,\n    type VectorStoreSearchResponsesPage as VectorStoreSearchResponsesPage,\n    type VectorStoreCreateParams as VectorStoreCreateParams,\n    type VectorStoreUpdateParams as VectorStoreUpdateParams,\n    type VectorStoreListParams as VectorStoreListParams,\n    type VectorStoreSearchParams as VectorStoreSearchParams,\n  };\n\n  export {\n    Files as Files,\n    type VectorStoreFile as VectorStoreFile,\n    type VectorStoreFileDeleted as VectorStoreFileDeleted,\n    type FileContentResponse as FileContentResponse,\n    type VectorStoreFilesPage as VectorStoreFilesPage,\n    type FileContentResponsesPage as FileContentResponsesPage,\n    type FileCreateParams as FileCreateParams,\n    type FileRetrieveParams as FileRetrieveParams,\n    type FileUpdateParams as FileUpdateParams,\n    type FileListParams as FileListParams,\n    type FileDeleteParams as FileDeleteParams,\n    type FileContentParams as FileContentParams,\n  };\n\n  export {\n    FileBatches as FileBatches,\n    type VectorStoreFileBatch as VectorStoreFileBatch,\n    type FileBatchCreateParams as FileBatchCreateParams,\n    type FileBatchRetrieveParams as FileBatchRetrieveParams,\n    type FileBatchCancelParams as FileBatchCancelParams,\n    type FileBatchListFilesParams as FileBatchListFilesParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../core/resource';\nimport { APIPromise } from '../core/api-promise';\nimport { ConversationCursorPage, type ConversationCursorPageParams, PagePromise } from '../core/pagination';\nimport { type Uploadable } from '../core/uploads';\nimport { buildHeaders } from '../internal/headers';\nimport { RequestOptions } from '../internal/request-options';\nimport { maybeMultipartFormRequestOptions } from '../internal/uploads';\nimport { path } from '../internal/utils/path';\n\nexport class Videos extends APIResource {\n  /**\n   * Create a video\n   */\n  create(body: VideoCreateParams, options?: RequestOptions): APIPromise<Video> {\n    return this._client.post('/videos', maybeMultipartFormRequestOptions({ body, ...options }, this._client));\n  }\n\n  /**\n   * Retrieve a video\n   */\n  retrieve(videoID: string, options?: RequestOptions): APIPromise<Video> {\n    return this._client.get(path`/videos/${videoID}`, options);\n  }\n\n  /**\n   * List videos\n   */\n  list(\n    query: VideoListParams | null | undefined = {},\n    options?: RequestOptions,\n  ): PagePromise<VideosPage, Video> {\n    return this._client.getAPIList('/videos', ConversationCursorPage<Video>, { query, ...options });\n  }\n\n  /**\n   * Delete a video\n   */\n  delete(videoID: string, options?: RequestOptions): APIPromise<VideoDeleteResponse> {\n    return this._client.delete(path`/videos/${videoID}`, options);\n  }\n\n  /**\n   * Download video content\n   */\n  downloadContent(\n    videoID: string,\n    query: VideoDownloadContentParams | null | undefined = {},\n    options?: RequestOptions,\n  ): APIPromise<Response> {\n    return this._client.get(path`/videos/${videoID}/content`, {\n      query,\n      ...options,\n      headers: buildHeaders([{ Accept: 'application/binary' }, options?.headers]),\n      __binaryResponse: true,\n    });\n  }\n\n  /**\n   * Create a video remix\n   */\n  remix(videoID: string, body: VideoRemixParams, options?: RequestOptions): APIPromise<Video> {\n    return this._client.post(\n      path`/videos/${videoID}/remix`,\n      maybeMultipartFormRequestOptions({ body, ...options }, this._client),\n    );\n  }\n}\n\nexport type VideosPage = ConversationCursorPage<Video>;\n\n/**\n * Structured information describing a generated video job.\n */\nexport interface Video {\n  /**\n   * Unique identifier for the video job.\n   */\n  id: string;\n\n  /**\n   * Unix timestamp (seconds) for when the job completed, if finished.\n   */\n  completed_at: number | null;\n\n  /**\n   * Unix timestamp (seconds) for when the job was created.\n   */\n  created_at: number;\n\n  /**\n   * Error payload that explains why generation failed, if applicable.\n   */\n  error: VideoCreateError | null;\n\n  /**\n   * Unix timestamp (seconds) for when the downloadable assets expire, if set.\n   */\n  expires_at: number | null;\n\n  /**\n   * The video generation model that produced the job.\n   */\n  model: VideoModel;\n\n  /**\n   * The object type, which is always `video`.\n   */\n  object: 'video';\n\n  /**\n   * Approximate completion percentage for the generation task.\n   */\n  progress: number;\n\n  /**\n   * The prompt that was used to generate the video.\n   */\n  prompt: string | null;\n\n  /**\n   * Identifier of the source video if this video is a remix.\n   */\n  remixed_from_video_id: string | null;\n\n  /**\n   * Duration of the generated clip in seconds.\n   */\n  seconds: VideoSeconds;\n\n  /**\n   * The resolution of the generated video.\n   */\n  size: VideoSize;\n\n  /**\n   * Current lifecycle status of the video job.\n   */\n  status: 'queued' | 'in_progress' | 'completed' | 'failed';\n}\n\nexport interface VideoCreateError {\n  code: string;\n\n  message: string;\n}\n\nexport type VideoModel = 'sora-2' | 'sora-2-pro';\n\nexport type VideoSeconds = '4' | '8' | '12';\n\nexport type VideoSize = '720x1280' | '1280x720' | '1024x1792' | '1792x1024';\n\n/**\n * Confirmation payload returned after deleting a video.\n */\nexport interface VideoDeleteResponse {\n  /**\n   * Identifier of the deleted video.\n   */\n  id: string;\n\n  /**\n   * Indicates that the video resource was deleted.\n   */\n  deleted: boolean;\n\n  /**\n   * The object type that signals the deletion response.\n   */\n  object: 'video.deleted';\n}\n\nexport interface VideoCreateParams {\n  /**\n   * Text prompt that describes the video to generate.\n   */\n  prompt: string;\n\n  /**\n   * Optional image reference that guides generation.\n   */\n  input_reference?: Uploadable;\n\n  /**\n   * The video generation model to use. Defaults to `sora-2`.\n   */\n  model?: VideoModel;\n\n  /**\n   * Clip duration in seconds. Defaults to 4 seconds.\n   */\n  seconds?: VideoSeconds;\n\n  /**\n   * Output resolution formatted as width x height. Defaults to 720x1280.\n   */\n  size?: VideoSize;\n}\n\nexport interface VideoListParams extends ConversationCursorPageParams {\n  /**\n   * Sort order of results by timestamp. Use `asc` for ascending order or `desc` for\n   * descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport interface VideoDownloadContentParams {\n  /**\n   * Which downloadable asset to return. Defaults to the MP4 video.\n   */\n  variant?: 'video' | 'thumbnail' | 'spritesheet';\n}\n\nexport interface VideoRemixParams {\n  /**\n   * Updated text prompt that directs the remix generation.\n   */\n  prompt: string;\n}\n\nexport declare namespace Videos {\n  export {\n    type Video as Video,\n    type VideoCreateError as VideoCreateError,\n    type VideoModel as VideoModel,\n    type VideoSeconds as VideoSeconds,\n    type VideoSize as VideoSize,\n    type VideoDeleteResponse as VideoDeleteResponse,\n    type VideosPage as VideosPage,\n    type VideoCreateParams as VideoCreateParams,\n    type VideoListParams as VideoListParams,\n    type VideoDownloadContentParams as VideoDownloadContentParams,\n    type VideoRemixParams as VideoRemixParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport * as RealtimeAPI from './realtime';\nimport * as Shared from '../../shared';\nimport * as SessionsAPI from './sessions';\nimport {\n  Session as SessionsAPISession,\n  SessionCreateParams,\n  SessionCreateResponse,\n  Sessions,\n} from './sessions';\nimport * as TranscriptionSessionsAPI from './transcription-sessions';\nimport {\n  TranscriptionSession,\n  TranscriptionSessionCreateParams,\n  TranscriptionSessions,\n} from './transcription-sessions';\n\n/**\n * @deprecated Realtime has now launched and is generally available. The old beta API is now deprecated.\n */\nexport class Realtime extends APIResource {\n  sessions: SessionsAPI.Sessions = new SessionsAPI.Sessions(this._client);\n  transcriptionSessions: TranscriptionSessionsAPI.TranscriptionSessions =\n    new TranscriptionSessionsAPI.TranscriptionSessions(this._client);\n}\n\n/**\n * Returned when a conversation is created. Emitted right after session creation.\n */\nexport interface ConversationCreatedEvent {\n  /**\n   * The conversation resource.\n   */\n  conversation: ConversationCreatedEvent.Conversation;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The event type, must be `conversation.created`.\n   */\n  type: 'conversation.created';\n}\n\nexport namespace ConversationCreatedEvent {\n  /**\n   * The conversation resource.\n   */\n  export interface Conversation {\n    /**\n     * The unique ID of the conversation.\n     */\n    id?: string;\n\n    /**\n     * The object type, must be `realtime.conversation`.\n     */\n    object?: 'realtime.conversation';\n  }\n}\n\n/**\n * The item to add to the conversation.\n */\nexport interface ConversationItem {\n  /**\n   * The unique ID of the item, this can be generated by the client to help manage\n   * server-side context, but is not required because the server will generate one if\n   * not provided.\n   */\n  id?: string;\n\n  /**\n   * The arguments of the function call (for `function_call` items).\n   */\n  arguments?: string;\n\n  /**\n   * The ID of the function call (for `function_call` and `function_call_output`\n   * items). If passed on a `function_call_output` item, the server will check that a\n   * `function_call` item with the same ID exists in the conversation history.\n   */\n  call_id?: string;\n\n  /**\n   * The content of the message, applicable for `message` items.\n   *\n   * - Message items of role `system` support only `input_text` content\n   * - Message items of role `user` support `input_text` and `input_audio` content\n   * - Message items of role `assistant` support `text` content.\n   */\n  content?: Array<ConversationItemContent>;\n\n  /**\n   * The name of the function being called (for `function_call` items).\n   */\n  name?: string;\n\n  /**\n   * Identifier for the API object being returned - always `realtime.item`.\n   */\n  object?: 'realtime.item';\n\n  /**\n   * The output of the function call (for `function_call_output` items).\n   */\n  output?: string;\n\n  /**\n   * The role of the message sender (`user`, `assistant`, `system`), only applicable\n   * for `message` items.\n   */\n  role?: 'user' | 'assistant' | 'system';\n\n  /**\n   * The status of the item (`completed`, `incomplete`, `in_progress`). These have no\n   * effect on the conversation, but are accepted for consistency with the\n   * `conversation.item.created` event.\n   */\n  status?: 'completed' | 'incomplete' | 'in_progress';\n\n  /**\n   * The type of the item (`message`, `function_call`, `function_call_output`).\n   */\n  type?: 'message' | 'function_call' | 'function_call_output';\n}\n\nexport interface ConversationItemContent {\n  /**\n   * ID of a previous conversation item to reference (for `item_reference` content\n   * types in `response.create` events). These can reference both client and server\n   * created items.\n   */\n  id?: string;\n\n  /**\n   * Base64-encoded audio bytes, used for `input_audio` content type.\n   */\n  audio?: string;\n\n  /**\n   * The text content, used for `input_text` and `text` content types.\n   */\n  text?: string;\n\n  /**\n   * The transcript of the audio, used for `input_audio` and `audio` content types.\n   */\n  transcript?: string;\n\n  /**\n   * The content type (`input_text`, `input_audio`, `item_reference`, `text`,\n   * `audio`).\n   */\n  type?: 'input_text' | 'input_audio' | 'item_reference' | 'text' | 'audio';\n}\n\n/**\n * Add a new Item to the Conversation's context, including messages, function\n * calls, and function call responses. This event can be used both to populate a\n * \"history\" of the conversation and to add new items mid-stream, but has the\n * current limitation that it cannot populate assistant audio messages.\n *\n * If successful, the server will respond with a `conversation.item.created` event,\n * otherwise an `error` event will be sent.\n */\nexport interface ConversationItemCreateEvent {\n  /**\n   * The item to add to the conversation.\n   */\n  item: ConversationItem;\n\n  /**\n   * The event type, must be `conversation.item.create`.\n   */\n  type: 'conversation.item.create';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n\n  /**\n   * The ID of the preceding item after which the new item will be inserted. If not\n   * set, the new item will be appended to the end of the conversation. If set to\n   * `root`, the new item will be added to the beginning of the conversation. If set\n   * to an existing ID, it allows an item to be inserted mid-conversation. If the ID\n   * cannot be found, an error will be returned and the item will not be added.\n   */\n  previous_item_id?: string;\n}\n\n/**\n * Returned when a conversation item is created. There are several scenarios that\n * produce this event:\n *\n * - The server is generating a Response, which if successful will produce either\n *   one or two Items, which will be of type `message` (role `assistant`) or type\n *   `function_call`.\n * - The input audio buffer has been committed, either by the client or the server\n *   (in `server_vad` mode). The server will take the content of the input audio\n *   buffer and add it to a new user message Item.\n * - The client has sent a `conversation.item.create` event to add a new Item to\n *   the Conversation.\n */\nexport interface ConversationItemCreatedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The item to add to the conversation.\n   */\n  item: ConversationItem;\n\n  /**\n   * The event type, must be `conversation.item.created`.\n   */\n  type: 'conversation.item.created';\n\n  /**\n   * The ID of the preceding item in the Conversation context, allows the client to\n   * understand the order of the conversation. Can be `null` if the item has no\n   * predecessor.\n   */\n  previous_item_id?: string | null;\n}\n\n/**\n * Send this event when you want to remove any item from the conversation history.\n * The server will respond with a `conversation.item.deleted` event, unless the\n * item does not exist in the conversation history, in which case the server will\n * respond with an error.\n */\nexport interface ConversationItemDeleteEvent {\n  /**\n   * The ID of the item to delete.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.delete`.\n   */\n  type: 'conversation.item.delete';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\n/**\n * Returned when an item in the conversation is deleted by the client with a\n * `conversation.item.delete` event. This event is used to synchronize the server's\n * understanding of the conversation history with the client's view.\n */\nexport interface ConversationItemDeletedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item that was deleted.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.deleted`.\n   */\n  type: 'conversation.item.deleted';\n}\n\n/**\n * This event is the output of audio transcription for user audio written to the\n * user audio buffer. Transcription begins when the input audio buffer is committed\n * by the client or server (in `server_vad` mode). Transcription runs\n * asynchronously with Response creation, so this event may come before or after\n * the Response events.\n *\n * Realtime API models accept audio natively, and thus input transcription is a\n * separate process run on a separate ASR (Automatic Speech Recognition) model. The\n * transcript may diverge somewhat from the model's interpretation, and should be\n * treated as a rough guide.\n */\nexport interface ConversationItemInputAudioTranscriptionCompletedEvent {\n  /**\n   * The index of the content part containing the audio.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the user message item containing the audio.\n   */\n  item_id: string;\n\n  /**\n   * The transcribed text.\n   */\n  transcript: string;\n\n  /**\n   * The event type, must be `conversation.item.input_audio_transcription.completed`.\n   */\n  type: 'conversation.item.input_audio_transcription.completed';\n\n  /**\n   * Usage statistics for the transcription.\n   */\n  usage:\n    | ConversationItemInputAudioTranscriptionCompletedEvent.TranscriptTextUsageTokens\n    | ConversationItemInputAudioTranscriptionCompletedEvent.TranscriptTextUsageDuration;\n\n  /**\n   * The log probabilities of the transcription.\n   */\n  logprobs?: Array<ConversationItemInputAudioTranscriptionCompletedEvent.Logprob> | null;\n}\n\nexport namespace ConversationItemInputAudioTranscriptionCompletedEvent {\n  /**\n   * Usage statistics for models billed by token usage.\n   */\n  export interface TranscriptTextUsageTokens {\n    /**\n     * Number of input tokens billed for this request.\n     */\n    input_tokens: number;\n\n    /**\n     * Number of output tokens generated.\n     */\n    output_tokens: number;\n\n    /**\n     * Total number of tokens used (input + output).\n     */\n    total_tokens: number;\n\n    /**\n     * The type of the usage object. Always `tokens` for this variant.\n     */\n    type: 'tokens';\n\n    /**\n     * Details about the input tokens billed for this request.\n     */\n    input_token_details?: TranscriptTextUsageTokens.InputTokenDetails;\n  }\n\n  export namespace TranscriptTextUsageTokens {\n    /**\n     * Details about the input tokens billed for this request.\n     */\n    export interface InputTokenDetails {\n      /**\n       * Number of audio tokens billed for this request.\n       */\n      audio_tokens?: number;\n\n      /**\n       * Number of text tokens billed for this request.\n       */\n      text_tokens?: number;\n    }\n  }\n\n  /**\n   * Usage statistics for models billed by audio input duration.\n   */\n  export interface TranscriptTextUsageDuration {\n    /**\n     * Duration of the input audio in seconds.\n     */\n    seconds: number;\n\n    /**\n     * The type of the usage object. Always `duration` for this variant.\n     */\n    type: 'duration';\n  }\n\n  /**\n   * A log probability object.\n   */\n  export interface Logprob {\n    /**\n     * The token that was used to generate the log probability.\n     */\n    token: string;\n\n    /**\n     * The bytes that were used to generate the log probability.\n     */\n    bytes: Array<number>;\n\n    /**\n     * The log probability of the token.\n     */\n    logprob: number;\n  }\n}\n\n/**\n * Returned when the text value of an input audio transcription content part is\n * updated.\n */\nexport interface ConversationItemInputAudioTranscriptionDeltaEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.input_audio_transcription.delta`.\n   */\n  type: 'conversation.item.input_audio_transcription.delta';\n\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index?: number;\n\n  /**\n   * The text delta.\n   */\n  delta?: string;\n\n  /**\n   * The log probabilities of the transcription.\n   */\n  logprobs?: Array<ConversationItemInputAudioTranscriptionDeltaEvent.Logprob> | null;\n}\n\nexport namespace ConversationItemInputAudioTranscriptionDeltaEvent {\n  /**\n   * A log probability object.\n   */\n  export interface Logprob {\n    /**\n     * The token that was used to generate the log probability.\n     */\n    token: string;\n\n    /**\n     * The bytes that were used to generate the log probability.\n     */\n    bytes: Array<number>;\n\n    /**\n     * The log probability of the token.\n     */\n    logprob: number;\n  }\n}\n\n/**\n * Returned when input audio transcription is configured, and a transcription\n * request for a user message failed. These events are separate from other `error`\n * events so that the client can identify the related Item.\n */\nexport interface ConversationItemInputAudioTranscriptionFailedEvent {\n  /**\n   * The index of the content part containing the audio.\n   */\n  content_index: number;\n\n  /**\n   * Details of the transcription error.\n   */\n  error: ConversationItemInputAudioTranscriptionFailedEvent.Error;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the user message item.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.input_audio_transcription.failed`.\n   */\n  type: 'conversation.item.input_audio_transcription.failed';\n}\n\nexport namespace ConversationItemInputAudioTranscriptionFailedEvent {\n  /**\n   * Details of the transcription error.\n   */\n  export interface Error {\n    /**\n     * Error code, if any.\n     */\n    code?: string;\n\n    /**\n     * A human-readable error message.\n     */\n    message?: string;\n\n    /**\n     * Parameter related to the error, if any.\n     */\n    param?: string;\n\n    /**\n     * The type of error.\n     */\n    type?: string;\n  }\n}\n\n/**\n * Send this event when you want to retrieve the server's representation of a\n * specific item in the conversation history. This is useful, for example, to\n * inspect user audio after noise cancellation and VAD. The server will respond\n * with a `conversation.item.retrieved` event, unless the item does not exist in\n * the conversation history, in which case the server will respond with an error.\n */\nexport interface ConversationItemRetrieveEvent {\n  /**\n   * The ID of the item to retrieve.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.retrieve`.\n   */\n  type: 'conversation.item.retrieve';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\n/**\n * Send this event to truncate a previous assistant messages audio. The server\n * will produce audio faster than realtime, so this event is useful when the user\n * interrupts to truncate audio that has already been sent to the client but not\n * yet played. This will synchronize the server's understanding of the audio with\n * the client's playback.\n *\n * Truncating audio will delete the server-side text transcript to ensure there is\n * not text in the context that hasn't been heard by the user.\n *\n * If successful, the server will respond with a `conversation.item.truncated`\n * event.\n */\nexport interface ConversationItemTruncateEvent {\n  /**\n   * Inclusive duration up to which audio is truncated, in milliseconds. If the\n   * audio_end_ms is greater than the actual audio duration, the server will respond\n   * with an error.\n   */\n  audio_end_ms: number;\n\n  /**\n   * The index of the content part to truncate. Set this to 0.\n   */\n  content_index: number;\n\n  /**\n   * The ID of the assistant message item to truncate. Only assistant message items\n   * can be truncated.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.truncate`.\n   */\n  type: 'conversation.item.truncate';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\n/**\n * Returned when an earlier assistant audio message item is truncated by the client\n * with a `conversation.item.truncate` event. This event is used to synchronize the\n * server's understanding of the audio with the client's playback.\n *\n * This action will truncate the audio and remove the server-side text transcript\n * to ensure there is no text in the context that hasn't been heard by the user.\n */\nexport interface ConversationItemTruncatedEvent {\n  /**\n   * The duration up to which the audio was truncated, in milliseconds.\n   */\n  audio_end_ms: number;\n\n  /**\n   * The index of the content part that was truncated.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the assistant message item that was truncated.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `conversation.item.truncated`.\n   */\n  type: 'conversation.item.truncated';\n}\n\n/**\n * The item to add to the conversation.\n */\nexport interface ConversationItemWithReference {\n  /**\n   * For an item of type (`message` | `function_call` | `function_call_output`) this\n   * field allows the client to assign the unique ID of the item. It is not required\n   * because the server will generate one if not provided.\n   *\n   * For an item of type `item_reference`, this field is required and is a reference\n   * to any item that has previously existed in the conversation.\n   */\n  id?: string;\n\n  /**\n   * The arguments of the function call (for `function_call` items).\n   */\n  arguments?: string;\n\n  /**\n   * The ID of the function call (for `function_call` and `function_call_output`\n   * items). If passed on a `function_call_output` item, the server will check that a\n   * `function_call` item with the same ID exists in the conversation history.\n   */\n  call_id?: string;\n\n  /**\n   * The content of the message, applicable for `message` items.\n   *\n   * - Message items of role `system` support only `input_text` content\n   * - Message items of role `user` support `input_text` and `input_audio` content\n   * - Message items of role `assistant` support `text` content.\n   */\n  content?: Array<ConversationItemWithReference.Content>;\n\n  /**\n   * The name of the function being called (for `function_call` items).\n   */\n  name?: string;\n\n  /**\n   * Identifier for the API object being returned - always `realtime.item`.\n   */\n  object?: 'realtime.item';\n\n  /**\n   * The output of the function call (for `function_call_output` items).\n   */\n  output?: string;\n\n  /**\n   * The role of the message sender (`user`, `assistant`, `system`), only applicable\n   * for `message` items.\n   */\n  role?: 'user' | 'assistant' | 'system';\n\n  /**\n   * The status of the item (`completed`, `incomplete`, `in_progress`). These have no\n   * effect on the conversation, but are accepted for consistency with the\n   * `conversation.item.created` event.\n   */\n  status?: 'completed' | 'incomplete' | 'in_progress';\n\n  /**\n   * The type of the item (`message`, `function_call`, `function_call_output`,\n   * `item_reference`).\n   */\n  type?: 'message' | 'function_call' | 'function_call_output' | 'item_reference';\n}\n\nexport namespace ConversationItemWithReference {\n  export interface Content {\n    /**\n     * ID of a previous conversation item to reference (for `item_reference` content\n     * types in `response.create` events). These can reference both client and server\n     * created items.\n     */\n    id?: string;\n\n    /**\n     * Base64-encoded audio bytes, used for `input_audio` content type.\n     */\n    audio?: string;\n\n    /**\n     * The text content, used for `input_text` and `text` content types.\n     */\n    text?: string;\n\n    /**\n     * The transcript of the audio, used for `input_audio` content type.\n     */\n    transcript?: string;\n\n    /**\n     * The content type (`input_text`, `input_audio`, `item_reference`, `text`).\n     */\n    type?: 'input_text' | 'input_audio' | 'item_reference' | 'text';\n  }\n}\n\n/**\n * Returned when an error occurs, which could be a client problem or a server\n * problem. Most errors are recoverable and the session will stay open, we\n * recommend to implementors to monitor and log error messages by default.\n */\nexport interface ErrorEvent {\n  /**\n   * Details of the error.\n   */\n  error: ErrorEvent.Error;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The event type, must be `error`.\n   */\n  type: 'error';\n}\n\nexport namespace ErrorEvent {\n  /**\n   * Details of the error.\n   */\n  export interface Error {\n    /**\n     * A human-readable error message.\n     */\n    message: string;\n\n    /**\n     * The type of error (e.g., \"invalid_request_error\", \"server_error\").\n     */\n    type: string;\n\n    /**\n     * Error code, if any.\n     */\n    code?: string | null;\n\n    /**\n     * The event_id of the client event that caused the error, if applicable.\n     */\n    event_id?: string | null;\n\n    /**\n     * Parameter related to the error, if any.\n     */\n    param?: string | null;\n  }\n}\n\n/**\n * Send this event to append audio bytes to the input audio buffer. The audio\n * buffer is temporary storage you can write to and later commit. In Server VAD\n * mode, the audio buffer is used to detect speech and the server will decide when\n * to commit. When Server VAD is disabled, you must commit the audio buffer\n * manually.\n *\n * The client may choose how much audio to place in each event up to a maximum of\n * 15 MiB, for example streaming smaller chunks from the client may allow the VAD\n * to be more responsive. Unlike made other client events, the server will not send\n * a confirmation response to this event.\n */\nexport interface InputAudioBufferAppendEvent {\n  /**\n   * Base64-encoded audio bytes. This must be in the format specified by the\n   * `input_audio_format` field in the session configuration.\n   */\n  audio: string;\n\n  /**\n   * The event type, must be `input_audio_buffer.append`.\n   */\n  type: 'input_audio_buffer.append';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\n/**\n * Send this event to clear the audio bytes in the buffer. The server will respond\n * with an `input_audio_buffer.cleared` event.\n */\nexport interface InputAudioBufferClearEvent {\n  /**\n   * The event type, must be `input_audio_buffer.clear`.\n   */\n  type: 'input_audio_buffer.clear';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\n/**\n * Returned when the input audio buffer is cleared by the client with a\n * `input_audio_buffer.clear` event.\n */\nexport interface InputAudioBufferClearedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The event type, must be `input_audio_buffer.cleared`.\n   */\n  type: 'input_audio_buffer.cleared';\n}\n\n/**\n * Send this event to commit the user input audio buffer, which will create a new\n * user message item in the conversation. This event will produce an error if the\n * input audio buffer is empty. When in Server VAD mode, the client does not need\n * to send this event, the server will commit the audio buffer automatically.\n *\n * Committing the input audio buffer will trigger input audio transcription (if\n * enabled in session configuration), but it will not create a response from the\n * model. The server will respond with an `input_audio_buffer.committed` event.\n */\nexport interface InputAudioBufferCommitEvent {\n  /**\n   * The event type, must be `input_audio_buffer.commit`.\n   */\n  type: 'input_audio_buffer.commit';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\n/**\n * Returned when an input audio buffer is committed, either by the client or\n * automatically in server VAD mode. The `item_id` property is the ID of the user\n * message item that will be created, thus a `conversation.item.created` event will\n * also be sent to the client.\n */\nexport interface InputAudioBufferCommittedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the user message item that will be created.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `input_audio_buffer.committed`.\n   */\n  type: 'input_audio_buffer.committed';\n\n  /**\n   * The ID of the preceding item after which the new item will be inserted. Can be\n   * `null` if the item has no predecessor.\n   */\n  previous_item_id?: string | null;\n}\n\n/**\n * Sent by the server when in `server_vad` mode to indicate that speech has been\n * detected in the audio buffer. This can happen any time audio is added to the\n * buffer (unless speech is already detected). The client may want to use this\n * event to interrupt audio playback or provide visual feedback to the user.\n *\n * The client should expect to receive a `input_audio_buffer.speech_stopped` event\n * when speech stops. The `item_id` property is the ID of the user message item\n * that will be created when speech stops and will also be included in the\n * `input_audio_buffer.speech_stopped` event (unless the client manually commits\n * the audio buffer during VAD activation).\n */\nexport interface InputAudioBufferSpeechStartedEvent {\n  /**\n   * Milliseconds from the start of all audio written to the buffer during the\n   * session when speech was first detected. This will correspond to the beginning of\n   * audio sent to the model, and thus includes the `prefix_padding_ms` configured in\n   * the Session.\n   */\n  audio_start_ms: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the user message item that will be created when speech stops.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `input_audio_buffer.speech_started`.\n   */\n  type: 'input_audio_buffer.speech_started';\n}\n\n/**\n * Returned in `server_vad` mode when the server detects the end of speech in the\n * audio buffer. The server will also send an `conversation.item.created` event\n * with the user message item that is created from the audio buffer.\n */\nexport interface InputAudioBufferSpeechStoppedEvent {\n  /**\n   * Milliseconds since the session started when speech stopped. This will correspond\n   * to the end of audio sent to the model, and thus includes the\n   * `min_silence_duration_ms` configured in the Session.\n   */\n  audio_end_ms: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the user message item that will be created.\n   */\n  item_id: string;\n\n  /**\n   * The event type, must be `input_audio_buffer.speech_stopped`.\n   */\n  type: 'input_audio_buffer.speech_stopped';\n}\n\n/**\n * Emitted at the beginning of a Response to indicate the updated rate limits. When\n * a Response is created some tokens will be \"reserved\" for the output tokens, the\n * rate limits shown here reflect that reservation, which is then adjusted\n * accordingly once the Response is completed.\n */\nexport interface RateLimitsUpdatedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * List of rate limit information.\n   */\n  rate_limits: Array<RateLimitsUpdatedEvent.RateLimit>;\n\n  /**\n   * The event type, must be `rate_limits.updated`.\n   */\n  type: 'rate_limits.updated';\n}\n\nexport namespace RateLimitsUpdatedEvent {\n  export interface RateLimit {\n    /**\n     * The maximum allowed value for the rate limit.\n     */\n    limit?: number;\n\n    /**\n     * The name of the rate limit (`requests`, `tokens`).\n     */\n    name?: 'requests' | 'tokens';\n\n    /**\n     * The remaining value before the limit is reached.\n     */\n    remaining?: number;\n\n    /**\n     * Seconds until the rate limit resets.\n     */\n    reset_seconds?: number;\n  }\n}\n\n/**\n * A realtime client event.\n */\nexport type RealtimeClientEvent =\n  | ConversationItemCreateEvent\n  | ConversationItemDeleteEvent\n  | ConversationItemRetrieveEvent\n  | ConversationItemTruncateEvent\n  | InputAudioBufferAppendEvent\n  | InputAudioBufferClearEvent\n  | RealtimeClientEvent.OutputAudioBufferClear\n  | InputAudioBufferCommitEvent\n  | ResponseCancelEvent\n  | ResponseCreateEvent\n  | SessionUpdateEvent\n  | TranscriptionSessionUpdate;\n\nexport namespace RealtimeClientEvent {\n  /**\n   * **WebRTC Only:** Emit to cut off the current audio response. This will trigger\n   * the server to stop generating audio and emit a `output_audio_buffer.cleared`\n   * event. This event should be preceded by a `response.cancel` client event to stop\n   * the generation of the current response.\n   * [Learn more](https://platform.openai.com/docs/guides/realtime-conversations#client-and-server-events-for-audio-in-webrtc).\n   */\n  export interface OutputAudioBufferClear {\n    /**\n     * The event type, must be `output_audio_buffer.clear`.\n     */\n    type: 'output_audio_buffer.clear';\n\n    /**\n     * The unique ID of the client event used for error handling.\n     */\n    event_id?: string;\n  }\n}\n\n/**\n * The response resource.\n */\nexport interface RealtimeResponse {\n  /**\n   * The unique ID of the response.\n   */\n  id?: string;\n\n  /**\n   * Which conversation the response is added to, determined by the `conversation`\n   * field in the `response.create` event. If `auto`, the response will be added to\n   * the default conversation and the value of `conversation_id` will be an id like\n   * `conv_1234`. If `none`, the response will not be added to any conversation and\n   * the value of `conversation_id` will be `null`. If responses are being triggered\n   * by server VAD, the response will be added to the default conversation, thus the\n   * `conversation_id` will be an id like `conv_1234`.\n   */\n  conversation_id?: string;\n\n  /**\n   * Maximum number of output tokens for a single assistant response, inclusive of\n   * tool calls, that was used in this response.\n   */\n  max_output_tokens?: number | 'inf';\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format, and\n   * querying for objects via API or the dashboard.\n   *\n   * Keys are strings with a maximum length of 64 characters. Values are strings with\n   * a maximum length of 512 characters.\n   */\n  metadata?: Shared.Metadata | null;\n\n  /**\n   * The set of modalities the model used to respond. If there are multiple\n   * modalities, the model will pick one, for example if `modalities` is\n   * `[\"text\", \"audio\"]`, the model could be responding in either text or audio.\n   */\n  modalities?: Array<'text' | 'audio'>;\n\n  /**\n   * The object type, must be `realtime.response`.\n   */\n  object?: 'realtime.response';\n\n  /**\n   * The list of output items generated by the response.\n   */\n  output?: Array<ConversationItem>;\n\n  /**\n   * The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n   */\n  output_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n  /**\n   * The final status of the response (`completed`, `cancelled`, `failed`, or\n   * `incomplete`, `in_progress`).\n   */\n  status?: 'completed' | 'cancelled' | 'failed' | 'incomplete' | 'in_progress';\n\n  /**\n   * Additional details about the status.\n   */\n  status_details?: RealtimeResponseStatus;\n\n  /**\n   * Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8.\n   */\n  temperature?: number;\n\n  /**\n   * Usage statistics for the Response, this will correspond to billing. A Realtime\n   * API session will maintain a conversation context and append new Items to the\n   * Conversation, thus output from previous turns (text and audio tokens) will\n   * become the input for later turns.\n   */\n  usage?: RealtimeResponseUsage;\n\n  /**\n   * The voice the model used to respond. Current voice options are `alloy`, `ash`,\n   * `ballad`, `coral`, `echo`, `sage`, `shimmer`, and `verse`.\n   */\n  voice?: (string & {}) | 'alloy' | 'ash' | 'ballad' | 'coral' | 'echo' | 'sage' | 'shimmer' | 'verse';\n}\n\n/**\n * Additional details about the status.\n */\nexport interface RealtimeResponseStatus {\n  /**\n   * A description of the error that caused the response to fail, populated when the\n   * `status` is `failed`.\n   */\n  error?: RealtimeResponseStatus.Error;\n\n  /**\n   * The reason the Response did not complete. For a `cancelled` Response, one of\n   * `turn_detected` (the server VAD detected a new start of speech) or\n   * `client_cancelled` (the client sent a cancel event). For an `incomplete`\n   * Response, one of `max_output_tokens` or `content_filter` (the server-side safety\n   * filter activated and cut off the response).\n   */\n  reason?: 'turn_detected' | 'client_cancelled' | 'max_output_tokens' | 'content_filter';\n\n  /**\n   * The type of error that caused the response to fail, corresponding with the\n   * `status` field (`completed`, `cancelled`, `incomplete`, `failed`).\n   */\n  type?: 'completed' | 'cancelled' | 'incomplete' | 'failed';\n}\n\nexport namespace RealtimeResponseStatus {\n  /**\n   * A description of the error that caused the response to fail, populated when the\n   * `status` is `failed`.\n   */\n  export interface Error {\n    /**\n     * Error code, if any.\n     */\n    code?: string;\n\n    /**\n     * The type of error.\n     */\n    type?: string;\n  }\n}\n\n/**\n * Usage statistics for the Response, this will correspond to billing. A Realtime\n * API session will maintain a conversation context and append new Items to the\n * Conversation, thus output from previous turns (text and audio tokens) will\n * become the input for later turns.\n */\nexport interface RealtimeResponseUsage {\n  /**\n   * Details about the input tokens used in the Response.\n   */\n  input_token_details?: RealtimeResponseUsage.InputTokenDetails;\n\n  /**\n   * The number of input tokens used in the Response, including text and audio\n   * tokens.\n   */\n  input_tokens?: number;\n\n  /**\n   * Details about the output tokens used in the Response.\n   */\n  output_token_details?: RealtimeResponseUsage.OutputTokenDetails;\n\n  /**\n   * The number of output tokens sent in the Response, including text and audio\n   * tokens.\n   */\n  output_tokens?: number;\n\n  /**\n   * The total number of tokens in the Response including input and output text and\n   * audio tokens.\n   */\n  total_tokens?: number;\n}\n\nexport namespace RealtimeResponseUsage {\n  /**\n   * Details about the input tokens used in the Response.\n   */\n  export interface InputTokenDetails {\n    /**\n     * The number of audio tokens used in the Response.\n     */\n    audio_tokens?: number;\n\n    /**\n     * The number of cached tokens used in the Response.\n     */\n    cached_tokens?: number;\n\n    /**\n     * The number of text tokens used in the Response.\n     */\n    text_tokens?: number;\n  }\n\n  /**\n   * Details about the output tokens used in the Response.\n   */\n  export interface OutputTokenDetails {\n    /**\n     * The number of audio tokens used in the Response.\n     */\n    audio_tokens?: number;\n\n    /**\n     * The number of text tokens used in the Response.\n     */\n    text_tokens?: number;\n  }\n}\n\n/**\n * A realtime server event.\n */\nexport type RealtimeServerEvent =\n  | ConversationCreatedEvent\n  | ConversationItemCreatedEvent\n  | ConversationItemDeletedEvent\n  | ConversationItemInputAudioTranscriptionCompletedEvent\n  | ConversationItemInputAudioTranscriptionDeltaEvent\n  | ConversationItemInputAudioTranscriptionFailedEvent\n  | RealtimeServerEvent.ConversationItemRetrieved\n  | ConversationItemTruncatedEvent\n  | ErrorEvent\n  | InputAudioBufferClearedEvent\n  | InputAudioBufferCommittedEvent\n  | InputAudioBufferSpeechStartedEvent\n  | InputAudioBufferSpeechStoppedEvent\n  | RateLimitsUpdatedEvent\n  | ResponseAudioDeltaEvent\n  | ResponseAudioDoneEvent\n  | ResponseAudioTranscriptDeltaEvent\n  | ResponseAudioTranscriptDoneEvent\n  | ResponseContentPartAddedEvent\n  | ResponseContentPartDoneEvent\n  | ResponseCreatedEvent\n  | ResponseDoneEvent\n  | ResponseFunctionCallArgumentsDeltaEvent\n  | ResponseFunctionCallArgumentsDoneEvent\n  | ResponseOutputItemAddedEvent\n  | ResponseOutputItemDoneEvent\n  | ResponseTextDeltaEvent\n  | ResponseTextDoneEvent\n  | SessionCreatedEvent\n  | SessionUpdatedEvent\n  | TranscriptionSessionUpdatedEvent\n  | RealtimeServerEvent.OutputAudioBufferStarted\n  | RealtimeServerEvent.OutputAudioBufferStopped\n  | RealtimeServerEvent.OutputAudioBufferCleared;\n\nexport namespace RealtimeServerEvent {\n  /**\n   * Returned when a conversation item is retrieved with\n   * `conversation.item.retrieve`.\n   */\n  export interface ConversationItemRetrieved {\n    /**\n     * The unique ID of the server event.\n     */\n    event_id: string;\n\n    /**\n     * The item to add to the conversation.\n     */\n    item: RealtimeAPI.ConversationItem;\n\n    /**\n     * The event type, must be `conversation.item.retrieved`.\n     */\n    type: 'conversation.item.retrieved';\n  }\n\n  /**\n   * **WebRTC Only:** Emitted when the server begins streaming audio to the client.\n   * This event is emitted after an audio content part has been added\n   * (`response.content_part.added`) to the response.\n   * [Learn more](https://platform.openai.com/docs/guides/realtime-conversations#client-and-server-events-for-audio-in-webrtc).\n   */\n  export interface OutputAudioBufferStarted {\n    /**\n     * The unique ID of the server event.\n     */\n    event_id: string;\n\n    /**\n     * The unique ID of the response that produced the audio.\n     */\n    response_id: string;\n\n    /**\n     * The event type, must be `output_audio_buffer.started`.\n     */\n    type: 'output_audio_buffer.started';\n  }\n\n  /**\n   * **WebRTC Only:** Emitted when the output audio buffer has been completely\n   * drained on the server, and no more audio is forthcoming. This event is emitted\n   * after the full response data has been sent to the client (`response.done`).\n   * [Learn more](https://platform.openai.com/docs/guides/realtime-conversations#client-and-server-events-for-audio-in-webrtc).\n   */\n  export interface OutputAudioBufferStopped {\n    /**\n     * The unique ID of the server event.\n     */\n    event_id: string;\n\n    /**\n     * The unique ID of the response that produced the audio.\n     */\n    response_id: string;\n\n    /**\n     * The event type, must be `output_audio_buffer.stopped`.\n     */\n    type: 'output_audio_buffer.stopped';\n  }\n\n  /**\n   * **WebRTC Only:** Emitted when the output audio buffer is cleared. This happens\n   * either in VAD mode when the user has interrupted\n   * (`input_audio_buffer.speech_started`), or when the client has emitted the\n   * `output_audio_buffer.clear` event to manually cut off the current audio\n   * response.\n   * [Learn more](https://platform.openai.com/docs/guides/realtime-conversations#client-and-server-events-for-audio-in-webrtc).\n   */\n  export interface OutputAudioBufferCleared {\n    /**\n     * The unique ID of the server event.\n     */\n    event_id: string;\n\n    /**\n     * The unique ID of the response that produced the audio.\n     */\n    response_id: string;\n\n    /**\n     * The event type, must be `output_audio_buffer.cleared`.\n     */\n    type: 'output_audio_buffer.cleared';\n  }\n}\n\n/**\n * Returned when the model-generated audio is updated.\n */\nexport interface ResponseAudioDeltaEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * Base64-encoded audio data delta.\n   */\n  delta: string;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.audio.delta`.\n   */\n  type: 'response.audio.delta';\n}\n\n/**\n * Returned when the model-generated audio is done. Also emitted when a Response is\n * interrupted, incomplete, or cancelled.\n */\nexport interface ResponseAudioDoneEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.audio.done`.\n   */\n  type: 'response.audio.done';\n}\n\n/**\n * Returned when the model-generated transcription of audio output is updated.\n */\nexport interface ResponseAudioTranscriptDeltaEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The transcript delta.\n   */\n  delta: string;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.audio_transcript.delta`.\n   */\n  type: 'response.audio_transcript.delta';\n}\n\n/**\n * Returned when the model-generated transcription of audio output is done\n * streaming. Also emitted when a Response is interrupted, incomplete, or\n * cancelled.\n */\nexport interface ResponseAudioTranscriptDoneEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The final transcript of the audio.\n   */\n  transcript: string;\n\n  /**\n   * The event type, must be `response.audio_transcript.done`.\n   */\n  type: 'response.audio_transcript.done';\n}\n\n/**\n * Send this event to cancel an in-progress response. The server will respond with\n * a `response.done` event with a status of `response.status=cancelled`. If there\n * is no response to cancel, the server will respond with an error.\n */\nexport interface ResponseCancelEvent {\n  /**\n   * The event type, must be `response.cancel`.\n   */\n  type: 'response.cancel';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n\n  /**\n   * A specific response ID to cancel - if not provided, will cancel an in-progress\n   * response in the default conversation.\n   */\n  response_id?: string;\n}\n\n/**\n * Returned when a new content part is added to an assistant message item during\n * response generation.\n */\nexport interface ResponseContentPartAddedEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item to which the content part was added.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The content part that was added.\n   */\n  part: ResponseContentPartAddedEvent.Part;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.content_part.added`.\n   */\n  type: 'response.content_part.added';\n}\n\nexport namespace ResponseContentPartAddedEvent {\n  /**\n   * The content part that was added.\n   */\n  export interface Part {\n    /**\n     * Base64-encoded audio data (if type is \"audio\").\n     */\n    audio?: string;\n\n    /**\n     * The text content (if type is \"text\").\n     */\n    text?: string;\n\n    /**\n     * The transcript of the audio (if type is \"audio\").\n     */\n    transcript?: string;\n\n    /**\n     * The content type (\"text\", \"audio\").\n     */\n    type?: 'text' | 'audio';\n  }\n}\n\n/**\n * Returned when a content part is done streaming in an assistant message item.\n * Also emitted when a Response is interrupted, incomplete, or cancelled.\n */\nexport interface ResponseContentPartDoneEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The content part that is done.\n   */\n  part: ResponseContentPartDoneEvent.Part;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.content_part.done`.\n   */\n  type: 'response.content_part.done';\n}\n\nexport namespace ResponseContentPartDoneEvent {\n  /**\n   * The content part that is done.\n   */\n  export interface Part {\n    /**\n     * Base64-encoded audio data (if type is \"audio\").\n     */\n    audio?: string;\n\n    /**\n     * The text content (if type is \"text\").\n     */\n    text?: string;\n\n    /**\n     * The transcript of the audio (if type is \"audio\").\n     */\n    transcript?: string;\n\n    /**\n     * The content type (\"text\", \"audio\").\n     */\n    type?: 'text' | 'audio';\n  }\n}\n\n/**\n * This event instructs the server to create a Response, which means triggering\n * model inference. When in Server VAD mode, the server will create Responses\n * automatically.\n *\n * A Response will include at least one Item, and may have two, in which case the\n * second will be a function call. These Items will be appended to the conversation\n * history.\n *\n * The server will respond with a `response.created` event, events for Items and\n * content created, and finally a `response.done` event to indicate the Response is\n * complete.\n *\n * The `response.create` event includes inference configuration like\n * `instructions`, and `temperature`. These fields will override the Session's\n * configuration for this Response only.\n */\nexport interface ResponseCreateEvent {\n  /**\n   * The event type, must be `response.create`.\n   */\n  type: 'response.create';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n\n  /**\n   * Create a new Realtime response with these parameters\n   */\n  response?: ResponseCreateEvent.Response;\n}\n\nexport namespace ResponseCreateEvent {\n  /**\n   * Create a new Realtime response with these parameters\n   */\n  export interface Response {\n    /**\n     * Controls which conversation the response is added to. Currently supports `auto`\n     * and `none`, with `auto` as the default value. The `auto` value means that the\n     * contents of the response will be added to the default conversation. Set this to\n     * `none` to create an out-of-band response which will not add items to default\n     * conversation.\n     */\n    conversation?: (string & {}) | 'auto' | 'none';\n\n    /**\n     * Input items to include in the prompt for the model. Using this field creates a\n     * new context for this Response instead of using the default conversation. An\n     * empty array `[]` will clear the context for this Response. Note that this can\n     * include references to items from the default conversation.\n     */\n    input?: Array<RealtimeAPI.ConversationItemWithReference>;\n\n    /**\n     * The default system instructions (i.e. system message) prepended to model calls.\n     * This field allows the client to guide the model on desired responses. The model\n     * can be instructed on response content and format, (e.g. \"be extremely succinct\",\n     * \"act friendly\", \"here are examples of good responses\") and on audio behavior\n     * (e.g. \"talk quickly\", \"inject emotion into your voice\", \"laugh frequently\"). The\n     * instructions are not guaranteed to be followed by the model, but they provide\n     * guidance to the model on the desired behavior.\n     *\n     * Note that the server sets default instructions which will be used if this field\n     * is not set and are visible in the `session.created` event at the start of the\n     * session.\n     */\n    instructions?: string;\n\n    /**\n     * Maximum number of output tokens for a single assistant response, inclusive of\n     * tool calls. Provide an integer between 1 and 4096 to limit output tokens, or\n     * `inf` for the maximum available tokens for a given model. Defaults to `inf`.\n     */\n    max_response_output_tokens?: number | 'inf';\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format, and\n     * querying for objects via API or the dashboard.\n     *\n     * Keys are strings with a maximum length of 64 characters. Values are strings with\n     * a maximum length of 512 characters.\n     */\n    metadata?: Shared.Metadata | null;\n\n    /**\n     * The set of modalities the model can respond with. To disable audio, set this to\n     * [\"text\"].\n     */\n    modalities?: Array<'text' | 'audio'>;\n\n    /**\n     * The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n     */\n    output_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n    /**\n     * Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8.\n     */\n    temperature?: number;\n\n    /**\n     * How the model chooses tools. Options are `auto`, `none`, `required`, or specify\n     * a function, like `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}`.\n     */\n    tool_choice?: string;\n\n    /**\n     * Tools (functions) available to the model.\n     */\n    tools?: Array<Response.Tool>;\n\n    /**\n     * The voice the model uses to respond. Voice cannot be changed during the session\n     * once the model has responded with audio at least once. Current voice options are\n     * `alloy`, `ash`, `ballad`, `coral`, `echo`, `sage`, `shimmer`, and `verse`.\n     */\n    voice?: (string & {}) | 'alloy' | 'ash' | 'ballad' | 'coral' | 'echo' | 'sage' | 'shimmer' | 'verse';\n  }\n\n  export namespace Response {\n    export interface Tool {\n      /**\n       * The description of the function, including guidance on when and how to call it,\n       * and guidance about what to tell the user when calling (if anything).\n       */\n      description?: string;\n\n      /**\n       * The name of the function.\n       */\n      name?: string;\n\n      /**\n       * Parameters of the function in JSON Schema.\n       */\n      parameters?: unknown;\n\n      /**\n       * The type of the tool, i.e. `function`.\n       */\n      type?: 'function';\n    }\n  }\n}\n\n/**\n * Returned when a new Response is created. The first event of response creation,\n * where the response is in an initial state of `in_progress`.\n */\nexport interface ResponseCreatedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The response resource.\n   */\n  response: RealtimeResponse;\n\n  /**\n   * The event type, must be `response.created`.\n   */\n  type: 'response.created';\n}\n\n/**\n * Returned when a Response is done streaming. Always emitted, no matter the final\n * state. The Response object included in the `response.done` event will include\n * all output Items in the Response but will omit the raw audio data.\n */\nexport interface ResponseDoneEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The response resource.\n   */\n  response: RealtimeResponse;\n\n  /**\n   * The event type, must be `response.done`.\n   */\n  type: 'response.done';\n}\n\n/**\n * Returned when the model-generated function call arguments are updated.\n */\nexport interface ResponseFunctionCallArgumentsDeltaEvent {\n  /**\n   * The ID of the function call.\n   */\n  call_id: string;\n\n  /**\n   * The arguments delta as a JSON string.\n   */\n  delta: string;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the function call item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.function_call_arguments.delta`.\n   */\n  type: 'response.function_call_arguments.delta';\n}\n\n/**\n * Returned when the model-generated function call arguments are done streaming.\n * Also emitted when a Response is interrupted, incomplete, or cancelled.\n */\nexport interface ResponseFunctionCallArgumentsDoneEvent {\n  /**\n   * The final arguments as a JSON string.\n   */\n  arguments: string;\n\n  /**\n   * The ID of the function call.\n   */\n  call_id: string;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the function call item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.function_call_arguments.done`.\n   */\n  type: 'response.function_call_arguments.done';\n}\n\n/**\n * Returned when a new Item is created during Response generation.\n */\nexport interface ResponseOutputItemAddedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The item to add to the conversation.\n   */\n  item: ConversationItem;\n\n  /**\n   * The index of the output item in the Response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the Response to which the item belongs.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.output_item.added`.\n   */\n  type: 'response.output_item.added';\n}\n\n/**\n * Returned when an Item is done streaming. Also emitted when a Response is\n * interrupted, incomplete, or cancelled.\n */\nexport interface ResponseOutputItemDoneEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The item to add to the conversation.\n   */\n  item: ConversationItem;\n\n  /**\n   * The index of the output item in the Response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the Response to which the item belongs.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.output_item.done`.\n   */\n  type: 'response.output_item.done';\n}\n\n/**\n * Returned when the text value of a \"text\" content part is updated.\n */\nexport interface ResponseTextDeltaEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The text delta.\n   */\n  delta: string;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The event type, must be `response.text.delta`.\n   */\n  type: 'response.text.delta';\n}\n\n/**\n * Returned when the text value of a \"text\" content part is done streaming. Also\n * emitted when a Response is interrupted, incomplete, or cancelled.\n */\nexport interface ResponseTextDoneEvent {\n  /**\n   * The index of the content part in the item's content array.\n   */\n  content_index: number;\n\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * The ID of the item.\n   */\n  item_id: string;\n\n  /**\n   * The index of the output item in the response.\n   */\n  output_index: number;\n\n  /**\n   * The ID of the response.\n   */\n  response_id: string;\n\n  /**\n   * The final text content.\n   */\n  text: string;\n\n  /**\n   * The event type, must be `response.text.done`.\n   */\n  type: 'response.text.done';\n}\n\n/**\n * Returned when a Session is created. Emitted automatically when a new connection\n * is established as the first server event. This event will contain the default\n * Session configuration.\n */\nexport interface SessionCreatedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * Realtime session object configuration.\n   */\n  session: SessionsAPI.Session;\n\n  /**\n   * The event type, must be `session.created`.\n   */\n  type: 'session.created';\n}\n\n/**\n * Send this event to update the sessions default configuration. The client may\n * send this event at any time to update any field, except for `voice`. However,\n * note that once a session has been initialized with a particular `model`, it\n * cant be changed to another model using `session.update`.\n *\n * When the server receives a `session.update`, it will respond with a\n * `session.updated` event showing the full, effective configuration. Only the\n * fields that are present are updated. To clear a field like `instructions`, pass\n * an empty string.\n */\nexport interface SessionUpdateEvent {\n  /**\n   * Realtime session object configuration.\n   */\n  session: SessionUpdateEvent.Session;\n\n  /**\n   * The event type, must be `session.update`.\n   */\n  type: 'session.update';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\nexport namespace SessionUpdateEvent {\n  /**\n   * Realtime session object configuration.\n   */\n  export interface Session {\n    /**\n     * Configuration options for the generated client secret.\n     */\n    client_secret?: Session.ClientSecret;\n\n    /**\n     * The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`. For\n     * `pcm16`, input audio must be 16-bit PCM at a 24kHz sample rate, single channel\n     * (mono), and little-endian byte order.\n     */\n    input_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n    /**\n     * Configuration for input audio noise reduction. This can be set to `null` to turn\n     * off. Noise reduction filters audio added to the input audio buffer before it is\n     * sent to VAD and the model. Filtering the audio can improve VAD and turn\n     * detection accuracy (reducing false positives) and model performance by improving\n     * perception of the input audio.\n     */\n    input_audio_noise_reduction?: Session.InputAudioNoiseReduction;\n\n    /**\n     * Configuration for input audio transcription, defaults to off and can be set to\n     * `null` to turn off once on. Input audio transcription is not native to the\n     * model, since the model consumes audio directly. Transcription runs\n     * asynchronously through\n     * [the /audio/transcriptions endpoint](https://platform.openai.com/docs/api-reference/audio/createTranscription)\n     * and should be treated as guidance of input audio content rather than precisely\n     * what the model heard. The client can optionally set the language and prompt for\n     * transcription, these offer additional guidance to the transcription service.\n     */\n    input_audio_transcription?: Session.InputAudioTranscription;\n\n    /**\n     * The default system instructions (i.e. system message) prepended to model calls.\n     * This field allows the client to guide the model on desired responses. The model\n     * can be instructed on response content and format, (e.g. \"be extremely succinct\",\n     * \"act friendly\", \"here are examples of good responses\") and on audio behavior\n     * (e.g. \"talk quickly\", \"inject emotion into your voice\", \"laugh frequently\"). The\n     * instructions are not guaranteed to be followed by the model, but they provide\n     * guidance to the model on the desired behavior.\n     *\n     * Note that the server sets default instructions which will be used if this field\n     * is not set and are visible in the `session.created` event at the start of the\n     * session.\n     */\n    instructions?: string;\n\n    /**\n     * Maximum number of output tokens for a single assistant response, inclusive of\n     * tool calls. Provide an integer between 1 and 4096 to limit output tokens, or\n     * `inf` for the maximum available tokens for a given model. Defaults to `inf`.\n     */\n    max_response_output_tokens?: number | 'inf';\n\n    /**\n     * The set of modalities the model can respond with. To disable audio, set this to\n     * [\"text\"].\n     */\n    modalities?: Array<'text' | 'audio'>;\n\n    /**\n     * The Realtime model used for this session.\n     */\n    model?:\n      | 'gpt-4o-realtime-preview'\n      | 'gpt-4o-realtime-preview-2024-10-01'\n      | 'gpt-4o-realtime-preview-2024-12-17'\n      | 'gpt-4o-realtime-preview-2025-06-03'\n      | 'gpt-4o-mini-realtime-preview'\n      | 'gpt-4o-mini-realtime-preview-2024-12-17';\n\n    /**\n     * The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n     * For `pcm16`, output audio is sampled at a rate of 24kHz.\n     */\n    output_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n    /**\n     * The speed of the model's spoken response. 1.0 is the default speed. 0.25 is the\n     * minimum speed. 1.5 is the maximum speed. This value can only be changed in\n     * between model turns, not while a response is in progress.\n     */\n    speed?: number;\n\n    /**\n     * Sampling temperature for the model, limited to [0.6, 1.2]. For audio models a\n     * temperature of 0.8 is highly recommended for best performance.\n     */\n    temperature?: number;\n\n    /**\n     * How the model chooses tools. Options are `auto`, `none`, `required`, or specify\n     * a function.\n     */\n    tool_choice?: string;\n\n    /**\n     * Tools (functions) available to the model.\n     */\n    tools?: Array<Session.Tool>;\n\n    /**\n     * Configuration options for tracing. Set to null to disable tracing. Once tracing\n     * is enabled for a session, the configuration cannot be modified.\n     *\n     * `auto` will create a trace for the session with default values for the workflow\n     * name, group id, and metadata.\n     */\n    tracing?: 'auto' | Session.TracingConfiguration;\n\n    /**\n     * Configuration for turn detection, ether Server VAD or Semantic VAD. This can be\n     * set to `null` to turn off, in which case the client must manually trigger model\n     * response. Server VAD means that the model will detect the start and end of\n     * speech based on audio volume and respond at the end of user speech. Semantic VAD\n     * is more advanced and uses a turn detection model (in conjunction with VAD) to\n     * semantically estimate whether the user has finished speaking, then dynamically\n     * sets a timeout based on this probability. For example, if user audio trails off\n     * with \"uhhm\", the model will score a low probability of turn end and wait longer\n     * for the user to continue speaking. This can be useful for more natural\n     * conversations, but may have a higher latency.\n     */\n    turn_detection?: Session.TurnDetection;\n\n    /**\n     * The voice the model uses to respond. Voice cannot be changed during the session\n     * once the model has responded with audio at least once. Current voice options are\n     * `alloy`, `ash`, `ballad`, `coral`, `echo`, `sage`, `shimmer`, and `verse`.\n     */\n    voice?: (string & {}) | 'alloy' | 'ash' | 'ballad' | 'coral' | 'echo' | 'sage' | 'shimmer' | 'verse';\n  }\n\n  export namespace Session {\n    /**\n     * Configuration options for the generated client secret.\n     */\n    export interface ClientSecret {\n      /**\n       * Configuration for the ephemeral token expiration.\n       */\n      expires_after?: ClientSecret.ExpiresAfter;\n    }\n\n    export namespace ClientSecret {\n      /**\n       * Configuration for the ephemeral token expiration.\n       */\n      export interface ExpiresAfter {\n        /**\n         * The anchor point for the ephemeral token expiration. Only `created_at` is\n         * currently supported.\n         */\n        anchor: 'created_at';\n\n        /**\n         * The number of seconds from the anchor point to the expiration. Select a value\n         * between `10` and `7200`.\n         */\n        seconds?: number;\n      }\n    }\n\n    /**\n     * Configuration for input audio noise reduction. This can be set to `null` to turn\n     * off. Noise reduction filters audio added to the input audio buffer before it is\n     * sent to VAD and the model. Filtering the audio can improve VAD and turn\n     * detection accuracy (reducing false positives) and model performance by improving\n     * perception of the input audio.\n     */\n    export interface InputAudioNoiseReduction {\n      /**\n       * Type of noise reduction. `near_field` is for close-talking microphones such as\n       * headphones, `far_field` is for far-field microphones such as laptop or\n       * conference room microphones.\n       */\n      type?: 'near_field' | 'far_field';\n    }\n\n    /**\n     * Configuration for input audio transcription, defaults to off and can be set to\n     * `null` to turn off once on. Input audio transcription is not native to the\n     * model, since the model consumes audio directly. Transcription runs\n     * asynchronously through\n     * [the /audio/transcriptions endpoint](https://platform.openai.com/docs/api-reference/audio/createTranscription)\n     * and should be treated as guidance of input audio content rather than precisely\n     * what the model heard. The client can optionally set the language and prompt for\n     * transcription, these offer additional guidance to the transcription service.\n     */\n    export interface InputAudioTranscription {\n      /**\n       * The language of the input audio. Supplying the input language in\n       * [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`)\n       * format will improve accuracy and latency.\n       */\n      language?: string;\n\n      /**\n       * The model to use for transcription, current options are `gpt-4o-transcribe`,\n       * `gpt-4o-mini-transcribe`, and `whisper-1`.\n       */\n      model?: string;\n\n      /**\n       * An optional text to guide the model's style or continue a previous audio\n       * segment. For `whisper-1`, the\n       * [prompt is a list of keywords](https://platform.openai.com/docs/guides/speech-to-text#prompting).\n       * For `gpt-4o-transcribe` models, the prompt is a free text string, for example\n       * \"expect words related to technology\".\n       */\n      prompt?: string;\n    }\n\n    export interface Tool {\n      /**\n       * The description of the function, including guidance on when and how to call it,\n       * and guidance about what to tell the user when calling (if anything).\n       */\n      description?: string;\n\n      /**\n       * The name of the function.\n       */\n      name?: string;\n\n      /**\n       * Parameters of the function in JSON Schema.\n       */\n      parameters?: unknown;\n\n      /**\n       * The type of the tool, i.e. `function`.\n       */\n      type?: 'function';\n    }\n\n    /**\n     * Granular configuration for tracing.\n     */\n    export interface TracingConfiguration {\n      /**\n       * The group id to attach to this trace to enable filtering and grouping in the\n       * traces dashboard.\n       */\n      group_id?: string;\n\n      /**\n       * The arbitrary metadata to attach to this trace to enable filtering in the traces\n       * dashboard.\n       */\n      metadata?: unknown;\n\n      /**\n       * The name of the workflow to attach to this trace. This is used to name the trace\n       * in the traces dashboard.\n       */\n      workflow_name?: string;\n    }\n\n    /**\n     * Configuration for turn detection, ether Server VAD or Semantic VAD. This can be\n     * set to `null` to turn off, in which case the client must manually trigger model\n     * response. Server VAD means that the model will detect the start and end of\n     * speech based on audio volume and respond at the end of user speech. Semantic VAD\n     * is more advanced and uses a turn detection model (in conjunction with VAD) to\n     * semantically estimate whether the user has finished speaking, then dynamically\n     * sets a timeout based on this probability. For example, if user audio trails off\n     * with \"uhhm\", the model will score a low probability of turn end and wait longer\n     * for the user to continue speaking. This can be useful for more natural\n     * conversations, but may have a higher latency.\n     */\n    export interface TurnDetection {\n      /**\n       * Whether or not to automatically generate a response when a VAD stop event\n       * occurs.\n       */\n      create_response?: boolean;\n\n      /**\n       * Used only for `semantic_vad` mode. The eagerness of the model to respond. `low`\n       * will wait longer for the user to continue speaking, `high` will respond more\n       * quickly. `auto` is the default and is equivalent to `medium`.\n       */\n      eagerness?: 'low' | 'medium' | 'high' | 'auto';\n\n      /**\n       * Whether or not to automatically interrupt any ongoing response with output to\n       * the default conversation (i.e. `conversation` of `auto`) when a VAD start event\n       * occurs.\n       */\n      interrupt_response?: boolean;\n\n      /**\n       * Used only for `server_vad` mode. Amount of audio to include before the VAD\n       * detected speech (in milliseconds). Defaults to 300ms.\n       */\n      prefix_padding_ms?: number;\n\n      /**\n       * Used only for `server_vad` mode. Duration of silence to detect speech stop (in\n       * milliseconds). Defaults to 500ms. With shorter values the model will respond\n       * more quickly, but may jump in on short pauses from the user.\n       */\n      silence_duration_ms?: number;\n\n      /**\n       * Used only for `server_vad` mode. Activation threshold for VAD (0.0 to 1.0), this\n       * defaults to 0.5. A higher threshold will require louder audio to activate the\n       * model, and thus might perform better in noisy environments.\n       */\n      threshold?: number;\n\n      /**\n       * Type of turn detection.\n       */\n      type?: 'server_vad' | 'semantic_vad';\n    }\n  }\n}\n\n/**\n * Returned when a session is updated with a `session.update` event, unless there\n * is an error.\n */\nexport interface SessionUpdatedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * Realtime session object configuration.\n   */\n  session: SessionsAPI.Session;\n\n  /**\n   * The event type, must be `session.updated`.\n   */\n  type: 'session.updated';\n}\n\n/**\n * Send this event to update a transcription session.\n */\nexport interface TranscriptionSessionUpdate {\n  /**\n   * Realtime transcription session object configuration.\n   */\n  session: TranscriptionSessionUpdate.Session;\n\n  /**\n   * The event type, must be `transcription_session.update`.\n   */\n  type: 'transcription_session.update';\n\n  /**\n   * Optional client-generated ID used to identify this event.\n   */\n  event_id?: string;\n}\n\nexport namespace TranscriptionSessionUpdate {\n  /**\n   * Realtime transcription session object configuration.\n   */\n  export interface Session {\n    /**\n     * Configuration options for the generated client secret.\n     */\n    client_secret?: Session.ClientSecret;\n\n    /**\n     * The set of items to include in the transcription. Current available items are:\n     *\n     * - `item.input_audio_transcription.logprobs`\n     */\n    include?: Array<string>;\n\n    /**\n     * The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`. For\n     * `pcm16`, input audio must be 16-bit PCM at a 24kHz sample rate, single channel\n     * (mono), and little-endian byte order.\n     */\n    input_audio_format?: 'pcm16' | 'g711_ulaw' | 'g711_alaw';\n\n    /**\n     * Configuration for input audio noise reduction. This can be set to `null` to turn\n     * off. Noise reduction filters audio added to the input audio buffer before it is\n     * sent to VAD and the model. Filtering the audio can improve VAD and turn\n     * detection accuracy (reducing false positives) and model performance by improving\n     * perception of the input audio.\n     */\n    input_audio_noise_reduction?: Session.InputAudioNoiseReduction;\n\n    /**\n     * Configuration for input audio transcription. The client can optionally set the\n     * language and prompt for transcription, these offer additional guidance to the\n     * transcription service.\n     */\n    input_audio_transcription?: Session.InputAudioTranscription;\n\n    /**\n     * The set of modalities the model can respond with. To disable audio, set this to\n     * [\"text\"].\n     */\n    modalities?: Array<'text' | 'audio'>;\n\n    /**\n     * Configuration for turn detection, ether Server VAD or Semantic VAD. This can be\n     * set to `null` to turn off, in which case the client must manually trigger model\n     * response. Server VAD means that the model will detect the start and end of\n     * speech based on audio volume and respond at the end of user speech. Semantic VAD\n     * is more advanced and uses a turn detection model (in conjunction with VAD) to\n     * semantically estimate whether the user has finished speaking, then dynamically\n     * sets a timeout based on this probability. For example, if user audio trails off\n     * with \"uhhm\", the model will score a low probability of turn end and wait longer\n     * for the user to continue speaking. This can be useful for more natural\n     * conversations, but may have a higher latency.\n     */\n    turn_detection?: Session.TurnDetection;\n  }\n\n  export namespace Session {\n    /**\n     * Configuration options for the generated client secret.\n     */\n    export interface ClientSecret {\n      /**\n       * Configuration for the ephemeral token expiration.\n       */\n      expires_at?: ClientSecret.ExpiresAt;\n    }\n\n    export namespace ClientSecret {\n      /**\n       * Configuration for the ephemeral token expiration.\n       */\n      export interface ExpiresAt {\n        /**\n         * The anchor point for the ephemeral token expiration. Only `created_at` is\n         * currently supported.\n         */\n        anchor?: 'created_at';\n\n        /**\n         * The number of seconds from the anchor point to the expiration. Select a value\n         * between `10` and `7200`.\n         */\n        seconds?: number;\n      }\n    }\n\n    /**\n     * Configuration for input audio noise reduction. This can be set to `null` to turn\n     * off. Noise reduction filters audio added to the input audio buffer before it is\n     * sent to VAD and the model. Filtering the audio can improve VAD and turn\n     * detection accuracy (reducing false positives) and model performance by improving\n     * perception of the input audio.\n     */\n    export interface InputAudioNoiseReduction {\n      /**\n       * Type of noise reduction. `near_field` is for close-talking microphones such as\n       * headphones, `far_field` is for far-field microphones such as laptop or\n       * conference room microphones.\n       */\n      type?: 'near_field' | 'far_field';\n    }\n\n    /**\n     * Configuration for input audio transcription. The client can optionally set the\n     * language and prompt for transcription, these offer additional guidance to the\n     * transcription service.\n     */\n    export interface InputAudioTranscription {\n      /**\n       * The language of the input audio. Supplying the input language in\n       * [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`)\n       * format will improve accuracy and latency.\n       */\n      language?: string;\n\n      /**\n       * The model to use for transcription, current options are `gpt-4o-transcribe`,\n       * `gpt-4o-mini-transcribe`, and `whisper-1`.\n       */\n      model?: 'gpt-4o-transcribe' | 'gpt-4o-mini-transcribe' | 'whisper-1';\n\n      /**\n       * An optional text to guide the model's style or continue a previous audio\n       * segment. For `whisper-1`, the\n       * [prompt is a list of keywords](https://platform.openai.com/docs/guides/speech-to-text#prompting).\n       * For `gpt-4o-transcribe` models, the prompt is a free text string, for example\n       * \"expect words related to technology\".\n       */\n      prompt?: string;\n    }\n\n    /**\n     * Configuration for turn detection, ether Server VAD or Semantic VAD. This can be\n     * set to `null` to turn off, in which case the client must manually trigger model\n     * response. Server VAD means that the model will detect the start and end of\n     * speech based on audio volume and respond at the end of user speech. Semantic VAD\n     * is more advanced and uses a turn detection model (in conjunction with VAD) to\n     * semantically estimate whether the user has finished speaking, then dynamically\n     * sets a timeout based on this probability. For example, if user audio trails off\n     * with \"uhhm\", the model will score a low probability of turn end and wait longer\n     * for the user to continue speaking. This can be useful for more natural\n     * conversations, but may have a higher latency.\n     */\n    export interface TurnDetection {\n      /**\n       * Whether or not to automatically generate a response when a VAD stop event\n       * occurs. Not available for transcription sessions.\n       */\n      create_response?: boolean;\n\n      /**\n       * Used only for `semantic_vad` mode. The eagerness of the model to respond. `low`\n       * will wait longer for the user to continue speaking, `high` will respond more\n       * quickly. `auto` is the default and is equivalent to `medium`.\n       */\n      eagerness?: 'low' | 'medium' | 'high' | 'auto';\n\n      /**\n       * Whether or not to automatically interrupt any ongoing response with output to\n       * the default conversation (i.e. `conversation` of `auto`) when a VAD start event\n       * occurs. Not available for transcription sessions.\n       */\n      interrupt_response?: boolean;\n\n      /**\n       * Used only for `server_vad` mode. Amount of audio to include before the VAD\n       * detected speech (in milliseconds). Defaults to 300ms.\n       */\n      prefix_padding_ms?: number;\n\n      /**\n       * Used only for `server_vad` mode. Duration of silence to detect speech stop (in\n       * milliseconds). Defaults to 500ms. With shorter values the model will respond\n       * more quickly, but may jump in on short pauses from the user.\n       */\n      silence_duration_ms?: number;\n\n      /**\n       * Used only for `server_vad` mode. Activation threshold for VAD (0.0 to 1.0), this\n       * defaults to 0.5. A higher threshold will require louder audio to activate the\n       * model, and thus might perform better in noisy environments.\n       */\n      threshold?: number;\n\n      /**\n       * Type of turn detection.\n       */\n      type?: 'server_vad' | 'semantic_vad';\n    }\n  }\n}\n\n/**\n * Returned when a transcription session is updated with a\n * `transcription_session.update` event, unless there is an error.\n */\nexport interface TranscriptionSessionUpdatedEvent {\n  /**\n   * The unique ID of the server event.\n   */\n  event_id: string;\n\n  /**\n   * A new Realtime transcription session configuration.\n   *\n   * When a session is created on the server via REST API, the session object also\n   * contains an ephemeral key. Default TTL for keys is 10 minutes. This property is\n   * not present when a session is updated via the WebSocket API.\n   */\n  session: TranscriptionSessionsAPI.TranscriptionSession;\n\n  /**\n   * The event type, must be `transcription_session.updated`.\n   */\n  type: 'transcription_session.updated';\n}\n\nRealtime.Sessions = Sessions;\nRealtime.TranscriptionSessions = TranscriptionSessions;\n\nexport declare namespace Realtime {\n  export {\n    type ConversationCreatedEvent as ConversationCreatedEvent,\n    type ConversationItem as ConversationItem,\n    type ConversationItemContent as ConversationItemContent,\n    type ConversationItemCreateEvent as ConversationItemCreateEvent,\n    type ConversationItemCreatedEvent as ConversationItemCreatedEvent,\n    type ConversationItemDeleteEvent as ConversationItemDeleteEvent,\n    type ConversationItemDeletedEvent as ConversationItemDeletedEvent,\n    type ConversationItemInputAudioTranscriptionCompletedEvent as ConversationItemInputAudioTranscriptionCompletedEvent,\n    type ConversationItemInputAudioTranscriptionDeltaEvent as ConversationItemInputAudioTranscriptionDeltaEvent,\n    type ConversationItemInputAudioTranscriptionFailedEvent as ConversationItemInputAudioTranscriptionFailedEvent,\n    type ConversationItemRetrieveEvent as ConversationItemRetrieveEvent,\n    type ConversationItemTruncateEvent as ConversationItemTruncateEvent,\n    type ConversationItemTruncatedEvent as ConversationItemTruncatedEvent,\n    type ConversationItemWithReference as ConversationItemWithReference,\n    type ErrorEvent as ErrorEvent,\n    type InputAudioBufferAppendEvent as InputAudioBufferAppendEvent,\n    type InputAudioBufferClearEvent as InputAudioBufferClearEvent,\n    type InputAudioBufferClearedEvent as InputAudioBufferClearedEvent,\n    type InputAudioBufferCommitEvent as InputAudioBufferCommitEvent,\n    type InputAudioBufferCommittedEvent as InputAudioBufferCommittedEvent,\n    type InputAudioBufferSpeechStartedEvent as InputAudioBufferSpeechStartedEvent,\n    type InputAudioBufferSpeechStoppedEvent as InputAudioBufferSpeechStoppedEvent,\n    type RateLimitsUpdatedEvent as RateLimitsUpdatedEvent,\n    type RealtimeClientEvent as RealtimeClientEvent,\n    type RealtimeResponse as RealtimeResponse,\n    type RealtimeResponseStatus as RealtimeResponseStatus,\n    type RealtimeResponseUsage as RealtimeResponseUsage,\n    type RealtimeServerEvent as RealtimeServerEvent,\n    type ResponseAudioDeltaEvent as ResponseAudioDeltaEvent,\n    type ResponseAudioDoneEvent as ResponseAudioDoneEvent,\n    type ResponseAudioTranscriptDeltaEvent as ResponseAudioTranscriptDeltaEvent,\n    type ResponseAudioTranscriptDoneEvent as ResponseAudioTranscriptDoneEvent,\n    type ResponseCancelEvent as ResponseCancelEvent,\n    type ResponseContentPartAddedEvent as ResponseContentPartAddedEvent,\n    type ResponseContentPartDoneEvent as ResponseContentPartDoneEvent,\n    type ResponseCreateEvent as ResponseCreateEvent,\n    type ResponseCreatedEvent as ResponseCreatedEvent,\n    type ResponseDoneEvent as ResponseDoneEvent,\n    type ResponseFunctionCallArgumentsDeltaEvent as ResponseFunctionCallArgumentsDeltaEvent,\n    type ResponseFunctionCallArgumentsDoneEvent as ResponseFunctionCallArgumentsDoneEvent,\n    type ResponseOutputItemAddedEvent as ResponseOutputItemAddedEvent,\n    type ResponseOutputItemDoneEvent as ResponseOutputItemDoneEvent,\n    type ResponseTextDeltaEvent as ResponseTextDeltaEvent,\n    type ResponseTextDoneEvent as ResponseTextDoneEvent,\n    type SessionCreatedEvent as SessionCreatedEvent,\n    type SessionUpdateEvent as SessionUpdateEvent,\n    type SessionUpdatedEvent as SessionUpdatedEvent,\n    type TranscriptionSessionUpdate as TranscriptionSessionUpdate,\n    type TranscriptionSessionUpdatedEvent as TranscriptionSessionUpdatedEvent,\n  };\n\n  export {\n    Sessions as Sessions,\n    type SessionsAPISession as Session,\n    type SessionCreateResponse as SessionCreateResponse,\n    type SessionCreateParams as SessionCreateParams,\n  };\n\n  export {\n    TranscriptionSessions as TranscriptionSessions,\n    type TranscriptionSession as TranscriptionSession,\n    type TranscriptionSessionCreateParams as TranscriptionSessionCreateParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nexport { OpenAI as default } from './client';\n\nexport { type Uploadable, toFile } from './core/uploads';\nexport { APIPromise } from './core/api-promise';\nexport { OpenAI, type ClientOptions } from './client';\nexport { PagePromise } from './core/pagination';\nexport {\n  OpenAIError,\n  APIError,\n  APIConnectionError,\n  APIConnectionTimeoutError,\n  APIUserAbortError,\n  NotFoundError,\n  ConflictError,\n  RateLimitError,\n  BadRequestError,\n  AuthenticationError,\n  InternalServerError,\n  PermissionDeniedError,\n  UnprocessableEntityError,\n  InvalidWebhookSignatureError,\n} from './core/error';\n\nexport { AzureOpenAI } from './azure';\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../core/resource';\nimport * as PermissionsAPI from './permissions';\nimport {\n  PermissionCreateParams,\n  PermissionCreateResponse,\n  PermissionCreateResponsesPage,\n  PermissionDeleteParams,\n  PermissionDeleteResponse,\n  PermissionRetrieveParams,\n  PermissionRetrieveResponse,\n  Permissions,\n} from './permissions';\n\nexport class Checkpoints extends APIResource {\n  permissions: PermissionsAPI.Permissions = new PermissionsAPI.Permissions(this._client);\n}\n\nCheckpoints.Permissions = Permissions;\n\nexport declare namespace Checkpoints {\n  export {\n    Permissions as Permissions,\n    type PermissionCreateResponse as PermissionCreateResponse,\n    type PermissionRetrieveResponse as PermissionRetrieveResponse,\n    type PermissionDeleteResponse as PermissionDeleteResponse,\n    type PermissionCreateResponsesPage as PermissionCreateResponsesPage,\n    type PermissionCreateParams as PermissionCreateParams,\n    type PermissionRetrieveParams as PermissionRetrieveParams,\n    type PermissionDeleteParams as PermissionDeleteParams,\n  };\n}\n","import { ContentFilterFinishReasonError, LengthFinishReasonError, OpenAIError } from '../error';\nimport {\n  ChatCompletion,\n  ChatCompletionCreateParams,\n  ChatCompletionCreateParamsBase,\n  ChatCompletionFunctionTool,\n  ChatCompletionMessage,\n  ChatCompletionMessageFunctionToolCall,\n  ChatCompletionStreamingToolRunnerParams,\n  ChatCompletionStreamParams,\n  ChatCompletionToolRunnerParams,\n  ParsedChatCompletion,\n  ParsedChoice,\n  ParsedFunctionToolCall,\n} from '../resources/chat/completions';\nimport { type ResponseFormatTextJSONSchemaConfig } from '../resources/responses/responses';\nimport { ResponseFormatJSONSchema } from '../resources/shared';\n\ntype AnyChatCompletionCreateParams =\n  | ChatCompletionCreateParams\n  | ChatCompletionToolRunnerParams<any>\n  | ChatCompletionStreamingToolRunnerParams<any>\n  | ChatCompletionStreamParams;\n\ntype Unpacked<T> = T extends (infer U)[] ? U : T;\n\ntype ToolCall = Unpacked<ChatCompletionCreateParamsBase['tools']>;\n\nexport function isChatCompletionFunctionTool(tool: ToolCall): tool is ChatCompletionFunctionTool {\n  return tool !== undefined && 'function' in tool && tool.function !== undefined;\n}\n\nexport type ExtractParsedContentFromParams<Params extends AnyChatCompletionCreateParams> =\n  Params['response_format'] extends AutoParseableResponseFormat<infer P> ? P : null;\n\nexport type AutoParseableResponseFormat<ParsedT> = ResponseFormatJSONSchema & {\n  __output: ParsedT; // type-level only\n\n  $brand: 'auto-parseable-response-format';\n  $parseRaw(content: string): ParsedT;\n};\n\nexport function makeParseableResponseFormat<ParsedT>(\n  response_format: ResponseFormatJSONSchema,\n  parser: (content: string) => ParsedT,\n): AutoParseableResponseFormat<ParsedT> {\n  const obj = { ...response_format };\n\n  Object.defineProperties(obj, {\n    $brand: {\n      value: 'auto-parseable-response-format',\n      enumerable: false,\n    },\n    $parseRaw: {\n      value: parser,\n      enumerable: false,\n    },\n  });\n\n  return obj as AutoParseableResponseFormat<ParsedT>;\n}\n\nexport type AutoParseableTextFormat<ParsedT> = ResponseFormatTextJSONSchemaConfig & {\n  __output: ParsedT; // type-level only\n\n  $brand: 'auto-parseable-response-format';\n  $parseRaw(content: string): ParsedT;\n};\n\nexport function makeParseableTextFormat<ParsedT>(\n  response_format: ResponseFormatTextJSONSchemaConfig,\n  parser: (content: string) => ParsedT,\n): AutoParseableTextFormat<ParsedT> {\n  const obj = { ...response_format };\n\n  Object.defineProperties(obj, {\n    $brand: {\n      value: 'auto-parseable-response-format',\n      enumerable: false,\n    },\n    $parseRaw: {\n      value: parser,\n      enumerable: false,\n    },\n  });\n\n  return obj as AutoParseableTextFormat<ParsedT>;\n}\n\nexport function isAutoParsableResponseFormat<ParsedT>(\n  response_format: any,\n): response_format is AutoParseableResponseFormat<ParsedT> {\n  return response_format?.['$brand'] === 'auto-parseable-response-format';\n}\n\ntype ToolOptions = {\n  name: string;\n  arguments: any;\n  function?: ((args: any) => any) | undefined;\n};\n\nexport type AutoParseableTool<\n  OptionsT extends ToolOptions,\n  HasFunction = OptionsT['function'] extends Function ? true : false,\n> = ChatCompletionFunctionTool & {\n  __arguments: OptionsT['arguments']; // type-level only\n  __name: OptionsT['name']; // type-level only\n  __hasFunction: HasFunction; // type-level only\n\n  $brand: 'auto-parseable-tool';\n  $callback: ((args: OptionsT['arguments']) => any) | undefined;\n  $parseRaw(args: string): OptionsT['arguments'];\n};\n\nexport function makeParseableTool<OptionsT extends ToolOptions>(\n  tool: ChatCompletionFunctionTool,\n  {\n    parser,\n    callback,\n  }: {\n    parser: (content: string) => OptionsT['arguments'];\n    callback: ((args: any) => any) | undefined;\n  },\n): AutoParseableTool<OptionsT['arguments']> {\n  const obj = { ...tool };\n\n  Object.defineProperties(obj, {\n    $brand: {\n      value: 'auto-parseable-tool',\n      enumerable: false,\n    },\n    $parseRaw: {\n      value: parser,\n      enumerable: false,\n    },\n    $callback: {\n      value: callback,\n      enumerable: false,\n    },\n  });\n\n  return obj as AutoParseableTool<OptionsT['arguments']>;\n}\n\nexport function isAutoParsableTool(tool: any): tool is AutoParseableTool<any> {\n  return tool?.['$brand'] === 'auto-parseable-tool';\n}\n\nexport function maybeParseChatCompletion<\n  Params extends ChatCompletionCreateParams | null,\n  ParsedT = Params extends null ? null : ExtractParsedContentFromParams<NonNullable<Params>>,\n>(completion: ChatCompletion, params: Params): ParsedChatCompletion<ParsedT> {\n  if (!params || !hasAutoParseableInput(params)) {\n    return {\n      ...completion,\n      choices: completion.choices.map((choice) => {\n        assertToolCallsAreChatCompletionFunctionToolCalls(choice.message.tool_calls);\n\n        return {\n          ...choice,\n          message: {\n            ...choice.message,\n            parsed: null,\n            ...(choice.message.tool_calls ?\n              {\n                tool_calls: choice.message.tool_calls,\n              }\n            : undefined),\n          },\n        };\n      }),\n    } as ParsedChatCompletion<ParsedT>;\n  }\n\n  return parseChatCompletion(completion, params);\n}\n\nexport function parseChatCompletion<\n  Params extends ChatCompletionCreateParams,\n  ParsedT = ExtractParsedContentFromParams<Params>,\n>(completion: ChatCompletion, params: Params): ParsedChatCompletion<ParsedT> {\n  const choices: Array<ParsedChoice<ParsedT>> = completion.choices.map((choice): ParsedChoice<ParsedT> => {\n    if (choice.finish_reason === 'length') {\n      throw new LengthFinishReasonError();\n    }\n\n    if (choice.finish_reason === 'content_filter') {\n      throw new ContentFilterFinishReasonError();\n    }\n\n    assertToolCallsAreChatCompletionFunctionToolCalls(choice.message.tool_calls);\n\n    return {\n      ...choice,\n      message: {\n        ...choice.message,\n        ...(choice.message.tool_calls ?\n          {\n            tool_calls:\n              choice.message.tool_calls?.map((toolCall) => parseToolCall(params, toolCall)) ?? undefined,\n          }\n        : undefined),\n        parsed:\n          choice.message.content && !choice.message.refusal ?\n            parseResponseFormat(params, choice.message.content)\n          : null,\n      },\n    } as ParsedChoice<ParsedT>;\n  });\n\n  return { ...completion, choices };\n}\n\nfunction parseResponseFormat<\n  Params extends ChatCompletionCreateParams,\n  ParsedT = ExtractParsedContentFromParams<Params>,\n>(params: Params, content: string): ParsedT | null {\n  if (params.response_format?.type !== 'json_schema') {\n    return null;\n  }\n\n  if (params.response_format?.type === 'json_schema') {\n    if ('$parseRaw' in params.response_format) {\n      const response_format = params.response_format as AutoParseableResponseFormat<ParsedT>;\n\n      return response_format.$parseRaw(content);\n    }\n\n    return JSON.parse(content);\n  }\n\n  return null;\n}\n\nfunction parseToolCall<Params extends ChatCompletionCreateParams>(\n  params: Params,\n  toolCall: ChatCompletionMessageFunctionToolCall,\n): ParsedFunctionToolCall {\n  const inputTool = params.tools?.find(\n    (inputTool) =>\n      isChatCompletionFunctionTool(inputTool) && inputTool.function?.name === toolCall.function.name,\n  ) as ChatCompletionFunctionTool | undefined; // TS doesn't narrow based on isChatCompletionTool\n  return {\n    ...toolCall,\n    function: {\n      ...toolCall.function,\n      parsed_arguments:\n        isAutoParsableTool(inputTool) ? inputTool.$parseRaw(toolCall.function.arguments)\n        : inputTool?.function.strict ? JSON.parse(toolCall.function.arguments)\n        : null,\n    },\n  };\n}\n\nexport function shouldParseToolCall(\n  params: ChatCompletionCreateParams | null | undefined,\n  toolCall: ChatCompletionMessageFunctionToolCall,\n): boolean {\n  if (!params || !('tools' in params) || !params.tools) {\n    return false;\n  }\n\n  const inputTool = params.tools?.find(\n    (inputTool) =>\n      isChatCompletionFunctionTool(inputTool) && inputTool.function?.name === toolCall.function.name,\n  );\n  return (\n    isChatCompletionFunctionTool(inputTool) &&\n    (isAutoParsableTool(inputTool) || inputTool?.function.strict || false)\n  );\n}\n\nexport function hasAutoParseableInput(params: AnyChatCompletionCreateParams): boolean {\n  if (isAutoParsableResponseFormat(params.response_format)) {\n    return true;\n  }\n\n  return (\n    params.tools?.some(\n      (t) => isAutoParsableTool(t) || (t.type === 'function' && t.function.strict === true),\n    ) ?? false\n  );\n}\n\nexport function assertToolCallsAreChatCompletionFunctionToolCalls(\n  toolCalls: ChatCompletionMessage['tool_calls'],\n): asserts toolCalls is ChatCompletionMessageFunctionToolCall[] {\n  for (const toolCall of toolCalls || []) {\n    if (toolCall.type !== 'function') {\n      throw new OpenAIError(\n        `Currently only \\`function\\` tool calls are supported; Received \\`${toolCall.type}\\``,\n      );\n    }\n  }\n}\n\nexport function validateInputTools(tools: ChatCompletionCreateParamsBase['tools']) {\n  for (const tool of tools ?? []) {\n    if (tool.type !== 'function') {\n      throw new OpenAIError(\n        `Currently only \\`function\\` tool types support auto-parsing; Received \\`${tool.type}\\``,\n      );\n    }\n\n    if (tool.function.strict !== true) {\n      throw new OpenAIError(\n        `The \\`${tool.function.name}\\` tool is not marked with \\`strict: true\\`. Only strict function tools can be auto-parsed`,\n      );\n    }\n  }\n}\n","import { type RequestOptions } from './request-options';\nimport type { FilePropertyBag, Fetch } from './builtin-types';\nimport type { OpenAI } from '../client';\nimport { ReadableStreamFrom } from './shims';\n\nexport type BlobPart = string | ArrayBuffer | ArrayBufferView | Blob | DataView;\ntype FsReadStream = AsyncIterable<Uint8Array> & { path: string | { toString(): string } };\n\n// https://github.com/oven-sh/bun/issues/5980\ninterface BunFile extends Blob {\n  readonly name?: string | undefined;\n}\n\nexport const checkFileSupport = () => {\n  if (typeof File === 'undefined') {\n    const { process } = globalThis as any;\n    const isOldNode =\n      typeof process?.versions?.node === 'string' && parseInt(process.versions.node.split('.')) < 20;\n    throw new Error(\n      '`File` is not defined as a global, which is required for file uploads.' +\n        (isOldNode ?\n          \" Update to Node 20 LTS or newer, or set `globalThis.File` to `import('node:buffer').File`.\"\n        : ''),\n    );\n  }\n};\n\n/**\n * Typically, this is a native \"File\" class.\n *\n * We provide the {@link toFile} utility to convert a variety of objects\n * into the File class.\n *\n * For convenience, you can also pass a fetch Response, or in Node,\n * the result of fs.createReadStream().\n */\nexport type Uploadable = File | Response | FsReadStream | BunFile;\n\n/**\n * Construct a `File` instance. This is used to ensure a helpful error is thrown\n * for environments that don't define a global `File` yet.\n */\nexport function makeFile(\n  fileBits: BlobPart[],\n  fileName: string | undefined,\n  options?: FilePropertyBag,\n): File {\n  checkFileSupport();\n  return new File(fileBits as any, fileName ?? 'unknown_file', options);\n}\n\nexport function getName(value: any): string | undefined {\n  return (\n    (\n      (typeof value === 'object' &&\n        value !== null &&\n        (('name' in value && value.name && String(value.name)) ||\n          ('url' in value && value.url && String(value.url)) ||\n          ('filename' in value && value.filename && String(value.filename)) ||\n          ('path' in value && value.path && String(value.path)))) ||\n      ''\n    )\n      .split(/[\\\\/]/)\n      .pop() || undefined\n  );\n}\n\nexport const isAsyncIterable = (value: any): value is AsyncIterable<any> =>\n  value != null && typeof value === 'object' && typeof value[Symbol.asyncIterator] === 'function';\n\n/**\n * Returns a multipart/form-data request if any part of the given request body contains a File / Blob value.\n * Otherwise returns the request as is.\n */\nexport const maybeMultipartFormRequestOptions = async (\n  opts: RequestOptions,\n  fetch: OpenAI | Fetch,\n): Promise<RequestOptions> => {\n  if (!hasUploadableValue(opts.body)) return opts;\n\n  return { ...opts, body: await createForm(opts.body, fetch) };\n};\n\ntype MultipartFormRequestOptions = Omit<RequestOptions, 'body'> & { body: unknown };\n\nexport const multipartFormRequestOptions = async (\n  opts: MultipartFormRequestOptions,\n  fetch: OpenAI | Fetch,\n): Promise<RequestOptions> => {\n  return { ...opts, body: await createForm(opts.body, fetch) };\n};\n\nconst supportsFormDataMap = /* @__PURE__ */ new WeakMap<Fetch, Promise<boolean>>();\n\n/**\n * node-fetch doesn't support the global FormData object in recent node versions. Instead of sending\n * properly-encoded form data, it just stringifies the object, resulting in a request body of \"[object FormData]\".\n * This function detects if the fetch function provided supports the global FormData object to avoid\n * confusing error messages later on.\n */\nfunction supportsFormData(fetchObject: OpenAI | Fetch): Promise<boolean> {\n  const fetch: Fetch = typeof fetchObject === 'function' ? fetchObject : (fetchObject as any).fetch;\n  const cached = supportsFormDataMap.get(fetch);\n  if (cached) return cached;\n  const promise = (async () => {\n    try {\n      const FetchResponse = (\n        'Response' in fetch ?\n          fetch.Response\n        : (await fetch('data:,')).constructor) as typeof Response;\n      const data = new FormData();\n      if (data.toString() === (await new FetchResponse(data).text())) {\n        return false;\n      }\n      return true;\n    } catch {\n      // avoid false negatives\n      return true;\n    }\n  })();\n  supportsFormDataMap.set(fetch, promise);\n  return promise;\n}\n\nexport const createForm = async <T = Record<string, unknown>>(\n  body: T | undefined,\n  fetch: OpenAI | Fetch,\n): Promise<FormData> => {\n  if (!(await supportsFormData(fetch))) {\n    throw new TypeError(\n      'The provided fetch function does not support file uploads with the current global FormData class.',\n    );\n  }\n  const form = new FormData();\n  await Promise.all(Object.entries(body || {}).map(([key, value]) => addFormValue(form, key, value)));\n  return form;\n};\n\n// We check for Blob not File because Bun.File doesn't inherit from File,\n// but they both inherit from Blob and have a `name` property at runtime.\nconst isNamedBlob = (value: unknown) => value instanceof Blob && 'name' in value;\n\nconst isUploadable = (value: unknown) =>\n  typeof value === 'object' &&\n  value !== null &&\n  (value instanceof Response || isAsyncIterable(value) || isNamedBlob(value));\n\nconst hasUploadableValue = (value: unknown): boolean => {\n  if (isUploadable(value)) return true;\n  if (Array.isArray(value)) return value.some(hasUploadableValue);\n  if (value && typeof value === 'object') {\n    for (const k in value) {\n      if (hasUploadableValue((value as any)[k])) return true;\n    }\n  }\n  return false;\n};\n\nconst addFormValue = async (form: FormData, key: string, value: unknown): Promise<void> => {\n  if (value === undefined) return;\n  if (value == null) {\n    throw new TypeError(\n      `Received null for \"${key}\"; to pass null in FormData, you must use the string 'null'`,\n    );\n  }\n\n  // TODO: make nested formats configurable\n  if (typeof value === 'string' || typeof value === 'number' || typeof value === 'boolean') {\n    form.append(key, String(value));\n  } else if (value instanceof Response) {\n    form.append(key, makeFile([await value.blob()], getName(value)));\n  } else if (isAsyncIterable(value)) {\n    form.append(key, makeFile([await new Response(ReadableStreamFrom(value)).blob()], getName(value)));\n  } else if (isNamedBlob(value)) {\n    form.append(key, value, getName(value));\n  } else if (Array.isArray(value)) {\n    await Promise.all(value.map((entry) => addFormValue(form, key + '[]', entry)));\n  } else if (typeof value === 'object') {\n    await Promise.all(\n      Object.entries(value).map(([name, prop]) => addFormValue(form, `${key}[${name}]`, prop)),\n    );\n  } else {\n    throw new TypeError(\n      `Invalid value given to form, expected a string, number, boolean, object, Array, File or Blob but got ${value} instead`,\n    );\n  }\n};\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { NullableHeaders } from './headers';\n\nimport type { BodyInit } from './builtin-types';\nimport { Stream } from '../core/streaming';\nimport type { HTTPMethod, MergedRequestInit } from './types';\nimport { type HeadersLike } from './headers';\n\nexport type FinalRequestOptions = RequestOptions & { method: HTTPMethod; path: string };\n\nexport type RequestOptions = {\n  /**\n   * The HTTP method for the request (e.g., 'get', 'post', 'put', 'delete').\n   */\n  method?: HTTPMethod;\n\n  /**\n   * The URL path for the request.\n   *\n   * @example \"/v1/foo\"\n   */\n  path?: string;\n\n  /**\n   * Query parameters to include in the request URL.\n   */\n  query?: object | undefined | null;\n\n  /**\n   * The request body. Can be a string, JSON object, FormData, or other supported types.\n   */\n  body?: unknown;\n\n  /**\n   * HTTP headers to include with the request. Can be a Headers object, plain object, or array of tuples.\n   */\n  headers?: HeadersLike;\n\n  /**\n   * The maximum number of times that the client will retry a request in case of a\n   * temporary failure, like a network error or a 5XX error from the server.\n   *\n   * @default 2\n   */\n  maxRetries?: number;\n\n  stream?: boolean | undefined;\n\n  /**\n   * The maximum amount of time (in milliseconds) that the client should wait for a response\n   * from the server before timing out a single request.\n   *\n   * @unit milliseconds\n   */\n  timeout?: number;\n\n  /**\n   * Additional `RequestInit` options to be passed to the underlying `fetch` call.\n   * These options will be merged with the client's default fetch options.\n   */\n  fetchOptions?: MergedRequestInit;\n\n  /**\n   * An AbortSignal that can be used to cancel the request.\n   */\n  signal?: AbortSignal | undefined | null;\n\n  /**\n   * A unique key for this request to enable idempotency.\n   */\n  idempotencyKey?: string;\n\n  /**\n   * Override the default base URL for this specific request.\n   */\n  defaultBaseURL?: string | undefined;\n\n  __metadata?: Record<string, unknown>;\n  __binaryResponse?: boolean | undefined;\n  __streamClass?: typeof Stream;\n};\n\nexport type EncodedContent = { bodyHeaders: HeadersLike; body: BodyInit };\nexport type RequestEncoder = (request: { headers: NullableHeaders; body: unknown }) => EncodedContent;\n\nexport const FallbackEncoder: RequestEncoder = ({ headers, body }) => {\n  return {\n    bodyHeaders: {\n      'content-type': 'application/json',\n    },\n    body: JSON.stringify(body),\n  };\n};\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nexport const sleep = (ms: number) => new Promise<void>((resolve) => setTimeout(resolve, ms));\n","import {\n  type ChatCompletionChunk,\n  type ChatCompletionCreateParamsStreaming,\n} from '../resources/chat/completions';\nimport { RunnerOptions, type AbstractChatCompletionRunnerEvents } from './AbstractChatCompletionRunner';\nimport { type ReadableStream } from '../internal/shim-types';\nimport { RunnableTools, type BaseFunctionsArgs } from './RunnableFunction';\nimport { ChatCompletionSnapshot, ChatCompletionStream } from './ChatCompletionStream';\nimport OpenAI from '../index';\nimport { AutoParseableTool } from '../lib/parser';\n\nexport interface ChatCompletionStreamEvents extends AbstractChatCompletionRunnerEvents {\n  content: (contentDelta: string, contentSnapshot: string) => void;\n  chunk: (chunk: ChatCompletionChunk, snapshot: ChatCompletionSnapshot) => void;\n}\n\nexport type ChatCompletionStreamingToolRunnerParams<FunctionsArgs extends BaseFunctionsArgs> = Omit<\n  ChatCompletionCreateParamsStreaming,\n  'tools'\n> & {\n  tools: RunnableTools<FunctionsArgs> | AutoParseableTool<any, true>[];\n};\n\nexport class ChatCompletionStreamingRunner<ParsedT = null>\n  extends ChatCompletionStream<ParsedT>\n  implements AsyncIterable<ChatCompletionChunk>\n{\n  static override fromReadableStream(stream: ReadableStream): ChatCompletionStreamingRunner<null> {\n    const runner = new ChatCompletionStreamingRunner(null);\n    runner._run(() => runner._fromReadableStream(stream));\n    return runner;\n  }\n\n  static runTools<T extends (string | object)[], ParsedT = null>(\n    client: OpenAI,\n    params: ChatCompletionStreamingToolRunnerParams<T>,\n    options?: RunnerOptions,\n  ): ChatCompletionStreamingRunner<ParsedT> {\n    const runner = new ChatCompletionStreamingRunner<ParsedT>(\n      // @ts-expect-error TODO these types are incompatible\n      params,\n    );\n    const opts = {\n      ...options,\n      headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'runTools' },\n    };\n    runner._run(() => runner._runTools(client, params, opts));\n    return runner;\n  }\n}\n","\"use server\";\n\nimport { revalidatePath } from \"next/cache\";\nimport * as geminiService from \"../services/geminiService\";\nimport * as dbService from \"../services/db\";\nimport { ArtigoNoticia } from \"../types\";\n\n/* =========================================================\n    MODO COMPLETO (para compatibilidade retroativa)\n   ========================================================= */\nexport async function generateAndSaveArticleAction(\n  topic: string,\n  language: string,\n  focusKeywords: string\n): Promise<ArtigoNoticia> {\n  try {\n    //  Etapa 1: IA Escritora\n    const rawContent = await geminiService.writeNewsArticle(topic, language, focusKeywords);\n\n    //  Etapa 2: IA Formatadora\n    const formattedContent = await geminiService.formatArticleToHtml(rawContent);\n\n    //  Etapa 3: IA de SEO\n    const { keywords, metaDescription } = await geminiService.analyzeSeoAndExtractMetadata(rawContent, focusKeywords);\n\n    //  Etapa 4: Salvar tudo no banco\n    const articleToSave: Omit<ArtigoNoticia, \"id\"> = {\n      title: topic,\n      rawContent,\n      formattedContent,\n      generationDate: new Date().toISOString(),\n      published: false,\n      keywords,\n      metaDescription,\n    };\n\n    const savedArticle = await dbService.saveArticle(articleToSave);\n\n    //  Revalida histrico no dashboard\n    revalidatePath(\"/dashboard/history\");\n\n    return { ...savedArticle, published: true };\n  } catch (error) {\n    console.error(\" Erro em generateAndSaveArticleAction:\", error);\n    throw new Error(`Falha ao gerar e salvar o artigo: ${error instanceof Error ? error.message : String(error)}`);\n  }\n}\n\n/* =========================================================\n    MODO MODULAR (para pipeline dividido)\n   ========================================================= */\n\n/** 1 Gera o texto base e salva como rascunho */\nexport async function saveArticleDraft(data: {\n  title: string;\n  content: string;\n  language: string;\n  focusKeywords: string;\n  status?: string;\n}) {\n  try {\n    const articleToSave: Omit<ArtigoNoticia, \"id\"> = {\n      title: data.title,\n      rawContent: data.content,\n      formattedContent: \"\",\n      generationDate: new Date().toISOString(),\n      published: false,\n      keywords: [\"\"],\n      metaDescription: \"\",\n    };\n\n    const saved = await dbService.saveArticle(articleToSave);\n    console.log(` Rascunho salvo com ID: ${saved.id}`);\n    revalidatePath(\"/dashboard/history\");\n    return saved;\n  } catch (error) {\n    console.error(\" Erro ao salvar rascunho:\", error);\n    throw new Error(\"Falha ao salvar rascunho.\");\n  }\n}\n\n/** 2 Busca artigo pelo ID */\nexport async function getArticleById(id: string): Promise<ArtigoNoticia | null> {\n  try {\n    const article = await dbService.getArticleById(id);\n    return article;\n  } catch (error) {\n    console.error(\" Erro ao buscar artigo:\", error);\n    return null;\n  }\n}\n\n/** 3 Atualiza HTML formatado */\nexport async function updateArticleHtml(id: string, formattedContent: string) {\n  try {\n    await dbService.updateArticle(id, { formattedContent });\n    console.log(` HTML atualizado com sucesso para o artigo ${id}`);\n    revalidatePath(\"/dashboard/history\");\n  } catch (error) {\n    console.error(\" Erro ao atualizar HTML:\", error);\n    throw new Error(\"Falha ao atualizar o HTML do artigo.\");\n  }\n}\n\n/** 4 Atualiza dados de SEO e marca como publicado */\n\nexport async function updateArticleSeo(\n  id: string,\n  data: { keywords: string[] | string; metaDescription: string; status?: string }\n) {\n  try {\n    //  Garante que keywords sempre ser um array de strings\n    let keywords: string[];\n\n    if (Array.isArray(data.keywords)) {\n      keywords = data.keywords;\n    } else if (typeof data.keywords === \"string\") {\n      keywords = data.keywords.split(\",\").map((k) => k.trim());\n    } else {\n      keywords = [];\n    }\n\n    const metaDescription = data.metaDescription || \"\";\n\n    await dbService.updateArticle(id, {\n      keywords,\n      metaDescription,\n      published: true,\n      generationDate: new Date().toISOString(),\n    });\n\n    console.log(` SEO atualizado e artigo ${id} publicado com sucesso.`);\n    revalidatePath(\"/dashboard/history\");\n  } catch (error: any) {\n    console.error(\" Erro ao atualizar SEO:\", error);\n    throw new Error(\n      error?.message || \"Falha ao atualizar os dados de SEO do artigo.\"\n    );\n  }\n}\n\n\n\n/* =========================================================\n    LISTAGEM (inalterada)\n   ========================================================= */\nexport async function getArticlesAction(): Promise<ArtigoNoticia[]> {\n  try {\n    await dbService.setupDatabase(); // garante tabela\n    const articles = await dbService.getArticles();\n    return articles;\n  } catch (error) {\n    console.error(\" Erro em getArticlesAction:\", error);\n    return [];\n  }\n}\n","import { GoogleGenAI, Type } from \"@google/genai\";\nimport OpenAI from \"openai\";\nimport { getSettings } from \"@/services/configService\";\n\n/* =============================================================\n *  Inicializao das APIs\n * ============================================================= */\nif (!process.env.GEMINI_API_KEY) {\n  console.error(\" [GeminiService] Varivel de ambiente GEMINI_API_KEY no configurada!\");\n} else {\n  console.log(\" [GeminiService] GEMINI_API_KEY detectada com sucesso.\");\n}\n\nif (!process.env.OPENAI_API_KEY) {\n  console.error(\" [OpenAIService] Varivel de ambiente OPENAI_API_KEY no configurada!\");\n} else {\n  console.log(\" [OpenAIService] OPENAI_API_KEY detectada com sucesso.\");\n}\n\nconst gemini = new GoogleGenAI({ apiKey: process.env.GEMINI_API_KEY as string });\nconst openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY as string });\n\n/* =============================================================\n *   Carrega configuraes dinmicas do banco\n * ============================================================= */\nasync function loadAgentSettings() {\n  const settings = await getSettings();\n  if (!settings) throw new Error(\"Configuraes de IA no encontradas no banco.\");\n  return settings;\n}\n\n/* =============================================================\n *  1. Criao do artigo jornalstico (GPT-4o-mini)\n * ============================================================= */\nexport const writeNewsArticle = async (\n  topic: string,\n  language: string,\n  focusKeywords: string\n): Promise<string> => {\n  console.log(\" [writeNewsArticle] Gerando artigo com OpenAI (GPT-4o-mini)\");\n\n  const settings = await loadAgentSettings();\n\n  const prompt =\n    settings.writer_instructions +\n    `\nTema: \"${topic}\"  \nIdioma: ${language}  \nPalavras-chave foco: ${focusKeywords}\n\n` + ``;\n\n  console.log(`[writeNewsArticle] Tema: ${topic}`);\n  console.log(`[writeNewsArticle] Idioma: ${language}`);\n  console.log(`[writeNewsArticle] Palavras-chave: ${focusKeywords}`);\n  console.log(`[writeNewsArticle] Instrues utilizadas:`, settings.writer_instructions);\n\n  try {\n    const response = await openai.chat.completions.create({\n      model: \"gpt-4o-mini\", //  modelo fixo para este agente\n      messages: [\n        {\n          role: \"user\",\n          content: prompt,\n        },\n      ],\n      temperature: 0.8,\n    });\n\n    const text = response.choices[0]?.message?.content || \"\";\n    console.log(\" [writeNewsArticle] Artigo gerado com sucesso.\");\n    return text.trim();\n  } catch (error) {\n    console.error(\" [writeNewsArticle] Erro:\", error);\n    throw new Error(\"Falha ao gerar o artigo de notcia pela OpenAI.\");\n  }\n};\n\n/* =============================================================\n *  2. Converso para HTML semntico  Gemini\n * ============================================================= */\nexport const formatArticleToHtml = async (articleText: string): Promise<string> => {\n  console.log(\" [formatArticleToHtml] Iniciando formatao com Gemini\");\n\n  const settings = await loadAgentSettings();\n  const prompt =\n    settings.formatter_instructions +\n    `\n\nTexto para formatar:\n${articleText}\n\n` + ``;\n\n  console.log(\"[formatArticleToHtml] Instrues utilizadas:\", settings.formatter_instructions);\n\n  try {\n    const response = await gemini.models.generateContent({\n      model: settings.formatter_model || \"gemini-1.5-flash\",\n      contents: [{ parts: [{ text: prompt }] }],\n    });\n\n    let htmlContent = response.text || \"\";\n    if (htmlContent.startsWith(\"```html\")) htmlContent = htmlContent.slice(7);\n    if (htmlContent.endsWith(\"```\")) htmlContent = htmlContent.slice(0, -3);\n\n    console.log(\" [formatArticleToHtml] HTML gerado com sucesso. Tamanho:\", htmlContent.length);\n    return htmlContent.trim();\n  } catch (error) {\n    console.error(\" [formatArticleToHtml] Erro ao gerar HTML:\", error);\n    throw new Error(\"Falha ao formatar o artigo para HTML.\");\n  }\n};\n\n/* =============================================================\n *  3. Extrao de metadados SEO  Gemini\n * ============================================================= */\nexport const analyzeSeoAndExtractMetadata = async (\n  articleText: string,\n  focusKeywords: string\n): Promise<{ keywords: string[]; metaDescription: string }> => {\n  console.log(\" [analyzeSeoAndExtractMetadata] Iniciando anlise SEO com Gemini\");\n\n  const settings = await loadAgentSettings();\n  const prompt = settings.seo_instructions;\n\n  console.log(\"[analyzeSeoAndExtractMetadata] Instrues utilizadas:\", settings.seo_instructions);\n\n  try {\n    const response = await gemini.models.generateContent({\n      model: settings.seo_model || \"gemini-1.5-flash\",\n      contents: [{ parts: [{ text: prompt }] }],\n      config: {\n        responseMimeType: \"application/json\",\n        responseSchema: {\n          type: Type.OBJECT,\n          properties: {\n            keywords: { type: Type.ARRAY, items: { type: Type.STRING } },\n            metaDescription: { type: Type.STRING },\n          },\n        },\n      },\n    });\n\n    const result = JSON.parse(response.text);\n    console.log(\" [analyzeSeoAndExtractMetadata] SEO extrado:\", result);\n    return {\n      keywords: result.keywords || [],\n      metaDescription: result.metaDescription || \"\",\n    };\n  } catch (error) {\n    console.error(\" [analyzeSeoAndExtractMetadata] Erro SEO:\", error);\n    return { keywords: [], metaDescription: \"No foi possvel gerar a meta descrio.\" };\n  }\n};\n","import { concatBytes, decodeUTF8, encodeUTF8 } from '../utils/bytes';\n\nexport type Bytes = string | ArrayBuffer | Uint8Array | null | undefined;\n\n/**\n * A re-implementation of httpx's `LineDecoder` in Python that handles incrementally\n * reading lines from text.\n *\n * https://github.com/encode/httpx/blob/920333ea98118e9cf617f246905d7b202510941c/httpx/_decoders.py#L258\n */\nexport class LineDecoder {\n  // prettier-ignore\n  static NEWLINE_CHARS = new Set(['\\n', '\\r']);\n  static NEWLINE_REGEXP = /\\r\\n|[\\n\\r]/g;\n\n  #buffer: Uint8Array;\n  #carriageReturnIndex: number | null;\n\n  constructor() {\n    this.#buffer = new Uint8Array();\n    this.#carriageReturnIndex = null;\n  }\n\n  decode(chunk: Bytes): string[] {\n    if (chunk == null) {\n      return [];\n    }\n\n    const binaryChunk =\n      chunk instanceof ArrayBuffer ? new Uint8Array(chunk)\n      : typeof chunk === 'string' ? encodeUTF8(chunk)\n      : chunk;\n\n    this.#buffer = concatBytes([this.#buffer, binaryChunk]);\n\n    const lines: string[] = [];\n    let patternIndex;\n    while ((patternIndex = findNewlineIndex(this.#buffer, this.#carriageReturnIndex)) != null) {\n      if (patternIndex.carriage && this.#carriageReturnIndex == null) {\n        // skip until we either get a corresponding `\\n`, a new `\\r` or nothing\n        this.#carriageReturnIndex = patternIndex.index;\n        continue;\n      }\n\n      // we got double \\r or \\rtext\\n\n      if (\n        this.#carriageReturnIndex != null &&\n        (patternIndex.index !== this.#carriageReturnIndex + 1 || patternIndex.carriage)\n      ) {\n        lines.push(decodeUTF8(this.#buffer.subarray(0, this.#carriageReturnIndex - 1)));\n        this.#buffer = this.#buffer.subarray(this.#carriageReturnIndex);\n        this.#carriageReturnIndex = null;\n        continue;\n      }\n\n      const endIndex =\n        this.#carriageReturnIndex !== null ? patternIndex.preceding - 1 : patternIndex.preceding;\n\n      const line = decodeUTF8(this.#buffer.subarray(0, endIndex));\n      lines.push(line);\n\n      this.#buffer = this.#buffer.subarray(patternIndex.index);\n      this.#carriageReturnIndex = null;\n    }\n\n    return lines;\n  }\n\n  flush(): string[] {\n    if (!this.#buffer.length) {\n      return [];\n    }\n    return this.decode('\\n');\n  }\n}\n\n/**\n * This function searches the buffer for the end patterns, (\\r or \\n)\n * and returns an object with the index preceding the matched newline and the\n * index after the newline char. `null` is returned if no new line is found.\n *\n * ```ts\n * findNewLineIndex('abc\\ndef') -> { preceding: 2, index: 3 }\n * ```\n */\nfunction findNewlineIndex(\n  buffer: Uint8Array,\n  startIndex: number | null,\n): { preceding: number; index: number; carriage: boolean } | null {\n  const newline = 0x0a; // \\n\n  const carriage = 0x0d; // \\r\n\n  for (let i = startIndex ?? 0; i < buffer.length; i++) {\n    if (buffer[i] === newline) {\n      return { preceding: i, index: i + 1, carriage: false };\n    }\n\n    if (buffer[i] === carriage) {\n      return { preceding: i, index: i + 1, carriage: true };\n    }\n  }\n\n  return null;\n}\n\nexport function findDoubleNewlineIndex(buffer: Uint8Array): number {\n  // This function searches the buffer for the end patterns (\\r\\r, \\n\\n, \\r\\n\\r\\n)\n  // and returns the index right after the first occurrence of any pattern,\n  // or -1 if none of the patterns are found.\n  const newline = 0x0a; // \\n\n  const carriage = 0x0d; // \\r\n\n  for (let i = 0; i < buffer.length - 1; i++) {\n    if (buffer[i] === newline && buffer[i + 1] === newline) {\n      // \\n\\n\n      return i + 2;\n    }\n    if (buffer[i] === carriage && buffer[i + 1] === carriage) {\n      // \\r\\r\n      return i + 2;\n    }\n    if (\n      buffer[i] === carriage &&\n      buffer[i + 1] === newline &&\n      i + 3 < buffer.length &&\n      buffer[i + 2] === carriage &&\n      buffer[i + 3] === newline\n    ) {\n      // \\r\\n\\r\\n\n      return i + 4;\n    }\n  }\n\n  return -1;\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport type { OpenAI } from '../client';\n\nexport abstract class APIResource {\n  protected _client: OpenAI;\n\n  constructor(client: OpenAI) {\n    this._client = client;\n  }\n}\n","/**\n * Like `Promise.allSettled()` but throws an error if any promises are rejected.\n */\nexport const allSettledWithThrow = async <R>(promises: Promise<R>[]): Promise<R[]> => {\n  const results = await Promise.allSettled(promises);\n  const rejected = results.filter((result): result is PromiseRejectedResult => result.status === 'rejected');\n  if (rejected.length) {\n    for (const result of rejected) {\n      console.error(result.reason);\n    }\n\n    throw new Error(`${rejected.length} promise(s) failed - see the above errors`);\n  }\n\n  // Note: TS was complaining about using `.filter().map()` here for some reason\n  const values: R[] = [];\n  for (const result of results) {\n    if (result.status === 'fulfilled') {\n      values.push(result.value);\n    }\n  }\n  return values;\n};\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { InvalidWebhookSignatureError } from '../error';\nimport { APIResource } from '../core/resource';\nimport { buildHeaders, HeadersLike } from '../internal/headers';\n\nexport class Webhooks extends APIResource {\n  /**\n   * Validates that the given payload was sent by OpenAI and parses the payload.\n   */\n  async unwrap(\n    payload: string,\n    headers: HeadersLike,\n    secret: string | undefined | null = this._client.webhookSecret,\n    tolerance: number = 300,\n  ): Promise<UnwrapWebhookEvent> {\n    await this.verifySignature(payload, headers, secret, tolerance);\n\n    return JSON.parse(payload) as UnwrapWebhookEvent;\n  }\n\n  /**\n   * Validates whether or not the webhook payload was sent by OpenAI.\n   *\n   * An error will be raised if the webhook payload was not sent by OpenAI.\n   *\n   * @param payload - The webhook payload\n   * @param headers - The webhook headers\n   * @param secret - The webhook secret (optional, will use client secret if not provided)\n   * @param tolerance - Maximum age of the webhook in seconds (default: 300 = 5 minutes)\n   */\n  async verifySignature(\n    payload: string,\n    headers: HeadersLike,\n    secret: string | undefined | null = this._client.webhookSecret,\n    tolerance: number = 300,\n  ): Promise<void> {\n    if (\n      typeof crypto === 'undefined' ||\n      typeof crypto.subtle.importKey !== 'function' ||\n      typeof crypto.subtle.verify !== 'function'\n    ) {\n      throw new Error('Webhook signature verification is only supported when the `crypto` global is defined');\n    }\n\n    this.#validateSecret(secret);\n\n    const headersObj = buildHeaders([headers]).values;\n    const signatureHeader = this.#getRequiredHeader(headersObj, 'webhook-signature');\n    const timestamp = this.#getRequiredHeader(headersObj, 'webhook-timestamp');\n    const webhookId = this.#getRequiredHeader(headersObj, 'webhook-id');\n\n    // Validate timestamp to prevent replay attacks\n    const timestampSeconds = parseInt(timestamp, 10);\n    if (isNaN(timestampSeconds)) {\n      throw new InvalidWebhookSignatureError('Invalid webhook timestamp format');\n    }\n\n    const nowSeconds = Math.floor(Date.now() / 1000);\n\n    if (nowSeconds - timestampSeconds > tolerance) {\n      throw new InvalidWebhookSignatureError('Webhook timestamp is too old');\n    }\n\n    if (timestampSeconds > nowSeconds + tolerance) {\n      throw new InvalidWebhookSignatureError('Webhook timestamp is too new');\n    }\n\n    // Extract signatures from v1,<base64> format\n    // The signature header can have multiple values, separated by spaces.\n    // Each value is in the format v1,<base64>. We should accept if any match.\n    const signatures = signatureHeader\n      .split(' ')\n      .map((part) => (part.startsWith('v1,') ? part.substring(3) : part));\n\n    // Decode the secret if it starts with whsec_\n    const decodedSecret =\n      secret.startsWith('whsec_') ?\n        Buffer.from(secret.replace('whsec_', ''), 'base64')\n      : Buffer.from(secret, 'utf-8');\n\n    // Create the signed payload: {webhook_id}.{timestamp}.{payload}\n    const signedPayload = webhookId ? `${webhookId}.${timestamp}.${payload}` : `${timestamp}.${payload}`;\n\n    // Import the secret as a cryptographic key for HMAC\n    const key = await crypto.subtle.importKey(\n      'raw',\n      decodedSecret,\n      { name: 'HMAC', hash: 'SHA-256' },\n      false,\n      ['verify'],\n    );\n\n    // Check if any signature matches using timing-safe WebCrypto verify\n    for (const signature of signatures) {\n      try {\n        const signatureBytes = Buffer.from(signature, 'base64');\n        const isValid = await crypto.subtle.verify(\n          'HMAC',\n          key,\n          signatureBytes,\n          new TextEncoder().encode(signedPayload),\n        );\n\n        if (isValid) {\n          return; // Valid signature found\n        }\n      } catch {\n        // Invalid base64 or signature format, continue to next signature\n        continue;\n      }\n    }\n\n    throw new InvalidWebhookSignatureError(\n      'The given webhook signature does not match the expected signature',\n    );\n  }\n\n  #validateSecret(secret: string | null | undefined): asserts secret is string {\n    if (typeof secret !== 'string' || secret.length === 0) {\n      throw new Error(\n        `The webhook secret must either be set using the env var, OPENAI_WEBHOOK_SECRET, on the client class, OpenAI({ webhookSecret: '123' }), or passed to this function`,\n      );\n    }\n  }\n\n  #getRequiredHeader(headers: Headers, name: string): string {\n    if (!headers) {\n      throw new Error(`Headers are required`);\n    }\n\n    const value = headers.get(name);\n\n    if (value === null || value === undefined) {\n      throw new Error(`Missing required header: ${name}`);\n    }\n\n    return value;\n  }\n}\n\n/**\n * Sent when a batch API request has been cancelled.\n */\nexport interface BatchCancelledWebhookEvent {\n  /**\n   * The unique ID of the event.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) of when the batch API request was cancelled.\n   */\n  created_at: number;\n\n  /**\n   * Event data payload.\n   */\n  data: BatchCancelledWebhookEvent.Data;\n\n  /**\n   * The type of the event. Always `batch.cancelled`.\n   */\n  type: 'batch.cancelled';\n\n  /**\n   * The object of the event. Always `event`.\n   */\n  object?: 'event';\n}\n\nexport namespace BatchCancelledWebhookEvent {\n  /**\n   * Event data payload.\n   */\n  export interface Data {\n    /**\n     * The unique ID of the batch API request.\n     */\n    id: string;\n  }\n}\n\n/**\n * Sent when a batch API request has been completed.\n */\nexport interface BatchCompletedWebhookEvent {\n  /**\n   * The unique ID of the event.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) of when the batch API request was completed.\n   */\n  created_at: number;\n\n  /**\n   * Event data payload.\n   */\n  data: BatchCompletedWebhookEvent.Data;\n\n  /**\n   * The type of the event. Always `batch.completed`.\n   */\n  type: 'batch.completed';\n\n  /**\n   * The object of the event. Always `event`.\n   */\n  object?: 'event';\n}\n\nexport namespace BatchCompletedWebhookEvent {\n  /**\n   * Event data payload.\n   */\n  export interface Data {\n    /**\n     * The unique ID of the batch API request.\n     */\n    id: string;\n  }\n}\n\n/**\n * Sent when a batch API request has expired.\n */\nexport interface BatchExpiredWebhookEvent {\n  /**\n   * The unique ID of the event.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) of when the batch API request expired.\n   */\n  created_at: number;\n\n  /**\n   * Event data payload.\n   */\n  data: BatchExpiredWebhookEvent.Data;\n\n  /**\n   * The type of the event. Always `batch.expired`.\n   */\n  type: 'batch.expired';\n\n  /**\n   * The object of the event. Always `event`.\n   */\n  object?: 'event';\n}\n\nexport namespace BatchExpiredWebhookEvent {\n  /**\n   * Event data payload.\n   */\n  export interface Data {\n    /**\n     * The unique ID of the batch API request.\n     */\n    id: string;\n  }\n}\n\n/**\n * Sent when a batch API request has failed.\n */\nexport interface BatchFailedWebhookEvent {\n  /**\n   * The unique ID of the event.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) of when the batch API request failed.\n   */\n  created_at: number;\n\n  /**\n   * Event data payload.\n   */\n  data: BatchFailedWebhookEvent.Data;\n\n  /**\n   * The type of the event. Always `batch.failed`.\n   */\n  type: 'batch.failed';\n\n  /**\n   * The object of the event. Always `event`.\n   */\n  object?: 'event';\n}\n\nexport namespace BatchFailedWebhookEvent {\n  /**\n   * Event data payload.\n   */\n  export interface Data {\n    /**\n     * The unique ID of the batch API request.\n     */\n    id: string;\n  }\n}\n\n/**\n * Sent when an eval run has been canceled.\n */\nexport interface EvalRunCanceledWebhookEvent {\n  /**\n   * The unique ID of the event.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) of when the eval run was canceled.\n   */\n  created_at: number;\n\n  /**\n   * Event data payload.\n   */\n  data: EvalRunCanceledWebhookEvent.Data;\n\n  /**\n   * The type of the event. Always `eval.run.canceled`.\n   */\n  type: 'eval.run.canceled';\n\n  /**\n   * The object of the event. Always `event`.\n   */\n  object?: 'event';\n}\n\nexport namespace EvalRunCanceledWebhookEvent {\n  /**\n   * Event data payload.\n   */\n  export interface Data {\n    /**\n     * The unique ID of the eval run.\n     */\n    id: string;\n  }\n}\n\n/**\n * Sent when an eval run has failed.\n */\nexport interface EvalRunFailedWebhookEvent {\n  /**\n   * The unique ID of the event.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) of when the eval run failed.\n   */\n  created_at: number;\n\n  /**\n   * Event data payload.\n   */\n  data: EvalRunFailedWebhookEvent.Data;\n\n  /**\n   * The type of the event. Always `eval.run.failed`.\n   */\n  type: 'eval.run.failed';\n\n  /**\n   * The object of the event. Always `event`.\n   */\n  object?: 'event';\n}\n\nexport namespace EvalRunFailedWebhookEvent {\n  /**\n   * Event data payload.\n   */\n  export interface Data {\n    /**\n     * The unique ID of the eval run.\n     */\n    id: string;\n  }\n}\n\n/**\n * Sent when an eval run has succeeded.\n */\nexport interface EvalRunSucceededWebhookEvent {\n  /**\n   * The unique ID of the event.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) of when the eval run succeeded.\n   */\n  created_at: number;\n\n  /**\n   * Event data payload.\n   */\n  data: EvalRunSucceededWebhookEvent.Data;\n\n  /**\n   * The type of the event. Always `eval.run.succeeded`.\n   */\n  type: 'eval.run.succeeded';\n\n  /**\n   * The object of the event. Always `event`.\n   */\n  object?: 'event';\n}\n\nexport namespace EvalRunSucceededWebhookEvent {\n  /**\n   * Event data payload.\n   */\n  export interface Data {\n    /**\n     * The unique ID of the eval run.\n     */\n    id: string;\n  }\n}\n\n/**\n * Sent when a fine-tuning job has been cancelled.\n */\nexport interface FineTuningJobCancelledWebhookEvent {\n  /**\n   * The unique ID of the event.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) of when the fine-tuning job was cancelled.\n   */\n  created_at: number;\n\n  /**\n   * Event data payload.\n   */\n  data: FineTuningJobCancelledWebhookEvent.Data;\n\n  /**\n   * The type of the event. Always `fine_tuning.job.cancelled`.\n   */\n  type: 'fine_tuning.job.cancelled';\n\n  /**\n   * The object of the event. Always `event`.\n   */\n  object?: 'event';\n}\n\nexport namespace FineTuningJobCancelledWebhookEvent {\n  /**\n   * Event data payload.\n   */\n  export interface Data {\n    /**\n     * The unique ID of the fine-tuning job.\n     */\n    id: string;\n  }\n}\n\n/**\n * Sent when a fine-tuning job has failed.\n */\nexport interface FineTuningJobFailedWebhookEvent {\n  /**\n   * The unique ID of the event.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) of when the fine-tuning job failed.\n   */\n  created_at: number;\n\n  /**\n   * Event data payload.\n   */\n  data: FineTuningJobFailedWebhookEvent.Data;\n\n  /**\n   * The type of the event. Always `fine_tuning.job.failed`.\n   */\n  type: 'fine_tuning.job.failed';\n\n  /**\n   * The object of the event. Always `event`.\n   */\n  object?: 'event';\n}\n\nexport namespace FineTuningJobFailedWebhookEvent {\n  /**\n   * Event data payload.\n   */\n  export interface Data {\n    /**\n     * The unique ID of the fine-tuning job.\n     */\n    id: string;\n  }\n}\n\n/**\n * Sent when a fine-tuning job has succeeded.\n */\nexport interface FineTuningJobSucceededWebhookEvent {\n  /**\n   * The unique ID of the event.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) of when the fine-tuning job succeeded.\n   */\n  created_at: number;\n\n  /**\n   * Event data payload.\n   */\n  data: FineTuningJobSucceededWebhookEvent.Data;\n\n  /**\n   * The type of the event. Always `fine_tuning.job.succeeded`.\n   */\n  type: 'fine_tuning.job.succeeded';\n\n  /**\n   * The object of the event. Always `event`.\n   */\n  object?: 'event';\n}\n\nexport namespace FineTuningJobSucceededWebhookEvent {\n  /**\n   * Event data payload.\n   */\n  export interface Data {\n    /**\n     * The unique ID of the fine-tuning job.\n     */\n    id: string;\n  }\n}\n\n/**\n * Sent when Realtime API Receives a incoming SIP call.\n */\nexport interface RealtimeCallIncomingWebhookEvent {\n  /**\n   * The unique ID of the event.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) of when the model response was completed.\n   */\n  created_at: number;\n\n  /**\n   * Event data payload.\n   */\n  data: RealtimeCallIncomingWebhookEvent.Data;\n\n  /**\n   * The type of the event. Always `realtime.call.incoming`.\n   */\n  type: 'realtime.call.incoming';\n\n  /**\n   * The object of the event. Always `event`.\n   */\n  object?: 'event';\n}\n\nexport namespace RealtimeCallIncomingWebhookEvent {\n  /**\n   * Event data payload.\n   */\n  export interface Data {\n    /**\n     * The unique ID of this call.\n     */\n    call_id: string;\n\n    /**\n     * Headers from the SIP Invite.\n     */\n    sip_headers: Array<Data.SipHeader>;\n  }\n\n  export namespace Data {\n    /**\n     * A header from the SIP Invite.\n     */\n    export interface SipHeader {\n      /**\n       * Name of the SIP Header.\n       */\n      name: string;\n\n      /**\n       * Value of the SIP Header.\n       */\n      value: string;\n    }\n  }\n}\n\n/**\n * Sent when a background response has been cancelled.\n */\nexport interface ResponseCancelledWebhookEvent {\n  /**\n   * The unique ID of the event.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) of when the model response was cancelled.\n   */\n  created_at: number;\n\n  /**\n   * Event data payload.\n   */\n  data: ResponseCancelledWebhookEvent.Data;\n\n  /**\n   * The type of the event. Always `response.cancelled`.\n   */\n  type: 'response.cancelled';\n\n  /**\n   * The object of the event. Always `event`.\n   */\n  object?: 'event';\n}\n\nexport namespace ResponseCancelledWebhookEvent {\n  /**\n   * Event data payload.\n   */\n  export interface Data {\n    /**\n     * The unique ID of the model response.\n     */\n    id: string;\n  }\n}\n\n/**\n * Sent when a background response has been completed.\n */\nexport interface ResponseCompletedWebhookEvent {\n  /**\n   * The unique ID of the event.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) of when the model response was completed.\n   */\n  created_at: number;\n\n  /**\n   * Event data payload.\n   */\n  data: ResponseCompletedWebhookEvent.Data;\n\n  /**\n   * The type of the event. Always `response.completed`.\n   */\n  type: 'response.completed';\n\n  /**\n   * The object of the event. Always `event`.\n   */\n  object?: 'event';\n}\n\nexport namespace ResponseCompletedWebhookEvent {\n  /**\n   * Event data payload.\n   */\n  export interface Data {\n    /**\n     * The unique ID of the model response.\n     */\n    id: string;\n  }\n}\n\n/**\n * Sent when a background response has failed.\n */\nexport interface ResponseFailedWebhookEvent {\n  /**\n   * The unique ID of the event.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) of when the model response failed.\n   */\n  created_at: number;\n\n  /**\n   * Event data payload.\n   */\n  data: ResponseFailedWebhookEvent.Data;\n\n  /**\n   * The type of the event. Always `response.failed`.\n   */\n  type: 'response.failed';\n\n  /**\n   * The object of the event. Always `event`.\n   */\n  object?: 'event';\n}\n\nexport namespace ResponseFailedWebhookEvent {\n  /**\n   * Event data payload.\n   */\n  export interface Data {\n    /**\n     * The unique ID of the model response.\n     */\n    id: string;\n  }\n}\n\n/**\n * Sent when a background response has been interrupted.\n */\nexport interface ResponseIncompleteWebhookEvent {\n  /**\n   * The unique ID of the event.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) of when the model response was interrupted.\n   */\n  created_at: number;\n\n  /**\n   * Event data payload.\n   */\n  data: ResponseIncompleteWebhookEvent.Data;\n\n  /**\n   * The type of the event. Always `response.incomplete`.\n   */\n  type: 'response.incomplete';\n\n  /**\n   * The object of the event. Always `event`.\n   */\n  object?: 'event';\n}\n\nexport namespace ResponseIncompleteWebhookEvent {\n  /**\n   * Event data payload.\n   */\n  export interface Data {\n    /**\n     * The unique ID of the model response.\n     */\n    id: string;\n  }\n}\n\n/**\n * Sent when a batch API request has been cancelled.\n */\nexport type UnwrapWebhookEvent =\n  | BatchCancelledWebhookEvent\n  | BatchCompletedWebhookEvent\n  | BatchExpiredWebhookEvent\n  | BatchFailedWebhookEvent\n  | EvalRunCanceledWebhookEvent\n  | EvalRunFailedWebhookEvent\n  | EvalRunSucceededWebhookEvent\n  | FineTuningJobCancelledWebhookEvent\n  | FineTuningJobFailedWebhookEvent\n  | FineTuningJobSucceededWebhookEvent\n  | RealtimeCallIncomingWebhookEvent\n  | ResponseCancelledWebhookEvent\n  | ResponseCompletedWebhookEvent\n  | ResponseFailedWebhookEvent\n  | ResponseIncompleteWebhookEvent;\n\nexport declare namespace Webhooks {\n  export {\n    type BatchCancelledWebhookEvent as BatchCancelledWebhookEvent,\n    type BatchCompletedWebhookEvent as BatchCompletedWebhookEvent,\n    type BatchExpiredWebhookEvent as BatchExpiredWebhookEvent,\n    type BatchFailedWebhookEvent as BatchFailedWebhookEvent,\n    type EvalRunCanceledWebhookEvent as EvalRunCanceledWebhookEvent,\n    type EvalRunFailedWebhookEvent as EvalRunFailedWebhookEvent,\n    type EvalRunSucceededWebhookEvent as EvalRunSucceededWebhookEvent,\n    type FineTuningJobCancelledWebhookEvent as FineTuningJobCancelledWebhookEvent,\n    type FineTuningJobFailedWebhookEvent as FineTuningJobFailedWebhookEvent,\n    type FineTuningJobSucceededWebhookEvent as FineTuningJobSucceededWebhookEvent,\n    type RealtimeCallIncomingWebhookEvent as RealtimeCallIncomingWebhookEvent,\n    type ResponseCancelledWebhookEvent as ResponseCancelledWebhookEvent,\n    type ResponseCompletedWebhookEvent as ResponseCompletedWebhookEvent,\n    type ResponseFailedWebhookEvent as ResponseFailedWebhookEvent,\n    type ResponseIncompleteWebhookEvent as ResponseIncompleteWebhookEvent,\n    type UnwrapWebhookEvent as UnwrapWebhookEvent,\n  };\n}\n","import {\n  TextContentBlock,\n  ImageFileContentBlock,\n  Message,\n  MessageContentDelta,\n  Text,\n  ImageFile,\n  TextDelta,\n  MessageDelta,\n  MessageContent,\n} from '../resources/beta/threads/messages';\nimport { RequestOptions } from '../internal/request-options';\nimport {\n  Run,\n  RunCreateParamsBase,\n  RunCreateParamsStreaming,\n  Runs,\n  RunSubmitToolOutputsParamsBase,\n  RunSubmitToolOutputsParamsStreaming,\n} from '../resources/beta/threads/runs/runs';\nimport { type ReadableStream } from '../internal/shim-types';\nimport { Stream } from '../streaming';\nimport { APIUserAbortError, OpenAIError } from '../error';\nimport {\n  AssistantStreamEvent,\n  MessageStreamEvent,\n  RunStepStreamEvent,\n  RunStreamEvent,\n} from '../resources/beta/assistants';\nimport { RunStep, RunStepDelta, ToolCall, ToolCallDelta } from '../resources/beta/threads/runs/steps';\nimport { ThreadCreateAndRunParamsBase, Threads } from '../resources/beta/threads/threads';\nimport { BaseEvents, EventStream } from './EventStream';\nimport { isObj } from '../internal/utils';\n\nexport interface AssistantStreamEvents extends BaseEvents {\n  run: (run: Run) => void;\n\n  //New event structure\n  messageCreated: (message: Message) => void;\n  messageDelta: (message: MessageDelta, snapshot: Message) => void;\n  messageDone: (message: Message) => void;\n\n  runStepCreated: (runStep: RunStep) => void;\n  runStepDelta: (delta: RunStepDelta, snapshot: Runs.RunStep) => void;\n  runStepDone: (runStep: Runs.RunStep, snapshot: Runs.RunStep) => void;\n\n  toolCallCreated: (toolCall: ToolCall) => void;\n  toolCallDelta: (delta: ToolCallDelta, snapshot: ToolCall) => void;\n  toolCallDone: (toolCall: ToolCall) => void;\n\n  textCreated: (content: Text) => void;\n  textDelta: (delta: TextDelta, snapshot: Text) => void;\n  textDone: (content: Text, snapshot: Message) => void;\n\n  //No created or delta as this is not streamed\n  imageFileDone: (content: ImageFile, snapshot: Message) => void;\n\n  event: (event: AssistantStreamEvent) => void;\n}\n\nexport type ThreadCreateAndRunParamsBaseStream = Omit<ThreadCreateAndRunParamsBase, 'stream'> & {\n  stream?: true;\n};\n\nexport type RunCreateParamsBaseStream = Omit<RunCreateParamsBase, 'stream'> & {\n  stream?: true;\n};\n\nexport type RunSubmitToolOutputsParamsStream = Omit<RunSubmitToolOutputsParamsBase, 'stream'> & {\n  stream?: true;\n};\n\nexport class AssistantStream\n  extends EventStream<AssistantStreamEvents>\n  implements AsyncIterable<AssistantStreamEvent>\n{\n  //Track all events in a single list for reference\n  #events: AssistantStreamEvent[] = [];\n\n  //Used to accumulate deltas\n  //We are accumulating many types so the value here is not strict\n  #runStepSnapshots: { [id: string]: Runs.RunStep } = {};\n  #messageSnapshots: { [id: string]: Message } = {};\n  #messageSnapshot: Message | undefined;\n  #finalRun: Run | undefined;\n  #currentContentIndex: number | undefined;\n  #currentContent: MessageContent | undefined;\n  #currentToolCallIndex: number | undefined;\n  #currentToolCall: ToolCall | undefined;\n\n  //For current snapshot methods\n  #currentEvent: AssistantStreamEvent | undefined;\n  #currentRunSnapshot: Run | undefined;\n  #currentRunStepSnapshot: Runs.RunStep | undefined;\n\n  [Symbol.asyncIterator](): AsyncIterator<AssistantStreamEvent> {\n    const pushQueue: AssistantStreamEvent[] = [];\n    const readQueue: {\n      resolve: (chunk: AssistantStreamEvent | undefined) => void;\n      reject: (err: unknown) => void;\n    }[] = [];\n    let done = false;\n\n    //Catch all for passing along all events\n    this.on('event', (event) => {\n      const reader = readQueue.shift();\n      if (reader) {\n        reader.resolve(event);\n      } else {\n        pushQueue.push(event);\n      }\n    });\n\n    this.on('end', () => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.resolve(undefined);\n      }\n      readQueue.length = 0;\n    });\n\n    this.on('abort', (err) => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.reject(err);\n      }\n      readQueue.length = 0;\n    });\n\n    this.on('error', (err) => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.reject(err);\n      }\n      readQueue.length = 0;\n    });\n\n    return {\n      next: async (): Promise<IteratorResult<AssistantStreamEvent>> => {\n        if (!pushQueue.length) {\n          if (done) {\n            return { value: undefined, done: true };\n          }\n          return new Promise<AssistantStreamEvent | undefined>((resolve, reject) =>\n            readQueue.push({ resolve, reject }),\n          ).then((chunk) => (chunk ? { value: chunk, done: false } : { value: undefined, done: true }));\n        }\n        const chunk = pushQueue.shift()!;\n        return { value: chunk, done: false };\n      },\n      return: async () => {\n        this.abort();\n        return { value: undefined, done: true };\n      },\n    };\n  }\n\n  static fromReadableStream(stream: ReadableStream): AssistantStream {\n    const runner = new AssistantStream();\n    runner._run(() => runner._fromReadableStream(stream));\n    return runner;\n  }\n\n  protected async _fromReadableStream(\n    readableStream: ReadableStream,\n    options?: RequestOptions,\n  ): Promise<Run> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n    this._connected();\n    const stream = Stream.fromReadableStream<AssistantStreamEvent>(readableStream, this.controller);\n    for await (const event of stream) {\n      this.#addEvent(event);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n    return this._addRun(this.#endRequest());\n  }\n\n  toReadableStream(): ReadableStream {\n    const stream = new Stream(this[Symbol.asyncIterator].bind(this), this.controller);\n    return stream.toReadableStream();\n  }\n\n  static createToolAssistantStream(\n    runId: string,\n    runs: Runs,\n    params: RunSubmitToolOutputsParamsStream,\n    options: RequestOptions | undefined,\n  ): AssistantStream {\n    const runner = new AssistantStream();\n    runner._run(() =>\n      runner._runToolAssistantStream(runId, runs, params, {\n        ...options,\n        headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' },\n      }),\n    );\n    return runner;\n  }\n\n  protected async _createToolAssistantStream(\n    run: Runs,\n    runId: string,\n    params: RunSubmitToolOutputsParamsStream,\n    options?: RequestOptions,\n  ): Promise<Run> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n\n    const body: RunSubmitToolOutputsParamsStreaming = { ...params, stream: true };\n    const stream = await run.submitToolOutputs(runId, body, {\n      ...options,\n      signal: this.controller.signal,\n    });\n\n    this._connected();\n\n    for await (const event of stream) {\n      this.#addEvent(event);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n\n    return this._addRun(this.#endRequest());\n  }\n\n  static createThreadAssistantStream(\n    params: ThreadCreateAndRunParamsBaseStream,\n    thread: Threads,\n    options?: RequestOptions,\n  ): AssistantStream {\n    const runner = new AssistantStream();\n    runner._run(() =>\n      runner._threadAssistantStream(params, thread, {\n        ...options,\n        headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' },\n      }),\n    );\n    return runner;\n  }\n\n  static createAssistantStream(\n    threadId: string,\n    runs: Runs,\n    params: RunCreateParamsBaseStream,\n    options?: RequestOptions,\n  ): AssistantStream {\n    const runner = new AssistantStream();\n    runner._run(() =>\n      runner._runAssistantStream(threadId, runs, params, {\n        ...options,\n        headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' },\n      }),\n    );\n    return runner;\n  }\n\n  currentEvent(): AssistantStreamEvent | undefined {\n    return this.#currentEvent;\n  }\n\n  currentRun(): Run | undefined {\n    return this.#currentRunSnapshot;\n  }\n\n  currentMessageSnapshot(): Message | undefined {\n    return this.#messageSnapshot;\n  }\n\n  currentRunStepSnapshot(): Runs.RunStep | undefined {\n    return this.#currentRunStepSnapshot;\n  }\n\n  async finalRunSteps(): Promise<Runs.RunStep[]> {\n    await this.done();\n\n    return Object.values(this.#runStepSnapshots);\n  }\n\n  async finalMessages(): Promise<Message[]> {\n    await this.done();\n\n    return Object.values(this.#messageSnapshots);\n  }\n\n  async finalRun(): Promise<Run> {\n    await this.done();\n    if (!this.#finalRun) throw Error('Final run was not received.');\n\n    return this.#finalRun;\n  }\n\n  protected async _createThreadAssistantStream(\n    thread: Threads,\n    params: ThreadCreateAndRunParamsBase,\n    options?: RequestOptions,\n  ): Promise<Run> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n\n    const body: RunCreateParamsStreaming = { ...params, stream: true };\n    const stream = await thread.createAndRun(body, { ...options, signal: this.controller.signal });\n\n    this._connected();\n\n    for await (const event of stream) {\n      this.#addEvent(event);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n\n    return this._addRun(this.#endRequest());\n  }\n\n  protected async _createAssistantStream(\n    run: Runs,\n    threadId: string,\n    params: RunCreateParamsBase,\n    options?: RequestOptions,\n  ): Promise<Run> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n\n    const body: RunCreateParamsStreaming = { ...params, stream: true };\n    const stream = await run.create(threadId, body, { ...options, signal: this.controller.signal });\n\n    this._connected();\n\n    for await (const event of stream) {\n      this.#addEvent(event);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n\n    return this._addRun(this.#endRequest());\n  }\n\n  #addEvent(event: AssistantStreamEvent) {\n    if (this.ended) return;\n\n    this.#currentEvent = event;\n\n    this.#handleEvent(event);\n\n    switch (event.event) {\n      case 'thread.created':\n        //No action on this event.\n        break;\n\n      case 'thread.run.created':\n      case 'thread.run.queued':\n      case 'thread.run.in_progress':\n      case 'thread.run.requires_action':\n      case 'thread.run.completed':\n      case 'thread.run.incomplete':\n      case 'thread.run.failed':\n      case 'thread.run.cancelling':\n      case 'thread.run.cancelled':\n      case 'thread.run.expired':\n        this.#handleRun(event);\n        break;\n\n      case 'thread.run.step.created':\n      case 'thread.run.step.in_progress':\n      case 'thread.run.step.delta':\n      case 'thread.run.step.completed':\n      case 'thread.run.step.failed':\n      case 'thread.run.step.cancelled':\n      case 'thread.run.step.expired':\n        this.#handleRunStep(event);\n        break;\n\n      case 'thread.message.created':\n      case 'thread.message.in_progress':\n      case 'thread.message.delta':\n      case 'thread.message.completed':\n      case 'thread.message.incomplete':\n        this.#handleMessage(event);\n        break;\n\n      case 'error':\n        //This is included for completeness, but errors are processed in the SSE event processing so this should not occur\n        throw new Error(\n          'Encountered an error event in event processing - errors should be processed earlier',\n        );\n      default:\n        assertNever(event);\n    }\n  }\n\n  #endRequest(): Run {\n    if (this.ended) {\n      throw new OpenAIError(`stream has ended, this shouldn't happen`);\n    }\n\n    if (!this.#finalRun) throw Error('Final run has not been received');\n\n    return this.#finalRun;\n  }\n\n  #handleMessage(this: AssistantStream, event: MessageStreamEvent) {\n    const [accumulatedMessage, newContent] = this.#accumulateMessage(event, this.#messageSnapshot);\n    this.#messageSnapshot = accumulatedMessage;\n    this.#messageSnapshots[accumulatedMessage.id] = accumulatedMessage;\n\n    for (const content of newContent) {\n      const snapshotContent = accumulatedMessage.content[content.index];\n      if (snapshotContent?.type == 'text') {\n        this._emit('textCreated', snapshotContent.text);\n      }\n    }\n\n    switch (event.event) {\n      case 'thread.message.created':\n        this._emit('messageCreated', event.data);\n        break;\n\n      case 'thread.message.in_progress':\n        break;\n\n      case 'thread.message.delta':\n        this._emit('messageDelta', event.data.delta, accumulatedMessage);\n\n        if (event.data.delta.content) {\n          for (const content of event.data.delta.content) {\n            //If it is text delta, emit a text delta event\n            if (content.type == 'text' && content.text) {\n              let textDelta = content.text;\n              let snapshot = accumulatedMessage.content[content.index];\n              if (snapshot && snapshot.type == 'text') {\n                this._emit('textDelta', textDelta, snapshot.text);\n              } else {\n                throw Error('The snapshot associated with this text delta is not text or missing');\n              }\n            }\n\n            if (content.index != this.#currentContentIndex) {\n              //See if we have in progress content\n              if (this.#currentContent) {\n                switch (this.#currentContent.type) {\n                  case 'text':\n                    this._emit('textDone', this.#currentContent.text, this.#messageSnapshot);\n                    break;\n                  case 'image_file':\n                    this._emit('imageFileDone', this.#currentContent.image_file, this.#messageSnapshot);\n                    break;\n                }\n              }\n\n              this.#currentContentIndex = content.index;\n            }\n\n            this.#currentContent = accumulatedMessage.content[content.index];\n          }\n        }\n\n        break;\n\n      case 'thread.message.completed':\n      case 'thread.message.incomplete':\n        //We emit the latest content we were working on on completion (including incomplete)\n        if (this.#currentContentIndex !== undefined) {\n          const currentContent = event.data.content[this.#currentContentIndex];\n          if (currentContent) {\n            switch (currentContent.type) {\n              case 'image_file':\n                this._emit('imageFileDone', currentContent.image_file, this.#messageSnapshot);\n                break;\n              case 'text':\n                this._emit('textDone', currentContent.text, this.#messageSnapshot);\n                break;\n            }\n          }\n        }\n\n        if (this.#messageSnapshot) {\n          this._emit('messageDone', event.data);\n        }\n\n        this.#messageSnapshot = undefined;\n    }\n  }\n\n  #handleRunStep(this: AssistantStream, event: RunStepStreamEvent) {\n    const accumulatedRunStep = this.#accumulateRunStep(event);\n    this.#currentRunStepSnapshot = accumulatedRunStep;\n\n    switch (event.event) {\n      case 'thread.run.step.created':\n        this._emit('runStepCreated', event.data);\n        break;\n      case 'thread.run.step.delta':\n        const delta = event.data.delta;\n        if (\n          delta.step_details &&\n          delta.step_details.type == 'tool_calls' &&\n          delta.step_details.tool_calls &&\n          accumulatedRunStep.step_details.type == 'tool_calls'\n        ) {\n          for (const toolCall of delta.step_details.tool_calls) {\n            if (toolCall.index == this.#currentToolCallIndex) {\n              this._emit(\n                'toolCallDelta',\n                toolCall,\n                accumulatedRunStep.step_details.tool_calls[toolCall.index] as ToolCall,\n              );\n            } else {\n              if (this.#currentToolCall) {\n                this._emit('toolCallDone', this.#currentToolCall);\n              }\n\n              this.#currentToolCallIndex = toolCall.index;\n              this.#currentToolCall = accumulatedRunStep.step_details.tool_calls[toolCall.index];\n              if (this.#currentToolCall) this._emit('toolCallCreated', this.#currentToolCall);\n            }\n          }\n        }\n\n        this._emit('runStepDelta', event.data.delta, accumulatedRunStep);\n        break;\n      case 'thread.run.step.completed':\n      case 'thread.run.step.failed':\n      case 'thread.run.step.cancelled':\n      case 'thread.run.step.expired':\n        this.#currentRunStepSnapshot = undefined;\n        const details = event.data.step_details;\n        if (details.type == 'tool_calls') {\n          if (this.#currentToolCall) {\n            this._emit('toolCallDone', this.#currentToolCall as ToolCall);\n            this.#currentToolCall = undefined;\n          }\n        }\n        this._emit('runStepDone', event.data, accumulatedRunStep);\n        break;\n      case 'thread.run.step.in_progress':\n        break;\n    }\n  }\n\n  #handleEvent(this: AssistantStream, event: AssistantStreamEvent) {\n    this.#events.push(event);\n    this._emit('event', event);\n  }\n\n  #accumulateRunStep(event: RunStepStreamEvent): Runs.RunStep {\n    switch (event.event) {\n      case 'thread.run.step.created':\n        this.#runStepSnapshots[event.data.id] = event.data;\n        return event.data;\n\n      case 'thread.run.step.delta':\n        let snapshot = this.#runStepSnapshots[event.data.id] as Runs.RunStep;\n        if (!snapshot) {\n          throw Error('Received a RunStepDelta before creation of a snapshot');\n        }\n\n        let data = event.data;\n\n        if (data.delta) {\n          const accumulated = AssistantStream.accumulateDelta(snapshot, data.delta) as Runs.RunStep;\n          this.#runStepSnapshots[event.data.id] = accumulated;\n        }\n\n        return this.#runStepSnapshots[event.data.id] as Runs.RunStep;\n\n      case 'thread.run.step.completed':\n      case 'thread.run.step.failed':\n      case 'thread.run.step.cancelled':\n      case 'thread.run.step.expired':\n      case 'thread.run.step.in_progress':\n        this.#runStepSnapshots[event.data.id] = event.data;\n        break;\n    }\n\n    if (this.#runStepSnapshots[event.data.id]) return this.#runStepSnapshots[event.data.id] as Runs.RunStep;\n    throw new Error('No snapshot available');\n  }\n\n  #accumulateMessage(\n    event: AssistantStreamEvent,\n    snapshot: Message | undefined,\n  ): [Message, MessageContentDelta[]] {\n    let newContent: MessageContentDelta[] = [];\n\n    switch (event.event) {\n      case 'thread.message.created':\n        //On creation the snapshot is just the initial message\n        return [event.data, newContent];\n\n      case 'thread.message.delta':\n        if (!snapshot) {\n          throw Error(\n            'Received a delta with no existing snapshot (there should be one from message creation)',\n          );\n        }\n\n        let data = event.data;\n\n        //If this delta does not have content, nothing to process\n        if (data.delta.content) {\n          for (const contentElement of data.delta.content) {\n            if (contentElement.index in snapshot.content) {\n              let currentContent = snapshot.content[contentElement.index];\n              snapshot.content[contentElement.index] = this.#accumulateContent(\n                contentElement,\n                currentContent,\n              );\n            } else {\n              snapshot.content[contentElement.index] = contentElement as MessageContent;\n              // This is a new element\n              newContent.push(contentElement);\n            }\n          }\n        }\n\n        return [snapshot, newContent];\n\n      case 'thread.message.in_progress':\n      case 'thread.message.completed':\n      case 'thread.message.incomplete':\n        //No changes on other thread events\n        if (snapshot) {\n          return [snapshot, newContent];\n        } else {\n          throw Error('Received thread message event with no existing snapshot');\n        }\n    }\n    throw Error('Tried to accumulate a non-message event');\n  }\n\n  #accumulateContent(\n    contentElement: MessageContentDelta,\n    currentContent: MessageContent | undefined,\n  ): TextContentBlock | ImageFileContentBlock {\n    return AssistantStream.accumulateDelta(currentContent as unknown as Record<any, any>, contentElement) as\n      | TextContentBlock\n      | ImageFileContentBlock;\n  }\n\n  static accumulateDelta(acc: Record<string, any>, delta: Record<string, any>): Record<string, any> {\n    for (const [key, deltaValue] of Object.entries(delta)) {\n      if (!acc.hasOwnProperty(key)) {\n        acc[key] = deltaValue;\n        continue;\n      }\n\n      let accValue = acc[key];\n      if (accValue === null || accValue === undefined) {\n        acc[key] = deltaValue;\n        continue;\n      }\n\n      // We don't accumulate these special properties\n      if (key === 'index' || key === 'type') {\n        acc[key] = deltaValue;\n        continue;\n      }\n\n      // Type-specific accumulation logic\n      if (typeof accValue === 'string' && typeof deltaValue === 'string') {\n        accValue += deltaValue;\n      } else if (typeof accValue === 'number' && typeof deltaValue === 'number') {\n        accValue += deltaValue;\n      } else if (isObj(accValue) && isObj(deltaValue)) {\n        accValue = this.accumulateDelta(accValue as Record<string, any>, deltaValue as Record<string, any>);\n      } else if (Array.isArray(accValue) && Array.isArray(deltaValue)) {\n        if (accValue.every((x) => typeof x === 'string' || typeof x === 'number')) {\n          accValue.push(...deltaValue); // Use spread syntax for efficient addition\n          continue;\n        }\n\n        for (const deltaEntry of deltaValue) {\n          if (!isObj(deltaEntry)) {\n            throw new Error(`Expected array delta entry to be an object but got: ${deltaEntry}`);\n          }\n\n          const index = deltaEntry['index'];\n          if (index == null) {\n            console.error(deltaEntry);\n            throw new Error('Expected array delta entry to have an `index` property');\n          }\n\n          if (typeof index !== 'number') {\n            throw new Error(`Expected array delta entry \\`index\\` property to be a number but got ${index}`);\n          }\n\n          const accEntry = accValue[index];\n          if (accEntry == null) {\n            accValue.push(deltaEntry);\n          } else {\n            accValue[index] = this.accumulateDelta(accEntry, deltaEntry);\n          }\n        }\n        continue;\n      } else {\n        throw Error(`Unhandled record type: ${key}, deltaValue: ${deltaValue}, accValue: ${accValue}`);\n      }\n      acc[key] = accValue;\n    }\n\n    return acc;\n  }\n\n  #handleRun(this: AssistantStream, event: RunStreamEvent) {\n    this.#currentRunSnapshot = event.data;\n\n    switch (event.event) {\n      case 'thread.run.created':\n        break;\n      case 'thread.run.queued':\n        break;\n      case 'thread.run.in_progress':\n        break;\n      case 'thread.run.requires_action':\n      case 'thread.run.cancelled':\n      case 'thread.run.failed':\n      case 'thread.run.completed':\n      case 'thread.run.expired':\n      case 'thread.run.incomplete':\n        this.#finalRun = event.data;\n        if (this.#currentToolCall) {\n          this._emit('toolCallDone', this.#currentToolCall);\n          this.#currentToolCall = undefined;\n        }\n        break;\n      case 'thread.run.cancelling':\n        break;\n    }\n  }\n\n  protected _addRun(run: Run): Run {\n    return run;\n  }\n\n  protected async _threadAssistantStream(\n    params: ThreadCreateAndRunParamsBase,\n    thread: Threads,\n    options?: RequestOptions,\n  ): Promise<Run> {\n    return await this._createThreadAssistantStream(thread, params, options);\n  }\n\n  protected async _runAssistantStream(\n    threadId: string,\n    runs: Runs,\n    params: RunCreateParamsBase,\n    options?: RequestOptions,\n  ): Promise<Run> {\n    return await this._createAssistantStream(runs, threadId, params, options);\n  }\n\n  protected async _runToolAssistantStream(\n    runId: string,\n    runs: Runs,\n    params: RunSubmitToolOutputsParamsStream,\n    options?: RequestOptions,\n  ): Promise<Run> {\n    return await this._createToolAssistantStream(runs, runId, params, options);\n  }\n}\n\nfunction assertNever(_x: never) {}\n","import { partialParse } from '../_vendor/partial-json-parser/parser';\nimport {\n  APIUserAbortError,\n  ContentFilterFinishReasonError,\n  LengthFinishReasonError,\n  OpenAIError,\n} from '../error';\nimport OpenAI from '../index';\nimport { RequestOptions } from '../internal/request-options';\nimport { type ReadableStream } from '../internal/shim-types';\nimport {\n  AutoParseableResponseFormat,\n  hasAutoParseableInput,\n  isAutoParsableResponseFormat,\n  isAutoParsableTool,\n  isChatCompletionFunctionTool,\n  maybeParseChatCompletion,\n  shouldParseToolCall,\n} from '../lib/parser';\nimport { ChatCompletionFunctionTool, ParsedChatCompletion } from '../resources/chat/completions';\nimport {\n  ChatCompletionTokenLogprob,\n  type ChatCompletion,\n  type ChatCompletionChunk,\n  type ChatCompletionCreateParams,\n  type ChatCompletionCreateParamsBase,\n  type ChatCompletionCreateParamsStreaming,\n  type ChatCompletionRole,\n} from '../resources/chat/completions/completions';\nimport { Stream } from '../streaming';\nimport {\n  AbstractChatCompletionRunner,\n  type AbstractChatCompletionRunnerEvents,\n} from './AbstractChatCompletionRunner';\n\nexport interface ContentDeltaEvent {\n  delta: string;\n  snapshot: string;\n  parsed: unknown | null;\n}\n\nexport interface ContentDoneEvent<ParsedT = null> {\n  content: string;\n  parsed: ParsedT | null;\n}\n\nexport interface RefusalDeltaEvent {\n  delta: string;\n  snapshot: string;\n}\n\nexport interface RefusalDoneEvent {\n  refusal: string;\n}\n\nexport interface FunctionToolCallArgumentsDeltaEvent {\n  name: string;\n\n  index: number;\n\n  arguments: string;\n\n  parsed_arguments: unknown;\n\n  arguments_delta: string;\n}\n\nexport interface FunctionToolCallArgumentsDoneEvent {\n  name: string;\n\n  index: number;\n\n  arguments: string;\n\n  parsed_arguments: unknown;\n}\n\nexport interface LogProbsContentDeltaEvent {\n  content: Array<ChatCompletionTokenLogprob>;\n  snapshot: Array<ChatCompletionTokenLogprob>;\n}\n\nexport interface LogProbsContentDoneEvent {\n  content: Array<ChatCompletionTokenLogprob>;\n}\n\nexport interface LogProbsRefusalDeltaEvent {\n  refusal: Array<ChatCompletionTokenLogprob>;\n  snapshot: Array<ChatCompletionTokenLogprob>;\n}\n\nexport interface LogProbsRefusalDoneEvent {\n  refusal: Array<ChatCompletionTokenLogprob>;\n}\n\nexport interface ChatCompletionStreamEvents<ParsedT = null> extends AbstractChatCompletionRunnerEvents {\n  content: (contentDelta: string, contentSnapshot: string) => void;\n  chunk: (chunk: ChatCompletionChunk, snapshot: ChatCompletionSnapshot) => void;\n\n  'content.delta': (props: ContentDeltaEvent) => void;\n  'content.done': (props: ContentDoneEvent<ParsedT>) => void;\n\n  'refusal.delta': (props: RefusalDeltaEvent) => void;\n  'refusal.done': (props: RefusalDoneEvent) => void;\n\n  'tool_calls.function.arguments.delta': (props: FunctionToolCallArgumentsDeltaEvent) => void;\n  'tool_calls.function.arguments.done': (props: FunctionToolCallArgumentsDoneEvent) => void;\n\n  'logprobs.content.delta': (props: LogProbsContentDeltaEvent) => void;\n  'logprobs.content.done': (props: LogProbsContentDoneEvent) => void;\n\n  'logprobs.refusal.delta': (props: LogProbsRefusalDeltaEvent) => void;\n  'logprobs.refusal.done': (props: LogProbsRefusalDoneEvent) => void;\n}\n\nexport type ChatCompletionStreamParams = Omit<ChatCompletionCreateParamsBase, 'stream'> & {\n  stream?: true;\n};\n\ninterface ChoiceEventState {\n  content_done: boolean;\n  refusal_done: boolean;\n  logprobs_content_done: boolean;\n  logprobs_refusal_done: boolean;\n  current_tool_call_index: number | null;\n  done_tool_calls: Set<number>;\n}\n\nexport class ChatCompletionStream<ParsedT = null>\n  extends AbstractChatCompletionRunner<ChatCompletionStreamEvents<ParsedT>, ParsedT>\n  implements AsyncIterable<ChatCompletionChunk>\n{\n  #params: ChatCompletionCreateParams | null;\n  #choiceEventStates: ChoiceEventState[];\n  #currentChatCompletionSnapshot: ChatCompletionSnapshot | undefined;\n\n  constructor(params: ChatCompletionCreateParams | null) {\n    super();\n    this.#params = params;\n    this.#choiceEventStates = [];\n  }\n\n  get currentChatCompletionSnapshot(): ChatCompletionSnapshot | undefined {\n    return this.#currentChatCompletionSnapshot;\n  }\n\n  /**\n   * Intended for use on the frontend, consuming a stream produced with\n   * `.toReadableStream()` on the backend.\n   *\n   * Note that messages sent to the model do not appear in `.on('message')`\n   * in this context.\n   */\n  static fromReadableStream(stream: ReadableStream): ChatCompletionStream<null> {\n    const runner = new ChatCompletionStream(null);\n    runner._run(() => runner._fromReadableStream(stream));\n    return runner;\n  }\n\n  static createChatCompletion<ParsedT>(\n    client: OpenAI,\n    params: ChatCompletionStreamParams,\n    options?: RequestOptions,\n  ): ChatCompletionStream<ParsedT> {\n    const runner = new ChatCompletionStream<ParsedT>(params as ChatCompletionCreateParamsStreaming);\n    runner._run(() =>\n      runner._runChatCompletion(\n        client,\n        { ...params, stream: true },\n        { ...options, headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' } },\n      ),\n    );\n    return runner;\n  }\n\n  #beginRequest() {\n    if (this.ended) return;\n    this.#currentChatCompletionSnapshot = undefined;\n  }\n\n  #getChoiceEventState(choice: ChatCompletionSnapshot.Choice): ChoiceEventState {\n    let state = this.#choiceEventStates[choice.index];\n    if (state) {\n      return state;\n    }\n\n    state = {\n      content_done: false,\n      refusal_done: false,\n      logprobs_content_done: false,\n      logprobs_refusal_done: false,\n      done_tool_calls: new Set(),\n      current_tool_call_index: null,\n    };\n    this.#choiceEventStates[choice.index] = state;\n    return state;\n  }\n\n  #addChunk(this: ChatCompletionStream<ParsedT>, chunk: ChatCompletionChunk) {\n    if (this.ended) return;\n\n    const completion = this.#accumulateChatCompletion(chunk);\n    this._emit('chunk', chunk, completion);\n\n    for (const choice of chunk.choices) {\n      const choiceSnapshot = completion.choices[choice.index]!;\n\n      if (\n        choice.delta.content != null &&\n        choiceSnapshot.message?.role === 'assistant' &&\n        choiceSnapshot.message?.content\n      ) {\n        this._emit('content', choice.delta.content, choiceSnapshot.message.content);\n        this._emit('content.delta', {\n          delta: choice.delta.content,\n          snapshot: choiceSnapshot.message.content,\n          parsed: choiceSnapshot.message.parsed,\n        });\n      }\n\n      if (\n        choice.delta.refusal != null &&\n        choiceSnapshot.message?.role === 'assistant' &&\n        choiceSnapshot.message?.refusal\n      ) {\n        this._emit('refusal.delta', {\n          delta: choice.delta.refusal,\n          snapshot: choiceSnapshot.message.refusal,\n        });\n      }\n\n      if (choice.logprobs?.content != null && choiceSnapshot.message?.role === 'assistant') {\n        this._emit('logprobs.content.delta', {\n          content: choice.logprobs?.content,\n          snapshot: choiceSnapshot.logprobs?.content ?? [],\n        });\n      }\n\n      if (choice.logprobs?.refusal != null && choiceSnapshot.message?.role === 'assistant') {\n        this._emit('logprobs.refusal.delta', {\n          refusal: choice.logprobs?.refusal,\n          snapshot: choiceSnapshot.logprobs?.refusal ?? [],\n        });\n      }\n\n      const state = this.#getChoiceEventState(choiceSnapshot);\n\n      if (choiceSnapshot.finish_reason) {\n        this.#emitContentDoneEvents(choiceSnapshot);\n\n        if (state.current_tool_call_index != null) {\n          this.#emitToolCallDoneEvent(choiceSnapshot, state.current_tool_call_index);\n        }\n      }\n\n      for (const toolCall of choice.delta.tool_calls ?? []) {\n        if (state.current_tool_call_index !== toolCall.index) {\n          this.#emitContentDoneEvents(choiceSnapshot);\n\n          // new tool call started, the previous one is done\n          if (state.current_tool_call_index != null) {\n            this.#emitToolCallDoneEvent(choiceSnapshot, state.current_tool_call_index);\n          }\n        }\n\n        state.current_tool_call_index = toolCall.index;\n      }\n\n      for (const toolCallDelta of choice.delta.tool_calls ?? []) {\n        const toolCallSnapshot = choiceSnapshot.message.tool_calls?.[toolCallDelta.index];\n        if (!toolCallSnapshot?.type) {\n          continue;\n        }\n\n        if (toolCallSnapshot?.type === 'function') {\n          this._emit('tool_calls.function.arguments.delta', {\n            name: toolCallSnapshot.function?.name,\n            index: toolCallDelta.index,\n            arguments: toolCallSnapshot.function.arguments,\n            parsed_arguments: toolCallSnapshot.function.parsed_arguments,\n            arguments_delta: toolCallDelta.function?.arguments ?? '',\n          });\n        } else {\n          assertNever(toolCallSnapshot?.type);\n        }\n      }\n    }\n  }\n\n  #emitToolCallDoneEvent(choiceSnapshot: ChatCompletionSnapshot.Choice, toolCallIndex: number) {\n    const state = this.#getChoiceEventState(choiceSnapshot);\n    if (state.done_tool_calls.has(toolCallIndex)) {\n      // we've already fired the done event\n      return;\n    }\n\n    const toolCallSnapshot = choiceSnapshot.message.tool_calls?.[toolCallIndex];\n    if (!toolCallSnapshot) {\n      throw new Error('no tool call snapshot');\n    }\n    if (!toolCallSnapshot.type) {\n      throw new Error('tool call snapshot missing `type`');\n    }\n\n    if (toolCallSnapshot.type === 'function') {\n      const inputTool = this.#params?.tools?.find(\n        (tool) => isChatCompletionFunctionTool(tool) && tool.function.name === toolCallSnapshot.function.name,\n      ) as ChatCompletionFunctionTool | undefined; // TS doesn't narrow based on isChatCompletionTool\n\n      this._emit('tool_calls.function.arguments.done', {\n        name: toolCallSnapshot.function.name,\n        index: toolCallIndex,\n        arguments: toolCallSnapshot.function.arguments,\n        parsed_arguments:\n          isAutoParsableTool(inputTool) ? inputTool.$parseRaw(toolCallSnapshot.function.arguments)\n          : inputTool?.function.strict ? JSON.parse(toolCallSnapshot.function.arguments)\n          : null,\n      });\n    } else {\n      assertNever(toolCallSnapshot.type);\n    }\n  }\n\n  #emitContentDoneEvents(choiceSnapshot: ChatCompletionSnapshot.Choice) {\n    const state = this.#getChoiceEventState(choiceSnapshot);\n\n    if (choiceSnapshot.message.content && !state.content_done) {\n      state.content_done = true;\n\n      const responseFormat = this.#getAutoParseableResponseFormat();\n\n      this._emit('content.done', {\n        content: choiceSnapshot.message.content,\n        parsed: responseFormat ? responseFormat.$parseRaw(choiceSnapshot.message.content) : (null as any),\n      });\n    }\n\n    if (choiceSnapshot.message.refusal && !state.refusal_done) {\n      state.refusal_done = true;\n\n      this._emit('refusal.done', { refusal: choiceSnapshot.message.refusal });\n    }\n\n    if (choiceSnapshot.logprobs?.content && !state.logprobs_content_done) {\n      state.logprobs_content_done = true;\n\n      this._emit('logprobs.content.done', { content: choiceSnapshot.logprobs.content });\n    }\n\n    if (choiceSnapshot.logprobs?.refusal && !state.logprobs_refusal_done) {\n      state.logprobs_refusal_done = true;\n\n      this._emit('logprobs.refusal.done', { refusal: choiceSnapshot.logprobs.refusal });\n    }\n  }\n\n  #endRequest(): ParsedChatCompletion<ParsedT> {\n    if (this.ended) {\n      throw new OpenAIError(`stream has ended, this shouldn't happen`);\n    }\n    const snapshot = this.#currentChatCompletionSnapshot;\n    if (!snapshot) {\n      throw new OpenAIError(`request ended without sending any chunks`);\n    }\n    this.#currentChatCompletionSnapshot = undefined;\n    this.#choiceEventStates = [];\n    return finalizeChatCompletion(snapshot, this.#params);\n  }\n\n  protected override async _createChatCompletion(\n    client: OpenAI,\n    params: ChatCompletionCreateParams,\n    options?: RequestOptions,\n  ): Promise<ParsedChatCompletion<ParsedT>> {\n    super._createChatCompletion;\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n    this.#beginRequest();\n\n    const stream = await client.chat.completions.create(\n      { ...params, stream: true },\n      { ...options, signal: this.controller.signal },\n    );\n    this._connected();\n    for await (const chunk of stream) {\n      this.#addChunk(chunk);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n    return this._addChatCompletion(this.#endRequest());\n  }\n\n  protected async _fromReadableStream(\n    readableStream: ReadableStream,\n    options?: RequestOptions,\n  ): Promise<ChatCompletion> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n    this.#beginRequest();\n    this._connected();\n    const stream = Stream.fromReadableStream<ChatCompletionChunk>(readableStream, this.controller);\n    let chatId;\n    for await (const chunk of stream) {\n      if (chatId && chatId !== chunk.id) {\n        // A new request has been made.\n        this._addChatCompletion(this.#endRequest());\n      }\n\n      this.#addChunk(chunk);\n      chatId = chunk.id;\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n    return this._addChatCompletion(this.#endRequest());\n  }\n\n  #getAutoParseableResponseFormat(): AutoParseableResponseFormat<ParsedT> | null {\n    const responseFormat = this.#params?.response_format;\n    if (isAutoParsableResponseFormat<ParsedT>(responseFormat)) {\n      return responseFormat;\n    }\n\n    return null;\n  }\n\n  #accumulateChatCompletion(chunk: ChatCompletionChunk): ChatCompletionSnapshot {\n    let snapshot = this.#currentChatCompletionSnapshot;\n    const { choices, ...rest } = chunk;\n    if (!snapshot) {\n      snapshot = this.#currentChatCompletionSnapshot = {\n        ...rest,\n        choices: [],\n      };\n    } else {\n      Object.assign(snapshot, rest);\n    }\n\n    for (const { delta, finish_reason, index, logprobs = null, ...other } of chunk.choices) {\n      let choice = snapshot.choices[index];\n      if (!choice) {\n        choice = snapshot.choices[index] = { finish_reason, index, message: {}, logprobs, ...other };\n      }\n\n      if (logprobs) {\n        if (!choice.logprobs) {\n          choice.logprobs = Object.assign({}, logprobs);\n        } else {\n          const { content, refusal, ...rest } = logprobs;\n          assertIsEmpty(rest);\n          Object.assign(choice.logprobs, rest);\n\n          if (content) {\n            choice.logprobs.content ??= [];\n            choice.logprobs.content.push(...content);\n          }\n\n          if (refusal) {\n            choice.logprobs.refusal ??= [];\n            choice.logprobs.refusal.push(...refusal);\n          }\n        }\n      }\n\n      if (finish_reason) {\n        choice.finish_reason = finish_reason;\n\n        if (this.#params && hasAutoParseableInput(this.#params)) {\n          if (finish_reason === 'length') {\n            throw new LengthFinishReasonError();\n          }\n\n          if (finish_reason === 'content_filter') {\n            throw new ContentFilterFinishReasonError();\n          }\n        }\n      }\n\n      Object.assign(choice, other);\n\n      if (!delta) continue; // Shouldn't happen; just in case.\n\n      const { content, refusal, function_call, role, tool_calls, ...rest } = delta;\n      assertIsEmpty(rest);\n      Object.assign(choice.message, rest);\n\n      if (refusal) {\n        choice.message.refusal = (choice.message.refusal || '') + refusal;\n      }\n\n      if (role) choice.message.role = role;\n      if (function_call) {\n        if (!choice.message.function_call) {\n          choice.message.function_call = function_call;\n        } else {\n          if (function_call.name) choice.message.function_call.name = function_call.name;\n          if (function_call.arguments) {\n            choice.message.function_call.arguments ??= '';\n            choice.message.function_call.arguments += function_call.arguments;\n          }\n        }\n      }\n      if (content) {\n        choice.message.content = (choice.message.content || '') + content;\n\n        if (!choice.message.refusal && this.#getAutoParseableResponseFormat()) {\n          choice.message.parsed = partialParse(choice.message.content);\n        }\n      }\n\n      if (tool_calls) {\n        if (!choice.message.tool_calls) choice.message.tool_calls = [];\n\n        for (const { index, id, type, function: fn, ...rest } of tool_calls) {\n          const tool_call = (choice.message.tool_calls[index] ??=\n            {} as ChatCompletionSnapshot.Choice.Message.ToolCall);\n          Object.assign(tool_call, rest);\n          if (id) tool_call.id = id;\n          if (type) tool_call.type = type;\n          if (fn) tool_call.function ??= { name: fn.name ?? '', arguments: '' };\n          if (fn?.name) tool_call.function!.name = fn.name;\n          if (fn?.arguments) {\n            tool_call.function!.arguments += fn.arguments;\n\n            if (shouldParseToolCall(this.#params, tool_call)) {\n              tool_call.function!.parsed_arguments = partialParse(tool_call.function!.arguments);\n            }\n          }\n        }\n      }\n    }\n    return snapshot;\n  }\n\n  [Symbol.asyncIterator](this: ChatCompletionStream<ParsedT>): AsyncIterator<ChatCompletionChunk> {\n    const pushQueue: ChatCompletionChunk[] = [];\n    const readQueue: {\n      resolve: (chunk: ChatCompletionChunk | undefined) => void;\n      reject: (err: unknown) => void;\n    }[] = [];\n    let done = false;\n\n    this.on('chunk', (chunk) => {\n      const reader = readQueue.shift();\n      if (reader) {\n        reader.resolve(chunk);\n      } else {\n        pushQueue.push(chunk);\n      }\n    });\n\n    this.on('end', () => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.resolve(undefined);\n      }\n      readQueue.length = 0;\n    });\n\n    this.on('abort', (err) => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.reject(err);\n      }\n      readQueue.length = 0;\n    });\n\n    this.on('error', (err) => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.reject(err);\n      }\n      readQueue.length = 0;\n    });\n\n    return {\n      next: async (): Promise<IteratorResult<ChatCompletionChunk>> => {\n        if (!pushQueue.length) {\n          if (done) {\n            return { value: undefined, done: true };\n          }\n          return new Promise<ChatCompletionChunk | undefined>((resolve, reject) =>\n            readQueue.push({ resolve, reject }),\n          ).then((chunk) => (chunk ? { value: chunk, done: false } : { value: undefined, done: true }));\n        }\n        const chunk = pushQueue.shift()!;\n        return { value: chunk, done: false };\n      },\n      return: async () => {\n        this.abort();\n        return { value: undefined, done: true };\n      },\n    };\n  }\n\n  toReadableStream(): ReadableStream {\n    const stream = new Stream(this[Symbol.asyncIterator].bind(this), this.controller);\n    return stream.toReadableStream();\n  }\n}\n\nfunction finalizeChatCompletion<ParsedT>(\n  snapshot: ChatCompletionSnapshot,\n  params: ChatCompletionCreateParams | null,\n): ParsedChatCompletion<ParsedT> {\n  const { id, choices, created, model, system_fingerprint, ...rest } = snapshot;\n  const completion: ChatCompletion = {\n    ...rest,\n    id,\n    choices: choices.map(\n      ({ message, finish_reason, index, logprobs, ...choiceRest }): ChatCompletion.Choice => {\n        if (!finish_reason) {\n          throw new OpenAIError(`missing finish_reason for choice ${index}`);\n        }\n\n        const { content = null, function_call, tool_calls, ...messageRest } = message;\n        const role = message.role as 'assistant'; // this is what we expect; in theory it could be different which would make our types a slight lie but would be fine.\n        if (!role) {\n          throw new OpenAIError(`missing role for choice ${index}`);\n        }\n\n        if (function_call) {\n          const { arguments: args, name } = function_call;\n          if (args == null) {\n            throw new OpenAIError(`missing function_call.arguments for choice ${index}`);\n          }\n\n          if (!name) {\n            throw new OpenAIError(`missing function_call.name for choice ${index}`);\n          }\n\n          return {\n            ...choiceRest,\n            message: {\n              content,\n              function_call: { arguments: args, name },\n              role,\n              refusal: message.refusal ?? null,\n            },\n            finish_reason,\n            index,\n            logprobs,\n          };\n        }\n\n        if (tool_calls) {\n          return {\n            ...choiceRest,\n            index,\n            finish_reason,\n            logprobs,\n            message: {\n              ...messageRest,\n              role,\n              content,\n              refusal: message.refusal ?? null,\n              tool_calls: tool_calls.map((tool_call, i) => {\n                const { function: fn, type, id, ...toolRest } = tool_call;\n                const { arguments: args, name, ...fnRest } = fn || {};\n                if (id == null) {\n                  throw new OpenAIError(`missing choices[${index}].tool_calls[${i}].id\\n${str(snapshot)}`);\n                }\n                if (type == null) {\n                  throw new OpenAIError(`missing choices[${index}].tool_calls[${i}].type\\n${str(snapshot)}`);\n                }\n                if (name == null) {\n                  throw new OpenAIError(\n                    `missing choices[${index}].tool_calls[${i}].function.name\\n${str(snapshot)}`,\n                  );\n                }\n                if (args == null) {\n                  throw new OpenAIError(\n                    `missing choices[${index}].tool_calls[${i}].function.arguments\\n${str(snapshot)}`,\n                  );\n                }\n\n                return { ...toolRest, id, type, function: { ...fnRest, name, arguments: args } };\n              }),\n            },\n          };\n        }\n        return {\n          ...choiceRest,\n          message: { ...messageRest, content, role, refusal: message.refusal ?? null },\n          finish_reason,\n          index,\n          logprobs,\n        };\n      },\n    ),\n    created,\n    model,\n    object: 'chat.completion',\n    ...(system_fingerprint ? { system_fingerprint } : {}),\n  };\n\n  return maybeParseChatCompletion(completion, params);\n}\n\nfunction str(x: unknown) {\n  return JSON.stringify(x);\n}\n\n/**\n * Represents a streamed chunk of a chat completion response returned by model,\n * based on the provided input.\n */\nexport interface ChatCompletionSnapshot {\n  /**\n   * A unique identifier for the chat completion.\n   */\n  id: string;\n\n  /**\n   * A list of chat completion choices. Can be more than one if `n` is greater\n   * than 1.\n   */\n  choices: Array<ChatCompletionSnapshot.Choice>;\n\n  /**\n   * The Unix timestamp (in seconds) of when the chat completion was created.\n   */\n  created: number;\n\n  /**\n   * The model to generate the completion.\n   */\n  model: string;\n\n  // Note we do not include an \"object\" type on the snapshot,\n  // because the object is not a valid \"chat.completion\" until finalized.\n  // object: 'chat.completion';\n\n  /**\n   * This fingerprint represents the backend configuration that the model runs with.\n   *\n   * Can be used in conjunction with the `seed` request parameter to understand when\n   * backend changes have been made that might impact determinism.\n   */\n  system_fingerprint?: string;\n}\n\nexport namespace ChatCompletionSnapshot {\n  export interface Choice {\n    /**\n     * A chat completion delta generated by streamed model responses.\n     */\n    message: Choice.Message;\n\n    /**\n     * The reason the model stopped generating tokens. This will be `stop` if the model\n     * hit a natural stop point or a provided stop sequence, `length` if the maximum\n     * number of tokens specified in the request was reached, `content_filter` if\n     * content was omitted due to a flag from our content filters, or `function_call`\n     * if the model called a function.\n     */\n    finish_reason: ChatCompletion.Choice['finish_reason'] | null;\n\n    /**\n     * Log probability information for the choice.\n     */\n    logprobs: ChatCompletion.Choice.Logprobs | null;\n\n    /**\n     * The index of the choice in the list of choices.\n     */\n    index: number;\n  }\n\n  export namespace Choice {\n    /**\n     * A chat completion delta generated by streamed model responses.\n     */\n    export interface Message {\n      /**\n       * The contents of the chunk message.\n       */\n      content?: string | null;\n\n      refusal?: string | null;\n\n      parsed?: unknown | null;\n\n      /**\n       * The name and arguments of a function that should be called, as generated by the\n       * model.\n       */\n      function_call?: Message.FunctionCall;\n\n      tool_calls?: Array<Message.ToolCall>;\n\n      /**\n       * The role of the author of this message.\n       */\n      role?: ChatCompletionRole;\n    }\n\n    export namespace Message {\n      export interface ToolCall {\n        /**\n         * The ID of the tool call.\n         */\n        id: string;\n\n        function: ToolCall.Function;\n\n        /**\n         * The type of the tool.\n         */\n        type: 'function';\n      }\n\n      export namespace ToolCall {\n        export interface Function {\n          /**\n           * The arguments to call the function with, as generated by the model in JSON\n           * format. Note that the model does not always generate valid JSON, and may\n           * hallucinate parameters not defined by your function schema. Validate the\n           * arguments in your code before calling your function.\n           */\n          arguments: string;\n\n          parsed_arguments?: unknown;\n\n          /**\n           * The name of the function to call.\n           */\n          name: string;\n        }\n      }\n\n      /**\n       * The name and arguments of a function that should be called, as generated by the\n       * model.\n       */\n      export interface FunctionCall {\n        /**\n         * The arguments to call the function with, as generated by the model in JSON\n         * format. Note that the model does not always generate valid JSON, and may\n         * hallucinate parameters not defined by your function schema. Validate the\n         * arguments in your code before calling your function.\n         */\n        arguments?: string;\n\n        /**\n         * The name of the function to call.\n         */\n        name?: string;\n      }\n    }\n  }\n}\n\ntype AssertIsEmpty<T extends {}> = keyof T extends never ? T : never;\n\n/**\n * Ensures the given argument is an empty object, useful for\n * asserting that all known properties on an object have been\n * destructured.\n */\nfunction assertIsEmpty<T extends {}>(obj: AssertIsEmpty<T>): asserts obj is AssertIsEmpty<T> {\n  return;\n}\n\nfunction assertNever(_x: never) {}\n","import { OpenAIError } from './error';\nimport { type ReadableStream } from '../internal/shim-types';\nimport { makeReadableStream } from '../internal/shims';\nimport { findDoubleNewlineIndex, LineDecoder } from '../internal/decoders/line';\nimport { ReadableStreamToAsyncIterable } from '../internal/shims';\nimport { isAbortError } from '../internal/errors';\nimport { encodeUTF8 } from '../internal/utils/bytes';\nimport { loggerFor } from '../internal/utils/log';\nimport type { OpenAI } from '../client';\n\nimport { APIError } from './error';\n\ntype Bytes = string | ArrayBuffer | Uint8Array | null | undefined;\n\nexport type ServerSentEvent = {\n  event: string | null;\n  data: string;\n  raw: string[];\n};\n\nexport class Stream<Item> implements AsyncIterable<Item> {\n  controller: AbortController;\n  #client: OpenAI | undefined;\n\n  constructor(\n    private iterator: () => AsyncIterator<Item>,\n    controller: AbortController,\n    client?: OpenAI,\n  ) {\n    this.controller = controller;\n    this.#client = client;\n  }\n\n  static fromSSEResponse<Item>(\n    response: Response,\n    controller: AbortController,\n    client?: OpenAI,\n  ): Stream<Item> {\n    let consumed = false;\n    const logger = client ? loggerFor(client) : console;\n\n    async function* iterator(): AsyncIterator<Item, any, undefined> {\n      if (consumed) {\n        throw new OpenAIError('Cannot iterate over a consumed stream, use `.tee()` to split the stream.');\n      }\n      consumed = true;\n      let done = false;\n      try {\n        for await (const sse of _iterSSEMessages(response, controller)) {\n          if (done) continue;\n\n          if (sse.data.startsWith('[DONE]')) {\n            done = true;\n            continue;\n          }\n\n          if (sse.event === null || !sse.event.startsWith('thread.')) {\n            let data;\n\n            try {\n              data = JSON.parse(sse.data);\n            } catch (e) {\n              logger.error(`Could not parse message into JSON:`, sse.data);\n              logger.error(`From chunk:`, sse.raw);\n              throw e;\n            }\n\n            if (data && data.error) {\n              throw new APIError(undefined, data.error, undefined, response.headers);\n            }\n\n            yield data;\n          } else {\n            let data;\n            try {\n              data = JSON.parse(sse.data);\n            } catch (e) {\n              console.error(`Could not parse message into JSON:`, sse.data);\n              console.error(`From chunk:`, sse.raw);\n              throw e;\n            }\n            // TODO: Is this where the error should be thrown?\n            if (sse.event == 'error') {\n              throw new APIError(undefined, data.error, data.message, undefined);\n            }\n            yield { event: sse.event, data: data } as any;\n          }\n        }\n        done = true;\n      } catch (e) {\n        // If the user calls `stream.controller.abort()`, we should exit without throwing.\n        if (isAbortError(e)) return;\n        throw e;\n      } finally {\n        // If the user `break`s, abort the ongoing request.\n        if (!done) controller.abort();\n      }\n    }\n\n    return new Stream(iterator, controller, client);\n  }\n\n  /**\n   * Generates a Stream from a newline-separated ReadableStream\n   * where each item is a JSON value.\n   */\n  static fromReadableStream<Item>(\n    readableStream: ReadableStream,\n    controller: AbortController,\n    client?: OpenAI,\n  ): Stream<Item> {\n    let consumed = false;\n\n    async function* iterLines(): AsyncGenerator<string, void, unknown> {\n      const lineDecoder = new LineDecoder();\n\n      const iter = ReadableStreamToAsyncIterable<Bytes>(readableStream);\n      for await (const chunk of iter) {\n        for (const line of lineDecoder.decode(chunk)) {\n          yield line;\n        }\n      }\n\n      for (const line of lineDecoder.flush()) {\n        yield line;\n      }\n    }\n\n    async function* iterator(): AsyncIterator<Item, any, undefined> {\n      if (consumed) {\n        throw new OpenAIError('Cannot iterate over a consumed stream, use `.tee()` to split the stream.');\n      }\n      consumed = true;\n      let done = false;\n      try {\n        for await (const line of iterLines()) {\n          if (done) continue;\n          if (line) yield JSON.parse(line);\n        }\n        done = true;\n      } catch (e) {\n        // If the user calls `stream.controller.abort()`, we should exit without throwing.\n        if (isAbortError(e)) return;\n        throw e;\n      } finally {\n        // If the user `break`s, abort the ongoing request.\n        if (!done) controller.abort();\n      }\n    }\n\n    return new Stream(iterator, controller, client);\n  }\n\n  [Symbol.asyncIterator](): AsyncIterator<Item> {\n    return this.iterator();\n  }\n\n  /**\n   * Splits the stream into two streams which can be\n   * independently read from at different speeds.\n   */\n  tee(): [Stream<Item>, Stream<Item>] {\n    const left: Array<Promise<IteratorResult<Item>>> = [];\n    const right: Array<Promise<IteratorResult<Item>>> = [];\n    const iterator = this.iterator();\n\n    const teeIterator = (queue: Array<Promise<IteratorResult<Item>>>): AsyncIterator<Item> => {\n      return {\n        next: () => {\n          if (queue.length === 0) {\n            const result = iterator.next();\n            left.push(result);\n            right.push(result);\n          }\n          return queue.shift()!;\n        },\n      };\n    };\n\n    return [\n      new Stream(() => teeIterator(left), this.controller, this.#client),\n      new Stream(() => teeIterator(right), this.controller, this.#client),\n    ];\n  }\n\n  /**\n   * Converts this stream to a newline-separated ReadableStream of\n   * JSON stringified values in the stream\n   * which can be turned back into a Stream with `Stream.fromReadableStream()`.\n   */\n  toReadableStream(): ReadableStream {\n    const self = this;\n    let iter: AsyncIterator<Item>;\n\n    return makeReadableStream({\n      async start() {\n        iter = self[Symbol.asyncIterator]();\n      },\n      async pull(ctrl: any) {\n        try {\n          const { value, done } = await iter.next();\n          if (done) return ctrl.close();\n\n          const bytes = encodeUTF8(JSON.stringify(value) + '\\n');\n\n          ctrl.enqueue(bytes);\n        } catch (err) {\n          ctrl.error(err);\n        }\n      },\n      async cancel() {\n        await iter.return?.();\n      },\n    });\n  }\n}\n\nexport async function* _iterSSEMessages(\n  response: Response,\n  controller: AbortController,\n): AsyncGenerator<ServerSentEvent, void, unknown> {\n  if (!response.body) {\n    controller.abort();\n    if (\n      typeof (globalThis as any).navigator !== 'undefined' &&\n      (globalThis as any).navigator.product === 'ReactNative'\n    ) {\n      throw new OpenAIError(\n        `The default react-native fetch implementation does not support streaming. Please use expo/fetch: https://docs.expo.dev/versions/latest/sdk/expo/#expofetch-api`,\n      );\n    }\n    throw new OpenAIError(`Attempted to iterate over a response with no body`);\n  }\n\n  const sseDecoder = new SSEDecoder();\n  const lineDecoder = new LineDecoder();\n\n  const iter = ReadableStreamToAsyncIterable<Bytes>(response.body);\n  for await (const sseChunk of iterSSEChunks(iter)) {\n    for (const line of lineDecoder.decode(sseChunk)) {\n      const sse = sseDecoder.decode(line);\n      if (sse) yield sse;\n    }\n  }\n\n  for (const line of lineDecoder.flush()) {\n    const sse = sseDecoder.decode(line);\n    if (sse) yield sse;\n  }\n}\n\n/**\n * Given an async iterable iterator, iterates over it and yields full\n * SSE chunks, i.e. yields when a double new-line is encountered.\n */\nasync function* iterSSEChunks(iterator: AsyncIterableIterator<Bytes>): AsyncGenerator<Uint8Array> {\n  let data = new Uint8Array();\n\n  for await (const chunk of iterator) {\n    if (chunk == null) {\n      continue;\n    }\n\n    const binaryChunk =\n      chunk instanceof ArrayBuffer ? new Uint8Array(chunk)\n      : typeof chunk === 'string' ? encodeUTF8(chunk)\n      : chunk;\n\n    let newData = new Uint8Array(data.length + binaryChunk.length);\n    newData.set(data);\n    newData.set(binaryChunk, data.length);\n    data = newData;\n\n    let patternIndex;\n    while ((patternIndex = findDoubleNewlineIndex(data)) !== -1) {\n      yield data.slice(0, patternIndex);\n      data = data.slice(patternIndex);\n    }\n  }\n\n  if (data.length > 0) {\n    yield data;\n  }\n}\n\nclass SSEDecoder {\n  private data: string[];\n  private event: string | null;\n  private chunks: string[];\n\n  constructor() {\n    this.event = null;\n    this.data = [];\n    this.chunks = [];\n  }\n\n  decode(line: string) {\n    if (line.endsWith('\\r')) {\n      line = line.substring(0, line.length - 1);\n    }\n\n    if (!line) {\n      // empty line and we didn't previously encounter any messages\n      if (!this.event && !this.data.length) return null;\n\n      const sse: ServerSentEvent = {\n        event: this.event,\n        data: this.data.join('\\n'),\n        raw: this.chunks,\n      };\n\n      this.event = null;\n      this.data = [];\n      this.chunks = [];\n\n      return sse;\n    }\n\n    this.chunks.push(line);\n\n    if (line.startsWith(':')) {\n      return null;\n    }\n\n    let [fieldname, _, value] = partition(line, ':');\n\n    if (value.startsWith(' ')) {\n      value = value.substring(1);\n    }\n\n    if (fieldname === 'event') {\n      this.event = value;\n    } else if (fieldname === 'data') {\n      this.data.push(value);\n    }\n\n    return null;\n  }\n}\n\nfunction partition(str: string, delimiter: string): [string, string, string] {\n  const index = str.indexOf(delimiter);\n  if (index !== -1) {\n    return [str.substring(0, index), delimiter, str.substring(index + delimiter.length)];\n  }\n\n  return [str, '', ''];\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n/**\n * https://stackoverflow.com/a/2117523\n */\nexport let uuid4 = function () {\n  const { crypto } = globalThis as any;\n  if (crypto?.randomUUID) {\n    uuid4 = crypto.randomUUID.bind(crypto);\n    return crypto.randomUUID();\n  }\n  const u8 = new Uint8Array(1);\n  const randomByte = crypto ? () => crypto.getRandomValues(u8)[0]! : () => (Math.random() * 0xff) & 0xff;\n  return '10000000-1000-4000-8000-100000000000'.replace(/[018]/g, (c) =>\n    (+c ^ (randomByte() & (15 >> (+c / 4)))).toString(16),\n  );\n};\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n/**\n * This module provides internal shims and utility functions for environments where certain Node.js or global types may not be available.\n *\n * These are used to ensure we can provide a consistent behaviour between different JavaScript environments and good error\n * messages in cases where an environment isn't fully supported.\n */\n\nimport type { Fetch } from './builtin-types';\nimport type { ReadableStream } from './shim-types';\n\nexport function getDefaultFetch(): Fetch {\n  if (typeof fetch !== 'undefined') {\n    return fetch as any;\n  }\n\n  throw new Error(\n    '`fetch` is not defined as a global; Either pass `fetch` to the client, `new OpenAI({ fetch })` or polyfill the global, `globalThis.fetch = fetch`',\n  );\n}\n\ntype ReadableStreamArgs = ConstructorParameters<typeof ReadableStream>;\n\nexport function makeReadableStream(...args: ReadableStreamArgs): ReadableStream {\n  const ReadableStream = (globalThis as any).ReadableStream;\n  if (typeof ReadableStream === 'undefined') {\n    // Note: All of the platforms / runtimes we officially support already define\n    // `ReadableStream` as a global, so this should only ever be hit on unsupported runtimes.\n    throw new Error(\n      '`ReadableStream` is not defined as a global; You will need to polyfill it, `globalThis.ReadableStream = ReadableStream`',\n    );\n  }\n\n  return new ReadableStream(...args);\n}\n\nexport function ReadableStreamFrom<T>(iterable: Iterable<T> | AsyncIterable<T>): ReadableStream<T> {\n  let iter: AsyncIterator<T> | Iterator<T> =\n    Symbol.asyncIterator in iterable ? iterable[Symbol.asyncIterator]() : iterable[Symbol.iterator]();\n\n  return makeReadableStream({\n    start() {},\n    async pull(controller: any) {\n      const { done, value } = await iter.next();\n      if (done) {\n        controller.close();\n      } else {\n        controller.enqueue(value);\n      }\n    },\n    async cancel() {\n      await iter.return?.();\n    },\n  });\n}\n\n/**\n * Most browsers don't yet have async iterable support for ReadableStream,\n * and Node has a very different way of reading bytes from its \"ReadableStream\".\n *\n * This polyfill was pulled from https://github.com/MattiasBuelens/web-streams-polyfill/pull/122#issuecomment-1627354490\n */\nexport function ReadableStreamToAsyncIterable<T>(stream: any): AsyncIterableIterator<T> {\n  if (stream[Symbol.asyncIterator]) return stream;\n\n  const reader = stream.getReader();\n  return {\n    async next() {\n      try {\n        const result = await reader.read();\n        if (result?.done) reader.releaseLock(); // release lock when stream becomes closed\n        return result;\n      } catch (e) {\n        reader.releaseLock(); // release lock when stream becomes errored\n        throw e;\n      }\n    },\n    async return() {\n      const cancelPromise = reader.cancel();\n      reader.releaseLock();\n      await cancelPromise;\n      return { done: true, value: undefined };\n    },\n    [Symbol.asyncIterator]() {\n      return this;\n    },\n  };\n}\n\n/**\n * Cancels a ReadableStream we don't need to consume.\n * See https://undici.nodejs.org/#/?id=garbage-collection\n */\nexport async function CancelReadableStream(stream: any): Promise<void> {\n  if (stream === null || typeof stream !== 'object') return;\n\n  if (stream[Symbol.asyncIterator]) {\n    await stream[Symbol.asyncIterator]().return?.();\n    return;\n  }\n\n  const reader = stream.getReader();\n  const cancelPromise = reader.cancel();\n  reader.releaseLock();\n  await cancelPromise;\n}\n","import { APIUserAbortError, OpenAIError } from '../error';\n\nexport class EventStream<EventTypes extends BaseEvents> {\n  controller: AbortController = new AbortController();\n\n  #connectedPromise: Promise<void>;\n  #resolveConnectedPromise: () => void = () => {};\n  #rejectConnectedPromise: (error: OpenAIError) => void = () => {};\n\n  #endPromise: Promise<void>;\n  #resolveEndPromise: () => void = () => {};\n  #rejectEndPromise: (error: OpenAIError) => void = () => {};\n\n  #listeners: {\n    [Event in keyof EventTypes]?: EventListeners<EventTypes, Event>;\n  } = {};\n\n  #ended = false;\n  #errored = false;\n  #aborted = false;\n  #catchingPromiseCreated = false;\n\n  constructor() {\n    this.#connectedPromise = new Promise<void>((resolve, reject) => {\n      this.#resolveConnectedPromise = resolve;\n      this.#rejectConnectedPromise = reject;\n    });\n\n    this.#endPromise = new Promise<void>((resolve, reject) => {\n      this.#resolveEndPromise = resolve;\n      this.#rejectEndPromise = reject;\n    });\n\n    // Don't let these promises cause unhandled rejection errors.\n    // we will manually cause an unhandled rejection error later\n    // if the user hasn't registered any error listener or called\n    // any promise-returning method.\n    this.#connectedPromise.catch(() => {});\n    this.#endPromise.catch(() => {});\n  }\n\n  protected _run(this: EventStream<EventTypes>, executor: () => Promise<any>) {\n    // Unfortunately if we call `executor()` immediately we get runtime errors about\n    // references to `this` before the `super()` constructor call returns.\n    setTimeout(() => {\n      executor().then(() => {\n        this._emitFinal();\n        this._emit('end');\n      }, this.#handleError.bind(this));\n    }, 0);\n  }\n\n  protected _connected(this: EventStream<EventTypes>) {\n    if (this.ended) return;\n    this.#resolveConnectedPromise();\n    this._emit('connect');\n  }\n\n  get ended(): boolean {\n    return this.#ended;\n  }\n\n  get errored(): boolean {\n    return this.#errored;\n  }\n\n  get aborted(): boolean {\n    return this.#aborted;\n  }\n\n  abort() {\n    this.controller.abort();\n  }\n\n  /**\n   * Adds the listener function to the end of the listeners array for the event.\n   * No checks are made to see if the listener has already been added. Multiple calls passing\n   * the same combination of event and listener will result in the listener being added, and\n   * called, multiple times.\n   * @returns this ChatCompletionStream, so that calls can be chained\n   */\n  on<Event extends keyof EventTypes>(event: Event, listener: EventListener<EventTypes, Event>): this {\n    const listeners: EventListeners<EventTypes, Event> =\n      this.#listeners[event] || (this.#listeners[event] = []);\n    listeners.push({ listener });\n    return this;\n  }\n\n  /**\n   * Removes the specified listener from the listener array for the event.\n   * off() will remove, at most, one instance of a listener from the listener array. If any single\n   * listener has been added multiple times to the listener array for the specified event, then\n   * off() must be called multiple times to remove each instance.\n   * @returns this ChatCompletionStream, so that calls can be chained\n   */\n  off<Event extends keyof EventTypes>(event: Event, listener: EventListener<EventTypes, Event>): this {\n    const listeners = this.#listeners[event];\n    if (!listeners) return this;\n    const index = listeners.findIndex((l) => l.listener === listener);\n    if (index >= 0) listeners.splice(index, 1);\n    return this;\n  }\n\n  /**\n   * Adds a one-time listener function for the event. The next time the event is triggered,\n   * this listener is removed and then invoked.\n   * @returns this ChatCompletionStream, so that calls can be chained\n   */\n  once<Event extends keyof EventTypes>(event: Event, listener: EventListener<EventTypes, Event>): this {\n    const listeners: EventListeners<EventTypes, Event> =\n      this.#listeners[event] || (this.#listeners[event] = []);\n    listeners.push({ listener, once: true });\n    return this;\n  }\n\n  /**\n   * This is similar to `.once()`, but returns a Promise that resolves the next time\n   * the event is triggered, instead of calling a listener callback.\n   * @returns a Promise that resolves the next time given event is triggered,\n   * or rejects if an error is emitted.  (If you request the 'error' event,\n   * returns a promise that resolves with the error).\n   *\n   * Example:\n   *\n   *   const message = await stream.emitted('message') // rejects if the stream errors\n   */\n  emitted<Event extends keyof EventTypes>(\n    event: Event,\n  ): Promise<\n    EventParameters<EventTypes, Event> extends [infer Param] ? Param\n    : EventParameters<EventTypes, Event> extends [] ? void\n    : EventParameters<EventTypes, Event>\n  > {\n    return new Promise((resolve, reject) => {\n      this.#catchingPromiseCreated = true;\n      if (event !== 'error') this.once('error', reject);\n      this.once(event, resolve as any);\n    });\n  }\n\n  async done(): Promise<void> {\n    this.#catchingPromiseCreated = true;\n    await this.#endPromise;\n  }\n\n  #handleError(this: EventStream<EventTypes>, error: unknown) {\n    this.#errored = true;\n    if (error instanceof Error && error.name === 'AbortError') {\n      error = new APIUserAbortError();\n    }\n    if (error instanceof APIUserAbortError) {\n      this.#aborted = true;\n      return this._emit('abort', error);\n    }\n    if (error instanceof OpenAIError) {\n      return this._emit('error', error);\n    }\n    if (error instanceof Error) {\n      const openAIError: OpenAIError = new OpenAIError(error.message);\n      // @ts-ignore\n      openAIError.cause = error;\n      return this._emit('error', openAIError);\n    }\n    return this._emit('error', new OpenAIError(String(error)));\n  }\n\n  _emit<Event extends keyof BaseEvents>(event: Event, ...args: EventParameters<BaseEvents, Event>): void;\n  _emit<Event extends keyof EventTypes>(event: Event, ...args: EventParameters<EventTypes, Event>): void;\n  _emit<Event extends keyof EventTypes>(\n    this: EventStream<EventTypes>,\n    event: Event,\n    ...args: EventParameters<EventTypes, Event>\n  ) {\n    // make sure we don't emit any events after end\n    if (this.#ended) {\n      return;\n    }\n\n    if (event === 'end') {\n      this.#ended = true;\n      this.#resolveEndPromise();\n    }\n\n    const listeners: EventListeners<EventTypes, Event> | undefined = this.#listeners[event];\n    if (listeners) {\n      this.#listeners[event] = listeners.filter((l) => !l.once) as any;\n      listeners.forEach(({ listener }: any) => listener(...(args as any)));\n    }\n\n    if (event === 'abort') {\n      const error = args[0] as APIUserAbortError;\n      if (!this.#catchingPromiseCreated && !listeners?.length) {\n        Promise.reject(error);\n      }\n      this.#rejectConnectedPromise(error);\n      this.#rejectEndPromise(error);\n      this._emit('end');\n      return;\n    }\n\n    if (event === 'error') {\n      // NOTE: _emit('error', error) should only be called from #handleError().\n\n      const error = args[0] as OpenAIError;\n      if (!this.#catchingPromiseCreated && !listeners?.length) {\n        // Trigger an unhandled rejection if the user hasn't registered any error handlers.\n        // If you are seeing stack traces here, make sure to handle errors via either:\n        // - runner.on('error', () => ...)\n        // - await runner.done()\n        // - await runner.finalChatCompletion()\n        // - etc.\n        Promise.reject(error);\n      }\n      this.#rejectConnectedPromise(error);\n      this.#rejectEndPromise(error);\n      this._emit('end');\n    }\n  }\n\n  protected _emitFinal(): void {}\n}\n\ntype EventListener<Events, EventType extends keyof Events> = Events[EventType];\n\ntype EventListeners<Events, EventType extends keyof Events> = Array<{\n  listener: EventListener<Events, EventType>;\n  once?: boolean;\n}>;\n\nexport type EventParameters<Events, EventType extends keyof Events> = {\n  [Event in EventType]: EventListener<Events, EventType> extends (...args: infer P) => any ? P : never;\n}[EventType];\n\nexport interface BaseEvents {\n  connect: () => void;\n  error: (error: OpenAIError) => void;\n  abort: (error: APIUserAbortError) => void;\n  end: () => void;\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nexport function isAbortError(err: unknown) {\n  return (\n    typeof err === 'object' &&\n    err !== null &&\n    // Spec-compliant fetch implementations\n    (('name' in err && (err as any).name === 'AbortError') ||\n      // Expo fetch\n      ('message' in err && String((err as any).message).includes('FetchRequestCanceledException')))\n  );\n}\n\nexport const castToError = (err: any): Error => {\n  if (err instanceof Error) return err;\n  if (typeof err === 'object' && err !== null) {\n    try {\n      if (Object.prototype.toString.call(err) === '[object Error]') {\n        // @ts-ignore - not all envs have native support for cause yet\n        const error = new Error(err.message, err.cause ? { cause: err.cause } : {});\n        if (err.stack) error.stack = err.stack;\n        // @ts-ignore - not all envs have native support for cause yet\n        if (err.cause && !error.cause) error.cause = err.cause;\n        if (err.name) error.name = err.name;\n        return error;\n      }\n    } catch {}\n    try {\n      return new Error(JSON.stringify(err));\n    } catch {}\n  }\n  return new Error(err);\n};\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { OpenAIError } from './error';\nimport { FinalRequestOptions } from '../internal/request-options';\nimport { defaultParseResponse, WithRequestID } from '../internal/parse';\nimport { APIPromise } from './api-promise';\nimport { type OpenAI } from '../client';\nimport { type APIResponseProps } from '../internal/parse';\nimport { maybeObj } from '../internal/utils/values';\n\nexport type PageRequestOptions = Pick<FinalRequestOptions, 'query' | 'headers' | 'body' | 'path' | 'method'>;\n\nexport abstract class AbstractPage<Item> implements AsyncIterable<Item> {\n  #client: OpenAI;\n  protected options: FinalRequestOptions;\n\n  protected response: Response;\n  protected body: unknown;\n\n  constructor(client: OpenAI, response: Response, body: unknown, options: FinalRequestOptions) {\n    this.#client = client;\n    this.options = options;\n    this.response = response;\n    this.body = body;\n  }\n\n  abstract nextPageRequestOptions(): PageRequestOptions | null;\n\n  abstract getPaginatedItems(): Item[];\n\n  hasNextPage(): boolean {\n    const items = this.getPaginatedItems();\n    if (!items.length) return false;\n    return this.nextPageRequestOptions() != null;\n  }\n\n  async getNextPage(): Promise<this> {\n    const nextOptions = this.nextPageRequestOptions();\n    if (!nextOptions) {\n      throw new OpenAIError(\n        'No next page expected; please check `.hasNextPage()` before calling `.getNextPage()`.',\n      );\n    }\n\n    return await this.#client.requestAPIList(this.constructor as any, nextOptions);\n  }\n\n  async *iterPages(): AsyncGenerator<this> {\n    let page: this = this;\n    yield page;\n    while (page.hasNextPage()) {\n      page = await page.getNextPage();\n      yield page;\n    }\n  }\n\n  async *[Symbol.asyncIterator](): AsyncGenerator<Item> {\n    for await (const page of this.iterPages()) {\n      for (const item of page.getPaginatedItems()) {\n        yield item;\n      }\n    }\n  }\n}\n\n/**\n * This subclass of Promise will resolve to an instantiated Page once the request completes.\n *\n * It also implements AsyncIterable to allow auto-paginating iteration on an unawaited list call, eg:\n *\n *    for await (const item of client.items.list()) {\n *      console.log(item)\n *    }\n */\nexport class PagePromise<\n    PageClass extends AbstractPage<Item>,\n    Item = ReturnType<PageClass['getPaginatedItems']>[number],\n  >\n  extends APIPromise<PageClass>\n  implements AsyncIterable<Item>\n{\n  constructor(\n    client: OpenAI,\n    request: Promise<APIResponseProps>,\n    Page: new (...args: ConstructorParameters<typeof AbstractPage>) => PageClass,\n  ) {\n    super(\n      client,\n      request,\n      async (client, props) =>\n        new Page(\n          client,\n          props.response,\n          await defaultParseResponse(client, props),\n          props.options,\n        ) as WithRequestID<PageClass>,\n    );\n  }\n\n  /**\n   * Allow auto-paginating iteration on an unawaited list call, eg:\n   *\n   *    for await (const item of client.items.list()) {\n   *      console.log(item)\n   *    }\n   */\n  async *[Symbol.asyncIterator](): AsyncGenerator<Item> {\n    const page = await this;\n    for await (const item of page) {\n      yield item;\n    }\n  }\n}\n\nexport interface PageResponse<Item> {\n  data: Array<Item>;\n\n  object: string;\n}\n\n/**\n * Note: no pagination actually occurs yet, this is for forwards-compatibility.\n */\nexport class Page<Item> extends AbstractPage<Item> implements PageResponse<Item> {\n  data: Array<Item>;\n\n  object: string;\n\n  constructor(client: OpenAI, response: Response, body: PageResponse<Item>, options: FinalRequestOptions) {\n    super(client, response, body, options);\n\n    this.data = body.data || [];\n    this.object = body.object;\n  }\n\n  getPaginatedItems(): Item[] {\n    return this.data ?? [];\n  }\n\n  nextPageRequestOptions(): PageRequestOptions | null {\n    return null;\n  }\n}\n\nexport interface CursorPageResponse<Item> {\n  data: Array<Item>;\n\n  has_more: boolean;\n}\n\nexport interface CursorPageParams {\n  after?: string;\n\n  limit?: number;\n}\n\nexport class CursorPage<Item extends { id: string }>\n  extends AbstractPage<Item>\n  implements CursorPageResponse<Item>\n{\n  data: Array<Item>;\n\n  has_more: boolean;\n\n  constructor(\n    client: OpenAI,\n    response: Response,\n    body: CursorPageResponse<Item>,\n    options: FinalRequestOptions,\n  ) {\n    super(client, response, body, options);\n\n    this.data = body.data || [];\n    this.has_more = body.has_more || false;\n  }\n\n  getPaginatedItems(): Item[] {\n    return this.data ?? [];\n  }\n\n  override hasNextPage(): boolean {\n    if (this.has_more === false) {\n      return false;\n    }\n\n    return super.hasNextPage();\n  }\n\n  nextPageRequestOptions(): PageRequestOptions | null {\n    const data = this.getPaginatedItems();\n    const id = data[data.length - 1]?.id;\n    if (!id) {\n      return null;\n    }\n\n    return {\n      ...this.options,\n      query: {\n        ...maybeObj(this.options.query),\n        after: id,\n      },\n    };\n  }\n}\n\nexport interface ConversationCursorPageResponse<Item> {\n  data: Array<Item>;\n\n  has_more: boolean;\n\n  last_id: string;\n}\n\nexport interface ConversationCursorPageParams {\n  after?: string;\n\n  limit?: number;\n}\n\nexport class ConversationCursorPage<Item>\n  extends AbstractPage<Item>\n  implements ConversationCursorPageResponse<Item>\n{\n  data: Array<Item>;\n\n  has_more: boolean;\n\n  last_id: string;\n\n  constructor(\n    client: OpenAI,\n    response: Response,\n    body: ConversationCursorPageResponse<Item>,\n    options: FinalRequestOptions,\n  ) {\n    super(client, response, body, options);\n\n    this.data = body.data || [];\n    this.has_more = body.has_more || false;\n    this.last_id = body.last_id || '';\n  }\n\n  getPaginatedItems(): Item[] {\n    return this.data ?? [];\n  }\n\n  override hasNextPage(): boolean {\n    if (this.has_more === false) {\n      return false;\n    }\n\n    return super.hasNextPage();\n  }\n\n  nextPageRequestOptions(): PageRequestOptions | null {\n    const cursor = this.last_id;\n    if (!cursor) {\n      return null;\n    }\n\n    return {\n      ...this.options,\n      query: {\n        ...maybeObj(this.options.query),\n        after: cursor,\n      },\n    };\n  }\n}\n","import { OpenAIError } from '../error';\nimport type OpenAI from '../index';\nimport type { RequestOptions } from '../internal/request-options';\nimport { isAutoParsableTool, parseChatCompletion } from '../lib/parser';\nimport type {\n  ChatCompletion,\n  ChatCompletionCreateParams,\n  ChatCompletionMessage,\n  ChatCompletionMessageFunctionToolCall,\n  ChatCompletionMessageParam,\n  ChatCompletionTool,\n  ParsedChatCompletion,\n} from '../resources/chat/completions';\nimport type { CompletionUsage } from '../resources/completions';\nimport type { ChatCompletionToolRunnerParams } from './ChatCompletionRunner';\nimport type { ChatCompletionStreamingToolRunnerParams } from './ChatCompletionStreamingRunner';\nimport { isAssistantMessage, isToolMessage } from './chatCompletionUtils';\nimport { BaseEvents, EventStream } from './EventStream';\nimport {\n  isRunnableFunctionWithParse,\n  type BaseFunctionsArgs,\n  type RunnableFunction,\n  type RunnableToolFunction,\n} from './RunnableFunction';\n\nconst DEFAULT_MAX_CHAT_COMPLETIONS = 10;\nexport interface RunnerOptions extends RequestOptions {\n  /** How many requests to make before canceling. Default 10. */\n  maxChatCompletions?: number;\n}\n\nexport class AbstractChatCompletionRunner<\n  EventTypes extends AbstractChatCompletionRunnerEvents,\n  ParsedT,\n> extends EventStream<EventTypes> {\n  protected _chatCompletions: ParsedChatCompletion<ParsedT>[] = [];\n  messages: ChatCompletionMessageParam[] = [];\n\n  protected _addChatCompletion(\n    this: AbstractChatCompletionRunner<AbstractChatCompletionRunnerEvents, ParsedT>,\n    chatCompletion: ParsedChatCompletion<ParsedT>,\n  ): ParsedChatCompletion<ParsedT> {\n    this._chatCompletions.push(chatCompletion);\n    this._emit('chatCompletion', chatCompletion);\n    const message = chatCompletion.choices[0]?.message;\n    if (message) this._addMessage(message as ChatCompletionMessageParam);\n    return chatCompletion;\n  }\n\n  protected _addMessage(\n    this: AbstractChatCompletionRunner<AbstractChatCompletionRunnerEvents, ParsedT>,\n    message: ChatCompletionMessageParam,\n    emit = true,\n  ) {\n    if (!('content' in message)) message.content = null;\n\n    this.messages.push(message);\n\n    if (emit) {\n      this._emit('message', message);\n      if (isToolMessage(message) && message.content) {\n        // Note, this assumes that {role: 'tool', content: } is always the result of a call of tool of type=function.\n        this._emit('functionToolCallResult', message.content as string);\n      } else if (isAssistantMessage(message) && message.tool_calls) {\n        for (const tool_call of message.tool_calls) {\n          if (tool_call.type === 'function') {\n            this._emit('functionToolCall', tool_call.function);\n          }\n        }\n      }\n    }\n  }\n\n  /**\n   * @returns a promise that resolves with the final ChatCompletion, or rejects\n   * if an error occurred or the stream ended prematurely without producing a ChatCompletion.\n   */\n  async finalChatCompletion(): Promise<ParsedChatCompletion<ParsedT>> {\n    await this.done();\n    const completion = this._chatCompletions[this._chatCompletions.length - 1];\n    if (!completion) throw new OpenAIError('stream ended without producing a ChatCompletion');\n    return completion;\n  }\n\n  #getFinalContent(): string | null {\n    return this.#getFinalMessage().content ?? null;\n  }\n\n  /**\n   * @returns a promise that resolves with the content of the final ChatCompletionMessage, or rejects\n   * if an error occurred or the stream ended prematurely without producing a ChatCompletionMessage.\n   */\n  async finalContent(): Promise<string | null> {\n    await this.done();\n    return this.#getFinalContent();\n  }\n\n  #getFinalMessage(): ChatCompletionMessage {\n    let i = this.messages.length;\n    while (i-- > 0) {\n      const message = this.messages[i];\n      if (isAssistantMessage(message)) {\n        // TODO: support audio here\n        const ret: Omit<ChatCompletionMessage, 'audio'> = {\n          ...message,\n          content: (message as ChatCompletionMessage).content ?? null,\n          refusal: (message as ChatCompletionMessage).refusal ?? null,\n        };\n        return ret;\n      }\n    }\n    throw new OpenAIError('stream ended without producing a ChatCompletionMessage with role=assistant');\n  }\n\n  /**\n   * @returns a promise that resolves with the the final assistant ChatCompletionMessage response,\n   * or rejects if an error occurred or the stream ended prematurely without producing a ChatCompletionMessage.\n   */\n  async finalMessage(): Promise<ChatCompletionMessage> {\n    await this.done();\n    return this.#getFinalMessage();\n  }\n\n  #getFinalFunctionToolCall(): ChatCompletionMessageFunctionToolCall.Function | undefined {\n    for (let i = this.messages.length - 1; i >= 0; i--) {\n      const message = this.messages[i];\n      if (isAssistantMessage(message) && message?.tool_calls?.length) {\n        return message.tool_calls.filter((x) => x.type === 'function').at(-1)?.function;\n      }\n    }\n\n    return;\n  }\n\n  /**\n   * @returns a promise that resolves with the content of the final FunctionCall, or rejects\n   * if an error occurred or the stream ended prematurely without producing a ChatCompletionMessage.\n   */\n  async finalFunctionToolCall(): Promise<ChatCompletionMessageFunctionToolCall.Function | undefined> {\n    await this.done();\n    return this.#getFinalFunctionToolCall();\n  }\n\n  #getFinalFunctionToolCallResult(): string | undefined {\n    for (let i = this.messages.length - 1; i >= 0; i--) {\n      const message = this.messages[i];\n      if (\n        isToolMessage(message) &&\n        message.content != null &&\n        typeof message.content === 'string' &&\n        this.messages.some(\n          (x) =>\n            x.role === 'assistant' &&\n            x.tool_calls?.some((y) => y.type === 'function' && y.id === message.tool_call_id),\n        )\n      ) {\n        return message.content;\n      }\n    }\n\n    return;\n  }\n\n  async finalFunctionToolCallResult(): Promise<string | undefined> {\n    await this.done();\n    return this.#getFinalFunctionToolCallResult();\n  }\n\n  #calculateTotalUsage(): CompletionUsage {\n    const total: CompletionUsage = {\n      completion_tokens: 0,\n      prompt_tokens: 0,\n      total_tokens: 0,\n    };\n    for (const { usage } of this._chatCompletions) {\n      if (usage) {\n        total.completion_tokens += usage.completion_tokens;\n        total.prompt_tokens += usage.prompt_tokens;\n        total.total_tokens += usage.total_tokens;\n      }\n    }\n    return total;\n  }\n\n  async totalUsage(): Promise<CompletionUsage> {\n    await this.done();\n    return this.#calculateTotalUsage();\n  }\n\n  allChatCompletions(): ChatCompletion[] {\n    return [...this._chatCompletions];\n  }\n\n  protected override _emitFinal(\n    this: AbstractChatCompletionRunner<AbstractChatCompletionRunnerEvents, ParsedT>,\n  ) {\n    const completion = this._chatCompletions[this._chatCompletions.length - 1];\n    if (completion) this._emit('finalChatCompletion', completion);\n    const finalMessage = this.#getFinalMessage();\n    if (finalMessage) this._emit('finalMessage', finalMessage);\n    const finalContent = this.#getFinalContent();\n    if (finalContent) this._emit('finalContent', finalContent);\n\n    const finalFunctionCall = this.#getFinalFunctionToolCall();\n    if (finalFunctionCall) this._emit('finalFunctionToolCall', finalFunctionCall);\n\n    const finalFunctionCallResult = this.#getFinalFunctionToolCallResult();\n    if (finalFunctionCallResult != null) this._emit('finalFunctionToolCallResult', finalFunctionCallResult);\n\n    if (this._chatCompletions.some((c) => c.usage)) {\n      this._emit('totalUsage', this.#calculateTotalUsage());\n    }\n  }\n\n  #validateParams(params: ChatCompletionCreateParams): void {\n    if (params.n != null && params.n > 1) {\n      throw new OpenAIError(\n        'ChatCompletion convenience helpers only support n=1 at this time. To use n>1, please use chat.completions.create() directly.',\n      );\n    }\n  }\n\n  protected async _createChatCompletion(\n    client: OpenAI,\n    params: ChatCompletionCreateParams,\n    options?: RequestOptions,\n  ): Promise<ParsedChatCompletion<ParsedT>> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n    this.#validateParams(params);\n\n    const chatCompletion = await client.chat.completions.create(\n      { ...params, stream: false },\n      { ...options, signal: this.controller.signal },\n    );\n    this._connected();\n    return this._addChatCompletion(parseChatCompletion(chatCompletion, params));\n  }\n\n  protected async _runChatCompletion(\n    client: OpenAI,\n    params: ChatCompletionCreateParams,\n    options?: RequestOptions,\n  ): Promise<ChatCompletion> {\n    for (const message of params.messages) {\n      this._addMessage(message, false);\n    }\n    return await this._createChatCompletion(client, params, options);\n  }\n\n  protected async _runTools<FunctionsArgs extends BaseFunctionsArgs>(\n    client: OpenAI,\n    params:\n      | ChatCompletionToolRunnerParams<FunctionsArgs>\n      | ChatCompletionStreamingToolRunnerParams<FunctionsArgs>,\n    options?: RunnerOptions,\n  ) {\n    const role = 'tool' as const;\n    const { tool_choice = 'auto', stream, ...restParams } = params;\n    const singleFunctionToCall =\n      typeof tool_choice !== 'string' && tool_choice.type === 'function' && tool_choice?.function?.name;\n    const { maxChatCompletions = DEFAULT_MAX_CHAT_COMPLETIONS } = options || {};\n\n    // TODO(someday): clean this logic up\n    const inputTools = params.tools.map((tool): RunnableToolFunction<any> => {\n      if (isAutoParsableTool(tool)) {\n        if (!tool.$callback) {\n          throw new OpenAIError('Tool given to `.runTools()` that does not have an associated function');\n        }\n\n        return {\n          type: 'function',\n          function: {\n            function: tool.$callback,\n            name: tool.function.name,\n            description: tool.function.description || '',\n            parameters: tool.function.parameters as any,\n            parse: tool.$parseRaw,\n            strict: true,\n          },\n        };\n      }\n\n      return tool as any as RunnableToolFunction<any>;\n    });\n\n    const functionsByName: Record<string, RunnableFunction<any>> = {};\n    for (const f of inputTools) {\n      if (f.type === 'function') {\n        functionsByName[f.function.name || f.function.function.name] = f.function;\n      }\n    }\n\n    const tools: ChatCompletionTool[] =\n      'tools' in params ?\n        inputTools.map((t) =>\n          t.type === 'function' ?\n            {\n              type: 'function',\n              function: {\n                name: t.function.name || t.function.function.name,\n                parameters: t.function.parameters as Record<string, unknown>,\n                description: t.function.description,\n                strict: t.function.strict,\n              },\n            }\n          : (t as unknown as ChatCompletionTool),\n        )\n      : (undefined as any);\n\n    for (const message of params.messages) {\n      this._addMessage(message, false);\n    }\n\n    for (let i = 0; i < maxChatCompletions; ++i) {\n      const chatCompletion: ChatCompletion = await this._createChatCompletion(\n        client,\n        {\n          ...restParams,\n          tool_choice,\n          tools,\n          messages: [...this.messages],\n        },\n        options,\n      );\n      const message = chatCompletion.choices[0]?.message;\n      if (!message) {\n        throw new OpenAIError(`missing message in ChatCompletion response`);\n      }\n      if (!message.tool_calls?.length) {\n        return;\n      }\n\n      for (const tool_call of message.tool_calls) {\n        if (tool_call.type !== 'function') continue;\n        const tool_call_id = tool_call.id;\n        const { name, arguments: args } = tool_call.function;\n        const fn = functionsByName[name];\n\n        if (!fn) {\n          const content = `Invalid tool_call: ${JSON.stringify(name)}. Available options are: ${Object.keys(\n            functionsByName,\n          )\n            .map((name) => JSON.stringify(name))\n            .join(', ')}. Please try again`;\n\n          this._addMessage({ role, tool_call_id, content });\n          continue;\n        } else if (singleFunctionToCall && singleFunctionToCall !== name) {\n          const content = `Invalid tool_call: ${JSON.stringify(name)}. ${JSON.stringify(\n            singleFunctionToCall,\n          )} requested. Please try again`;\n\n          this._addMessage({ role, tool_call_id, content });\n          continue;\n        }\n\n        let parsed;\n        try {\n          parsed = isRunnableFunctionWithParse(fn) ? await fn.parse(args) : args;\n        } catch (error) {\n          const content = error instanceof Error ? error.message : String(error);\n          this._addMessage({ role, tool_call_id, content });\n          continue;\n        }\n\n        // @ts-expect-error it can't rule out `never` type.\n        const rawContent = await fn.function(parsed, this);\n        const content = this.#stringifyFunctionCallResult(rawContent);\n        this._addMessage({ role, tool_call_id, content });\n\n        if (singleFunctionToCall) {\n          return;\n        }\n      }\n    }\n\n    return;\n  }\n\n  #stringifyFunctionCallResult(rawContent: unknown): string {\n    return (\n      typeof rawContent === 'string' ? rawContent\n      : rawContent === undefined ? 'undefined'\n      : JSON.stringify(rawContent)\n    );\n  }\n}\n\nexport interface AbstractChatCompletionRunnerEvents extends BaseEvents {\n  functionToolCall: (functionCall: ChatCompletionMessageFunctionToolCall.Function) => void;\n  message: (message: ChatCompletionMessageParam) => void;\n  chatCompletion: (completion: ChatCompletion) => void;\n  finalContent: (contentSnapshot: string) => void;\n  finalMessage: (message: ChatCompletionMessageParam) => void;\n  finalChatCompletion: (completion: ChatCompletion) => void;\n  finalFunctionToolCall: (functionCall: ChatCompletionMessageFunctionToolCall.Function) => void;\n  functionToolCallResult: (content: string) => void;\n  finalFunctionToolCallResult: (content: string) => void;\n  totalUsage: (usage: CompletionUsage) => void;\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport type { RequestInit, RequestInfo, BodyInit } from './internal/builtin-types';\nimport type { HTTPMethod, PromiseOrValue, MergedRequestInit, FinalizedRequestInit } from './internal/types';\nimport { uuid4 } from './internal/utils/uuid';\nimport { validatePositiveInteger, isAbsoluteURL, safeJSON } from './internal/utils/values';\nimport { sleep } from './internal/utils/sleep';\nexport type { Logger, LogLevel } from './internal/utils/log';\nimport { castToError, isAbortError } from './internal/errors';\nimport type { APIResponseProps } from './internal/parse';\nimport { getPlatformHeaders } from './internal/detect-platform';\nimport * as Shims from './internal/shims';\nimport * as Opts from './internal/request-options';\nimport * as qs from './internal/qs';\nimport { VERSION } from './version';\nimport * as Errors from './core/error';\nimport * as Pagination from './core/pagination';\nimport {\n  AbstractPage,\n  type ConversationCursorPageParams,\n  ConversationCursorPageResponse,\n  type CursorPageParams,\n  CursorPageResponse,\n  PageResponse,\n} from './core/pagination';\nimport * as Uploads from './core/uploads';\nimport * as API from './resources/index';\nimport { APIPromise } from './core/api-promise';\nimport {\n  Batch,\n  BatchCreateParams,\n  BatchError,\n  BatchListParams,\n  BatchRequestCounts,\n  BatchUsage,\n  Batches,\n  BatchesPage,\n} from './resources/batches';\nimport {\n  Completion,\n  CompletionChoice,\n  CompletionCreateParams,\n  CompletionCreateParamsNonStreaming,\n  CompletionCreateParamsStreaming,\n  CompletionUsage,\n  Completions,\n} from './resources/completions';\nimport {\n  CreateEmbeddingResponse,\n  Embedding,\n  EmbeddingCreateParams,\n  EmbeddingModel,\n  Embeddings,\n} from './resources/embeddings';\nimport {\n  FileContent,\n  FileCreateParams,\n  FileDeleted,\n  FileListParams,\n  FileObject,\n  FileObjectsPage,\n  FilePurpose,\n  Files,\n} from './resources/files';\nimport {\n  Image,\n  ImageCreateVariationParams,\n  ImageEditCompletedEvent,\n  ImageEditParams,\n  ImageEditParamsNonStreaming,\n  ImageEditParamsStreaming,\n  ImageEditPartialImageEvent,\n  ImageEditStreamEvent,\n  ImageGenCompletedEvent,\n  ImageGenPartialImageEvent,\n  ImageGenStreamEvent,\n  ImageGenerateParams,\n  ImageGenerateParamsNonStreaming,\n  ImageGenerateParamsStreaming,\n  ImageModel,\n  Images,\n  ImagesResponse,\n} from './resources/images';\nimport { Model, ModelDeleted, Models, ModelsPage } from './resources/models';\nimport {\n  Moderation,\n  ModerationCreateParams,\n  ModerationCreateResponse,\n  ModerationImageURLInput,\n  ModerationModel,\n  ModerationMultiModalInput,\n  ModerationTextInput,\n  Moderations,\n} from './resources/moderations';\nimport {\n  Video,\n  VideoCreateError,\n  VideoCreateParams,\n  VideoDeleteResponse,\n  VideoDownloadContentParams,\n  VideoListParams,\n  VideoModel,\n  VideoRemixParams,\n  VideoSeconds,\n  VideoSize,\n  Videos,\n  VideosPage,\n} from './resources/videos';\nimport { Webhooks } from './resources/webhooks';\nimport { Audio, AudioModel, AudioResponseFormat } from './resources/audio/audio';\nimport { Beta } from './resources/beta/beta';\nimport { Chat } from './resources/chat/chat';\nimport {\n  ContainerCreateParams,\n  ContainerCreateResponse,\n  ContainerListParams,\n  ContainerListResponse,\n  ContainerListResponsesPage,\n  ContainerRetrieveResponse,\n  Containers,\n} from './resources/containers/containers';\nimport { Conversations } from './resources/conversations/conversations';\nimport {\n  EvalCreateParams,\n  EvalCreateResponse,\n  EvalCustomDataSourceConfig,\n  EvalDeleteResponse,\n  EvalListParams,\n  EvalListResponse,\n  EvalListResponsesPage,\n  EvalRetrieveResponse,\n  EvalStoredCompletionsDataSourceConfig,\n  EvalUpdateParams,\n  EvalUpdateResponse,\n  Evals,\n} from './resources/evals/evals';\nimport { FineTuning } from './resources/fine-tuning/fine-tuning';\nimport { Graders } from './resources/graders/graders';\nimport { Realtime } from './resources/realtime/realtime';\nimport { Responses } from './resources/responses/responses';\nimport {\n  Upload,\n  UploadCompleteParams,\n  UploadCreateParams,\n  Uploads as UploadsAPIUploads,\n} from './resources/uploads/uploads';\nimport {\n  AutoFileChunkingStrategyParam,\n  FileChunkingStrategy,\n  FileChunkingStrategyParam,\n  OtherFileChunkingStrategyObject,\n  StaticFileChunkingStrategy,\n  StaticFileChunkingStrategyObject,\n  StaticFileChunkingStrategyObjectParam,\n  VectorStore,\n  VectorStoreCreateParams,\n  VectorStoreDeleted,\n  VectorStoreListParams,\n  VectorStoreSearchParams,\n  VectorStoreSearchResponse,\n  VectorStoreSearchResponsesPage,\n  VectorStoreUpdateParams,\n  VectorStores,\n  VectorStoresPage,\n} from './resources/vector-stores/vector-stores';\nimport {\n  ChatCompletion,\n  ChatCompletionAllowedToolChoice,\n  ChatCompletionAllowedTools,\n  ChatCompletionAssistantMessageParam,\n  ChatCompletionAudio,\n  ChatCompletionAudioParam,\n  ChatCompletionChunk,\n  ChatCompletionContentPart,\n  ChatCompletionContentPartImage,\n  ChatCompletionContentPartInputAudio,\n  ChatCompletionContentPartRefusal,\n  ChatCompletionContentPartText,\n  ChatCompletionCreateParams,\n  ChatCompletionCreateParamsNonStreaming,\n  ChatCompletionCreateParamsStreaming,\n  ChatCompletionCustomTool,\n  ChatCompletionDeleted,\n  ChatCompletionDeveloperMessageParam,\n  ChatCompletionFunctionCallOption,\n  ChatCompletionFunctionMessageParam,\n  ChatCompletionFunctionTool,\n  ChatCompletionListParams,\n  ChatCompletionMessage,\n  ChatCompletionMessageCustomToolCall,\n  ChatCompletionMessageFunctionToolCall,\n  ChatCompletionMessageParam,\n  ChatCompletionMessageToolCall,\n  ChatCompletionModality,\n  ChatCompletionNamedToolChoice,\n  ChatCompletionNamedToolChoiceCustom,\n  ChatCompletionPredictionContent,\n  ChatCompletionReasoningEffort,\n  ChatCompletionRole,\n  ChatCompletionStoreMessage,\n  ChatCompletionStreamOptions,\n  ChatCompletionSystemMessageParam,\n  ChatCompletionTokenLogprob,\n  ChatCompletionTool,\n  ChatCompletionToolChoiceOption,\n  ChatCompletionToolMessageParam,\n  ChatCompletionUpdateParams,\n  ChatCompletionUserMessageParam,\n  ChatCompletionsPage,\n} from './resources/chat/completions/completions';\nimport { type Fetch } from './internal/builtin-types';\nimport { isRunningInBrowser } from './internal/detect-platform';\nimport { HeadersLike, NullableHeaders, buildHeaders } from './internal/headers';\nimport { FinalRequestOptions, RequestOptions } from './internal/request-options';\nimport { readEnv } from './internal/utils/env';\nimport {\n  type LogLevel,\n  type Logger,\n  formatRequestDetails,\n  loggerFor,\n  parseLogLevel,\n} from './internal/utils/log';\nimport { isEmptyObj } from './internal/utils/values';\n\nexport type ApiKeySetter = () => Promise<string>;\n\nexport interface ClientOptions {\n  /**\n   * API key used for authentication.\n   *\n   * - Accepts either a static string or an async function that resolves to a string.\n   * - Defaults to process.env['OPENAI_API_KEY'].\n   * - When a function is provided, it is invoked before each request so you can rotate\n   *   or refresh credentials at runtime.\n   * - The function must return a non-empty string; otherwise an OpenAIError is thrown.\n   * - If the function throws, the error is wrapped in an OpenAIError with the original\n   *   error available as `cause`.\n   */\n  apiKey?: string | ApiKeySetter | undefined;\n  /**\n   * Defaults to process.env['OPENAI_ORG_ID'].\n   */\n  organization?: string | null | undefined;\n\n  /**\n   * Defaults to process.env['OPENAI_PROJECT_ID'].\n   */\n  project?: string | null | undefined;\n\n  /**\n   * Defaults to process.env['OPENAI_WEBHOOK_SECRET'].\n   */\n  webhookSecret?: string | null | undefined;\n\n  /**\n   * Override the default base URL for the API, e.g., \"https://api.example.com/v2/\"\n   *\n   * Defaults to process.env['OPENAI_BASE_URL'].\n   */\n  baseURL?: string | null | undefined;\n\n  /**\n   * The maximum amount of time (in milliseconds) that the client should wait for a response\n   * from the server before timing out a single request.\n   *\n   * Note that request timeouts are retried by default, so in a worst-case scenario you may wait\n   * much longer than this timeout before the promise succeeds or fails.\n   *\n   * @unit milliseconds\n   */\n  timeout?: number | undefined;\n  /**\n   * Additional `RequestInit` options to be passed to `fetch` calls.\n   * Properties will be overridden by per-request `fetchOptions`.\n   */\n  fetchOptions?: MergedRequestInit | undefined;\n\n  /**\n   * Specify a custom `fetch` function implementation.\n   *\n   * If not provided, we expect that `fetch` is defined globally.\n   */\n  fetch?: Fetch | undefined;\n\n  /**\n   * The maximum number of times that the client will retry a request in case of a\n   * temporary failure, like a network error or a 5XX error from the server.\n   *\n   * @default 2\n   */\n  maxRetries?: number | undefined;\n\n  /**\n   * Default headers to include with every request to the API.\n   *\n   * These can be removed in individual requests by explicitly setting the\n   * header to `null` in request options.\n   */\n  defaultHeaders?: HeadersLike | undefined;\n\n  /**\n   * Default query parameters to include with every request to the API.\n   *\n   * These can be removed in individual requests by explicitly setting the\n   * param to `undefined` in request options.\n   */\n  defaultQuery?: Record<string, string | undefined> | undefined;\n\n  /**\n   * By default, client-side use of this library is not allowed, as it risks exposing your secret API credentials to attackers.\n   * Only set this option to `true` if you understand the risks and have appropriate mitigations in place.\n   */\n  dangerouslyAllowBrowser?: boolean | undefined;\n\n  /**\n   * Set the log level.\n   *\n   * Defaults to process.env['OPENAI_LOG'] or 'warn' if it isn't set.\n   */\n  logLevel?: LogLevel | undefined;\n\n  /**\n   * Set the logger.\n   *\n   * Defaults to globalThis.console.\n   */\n  logger?: Logger | undefined;\n}\n\n/**\n * API Client for interfacing with the OpenAI API.\n */\nexport class OpenAI {\n  apiKey: string;\n  organization: string | null;\n  project: string | null;\n  webhookSecret: string | null;\n\n  baseURL: string;\n  maxRetries: number;\n  timeout: number;\n  logger: Logger | undefined;\n  logLevel: LogLevel | undefined;\n  fetchOptions: MergedRequestInit | undefined;\n\n  private fetch: Fetch;\n  #encoder: Opts.RequestEncoder;\n  protected idempotencyHeader?: string;\n  protected _options: ClientOptions;\n\n  /**\n   * API Client for interfacing with the OpenAI API.\n   *\n   * @param {string | undefined} [opts.apiKey=process.env['OPENAI_API_KEY'] ?? undefined]\n   * @param {string | null | undefined} [opts.organization=process.env['OPENAI_ORG_ID'] ?? null]\n   * @param {string | null | undefined} [opts.project=process.env['OPENAI_PROJECT_ID'] ?? null]\n   * @param {string | null | undefined} [opts.webhookSecret=process.env['OPENAI_WEBHOOK_SECRET'] ?? null]\n   * @param {string} [opts.baseURL=process.env['OPENAI_BASE_URL'] ?? https://api.openai.com/v1] - Override the default base URL for the API.\n   * @param {number} [opts.timeout=10 minutes] - The maximum amount of time (in milliseconds) the client will wait for a response before timing out.\n   * @param {MergedRequestInit} [opts.fetchOptions] - Additional `RequestInit` options to be passed to `fetch` calls.\n   * @param {Fetch} [opts.fetch] - Specify a custom `fetch` function implementation.\n   * @param {number} [opts.maxRetries=2] - The maximum number of times the client will retry a request.\n   * @param {HeadersLike} opts.defaultHeaders - Default headers to include with every request to the API.\n   * @param {Record<string, string | undefined>} opts.defaultQuery - Default query parameters to include with every request to the API.\n   * @param {boolean} [opts.dangerouslyAllowBrowser=false] - By default, client-side use of this library is not allowed, as it risks exposing your secret API credentials to attackers.\n   */\n  constructor({\n    baseURL = readEnv('OPENAI_BASE_URL'),\n    apiKey = readEnv('OPENAI_API_KEY'),\n    organization = readEnv('OPENAI_ORG_ID') ?? null,\n    project = readEnv('OPENAI_PROJECT_ID') ?? null,\n    webhookSecret = readEnv('OPENAI_WEBHOOK_SECRET') ?? null,\n    ...opts\n  }: ClientOptions = {}) {\n    if (apiKey === undefined) {\n      throw new Errors.OpenAIError(\n        'Missing credentials. Please pass an `apiKey`, or set the `OPENAI_API_KEY` environment variable.',\n      );\n    }\n\n    const options: ClientOptions = {\n      apiKey,\n      organization,\n      project,\n      webhookSecret,\n      ...opts,\n      baseURL: baseURL || `https://api.openai.com/v1`,\n    };\n\n    if (!options.dangerouslyAllowBrowser && isRunningInBrowser()) {\n      throw new Errors.OpenAIError(\n        \"It looks like you're running in a browser-like environment.\\n\\nThis is disabled by default, as it risks exposing your secret API credentials to attackers.\\nIf you understand the risks and have appropriate mitigations in place,\\nyou can set the `dangerouslyAllowBrowser` option to `true`, e.g.,\\n\\nnew OpenAI({ apiKey, dangerouslyAllowBrowser: true });\\n\\nhttps://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety\\n\",\n      );\n    }\n\n    this.baseURL = options.baseURL!;\n    this.timeout = options.timeout ?? OpenAI.DEFAULT_TIMEOUT /* 10 minutes */;\n    this.logger = options.logger ?? console;\n    const defaultLogLevel = 'warn';\n    // Set default logLevel early so that we can log a warning in parseLogLevel.\n    this.logLevel = defaultLogLevel;\n    this.logLevel =\n      parseLogLevel(options.logLevel, 'ClientOptions.logLevel', this) ??\n      parseLogLevel(readEnv('OPENAI_LOG'), \"process.env['OPENAI_LOG']\", this) ??\n      defaultLogLevel;\n    this.fetchOptions = options.fetchOptions;\n    this.maxRetries = options.maxRetries ?? 2;\n    this.fetch = options.fetch ?? Shims.getDefaultFetch();\n    this.#encoder = Opts.FallbackEncoder;\n\n    this._options = options;\n\n    this.apiKey = typeof apiKey === 'string' ? apiKey : 'Missing Key';\n    this.organization = organization;\n    this.project = project;\n    this.webhookSecret = webhookSecret;\n  }\n\n  /**\n   * Create a new client instance re-using the same options given to the current client with optional overriding.\n   */\n  withOptions(options: Partial<ClientOptions>): this {\n    const client = new (this.constructor as any as new (props: ClientOptions) => typeof this)({\n      ...this._options,\n      baseURL: this.baseURL,\n      maxRetries: this.maxRetries,\n      timeout: this.timeout,\n      logger: this.logger,\n      logLevel: this.logLevel,\n      fetch: this.fetch,\n      fetchOptions: this.fetchOptions,\n      apiKey: this.apiKey,\n      organization: this.organization,\n      project: this.project,\n      webhookSecret: this.webhookSecret,\n      ...options,\n    });\n    return client;\n  }\n\n  /**\n   * Check whether the base URL is set to its default.\n   */\n  #baseURLOverridden(): boolean {\n    return this.baseURL !== 'https://api.openai.com/v1';\n  }\n\n  protected defaultQuery(): Record<string, string | undefined> | undefined {\n    return this._options.defaultQuery;\n  }\n\n  protected validateHeaders({ values, nulls }: NullableHeaders) {\n    return;\n  }\n\n  protected async authHeaders(opts: FinalRequestOptions): Promise<NullableHeaders | undefined> {\n    return buildHeaders([{ Authorization: `Bearer ${this.apiKey}` }]);\n  }\n\n  protected stringifyQuery(query: Record<string, unknown>): string {\n    return qs.stringify(query, { arrayFormat: 'brackets' });\n  }\n\n  private getUserAgent(): string {\n    return `${this.constructor.name}/JS ${VERSION}`;\n  }\n\n  protected defaultIdempotencyKey(): string {\n    return `stainless-node-retry-${uuid4()}`;\n  }\n\n  protected makeStatusError(\n    status: number,\n    error: Object,\n    message: string | undefined,\n    headers: Headers,\n  ): Errors.APIError {\n    return Errors.APIError.generate(status, error, message, headers);\n  }\n\n  async _callApiKey(): Promise<boolean> {\n    const apiKey = this._options.apiKey;\n    if (typeof apiKey !== 'function') return false;\n\n    let token: unknown;\n    try {\n      token = await apiKey();\n    } catch (err: any) {\n      if (err instanceof Errors.OpenAIError) throw err;\n      throw new Errors.OpenAIError(\n        `Failed to get token from 'apiKey' function: ${err.message}`,\n        // @ts-ignore\n        { cause: err },\n      );\n    }\n\n    if (typeof token !== 'string' || !token) {\n      throw new Errors.OpenAIError(\n        `Expected 'apiKey' function argument to return a string but it returned ${token}`,\n      );\n    }\n    this.apiKey = token;\n    return true;\n  }\n\n  buildURL(\n    path: string,\n    query: Record<string, unknown> | null | undefined,\n    defaultBaseURL?: string | undefined,\n  ): string {\n    const baseURL = (!this.#baseURLOverridden() && defaultBaseURL) || this.baseURL;\n    const url =\n      isAbsoluteURL(path) ?\n        new URL(path)\n      : new URL(baseURL + (baseURL.endsWith('/') && path.startsWith('/') ? path.slice(1) : path));\n\n    const defaultQuery = this.defaultQuery();\n    if (!isEmptyObj(defaultQuery)) {\n      query = { ...defaultQuery, ...query };\n    }\n\n    if (typeof query === 'object' && query && !Array.isArray(query)) {\n      url.search = this.stringifyQuery(query as Record<string, unknown>);\n    }\n\n    return url.toString();\n  }\n\n  /**\n   * Used as a callback for mutating the given `FinalRequestOptions` object.\n   */\n  protected async prepareOptions(options: FinalRequestOptions): Promise<void> {\n    await this._callApiKey();\n  }\n\n  /**\n   * Used as a callback for mutating the given `RequestInit` object.\n   *\n   * This is useful for cases where you want to add certain headers based off of\n   * the request properties, e.g. `method` or `url`.\n   */\n  protected async prepareRequest(\n    request: RequestInit,\n    { url, options }: { url: string; options: FinalRequestOptions },\n  ): Promise<void> {}\n\n  get<Rsp>(path: string, opts?: PromiseOrValue<RequestOptions>): APIPromise<Rsp> {\n    return this.methodRequest('get', path, opts);\n  }\n\n  post<Rsp>(path: string, opts?: PromiseOrValue<RequestOptions>): APIPromise<Rsp> {\n    return this.methodRequest('post', path, opts);\n  }\n\n  patch<Rsp>(path: string, opts?: PromiseOrValue<RequestOptions>): APIPromise<Rsp> {\n    return this.methodRequest('patch', path, opts);\n  }\n\n  put<Rsp>(path: string, opts?: PromiseOrValue<RequestOptions>): APIPromise<Rsp> {\n    return this.methodRequest('put', path, opts);\n  }\n\n  delete<Rsp>(path: string, opts?: PromiseOrValue<RequestOptions>): APIPromise<Rsp> {\n    return this.methodRequest('delete', path, opts);\n  }\n\n  private methodRequest<Rsp>(\n    method: HTTPMethod,\n    path: string,\n    opts?: PromiseOrValue<RequestOptions>,\n  ): APIPromise<Rsp> {\n    return this.request(\n      Promise.resolve(opts).then((opts) => {\n        return { method, path, ...opts };\n      }),\n    );\n  }\n\n  request<Rsp>(\n    options: PromiseOrValue<FinalRequestOptions>,\n    remainingRetries: number | null = null,\n  ): APIPromise<Rsp> {\n    return new APIPromise(this, this.makeRequest(options, remainingRetries, undefined));\n  }\n\n  private async makeRequest(\n    optionsInput: PromiseOrValue<FinalRequestOptions>,\n    retriesRemaining: number | null,\n    retryOfRequestLogID: string | undefined,\n  ): Promise<APIResponseProps> {\n    const options = await optionsInput;\n    const maxRetries = options.maxRetries ?? this.maxRetries;\n    if (retriesRemaining == null) {\n      retriesRemaining = maxRetries;\n    }\n\n    await this.prepareOptions(options);\n\n    const { req, url, timeout } = await this.buildRequest(options, {\n      retryCount: maxRetries - retriesRemaining,\n    });\n\n    await this.prepareRequest(req, { url, options });\n\n    /** Not an API request ID, just for correlating local log entries. */\n    const requestLogID = 'log_' + ((Math.random() * (1 << 24)) | 0).toString(16).padStart(6, '0');\n    const retryLogStr = retryOfRequestLogID === undefined ? '' : `, retryOf: ${retryOfRequestLogID}`;\n    const startTime = Date.now();\n\n    loggerFor(this).debug(\n      `[${requestLogID}] sending request`,\n      formatRequestDetails({\n        retryOfRequestLogID,\n        method: options.method,\n        url,\n        options,\n        headers: req.headers,\n      }),\n    );\n\n    if (options.signal?.aborted) {\n      throw new Errors.APIUserAbortError();\n    }\n\n    const controller = new AbortController();\n    const response = await this.fetchWithTimeout(url, req, timeout, controller).catch(castToError);\n    const headersTime = Date.now();\n\n    if (response instanceof globalThis.Error) {\n      const retryMessage = `retrying, ${retriesRemaining} attempts remaining`;\n      if (options.signal?.aborted) {\n        throw new Errors.APIUserAbortError();\n      }\n      // detect native connection timeout errors\n      // deno throws \"TypeError: error sending request for url (https://example/): client error (Connect): tcp connect error: Operation timed out (os error 60): Operation timed out (os error 60)\"\n      // undici throws \"TypeError: fetch failed\" with cause \"ConnectTimeoutError: Connect Timeout Error (attempted address: example:443, timeout: 1ms)\"\n      // others do not provide enough information to distinguish timeouts from other connection errors\n      const isTimeout =\n        isAbortError(response) ||\n        /timed? ?out/i.test(String(response) + ('cause' in response ? String(response.cause) : ''));\n      if (retriesRemaining) {\n        loggerFor(this).info(\n          `[${requestLogID}] connection ${isTimeout ? 'timed out' : 'failed'} - ${retryMessage}`,\n        );\n        loggerFor(this).debug(\n          `[${requestLogID}] connection ${isTimeout ? 'timed out' : 'failed'} (${retryMessage})`,\n          formatRequestDetails({\n            retryOfRequestLogID,\n            url,\n            durationMs: headersTime - startTime,\n            message: response.message,\n          }),\n        );\n        return this.retryRequest(options, retriesRemaining, retryOfRequestLogID ?? requestLogID);\n      }\n      loggerFor(this).info(\n        `[${requestLogID}] connection ${isTimeout ? 'timed out' : 'failed'} - error; no more retries left`,\n      );\n      loggerFor(this).debug(\n        `[${requestLogID}] connection ${isTimeout ? 'timed out' : 'failed'} (error; no more retries left)`,\n        formatRequestDetails({\n          retryOfRequestLogID,\n          url,\n          durationMs: headersTime - startTime,\n          message: response.message,\n        }),\n      );\n      if (isTimeout) {\n        throw new Errors.APIConnectionTimeoutError();\n      }\n      throw new Errors.APIConnectionError({ cause: response });\n    }\n\n    const specialHeaders = [...response.headers.entries()]\n      .filter(([name]) => name === 'x-request-id')\n      .map(([name, value]) => ', ' + name + ': ' + JSON.stringify(value))\n      .join('');\n    const responseInfo = `[${requestLogID}${retryLogStr}${specialHeaders}] ${req.method} ${url} ${\n      response.ok ? 'succeeded' : 'failed'\n    } with status ${response.status} in ${headersTime - startTime}ms`;\n\n    if (!response.ok) {\n      const shouldRetry = await this.shouldRetry(response);\n      if (retriesRemaining && shouldRetry) {\n        const retryMessage = `retrying, ${retriesRemaining} attempts remaining`;\n\n        // We don't need the body of this response.\n        await Shims.CancelReadableStream(response.body);\n        loggerFor(this).info(`${responseInfo} - ${retryMessage}`);\n        loggerFor(this).debug(\n          `[${requestLogID}] response error (${retryMessage})`,\n          formatRequestDetails({\n            retryOfRequestLogID,\n            url: response.url,\n            status: response.status,\n            headers: response.headers,\n            durationMs: headersTime - startTime,\n          }),\n        );\n        return this.retryRequest(\n          options,\n          retriesRemaining,\n          retryOfRequestLogID ?? requestLogID,\n          response.headers,\n        );\n      }\n\n      const retryMessage = shouldRetry ? `error; no more retries left` : `error; not retryable`;\n\n      loggerFor(this).info(`${responseInfo} - ${retryMessage}`);\n\n      const errText = await response.text().catch((err: any) => castToError(err).message);\n      const errJSON = safeJSON(errText);\n      const errMessage = errJSON ? undefined : errText;\n\n      loggerFor(this).debug(\n        `[${requestLogID}] response error (${retryMessage})`,\n        formatRequestDetails({\n          retryOfRequestLogID,\n          url: response.url,\n          status: response.status,\n          headers: response.headers,\n          message: errMessage,\n          durationMs: Date.now() - startTime,\n        }),\n      );\n\n      const err = this.makeStatusError(response.status, errJSON, errMessage, response.headers);\n      throw err;\n    }\n\n    loggerFor(this).info(responseInfo);\n    loggerFor(this).debug(\n      `[${requestLogID}] response start`,\n      formatRequestDetails({\n        retryOfRequestLogID,\n        url: response.url,\n        status: response.status,\n        headers: response.headers,\n        durationMs: headersTime - startTime,\n      }),\n    );\n\n    return { response, options, controller, requestLogID, retryOfRequestLogID, startTime };\n  }\n\n  getAPIList<Item, PageClass extends Pagination.AbstractPage<Item> = Pagination.AbstractPage<Item>>(\n    path: string,\n    Page: new (...args: any[]) => PageClass,\n    opts?: RequestOptions,\n  ): Pagination.PagePromise<PageClass, Item> {\n    return this.requestAPIList(Page, { method: 'get', path, ...opts });\n  }\n\n  requestAPIList<\n    Item = unknown,\n    PageClass extends Pagination.AbstractPage<Item> = Pagination.AbstractPage<Item>,\n  >(\n    Page: new (...args: ConstructorParameters<typeof Pagination.AbstractPage>) => PageClass,\n    options: FinalRequestOptions,\n  ): Pagination.PagePromise<PageClass, Item> {\n    const request = this.makeRequest(options, null, undefined);\n    return new Pagination.PagePromise<PageClass, Item>(this as any as OpenAI, request, Page);\n  }\n\n  async fetchWithTimeout(\n    url: RequestInfo,\n    init: RequestInit | undefined,\n    ms: number,\n    controller: AbortController,\n  ): Promise<Response> {\n    const { signal, method, ...options } = init || {};\n    if (signal) signal.addEventListener('abort', () => controller.abort());\n\n    const timeout = setTimeout(() => controller.abort(), ms);\n\n    const isReadableBody =\n      ((globalThis as any).ReadableStream && options.body instanceof (globalThis as any).ReadableStream) ||\n      (typeof options.body === 'object' && options.body !== null && Symbol.asyncIterator in options.body);\n\n    const fetchOptions: RequestInit = {\n      signal: controller.signal as any,\n      ...(isReadableBody ? { duplex: 'half' } : {}),\n      method: 'GET',\n      ...options,\n    };\n    if (method) {\n      // Custom methods like 'patch' need to be uppercased\n      // See https://github.com/nodejs/undici/issues/2294\n      fetchOptions.method = method.toUpperCase();\n    }\n\n    try {\n      // use undefined this binding; fetch errors if bound to something else in browser/cloudflare\n      return await this.fetch.call(undefined, url, fetchOptions);\n    } finally {\n      clearTimeout(timeout);\n    }\n  }\n\n  private async shouldRetry(response: Response): Promise<boolean> {\n    // Note this is not a standard header.\n    const shouldRetryHeader = response.headers.get('x-should-retry');\n\n    // If the server explicitly says whether or not to retry, obey.\n    if (shouldRetryHeader === 'true') return true;\n    if (shouldRetryHeader === 'false') return false;\n\n    // Retry on request timeouts.\n    if (response.status === 408) return true;\n\n    // Retry on lock timeouts.\n    if (response.status === 409) return true;\n\n    // Retry on rate limits.\n    if (response.status === 429) return true;\n\n    // Retry internal errors.\n    if (response.status >= 500) return true;\n\n    return false;\n  }\n\n  private async retryRequest(\n    options: FinalRequestOptions,\n    retriesRemaining: number,\n    requestLogID: string,\n    responseHeaders?: Headers | undefined,\n  ): Promise<APIResponseProps> {\n    let timeoutMillis: number | undefined;\n\n    // Note the `retry-after-ms` header may not be standard, but is a good idea and we'd like proactive support for it.\n    const retryAfterMillisHeader = responseHeaders?.get('retry-after-ms');\n    if (retryAfterMillisHeader) {\n      const timeoutMs = parseFloat(retryAfterMillisHeader);\n      if (!Number.isNaN(timeoutMs)) {\n        timeoutMillis = timeoutMs;\n      }\n    }\n\n    // About the Retry-After header: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Retry-After\n    const retryAfterHeader = responseHeaders?.get('retry-after');\n    if (retryAfterHeader && !timeoutMillis) {\n      const timeoutSeconds = parseFloat(retryAfterHeader);\n      if (!Number.isNaN(timeoutSeconds)) {\n        timeoutMillis = timeoutSeconds * 1000;\n      } else {\n        timeoutMillis = Date.parse(retryAfterHeader) - Date.now();\n      }\n    }\n\n    // If the API asks us to wait a certain amount of time (and it's a reasonable amount),\n    // just do what it says, but otherwise calculate a default\n    if (!(timeoutMillis && 0 <= timeoutMillis && timeoutMillis < 60 * 1000)) {\n      const maxRetries = options.maxRetries ?? this.maxRetries;\n      timeoutMillis = this.calculateDefaultRetryTimeoutMillis(retriesRemaining, maxRetries);\n    }\n    await sleep(timeoutMillis);\n\n    return this.makeRequest(options, retriesRemaining - 1, requestLogID);\n  }\n\n  private calculateDefaultRetryTimeoutMillis(retriesRemaining: number, maxRetries: number): number {\n    const initialRetryDelay = 0.5;\n    const maxRetryDelay = 8.0;\n\n    const numRetries = maxRetries - retriesRemaining;\n\n    // Apply exponential backoff, but not more than the max.\n    const sleepSeconds = Math.min(initialRetryDelay * Math.pow(2, numRetries), maxRetryDelay);\n\n    // Apply some jitter, take up to at most 25 percent of the retry time.\n    const jitter = 1 - Math.random() * 0.25;\n\n    return sleepSeconds * jitter * 1000;\n  }\n\n  async buildRequest(\n    inputOptions: FinalRequestOptions,\n    { retryCount = 0 }: { retryCount?: number } = {},\n  ): Promise<{ req: FinalizedRequestInit; url: string; timeout: number }> {\n    const options = { ...inputOptions };\n    const { method, path, query, defaultBaseURL } = options;\n\n    const url = this.buildURL(path!, query as Record<string, unknown>, defaultBaseURL);\n    if ('timeout' in options) validatePositiveInteger('timeout', options.timeout);\n    options.timeout = options.timeout ?? this.timeout;\n    const { bodyHeaders, body } = this.buildBody({ options });\n    const reqHeaders = await this.buildHeaders({ options: inputOptions, method, bodyHeaders, retryCount });\n\n    const req: FinalizedRequestInit = {\n      method,\n      headers: reqHeaders,\n      ...(options.signal && { signal: options.signal }),\n      ...((globalThis as any).ReadableStream &&\n        body instanceof (globalThis as any).ReadableStream && { duplex: 'half' }),\n      ...(body && { body }),\n      ...((this.fetchOptions as any) ?? {}),\n      ...((options.fetchOptions as any) ?? {}),\n    };\n\n    return { req, url, timeout: options.timeout };\n  }\n\n  private async buildHeaders({\n    options,\n    method,\n    bodyHeaders,\n    retryCount,\n  }: {\n    options: FinalRequestOptions;\n    method: HTTPMethod;\n    bodyHeaders: HeadersLike;\n    retryCount: number;\n  }): Promise<Headers> {\n    let idempotencyHeaders: HeadersLike = {};\n    if (this.idempotencyHeader && method !== 'get') {\n      if (!options.idempotencyKey) options.idempotencyKey = this.defaultIdempotencyKey();\n      idempotencyHeaders[this.idempotencyHeader] = options.idempotencyKey;\n    }\n\n    const headers = buildHeaders([\n      idempotencyHeaders,\n      {\n        Accept: 'application/json',\n        'User-Agent': this.getUserAgent(),\n        'X-Stainless-Retry-Count': String(retryCount),\n        ...(options.timeout ? { 'X-Stainless-Timeout': String(Math.trunc(options.timeout / 1000)) } : {}),\n        ...getPlatformHeaders(),\n        'OpenAI-Organization': this.organization,\n        'OpenAI-Project': this.project,\n      },\n      await this.authHeaders(options),\n      this._options.defaultHeaders,\n      bodyHeaders,\n      options.headers,\n    ]);\n\n    this.validateHeaders(headers);\n\n    return headers.values;\n  }\n\n  private buildBody({ options: { body, headers: rawHeaders } }: { options: FinalRequestOptions }): {\n    bodyHeaders: HeadersLike;\n    body: BodyInit | undefined;\n  } {\n    if (!body) {\n      return { bodyHeaders: undefined, body: undefined };\n    }\n    const headers = buildHeaders([rawHeaders]);\n    if (\n      // Pass raw type verbatim\n      ArrayBuffer.isView(body) ||\n      body instanceof ArrayBuffer ||\n      body instanceof DataView ||\n      (typeof body === 'string' &&\n        // Preserve legacy string encoding behavior for now\n        headers.values.has('content-type')) ||\n      // `Blob` is superset of `File`\n      ((globalThis as any).Blob && body instanceof (globalThis as any).Blob) ||\n      // `FormData` -> `multipart/form-data`\n      body instanceof FormData ||\n      // `URLSearchParams` -> `application/x-www-form-urlencoded`\n      body instanceof URLSearchParams ||\n      // Send chunked stream (each chunk has own `length`)\n      ((globalThis as any).ReadableStream && body instanceof (globalThis as any).ReadableStream)\n    ) {\n      return { bodyHeaders: undefined, body: body as BodyInit };\n    } else if (\n      typeof body === 'object' &&\n      (Symbol.asyncIterator in body ||\n        (Symbol.iterator in body && 'next' in body && typeof body.next === 'function'))\n    ) {\n      return { bodyHeaders: undefined, body: Shims.ReadableStreamFrom(body as AsyncIterable<Uint8Array>) };\n    } else {\n      return this.#encoder({ body, headers });\n    }\n  }\n\n  static OpenAI = this;\n  static DEFAULT_TIMEOUT = 600000; // 10 minutes\n\n  static OpenAIError = Errors.OpenAIError;\n  static APIError = Errors.APIError;\n  static APIConnectionError = Errors.APIConnectionError;\n  static APIConnectionTimeoutError = Errors.APIConnectionTimeoutError;\n  static APIUserAbortError = Errors.APIUserAbortError;\n  static NotFoundError = Errors.NotFoundError;\n  static ConflictError = Errors.ConflictError;\n  static RateLimitError = Errors.RateLimitError;\n  static BadRequestError = Errors.BadRequestError;\n  static AuthenticationError = Errors.AuthenticationError;\n  static InternalServerError = Errors.InternalServerError;\n  static PermissionDeniedError = Errors.PermissionDeniedError;\n  static UnprocessableEntityError = Errors.UnprocessableEntityError;\n  static InvalidWebhookSignatureError = Errors.InvalidWebhookSignatureError;\n\n  static toFile = Uploads.toFile;\n\n  completions: API.Completions = new API.Completions(this);\n  chat: API.Chat = new API.Chat(this);\n  embeddings: API.Embeddings = new API.Embeddings(this);\n  files: API.Files = new API.Files(this);\n  images: API.Images = new API.Images(this);\n  audio: API.Audio = new API.Audio(this);\n  moderations: API.Moderations = new API.Moderations(this);\n  models: API.Models = new API.Models(this);\n  fineTuning: API.FineTuning = new API.FineTuning(this);\n  graders: API.Graders = new API.Graders(this);\n  vectorStores: API.VectorStores = new API.VectorStores(this);\n  webhooks: API.Webhooks = new API.Webhooks(this);\n  beta: API.Beta = new API.Beta(this);\n  batches: API.Batches = new API.Batches(this);\n  uploads: API.Uploads = new API.Uploads(this);\n  responses: API.Responses = new API.Responses(this);\n  realtime: API.Realtime = new API.Realtime(this);\n  conversations: API.Conversations = new API.Conversations(this);\n  evals: API.Evals = new API.Evals(this);\n  containers: API.Containers = new API.Containers(this);\n  videos: API.Videos = new API.Videos(this);\n}\n\nOpenAI.Completions = Completions;\nOpenAI.Chat = Chat;\nOpenAI.Embeddings = Embeddings;\nOpenAI.Files = Files;\nOpenAI.Images = Images;\nOpenAI.Audio = Audio;\nOpenAI.Moderations = Moderations;\nOpenAI.Models = Models;\nOpenAI.FineTuning = FineTuning;\nOpenAI.Graders = Graders;\nOpenAI.VectorStores = VectorStores;\nOpenAI.Webhooks = Webhooks;\nOpenAI.Beta = Beta;\nOpenAI.Batches = Batches;\nOpenAI.Uploads = UploadsAPIUploads;\nOpenAI.Responses = Responses;\nOpenAI.Realtime = Realtime;\nOpenAI.Conversations = Conversations;\nOpenAI.Evals = Evals;\nOpenAI.Containers = Containers;\nOpenAI.Videos = Videos;\n\nexport declare namespace OpenAI {\n  export type RequestOptions = Opts.RequestOptions;\n\n  export import Page = Pagination.Page;\n  export { type PageResponse as PageResponse };\n\n  export import CursorPage = Pagination.CursorPage;\n  export { type CursorPageParams as CursorPageParams, type CursorPageResponse as CursorPageResponse };\n\n  export import ConversationCursorPage = Pagination.ConversationCursorPage;\n  export {\n    type ConversationCursorPageParams as ConversationCursorPageParams,\n    type ConversationCursorPageResponse as ConversationCursorPageResponse,\n  };\n\n  export {\n    Completions as Completions,\n    type Completion as Completion,\n    type CompletionChoice as CompletionChoice,\n    type CompletionUsage as CompletionUsage,\n    type CompletionCreateParams as CompletionCreateParams,\n    type CompletionCreateParamsNonStreaming as CompletionCreateParamsNonStreaming,\n    type CompletionCreateParamsStreaming as CompletionCreateParamsStreaming,\n  };\n\n  export {\n    Chat as Chat,\n    type ChatCompletion as ChatCompletion,\n    type ChatCompletionAllowedToolChoice as ChatCompletionAllowedToolChoice,\n    type ChatCompletionAssistantMessageParam as ChatCompletionAssistantMessageParam,\n    type ChatCompletionAudio as ChatCompletionAudio,\n    type ChatCompletionAudioParam as ChatCompletionAudioParam,\n    type ChatCompletionChunk as ChatCompletionChunk,\n    type ChatCompletionContentPart as ChatCompletionContentPart,\n    type ChatCompletionContentPartImage as ChatCompletionContentPartImage,\n    type ChatCompletionContentPartInputAudio as ChatCompletionContentPartInputAudio,\n    type ChatCompletionContentPartRefusal as ChatCompletionContentPartRefusal,\n    type ChatCompletionContentPartText as ChatCompletionContentPartText,\n    type ChatCompletionCustomTool as ChatCompletionCustomTool,\n    type ChatCompletionDeleted as ChatCompletionDeleted,\n    type ChatCompletionDeveloperMessageParam as ChatCompletionDeveloperMessageParam,\n    type ChatCompletionFunctionCallOption as ChatCompletionFunctionCallOption,\n    type ChatCompletionFunctionMessageParam as ChatCompletionFunctionMessageParam,\n    type ChatCompletionFunctionTool as ChatCompletionFunctionTool,\n    type ChatCompletionMessage as ChatCompletionMessage,\n    type ChatCompletionMessageCustomToolCall as ChatCompletionMessageCustomToolCall,\n    type ChatCompletionMessageFunctionToolCall as ChatCompletionMessageFunctionToolCall,\n    type ChatCompletionMessageParam as ChatCompletionMessageParam,\n    type ChatCompletionMessageToolCall as ChatCompletionMessageToolCall,\n    type ChatCompletionModality as ChatCompletionModality,\n    type ChatCompletionNamedToolChoice as ChatCompletionNamedToolChoice,\n    type ChatCompletionNamedToolChoiceCustom as ChatCompletionNamedToolChoiceCustom,\n    type ChatCompletionPredictionContent as ChatCompletionPredictionContent,\n    type ChatCompletionRole as ChatCompletionRole,\n    type ChatCompletionStoreMessage as ChatCompletionStoreMessage,\n    type ChatCompletionStreamOptions as ChatCompletionStreamOptions,\n    type ChatCompletionSystemMessageParam as ChatCompletionSystemMessageParam,\n    type ChatCompletionTokenLogprob as ChatCompletionTokenLogprob,\n    type ChatCompletionTool as ChatCompletionTool,\n    type ChatCompletionToolChoiceOption as ChatCompletionToolChoiceOption,\n    type ChatCompletionToolMessageParam as ChatCompletionToolMessageParam,\n    type ChatCompletionUserMessageParam as ChatCompletionUserMessageParam,\n    type ChatCompletionAllowedTools as ChatCompletionAllowedTools,\n    type ChatCompletionReasoningEffort as ChatCompletionReasoningEffort,\n    type ChatCompletionsPage as ChatCompletionsPage,\n    type ChatCompletionCreateParams as ChatCompletionCreateParams,\n    type ChatCompletionCreateParamsNonStreaming as ChatCompletionCreateParamsNonStreaming,\n    type ChatCompletionCreateParamsStreaming as ChatCompletionCreateParamsStreaming,\n    type ChatCompletionUpdateParams as ChatCompletionUpdateParams,\n    type ChatCompletionListParams as ChatCompletionListParams,\n  };\n\n  export {\n    Embeddings as Embeddings,\n    type CreateEmbeddingResponse as CreateEmbeddingResponse,\n    type Embedding as Embedding,\n    type EmbeddingModel as EmbeddingModel,\n    type EmbeddingCreateParams as EmbeddingCreateParams,\n  };\n\n  export {\n    Files as Files,\n    type FileContent as FileContent,\n    type FileDeleted as FileDeleted,\n    type FileObject as FileObject,\n    type FilePurpose as FilePurpose,\n    type FileObjectsPage as FileObjectsPage,\n    type FileCreateParams as FileCreateParams,\n    type FileListParams as FileListParams,\n  };\n\n  export {\n    Images as Images,\n    type Image as Image,\n    type ImageEditCompletedEvent as ImageEditCompletedEvent,\n    type ImageEditPartialImageEvent as ImageEditPartialImageEvent,\n    type ImageEditStreamEvent as ImageEditStreamEvent,\n    type ImageGenCompletedEvent as ImageGenCompletedEvent,\n    type ImageGenPartialImageEvent as ImageGenPartialImageEvent,\n    type ImageGenStreamEvent as ImageGenStreamEvent,\n    type ImageModel as ImageModel,\n    type ImagesResponse as ImagesResponse,\n    type ImageCreateVariationParams as ImageCreateVariationParams,\n    type ImageEditParams as ImageEditParams,\n    type ImageEditParamsNonStreaming as ImageEditParamsNonStreaming,\n    type ImageEditParamsStreaming as ImageEditParamsStreaming,\n    type ImageGenerateParams as ImageGenerateParams,\n    type ImageGenerateParamsNonStreaming as ImageGenerateParamsNonStreaming,\n    type ImageGenerateParamsStreaming as ImageGenerateParamsStreaming,\n  };\n\n  export { Audio as Audio, type AudioModel as AudioModel, type AudioResponseFormat as AudioResponseFormat };\n\n  export {\n    Moderations as Moderations,\n    type Moderation as Moderation,\n    type ModerationImageURLInput as ModerationImageURLInput,\n    type ModerationModel as ModerationModel,\n    type ModerationMultiModalInput as ModerationMultiModalInput,\n    type ModerationTextInput as ModerationTextInput,\n    type ModerationCreateResponse as ModerationCreateResponse,\n    type ModerationCreateParams as ModerationCreateParams,\n  };\n\n  export {\n    Models as Models,\n    type Model as Model,\n    type ModelDeleted as ModelDeleted,\n    type ModelsPage as ModelsPage,\n  };\n\n  export { FineTuning as FineTuning };\n\n  export { Graders as Graders };\n\n  export {\n    VectorStores as VectorStores,\n    type AutoFileChunkingStrategyParam as AutoFileChunkingStrategyParam,\n    type FileChunkingStrategy as FileChunkingStrategy,\n    type FileChunkingStrategyParam as FileChunkingStrategyParam,\n    type OtherFileChunkingStrategyObject as OtherFileChunkingStrategyObject,\n    type StaticFileChunkingStrategy as StaticFileChunkingStrategy,\n    type StaticFileChunkingStrategyObject as StaticFileChunkingStrategyObject,\n    type StaticFileChunkingStrategyObjectParam as StaticFileChunkingStrategyObjectParam,\n    type VectorStore as VectorStore,\n    type VectorStoreDeleted as VectorStoreDeleted,\n    type VectorStoreSearchResponse as VectorStoreSearchResponse,\n    type VectorStoresPage as VectorStoresPage,\n    type VectorStoreSearchResponsesPage as VectorStoreSearchResponsesPage,\n    type VectorStoreCreateParams as VectorStoreCreateParams,\n    type VectorStoreUpdateParams as VectorStoreUpdateParams,\n    type VectorStoreListParams as VectorStoreListParams,\n    type VectorStoreSearchParams as VectorStoreSearchParams,\n  };\n\n  export { Webhooks as Webhooks };\n\n  export { Beta as Beta };\n\n  export {\n    Batches as Batches,\n    type Batch as Batch,\n    type BatchError as BatchError,\n    type BatchRequestCounts as BatchRequestCounts,\n    type BatchUsage as BatchUsage,\n    type BatchesPage as BatchesPage,\n    type BatchCreateParams as BatchCreateParams,\n    type BatchListParams as BatchListParams,\n  };\n\n  export {\n    UploadsAPIUploads as Uploads,\n    type Upload as Upload,\n    type UploadCreateParams as UploadCreateParams,\n    type UploadCompleteParams as UploadCompleteParams,\n  };\n\n  export { Responses as Responses };\n\n  export { Realtime as Realtime };\n\n  export { Conversations as Conversations };\n\n  export {\n    Evals as Evals,\n    type EvalCustomDataSourceConfig as EvalCustomDataSourceConfig,\n    type EvalStoredCompletionsDataSourceConfig as EvalStoredCompletionsDataSourceConfig,\n    type EvalCreateResponse as EvalCreateResponse,\n    type EvalRetrieveResponse as EvalRetrieveResponse,\n    type EvalUpdateResponse as EvalUpdateResponse,\n    type EvalListResponse as EvalListResponse,\n    type EvalDeleteResponse as EvalDeleteResponse,\n    type EvalListResponsesPage as EvalListResponsesPage,\n    type EvalCreateParams as EvalCreateParams,\n    type EvalUpdateParams as EvalUpdateParams,\n    type EvalListParams as EvalListParams,\n  };\n\n  export {\n    Containers as Containers,\n    type ContainerCreateResponse as ContainerCreateResponse,\n    type ContainerRetrieveResponse as ContainerRetrieveResponse,\n    type ContainerListResponse as ContainerListResponse,\n    type ContainerListResponsesPage as ContainerListResponsesPage,\n    type ContainerCreateParams as ContainerCreateParams,\n    type ContainerListParams as ContainerListParams,\n  };\n\n  export {\n    Videos as Videos,\n    type Video as Video,\n    type VideoCreateError as VideoCreateError,\n    type VideoModel as VideoModel,\n    type VideoSeconds as VideoSeconds,\n    type VideoSize as VideoSize,\n    type VideoDeleteResponse as VideoDeleteResponse,\n    type VideosPage as VideosPage,\n    type VideoCreateParams as VideoCreateParams,\n    type VideoListParams as VideoListParams,\n    type VideoDownloadContentParams as VideoDownloadContentParams,\n    type VideoRemixParams as VideoRemixParams,\n  };\n\n  export type AllModels = API.AllModels;\n  export type ChatModel = API.ChatModel;\n  export type ComparisonFilter = API.ComparisonFilter;\n  export type CompoundFilter = API.CompoundFilter;\n  export type CustomToolInputFormat = API.CustomToolInputFormat;\n  export type ErrorObject = API.ErrorObject;\n  export type FunctionDefinition = API.FunctionDefinition;\n  export type FunctionParameters = API.FunctionParameters;\n  export type Metadata = API.Metadata;\n  export type Reasoning = API.Reasoning;\n  export type ReasoningEffort = API.ReasoningEffort;\n  export type ResponseFormatJSONObject = API.ResponseFormatJSONObject;\n  export type ResponseFormatJSONSchema = API.ResponseFormatJSONSchema;\n  export type ResponseFormatText = API.ResponseFormatText;\n  export type ResponseFormatTextGrammar = API.ResponseFormatTextGrammar;\n  export type ResponseFormatTextPython = API.ResponseFormatTextPython;\n  export type ResponsesModel = API.ResponsesModel;\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nexport * from './chat/index';\nexport * from './shared';\nexport { Audio, type AudioModel, type AudioResponseFormat } from './audio/audio';\nexport {\n  Batches,\n  type Batch,\n  type BatchError,\n  type BatchRequestCounts,\n  type BatchUsage,\n  type BatchCreateParams,\n  type BatchListParams,\n  type BatchesPage,\n} from './batches';\nexport { Beta } from './beta/beta';\nexport {\n  Completions,\n  type Completion,\n  type CompletionChoice,\n  type CompletionUsage,\n  type CompletionCreateParams,\n  type CompletionCreateParamsNonStreaming,\n  type CompletionCreateParamsStreaming,\n} from './completions';\nexport {\n  Containers,\n  type ContainerCreateResponse,\n  type ContainerRetrieveResponse,\n  type ContainerListResponse,\n  type ContainerCreateParams,\n  type ContainerListParams,\n  type ContainerListResponsesPage,\n} from './containers/containers';\nexport { Conversations } from './conversations/conversations';\nexport {\n  Embeddings,\n  type CreateEmbeddingResponse,\n  type Embedding,\n  type EmbeddingModel,\n  type EmbeddingCreateParams,\n} from './embeddings';\nexport {\n  Evals,\n  type EvalCustomDataSourceConfig,\n  type EvalStoredCompletionsDataSourceConfig,\n  type EvalCreateResponse,\n  type EvalRetrieveResponse,\n  type EvalUpdateResponse,\n  type EvalListResponse,\n  type EvalDeleteResponse,\n  type EvalCreateParams,\n  type EvalUpdateParams,\n  type EvalListParams,\n  type EvalListResponsesPage,\n} from './evals/evals';\nexport {\n  Files,\n  type FileContent,\n  type FileDeleted,\n  type FileObject,\n  type FilePurpose,\n  type FileCreateParams,\n  type FileListParams,\n  type FileObjectsPage,\n} from './files';\nexport { FineTuning } from './fine-tuning/fine-tuning';\nexport { Graders } from './graders/graders';\nexport {\n  Images,\n  type Image,\n  type ImageEditCompletedEvent,\n  type ImageEditPartialImageEvent,\n  type ImageEditStreamEvent,\n  type ImageGenCompletedEvent,\n  type ImageGenPartialImageEvent,\n  type ImageGenStreamEvent,\n  type ImageModel,\n  type ImagesResponse,\n  type ImageCreateVariationParams,\n  type ImageEditParams,\n  type ImageEditParamsNonStreaming,\n  type ImageEditParamsStreaming,\n  type ImageGenerateParams,\n  type ImageGenerateParamsNonStreaming,\n  type ImageGenerateParamsStreaming,\n} from './images';\nexport { Models, type Model, type ModelDeleted, type ModelsPage } from './models';\nexport {\n  Moderations,\n  type Moderation,\n  type ModerationImageURLInput,\n  type ModerationModel,\n  type ModerationMultiModalInput,\n  type ModerationTextInput,\n  type ModerationCreateResponse,\n  type ModerationCreateParams,\n} from './moderations';\nexport { Realtime } from './realtime/realtime';\nexport { Responses } from './responses/responses';\nexport { Uploads, type Upload, type UploadCreateParams, type UploadCompleteParams } from './uploads/uploads';\nexport {\n  VectorStores,\n  type AutoFileChunkingStrategyParam,\n  type FileChunkingStrategy,\n  type FileChunkingStrategyParam,\n  type OtherFileChunkingStrategyObject,\n  type StaticFileChunkingStrategy,\n  type StaticFileChunkingStrategyObject,\n  type StaticFileChunkingStrategyObjectParam,\n  type VectorStore,\n  type VectorStoreDeleted,\n  type VectorStoreSearchResponse,\n  type VectorStoreCreateParams,\n  type VectorStoreUpdateParams,\n  type VectorStoreListParams,\n  type VectorStoreSearchParams,\n  type VectorStoresPage,\n  type VectorStoreSearchResponsesPage,\n} from './vector-stores/vector-stores';\nexport {\n  Videos,\n  type Video,\n  type VideoCreateError,\n  type VideoModel,\n  type VideoSeconds,\n  type VideoSize,\n  type VideoDeleteResponse,\n  type VideoCreateParams,\n  type VideoListParams,\n  type VideoDownloadContentParams,\n  type VideoRemixParams,\n  type VideosPage,\n} from './videos';\nexport { Webhooks } from './webhooks';\n","import {\n  ResponseTextConfig,\n  type ParsedResponse,\n  type Response,\n  type ResponseCreateParamsBase,\n  type ResponseCreateParamsStreaming,\n  type ResponseStreamEvent,\n} from '../../resources/responses/responses';\nimport { RequestOptions } from '../../internal/request-options';\nimport { APIUserAbortError, OpenAIError } from '../../error';\nimport OpenAI from '../../index';\nimport { type BaseEvents, EventStream } from '../EventStream';\nimport { type ResponseFunctionCallArgumentsDeltaEvent, type ResponseTextDeltaEvent } from './EventTypes';\nimport { maybeParseResponse, ParseableToolsParams } from '../ResponsesParser';\nimport { Stream } from '../../streaming';\n\nexport type ResponseStreamParams = ResponseCreateAndStreamParams | ResponseStreamByIdParams;\n\nexport type ResponseCreateAndStreamParams = Omit<ResponseCreateParamsBase, 'stream'> & {\n  stream?: true;\n};\n\nexport type ResponseStreamByIdParams = {\n  /**\n   * The ID of the response to stream.\n   */\n  response_id: string;\n  /**\n   * If provided, the stream will start after the event with the given sequence number.\n   */\n  starting_after?: number;\n  /**\n   * Configuration options for a text response from the model. Can be plain text or\n   * structured JSON data. Learn more:\n   *\n   * - [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n   * - [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n   */\n  text?: ResponseTextConfig;\n\n  /**\n   * An array of tools the model may call while generating a response. When continuing a stream, provide\n   * the same tools as the original request.\n   */\n  tools?: ParseableToolsParams;\n};\n\ntype ResponseEvents = BaseEvents &\n  Omit<\n    {\n      [K in ResponseStreamEvent['type']]: (event: Extract<ResponseStreamEvent, { type: K }>) => void;\n    },\n    'response.output_text.delta' | 'response.function_call_arguments.delta'\n  > & {\n    event: (event: ResponseStreamEvent) => void;\n    'response.output_text.delta': (event: ResponseTextDeltaEvent) => void;\n    'response.function_call_arguments.delta': (event: ResponseFunctionCallArgumentsDeltaEvent) => void;\n  };\n\nexport type ResponseStreamingParams = Omit<ResponseCreateParamsBase, 'stream'> & {\n  stream?: true;\n};\n\nexport class ResponseStream<ParsedT = null>\n  extends EventStream<ResponseEvents>\n  implements AsyncIterable<ResponseStreamEvent>\n{\n  #params: ResponseStreamingParams | null;\n  #currentResponseSnapshot: Response | undefined;\n  #finalResponse: ParsedResponse<ParsedT> | undefined;\n\n  constructor(params: ResponseStreamingParams | null) {\n    super();\n    this.#params = params;\n  }\n\n  static createResponse<ParsedT>(\n    client: OpenAI,\n    params: ResponseStreamParams,\n    options?: RequestOptions,\n  ): ResponseStream<ParsedT> {\n    const runner = new ResponseStream<ParsedT>(params as ResponseCreateParamsStreaming);\n    runner._run(() =>\n      runner._createOrRetrieveResponse(client, params, {\n        ...options,\n        headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' },\n      }),\n    );\n    return runner;\n  }\n\n  #beginRequest() {\n    if (this.ended) return;\n    this.#currentResponseSnapshot = undefined;\n  }\n\n  #addEvent(this: ResponseStream<ParsedT>, event: ResponseStreamEvent, starting_after: number | null) {\n    if (this.ended) return;\n\n    const maybeEmit = (name: string, event: ResponseStreamEvent & { snapshot?: string }) => {\n      if (starting_after == null || event.sequence_number > starting_after) {\n        this._emit(name as any, event);\n      }\n    };\n\n    const response = this.#accumulateResponse(event);\n    maybeEmit('event', event);\n\n    switch (event.type) {\n      case 'response.output_text.delta': {\n        const output = response.output[event.output_index];\n        if (!output) {\n          throw new OpenAIError(`missing output at index ${event.output_index}`);\n        }\n        if (output.type === 'message') {\n          const content = output.content[event.content_index];\n          if (!content) {\n            throw new OpenAIError(`missing content at index ${event.content_index}`);\n          }\n          if (content.type !== 'output_text') {\n            throw new OpenAIError(`expected content to be 'output_text', got ${content.type}`);\n          }\n\n          maybeEmit('response.output_text.delta', {\n            ...event,\n            snapshot: content.text,\n          });\n        }\n        break;\n      }\n      case 'response.function_call_arguments.delta': {\n        const output = response.output[event.output_index];\n        if (!output) {\n          throw new OpenAIError(`missing output at index ${event.output_index}`);\n        }\n        if (output.type === 'function_call') {\n          maybeEmit('response.function_call_arguments.delta', {\n            ...event,\n            snapshot: output.arguments,\n          });\n        }\n        break;\n      }\n      default:\n        maybeEmit(event.type, event);\n        break;\n    }\n  }\n\n  #endRequest(): ParsedResponse<ParsedT> {\n    if (this.ended) {\n      throw new OpenAIError(`stream has ended, this shouldn't happen`);\n    }\n    const snapshot = this.#currentResponseSnapshot;\n    if (!snapshot) {\n      throw new OpenAIError(`request ended without sending any events`);\n    }\n    this.#currentResponseSnapshot = undefined;\n    const parsedResponse = finalizeResponse<ParsedT>(snapshot, this.#params);\n    this.#finalResponse = parsedResponse;\n\n    return parsedResponse;\n  }\n\n  protected async _createOrRetrieveResponse(\n    client: OpenAI,\n    params: ResponseStreamParams,\n    options?: RequestOptions,\n  ): Promise<ParsedResponse<ParsedT>> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n    this.#beginRequest();\n\n    let stream: Stream<ResponseStreamEvent> | undefined;\n    let starting_after: number | null = null;\n    if ('response_id' in params) {\n      stream = await client.responses.retrieve(\n        params.response_id,\n        { stream: true },\n        { ...options, signal: this.controller.signal, stream: true },\n      );\n      starting_after = params.starting_after ?? null;\n    } else {\n      stream = await client.responses.create(\n        { ...params, stream: true },\n        { ...options, signal: this.controller.signal },\n      );\n    }\n\n    this._connected();\n    for await (const event of stream) {\n      this.#addEvent(event, starting_after);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n    return this.#endRequest();\n  }\n\n  #accumulateResponse(event: ResponseStreamEvent): Response {\n    let snapshot = this.#currentResponseSnapshot;\n    if (!snapshot) {\n      if (event.type !== 'response.created') {\n        throw new OpenAIError(\n          `When snapshot hasn't been set yet, expected 'response.created' event, got ${event.type}`,\n        );\n      }\n      snapshot = this.#currentResponseSnapshot = event.response;\n      return snapshot;\n    }\n\n    switch (event.type) {\n      case 'response.output_item.added': {\n        snapshot.output.push(event.item);\n        break;\n      }\n      case 'response.content_part.added': {\n        const output = snapshot.output[event.output_index];\n        if (!output) {\n          throw new OpenAIError(`missing output at index ${event.output_index}`);\n        }\n        const type = output.type;\n        const part = event.part;\n        if (type === 'message' && part.type !== 'reasoning_text') {\n          output.content.push(part);\n        } else if (type === 'reasoning' && part.type === 'reasoning_text') {\n          if (!output.content) {\n            output.content = [];\n          }\n          output.content.push(part);\n        }\n        break;\n      }\n      case 'response.output_text.delta': {\n        const output = snapshot.output[event.output_index];\n        if (!output) {\n          throw new OpenAIError(`missing output at index ${event.output_index}`);\n        }\n        if (output.type === 'message') {\n          const content = output.content[event.content_index];\n          if (!content) {\n            throw new OpenAIError(`missing content at index ${event.content_index}`);\n          }\n          if (content.type !== 'output_text') {\n            throw new OpenAIError(`expected content to be 'output_text', got ${content.type}`);\n          }\n          content.text += event.delta;\n        }\n        break;\n      }\n      case 'response.function_call_arguments.delta': {\n        const output = snapshot.output[event.output_index];\n        if (!output) {\n          throw new OpenAIError(`missing output at index ${event.output_index}`);\n        }\n        if (output.type === 'function_call') {\n          output.arguments += event.delta;\n        }\n        break;\n      }\n      case 'response.reasoning_text.delta': {\n        const output = snapshot.output[event.output_index];\n        if (!output) {\n          throw new OpenAIError(`missing output at index ${event.output_index}`);\n        }\n        if (output.type === 'reasoning') {\n          const content = output.content?.[event.content_index];\n          if (!content) {\n            throw new OpenAIError(`missing content at index ${event.content_index}`);\n          }\n          if (content.type !== 'reasoning_text') {\n            throw new OpenAIError(`expected content to be 'reasoning_text', got ${content.type}`);\n          }\n          content.text += event.delta;\n        }\n        break;\n      }\n      case 'response.completed': {\n        this.#currentResponseSnapshot = event.response;\n        break;\n      }\n    }\n\n    return snapshot;\n  }\n\n  [Symbol.asyncIterator](this: ResponseStream<ParsedT>): AsyncIterator<ResponseStreamEvent> {\n    const pushQueue: ResponseStreamEvent[] = [];\n    const readQueue: {\n      resolve: (event: ResponseStreamEvent | undefined) => void;\n      reject: (err: unknown) => void;\n    }[] = [];\n    let done = false;\n\n    this.on('event', (event) => {\n      const reader = readQueue.shift();\n      if (reader) {\n        reader.resolve(event);\n      } else {\n        pushQueue.push(event);\n      }\n    });\n\n    this.on('end', () => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.resolve(undefined);\n      }\n      readQueue.length = 0;\n    });\n\n    this.on('abort', (err) => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.reject(err);\n      }\n      readQueue.length = 0;\n    });\n\n    this.on('error', (err) => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.reject(err);\n      }\n      readQueue.length = 0;\n    });\n\n    return {\n      next: async (): Promise<IteratorResult<ResponseStreamEvent>> => {\n        if (!pushQueue.length) {\n          if (done) {\n            return { value: undefined, done: true };\n          }\n          return new Promise<ResponseStreamEvent | undefined>((resolve, reject) =>\n            readQueue.push({ resolve, reject }),\n          ).then((event) => (event ? { value: event, done: false } : { value: undefined, done: true }));\n        }\n        const event = pushQueue.shift()!;\n        return { value: event, done: false };\n      },\n      return: async () => {\n        this.abort();\n        return { value: undefined, done: true };\n      },\n    };\n  }\n\n  /**\n   * @returns a promise that resolves with the final Response, or rejects\n   * if an error occurred or the stream ended prematurely without producing a REsponse.\n   */\n  async finalResponse(): Promise<ParsedResponse<ParsedT>> {\n    await this.done();\n    const response = this.#finalResponse;\n    if (!response) throw new OpenAIError('stream ended without producing a ChatCompletion');\n    return response;\n  }\n}\n\nfunction finalizeResponse<ParsedT>(\n  snapshot: Response,\n  params: ResponseStreamingParams | null,\n): ParsedResponse<ParsedT> {\n  return maybeParseResponse(snapshot, params);\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\n/**\n * Read an environment variable.\n *\n * Trims beginning and trailing whitespace.\n *\n * Will return undefined if the environment variable doesn't exist or cannot be accessed.\n */\nexport const readEnv = (env: string): string | undefined => {\n  if (typeof (globalThis as any).process !== 'undefined') {\n    return (globalThis as any).process.env?.[env]?.trim() ?? undefined;\n  }\n  if (typeof (globalThis as any).Deno !== 'undefined') {\n    return (globalThis as any).Deno.env?.get?.(env)?.trim();\n  }\n  return undefined;\n};\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { type OpenAI } from '../client';\n\nimport { type PromiseOrValue } from '../internal/types';\nimport {\n  type APIResponseProps,\n  defaultParseResponse,\n  type WithRequestID,\n  addRequestID,\n} from '../internal/parse';\n\n/**\n * A subclass of `Promise` providing additional helper methods\n * for interacting with the SDK.\n */\nexport class APIPromise<T> extends Promise<WithRequestID<T>> {\n  private parsedPromise: Promise<WithRequestID<T>> | undefined;\n  #client: OpenAI;\n\n  constructor(\n    client: OpenAI,\n    private responsePromise: Promise<APIResponseProps>,\n    private parseResponse: (\n      client: OpenAI,\n      props: APIResponseProps,\n    ) => PromiseOrValue<WithRequestID<T>> = defaultParseResponse,\n  ) {\n    super((resolve) => {\n      // this is maybe a bit weird but this has to be a no-op to not implicitly\n      // parse the response body; instead .then, .catch, .finally are overridden\n      // to parse the response\n      resolve(null as any);\n    });\n    this.#client = client;\n  }\n\n  _thenUnwrap<U>(transform: (data: T, props: APIResponseProps) => U): APIPromise<U> {\n    return new APIPromise(this.#client, this.responsePromise, async (client, props) =>\n      addRequestID(transform(await this.parseResponse(client, props), props), props.response),\n    );\n  }\n\n  /**\n   * Gets the raw `Response` instance instead of parsing the response\n   * data.\n   *\n   * If you want to parse the response body but still get the `Response`\n   * instance, you can use {@link withResponse()}.\n   *\n   *  Getting the wrong TypeScript type for `Response`?\n   * Try setting `\"moduleResolution\": \"NodeNext\"` or add `\"lib\": [\"DOM\"]`\n   * to your `tsconfig.json`.\n   */\n  asResponse(): Promise<Response> {\n    return this.responsePromise.then((p) => p.response);\n  }\n\n  /**\n   * Gets the parsed response data, the raw `Response` instance and the ID of the request,\n   * returned via the X-Request-ID header which is useful for debugging requests and reporting\n   * issues to OpenAI.\n   *\n   * If you just want to get the raw `Response` instance without parsing it,\n   * you can use {@link asResponse()}.\n   *\n   *  Getting the wrong TypeScript type for `Response`?\n   * Try setting `\"moduleResolution\": \"NodeNext\"` or add `\"lib\": [\"DOM\"]`\n   * to your `tsconfig.json`.\n   */\n  async withResponse(): Promise<{ data: T; response: Response; request_id: string | null }> {\n    const [data, response] = await Promise.all([this.parse(), this.asResponse()]);\n    return { data, response, request_id: response.headers.get('x-request-id') };\n  }\n\n  private parse(): Promise<WithRequestID<T>> {\n    if (!this.parsedPromise) {\n      this.parsedPromise = this.responsePromise.then((data) =>\n        this.parseResponse(this.#client, data),\n      ) as any as Promise<WithRequestID<T>>;\n    }\n    return this.parsedPromise;\n  }\n\n  override then<TResult1 = WithRequestID<T>, TResult2 = never>(\n    onfulfilled?: ((value: WithRequestID<T>) => TResult1 | PromiseLike<TResult1>) | undefined | null,\n    onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null,\n  ): Promise<TResult1 | TResult2> {\n    return this.parse().then(onfulfilled, onrejected);\n  }\n\n  override catch<TResult = never>(\n    onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | undefined | null,\n  ): Promise<WithRequestID<T> | TResult> {\n    return this.parse().catch(onrejected);\n  }\n\n  override finally(onfinally?: (() => void) | undefined | null): Promise<WithRequestID<T>> {\n    return this.parse().finally(onfinally);\n  }\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\nimport {HttpOptions} from './types.js';\n\nlet _defaultBaseGeminiUrl: string | undefined = undefined;\nlet _defaultBaseVertexUrl: string | undefined = undefined;\n\n/**\n * Parameters for setting the base URLs for the Gemini API and Vertex AI API.\n */\nexport interface BaseUrlParameters {\n  geminiUrl?: string;\n  vertexUrl?: string;\n}\n\n/**\n * Overrides the base URLs for the Gemini API and Vertex AI API.\n *\n * @remarks This function should be called before initializing the SDK. If the\n * base URLs are set after initializing the SDK, the base URLs will not be\n * updated. Base URLs provided in the HttpOptions will also take precedence over\n * URLs set here.\n *\n * @example\n * ```ts\n * import {GoogleGenAI, setDefaultBaseUrls} from '@google/genai';\n * // Override the base URL for the Gemini API.\n * setDefaultBaseUrls({geminiUrl:'https://gemini.google.com'});\n *\n * // Override the base URL for the Vertex AI API.\n * setDefaultBaseUrls({vertexUrl: 'https://vertexai.googleapis.com'});\n *\n * const ai = new GoogleGenAI({apiKey: 'GEMINI_API_KEY'});\n * ```\n */\nexport function setDefaultBaseUrls(baseUrlParams: BaseUrlParameters) {\n  _defaultBaseGeminiUrl = baseUrlParams.geminiUrl;\n  _defaultBaseVertexUrl = baseUrlParams.vertexUrl;\n}\n\n/**\n * Returns the default base URLs for the Gemini API and Vertex AI API.\n */\nexport function getDefaultBaseUrls(): BaseUrlParameters {\n  return {\n    geminiUrl: _defaultBaseGeminiUrl,\n    vertexUrl: _defaultBaseVertexUrl,\n  };\n}\n\n/**\n * Returns the default base URL based on the following priority:\n *   1. Base URLs set via HttpOptions.\n *   2. Base URLs set via the latest call to setDefaultBaseUrls.\n *   3. Base URLs set via environment variables.\n */\nexport function getBaseUrl(\n  httpOptions: HttpOptions | undefined,\n  vertexai: boolean | undefined,\n  vertexBaseUrlFromEnv: string | undefined,\n  geminiBaseUrlFromEnv: string | undefined,\n): string | undefined {\n  if (!httpOptions?.baseUrl) {\n    const defaultBaseUrls = getDefaultBaseUrls();\n    if (vertexai) {\n      return defaultBaseUrls.vertexUrl ?? vertexBaseUrlFromEnv;\n    } else {\n      return defaultBaseUrls.geminiUrl ?? geminiBaseUrlFromEnv;\n    }\n  }\n\n  return httpOptions.baseUrl;\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\nexport class BaseModule {}\n\nexport function formatMap(\n  templateString: string,\n  valueMap: Record<string, unknown>,\n): string {\n  // Use a regular expression to find all placeholders in the template string\n  const regex = /\\{([^}]+)\\}/g;\n\n  // Replace each placeholder with its corresponding value from the valueMap\n  return templateString.replace(regex, (match, key) => {\n    if (Object.prototype.hasOwnProperty.call(valueMap, key)) {\n      const value = valueMap[key];\n      // Convert the value to a string if it's not a string already\n      return value !== undefined && value !== null ? String(value) : '';\n    } else {\n      // Handle missing keys\n      throw new Error(`Key '${key}' not found in valueMap.`);\n    }\n  });\n}\n\nexport function setValueByPath(\n  data: Record<string, unknown>,\n  keys: string[],\n  value: unknown,\n): void {\n  for (let i = 0; i < keys.length - 1; i++) {\n    const key = keys[i];\n\n    if (key.endsWith('[]')) {\n      const keyName = key.slice(0, -2);\n      if (!(keyName in data)) {\n        if (Array.isArray(value)) {\n          data[keyName] = Array.from({length: value.length}, () => ({}));\n        } else {\n          throw new Error(`Value must be a list given an array path ${key}`);\n        }\n      }\n\n      if (Array.isArray(data[keyName])) {\n        const arrayData = data[keyName] as Array<unknown>;\n\n        if (Array.isArray(value)) {\n          for (let j = 0; j < arrayData.length; j++) {\n            const entry = arrayData[j] as Record<string, unknown>;\n            setValueByPath(entry, keys.slice(i + 1), value[j]);\n          }\n        } else {\n          for (const d of arrayData) {\n            setValueByPath(\n              d as Record<string, unknown>,\n              keys.slice(i + 1),\n              value,\n            );\n          }\n        }\n      }\n      return;\n    } else if (key.endsWith('[0]')) {\n      const keyName = key.slice(0, -3);\n      if (!(keyName in data)) {\n        data[keyName] = [{}];\n      }\n      const arrayData = (data as Record<string, unknown>)[keyName];\n      setValueByPath(\n        (arrayData as Array<Record<string, unknown>>)[0],\n        keys.slice(i + 1),\n        value,\n      );\n      return;\n    }\n\n    if (!data[key] || typeof data[key] !== 'object') {\n      data[key] = {};\n    }\n\n    data = data[key] as Record<string, unknown>;\n  }\n\n  const keyToSet = keys[keys.length - 1];\n  const existingData = data[keyToSet];\n\n  if (existingData !== undefined) {\n    if (\n      !value ||\n      (typeof value === 'object' && Object.keys(value).length === 0)\n    ) {\n      return;\n    }\n\n    if (value === existingData) {\n      return;\n    }\n\n    if (\n      typeof existingData === 'object' &&\n      typeof value === 'object' &&\n      existingData !== null &&\n      value !== null\n    ) {\n      Object.assign(existingData, value);\n    } else {\n      throw new Error(`Cannot set value for an existing key. Key: ${keyToSet}`);\n    }\n  } else {\n    if (\n      keyToSet === '_self' &&\n      typeof value === 'object' &&\n      value !== null &&\n      !Array.isArray(value)\n    ) {\n      const valueAsRecord = value as Record<string, unknown>;\n\n      Object.assign(data, valueAsRecord);\n    } else {\n      data[keyToSet] = value;\n    }\n  }\n}\n\nexport function getValueByPath(\n  data: unknown,\n  keys: string[],\n  defaultValue: unknown = undefined,\n): unknown {\n  try {\n    if (keys.length === 1 && keys[0] === '_self') {\n      return data;\n    }\n\n    for (let i = 0; i < keys.length; i++) {\n      if (typeof data !== 'object' || data === null) {\n        return defaultValue;\n      }\n\n      const key = keys[i];\n      if (key.endsWith('[]')) {\n        const keyName = key.slice(0, -2);\n        if (keyName in data) {\n          const arrayData = (data as Record<string, unknown>)[keyName];\n          if (!Array.isArray(arrayData)) {\n            return defaultValue;\n          }\n          return arrayData.map((d) =>\n            getValueByPath(d, keys.slice(i + 1), defaultValue),\n          );\n        } else {\n          return defaultValue;\n        }\n      } else {\n        data = (data as Record<string, unknown>)[key];\n      }\n    }\n\n    return data;\n  } catch (error) {\n    if (error instanceof TypeError) {\n      return defaultValue;\n    }\n    throw error;\n  }\n}\n\n/**\n * Moves values from source paths to destination paths.\n *\n * Examples:\n *   moveValueByPath(\n *     {'requests': [{'content': v1}, {'content': v2}]},\n *     {'requests[].*': 'requests[].request.*'}\n *   )\n *     -> {'requests': [{'request': {'content': v1}}, {'request': {'content': v2}}]}\n */\nexport function moveValueByPath(\n  data: unknown,\n  paths: Record<string, string>,\n): void {\n  for (const [sourcePath, destPath] of Object.entries(paths)) {\n    const sourceKeys = sourcePath.split('.');\n    const destKeys = destPath.split('.');\n\n    // Determine keys to exclude from wildcard to avoid cyclic references\n    const excludeKeys = new Set<string>();\n    let wildcardIdx = -1;\n    for (let i = 0; i < sourceKeys.length; i++) {\n      if (sourceKeys[i] === '*') {\n        wildcardIdx = i;\n        break;\n      }\n    }\n\n    if (wildcardIdx !== -1 && destKeys.length > wildcardIdx) {\n      // Extract the intermediate key between source and dest paths\n      // Example: source=['requests[]', '*'], dest=['requests[]', 'request', '*']\n      // We want to exclude 'request'\n      for (let i = wildcardIdx; i < destKeys.length; i++) {\n        const key = destKeys[i];\n        if (key !== '*' && !key.endsWith('[]') && !key.endsWith('[0]')) {\n          excludeKeys.add(key);\n        }\n      }\n    }\n\n    _moveValueRecursive(data, sourceKeys, destKeys, 0, excludeKeys);\n  }\n}\n\n/**\n * Recursively moves values from source path to destination path.\n */\nfunction _moveValueRecursive(\n  data: unknown,\n  sourceKeys: string[],\n  destKeys: string[],\n  keyIdx: number,\n  excludeKeys: Set<string>,\n): void {\n  if (keyIdx >= sourceKeys.length) {\n    return;\n  }\n\n  if (typeof data !== 'object' || data === null) {\n    return;\n  }\n\n  const key = sourceKeys[keyIdx];\n\n  if (key.endsWith('[]')) {\n    const keyName = key.slice(0, -2);\n    const dataRecord = data as Record<string, unknown>;\n    if (keyName in dataRecord && Array.isArray(dataRecord[keyName])) {\n      for (const item of dataRecord[keyName] as Array<unknown>) {\n        _moveValueRecursive(\n          item,\n          sourceKeys,\n          destKeys,\n          keyIdx + 1,\n          excludeKeys,\n        );\n      }\n    }\n  } else if (key === '*') {\n    // wildcard - move all fields\n    if (typeof data === 'object' && data !== null && !Array.isArray(data)) {\n      const dataRecord = data as Record<string, unknown>;\n      const keysToMove = Object.keys(dataRecord).filter(\n        (k) => !k.startsWith('_') && !excludeKeys.has(k),\n      );\n\n      const valuesToMove: Record<string, unknown> = {};\n      for (const k of keysToMove) {\n        valuesToMove[k] = dataRecord[k];\n      }\n\n      // Set values at destination\n      for (const [k, v] of Object.entries(valuesToMove)) {\n        const newDestKeys: string[] = [];\n        for (const dk of destKeys.slice(keyIdx)) {\n          if (dk === '*') {\n            newDestKeys.push(k);\n          } else {\n            newDestKeys.push(dk);\n          }\n        }\n        setValueByPath(dataRecord, newDestKeys, v);\n      }\n\n      for (const k of keysToMove) {\n        delete dataRecord[k];\n      }\n    }\n  } else {\n    // Navigate to next level\n    const dataRecord = data as Record<string, unknown>;\n    if (key in dataRecord) {\n      _moveValueRecursive(\n        dataRecord[key],\n        sourceKeys,\n        destKeys,\n        keyIdx + 1,\n        excludeKeys,\n      );\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\nexport function tBytes(fromBytes: string | unknown): string {\n  if (typeof fromBytes !== 'string') {\n    throw new Error('fromImageBytes must be a string');\n  }\n  // TODO(b/389133914): Remove dummy bytes converter.\n  return fromBytes;\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\n// Code generated by the Google Gen AI SDK generator DO NOT EDIT.\n\nimport * as t from '../_base_transformers.js';\nimport * as common from '../_common.js';\nimport type * as types from '../types.js';\n\nexport function fetchPredictOperationParametersToMldev(\n  fromObject: types.FetchPredictOperationParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  if (common.getValueByPath(fromObject, ['operationName']) !== undefined) {\n    throw new Error('operationName parameter is not supported in Gemini API.');\n  }\n\n  if (common.getValueByPath(fromObject, ['resourceName']) !== undefined) {\n    throw new Error('resourceName parameter is not supported in Gemini API.');\n  }\n\n  if (common.getValueByPath(fromObject, ['config']) !== undefined) {\n    throw new Error('config parameter is not supported in Gemini API.');\n  }\n\n  return toObject;\n}\n\nexport function fetchPredictOperationParametersToVertex(\n  fromObject: types.FetchPredictOperationParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromOperationName = common.getValueByPath(fromObject, [\n    'operationName',\n  ]);\n  if (fromOperationName != null) {\n    common.setValueByPath(toObject, ['operationName'], fromOperationName);\n  }\n\n  const fromResourceName = common.getValueByPath(fromObject, ['resourceName']);\n  if (fromResourceName != null) {\n    common.setValueByPath(toObject, ['_url', 'resourceName'], fromResourceName);\n  }\n\n  return toObject;\n}\n\nexport function generateVideosOperationFromMldev(\n  fromObject: types.GenerateVideosOperation,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(toObject, ['name'], fromName);\n  }\n\n  const fromMetadata = common.getValueByPath(fromObject, ['metadata']);\n  if (fromMetadata != null) {\n    common.setValueByPath(toObject, ['metadata'], fromMetadata);\n  }\n\n  const fromDone = common.getValueByPath(fromObject, ['done']);\n  if (fromDone != null) {\n    common.setValueByPath(toObject, ['done'], fromDone);\n  }\n\n  const fromError = common.getValueByPath(fromObject, ['error']);\n  if (fromError != null) {\n    common.setValueByPath(toObject, ['error'], fromError);\n  }\n\n  const fromResponse = common.getValueByPath(fromObject, [\n    'response',\n    'generateVideoResponse',\n  ]);\n  if (fromResponse != null) {\n    common.setValueByPath(\n      toObject,\n      ['response'],\n      generateVideosResponseFromMldev(fromResponse),\n    );\n  }\n\n  return toObject;\n}\n\nexport function generateVideosOperationFromVertex(\n  fromObject: types.GenerateVideosOperation,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(toObject, ['name'], fromName);\n  }\n\n  const fromMetadata = common.getValueByPath(fromObject, ['metadata']);\n  if (fromMetadata != null) {\n    common.setValueByPath(toObject, ['metadata'], fromMetadata);\n  }\n\n  const fromDone = common.getValueByPath(fromObject, ['done']);\n  if (fromDone != null) {\n    common.setValueByPath(toObject, ['done'], fromDone);\n  }\n\n  const fromError = common.getValueByPath(fromObject, ['error']);\n  if (fromError != null) {\n    common.setValueByPath(toObject, ['error'], fromError);\n  }\n\n  const fromResponse = common.getValueByPath(fromObject, ['response']);\n  if (fromResponse != null) {\n    common.setValueByPath(\n      toObject,\n      ['response'],\n      generateVideosResponseFromVertex(fromResponse),\n    );\n  }\n\n  return toObject;\n}\n\nexport function generateVideosResponseFromMldev(\n  fromObject: types.GenerateVideosResponse,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromGeneratedVideos = common.getValueByPath(fromObject, [\n    'generatedSamples',\n  ]);\n  if (fromGeneratedVideos != null) {\n    let transformedList = fromGeneratedVideos;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return generatedVideoFromMldev(item);\n      });\n    }\n    common.setValueByPath(toObject, ['generatedVideos'], transformedList);\n  }\n\n  const fromRaiMediaFilteredCount = common.getValueByPath(fromObject, [\n    'raiMediaFilteredCount',\n  ]);\n  if (fromRaiMediaFilteredCount != null) {\n    common.setValueByPath(\n      toObject,\n      ['raiMediaFilteredCount'],\n      fromRaiMediaFilteredCount,\n    );\n  }\n\n  const fromRaiMediaFilteredReasons = common.getValueByPath(fromObject, [\n    'raiMediaFilteredReasons',\n  ]);\n  if (fromRaiMediaFilteredReasons != null) {\n    common.setValueByPath(\n      toObject,\n      ['raiMediaFilteredReasons'],\n      fromRaiMediaFilteredReasons,\n    );\n  }\n\n  return toObject;\n}\n\nexport function generateVideosResponseFromVertex(\n  fromObject: types.GenerateVideosResponse,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromGeneratedVideos = common.getValueByPath(fromObject, ['videos']);\n  if (fromGeneratedVideos != null) {\n    let transformedList = fromGeneratedVideos;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return generatedVideoFromVertex(item);\n      });\n    }\n    common.setValueByPath(toObject, ['generatedVideos'], transformedList);\n  }\n\n  const fromRaiMediaFilteredCount = common.getValueByPath(fromObject, [\n    'raiMediaFilteredCount',\n  ]);\n  if (fromRaiMediaFilteredCount != null) {\n    common.setValueByPath(\n      toObject,\n      ['raiMediaFilteredCount'],\n      fromRaiMediaFilteredCount,\n    );\n  }\n\n  const fromRaiMediaFilteredReasons = common.getValueByPath(fromObject, [\n    'raiMediaFilteredReasons',\n  ]);\n  if (fromRaiMediaFilteredReasons != null) {\n    common.setValueByPath(\n      toObject,\n      ['raiMediaFilteredReasons'],\n      fromRaiMediaFilteredReasons,\n    );\n  }\n\n  return toObject;\n}\n\nexport function generatedVideoFromMldev(\n  fromObject: types.GeneratedVideo,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromVideo = common.getValueByPath(fromObject, ['video']);\n  if (fromVideo != null) {\n    common.setValueByPath(toObject, ['video'], videoFromMldev(fromVideo));\n  }\n\n  return toObject;\n}\n\nexport function generatedVideoFromVertex(\n  fromObject: types.GeneratedVideo,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromVideo = common.getValueByPath(fromObject, ['_self']);\n  if (fromVideo != null) {\n    common.setValueByPath(toObject, ['video'], videoFromVertex(fromVideo));\n  }\n\n  return toObject;\n}\n\nexport function getOperationParametersToMldev(\n  fromObject: types.GetOperationParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromOperationName = common.getValueByPath(fromObject, [\n    'operationName',\n  ]);\n  if (fromOperationName != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'operationName'],\n      fromOperationName,\n    );\n  }\n\n  return toObject;\n}\n\nexport function getOperationParametersToVertex(\n  fromObject: types.GetOperationParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromOperationName = common.getValueByPath(fromObject, [\n    'operationName',\n  ]);\n  if (fromOperationName != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'operationName'],\n      fromOperationName,\n    );\n  }\n\n  return toObject;\n}\n\nexport function videoFromMldev(\n  fromObject: types.Video,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromUri = common.getValueByPath(fromObject, ['uri']);\n  if (fromUri != null) {\n    common.setValueByPath(toObject, ['uri'], fromUri);\n  }\n\n  const fromVideoBytes = common.getValueByPath(fromObject, ['encodedVideo']);\n  if (fromVideoBytes != null) {\n    common.setValueByPath(toObject, ['videoBytes'], t.tBytes(fromVideoBytes));\n  }\n\n  const fromMimeType = common.getValueByPath(fromObject, ['encoding']);\n  if (fromMimeType != null) {\n    common.setValueByPath(toObject, ['mimeType'], fromMimeType);\n  }\n\n  return toObject;\n}\n\nexport function videoFromVertex(\n  fromObject: types.Video,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromUri = common.getValueByPath(fromObject, ['gcsUri']);\n  if (fromUri != null) {\n    common.setValueByPath(toObject, ['uri'], fromUri);\n  }\n\n  const fromVideoBytes = common.getValueByPath(fromObject, [\n    'bytesBase64Encoded',\n  ]);\n  if (fromVideoBytes != null) {\n    common.setValueByPath(toObject, ['videoBytes'], t.tBytes(fromVideoBytes));\n  }\n\n  const fromMimeType = common.getValueByPath(fromObject, ['mimeType']);\n  if (fromMimeType != null) {\n    common.setValueByPath(toObject, ['mimeType'], fromMimeType);\n  }\n\n  return toObject;\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\n// Code generated by the Google Gen AI SDK generator DO NOT EDIT.\n\nimport type {ReferenceImageAPIInternal} from './_internal_types.js';\nimport {\n  generateVideosOperationFromMldev,\n  generateVideosOperationFromVertex,\n} from './converters/_operations_converters.js';\n\n/** Required. Outcome of the code execution. */\nexport enum Outcome {\n  /**\n   * Unspecified status. This value should not be used.\n   */\n  OUTCOME_UNSPECIFIED = 'OUTCOME_UNSPECIFIED',\n  /**\n   * Code execution completed successfully.\n   */\n  OUTCOME_OK = 'OUTCOME_OK',\n  /**\n   * Code execution finished but with a failure. `stderr` should contain the reason.\n   */\n  OUTCOME_FAILED = 'OUTCOME_FAILED',\n  /**\n   * Code execution ran for too long, and was cancelled. There may or may not be a partial output present.\n   */\n  OUTCOME_DEADLINE_EXCEEDED = 'OUTCOME_DEADLINE_EXCEEDED',\n}\n\n/** Required. Programming language of the `code`. */\nexport enum Language {\n  /**\n   * Unspecified language. This value should not be used.\n   */\n  LANGUAGE_UNSPECIFIED = 'LANGUAGE_UNSPECIFIED',\n  /**\n   * Python >= 3.10, with numpy and simpy available.\n   */\n  PYTHON = 'PYTHON',\n}\n\n/** Specifies how the response should be scheduled in the conversation. */\nexport enum FunctionResponseScheduling {\n  /**\n   * This value is unused.\n   */\n  SCHEDULING_UNSPECIFIED = 'SCHEDULING_UNSPECIFIED',\n  /**\n   * Only add the result to the conversation context, do not interrupt or trigger generation.\n   */\n  SILENT = 'SILENT',\n  /**\n   * Add the result to the conversation context, and prompt to generate output without interrupting ongoing generation.\n   */\n  WHEN_IDLE = 'WHEN_IDLE',\n  /**\n   * Add the result to the conversation context, interrupt ongoing generation and prompt to generate output.\n   */\n  INTERRUPT = 'INTERRUPT',\n}\n\n/** Optional. The type of the data. */\nexport enum Type {\n  /**\n   * Not specified, should not be used.\n   */\n  TYPE_UNSPECIFIED = 'TYPE_UNSPECIFIED',\n  /**\n   * OpenAPI string type\n   */\n  STRING = 'STRING',\n  /**\n   * OpenAPI number type\n   */\n  NUMBER = 'NUMBER',\n  /**\n   * OpenAPI integer type\n   */\n  INTEGER = 'INTEGER',\n  /**\n   * OpenAPI boolean type\n   */\n  BOOLEAN = 'BOOLEAN',\n  /**\n   * OpenAPI array type\n   */\n  ARRAY = 'ARRAY',\n  /**\n   * OpenAPI object type\n   */\n  OBJECT = 'OBJECT',\n  /**\n   * Null type\n   */\n  NULL = 'NULL',\n}\n\n/** Required. Harm category. */\nexport enum HarmCategory {\n  /**\n   * The harm category is unspecified.\n   */\n  HARM_CATEGORY_UNSPECIFIED = 'HARM_CATEGORY_UNSPECIFIED',\n  /**\n   * The harm category is harassment.\n   */\n  HARM_CATEGORY_HARASSMENT = 'HARM_CATEGORY_HARASSMENT',\n  /**\n   * The harm category is hate speech.\n   */\n  HARM_CATEGORY_HATE_SPEECH = 'HARM_CATEGORY_HATE_SPEECH',\n  /**\n   * The harm category is sexually explicit content.\n   */\n  HARM_CATEGORY_SEXUALLY_EXPLICIT = 'HARM_CATEGORY_SEXUALLY_EXPLICIT',\n  /**\n   * The harm category is dangerous content.\n   */\n  HARM_CATEGORY_DANGEROUS_CONTENT = 'HARM_CATEGORY_DANGEROUS_CONTENT',\n  /**\n   * Deprecated: Election filter is not longer supported. The harm category is civic integrity.\n   */\n  HARM_CATEGORY_CIVIC_INTEGRITY = 'HARM_CATEGORY_CIVIC_INTEGRITY',\n  /**\n   * The harm category is image hate. This enum value is not supported in Gemini API.\n   */\n  HARM_CATEGORY_IMAGE_HATE = 'HARM_CATEGORY_IMAGE_HATE',\n  /**\n   * The harm category is image dangerous content. This enum value is not supported in Gemini API.\n   */\n  HARM_CATEGORY_IMAGE_DANGEROUS_CONTENT = 'HARM_CATEGORY_IMAGE_DANGEROUS_CONTENT',\n  /**\n   * The harm category is image harassment. This enum value is not supported in Gemini API.\n   */\n  HARM_CATEGORY_IMAGE_HARASSMENT = 'HARM_CATEGORY_IMAGE_HARASSMENT',\n  /**\n   * The harm category is image sexually explicit content. This enum value is not supported in Gemini API.\n   */\n  HARM_CATEGORY_IMAGE_SEXUALLY_EXPLICIT = 'HARM_CATEGORY_IMAGE_SEXUALLY_EXPLICIT',\n  /**\n   * The harm category is for jailbreak prompts. This enum value is not supported in Gemini API.\n   */\n  HARM_CATEGORY_JAILBREAK = 'HARM_CATEGORY_JAILBREAK',\n}\n\n/** Optional. Specify if the threshold is used for probability or severity score. If not specified, the threshold is used for probability score. */\nexport enum HarmBlockMethod {\n  /**\n   * The harm block method is unspecified.\n   */\n  HARM_BLOCK_METHOD_UNSPECIFIED = 'HARM_BLOCK_METHOD_UNSPECIFIED',\n  /**\n   * The harm block method uses both probability and severity scores.\n   */\n  SEVERITY = 'SEVERITY',\n  /**\n   * The harm block method uses the probability score.\n   */\n  PROBABILITY = 'PROBABILITY',\n}\n\n/** Required. The harm block threshold. */\nexport enum HarmBlockThreshold {\n  /**\n   * Unspecified harm block threshold.\n   */\n  HARM_BLOCK_THRESHOLD_UNSPECIFIED = 'HARM_BLOCK_THRESHOLD_UNSPECIFIED',\n  /**\n   * Block low threshold and above (i.e. block more).\n   */\n  BLOCK_LOW_AND_ABOVE = 'BLOCK_LOW_AND_ABOVE',\n  /**\n   * Block medium threshold and above.\n   */\n  BLOCK_MEDIUM_AND_ABOVE = 'BLOCK_MEDIUM_AND_ABOVE',\n  /**\n   * Block only high threshold (i.e. block less).\n   */\n  BLOCK_ONLY_HIGH = 'BLOCK_ONLY_HIGH',\n  /**\n   * Block none.\n   */\n  BLOCK_NONE = 'BLOCK_NONE',\n  /**\n   * Turn off the safety filter.\n   */\n  OFF = 'OFF',\n}\n\n/** The mode of the predictor to be used in dynamic retrieval. */\nexport enum Mode {\n  /**\n   * Always trigger retrieval.\n   */\n  MODE_UNSPECIFIED = 'MODE_UNSPECIFIED',\n  /**\n   * Run retrieval only when system decides it is necessary.\n   */\n  MODE_DYNAMIC = 'MODE_DYNAMIC',\n}\n\n/** Type of auth scheme. */\nexport enum AuthType {\n  AUTH_TYPE_UNSPECIFIED = 'AUTH_TYPE_UNSPECIFIED',\n  /**\n   * No Auth.\n   */\n  NO_AUTH = 'NO_AUTH',\n  /**\n   * API Key Auth.\n   */\n  API_KEY_AUTH = 'API_KEY_AUTH',\n  /**\n   * HTTP Basic Auth.\n   */\n  HTTP_BASIC_AUTH = 'HTTP_BASIC_AUTH',\n  /**\n   * Google Service Account Auth.\n   */\n  GOOGLE_SERVICE_ACCOUNT_AUTH = 'GOOGLE_SERVICE_ACCOUNT_AUTH',\n  /**\n   * OAuth auth.\n   */\n  OAUTH = 'OAUTH',\n  /**\n   * OpenID Connect (OIDC) Auth.\n   */\n  OIDC_AUTH = 'OIDC_AUTH',\n}\n\n/** The API spec that the external API implements. */\nexport enum ApiSpec {\n  /**\n   * Unspecified API spec. This value should not be used.\n   */\n  API_SPEC_UNSPECIFIED = 'API_SPEC_UNSPECIFIED',\n  /**\n   * Simple search API spec.\n   */\n  SIMPLE_SEARCH = 'SIMPLE_SEARCH',\n  /**\n   * Elastic search API spec.\n   */\n  ELASTIC_SEARCH = 'ELASTIC_SEARCH',\n}\n\n/** Status of the url retrieval. */\nexport enum UrlRetrievalStatus {\n  /**\n   * Default value. This value is unused\n   */\n  URL_RETRIEVAL_STATUS_UNSPECIFIED = 'URL_RETRIEVAL_STATUS_UNSPECIFIED',\n  /**\n   * Url retrieval is successful.\n   */\n  URL_RETRIEVAL_STATUS_SUCCESS = 'URL_RETRIEVAL_STATUS_SUCCESS',\n  /**\n   * Url retrieval is failed due to error.\n   */\n  URL_RETRIEVAL_STATUS_ERROR = 'URL_RETRIEVAL_STATUS_ERROR',\n  /**\n   * Url retrieval is failed because the content is behind paywall.\n   */\n  URL_RETRIEVAL_STATUS_PAYWALL = 'URL_RETRIEVAL_STATUS_PAYWALL',\n  /**\n   * Url retrieval is failed because the content is unsafe.\n   */\n  URL_RETRIEVAL_STATUS_UNSAFE = 'URL_RETRIEVAL_STATUS_UNSAFE',\n}\n\n/** Output only. The reason why the model stopped generating tokens.\n\nIf empty, the model has not stopped generating the tokens. */\nexport enum FinishReason {\n  /**\n   * The finish reason is unspecified.\n   */\n  FINISH_REASON_UNSPECIFIED = 'FINISH_REASON_UNSPECIFIED',\n  /**\n   * Token generation reached a natural stopping point or a configured stop sequence.\n   */\n  STOP = 'STOP',\n  /**\n   * Token generation reached the configured maximum output tokens.\n   */\n  MAX_TOKENS = 'MAX_TOKENS',\n  /**\n   * Token generation stopped because the content potentially contains safety violations. NOTE: When streaming, [content][] is empty if content filters blocks the output.\n   */\n  SAFETY = 'SAFETY',\n  /**\n   * The token generation stopped because of potential recitation.\n   */\n  RECITATION = 'RECITATION',\n  /**\n   * The token generation stopped because of using an unsupported language.\n   */\n  LANGUAGE = 'LANGUAGE',\n  /**\n   * All other reasons that stopped the token generation.\n   */\n  OTHER = 'OTHER',\n  /**\n   * Token generation stopped because the content contains forbidden terms.\n   */\n  BLOCKLIST = 'BLOCKLIST',\n  /**\n   * Token generation stopped for potentially containing prohibited content.\n   */\n  PROHIBITED_CONTENT = 'PROHIBITED_CONTENT',\n  /**\n   * Token generation stopped because the content potentially contains Sensitive Personally Identifiable Information (SPII).\n   */\n  SPII = 'SPII',\n  /**\n   * The function call generated by the model is invalid.\n   */\n  MALFORMED_FUNCTION_CALL = 'MALFORMED_FUNCTION_CALL',\n  /**\n   * Token generation stopped because generated images have safety violations.\n   */\n  IMAGE_SAFETY = 'IMAGE_SAFETY',\n  /**\n   * The tool call generated by the model is invalid.\n   */\n  UNEXPECTED_TOOL_CALL = 'UNEXPECTED_TOOL_CALL',\n  /**\n   * Image generation stopped because the generated images have prohibited content.\n   */\n  IMAGE_PROHIBITED_CONTENT = 'IMAGE_PROHIBITED_CONTENT',\n  /**\n   * The model was expected to generate an image, but none was generated.\n   */\n  NO_IMAGE = 'NO_IMAGE',\n}\n\n/** Output only. Harm probability levels in the content. */\nexport enum HarmProbability {\n  /**\n   * Harm probability unspecified.\n   */\n  HARM_PROBABILITY_UNSPECIFIED = 'HARM_PROBABILITY_UNSPECIFIED',\n  /**\n   * Negligible level of harm.\n   */\n  NEGLIGIBLE = 'NEGLIGIBLE',\n  /**\n   * Low level of harm.\n   */\n  LOW = 'LOW',\n  /**\n   * Medium level of harm.\n   */\n  MEDIUM = 'MEDIUM',\n  /**\n   * High level of harm.\n   */\n  HIGH = 'HIGH',\n}\n\n/** Output only. Harm severity levels in the content. */\nexport enum HarmSeverity {\n  /**\n   * Harm severity unspecified.\n   */\n  HARM_SEVERITY_UNSPECIFIED = 'HARM_SEVERITY_UNSPECIFIED',\n  /**\n   * Negligible level of harm severity.\n   */\n  HARM_SEVERITY_NEGLIGIBLE = 'HARM_SEVERITY_NEGLIGIBLE',\n  /**\n   * Low level of harm severity.\n   */\n  HARM_SEVERITY_LOW = 'HARM_SEVERITY_LOW',\n  /**\n   * Medium level of harm severity.\n   */\n  HARM_SEVERITY_MEDIUM = 'HARM_SEVERITY_MEDIUM',\n  /**\n   * High level of harm severity.\n   */\n  HARM_SEVERITY_HIGH = 'HARM_SEVERITY_HIGH',\n}\n\n/** Output only. The reason why the prompt was blocked. */\nexport enum BlockedReason {\n  /**\n   * The blocked reason is unspecified.\n   */\n  BLOCKED_REASON_UNSPECIFIED = 'BLOCKED_REASON_UNSPECIFIED',\n  /**\n   * The prompt was blocked for safety reasons.\n   */\n  SAFETY = 'SAFETY',\n  /**\n   * The prompt was blocked for other reasons. For example, it may be due to the prompt's language, or because it contains other harmful content.\n   */\n  OTHER = 'OTHER',\n  /**\n   * The prompt was blocked because it contains a term from the terminology blocklist.\n   */\n  BLOCKLIST = 'BLOCKLIST',\n  /**\n   * The prompt was blocked because it contains prohibited content.\n   */\n  PROHIBITED_CONTENT = 'PROHIBITED_CONTENT',\n  /**\n   * The prompt was blocked because it contains content that is unsafe for image generation.\n   */\n  IMAGE_SAFETY = 'IMAGE_SAFETY',\n  /**\n   * The prompt was blocked by Model Armor. This enum value is not supported in Gemini API.\n   */\n  MODEL_ARMOR = 'MODEL_ARMOR',\n  /**\n   * The prompt was blocked as a jailbreak attempt. This enum value is not supported in Gemini API.\n   */\n  JAILBREAK = 'JAILBREAK',\n}\n\n/** Output only. Traffic type. This shows whether a request consumes Pay-As-You-Go or Provisioned Throughput quota. */\nexport enum TrafficType {\n  /**\n   * Unspecified request traffic type.\n   */\n  TRAFFIC_TYPE_UNSPECIFIED = 'TRAFFIC_TYPE_UNSPECIFIED',\n  /**\n   * Type for Pay-As-You-Go traffic.\n   */\n  ON_DEMAND = 'ON_DEMAND',\n  /**\n   * Type for Provisioned Throughput traffic.\n   */\n  PROVISIONED_THROUGHPUT = 'PROVISIONED_THROUGHPUT',\n}\n\n/** Server content modalities. */\nexport enum Modality {\n  /**\n   * The modality is unspecified.\n   */\n  MODALITY_UNSPECIFIED = 'MODALITY_UNSPECIFIED',\n  /**\n   * Indicates the model should return text\n   */\n  TEXT = 'TEXT',\n  /**\n   * Indicates the model should return images.\n   */\n  IMAGE = 'IMAGE',\n  /**\n   * Indicates the model should return audio.\n   */\n  AUDIO = 'AUDIO',\n}\n\n/** The media resolution to use. */\nexport enum MediaResolution {\n  /**\n   * Media resolution has not been set\n   */\n  MEDIA_RESOLUTION_UNSPECIFIED = 'MEDIA_RESOLUTION_UNSPECIFIED',\n  /**\n   * Media resolution set to low (64 tokens).\n   */\n  MEDIA_RESOLUTION_LOW = 'MEDIA_RESOLUTION_LOW',\n  /**\n   * Media resolution set to medium (256 tokens).\n   */\n  MEDIA_RESOLUTION_MEDIUM = 'MEDIA_RESOLUTION_MEDIUM',\n  /**\n   * Media resolution set to high (zoomed reframing with 256 tokens).\n   */\n  MEDIA_RESOLUTION_HIGH = 'MEDIA_RESOLUTION_HIGH',\n}\n\n/** Job state. */\nexport enum JobState {\n  /**\n   * The job state is unspecified.\n   */\n  JOB_STATE_UNSPECIFIED = 'JOB_STATE_UNSPECIFIED',\n  /**\n   * The job has been just created or resumed and processing has not yet begun.\n   */\n  JOB_STATE_QUEUED = 'JOB_STATE_QUEUED',\n  /**\n   * The service is preparing to run the job.\n   */\n  JOB_STATE_PENDING = 'JOB_STATE_PENDING',\n  /**\n   * The job is in progress.\n   */\n  JOB_STATE_RUNNING = 'JOB_STATE_RUNNING',\n  /**\n   * The job completed successfully.\n   */\n  JOB_STATE_SUCCEEDED = 'JOB_STATE_SUCCEEDED',\n  /**\n   * The job failed.\n   */\n  JOB_STATE_FAILED = 'JOB_STATE_FAILED',\n  /**\n   * The job is being cancelled. From this state the job may only go to either `JOB_STATE_SUCCEEDED`, `JOB_STATE_FAILED` or `JOB_STATE_CANCELLED`.\n   */\n  JOB_STATE_CANCELLING = 'JOB_STATE_CANCELLING',\n  /**\n   * The job has been cancelled.\n   */\n  JOB_STATE_CANCELLED = 'JOB_STATE_CANCELLED',\n  /**\n   * The job has been stopped, and can be resumed.\n   */\n  JOB_STATE_PAUSED = 'JOB_STATE_PAUSED',\n  /**\n   * The job has expired.\n   */\n  JOB_STATE_EXPIRED = 'JOB_STATE_EXPIRED',\n  /**\n   * The job is being updated. Only jobs in the `JOB_STATE_RUNNING` state can be updated. After updating, the job goes back to the `JOB_STATE_RUNNING` state.\n   */\n  JOB_STATE_UPDATING = 'JOB_STATE_UPDATING',\n  /**\n   * The job is partially succeeded, some results may be missing due to errors.\n   */\n  JOB_STATE_PARTIALLY_SUCCEEDED = 'JOB_STATE_PARTIALLY_SUCCEEDED',\n}\n\n/** Tuning mode. */\nexport enum TuningMode {\n  /**\n   * Tuning mode is unspecified.\n   */\n  TUNING_MODE_UNSPECIFIED = 'TUNING_MODE_UNSPECIFIED',\n  /**\n   * Full fine-tuning mode.\n   */\n  TUNING_MODE_FULL = 'TUNING_MODE_FULL',\n  /**\n   * PEFT adapter tuning mode.\n   */\n  TUNING_MODE_PEFT_ADAPTER = 'TUNING_MODE_PEFT_ADAPTER',\n}\n\n/** Optional. Adapter size for tuning. */\nexport enum AdapterSize {\n  /**\n   * Adapter size is unspecified.\n   */\n  ADAPTER_SIZE_UNSPECIFIED = 'ADAPTER_SIZE_UNSPECIFIED',\n  /**\n   * Adapter size 1.\n   */\n  ADAPTER_SIZE_ONE = 'ADAPTER_SIZE_ONE',\n  /**\n   * Adapter size 2.\n   */\n  ADAPTER_SIZE_TWO = 'ADAPTER_SIZE_TWO',\n  /**\n   * Adapter size 4.\n   */\n  ADAPTER_SIZE_FOUR = 'ADAPTER_SIZE_FOUR',\n  /**\n   * Adapter size 8.\n   */\n  ADAPTER_SIZE_EIGHT = 'ADAPTER_SIZE_EIGHT',\n  /**\n   * Adapter size 16.\n   */\n  ADAPTER_SIZE_SIXTEEN = 'ADAPTER_SIZE_SIXTEEN',\n  /**\n   * Adapter size 32.\n   */\n  ADAPTER_SIZE_THIRTY_TWO = 'ADAPTER_SIZE_THIRTY_TWO',\n}\n\n/** Optional. The tuning task. Either I2V or T2V. */\nexport enum TuningTask {\n  /**\n   * Default value. This value is unused.\n   */\n  TUNING_TASK_UNSPECIFIED = 'TUNING_TASK_UNSPECIFIED',\n  /**\n   * Tuning task for image to video.\n   */\n  TUNING_TASK_I2V = 'TUNING_TASK_I2V',\n  /**\n   * Tuning task for text to video.\n   */\n  TUNING_TASK_T2V = 'TUNING_TASK_T2V',\n}\n\n/** Options for feature selection preference. */\nexport enum FeatureSelectionPreference {\n  FEATURE_SELECTION_PREFERENCE_UNSPECIFIED = 'FEATURE_SELECTION_PREFERENCE_UNSPECIFIED',\n  PRIORITIZE_QUALITY = 'PRIORITIZE_QUALITY',\n  BALANCED = 'BALANCED',\n  PRIORITIZE_COST = 'PRIORITIZE_COST',\n}\n\n/** Defines the function behavior. Defaults to `BLOCKING`. */\nexport enum Behavior {\n  /**\n   * This value is unused.\n   */\n  UNSPECIFIED = 'UNSPECIFIED',\n  /**\n   * If set, the system will wait to receive the function response before continuing the conversation.\n   */\n  BLOCKING = 'BLOCKING',\n  /**\n   * If set, the system will not wait to receive the function response. Instead, it will attempt to handle function responses as they become available while maintaining the conversation between the user and the model.\n   */\n  NON_BLOCKING = 'NON_BLOCKING',\n}\n\n/** Config for the dynamic retrieval config mode. */\nexport enum DynamicRetrievalConfigMode {\n  /**\n   * Always trigger retrieval.\n   */\n  MODE_UNSPECIFIED = 'MODE_UNSPECIFIED',\n  /**\n   * Run retrieval only when system decides it is necessary.\n   */\n  MODE_DYNAMIC = 'MODE_DYNAMIC',\n}\n\n/** The environment being operated. */\nexport enum Environment {\n  /**\n   * Defaults to browser.\n   */\n  ENVIRONMENT_UNSPECIFIED = 'ENVIRONMENT_UNSPECIFIED',\n  /**\n   * Operates in a web browser.\n   */\n  ENVIRONMENT_BROWSER = 'ENVIRONMENT_BROWSER',\n}\n\n/** Config for the function calling config mode. */\nexport enum FunctionCallingConfigMode {\n  /**\n   * The function calling config mode is unspecified. Should not be used.\n   */\n  MODE_UNSPECIFIED = 'MODE_UNSPECIFIED',\n  /**\n   * Default model behavior, model decides to predict either function calls or natural language response.\n   */\n  AUTO = 'AUTO',\n  /**\n   * Model is constrained to always predicting function calls only. If \"allowed_function_names\" are set, the predicted function calls will be limited to any one of \"allowed_function_names\", else the predicted function calls will be any one of the provided \"function_declarations\".\n   */\n  ANY = 'ANY',\n  /**\n   * Model will not predict any function calls. Model behavior is same as when not passing any function declarations.\n   */\n  NONE = 'NONE',\n  /**\n   * Model decides to predict either a function call or a natural language response, but will validate function calls with constrained decoding. If \"allowed_function_names\" are set, the predicted function call will be limited to any one of \"allowed_function_names\", else the predicted function call will be any one of the provided \"function_declarations\".\n   */\n  VALIDATED = 'VALIDATED',\n}\n\n/** Enum that controls the safety filter level for objectionable content. */\nexport enum SafetyFilterLevel {\n  BLOCK_LOW_AND_ABOVE = 'BLOCK_LOW_AND_ABOVE',\n  BLOCK_MEDIUM_AND_ABOVE = 'BLOCK_MEDIUM_AND_ABOVE',\n  BLOCK_ONLY_HIGH = 'BLOCK_ONLY_HIGH',\n  BLOCK_NONE = 'BLOCK_NONE',\n}\n\n/** Enum that controls the generation of people. */\nexport enum PersonGeneration {\n  /**\n   * Block generation of images of people.\n   */\n  DONT_ALLOW = 'DONT_ALLOW',\n  /**\n   * Generate images of adults, but not children.\n   */\n  ALLOW_ADULT = 'ALLOW_ADULT',\n  /**\n   * Generate images that include adults and children.\n   */\n  ALLOW_ALL = 'ALLOW_ALL',\n}\n\n/** Enum that specifies the language of the text in the prompt. */\nexport enum ImagePromptLanguage {\n  /**\n   * Auto-detect the language.\n   */\n  auto = 'auto',\n  /**\n   * English\n   */\n  en = 'en',\n  /**\n   * Japanese\n   */\n  ja = 'ja',\n  /**\n   * Korean\n   */\n  ko = 'ko',\n  /**\n   * Hindi\n   */\n  hi = 'hi',\n  /**\n   * Chinese\n   */\n  zh = 'zh',\n  /**\n   * Portuguese\n   */\n  pt = 'pt',\n  /**\n   * Spanish\n   */\n  es = 'es',\n}\n\n/** Enum representing the mask mode of a mask reference image. */\nexport enum MaskReferenceMode {\n  MASK_MODE_DEFAULT = 'MASK_MODE_DEFAULT',\n  MASK_MODE_USER_PROVIDED = 'MASK_MODE_USER_PROVIDED',\n  MASK_MODE_BACKGROUND = 'MASK_MODE_BACKGROUND',\n  MASK_MODE_FOREGROUND = 'MASK_MODE_FOREGROUND',\n  MASK_MODE_SEMANTIC = 'MASK_MODE_SEMANTIC',\n}\n\n/** Enum representing the control type of a control reference image. */\nexport enum ControlReferenceType {\n  CONTROL_TYPE_DEFAULT = 'CONTROL_TYPE_DEFAULT',\n  CONTROL_TYPE_CANNY = 'CONTROL_TYPE_CANNY',\n  CONTROL_TYPE_SCRIBBLE = 'CONTROL_TYPE_SCRIBBLE',\n  CONTROL_TYPE_FACE_MESH = 'CONTROL_TYPE_FACE_MESH',\n}\n\n/** Enum representing the subject type of a subject reference image. */\nexport enum SubjectReferenceType {\n  SUBJECT_TYPE_DEFAULT = 'SUBJECT_TYPE_DEFAULT',\n  SUBJECT_TYPE_PERSON = 'SUBJECT_TYPE_PERSON',\n  SUBJECT_TYPE_ANIMAL = 'SUBJECT_TYPE_ANIMAL',\n  SUBJECT_TYPE_PRODUCT = 'SUBJECT_TYPE_PRODUCT',\n}\n\n/** Enum representing the editing mode. */\nexport enum EditMode {\n  EDIT_MODE_DEFAULT = 'EDIT_MODE_DEFAULT',\n  EDIT_MODE_INPAINT_REMOVAL = 'EDIT_MODE_INPAINT_REMOVAL',\n  EDIT_MODE_INPAINT_INSERTION = 'EDIT_MODE_INPAINT_INSERTION',\n  EDIT_MODE_OUTPAINT = 'EDIT_MODE_OUTPAINT',\n  EDIT_MODE_CONTROLLED_EDITING = 'EDIT_MODE_CONTROLLED_EDITING',\n  EDIT_MODE_STYLE = 'EDIT_MODE_STYLE',\n  EDIT_MODE_BGSWAP = 'EDIT_MODE_BGSWAP',\n  EDIT_MODE_PRODUCT_IMAGE = 'EDIT_MODE_PRODUCT_IMAGE',\n}\n\n/** Enum that represents the segmentation mode. */\nexport enum SegmentMode {\n  FOREGROUND = 'FOREGROUND',\n  BACKGROUND = 'BACKGROUND',\n  PROMPT = 'PROMPT',\n  SEMANTIC = 'SEMANTIC',\n  INTERACTIVE = 'INTERACTIVE',\n}\n\n/** Enum for the reference type of a video generation reference image. */\nexport enum VideoGenerationReferenceType {\n  /**\n   * A reference image that provides assets to the generated video,\n      such as the scene, an object, a character, etc.\n   */\n  ASSET = 'ASSET',\n  /**\n   * A reference image that provides aesthetics including colors,\n      lighting, texture, etc., to be used as the style of the generated video,\n      such as 'anime', 'photography', 'origami', etc.\n   */\n  STYLE = 'STYLE',\n}\n\n/** Enum for the mask mode of a video generation mask. */\nexport enum VideoGenerationMaskMode {\n  /**\n   * The image mask contains a masked rectangular region which is\n      applied on the first frame of the input video. The object described in\n      the prompt is inserted into this region and will appear in subsequent\n      frames.\n   */\n  INSERT = 'INSERT',\n  /**\n   * The image mask is used to determine an object in the\n      first video frame to track. This object is removed from the video.\n   */\n  REMOVE = 'REMOVE',\n  /**\n   * The image mask is used to determine a region in the\n      video. Objects in this region will be removed.\n   */\n  REMOVE_STATIC = 'REMOVE_STATIC',\n  /**\n   * The image mask contains a masked rectangular region where\n      the input video will go. The remaining area will be generated. Video\n      masks are not supported.\n   */\n  OUTPAINT = 'OUTPAINT',\n}\n\n/** Enum that controls the compression quality of the generated videos. */\nexport enum VideoCompressionQuality {\n  /**\n   * Optimized video compression quality. This will produce videos\n      with a compressed, smaller file size.\n   */\n  OPTIMIZED = 'OPTIMIZED',\n  /**\n   * Lossless video compression quality. This will produce videos\n      with a larger file size.\n   */\n  LOSSLESS = 'LOSSLESS',\n}\n\n/** State for the lifecycle of a File. */\nexport enum FileState {\n  STATE_UNSPECIFIED = 'STATE_UNSPECIFIED',\n  PROCESSING = 'PROCESSING',\n  ACTIVE = 'ACTIVE',\n  FAILED = 'FAILED',\n}\n\n/** Source of the File. */\nexport enum FileSource {\n  SOURCE_UNSPECIFIED = 'SOURCE_UNSPECIFIED',\n  UPLOADED = 'UPLOADED',\n  GENERATED = 'GENERATED',\n}\n\n/** The reason why the turn is complete. */\nexport enum TurnCompleteReason {\n  /**\n   * Default value. Reason is unspecified.\n   */\n  TURN_COMPLETE_REASON_UNSPECIFIED = 'TURN_COMPLETE_REASON_UNSPECIFIED',\n  /**\n   * The function call generated by the model is invalid.\n   */\n  MALFORMED_FUNCTION_CALL = 'MALFORMED_FUNCTION_CALL',\n  /**\n   * The response is rejected by the model.\n   */\n  RESPONSE_REJECTED = 'RESPONSE_REJECTED',\n  /**\n   * Needs more input from the user.\n   */\n  NEED_MORE_INPUT = 'NEED_MORE_INPUT',\n}\n\n/** Server content modalities. */\nexport enum MediaModality {\n  /**\n   * The modality is unspecified.\n   */\n  MODALITY_UNSPECIFIED = 'MODALITY_UNSPECIFIED',\n  /**\n   * Plain text.\n   */\n  TEXT = 'TEXT',\n  /**\n   * Images.\n   */\n  IMAGE = 'IMAGE',\n  /**\n   * Video.\n   */\n  VIDEO = 'VIDEO',\n  /**\n   * Audio.\n   */\n  AUDIO = 'AUDIO',\n  /**\n   * Document, e.g. PDF.\n   */\n  DOCUMENT = 'DOCUMENT',\n}\n\n/** Start of speech sensitivity. */\nexport enum StartSensitivity {\n  /**\n   * The default is START_SENSITIVITY_LOW.\n   */\n  START_SENSITIVITY_UNSPECIFIED = 'START_SENSITIVITY_UNSPECIFIED',\n  /**\n   * Automatic detection will detect the start of speech more often.\n   */\n  START_SENSITIVITY_HIGH = 'START_SENSITIVITY_HIGH',\n  /**\n   * Automatic detection will detect the start of speech less often.\n   */\n  START_SENSITIVITY_LOW = 'START_SENSITIVITY_LOW',\n}\n\n/** End of speech sensitivity. */\nexport enum EndSensitivity {\n  /**\n   * The default is END_SENSITIVITY_LOW.\n   */\n  END_SENSITIVITY_UNSPECIFIED = 'END_SENSITIVITY_UNSPECIFIED',\n  /**\n   * Automatic detection ends speech more often.\n   */\n  END_SENSITIVITY_HIGH = 'END_SENSITIVITY_HIGH',\n  /**\n   * Automatic detection ends speech less often.\n   */\n  END_SENSITIVITY_LOW = 'END_SENSITIVITY_LOW',\n}\n\n/** The different ways of handling user activity. */\nexport enum ActivityHandling {\n  /**\n   * If unspecified, the default behavior is `START_OF_ACTIVITY_INTERRUPTS`.\n   */\n  ACTIVITY_HANDLING_UNSPECIFIED = 'ACTIVITY_HANDLING_UNSPECIFIED',\n  /**\n   * If true, start of activity will interrupt the model's response (also called \"barge in\"). The model's current response will be cut-off in the moment of the interruption. This is the default behavior.\n   */\n  START_OF_ACTIVITY_INTERRUPTS = 'START_OF_ACTIVITY_INTERRUPTS',\n  /**\n   * The model's response will not be interrupted.\n   */\n  NO_INTERRUPTION = 'NO_INTERRUPTION',\n}\n\n/** Options about which input is included in the user's turn. */\nexport enum TurnCoverage {\n  /**\n   * If unspecified, the default behavior is `TURN_INCLUDES_ONLY_ACTIVITY`.\n   */\n  TURN_COVERAGE_UNSPECIFIED = 'TURN_COVERAGE_UNSPECIFIED',\n  /**\n   * The users turn only includes activity since the last turn, excluding inactivity (e.g. silence on the audio stream). This is the default behavior.\n   */\n  TURN_INCLUDES_ONLY_ACTIVITY = 'TURN_INCLUDES_ONLY_ACTIVITY',\n  /**\n   * The users turn includes all realtime input since the last turn, including inactivity (e.g. silence on the audio stream).\n   */\n  TURN_INCLUDES_ALL_INPUT = 'TURN_INCLUDES_ALL_INPUT',\n}\n\n/** Scale of the generated music. */\nexport enum Scale {\n  /**\n   * Default value. This value is unused.\n   */\n  SCALE_UNSPECIFIED = 'SCALE_UNSPECIFIED',\n  /**\n   * C major or A minor.\n   */\n  C_MAJOR_A_MINOR = 'C_MAJOR_A_MINOR',\n  /**\n   * Db major or Bb minor.\n   */\n  D_FLAT_MAJOR_B_FLAT_MINOR = 'D_FLAT_MAJOR_B_FLAT_MINOR',\n  /**\n   * D major or B minor.\n   */\n  D_MAJOR_B_MINOR = 'D_MAJOR_B_MINOR',\n  /**\n   * Eb major or C minor\n   */\n  E_FLAT_MAJOR_C_MINOR = 'E_FLAT_MAJOR_C_MINOR',\n  /**\n   * E major or Db minor.\n   */\n  E_MAJOR_D_FLAT_MINOR = 'E_MAJOR_D_FLAT_MINOR',\n  /**\n   * F major or D minor.\n   */\n  F_MAJOR_D_MINOR = 'F_MAJOR_D_MINOR',\n  /**\n   * Gb major or Eb minor.\n   */\n  G_FLAT_MAJOR_E_FLAT_MINOR = 'G_FLAT_MAJOR_E_FLAT_MINOR',\n  /**\n   * G major or E minor.\n   */\n  G_MAJOR_E_MINOR = 'G_MAJOR_E_MINOR',\n  /**\n   * Ab major or F minor.\n   */\n  A_FLAT_MAJOR_F_MINOR = 'A_FLAT_MAJOR_F_MINOR',\n  /**\n   * A major or Gb minor.\n   */\n  A_MAJOR_G_FLAT_MINOR = 'A_MAJOR_G_FLAT_MINOR',\n  /**\n   * Bb major or G minor.\n   */\n  B_FLAT_MAJOR_G_MINOR = 'B_FLAT_MAJOR_G_MINOR',\n  /**\n   * B major or Ab minor.\n   */\n  B_MAJOR_A_FLAT_MINOR = 'B_MAJOR_A_FLAT_MINOR',\n}\n\n/** The mode of music generation. */\nexport enum MusicGenerationMode {\n  /**\n   * Rely on the server default generation mode.\n   */\n  MUSIC_GENERATION_MODE_UNSPECIFIED = 'MUSIC_GENERATION_MODE_UNSPECIFIED',\n  /**\n   * Steer text prompts to regions of latent space with higher quality\n      music.\n   */\n  QUALITY = 'QUALITY',\n  /**\n   * Steer text prompts to regions of latent space with a larger\n      diversity of music.\n   */\n  DIVERSITY = 'DIVERSITY',\n  /**\n   * Steer text prompts to regions of latent space more likely to\n      generate music with vocals.\n   */\n  VOCALIZATION = 'VOCALIZATION',\n}\n\n/** The playback control signal to apply to the music generation. */\nexport enum LiveMusicPlaybackControl {\n  /**\n   * This value is unused.\n   */\n  PLAYBACK_CONTROL_UNSPECIFIED = 'PLAYBACK_CONTROL_UNSPECIFIED',\n  /**\n   * Start generating the music.\n   */\n  PLAY = 'PLAY',\n  /**\n   * Hold the music generation. Use PLAY to resume from the current position.\n   */\n  PAUSE = 'PAUSE',\n  /**\n   * Stop the music generation and reset the context (prompts retained).\n      Use PLAY to restart the music generation.\n   */\n  STOP = 'STOP',\n  /**\n   * Reset the context of the music generation without stopping it.\n      Retains the current prompts and config.\n   */\n  RESET_CONTEXT = 'RESET_CONTEXT',\n}\n\n/** Describes how the video in the Part should be used by the model. */\nexport declare interface VideoMetadata {\n  /** The frame rate of the video sent to the model. If not specified, the\n        default value will be 1.0. The fps range is (0.0, 24.0]. */\n  fps?: number;\n  /** Optional. The end offset of the video. */\n  endOffset?: string;\n  /** Optional. The start offset of the video. */\n  startOffset?: string;\n}\n\n/** Content blob. */\nexport declare interface Blob {\n  /** Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is not currently used in the Gemini GenerateContent calls. */\n  displayName?: string;\n  /** Required. Raw bytes.\n   * @remarks Encoded as base64 string. */\n  data?: string;\n  /** Required. The IANA standard MIME type of the source data. */\n  mimeType?: string;\n}\n\n/** URI based data. */\nexport declare interface FileData {\n  /** Optional. Display name of the file data. Used to provide a label or filename to distinguish file datas. It is not currently used in the Gemini GenerateContent calls. */\n  displayName?: string;\n  /** Required. URI. */\n  fileUri?: string;\n  /** Required. The IANA standard MIME type of the source data. */\n  mimeType?: string;\n}\n\n/** A function call. */\nexport declare interface FunctionCall {\n  /** The unique id of the function call. If populated, the client to execute the\n   `function_call` and return the response with the matching `id`. */\n  id?: string;\n  /** Optional. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details. */\n  args?: Record<string, unknown>;\n  /** Required. The name of the function to call. Matches [FunctionDeclaration.name]. */\n  name?: string;\n}\n\n/** Result of executing the [ExecutableCode]. Only generated when using the [CodeExecution] tool, and always follows a `part` containing the [ExecutableCode]. */\nexport declare interface CodeExecutionResult {\n  /** Required. Outcome of the code execution. */\n  outcome?: Outcome;\n  /** Optional. Contains stdout when code execution is successful, stderr or other description otherwise. */\n  output?: string;\n}\n\n/** Code generated by the model that is meant to be executed, and the result returned to the model. Generated when using the [CodeExecution] tool, in which the code will be automatically executed, and a corresponding [CodeExecutionResult] will also be generated. */\nexport declare interface ExecutableCode {\n  /** Required. The code to be executed. */\n  code?: string;\n  /** Required. Programming language of the `code`. */\n  language?: Language;\n}\n\n/** Raw media bytes for function response.\n\nText should not be sent as raw bytes, use the FunctionResponse.response\nfield. */\nexport class FunctionResponseBlob {\n  /** Required. The IANA standard MIME type of the source data. */\n  mimeType?: string;\n  /** Required. Inline media bytes.\n   * @remarks Encoded as base64 string. */\n  data?: string;\n}\n\n/** URI based data for function response. */\nexport class FunctionResponseFileData {\n  /** Required. URI. */\n  fileUri?: string;\n  /** Required. The IANA standard MIME type of the source data. */\n  mimeType?: string;\n}\n\n/** A datatype containing media that is part of a `FunctionResponse` message.\n\nA `FunctionResponsePart` consists of data which has an associated datatype. A\n`FunctionResponsePart` can only contain one of the accepted types in\n`FunctionResponsePart.data`.\n\nA `FunctionResponsePart` must have a fixed IANA MIME type identifying the\ntype and subtype of the media if the `inline_data` field is filled with raw\nbytes. */\nexport class FunctionResponsePart {\n  /** Optional. Inline media bytes. */\n  inlineData?: FunctionResponseBlob;\n  /** Optional. URI based data. */\n  fileData?: FunctionResponseFileData;\n}\n/**\n * Creates a `FunctionResponsePart` object from a `base64` encoded `string`.\n */\nexport function createFunctionResponsePartFromBase64(\n  data: string,\n  mimeType: string,\n): FunctionResponsePart {\n  return {\n    inlineData: {\n      data: data,\n      mimeType: mimeType,\n    },\n  };\n}\n/**\n * Creates a `FunctionResponsePart` object from a `URI` string.\n */\nexport function createFunctionResponsePartFromUri(\n  uri: string,\n  mimeType: string,\n): FunctionResponsePart {\n  return {\n    fileData: {\n      fileUri: uri,\n      mimeType: mimeType,\n    },\n  };\n}\n\n/** A function response. */\nexport class FunctionResponse {\n  /** Signals that function call continues, and more responses will be returned, turning the function call into a generator. Is only applicable to NON_BLOCKING function calls (see FunctionDeclaration.behavior for details), ignored otherwise. If false, the default, future responses will not be considered. Is only applicable to NON_BLOCKING function calls, is ignored otherwise. If set to false, future responses will not be considered. It is allowed to return empty `response` with `will_continue=False` to signal that the function call is finished. */\n  willContinue?: boolean;\n  /** Specifies how the response should be scheduled in the conversation. Only applicable to NON_BLOCKING function calls, is ignored otherwise. Defaults to WHEN_IDLE. */\n  scheduling?: FunctionResponseScheduling;\n  /** List of parts that constitute a function response. Each part may\n      have a different IANA MIME type. */\n  parts?: FunctionResponsePart[];\n  /** Optional. The id of the function call this response is for. Populated by the client to match the corresponding function call `id`. */\n  id?: string;\n  /** Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name]. */\n  name?: string;\n  /** Required. The function response in JSON object format. Use \"output\" key to specify function output and \"error\" key to specify error details (if any). If \"output\" and \"error\" keys are not specified, then whole \"response\" is treated as function output. */\n  response?: Record<string, unknown>;\n}\n\n/** A datatype containing media content.\n\nExactly one field within a Part should be set, representing the specific type\nof content being conveyed. Using multiple fields within the same `Part`\ninstance is considered invalid. */\nexport declare interface Part {\n  /** Metadata for a given video. */\n  videoMetadata?: VideoMetadata;\n  /** Indicates if the part is thought from the model. */\n  thought?: boolean;\n  /** Optional. Inlined bytes data. */\n  inlineData?: Blob;\n  /** Optional. URI based data. */\n  fileData?: FileData;\n  /** An opaque signature for the thought so it can be reused in subsequent requests.\n   * @remarks Encoded as base64 string. */\n  thoughtSignature?: string;\n  /** A predicted [FunctionCall] returned from the model that contains a string\n      representing the [FunctionDeclaration.name] and a structured JSON object\n      containing the parameters and their values. */\n  functionCall?: FunctionCall;\n  /** Optional. Result of executing the [ExecutableCode]. */\n  codeExecutionResult?: CodeExecutionResult;\n  /** Optional. Code generated by the model that is meant to be executed. */\n  executableCode?: ExecutableCode;\n  /** Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model. */\n  functionResponse?: FunctionResponse;\n  /** Optional. Text part (can be code). */\n  text?: string;\n}\n/**\n * Creates a `Part` object from a `URI` string.\n */\nexport function createPartFromUri(uri: string, mimeType: string): Part {\n  return {\n    fileData: {\n      fileUri: uri,\n      mimeType: mimeType,\n    },\n  };\n}\n/**\n * Creates a `Part` object from a `text` string.\n */\nexport function createPartFromText(text: string): Part {\n  return {\n    text: text,\n  };\n}\n/**\n * Creates a `Part` object from a `FunctionCall` object.\n */\nexport function createPartFromFunctionCall(\n  name: string,\n  args: Record<string, unknown>,\n): Part {\n  return {\n    functionCall: {\n      name: name,\n      args: args,\n    },\n  };\n}\n/**\n * Creates a `Part` object from a `FunctionResponse` object.\n */\nexport function createPartFromFunctionResponse(\n  id: string,\n  name: string,\n  response: Record<string, unknown>,\n  parts: FunctionResponsePart[] = [],\n): Part {\n  return {\n    functionResponse: {\n      id: id,\n      name: name,\n      response: response,\n      ...(parts.length > 0 && {parts}),\n    },\n  };\n}\n/**\n * Creates a `Part` object from a `base64` encoded `string`.\n */\nexport function createPartFromBase64(data: string, mimeType: string): Part {\n  return {\n    inlineData: {\n      data: data,\n      mimeType: mimeType,\n    },\n  };\n}\n/**\n * Creates a `Part` object from the `outcome` and `output` of a `CodeExecutionResult` object.\n */\nexport function createPartFromCodeExecutionResult(\n  outcome: Outcome,\n  output: string,\n): Part {\n  return {\n    codeExecutionResult: {\n      outcome: outcome,\n      output: output,\n    },\n  };\n}\n/**\n * Creates a `Part` object from the `code` and `language` of an `ExecutableCode` object.\n */\nexport function createPartFromExecutableCode(\n  code: string,\n  language: Language,\n): Part {\n  return {\n    executableCode: {\n      code: code,\n      language: language,\n    },\n  };\n}\n\n/** Contains the multi-part content of a message. */\nexport declare interface Content {\n  /** List of parts that constitute a single message. Each part may have\n      a different IANA MIME type. */\n  parts?: Part[];\n  /** Optional. The producer of the content. Must be either 'user' or\n      'model'. Useful to set for multi-turn conversations, otherwise can be\n      empty. If role is not specified, SDK will determine the role. */\n  role?: string;\n}\nfunction _isPart(obj: unknown): obj is Part {\n  if (typeof obj === 'object' && obj !== null) {\n    return (\n      'fileData' in obj ||\n      'text' in obj ||\n      'functionCall' in obj ||\n      'functionResponse' in obj ||\n      'inlineData' in obj ||\n      'videoMetadata' in obj ||\n      'codeExecutionResult' in obj ||\n      'executableCode' in obj\n    );\n  }\n  return false;\n}\nfunction _toParts(partOrString: PartListUnion | string): Part[] {\n  const parts: Part[] = [];\n  if (typeof partOrString === 'string') {\n    parts.push(createPartFromText(partOrString));\n  } else if (_isPart(partOrString)) {\n    parts.push(partOrString);\n  } else if (Array.isArray(partOrString)) {\n    if (partOrString.length === 0) {\n      throw new Error('partOrString cannot be an empty array');\n    }\n    for (const part of partOrString) {\n      if (typeof part === 'string') {\n        parts.push(createPartFromText(part));\n      } else if (_isPart(part)) {\n        parts.push(part);\n      } else {\n        throw new Error('element in PartUnion must be a Part object or string');\n      }\n    }\n  } else {\n    throw new Error('partOrString must be a Part object, string, or array');\n  }\n  return parts;\n}\n/**\n * Creates a `Content` object with a user role from a `PartListUnion` object or `string`.\n */\nexport function createUserContent(\n  partOrString: PartListUnion | string,\n): Content {\n  return {\n    role: 'user',\n    parts: _toParts(partOrString),\n  };\n}\n\n/**\n * Creates a `Content` object with a model role from a `PartListUnion` object or `string`.\n */\nexport function createModelContent(\n  partOrString: PartListUnion | string,\n): Content {\n  return {\n    role: 'model',\n    parts: _toParts(partOrString),\n  };\n}\n/** HTTP options to be used in each of the requests. */\nexport declare interface HttpOptions {\n  /** The base URL for the AI platform service endpoint. */\n  baseUrl?: string;\n  /** Specifies the version of the API to use. */\n  apiVersion?: string;\n  /** Additional HTTP headers to be sent with the request. */\n  headers?: Record<string, string>;\n  /** Timeout for the request in milliseconds. */\n  timeout?: number;\n  /** Extra parameters to add to the request body.\n      The structure must match the backend API's request structure.\n      - VertexAI backend API docs: https://cloud.google.com/vertex-ai/docs/reference/rest\n      - GeminiAPI backend API docs: https://ai.google.dev/api/rest */\n  extraBody?: Record<string, unknown>;\n}\n\n/** Schema is used to define the format of input/output data.\n\nRepresents a select subset of an [OpenAPI 3.0 schema\nobject](https://spec.openapis.org/oas/v3.0.3#schema-object). More fields may\nbe added in the future as needed. */\nexport declare interface Schema {\n  /** Optional. The value should be validated against any (one or more) of the subschemas in the list. */\n  anyOf?: Schema[];\n  /** Optional. Default value of the data. */\n  default?: unknown;\n  /** Optional. The description of the data. */\n  description?: string;\n  /** Optional. Possible values of the element of primitive type with enum format. Examples: 1. We can define direction as : {type:STRING, format:enum, enum:[\"EAST\", NORTH\", \"SOUTH\", \"WEST\"]} 2. We can define apartment number as : {type:INTEGER, format:enum, enum:[\"101\", \"201\", \"301\"]} */\n  enum?: string[];\n  /** Optional. Example of the object. Will only populated when the object is the root. */\n  example?: unknown;\n  /** Optional. The format of the data. Supported formats: for NUMBER type: \"float\", \"double\" for INTEGER type: \"int32\", \"int64\" for STRING type: \"email\", \"byte\", etc */\n  format?: string;\n  /** Optional. SCHEMA FIELDS FOR TYPE ARRAY Schema of the elements of Type.ARRAY. */\n  items?: Schema;\n  /** Optional. Maximum number of the elements for Type.ARRAY. */\n  maxItems?: string;\n  /** Optional. Maximum length of the Type.STRING */\n  maxLength?: string;\n  /** Optional. Maximum number of the properties for Type.OBJECT. */\n  maxProperties?: string;\n  /** Optional. Maximum value of the Type.INTEGER and Type.NUMBER */\n  maximum?: number;\n  /** Optional. Minimum number of the elements for Type.ARRAY. */\n  minItems?: string;\n  /** Optional. SCHEMA FIELDS FOR TYPE STRING Minimum length of the Type.STRING */\n  minLength?: string;\n  /** Optional. Minimum number of the properties for Type.OBJECT. */\n  minProperties?: string;\n  /** Optional. SCHEMA FIELDS FOR TYPE INTEGER and NUMBER Minimum value of the Type.INTEGER and Type.NUMBER */\n  minimum?: number;\n  /** Optional. Indicates if the value may be null. */\n  nullable?: boolean;\n  /** Optional. Pattern of the Type.STRING to restrict a string to a regular expression. */\n  pattern?: string;\n  /** Optional. SCHEMA FIELDS FOR TYPE OBJECT Properties of Type.OBJECT. */\n  properties?: Record<string, Schema>;\n  /** Optional. The order of the properties. Not a standard field in open api spec. Only used to support the order of the properties. */\n  propertyOrdering?: string[];\n  /** Optional. Required properties of Type.OBJECT. */\n  required?: string[];\n  /** Optional. The title of the Schema. */\n  title?: string;\n  /** Optional. The type of the data. */\n  type?: Type;\n}\n\n/** Config for model selection. */\nexport declare interface ModelSelectionConfig {\n  /** Options for feature selection preference. */\n  featureSelectionPreference?: FeatureSelectionPreference;\n}\n\n/** Safety settings. */\nexport declare interface SafetySetting {\n  /** Determines if the harm block method uses probability or probability\n      and severity scores. */\n  method?: HarmBlockMethod;\n  /** Required. Harm category. */\n  category?: HarmCategory;\n  /** Required. The harm block threshold. */\n  threshold?: HarmBlockThreshold;\n}\n\n/** Defines a function that the model can generate JSON inputs for.\n\nThe inputs are based on `OpenAPI 3.0 specifications\n<https://spec.openapis.org/oas/v3.0.3>`_. */\nexport declare interface FunctionDeclaration {\n  /** Defines the function behavior. */\n  behavior?: Behavior;\n  /** Optional. Description and purpose of the function. Model uses it to decide how and whether to call the function. */\n  description?: string;\n  /** Required. The name of the function to call. Must start with a letter or an underscore. Must be a-z, A-Z, 0-9, or contain underscores, dots and dashes, with a maximum length of 64. */\n  name?: string;\n  /** Optional. Describes the parameters to this function in JSON Schema Object format. Reflects the Open API 3.03 Parameter Object. string Key: the name of the parameter. Parameter names are case sensitive. Schema Value: the Schema defining the type used for the parameter. For function with no parameters, this can be left unset. Parameter names must start with a letter or an underscore and must only contain chars a-z, A-Z, 0-9, or underscores with a maximum length of 64. Example with 1 required and 1 optional parameter: type: OBJECT properties: param1: type: STRING param2: type: INTEGER required: - param1 */\n  parameters?: Schema;\n  /** Optional. Describes the parameters to the function in JSON Schema format. The schema must describe an object where the properties are the parameters to the function. For example: ``` { \"type\": \"object\", \"properties\": { \"name\": { \"type\": \"string\" }, \"age\": { \"type\": \"integer\" } }, \"additionalProperties\": false, \"required\": [\"name\", \"age\"], \"propertyOrdering\": [\"name\", \"age\"] } ``` This field is mutually exclusive with `parameters`. */\n  parametersJsonSchema?: unknown;\n  /** Optional. Describes the output from this function in JSON Schema format. Reflects the Open API 3.03 Response Object. The Schema defines the type used for the response value of the function. */\n  response?: Schema;\n  /** Optional. Describes the output from this function in JSON Schema format. The value specified by the schema is the response value of the function. This field is mutually exclusive with `response`. */\n  responseJsonSchema?: unknown;\n}\n\n/** Represents a time interval, encoded as a start time (inclusive) and an end time (exclusive).\n\nThe start time must be less than or equal to the end time.\nWhen the start equals the end time, the interval is an empty interval.\n(matches no time)\nWhen both start and end are unspecified, the interval matches any time. */\nexport declare interface Interval {\n  /** The start time of the interval. */\n  startTime?: string;\n  /** The end time of the interval. */\n  endTime?: string;\n}\n\n/** Tool to support Google Search in Model. Powered by Google. */\nexport declare interface GoogleSearch {\n  /** Optional. Filter search results to a specific time range.\n      If customers set a start time, they must set an end time (and vice versa).\n       */\n  timeRangeFilter?: Interval;\n  /** Optional. List of domains to be excluded from the search results. The default limit is 2000 domains. Example: [\"amazon.com\", \"facebook.com\"]. This field is not supported in Gemini API. */\n  excludeDomains?: string[];\n}\n\n/** Describes the options to customize dynamic retrieval. */\nexport declare interface DynamicRetrievalConfig {\n  /** The mode of the predictor to be used in dynamic retrieval. */\n  mode?: DynamicRetrievalConfigMode;\n  /** Optional. The threshold to be used in dynamic retrieval. If not set, a system default value is used. */\n  dynamicThreshold?: number;\n}\n\n/** Tool to retrieve public web data for grounding, powered by Google. */\nexport declare interface GoogleSearchRetrieval {\n  /** Specifies the dynamic retrieval configuration for the given source. */\n  dynamicRetrievalConfig?: DynamicRetrievalConfig;\n}\n\n/** Tool to search public web data, powered by Vertex AI Search and Sec4 compliance. */\nexport declare interface EnterpriseWebSearch {\n  /** Optional. List of domains to be excluded from the search results. The default limit is 2000 domains. */\n  excludeDomains?: string[];\n}\n\n/** Config for authentication with API key. */\nexport declare interface ApiKeyConfig {\n  /** The API key to be used in the request directly. */\n  apiKeyString?: string;\n}\n\n/** Config for Google Service Account Authentication. This data type is not supported in Gemini API. */\nexport declare interface AuthConfigGoogleServiceAccountConfig {\n  /** Optional. The service account that the extension execution service runs as. - If the service account is specified, the `iam.serviceAccounts.getAccessToken` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified service account. - If not specified, the Vertex AI Extension Service Agent will be used to execute the Extension. */\n  serviceAccount?: string;\n}\n\n/** Config for HTTP Basic Authentication. This data type is not supported in Gemini API. */\nexport declare interface AuthConfigHttpBasicAuthConfig {\n  /** Required. The name of the SecretManager secret version resource storing the base64 encoded credentials. Format: `projects/{project}/secrets/{secrete}/versions/{version}` - If specified, the `secretmanager.versions.access` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified resource. */\n  credentialSecret?: string;\n}\n\n/** Config for user oauth. This data type is not supported in Gemini API. */\nexport declare interface AuthConfigOauthConfig {\n  /** Access token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time. */\n  accessToken?: string;\n  /** The service account used to generate access tokens for executing the Extension. - If the service account is specified, the `iam.serviceAccounts.getAccessToken` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the provided service account. */\n  serviceAccount?: string;\n}\n\n/** Config for user OIDC auth. This data type is not supported in Gemini API. */\nexport declare interface AuthConfigOidcConfig {\n  /** OpenID Connect formatted ID token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time. */\n  idToken?: string;\n  /** The service account used to generate an OpenID Connect (OIDC)-compatible JWT token signed by the Google OIDC Provider (accounts.google.com) for extension endpoint (https://cloud.google.com/iam/docs/create-short-lived-credentials-direct#sa-credentials-oidc). - The audience for the token will be set to the URL in the server url defined in the OpenApi spec. - If the service account is provided, the service account should grant `iam.serviceAccounts.getOpenIdToken` permission to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents). */\n  serviceAccount?: string;\n}\n\n/** Auth configuration to run the extension. */\nexport declare interface AuthConfig {\n  /** Config for API key auth. */\n  apiKeyConfig?: ApiKeyConfig;\n  /** Type of auth scheme. */\n  authType?: AuthType;\n  /** Config for Google Service Account auth. */\n  googleServiceAccountConfig?: AuthConfigGoogleServiceAccountConfig;\n  /** Config for HTTP Basic auth. */\n  httpBasicAuthConfig?: AuthConfigHttpBasicAuthConfig;\n  /** Config for user oauth. */\n  oauthConfig?: AuthConfigOauthConfig;\n  /** Config for user OIDC auth. */\n  oidcConfig?: AuthConfigOidcConfig;\n}\n\n/** Tool to support Google Maps in Model. */\nexport declare interface GoogleMaps {\n  /** Optional. Auth config for the Google Maps tool. */\n  authConfig?: AuthConfig;\n  /** Optional. If true, include the widget context token in the response. */\n  enableWidget?: boolean;\n}\n\n/** Tool to support URL context retrieval. */\nexport declare interface UrlContext {}\n\n/** Tool to support computer use. */\nexport declare interface ComputerUse {\n  /** Required. The environment being operated. */\n  environment?: Environment;\n  /** By default, predefined functions are included in the final model call.\n    Some of them can be explicitly excluded from being automatically included.\n    This can serve two purposes:\n      1. Using a more restricted / different action space.\n      2. Improving the definitions / instructions of predefined functions. */\n  excludedPredefinedFunctions?: string[];\n}\n\n/** The API secret. This data type is not supported in Gemini API. */\nexport declare interface ApiAuthApiKeyConfig {\n  /** Required. The SecretManager secret version resource name storing API key. e.g. projects/{project}/secrets/{secret}/versions/{version} */\n  apiKeySecretVersion?: string;\n  /** The API key string. Either this or `api_key_secret_version` must be set. */\n  apiKeyString?: string;\n}\n\n/** The generic reusable api auth config. Deprecated. Please use AuthConfig (google/cloud/aiplatform/master/auth.proto) instead. This data type is not supported in Gemini API. */\nexport declare interface ApiAuth {\n  /** The API secret. */\n  apiKeyConfig?: ApiAuthApiKeyConfig;\n}\n\n/** The search parameters to use for the ELASTIC_SEARCH spec. This data type is not supported in Gemini API. */\nexport declare interface ExternalApiElasticSearchParams {\n  /** The ElasticSearch index to use. */\n  index?: string;\n  /** Optional. Number of hits (chunks) to request. When specified, it is passed to Elasticsearch as the `num_hits` param. */\n  numHits?: number;\n  /** The ElasticSearch search template to use. */\n  searchTemplate?: string;\n}\n\n/** The search parameters to use for SIMPLE_SEARCH spec. This data type is not supported in Gemini API. */\nexport declare interface ExternalApiSimpleSearchParams {}\n\n/** Retrieve from data source powered by external API for grounding. The external API is not owned by Google, but need to follow the pre-defined API spec. This data type is not supported in Gemini API. */\nexport declare interface ExternalApi {\n  /** The authentication config to access the API. Deprecated. Please use auth_config instead. */\n  apiAuth?: ApiAuth;\n  /** The API spec that the external API implements. */\n  apiSpec?: ApiSpec;\n  /** The authentication config to access the API. */\n  authConfig?: AuthConfig;\n  /** Parameters for the elastic search API. */\n  elasticSearchParams?: ExternalApiElasticSearchParams;\n  /** The endpoint of the external API. The system will call the API at this endpoint to retrieve the data for grounding. Example: https://acme.com:443/search */\n  endpoint?: string;\n  /** Parameters for the simple search API. */\n  simpleSearchParams?: ExternalApiSimpleSearchParams;\n}\n\n/** Define data stores within engine to filter on in a search call and configurations for those data stores. For more information, see https://cloud.google.com/generative-ai-app-builder/docs/reference/rpc/google.cloud.discoveryengine.v1#datastorespec. This data type is not supported in Gemini API. */\nexport declare interface VertexAISearchDataStoreSpec {\n  /** Full resource name of DataStore, such as Format: `projects/{project}/locations/{location}/collections/{collection}/dataStores/{dataStore}` */\n  dataStore?: string;\n  /** Optional. Filter specification to filter documents in the data store specified by data_store field. For more information on filtering, see [Filtering](https://cloud.google.com/generative-ai-app-builder/docs/filter-search-metadata) */\n  filter?: string;\n}\n\n/** Retrieve from Vertex AI Search datastore or engine for grounding. datastore and engine are mutually exclusive. See https://cloud.google.com/products/agent-builder. This data type is not supported in Gemini API. */\nexport declare interface VertexAISearch {\n  /** Specifications that define the specific DataStores to be searched, along with configurations for those data stores. This is only considered for Engines with multiple data stores. It should only be set if engine is used. */\n  dataStoreSpecs?: VertexAISearchDataStoreSpec[];\n  /** Optional. Fully-qualified Vertex AI Search data store resource ID. Format: `projects/{project}/locations/{location}/collections/{collection}/dataStores/{dataStore}` */\n  datastore?: string;\n  /** Optional. Fully-qualified Vertex AI Search engine resource ID. Format: `projects/{project}/locations/{location}/collections/{collection}/engines/{engine}` */\n  engine?: string;\n  /** Optional. Filter strings to be passed to the search API. */\n  filter?: string;\n  /** Optional. Number of search results to return per query. The default value is 10. The maximumm allowed value is 10. */\n  maxResults?: number;\n}\n\n/** The definition of the Rag resource. This data type is not supported in Gemini API. */\nexport declare interface VertexRagStoreRagResource {\n  /** Optional. RagCorpora resource name. Format: `projects/{project}/locations/{location}/ragCorpora/{rag_corpus}` */\n  ragCorpus?: string;\n  /** Optional. rag_file_id. The files should be in the same rag_corpus set in rag_corpus field. */\n  ragFileIds?: string[];\n}\n\n/** Config for filters. This data type is not supported in Gemini API. */\nexport declare interface RagRetrievalConfigFilter {\n  /** Optional. String for metadata filtering. */\n  metadataFilter?: string;\n  /** Optional. Only returns contexts with vector distance smaller than the threshold. */\n  vectorDistanceThreshold?: number;\n  /** Optional. Only returns contexts with vector similarity larger than the threshold. */\n  vectorSimilarityThreshold?: number;\n}\n\n/** Config for Hybrid Search. This data type is not supported in Gemini API. */\nexport declare interface RagRetrievalConfigHybridSearch {\n  /** Optional. Alpha value controls the weight between dense and sparse vector search results. The range is [0, 1], while 0 means sparse vector search only and 1 means dense vector search only. The default value is 0.5 which balances sparse and dense vector search equally. */\n  alpha?: number;\n}\n\n/** Config for LlmRanker. This data type is not supported in Gemini API. */\nexport declare interface RagRetrievalConfigRankingLlmRanker {\n  /** Optional. The model name used for ranking. See [Supported models](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#supported-models). */\n  modelName?: string;\n}\n\n/** Config for Rank Service. This data type is not supported in Gemini API. */\nexport declare interface RagRetrievalConfigRankingRankService {\n  /** Optional. The model name of the rank service. Format: `semantic-ranker-512@latest` */\n  modelName?: string;\n}\n\n/** Config for ranking and reranking. This data type is not supported in Gemini API. */\nexport declare interface RagRetrievalConfigRanking {\n  /** Optional. Config for LlmRanker. */\n  llmRanker?: RagRetrievalConfigRankingLlmRanker;\n  /** Optional. Config for Rank Service. */\n  rankService?: RagRetrievalConfigRankingRankService;\n}\n\n/** Specifies the context retrieval config. This data type is not supported in Gemini API. */\nexport declare interface RagRetrievalConfig {\n  /** Optional. Config for filters. */\n  filter?: RagRetrievalConfigFilter;\n  /** Optional. Config for Hybrid Search. */\n  hybridSearch?: RagRetrievalConfigHybridSearch;\n  /** Optional. Config for ranking and reranking. */\n  ranking?: RagRetrievalConfigRanking;\n  /** Optional. The number of contexts to retrieve. */\n  topK?: number;\n}\n\n/** Retrieve from Vertex RAG Store for grounding. This data type is not supported in Gemini API. */\nexport declare interface VertexRagStore {\n  /** Optional. Deprecated. Please use rag_resources instead. */\n  ragCorpora?: string[];\n  /** Optional. The representation of the rag source. It can be used to specify corpus only or ragfiles. Currently only support one corpus or multiple files from one corpus. In the future we may open up multiple corpora support. */\n  ragResources?: VertexRagStoreRagResource[];\n  /** Optional. The retrieval config for the Rag query. */\n  ragRetrievalConfig?: RagRetrievalConfig;\n  /** Optional. Number of top k results to return from the selected corpora. */\n  similarityTopK?: number;\n  /** Optional. Currently only supported for Gemini Multimodal Live API. In Gemini Multimodal Live API, if `store_context` bool is specified, Gemini will leverage it to automatically memorize the interactions between the client and Gemini, and retrieve context when needed to augment the response generation for users' ongoing and future interactions. */\n  storeContext?: boolean;\n  /** Optional. Only return results with vector distance smaller than the threshold. */\n  vectorDistanceThreshold?: number;\n}\n\n/** Defines a retrieval tool that model can call to access external knowledge. This data type is not supported in Gemini API. */\nexport declare interface Retrieval {\n  /** Optional. Deprecated. This option is no longer supported. */\n  disableAttribution?: boolean;\n  /** Use data source powered by external API for grounding. */\n  externalApi?: ExternalApi;\n  /** Set to use data source powered by Vertex AI Search. */\n  vertexAiSearch?: VertexAISearch;\n  /** Set to use data source powered by Vertex RAG store. User data is uploaded via the VertexRagDataService. */\n  vertexRagStore?: VertexRagStore;\n}\n\n/** Tool that executes code generated by the model, and automatically returns the result to the model. See also [ExecutableCode]and [CodeExecutionResult] which are input and output to this tool. This data type is not supported in Gemini API. */\nexport declare interface ToolCodeExecution {}\n\n/** Tool details of a tool that the model may use to generate a response. */\nexport declare interface Tool {\n  /** List of function declarations that the tool supports. */\n  functionDeclarations?: FunctionDeclaration[];\n  /** Optional. Retrieval tool type. System will always execute the provided retrieval tool(s) to get external knowledge to answer the prompt. Retrieval results are presented to the model for generation. This field is not supported in Gemini API. */\n  retrieval?: Retrieval;\n  /** Optional. Google Search tool type. Specialized retrieval tool\n      that is powered by Google Search. */\n  googleSearch?: GoogleSearch;\n  /** Optional. GoogleSearchRetrieval tool type. Specialized retrieval tool that is powered by Google search. */\n  googleSearchRetrieval?: GoogleSearchRetrieval;\n  /** Optional. Enterprise web search tool type. Specialized retrieval\n      tool that is powered by Vertex AI Search and Sec4 compliance. */\n  enterpriseWebSearch?: EnterpriseWebSearch;\n  /** Optional. Google Maps tool type. Specialized retrieval tool\n      that is powered by Google Maps. */\n  googleMaps?: GoogleMaps;\n  /** Optional. Tool to support URL context retrieval. */\n  urlContext?: UrlContext;\n  /** Optional. Tool to support the model interacting directly with the\n      computer. If enabled, it automatically populates computer-use specific\n      Function Declarations. */\n  computerUse?: ComputerUse;\n  /** Optional. CodeExecution tool type. Enables the model to execute code as part of generation. */\n  codeExecution?: ToolCodeExecution;\n}\n\n/** Function calling config. */\nexport declare interface FunctionCallingConfig {\n  /** Optional. Function calling mode. */\n  mode?: FunctionCallingConfigMode;\n  /** Optional. Function names to call. Only set when the Mode is ANY. Function names should match [FunctionDeclaration.name]. With mode set to ANY, model will predict a function call from the set of function names provided. */\n  allowedFunctionNames?: string[];\n}\n\n/** An object that represents a latitude/longitude pair.\n\nThis is expressed as a pair of doubles to represent degrees latitude and\ndegrees longitude. Unless specified otherwise, this object must conform to the\n<a href=\"https://en.wikipedia.org/wiki/World_Geodetic_System#1984_version\">\nWGS84 standard</a>. Values must be within normalized ranges. */\nexport declare interface LatLng {\n  /** The latitude in degrees. It must be in the range [-90.0, +90.0]. */\n  latitude?: number;\n  /** The longitude in degrees. It must be in the range [-180.0, +180.0] */\n  longitude?: number;\n}\n\n/** Retrieval config.\n */\nexport declare interface RetrievalConfig {\n  /** Optional. The location of the user. */\n  latLng?: LatLng;\n  /** The language code of the user. */\n  languageCode?: string;\n}\n\n/** Tool config.\n\nThis config is shared for all tools provided in the request. */\nexport declare interface ToolConfig {\n  /** Optional. Function calling config. */\n  functionCallingConfig?: FunctionCallingConfig;\n  /** Optional. Retrieval config. */\n  retrievalConfig?: RetrievalConfig;\n}\n\n/** The configuration for the prebuilt speaker to use. */\nexport declare interface PrebuiltVoiceConfig {\n  /** The name of the prebuilt voice to use. */\n  voiceName?: string;\n}\n\n/** The configuration for the voice to use. */\nexport declare interface VoiceConfig {\n  /** The configuration for the speaker to use.\n   */\n  prebuiltVoiceConfig?: PrebuiltVoiceConfig;\n}\n\n/** The configuration for the speaker to use. */\nexport declare interface SpeakerVoiceConfig {\n  /** The name of the speaker to use. Should be the same as in the\n          prompt. */\n  speaker?: string;\n  /** The configuration for the voice to use. */\n  voiceConfig?: VoiceConfig;\n}\n\n/** The configuration for the multi-speaker setup. */\nexport declare interface MultiSpeakerVoiceConfig {\n  /** The configuration for the speaker to use. */\n  speakerVoiceConfigs?: SpeakerVoiceConfig[];\n}\n\n/** The speech generation configuration. */\nexport declare interface SpeechConfig {\n  /** The configuration for the speaker to use.\n   */\n  voiceConfig?: VoiceConfig;\n  /** The configuration for the multi-speaker setup.\n          It is mutually exclusive with the voice_config field.\n           */\n  multiSpeakerVoiceConfig?: MultiSpeakerVoiceConfig;\n  /** Language code (ISO 639. e.g. en-US) for the speech synthesization.\n      Only available for Live API.\n       */\n  languageCode?: string;\n}\n\n/** The configuration for automatic function calling. */\nexport declare interface AutomaticFunctionCallingConfig {\n  /** Whether to disable automatic function calling.\n      If not set or set to False, will enable automatic function calling.\n      If set to True, will disable automatic function calling.\n       */\n  disable?: boolean;\n  /** If automatic function calling is enabled,\n      maximum number of remote calls for automatic function calling.\n      This number should be a positive integer.\n      If not set, SDK will set maximum number of remote calls to 10.\n       */\n  maximumRemoteCalls?: number;\n  /** If automatic function calling is enabled,\n      whether to ignore call history to the response.\n      If not set, SDK will set ignore_call_history to false,\n      and will append the call history to\n      GenerateContentResponse.automatic_function_calling_history.\n       */\n  ignoreCallHistory?: boolean;\n}\n\n/** The thinking features configuration. */\nexport declare interface ThinkingConfig {\n  /** Indicates whether to include thoughts in the response. If true, thoughts are returned only if the model supports thought and thoughts are available.\n   */\n  includeThoughts?: boolean;\n  /** Indicates the thinking budget in tokens. 0 is DISABLED. -1 is AUTOMATIC. The default values and allowed ranges are model dependent.\n   */\n  thinkingBudget?: number;\n}\n\n/** The image generation configuration to be used in GenerateContentConfig. */\nexport declare interface ImageConfig {\n  /** Aspect ratio of the generated images. Supported values are\n      \"1:1\", \"2:3\", \"3:2\", \"3:4\", \"4:3\", \"9:16\", \"16:9\", and \"21:9\". */\n  aspectRatio?: string;\n}\n\n/** When automated routing is specified, the routing will be determined by the pretrained routing model and customer provided model routing preference. This data type is not supported in Gemini API. */\nexport declare interface GenerationConfigRoutingConfigAutoRoutingMode {\n  /** The model routing preference. */\n  modelRoutingPreference?:\n    | 'UNKNOWN'\n    | 'PRIORITIZE_QUALITY'\n    | 'BALANCED'\n    | 'PRIORITIZE_COST';\n}\n\n/** When manual routing is set, the specified model will be used directly. This data type is not supported in Gemini API. */\nexport declare interface GenerationConfigRoutingConfigManualRoutingMode {\n  /** The model name to use. Only the public LLM models are accepted. See [Supported models](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#supported-models). */\n  modelName?: string;\n}\n\n/** The configuration for routing the request to a specific model. This data type is not supported in Gemini API. */\nexport declare interface GenerationConfigRoutingConfig {\n  /** Automated routing. */\n  autoMode?: GenerationConfigRoutingConfigAutoRoutingMode;\n  /** Manual routing. */\n  manualMode?: GenerationConfigRoutingConfigManualRoutingMode;\n}\n\n/** Optional model configuration parameters.\n\nFor more information, see `Content generation parameters\n<https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/content-generation-parameters>`_. */\nexport declare interface GenerateContentConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n  /** Instructions for the model to steer it toward better performance.\n      For example, \"Answer as concisely as possible\" or \"Don't use technical\n      terms in your response\".\n       */\n  systemInstruction?: ContentUnion;\n  /** Value that controls the degree of randomness in token selection.\n      Lower temperatures are good for prompts that require a less open-ended or\n      creative response, while higher temperatures can lead to more diverse or\n      creative results.\n       */\n  temperature?: number;\n  /** Tokens are selected from the most to least probable until the sum\n      of their probabilities equals this value. Use a lower value for less\n      random responses and a higher value for more random responses.\n       */\n  topP?: number;\n  /** For each token selection step, the ``top_k`` tokens with the\n      highest probabilities are sampled. Then tokens are further filtered based\n      on ``top_p`` with the final token selected using temperature sampling. Use\n      a lower number for less random responses and a higher number for more\n      random responses.\n       */\n  topK?: number;\n  /** Number of response variations to return.\n   */\n  candidateCount?: number;\n  /** Maximum number of tokens that can be generated in the response.\n   */\n  maxOutputTokens?: number;\n  /** List of strings that tells the model to stop generating text if one\n      of the strings is encountered in the response.\n       */\n  stopSequences?: string[];\n  /** Whether to return the log probabilities of the tokens that were\n      chosen by the model at each step.\n       */\n  responseLogprobs?: boolean;\n  /** Number of top candidate tokens to return the log probabilities for\n      at each generation step.\n       */\n  logprobs?: number;\n  /** Positive values penalize tokens that already appear in the\n      generated text, increasing the probability of generating more diverse\n      content.\n       */\n  presencePenalty?: number;\n  /** Positive values penalize tokens that repeatedly appear in the\n      generated text, increasing the probability of generating more diverse\n      content.\n       */\n  frequencyPenalty?: number;\n  /** When ``seed`` is fixed to a specific number, the model makes a best\n      effort to provide the same response for repeated requests. By default, a\n      random number is used.\n       */\n  seed?: number;\n  /** Output response mimetype of the generated candidate text.\n      Supported mimetype:\n        - `text/plain`: (default) Text output.\n        - `application/json`: JSON response in the candidates.\n      The model needs to be prompted to output the appropriate response type,\n      otherwise the behavior is undefined.\n      This is a preview feature.\n       */\n  responseMimeType?: string;\n  /** The `Schema` object allows the definition of input and output data types.\n      These types can be objects, but also primitives and arrays.\n      Represents a select subset of an [OpenAPI 3.0 schema\n      object](https://spec.openapis.org/oas/v3.0.3#schema).\n      If set, a compatible response_mime_type must also be set.\n      Compatible mimetypes: `application/json`: Schema for JSON response.\n       */\n  responseSchema?: SchemaUnion;\n  /** Optional. Output schema of the generated response.\n      This is an alternative to `response_schema` that accepts [JSON\n      Schema](https://json-schema.org/). If set, `response_schema` must be\n      omitted, but `response_mime_type` is required. While the full JSON Schema\n      may be sent, not all features are supported. Specifically, only the\n      following properties are supported: - `$id` - `$defs` - `$ref` - `$anchor`\n      - `type` - `format` - `title` - `description` - `enum` (for strings and\n      numbers) - `items` - `prefixItems` - `minItems` - `maxItems` - `minimum` -\n      `maximum` - `anyOf` - `oneOf` (interpreted the same as `anyOf`) -\n      `properties` - `additionalProperties` - `required` The non-standard\n      `propertyOrdering` property may also be set. Cyclic references are\n      unrolled to a limited degree and, as such, may only be used within\n      non-required properties. (Nullable properties are not sufficient.) If\n      `$ref` is set on a sub-schema, no other properties, except for than those\n      starting as a `$`, may be set. */\n  responseJsonSchema?: unknown;\n  /** Configuration for model router requests.\n   */\n  routingConfig?: GenerationConfigRoutingConfig;\n  /** Configuration for model selection.\n   */\n  modelSelectionConfig?: ModelSelectionConfig;\n  /** Safety settings in the request to block unsafe content in the\n      response.\n       */\n  safetySettings?: SafetySetting[];\n  /** Code that enables the system to interact with external systems to\n      perform an action outside of the knowledge and scope of the model.\n       */\n  tools?: ToolListUnion;\n  /** Associates model output to a specific function call.\n   */\n  toolConfig?: ToolConfig;\n  /** Labels with user-defined metadata to break down billed charges. */\n  labels?: Record<string, string>;\n  /** Resource name of a context cache that can be used in subsequent\n      requests.\n       */\n  cachedContent?: string;\n  /** The requested modalities of the response. Represents the set of\n      modalities that the model can return.\n       */\n  responseModalities?: string[];\n  /** If specified, the media resolution specified will be used.\n   */\n  mediaResolution?: MediaResolution;\n  /** The speech generation configuration.\n   */\n  speechConfig?: SpeechConfigUnion;\n  /** If enabled, audio timestamp will be included in the request to the\n       model.\n       */\n  audioTimestamp?: boolean;\n  /** The configuration for automatic function calling.\n   */\n  automaticFunctionCalling?: AutomaticFunctionCallingConfig;\n  /** The thinking features configuration.\n   */\n  thinkingConfig?: ThinkingConfig;\n  /** The image generation configuration.\n   */\n  imageConfig?: ImageConfig;\n}\n\n/** Config for models.generate_content parameters. */\nexport declare interface GenerateContentParameters {\n  /** ID of the model to use. For a list of models, see `Google models\n    <https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models>`_. */\n  model: string;\n  /** Content of the request.\n   */\n  contents: ContentListUnion;\n  /** Configuration that contains optional model parameters.\n   */\n  config?: GenerateContentConfig;\n}\n\n/** A wrapper class for the http response. */\nexport class HttpResponse {\n  /** Used to retain the processed HTTP headers in the response. */\n  headers?: Record<string, string>;\n  /**\n   * The original http response.\n   */\n  responseInternal: Response;\n\n  constructor(response: Response) {\n    // Process the headers.\n    const headers: Record<string, string> = {};\n    for (const pair of response.headers.entries()) {\n      headers[pair[0]] = pair[1];\n    }\n    this.headers = headers;\n\n    // Keep the original response.\n    this.responseInternal = response;\n  }\n\n  json(): Promise<unknown> {\n    return this.responseInternal.json();\n  }\n}\n\n/** Callbacks for the live API. */\nexport interface LiveCallbacks {\n  /**\n   * Called when the websocket connection is established.\n   */\n  onopen?: (() => void) | null;\n  /**\n   * Called when a message is received from the server.\n   */\n  onmessage: (e: LiveServerMessage) => void;\n  /**\n   * Called when an error occurs.\n   */\n  onerror?: ((e: ErrorEvent) => void) | null;\n  /**\n   * Called when the websocket connection is closed.\n   */\n  onclose?: ((e: CloseEvent) => void) | null;\n}\n\n/** Represents a whole or partial calendar date, such as a birthday. The time of day and time zone are either specified elsewhere or are insignificant. The date is relative to the Gregorian Calendar. This can represent one of the following: * A full date, with non-zero year, month, and day values. * A month and day, with a zero year (for example, an anniversary). * A year on its own, with a zero month and a zero day. * A year and month, with a zero day (for example, a credit card expiration date). Related types: * google.type.TimeOfDay * google.type.DateTime * google.protobuf.Timestamp. This data type is not supported in Gemini API. */\nexport declare interface GoogleTypeDate {\n  /** Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant. */\n  day?: number;\n  /** Month of a year. Must be from 1 to 12, or 0 to specify a year without a month and day. */\n  month?: number;\n  /** Year of the date. Must be from 1 to 9999, or 0 to specify a date without a year. */\n  year?: number;\n}\n\n/** Source attributions for content. This data type is not supported in Gemini API. */\nexport declare interface Citation {\n  /** Output only. End index into the content. */\n  endIndex?: number;\n  /** Output only. License of the attribution. */\n  license?: string;\n  /** Output only. Publication date of the attribution. */\n  publicationDate?: GoogleTypeDate;\n  /** Output only. Start index into the content. */\n  startIndex?: number;\n  /** Output only. Title of the attribution. */\n  title?: string;\n  /** Output only. Url reference of the attribution. */\n  uri?: string;\n}\n\n/** Citation information when the model quotes another source. */\nexport declare interface CitationMetadata {\n  /** Contains citation information when the model directly quotes, at\n      length, from another source. Can include traditional websites and code\n      repositories.\n       */\n  citations?: Citation[];\n}\n\n/** Context for a single url retrieval. */\nexport declare interface UrlMetadata {\n  /** The URL retrieved by the tool. */\n  retrievedUrl?: string;\n  /** Status of the url retrieval. */\n  urlRetrievalStatus?: UrlRetrievalStatus;\n}\n\n/** Metadata related to url context retrieval tool. */\nexport declare interface UrlContextMetadata {\n  /** List of url context. */\n  urlMetadata?: UrlMetadata[];\n}\n\n/** Author attribution for a photo or review. This data type is not supported in Gemini API. */\nexport declare interface GroundingChunkMapsPlaceAnswerSourcesAuthorAttribution {\n  /** Name of the author of the Photo or Review. */\n  displayName?: string;\n  /** Profile photo URI of the author of the Photo or Review. */\n  photoUri?: string;\n  /** URI of the author of the Photo or Review. */\n  uri?: string;\n}\n\n/** Encapsulates a review snippet. This data type is not supported in Gemini API. */\nexport declare interface GroundingChunkMapsPlaceAnswerSourcesReviewSnippet {\n  /** This review's author. */\n  authorAttribution?: GroundingChunkMapsPlaceAnswerSourcesAuthorAttribution;\n  /** A link where users can flag a problem with the review. */\n  flagContentUri?: string;\n  /** A link to show the review on Google Maps. */\n  googleMapsUri?: string;\n  /** A string of formatted recent time, expressing the review time relative to the current time in a form appropriate for the language and country. */\n  relativePublishTimeDescription?: string;\n  /** A reference representing this place review which may be used to look up this place review again. */\n  review?: string;\n  /** Id of the review referencing the place. */\n  reviewId?: string;\n  /** Title of the review. */\n  title?: string;\n}\n\n/** Sources used to generate the place answer. This data type is not supported in Gemini API. */\nexport declare interface GroundingChunkMapsPlaceAnswerSources {\n  /** A link where users can flag a problem with the generated answer. */\n  flagContentUri?: string;\n  /** Snippets of reviews that are used to generate the answer. */\n  reviewSnippets?: GroundingChunkMapsPlaceAnswerSourcesReviewSnippet[];\n}\n\n/** Chunk from Google Maps. This data type is not supported in Gemini API. */\nexport declare interface GroundingChunkMaps {\n  /** Sources used to generate the place answer. This includes review snippets and photos that were used to generate the answer, as well as uris to flag content. */\n  placeAnswerSources?: GroundingChunkMapsPlaceAnswerSources;\n  /** This Place's resource name, in `places/{place_id}` format. Can be used to look up the Place. */\n  placeId?: string;\n  /** Text of the chunk. */\n  text?: string;\n  /** Title of the chunk. */\n  title?: string;\n  /** URI reference of the chunk. */\n  uri?: string;\n}\n\n/** Represents where the chunk starts and ends in the document. This data type is not supported in Gemini API. */\nexport declare interface RagChunkPageSpan {\n  /** Page where chunk starts in the document. Inclusive. 1-indexed. */\n  firstPage?: number;\n  /** Page where chunk ends in the document. Inclusive. 1-indexed. */\n  lastPage?: number;\n}\n\n/** A RagChunk includes the content of a chunk of a RagFile, and associated metadata. This data type is not supported in Gemini API. */\nexport declare interface RagChunk {\n  /** If populated, represents where the chunk starts and ends in the document. */\n  pageSpan?: RagChunkPageSpan;\n  /** The content of the chunk. */\n  text?: string;\n}\n\n/** Chunk from context retrieved by the retrieval tools. This data type is not supported in Gemini API. */\nexport declare interface GroundingChunkRetrievedContext {\n  /** Output only. The full document name for the referenced Vertex AI Search document. */\n  documentName?: string;\n  /** Additional context for the RAG retrieval result. This is only populated when using the RAG retrieval tool. */\n  ragChunk?: RagChunk;\n  /** Text of the attribution. */\n  text?: string;\n  /** Title of the attribution. */\n  title?: string;\n  /** URI reference of the attribution. */\n  uri?: string;\n}\n\n/** Chunk from the web. */\nexport declare interface GroundingChunkWeb {\n  /** Domain of the (original) URI. This field is not supported in Gemini API. */\n  domain?: string;\n  /** Title of the chunk. */\n  title?: string;\n  /** URI reference of the chunk. */\n  uri?: string;\n}\n\n/** Grounding chunk. */\nexport declare interface GroundingChunk {\n  /** Grounding chunk from Google Maps. This field is not supported in Gemini API. */\n  maps?: GroundingChunkMaps;\n  /** Grounding chunk from context retrieved by the retrieval tools. This field is not supported in Gemini API. */\n  retrievedContext?: GroundingChunkRetrievedContext;\n  /** Grounding chunk from the web. */\n  web?: GroundingChunkWeb;\n}\n\n/** Segment of the content. */\nexport declare interface Segment {\n  /** Output only. End index in the given Part, measured in bytes. Offset from the start of the Part, exclusive, starting at zero. */\n  endIndex?: number;\n  /** Output only. The index of a Part object within its parent Content object. */\n  partIndex?: number;\n  /** Output only. Start index in the given Part, measured in bytes. Offset from the start of the Part, inclusive, starting at zero. */\n  startIndex?: number;\n  /** Output only. The text corresponding to the segment from the response. */\n  text?: string;\n}\n\n/** Grounding support. */\nexport declare interface GroundingSupport {\n  /** Confidence score of the support references. Ranges from 0 to 1. 1 is the most confident. For Gemini 2.0 and before, this list must have the same size as the grounding_chunk_indices. For Gemini 2.5 and after, this list will be empty and should be ignored. */\n  confidenceScores?: number[];\n  /** A list of indices (into 'grounding_chunk') specifying the citations associated with the claim. For instance [1,3,4] means that grounding_chunk[1], grounding_chunk[3], grounding_chunk[4] are the retrieved content attributed to the claim. */\n  groundingChunkIndices?: number[];\n  /** Segment of the content this support belongs to. */\n  segment?: Segment;\n}\n\n/** Metadata related to retrieval in the grounding flow. */\nexport declare interface RetrievalMetadata {\n  /** Optional. Score indicating how likely information from Google Search could help answer the prompt. The score is in the range `[0, 1]`, where 0 is the least likely and 1 is the most likely. This score is only populated when Google Search grounding and dynamic retrieval is enabled. It will be compared to the threshold to determine whether to trigger Google Search. */\n  googleSearchDynamicRetrievalScore?: number;\n}\n\n/** Google search entry point. */\nexport declare interface SearchEntryPoint {\n  /** Optional. Web content snippet that can be embedded in a web page or an app webview. */\n  renderedContent?: string;\n  /** Optional. Base64 encoded JSON representing array of tuple.\n   * @remarks Encoded as base64 string. */\n  sdkBlob?: string;\n}\n\n/** Source content flagging uri for a place or review. This is currently populated only for Google Maps grounding. This data type is not supported in Gemini API. */\nexport declare interface GroundingMetadataSourceFlaggingUri {\n  /** A link where users can flag a problem with the source (place or review). */\n  flagContentUri?: string;\n  /** Id of the place or review. */\n  sourceId?: string;\n}\n\n/** Metadata returned to client when grounding is enabled. */\nexport declare interface GroundingMetadata {\n  /** Optional. Output only. Resource name of the Google Maps widget context token to be used with the PlacesContextElement widget to render contextual data. This is populated only for Google Maps grounding. This field is not supported in Gemini API. */\n  googleMapsWidgetContextToken?: string;\n  /** List of supporting references retrieved from specified grounding source. */\n  groundingChunks?: GroundingChunk[];\n  /** Optional. List of grounding support. */\n  groundingSupports?: GroundingSupport[];\n  /** Optional. Output only. Retrieval metadata. */\n  retrievalMetadata?: RetrievalMetadata;\n  /** Optional. Queries executed by the retrieval tools. This field is not supported in Gemini API. */\n  retrievalQueries?: string[];\n  /** Optional. Google search entry for the following-up web searches. */\n  searchEntryPoint?: SearchEntryPoint;\n  /** Optional. Output only. List of source flagging uris. This is currently populated only for Google Maps grounding. This field is not supported in Gemini API. */\n  sourceFlaggingUris?: GroundingMetadataSourceFlaggingUri[];\n  /** Optional. Web search queries for the following-up web search. */\n  webSearchQueries?: string[];\n}\n\n/** Candidate for the logprobs token and score. */\nexport declare interface LogprobsResultCandidate {\n  /** The candidate's log probability. */\n  logProbability?: number;\n  /** The candidate's token string value. */\n  token?: string;\n  /** The candidate's token id value. */\n  tokenId?: number;\n}\n\n/** Candidates with top log probabilities at each decoding step. */\nexport declare interface LogprobsResultTopCandidates {\n  /** Sorted by log probability in descending order. */\n  candidates?: LogprobsResultCandidate[];\n}\n\n/** Logprobs Result */\nexport declare interface LogprobsResult {\n  /** Length = total number of decoding steps. The chosen candidates may or may not be in top_candidates. */\n  chosenCandidates?: LogprobsResultCandidate[];\n  /** Length = total number of decoding steps. */\n  topCandidates?: LogprobsResultTopCandidates[];\n}\n\n/** Safety rating corresponding to the generated content. */\nexport declare interface SafetyRating {\n  /** Output only. Indicates whether the content was filtered out because of this rating. */\n  blocked?: boolean;\n  /** Output only. Harm category. */\n  category?: HarmCategory;\n  /** Output only. The overwritten threshold for the safety category of Gemini 2.0 image out. If minors are detected in the output image, the threshold of each safety category will be overwritten if user sets a lower threshold. */\n  overwrittenThreshold?: HarmBlockThreshold;\n  /** Output only. Harm probability levels in the content. */\n  probability?: HarmProbability;\n  /** Output only. Harm probability score. This field is not supported in Gemini API. */\n  probabilityScore?: number;\n  /** Output only. Harm severity levels in the content. */\n  severity?: HarmSeverity;\n  /** Output only. Harm severity score. This field is not supported in Gemini API. */\n  severityScore?: number;\n}\n\n/** A response candidate generated from the model. */\nexport declare interface Candidate {\n  /** Contains the multi-part content of the response.\n   */\n  content?: Content;\n  /** Source attribution of the generated content.\n   */\n  citationMetadata?: CitationMetadata;\n  /** Describes the reason the model stopped generating tokens.\n   */\n  finishMessage?: string;\n  /** Number of tokens for this candidate.\n   */\n  tokenCount?: number;\n  /** The reason why the model stopped generating tokens.\n      If empty, the model has not stopped generating the tokens.\n       */\n  finishReason?: FinishReason;\n  /** Metadata related to url context retrieval tool. */\n  urlContextMetadata?: UrlContextMetadata;\n  /** Output only. Average log probability score of the candidate. */\n  avgLogprobs?: number;\n  /** Output only. Metadata specifies sources used to ground generated content. */\n  groundingMetadata?: GroundingMetadata;\n  /** Output only. Index of the candidate. */\n  index?: number;\n  /** Output only. Log-likelihood scores for the response tokens and top tokens */\n  logprobsResult?: LogprobsResult;\n  /** Output only. List of ratings for the safety of a response candidate. There is at most one rating per category. */\n  safetyRatings?: SafetyRating[];\n}\n\n/** Content filter results for a prompt sent in the request. Note: This is sent only in the first stream chunk and only if no candidates were generated due to content violations. */\nexport class GenerateContentResponsePromptFeedback {\n  /** Output only. The reason why the prompt was blocked. */\n  blockReason?: BlockedReason;\n  /** Output only. A readable message that explains the reason why the prompt was blocked. This field is not supported in Gemini API. */\n  blockReasonMessage?: string;\n  /** Output only. A list of safety ratings for the prompt. There is one rating per category. */\n  safetyRatings?: SafetyRating[];\n}\n\n/** Represents token counting info for a single modality. */\nexport declare interface ModalityTokenCount {\n  /** The modality associated with this token count. */\n  modality?: MediaModality;\n  /** Number of tokens. */\n  tokenCount?: number;\n}\n\n/** Usage metadata about response(s). This data type is not supported in Gemini API. */\nexport class GenerateContentResponseUsageMetadata {\n  /** Output only. List of modalities of the cached content in the request input. */\n  cacheTokensDetails?: ModalityTokenCount[];\n  /** Output only. Number of tokens in the cached part in the input (the cached content). */\n  cachedContentTokenCount?: number;\n  /** Number of tokens in the response(s). */\n  candidatesTokenCount?: number;\n  /** Output only. List of modalities that were returned in the response. */\n  candidatesTokensDetails?: ModalityTokenCount[];\n  /** Number of tokens in the request. When `cached_content` is set, this is still the total effective prompt size meaning this includes the number of tokens in the cached content. */\n  promptTokenCount?: number;\n  /** Output only. List of modalities that were processed in the request input. */\n  promptTokensDetails?: ModalityTokenCount[];\n  /** Output only. Number of tokens present in thoughts output. */\n  thoughtsTokenCount?: number;\n  /** Output only. Number of tokens present in tool-use prompt(s). */\n  toolUsePromptTokenCount?: number;\n  /** Output only. List of modalities that were processed for tool-use request inputs. */\n  toolUsePromptTokensDetails?: ModalityTokenCount[];\n  /** Total token count for prompt, response candidates, and tool-use prompts (if present). */\n  totalTokenCount?: number;\n  /** Output only. Traffic type. This shows whether a request consumes Pay-As-You-Go or Provisioned Throughput quota. */\n  trafficType?: TrafficType;\n}\n\n/** Response message for PredictionService.GenerateContent. */\nexport class GenerateContentResponse {\n  /** Used to retain the full HTTP response. */\n  sdkHttpResponse?: HttpResponse;\n  /** Response variations returned by the model.\n   */\n  candidates?: Candidate[];\n  /** Timestamp when the request is made to the server.\n   */\n  createTime?: string;\n  /** The history of automatic function calling.\n   */\n  automaticFunctionCallingHistory?: Content[];\n  /** Output only. The model version used to generate the response. */\n  modelVersion?: string;\n  /** Output only. Content filter results for a prompt sent in the request. Note: Sent only in the first stream chunk. Only happens when no candidates were generated due to content violations. */\n  promptFeedback?: GenerateContentResponsePromptFeedback;\n  /** Output only. response_id is used to identify each response. It is the encoding of the event_id. */\n  responseId?: string;\n  /** Usage metadata about the response(s). */\n  usageMetadata?: GenerateContentResponseUsageMetadata;\n  /**\n   * Returns the concatenation of all text parts from the first candidate in the response.\n   *\n   * @remarks\n   * If there are multiple candidates in the response, the text from the first\n   * one will be returned.\n   * If there are non-text parts in the response, the concatenation of all text\n   * parts will be returned, and a warning will be logged.\n   * If there are thought parts in the response, the concatenation of all text\n   * parts excluding the thought parts will be returned.\n   *\n   * @example\n   * ```ts\n   * const response = await ai.models.generateContent({\n   *   model: 'gemini-2.0-flash',\n   *   contents:\n   *     'Why is the sky blue?',\n   * });\n   *\n   * console.debug(response.text);\n   * ```\n   */\n  get text(): string | undefined {\n    if (this.candidates?.[0]?.content?.parts?.length === 0) {\n      return undefined;\n    }\n    if (this.candidates && this.candidates.length > 1) {\n      console.warn(\n        'there are multiple candidates in the response, returning text from the first one.',\n      );\n    }\n    let text = '';\n    let anyTextPartText = false;\n    const nonTextParts = [];\n    for (const part of this.candidates?.[0]?.content?.parts ?? []) {\n      for (const [fieldName, fieldValue] of Object.entries(part)) {\n        if (\n          fieldName !== 'text' &&\n          fieldName !== 'thought' &&\n          (fieldValue !== null || fieldValue !== undefined)\n        ) {\n          nonTextParts.push(fieldName);\n        }\n      }\n      if (typeof part.text === 'string') {\n        if (typeof part.thought === 'boolean' && part.thought) {\n          continue;\n        }\n        anyTextPartText = true;\n        text += part.text;\n      }\n    }\n    if (nonTextParts.length > 0) {\n      console.warn(\n        `there are non-text parts ${nonTextParts} in the response, returning concatenation of all text parts. Please refer to the non text parts for a full response from model.`,\n      );\n    }\n    // part.text === '' is different from part.text is null\n    return anyTextPartText ? text : undefined;\n  }\n\n  /**\n   * Returns the concatenation of all inline data parts from the first candidate\n   * in the response.\n   *\n   * @remarks\n   * If there are multiple candidates in the response, the inline data from the\n   * first one will be returned. If there are non-inline data parts in the\n   * response, the concatenation of all inline data parts will be returned, and\n   * a warning will be logged.\n   */\n  get data(): string | undefined {\n    if (this.candidates?.[0]?.content?.parts?.length === 0) {\n      return undefined;\n    }\n    if (this.candidates && this.candidates.length > 1) {\n      console.warn(\n        'there are multiple candidates in the response, returning data from the first one.',\n      );\n    }\n    let data = '';\n    const nonDataParts = [];\n    for (const part of this.candidates?.[0]?.content?.parts ?? []) {\n      for (const [fieldName, fieldValue] of Object.entries(part)) {\n        if (\n          fieldName !== 'inlineData' &&\n          (fieldValue !== null || fieldValue !== undefined)\n        ) {\n          nonDataParts.push(fieldName);\n        }\n      }\n      if (part.inlineData && typeof part.inlineData.data === 'string') {\n        data += atob(part.inlineData.data);\n      }\n    }\n    if (nonDataParts.length > 0) {\n      console.warn(\n        `there are non-data parts ${nonDataParts} in the response, returning concatenation of all data parts. Please refer to the non data parts for a full response from model.`,\n      );\n    }\n    return data.length > 0 ? btoa(data) : undefined;\n  }\n\n  /**\n   * Returns the function calls from the first candidate in the response.\n   *\n   * @remarks\n   * If there are multiple candidates in the response, the function calls from\n   * the first one will be returned.\n   * If there are no function calls in the response, undefined will be returned.\n   *\n   * @example\n   * ```ts\n   * const controlLightFunctionDeclaration: FunctionDeclaration = {\n   *   name: 'controlLight',\n   *   parameters: {\n   *   type: Type.OBJECT,\n   *   description: 'Set the brightness and color temperature of a room light.',\n   *   properties: {\n   *     brightness: {\n   *       type: Type.NUMBER,\n   *       description:\n   *         'Light level from 0 to 100. Zero is off and 100 is full brightness.',\n   *     },\n   *     colorTemperature: {\n   *       type: Type.STRING,\n   *       description:\n   *         'Color temperature of the light fixture which can be `daylight`, `cool` or `warm`.',\n   *     },\n   *   },\n   *   required: ['brightness', 'colorTemperature'],\n   *  };\n   *  const response = await ai.models.generateContent({\n   *     model: 'gemini-2.0-flash',\n   *     contents: 'Dim the lights so the room feels cozy and warm.',\n   *     config: {\n   *       tools: [{functionDeclarations: [controlLightFunctionDeclaration]}],\n   *       toolConfig: {\n   *         functionCallingConfig: {\n   *           mode: FunctionCallingConfigMode.ANY,\n   *           allowedFunctionNames: ['controlLight'],\n   *         },\n   *       },\n   *     },\n   *   });\n   *  console.debug(JSON.stringify(response.functionCalls));\n   * ```\n   */\n  get functionCalls(): FunctionCall[] | undefined {\n    if (this.candidates?.[0]?.content?.parts?.length === 0) {\n      return undefined;\n    }\n    if (this.candidates && this.candidates.length > 1) {\n      console.warn(\n        'there are multiple candidates in the response, returning function calls from the first one.',\n      );\n    }\n    const functionCalls = this.candidates?.[0]?.content?.parts\n      ?.filter((part) => part.functionCall)\n      .map((part) => part.functionCall)\n      .filter(\n        (functionCall): functionCall is FunctionCall =>\n          functionCall !== undefined,\n      );\n    if (functionCalls?.length === 0) {\n      return undefined;\n    }\n    return functionCalls;\n  }\n  /**\n   * Returns the first executable code from the first candidate in the response.\n   *\n   * @remarks\n   * If there are multiple candidates in the response, the executable code from\n   * the first one will be returned.\n   * If there are no executable code in the response, undefined will be\n   * returned.\n   *\n   * @example\n   * ```ts\n   * const response = await ai.models.generateContent({\n   *   model: 'gemini-2.0-flash',\n   *   contents:\n   *     'What is the sum of the first 50 prime numbers? Generate and run code for the calculation, and make sure you get all 50.'\n   *   config: {\n   *     tools: [{codeExecution: {}}],\n   *   },\n   * });\n   *\n   * console.debug(response.executableCode);\n   * ```\n   */\n  get executableCode(): string | undefined {\n    if (this.candidates?.[0]?.content?.parts?.length === 0) {\n      return undefined;\n    }\n    if (this.candidates && this.candidates.length > 1) {\n      console.warn(\n        'there are multiple candidates in the response, returning executable code from the first one.',\n      );\n    }\n    const executableCode = this.candidates?.[0]?.content?.parts\n      ?.filter((part) => part.executableCode)\n      .map((part) => part.executableCode)\n      .filter(\n        (executableCode): executableCode is ExecutableCode =>\n          executableCode !== undefined,\n      );\n    if (executableCode?.length === 0) {\n      return undefined;\n    }\n\n    return executableCode?.[0]?.code;\n  }\n  /**\n   * Returns the first code execution result from the first candidate in the response.\n   *\n   * @remarks\n   * If there are multiple candidates in the response, the code execution result from\n   * the first one will be returned.\n   * If there are no code execution result in the response, undefined will be returned.\n   *\n   * @example\n   * ```ts\n   * const response = await ai.models.generateContent({\n   *   model: 'gemini-2.0-flash',\n   *   contents:\n   *     'What is the sum of the first 50 prime numbers? Generate and run code for the calculation, and make sure you get all 50.'\n   *   config: {\n   *     tools: [{codeExecution: {}}],\n   *   },\n   * });\n   *\n   * console.debug(response.codeExecutionResult);\n   * ```\n   */\n  get codeExecutionResult(): string | undefined {\n    if (this.candidates?.[0]?.content?.parts?.length === 0) {\n      return undefined;\n    }\n    if (this.candidates && this.candidates.length > 1) {\n      console.warn(\n        'there are multiple candidates in the response, returning code execution result from the first one.',\n      );\n    }\n    const codeExecutionResult = this.candidates?.[0]?.content?.parts\n      ?.filter((part) => part.codeExecutionResult)\n      .map((part) => part.codeExecutionResult)\n      .filter(\n        (codeExecutionResult): codeExecutionResult is CodeExecutionResult =>\n          codeExecutionResult !== undefined,\n      );\n    if (codeExecutionResult?.length === 0) {\n      return undefined;\n    }\n    return codeExecutionResult?.[0]?.output;\n  }\n}\n\nexport type ReferenceImage =\n  | RawReferenceImage\n  | MaskReferenceImage\n  | ControlReferenceImage\n  | StyleReferenceImage\n  | SubjectReferenceImage\n  | ContentReferenceImage;\n\n/** Parameters for the request to edit an image. */\nexport declare interface EditImageParameters {\n  /** The model to use. */\n  model: string;\n  /** A text description of the edit to apply to the image. */\n  prompt: string;\n  /** The reference images for Imagen 3 editing. */\n  referenceImages: ReferenceImage[];\n  /** Configuration for editing. */\n  config?: EditImageConfig;\n}\n\n/** Optional parameters for the embed_content method. */\nexport declare interface EmbedContentConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n  /** Type of task for which the embedding will be used.\n   */\n  taskType?: string;\n  /** Title for the text. Only applicable when TaskType is\n      `RETRIEVAL_DOCUMENT`.\n       */\n  title?: string;\n  /** Reduced dimension for the output embedding. If set,\n      excessive values in the output embedding are truncated from the end.\n      Supported by newer models since 2024 only. You cannot set this value if\n      using the earlier model (`models/embedding-001`).\n       */\n  outputDimensionality?: number;\n  /** Vertex API only. The MIME type of the input.\n   */\n  mimeType?: string;\n  /** Vertex API only. Whether to silently truncate inputs longer than\n      the max sequence length. If this option is set to false, oversized inputs\n      will lead to an INVALID_ARGUMENT error, similar to other text APIs.\n       */\n  autoTruncate?: boolean;\n}\n\n/** Parameters for the embed_content method. */\nexport declare interface EmbedContentParameters {\n  /** ID of the model to use. For a list of models, see `Google models\n    <https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models>`_. */\n  model: string;\n  /** The content to embed. Only the `parts.text` fields will be counted.\n   */\n  contents: ContentListUnion;\n  /** Configuration that contains optional parameters.\n   */\n  config?: EmbedContentConfig;\n}\n\n/** Statistics of the input text associated with the result of content embedding. */\nexport declare interface ContentEmbeddingStatistics {\n  /** Vertex API only. If the input text was truncated due to having\n      a length longer than the allowed maximum input.\n       */\n  truncated?: boolean;\n  /** Vertex API only. Number of tokens of the input text.\n   */\n  tokenCount?: number;\n}\n\n/** The embedding generated from an input content. */\nexport declare interface ContentEmbedding {\n  /** A list of floats representing an embedding.\n   */\n  values?: number[];\n  /** Vertex API only. Statistics of the input text associated with this\n      embedding.\n       */\n  statistics?: ContentEmbeddingStatistics;\n}\n\n/** Request-level metadata for the Vertex Embed Content API. */\nexport declare interface EmbedContentMetadata {\n  /** Vertex API only. The total number of billable characters included\n      in the request.\n       */\n  billableCharacterCount?: number;\n}\n\n/** Response for the embed_content method. */\nexport class EmbedContentResponse {\n  /** Used to retain the full HTTP response. */\n  sdkHttpResponse?: HttpResponse;\n  /** The embeddings for each request, in the same order as provided in\n      the batch request.\n       */\n  embeddings?: ContentEmbedding[];\n  /** Vertex API only. Metadata about the request.\n   */\n  metadata?: EmbedContentMetadata;\n}\n\n/** The config for generating an images. */\nexport declare interface GenerateImagesConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n  /** Cloud Storage URI used to store the generated images. */\n  outputGcsUri?: string;\n  /** Description of what to discourage in the generated images. */\n  negativePrompt?: string;\n  /** Number of images to generate. */\n  numberOfImages?: number;\n  /** Aspect ratio of the generated images. Supported values are\n      \"1:1\", \"3:4\", \"4:3\", \"9:16\", and \"16:9\". */\n  aspectRatio?: string;\n  /** Controls how much the model adheres to the text prompt. Large\n      values increase output and prompt alignment, but may compromise image\n      quality. */\n  guidanceScale?: number;\n  /** Random seed for image generation. This is not available when\n      ``add_watermark`` is set to true. */\n  seed?: number;\n  /** Filter level for safety filtering. */\n  safetyFilterLevel?: SafetyFilterLevel;\n  /** Allows generation of people by the model. */\n  personGeneration?: PersonGeneration;\n  /** Whether to report the safety scores of each generated image and\n      the positive prompt in the response. */\n  includeSafetyAttributes?: boolean;\n  /** Whether to include the Responsible AI filter reason if the image\n      is filtered out of the response. */\n  includeRaiReason?: boolean;\n  /** Language of the text in the prompt. */\n  language?: ImagePromptLanguage;\n  /** MIME type of the generated image. */\n  outputMimeType?: string;\n  /** Compression quality of the generated image (for ``image/jpeg``\n      only). */\n  outputCompressionQuality?: number;\n  /** Whether to add a watermark to the generated images. */\n  addWatermark?: boolean;\n  /** User specified labels to track billing usage. */\n  labels?: Record<string, string>;\n  /** The size of the largest dimension of the generated image.\n      Supported sizes are 1K and 2K (not supported for Imagen 3 models). */\n  imageSize?: string;\n  /** Whether to use the prompt rewriting logic. */\n  enhancePrompt?: boolean;\n}\n\n/** The parameters for generating images. */\nexport declare interface GenerateImagesParameters {\n  /** ID of the model to use. For a list of models, see `Google models\n    <https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models>`_. */\n  model: string;\n  /** Text prompt that typically describes the images to output.\n   */\n  prompt: string;\n  /** Configuration for generating images.\n   */\n  config?: GenerateImagesConfig;\n}\n\n/** An image. */\nexport declare interface Image {\n  /** The Cloud Storage URI of the image. ``Image`` can contain a value\n      for this field or the ``image_bytes`` field but not both. */\n  gcsUri?: string;\n  /** The image bytes data. ``Image`` can contain a value for this field\n      or the ``gcs_uri`` field but not both.\n  * @remarks Encoded as base64 string. */\n  imageBytes?: string;\n  /** The MIME type of the image. */\n  mimeType?: string;\n}\n\n/** Safety attributes of a GeneratedImage or the user-provided prompt. */\nexport declare interface SafetyAttributes {\n  /** List of RAI categories. */\n  categories?: string[];\n  /** List of scores of each categories. */\n  scores?: number[];\n  /** Internal use only. */\n  contentType?: string;\n}\n\n/** An output image. */\nexport declare interface GeneratedImage {\n  /** The output image data. */\n  image?: Image;\n  /** Responsible AI filter reason if the image is filtered out of the\n      response. */\n  raiFilteredReason?: string;\n  /** Safety attributes of the image. Lists of RAI categories and their\n      scores of each content. */\n  safetyAttributes?: SafetyAttributes;\n  /** The rewritten prompt used for the image generation if the prompt\n      enhancer is enabled. */\n  enhancedPrompt?: string;\n}\n\n/** The output images response. */\nexport class GenerateImagesResponse {\n  /** Used to retain the full HTTP response. */\n  sdkHttpResponse?: HttpResponse;\n  /** List of generated images. */\n  generatedImages?: GeneratedImage[];\n  /** Safety attributes of the positive prompt. Only populated if\n      ``include_safety_attributes`` is set to True. */\n  positivePromptSafetyAttributes?: SafetyAttributes;\n}\n\n/** Configuration for a Mask reference image. */\nexport declare interface MaskReferenceConfig {\n  /** Prompts the model to generate a mask instead of you needing to\n      provide one (unless MASK_MODE_USER_PROVIDED is used). */\n  maskMode?: MaskReferenceMode;\n  /** A list of up to 5 class ids to use for semantic segmentation.\n      Automatically creates an image mask based on specific objects. */\n  segmentationClasses?: number[];\n  /** Dilation percentage of the mask provided.\n      Float between 0 and 1. */\n  maskDilation?: number;\n}\n\n/** Configuration for a Control reference image. */\nexport declare interface ControlReferenceConfig {\n  /** The type of control reference image to use. */\n  controlType?: ControlReferenceType;\n  /** Defaults to False. When set to True, the control image will be\n      computed by the model based on the control type. When set to False,\n      the control image must be provided by the user. */\n  enableControlImageComputation?: boolean;\n}\n\n/** Configuration for a Style reference image. */\nexport declare interface StyleReferenceConfig {\n  /** A text description of the style to use for the generated image. */\n  styleDescription?: string;\n}\n\n/** Configuration for a Subject reference image. */\nexport declare interface SubjectReferenceConfig {\n  /** The subject type of a subject reference image. */\n  subjectType?: SubjectReferenceType;\n  /** Subject description for the image. */\n  subjectDescription?: string;\n}\n\n/** Configuration for editing an image. */\nexport declare interface EditImageConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n  /** Cloud Storage URI used to store the generated images. */\n  outputGcsUri?: string;\n  /** Description of what to discourage in the generated images. */\n  negativePrompt?: string;\n  /** Number of images to generate. */\n  numberOfImages?: number;\n  /** Aspect ratio of the generated images. Supported values are\n      \"1:1\", \"3:4\", \"4:3\", \"9:16\", and \"16:9\". */\n  aspectRatio?: string;\n  /** Controls how much the model adheres to the text prompt. Large\n      values increase output and prompt alignment, but may compromise image\n      quality. */\n  guidanceScale?: number;\n  /** Random seed for image generation. This is not available when\n      ``add_watermark`` is set to true. */\n  seed?: number;\n  /** Filter level for safety filtering. */\n  safetyFilterLevel?: SafetyFilterLevel;\n  /** Allows generation of people by the model. */\n  personGeneration?: PersonGeneration;\n  /** Whether to report the safety scores of each generated image and\n      the positive prompt in the response. */\n  includeSafetyAttributes?: boolean;\n  /** Whether to include the Responsible AI filter reason if the image\n      is filtered out of the response. */\n  includeRaiReason?: boolean;\n  /** Language of the text in the prompt. */\n  language?: ImagePromptLanguage;\n  /** MIME type of the generated image. */\n  outputMimeType?: string;\n  /** Compression quality of the generated image (for ``image/jpeg``\n      only). */\n  outputCompressionQuality?: number;\n  /** Whether to add a watermark to the generated images. */\n  addWatermark?: boolean;\n  /** User specified labels to track billing usage. */\n  labels?: Record<string, string>;\n  /** Describes the editing mode for the request. */\n  editMode?: EditMode;\n  /** The number of sampling steps. A higher value has better image\n      quality, while a lower value has better latency. */\n  baseSteps?: number;\n}\n\n/** Response for the request to edit an image. */\nexport class EditImageResponse {\n  /** Used to retain the full HTTP response. */\n  sdkHttpResponse?: HttpResponse;\n  /** Generated images. */\n  generatedImages?: GeneratedImage[];\n}\n\nexport class UpscaleImageResponse {\n  /** Used to retain the full HTTP response. */\n  sdkHttpResponse?: HttpResponse;\n  /** Generated images. */\n  generatedImages?: GeneratedImage[];\n}\n\n/** An image of the product. */\nexport declare interface ProductImage {\n  /** An image of the product to be recontextualized. */\n  productImage?: Image;\n}\n\n/** A set of source input(s) for image recontextualization. */\nexport declare interface RecontextImageSource {\n  /** A text prompt for guiding the model during image\n      recontextualization. Not supported for Virtual Try-On. */\n  prompt?: string;\n  /** Image of the person or subject who will be wearing the\n      product(s). */\n  personImage?: Image;\n  /** A list of product images. */\n  productImages?: ProductImage[];\n}\n\n/** Configuration for recontextualizing an image. */\nexport declare interface RecontextImageConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n  /** Number of images to generate. */\n  numberOfImages?: number;\n  /** The number of sampling steps. A higher value has better image\n      quality, while a lower value has better latency. */\n  baseSteps?: number;\n  /** Cloud Storage URI used to store the generated images. */\n  outputGcsUri?: string;\n  /** Random seed for image generation. */\n  seed?: number;\n  /** Filter level for safety filtering. */\n  safetyFilterLevel?: SafetyFilterLevel;\n  /** Whether allow to generate person images, and restrict to specific\n      ages. */\n  personGeneration?: PersonGeneration;\n  /** Whether to add a SynthID watermark to the generated images. */\n  addWatermark?: boolean;\n  /** MIME type of the generated image. */\n  outputMimeType?: string;\n  /** Compression quality of the generated image (for ``image/jpeg``\n      only). */\n  outputCompressionQuality?: number;\n  /** Whether to use the prompt rewriting logic. */\n  enhancePrompt?: boolean;\n  /** User specified labels to track billing usage. */\n  labels?: Record<string, string>;\n}\n\n/** The parameters for recontextualizing an image. */\nexport declare interface RecontextImageParameters {\n  /** ID of the model to use. For a list of models, see `Google models\n    <https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models>`_. */\n  model: string;\n  /** A set of source input(s) for image recontextualization. */\n  source: RecontextImageSource;\n  /** Configuration for image recontextualization. */\n  config?: RecontextImageConfig;\n}\n\n/** The output images response. */\nexport class RecontextImageResponse {\n  /** List of generated images. */\n  generatedImages?: GeneratedImage[];\n}\n\n/** An image mask representing a brush scribble. */\nexport declare interface ScribbleImage {\n  /** The brush scribble to guide segmentation. Valid for the interactive mode. */\n  image?: Image;\n}\n\n/** A set of source input(s) for image segmentation. */\nexport declare interface SegmentImageSource {\n  /** A text prompt for guiding the model during image segmentation.\n      Required for prompt mode and semantic mode, disallowed for other modes. */\n  prompt?: string;\n  /** The image to be segmented. */\n  image?: Image;\n  /** The brush scribble to guide segmentation.\n      Required for the interactive mode, disallowed for other modes. */\n  scribbleImage?: ScribbleImage;\n}\n\n/** Configuration for segmenting an image. */\nexport declare interface SegmentImageConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n  /** The segmentation mode to use. */\n  mode?: SegmentMode;\n  /** The maximum number of predictions to return up to, by top\n      confidence score. */\n  maxPredictions?: number;\n  /** The confidence score threshold for the detections as a decimal\n      value. Only predictions with a confidence score higher than this\n      threshold will be returned. */\n  confidenceThreshold?: number;\n  /** A decimal value representing how much dilation to apply to the\n      masks. 0 for no dilation. 1.0 means the masked area covers the whole\n      image. */\n  maskDilation?: number;\n  /** The binary color threshold to apply to the masks. The threshold\n      can be set to a decimal value between 0 and 255 non-inclusive.\n      Set to -1 for no binary color thresholding. */\n  binaryColorThreshold?: number;\n  /** User specified labels to track billing usage. */\n  labels?: Record<string, string>;\n}\n\n/** The parameters for segmenting an image. */\nexport declare interface SegmentImageParameters {\n  /** ID of the model to use. For a list of models, see `Google models\n    <https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models>`_. */\n  model: string;\n  /** A set of source input(s) for image segmentation. */\n  source: SegmentImageSource;\n  /** Configuration for image segmentation. */\n  config?: SegmentImageConfig;\n}\n\n/** An entity representing the segmented area. */\nexport declare interface EntityLabel {\n  /** The label of the segmented entity. */\n  label?: string;\n  /** The confidence score of the detected label. */\n  score?: number;\n}\n\n/** A generated image mask. */\nexport declare interface GeneratedImageMask {\n  /** The generated image mask. */\n  mask?: Image;\n  /** The detected entities on the segmented area. */\n  labels?: EntityLabel[];\n}\n\n/** The output images response. */\nexport class SegmentImageResponse {\n  /** List of generated image masks.\n   */\n  generatedMasks?: GeneratedImageMask[];\n}\n\n/** Optional parameters for models.get method. */\nexport declare interface GetModelConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n}\n\nexport declare interface GetModelParameters {\n  model: string;\n  /** Optional parameters for the request. */\n  config?: GetModelConfig;\n}\n\n/** An endpoint where you deploy models. */\nexport declare interface Endpoint {\n  /** Resource name of the endpoint. */\n  name?: string;\n  /** ID of the model that's deployed to the endpoint. */\n  deployedModelId?: string;\n}\n\n/** A tuned machine learning model. */\nexport declare interface TunedModelInfo {\n  /** ID of the base model that you want to tune. */\n  baseModel?: string;\n  /** Date and time when the base model was created. */\n  createTime?: string;\n  /** Date and time when the base model was last updated. */\n  updateTime?: string;\n}\n\n/** Describes the machine learning model version checkpoint. */\nexport declare interface Checkpoint {\n  /** The ID of the checkpoint.\n   */\n  checkpointId?: string;\n  /** The epoch of the checkpoint.\n   */\n  epoch?: string;\n  /** The step of the checkpoint.\n   */\n  step?: string;\n}\n\n/** A trained machine learning model. */\nexport declare interface Model {\n  /** Resource name of the model. */\n  name?: string;\n  /** Display name of the model. */\n  displayName?: string;\n  /** Description of the model. */\n  description?: string;\n  /** Version ID of the model. A new version is committed when a new\n      model version is uploaded or trained under an existing model ID. The\n      version ID is an auto-incrementing decimal number in string\n      representation. */\n  version?: string;\n  /** List of deployed models created from this base model. Note that a\n      model could have been deployed to endpoints in different locations. */\n  endpoints?: Endpoint[];\n  /** Labels with user-defined metadata to organize your models. */\n  labels?: Record<string, string>;\n  /** Information about the tuned model from the base model. */\n  tunedModelInfo?: TunedModelInfo;\n  /** The maximum number of input tokens that the model can handle. */\n  inputTokenLimit?: number;\n  /** The maximum number of output tokens that the model can generate. */\n  outputTokenLimit?: number;\n  /** List of actions that are supported by the model. */\n  supportedActions?: string[];\n  /** The default checkpoint id of a model version.\n   */\n  defaultCheckpointId?: string;\n  /** The checkpoints of the model. */\n  checkpoints?: Checkpoint[];\n}\n\nexport declare interface ListModelsConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n  pageSize?: number;\n  pageToken?: string;\n  filter?: string;\n  /** Set true to list base models, false to list tuned models. */\n  queryBase?: boolean;\n}\n\nexport declare interface ListModelsParameters {\n  config?: ListModelsConfig;\n}\n\nexport class ListModelsResponse {\n  /** Used to retain the full HTTP response. */\n  sdkHttpResponse?: HttpResponse;\n  nextPageToken?: string;\n  models?: Model[];\n}\n\n/** Configuration for updating a tuned model. */\nexport declare interface UpdateModelConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n  displayName?: string;\n  description?: string;\n  defaultCheckpointId?: string;\n}\n\n/** Configuration for updating a tuned model. */\nexport declare interface UpdateModelParameters {\n  model: string;\n  config?: UpdateModelConfig;\n}\n\n/** Configuration for deleting a tuned model. */\nexport declare interface DeleteModelConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n}\n\n/** Parameters for deleting a tuned model. */\nexport declare interface DeleteModelParameters {\n  model: string;\n  /** Optional parameters for the request. */\n  config?: DeleteModelConfig;\n}\n\nexport class DeleteModelResponse {\n  /** Used to retain the full HTTP response. */\n  sdkHttpResponse?: HttpResponse;\n}\n\n/** Generation config. */\nexport declare interface GenerationConfig {\n  /** Optional. Config for model selection. */\n  modelSelectionConfig?: ModelSelectionConfig;\n  /** Optional. If enabled, audio timestamp will be included in the request to the model. This field is not supported in Gemini API. */\n  audioTimestamp?: boolean;\n  /** Optional. Number of candidates to generate. */\n  candidateCount?: number;\n  /** Optional. If enabled, the model will detect emotions and adapt its responses accordingly. This field is not supported in Gemini API. */\n  enableAffectiveDialog?: boolean;\n  /** Optional. Frequency penalties. */\n  frequencyPenalty?: number;\n  /** Optional. Logit probabilities. */\n  logprobs?: number;\n  /** Optional. The maximum number of output tokens to generate per message. */\n  maxOutputTokens?: number;\n  /** Optional. If specified, the media resolution specified will be used. */\n  mediaResolution?: MediaResolution;\n  /** Optional. Positive penalties. */\n  presencePenalty?: number;\n  /** Optional. Output schema of the generated response. This is an alternative to `response_schema` that accepts [JSON Schema](https://json-schema.org/). If set, `response_schema` must be omitted, but `response_mime_type` is required. While the full JSON Schema may be sent, not all features are supported. Specifically, only the following properties are supported: - `$id` - `$defs` - `$ref` - `$anchor` - `type` - `format` - `title` - `description` - `enum` (for strings and numbers) - `items` - `prefixItems` - `minItems` - `maxItems` - `minimum` - `maximum` - `anyOf` - `oneOf` (interpreted the same as `anyOf`) - `properties` - `additionalProperties` - `required` The non-standard `propertyOrdering` property may also be set. Cyclic references are unrolled to a limited degree and, as such, may only be used within non-required properties. (Nullable properties are not sufficient.) If `$ref` is set on a sub-schema, no other properties, except for than those starting as a `$`, may be set. */\n  responseJsonSchema?: unknown;\n  /** Optional. If true, export the logprobs results in response. */\n  responseLogprobs?: boolean;\n  /** Optional. Output response mimetype of the generated candidate text. Supported mimetype: - `text/plain`: (default) Text output. - `application/json`: JSON response in the candidates. The model needs to be prompted to output the appropriate response type, otherwise the behavior is undefined. This is a preview feature. */\n  responseMimeType?: string;\n  /** Optional. The modalities of the response. */\n  responseModalities?: Modality[];\n  /** Optional. The `Schema` object allows the definition of input and output data types. These types can be objects, but also primitives and arrays. Represents a select subset of an [OpenAPI 3.0 schema object](https://spec.openapis.org/oas/v3.0.3#schema). If set, a compatible response_mime_type must also be set. Compatible mimetypes: `application/json`: Schema for JSON response. */\n  responseSchema?: Schema;\n  /** Optional. Routing configuration. This field is not supported in Gemini API. */\n  routingConfig?: GenerationConfigRoutingConfig;\n  /** Optional. Seed. */\n  seed?: number;\n  /** Optional. The speech generation config. */\n  speechConfig?: SpeechConfig;\n  /** Optional. Stop sequences. */\n  stopSequences?: string[];\n  /** Optional. Controls the randomness of predictions. */\n  temperature?: number;\n  /** Optional. Config for thinking features. An error will be returned if this field is set for models that don't support thinking. */\n  thinkingConfig?: ThinkingConfig;\n  /** Optional. If specified, top-k sampling will be used. */\n  topK?: number;\n  /** Optional. If specified, nucleus sampling will be used. */\n  topP?: number;\n  /** Optional. Enables enhanced civic answers. It may not be available for all models. This field is not supported in Vertex AI. */\n  enableEnhancedCivicAnswers?: boolean;\n}\n\n/** Config for the count_tokens method. */\nexport declare interface CountTokensConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n  /** Instructions for the model to steer it toward better performance.\n   */\n  systemInstruction?: ContentUnion;\n  /** Code that enables the system to interact with external systems to\n      perform an action outside of the knowledge and scope of the model.\n       */\n  tools?: Tool[];\n  /** Configuration that the model uses to generate the response. Not\n      supported by the Gemini Developer API.\n       */\n  generationConfig?: GenerationConfig;\n}\n\n/** Parameters for counting tokens. */\nexport declare interface CountTokensParameters {\n  /** ID of the model to use. For a list of models, see `Google models\n    <https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models>`_. */\n  model: string;\n  /** Input content. */\n  contents: ContentListUnion;\n  /** Configuration for counting tokens. */\n  config?: CountTokensConfig;\n}\n\n/** Response for counting tokens. */\nexport class CountTokensResponse {\n  /** Used to retain the full HTTP response. */\n  sdkHttpResponse?: HttpResponse;\n  /** Total number of tokens. */\n  totalTokens?: number;\n  /** Number of tokens in the cached part of the prompt (the cached content). */\n  cachedContentTokenCount?: number;\n}\n\n/** Optional parameters for computing tokens. */\nexport declare interface ComputeTokensConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n}\n\n/** Parameters for computing tokens. */\nexport declare interface ComputeTokensParameters {\n  /** ID of the model to use. For a list of models, see `Google models\n    <https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models>`_. */\n  model: string;\n  /** Input content. */\n  contents: ContentListUnion;\n  /** Optional parameters for the request.\n   */\n  config?: ComputeTokensConfig;\n}\n\n/** Tokens info with a list of tokens and the corresponding list of token ids. */\nexport declare interface TokensInfo {\n  /** Optional fields for the role from the corresponding Content. */\n  role?: string;\n  /** A list of token ids from the input. */\n  tokenIds?: string[];\n  /** A list of tokens from the input.\n   * @remarks Encoded as base64 string. */\n  tokens?: string[];\n}\n\n/** Response for computing tokens. */\nexport class ComputeTokensResponse {\n  /** Used to retain the full HTTP response. */\n  sdkHttpResponse?: HttpResponse;\n  /** Lists of tokens info from the input. A ComputeTokensRequest could have multiple instances with a prompt in each instance. We also need to return lists of tokens info for the request with multiple instances. */\n  tokensInfo?: TokensInfo[];\n}\n\n/** A generated video. */\nexport declare interface Video {\n  /** Path to another storage. */\n  uri?: string;\n  /** Video bytes.\n   * @remarks Encoded as base64 string. */\n  videoBytes?: string;\n  /** Video encoding, for example ``video/mp4``. */\n  mimeType?: string;\n}\n\n/** A set of source input(s) for video generation. */\nexport declare interface GenerateVideosSource {\n  /** The text prompt for generating the videos.\n      Optional if image or video is provided. */\n  prompt?: string;\n  /** The input image for generating the videos.\n      Optional if prompt is provided. Not allowed if video is provided. */\n  image?: Image;\n  /** The input video for video extension use cases.\n      Optional if prompt is provided. Not allowed if image is provided. */\n  video?: Video;\n}\n\n/** A reference image for video generation. */\nexport declare interface VideoGenerationReferenceImage {\n  /** The reference image. */\n  image?: Image;\n  /** The type of the reference image, which defines how the reference\n      image will be used to generate the video. */\n  referenceType?: VideoGenerationReferenceType;\n}\n\n/** A mask for video generation. */\nexport declare interface VideoGenerationMask {\n  /** The image mask to use for generating videos. */\n  image?: Image;\n  /** Describes how the mask will be used. Inpainting masks must\n      match the aspect ratio of the input video. Outpainting masks can be\n      either 9:16 or 16:9. */\n  maskMode?: VideoGenerationMaskMode;\n}\n\n/** Configuration for generating videos. */\nexport declare interface GenerateVideosConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n  /** Number of output videos. */\n  numberOfVideos?: number;\n  /** The gcs bucket where to save the generated videos. */\n  outputGcsUri?: string;\n  /** Frames per second for video generation. */\n  fps?: number;\n  /** Duration of the clip for video generation in seconds. */\n  durationSeconds?: number;\n  /** The RNG seed. If RNG seed is exactly same for each request with\n      unchanged inputs, the prediction results will be consistent. Otherwise,\n      a random RNG seed will be used each time to produce a different\n      result. */\n  seed?: number;\n  /** The aspect ratio for the generated video. 16:9 (landscape) and\n      9:16 (portrait) are supported. */\n  aspectRatio?: string;\n  /** The resolution for the generated video. 720p and 1080p are\n      supported. */\n  resolution?: string;\n  /** Whether allow to generate person videos, and restrict to specific\n      ages. Supported values are: dont_allow, allow_adult. */\n  personGeneration?: string;\n  /** The pubsub topic where to publish the video generation\n      progress. */\n  pubsubTopic?: string;\n  /** Explicitly state what should not be included in the generated\n      videos. */\n  negativePrompt?: string;\n  /** Whether to use the prompt rewriting logic. */\n  enhancePrompt?: boolean;\n  /** Whether to generate audio along with the video. */\n  generateAudio?: boolean;\n  /** Image to use as the last frame of generated videos.\n      Only supported for image to video use cases. */\n  lastFrame?: Image;\n  /** The images to use as the references to generate the videos.\n      If this field is provided, the text prompt field must also be provided.\n      The image, video, or last_frame field are not supported. Each image must\n      be associated with a type. Veo 2 supports up to 3 asset images *or* 1\n      style image. */\n  referenceImages?: VideoGenerationReferenceImage[];\n  /** The mask to use for generating videos. */\n  mask?: VideoGenerationMask;\n  /** Compression quality of the generated videos. */\n  compressionQuality?: VideoCompressionQuality;\n}\n\n/** Class that represents the parameters for generating videos. */\nexport declare interface GenerateVideosParameters {\n  /** ID of the model to use. For a list of models, see `Google models\n    <https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models>`_. */\n  model: string;\n  /** The text prompt for generating the videos.\n      Optional if image or video is provided. */\n  prompt?: string;\n  /** The input image for generating the videos.\n      Optional if prompt is provided. Not allowed if video is provided. */\n  image?: Image;\n  /** The input video for video extension use cases.\n      Optional if prompt is provided. Not allowed if image is provided. */\n  video?: Video;\n  /** A set of source input(s) for video generation. */\n  source?: GenerateVideosSource;\n  /** Configuration for generating videos. */\n  config?: GenerateVideosConfig;\n}\n\n/** A generated video. */\nexport declare interface GeneratedVideo {\n  /** The output video */\n  video?: Video;\n}\n\n/** Response with generated videos. */\nexport class GenerateVideosResponse {\n  /** List of the generated videos */\n  generatedVideos?: GeneratedVideo[];\n  /** Returns if any videos were filtered due to RAI policies. */\n  raiMediaFilteredCount?: number;\n  /** Returns rai failure reasons if any. */\n  raiMediaFilteredReasons?: string[];\n}\n\n/** A long-running operation. */\nexport declare interface Operation<T> {\n  /** The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`. */\n  name?: string;\n  /** Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata.  Any method that returns a long-running operation should document the metadata type, if any. */\n  metadata?: Record<string, unknown>;\n  /** If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available. */\n  done?: boolean;\n  /** The error result of the operation in case of failure or cancellation. */\n  error?: Record<string, unknown>;\n  /** The response if the operation is successful. */\n  response?: T;\n  /**\n   * Instantiates an Operation of the same type as the one being called with the fields set from the API response.\n   * @internal\n   */\n  _fromAPIResponse({\n    apiResponse,\n    isVertexAI,\n  }: OperationFromAPIResponseParameters): Operation<T>;\n}\n\n/** A video generation operation. */\nexport class GenerateVideosOperation\n  implements Operation<GenerateVideosResponse>\n{\n  /** The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`. */\n  name?: string;\n  /** Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata.  Any method that returns a long-running operation should document the metadata type, if any. */\n  metadata?: Record<string, unknown>;\n  /** If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available. */\n  done?: boolean;\n  /** The error result of the operation in case of failure or cancellation. */\n  error?: Record<string, unknown>;\n  /** The generated videos. */\n  response?: GenerateVideosResponse;\n\n  /**\n   * Instantiates an Operation of the same type as the one being called with the fields set from the API response.\n   * @internal\n   */\n  _fromAPIResponse({\n    apiResponse,\n    isVertexAI,\n  }: OperationFromAPIResponseParameters): Operation<GenerateVideosResponse> {\n    const operation = new GenerateVideosOperation();\n    let response;\n    const op = apiResponse as unknown as GenerateVideosOperation;\n\n    if (isVertexAI) {\n      response = generateVideosOperationFromVertex(op);\n    } else {\n      response = generateVideosOperationFromMldev(op);\n    }\n    Object.assign(operation, response);\n    return operation;\n  }\n  /** The full HTTP response. */\n  sdkHttpResponse?: HttpResponse;\n}\n\nexport /** Optional parameters for tunings.get method. */\ndeclare interface GetTuningJobConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n}\n\n/** Parameters for the get method. */\nexport declare interface GetTuningJobParameters {\n  name: string;\n  /** Optional parameters for the request. */\n  config?: GetTuningJobConfig;\n}\n\n/** TunedModelCheckpoint for the Tuned Model of a Tuning Job. */\nexport declare interface TunedModelCheckpoint {\n  /** The ID of the checkpoint.\n   */\n  checkpointId?: string;\n  /** The epoch of the checkpoint.\n   */\n  epoch?: string;\n  /** The step of the checkpoint.\n   */\n  step?: string;\n  /** The Endpoint resource name that the checkpoint is deployed to.\n      Format: `projects/{project}/locations/{location}/endpoints/{endpoint}`.\n       */\n  endpoint?: string;\n}\n\n/** TunedModel for the Tuned Model of a Tuning Job. */\nexport declare interface TunedModel {\n  /** Output only. The resource name of the TunedModel.\n      Format: `projects/{project}/locations/{location}/models/{model}@{version_id}`\n      When tuning from a base model, the version_id will be 1.\n      For continuous tuning, the version id will be incremented by 1 from the\n      last version id in the parent model. E.g., `projects/{project}/locations/{location}/models/{model}@{last_version_id + 1}`\n       */\n  model?: string;\n  /** Output only. A resource name of an Endpoint.\n      Format: `projects/{project}/locations/{location}/endpoints/{endpoint}`.\n       */\n  endpoint?: string;\n  /** The checkpoints associated with this TunedModel.\n      This field is only populated for tuning jobs that enable intermediate\n      checkpoints. */\n  checkpoints?: TunedModelCheckpoint[];\n}\n\n/** The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors). This data type is not supported in Gemini API. */\nexport declare interface GoogleRpcStatus {\n  /** The status code, which should be an enum value of google.rpc.Code. */\n  code?: number;\n  /** A list of messages that carry the error details. There is a common set of message types for APIs to use. */\n  details?: Record<string, unknown>[];\n  /** A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client. */\n  message?: string;\n}\n\n/** A pre-tuned model for continuous tuning. This data type is not supported in Gemini API. */\nexport declare interface PreTunedModel {\n  /** Output only. The name of the base model this PreTunedModel was tuned from. */\n  baseModel?: string;\n  /** Optional. The source checkpoint id. If not specified, the default checkpoint will be used. */\n  checkpointId?: string;\n  /** The resource name of the Model. E.g., a model resource name with a specified version id or alias: `projects/{project}/locations/{location}/models/{model}@{version_id}` `projects/{project}/locations/{location}/models/{model}@{alias}` Or, omit the version id to use the default version: `projects/{project}/locations/{location}/models/{model}` */\n  tunedModelName?: string;\n}\n\n/** Hyperparameters for SFT. This data type is not supported in Gemini API. */\nexport declare interface SupervisedHyperParameters {\n  /** Optional. Adapter size for tuning. */\n  adapterSize?: AdapterSize;\n  /** Optional. Batch size for tuning. This feature is only available for open source models. */\n  batchSize?: string;\n  /** Optional. Number of complete passes the model makes over the entire training dataset during training. */\n  epochCount?: string;\n  /** Optional. Learning rate for tuning. Mutually exclusive with `learning_rate_multiplier`. This feature is only available for open source models. */\n  learningRate?: number;\n  /** Optional. Multiplier for adjusting the default learning rate. Mutually exclusive with `learning_rate`. This feature is only available for 1P models. */\n  learningRateMultiplier?: number;\n}\n\n/** Tuning Spec for Supervised Tuning for first party models. This data type is not supported in Gemini API. */\nexport declare interface SupervisedTuningSpec {\n  /** Optional. If set to true, disable intermediate checkpoints for SFT and only the last checkpoint will be exported. Otherwise, enable intermediate checkpoints for SFT. Default is false. */\n  exportLastCheckpointOnly?: boolean;\n  /** Optional. Hyperparameters for SFT. */\n  hyperParameters?: SupervisedHyperParameters;\n  /** Required. Training dataset used for tuning. The dataset can be specified as either a Cloud Storage path to a JSONL file or as the resource name of a Vertex Multimodal Dataset. */\n  trainingDatasetUri?: string;\n  /** Tuning mode. */\n  tuningMode?: TuningMode;\n  /** Optional. Validation dataset used for tuning. The dataset can be specified as either a Cloud Storage path to a JSONL file or as the resource name of a Vertex Multimodal Dataset. */\n  validationDatasetUri?: string;\n}\n\n/** Dataset bucket used to create a histogram for the distribution given a population of values. This data type is not supported in Gemini API. */\nexport declare interface DatasetDistributionDistributionBucket {\n  /** Output only. Number of values in the bucket. */\n  count?: string;\n  /** Output only. Left bound of the bucket. */\n  left?: number;\n  /** Output only. Right bound of the bucket. */\n  right?: number;\n}\n\n/** Distribution computed over a tuning dataset. This data type is not supported in Gemini API. */\nexport declare interface DatasetDistribution {\n  /** Output only. Defines the histogram bucket. */\n  buckets?: DatasetDistributionDistributionBucket[];\n  /** Output only. The maximum of the population values. */\n  max?: number;\n  /** Output only. The arithmetic mean of the values in the population. */\n  mean?: number;\n  /** Output only. The median of the values in the population. */\n  median?: number;\n  /** Output only. The minimum of the population values. */\n  min?: number;\n  /** Output only. The 5th percentile of the values in the population. */\n  p5?: number;\n  /** Output only. The 95th percentile of the values in the population. */\n  p95?: number;\n  /** Output only. Sum of a given population of values. */\n  sum?: number;\n}\n\n/** Statistics computed over a tuning dataset. This data type is not supported in Gemini API. */\nexport declare interface DatasetStats {\n  /** Output only. Number of billable characters in the tuning dataset. */\n  totalBillableCharacterCount?: string;\n  /** Output only. Number of tuning characters in the tuning dataset. */\n  totalTuningCharacterCount?: string;\n  /** Output only. Number of examples in the tuning dataset. */\n  tuningDatasetExampleCount?: string;\n  /** Output only. Number of tuning steps for this Tuning Job. */\n  tuningStepCount?: string;\n  /** Output only. Sample user messages in the training dataset uri. */\n  userDatasetExamples?: Content[];\n  /** Output only. Dataset distributions for the user input tokens. */\n  userInputTokenDistribution?: DatasetDistribution;\n  /** Output only. Dataset distributions for the messages per example. */\n  userMessagePerExampleDistribution?: DatasetDistribution;\n  /** Output only. Dataset distributions for the user output tokens. */\n  userOutputTokenDistribution?: DatasetDistribution;\n}\n\n/** Statistics computed for datasets used for distillation. This data type is not supported in Gemini API. */\nexport declare interface DistillationDataStats {\n  /** Output only. Statistics computed for the training dataset. */\n  trainingDatasetStats?: DatasetStats;\n}\n\n/** Completion and its preference score. This data type is not supported in Gemini API. */\nexport declare interface GeminiPreferenceExampleCompletion {\n  /** Single turn completion for the given prompt. */\n  completion?: Content;\n  /** The score for the given completion. */\n  score?: number;\n}\n\n/** Input example for preference optimization. This data type is not supported in Gemini API. */\nexport declare interface GeminiPreferenceExample {\n  /** List of completions for a given prompt. */\n  completions?: GeminiPreferenceExampleCompletion[];\n  /** Multi-turn contents that represents the Prompt. */\n  contents?: Content[];\n}\n\n/** Statistics computed for datasets used for preference optimization. This data type is not supported in Gemini API. */\nexport declare interface PreferenceOptimizationDataStats {\n  /** Output only. Dataset distributions for scores variance per example. */\n  scoreVariancePerExampleDistribution?: DatasetDistribution;\n  /** Output only. Dataset distributions for scores. */\n  scoresDistribution?: DatasetDistribution;\n  /** Output only. Number of billable tokens in the tuning dataset. */\n  totalBillableTokenCount?: string;\n  /** Output only. Number of examples in the tuning dataset. */\n  tuningDatasetExampleCount?: string;\n  /** Output only. Number of tuning steps for this Tuning Job. */\n  tuningStepCount?: string;\n  /** Output only. Sample user examples in the training dataset. */\n  userDatasetExamples?: GeminiPreferenceExample[];\n  /** Output only. Dataset distributions for the user input tokens. */\n  userInputTokenDistribution?: DatasetDistribution;\n  /** Output only. Dataset distributions for the user output tokens. */\n  userOutputTokenDistribution?: DatasetDistribution;\n}\n\n/** Dataset bucket used to create a histogram for the distribution given a population of values. This data type is not supported in Gemini API. */\nexport declare interface SupervisedTuningDatasetDistributionDatasetBucket {\n  /** Output only. Number of values in the bucket. */\n  count?: number;\n  /** Output only. Left bound of the bucket. */\n  left?: number;\n  /** Output only. Right bound of the bucket. */\n  right?: number;\n}\n\n/** Dataset distribution for Supervised Tuning. This data type is not supported in Gemini API. */\nexport declare interface SupervisedTuningDatasetDistribution {\n  /** Output only. Sum of a given population of values that are billable. */\n  billableSum?: string;\n  /** Output only. Defines the histogram bucket. */\n  buckets?: SupervisedTuningDatasetDistributionDatasetBucket[];\n  /** Output only. The maximum of the population values. */\n  max?: number;\n  /** Output only. The arithmetic mean of the values in the population. */\n  mean?: number;\n  /** Output only. The median of the values in the population. */\n  median?: number;\n  /** Output only. The minimum of the population values. */\n  min?: number;\n  /** Output only. The 5th percentile of the values in the population. */\n  p5?: number;\n  /** Output only. The 95th percentile of the values in the population. */\n  p95?: number;\n  /** Output only. Sum of a given population of values. */\n  sum?: string;\n}\n\n/** Tuning data statistics for Supervised Tuning. This data type is not supported in Gemini API. */\nexport declare interface SupervisedTuningDataStats {\n  /** Output only. For each index in `truncated_example_indices`, the user-facing reason why the example was dropped. */\n  droppedExampleReasons?: string[];\n  /** Output only. Number of billable characters in the tuning dataset. */\n  totalBillableCharacterCount?: string;\n  /** Output only. Number of billable tokens in the tuning dataset. */\n  totalBillableTokenCount?: string;\n  /** Output only. The number of examples in the dataset that have been dropped. An example can be dropped for reasons including: too many tokens, contains an invalid image, contains too many images, etc. */\n  totalTruncatedExampleCount?: string;\n  /** Output only. Number of tuning characters in the tuning dataset. */\n  totalTuningCharacterCount?: string;\n  /** Output only. A partial sample of the indices (starting from 1) of the dropped examples. */\n  truncatedExampleIndices?: string[];\n  /** Output only. Number of examples in the tuning dataset. */\n  tuningDatasetExampleCount?: string;\n  /** Output only. Number of tuning steps for this Tuning Job. */\n  tuningStepCount?: string;\n  /** Output only. Sample user messages in the training dataset uri. */\n  userDatasetExamples?: Content[];\n  /** Output only. Dataset distributions for the user input tokens. */\n  userInputTokenDistribution?: SupervisedTuningDatasetDistribution;\n  /** Output only. Dataset distributions for the messages per example. */\n  userMessagePerExampleDistribution?: SupervisedTuningDatasetDistribution;\n  /** Output only. Dataset distributions for the user output tokens. */\n  userOutputTokenDistribution?: SupervisedTuningDatasetDistribution;\n}\n\n/** The tuning data statistic values for TuningJob. This data type is not supported in Gemini API. */\nexport declare interface TuningDataStats {\n  /** Output only. Statistics for distillation. */\n  distillationDataStats?: DistillationDataStats;\n  /** Output only. Statistics for preference optimization. */\n  preferenceOptimizationDataStats?: PreferenceOptimizationDataStats;\n  /** The SFT Tuning data stats. */\n  supervisedTuningDataStats?: SupervisedTuningDataStats;\n}\n\n/** Represents a customer-managed encryption key spec that can be applied to a top-level resource. This data type is not supported in Gemini API. */\nexport declare interface EncryptionSpec {\n  /** Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`. The key needs to be in the same region as where the compute resource is created. */\n  kmsKeyName?: string;\n}\n\n/** Tuning spec for Partner models. This data type is not supported in Gemini API. */\nexport declare interface PartnerModelTuningSpec {\n  /** Hyperparameters for tuning. The accepted hyper_parameters and their valid range of values will differ depending on the base model. */\n  hyperParameters?: Record<string, unknown>;\n  /** Required. Cloud Storage path to file containing training dataset for tuning. The dataset must be formatted as a JSONL file. */\n  trainingDatasetUri?: string;\n  /** Optional. Cloud Storage path to file containing validation dataset for tuning. The dataset must be formatted as a JSONL file. */\n  validationDatasetUri?: string;\n}\n\n/** Hyperparameters for Veo. This data type is not supported in Gemini API. */\nexport declare interface VeoHyperParameters {\n  /** Optional. Number of complete passes the model makes over the entire training dataset during training. */\n  epochCount?: string;\n  /** Optional. Multiplier for adjusting the default learning rate. */\n  learningRateMultiplier?: number;\n  /** Optional. The tuning task. Either I2V or T2V. */\n  tuningTask?: TuningTask;\n}\n\n/** Tuning Spec for Veo Model Tuning. This data type is not supported in Gemini API. */\nexport declare interface VeoTuningSpec {\n  /** Optional. Hyperparameters for Veo. */\n  hyperParameters?: VeoHyperParameters;\n  /** Required. Training dataset used for tuning. The dataset can be specified as either a Cloud Storage path to a JSONL file or as the resource name of a Vertex Multimodal Dataset. */\n  trainingDatasetUri?: string;\n  /** Optional. Validation dataset used for tuning. The dataset can be specified as either a Cloud Storage path to a JSONL file or as the resource name of a Vertex Multimodal Dataset. */\n  validationDatasetUri?: string;\n}\n\n/** A tuning job. */\nexport declare interface TuningJob {\n  /** Used to retain the full HTTP response. */\n  sdkHttpResponse?: HttpResponse;\n  /** Output only. Identifier. Resource name of a TuningJob. Format: `projects/{project}/locations/{location}/tuningJobs/{tuning_job}` */\n  name?: string;\n  /** Output only. The detailed state of the job. */\n  state?: JobState;\n  /** Output only. Time when the TuningJob was created. */\n  createTime?: string;\n  /** Output only. Time when the TuningJob for the first time entered the `JOB_STATE_RUNNING` state. */\n  startTime?: string;\n  /** Output only. Time when the TuningJob entered any of the following JobStates: `JOB_STATE_SUCCEEDED`, `JOB_STATE_FAILED`, `JOB_STATE_CANCELLED`, `JOB_STATE_EXPIRED`. */\n  endTime?: string;\n  /** Output only. Time when the TuningJob was most recently updated. */\n  updateTime?: string;\n  /** Output only. Only populated when job's state is `JOB_STATE_FAILED` or `JOB_STATE_CANCELLED`. */\n  error?: GoogleRpcStatus;\n  /** Optional. The description of the TuningJob. */\n  description?: string;\n  /** The base model that is being tuned. See [Supported models](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/tuning#supported_models). */\n  baseModel?: string;\n  /** Output only. The tuned model resources associated with this TuningJob. */\n  tunedModel?: TunedModel;\n  /** The pre-tuned model for continuous tuning. */\n  preTunedModel?: PreTunedModel;\n  /** Tuning Spec for Supervised Fine Tuning. */\n  supervisedTuningSpec?: SupervisedTuningSpec;\n  /** Output only. The tuning data statistics associated with this TuningJob. */\n  tuningDataStats?: TuningDataStats;\n  /** Customer-managed encryption key options for a TuningJob. If this is set, then all resources created by the TuningJob will be encrypted with the provided encryption key. */\n  encryptionSpec?: EncryptionSpec;\n  /** Tuning Spec for open sourced and third party Partner models. */\n  partnerModelTuningSpec?: PartnerModelTuningSpec;\n  /** Optional. The user-provided path to custom model weights. Set this field to tune a custom model. The path must be a Cloud Storage directory that contains the model weights in .safetensors format along with associated model metadata files. If this field is set, the base_model field must still be set to indicate which base model the custom model is derived from. This feature is only available for open source models. */\n  customBaseModel?: string;\n  /** Output only. The Experiment associated with this TuningJob. */\n  experiment?: string;\n  /** Optional. The labels with user-defined metadata to organize TuningJob and generated resources such as Model and Endpoint. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels. */\n  labels?: Record<string, string>;\n  /** Optional. Cloud Storage path to the directory where tuning job outputs are written to. This field is only available and required for open source models. */\n  outputUri?: string;\n  /** Output only. The resource name of the PipelineJob associated with the TuningJob. Format: `projects/{project}/locations/{location}/pipelineJobs/{pipeline_job}`. */\n  pipelineJob?: string;\n  /** The service account that the tuningJob workload runs as. If not specified, the Vertex AI Secure Fine-Tuned Service Agent in the project will be used. See https://cloud.google.com/iam/docs/service-agents#vertex-ai-secure-fine-tuning-service-agent Users starting the pipeline must have the `iam.serviceAccounts.actAs` permission on this service account. */\n  serviceAccount?: string;\n  /** Optional. The display name of the TunedModel. The name can be up to 128 characters long and can consist of any UTF-8 characters. */\n  tunedModelDisplayName?: string;\n  /** Tuning Spec for Veo Tuning. */\n  veoTuningSpec?: VeoTuningSpec;\n}\n\n/** Configuration for the list tuning jobs method. */\nexport declare interface ListTuningJobsConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n  pageSize?: number;\n  pageToken?: string;\n  filter?: string;\n}\n\n/** Parameters for the list tuning jobs method. */\nexport declare interface ListTuningJobsParameters {\n  config?: ListTuningJobsConfig;\n}\n\n/** Response for the list tuning jobs method. */\nexport class ListTuningJobsResponse {\n  /** Used to retain the full HTTP response. */\n  sdkHttpResponse?: HttpResponse;\n  /** A token to retrieve the next page of results. Pass to ListTuningJobsRequest.page_token to obtain that page. */\n  nextPageToken?: string;\n  /** List of TuningJobs in the requested page. */\n  tuningJobs?: TuningJob[];\n}\n\n/** Optional parameters for tunings.cancel method. */\nexport declare interface CancelTuningJobConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n}\n\n/** Parameters for the cancel method. */\nexport declare interface CancelTuningJobParameters {\n  /** The resource name of the tuning job. */\n  name: string;\n  /** Optional parameters for the request. */\n  config?: CancelTuningJobConfig;\n}\n\n/** A single example for tuning. This data type is not supported in Vertex AI. */\nexport declare interface TuningExample {\n  /** Required. The expected model output. */\n  output?: string;\n  /** Optional. Text model input. */\n  textInput?: string;\n}\n\n/** Supervised fine-tuning training dataset. */\nexport declare interface TuningDataset {\n  /** GCS URI of the file containing training dataset in JSONL format. */\n  gcsUri?: string;\n  /** The resource name of the Vertex Multimodal Dataset that is used as training dataset. Example: 'projects/my-project-id-or-number/locations/my-location/datasets/my-dataset-id'. */\n  vertexDatasetResource?: string;\n  /** Inline examples with simple input/output text. */\n  examples?: TuningExample[];\n}\n\nexport declare interface TuningValidationDataset {\n  /** GCS URI of the file containing validation dataset in JSONL format. */\n  gcsUri?: string;\n  /** The resource name of the Vertex Multimodal Dataset that is used as validation dataset. Example: 'projects/my-project-id-or-number/locations/my-location/datasets/my-dataset-id'. */\n  vertexDatasetResource?: string;\n}\n\n/** Supervised fine-tuning job creation request - optional fields. */\nexport declare interface CreateTuningJobConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n  /** Validation dataset for tuning. The dataset must be formatted as a JSONL file. */\n  validationDataset?: TuningValidationDataset;\n  /** The display name of the tuned Model. The name can be up to 128 characters long and can consist of any UTF-8 characters. */\n  tunedModelDisplayName?: string;\n  /** The description of the TuningJob */\n  description?: string;\n  /** Number of complete passes the model makes over the entire training dataset during training. */\n  epochCount?: number;\n  /** Multiplier for adjusting the default learning rate. */\n  learningRateMultiplier?: number;\n  /** If set to true, disable intermediate checkpoints for SFT and only the last checkpoint will be exported. Otherwise, enable intermediate checkpoints for SFT. */\n  exportLastCheckpointOnly?: boolean;\n  /** The optional checkpoint id of the pre-tuned model to use for tuning, if applicable. */\n  preTunedModelCheckpointId?: string;\n  /** Adapter size for tuning. */\n  adapterSize?: AdapterSize;\n  /** The batch size hyperparameter for tuning. If not set, a default of 4 or 16 will be used based on the number of training examples. */\n  batchSize?: number;\n  /** The learning rate hyperparameter for tuning. If not set, a default of 0.001 or 0.0002 will be calculated based on the number of training examples. */\n  learningRate?: number;\n  /** Optional. The labels with user-defined metadata to organize TuningJob and generated resources such as Model and Endpoint. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels. */\n  labels?: Record<string, string>;\n}\n\n/** Supervised fine-tuning job creation parameters - optional fields. */\nexport declare interface CreateTuningJobParametersPrivate {\n  /** The base model that is being tuned, e.g., \"gemini-2.5-flash\". */\n  baseModel?: string;\n  /** The PreTunedModel that is being tuned. */\n  preTunedModel?: PreTunedModel;\n  /** Cloud Storage path to file containing training dataset for tuning. The dataset must be formatted as a JSONL file. */\n  trainingDataset: TuningDataset;\n  /** Configuration for the tuning job. */\n  config?: CreateTuningJobConfig;\n}\n\n/** A long-running operation. */\nexport declare interface TuningOperation {\n  /** Used to retain the full HTTP response. */\n  sdkHttpResponse?: HttpResponse;\n  /** The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`. */\n  name?: string;\n  /** Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata.  Any method that returns a long-running operation should document the metadata type, if any. */\n  metadata?: Record<string, unknown>;\n  /** If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available. */\n  done?: boolean;\n  /** The error result of the operation in case of failure or cancellation. */\n  error?: Record<string, unknown>;\n}\n\n/** Optional configuration for cached content creation. */\nexport declare interface CreateCachedContentConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n  /** The TTL for this resource. The expiration time is computed: now + TTL. It is a duration string, with up to nine fractional digits, terminated by 's'. Example: \"3.5s\". */\n  ttl?: string;\n  /** Timestamp of when this resource is considered expired. Uses RFC 3339 format, Example: 2014-10-02T15:01:23Z. */\n  expireTime?: string;\n  /** The user-generated meaningful display name of the cached content.\n   */\n  displayName?: string;\n  /** The content to cache.\n   */\n  contents?: ContentListUnion;\n  /** Developer set system instruction.\n   */\n  systemInstruction?: ContentUnion;\n  /** A list of `Tools` the model may use to generate the next response.\n   */\n  tools?: Tool[];\n  /** Configuration for the tools to use. This config is shared for all tools.\n   */\n  toolConfig?: ToolConfig;\n  /** The Cloud KMS resource identifier of the customer managed\n      encryption key used to protect a resource.\n      The key needs to be in the same region as where the compute resource is\n      created. See\n      https://cloud.google.com/vertex-ai/docs/general/cmek for more\n      details. If this is set, then all created CachedContent objects\n      will be encrypted with the provided encryption key.\n      Allowed formats: projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}\n       */\n  kmsKeyName?: string;\n}\n\n/** Parameters for caches.create method. */\nexport declare interface CreateCachedContentParameters {\n  /** ID of the model to use. Example: gemini-2.0-flash */\n  model: string;\n  /** Configuration that contains optional parameters.\n   */\n  config?: CreateCachedContentConfig;\n}\n\n/** Metadata on the usage of the cached content. */\nexport declare interface CachedContentUsageMetadata {\n  /** Duration of audio in seconds. This field is not supported in Gemini API. */\n  audioDurationSeconds?: number;\n  /** Number of images. This field is not supported in Gemini API. */\n  imageCount?: number;\n  /** Number of text characters. This field is not supported in Gemini API. */\n  textCount?: number;\n  /** Total number of tokens that the cached content consumes. */\n  totalTokenCount?: number;\n  /** Duration of video in seconds. This field is not supported in Gemini API. */\n  videoDurationSeconds?: number;\n}\n\n/** A resource used in LLM queries for users to explicitly specify what to cache. */\nexport declare interface CachedContent {\n  /** The server-generated resource name of the cached content. */\n  name?: string;\n  /** The user-generated meaningful display name of the cached content. */\n  displayName?: string;\n  /** The name of the publisher model to use for cached content. */\n  model?: string;\n  /** Creation time of the cache entry. */\n  createTime?: string;\n  /** When the cache entry was last updated in UTC time. */\n  updateTime?: string;\n  /** Expiration time of the cached content. */\n  expireTime?: string;\n  /** Metadata on the usage of the cached content. */\n  usageMetadata?: CachedContentUsageMetadata;\n}\n\n/** Optional parameters for caches.get method. */\nexport declare interface GetCachedContentConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n}\n\n/** Parameters for caches.get method. */\nexport declare interface GetCachedContentParameters {\n  /** The server-generated resource name of the cached content.\n   */\n  name: string;\n  /** Optional parameters for the request.\n   */\n  config?: GetCachedContentConfig;\n}\n\n/** Optional parameters for caches.delete method. */\nexport declare interface DeleteCachedContentConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n}\n\n/** Parameters for caches.delete method. */\nexport declare interface DeleteCachedContentParameters {\n  /** The server-generated resource name of the cached content.\n   */\n  name: string;\n  /** Optional parameters for the request.\n   */\n  config?: DeleteCachedContentConfig;\n}\n\n/** Empty response for caches.delete method. */\nexport class DeleteCachedContentResponse {\n  /** Used to retain the full HTTP response. */\n  sdkHttpResponse?: HttpResponse;\n}\n\n/** Optional parameters for caches.update method. */\nexport declare interface UpdateCachedContentConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n  /** The TTL for this resource. The expiration time is computed: now + TTL. It is a duration string, with up to nine fractional digits, terminated by 's'. Example: \"3.5s\". */\n  ttl?: string;\n  /** Timestamp of when this resource is considered expired. Uses RFC 3339 format, Example: 2014-10-02T15:01:23Z. */\n  expireTime?: string;\n}\n\nexport declare interface UpdateCachedContentParameters {\n  /** The server-generated resource name of the cached content.\n   */\n  name: string;\n  /** Configuration that contains optional parameters.\n   */\n  config?: UpdateCachedContentConfig;\n}\n\n/** Config for caches.list method. */\nexport declare interface ListCachedContentsConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n  pageSize?: number;\n  pageToken?: string;\n}\n\n/** Parameters for caches.list method. */\nexport declare interface ListCachedContentsParameters {\n  /** Configuration that contains optional parameters.\n   */\n  config?: ListCachedContentsConfig;\n}\n\nexport class ListCachedContentsResponse {\n  /** Used to retain the full HTTP response. */\n  sdkHttpResponse?: HttpResponse;\n  nextPageToken?: string;\n  /** List of cached contents.\n   */\n  cachedContents?: CachedContent[];\n}\n\n/** Used to override the default configuration. */\nexport declare interface ListFilesConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n  pageSize?: number;\n  pageToken?: string;\n}\n\n/** Generates the parameters for the list method. */\nexport declare interface ListFilesParameters {\n  /** Used to override the default configuration. */\n  config?: ListFilesConfig;\n}\n\n/** Status of a File that uses a common error model. */\nexport declare interface FileStatus {\n  /** A list of messages that carry the error details. There is a common set of message types for APIs to use. */\n  details?: Record<string, unknown>[];\n  /** A list of messages that carry the error details. There is a common set of message types for APIs to use. */\n  message?: string;\n  /** The status code. 0 for OK, 1 for CANCELLED */\n  code?: number;\n}\n\n/** A file uploaded to the API. */\nexport declare interface File {\n  /** The `File` resource name. The ID (name excluding the \"files/\" prefix) can contain up to 40 characters that are lowercase alphanumeric or dashes (-). The ID cannot start or end with a dash. If the name is empty on create, a unique name will be generated. Example: `files/123-456` */\n  name?: string;\n  /** Optional. The human-readable display name for the `File`. The display name must be no more than 512 characters in length, including spaces. Example: 'Welcome Image' */\n  displayName?: string;\n  /** Output only. MIME type of the file. */\n  mimeType?: string;\n  /** Output only. Size of the file in bytes. */\n  sizeBytes?: string;\n  /** Output only. The timestamp of when the `File` was created. */\n  createTime?: string;\n  /** Output only. The timestamp of when the `File` will be deleted. Only set if the `File` is scheduled to expire. */\n  expirationTime?: string;\n  /** Output only. The timestamp of when the `File` was last updated. */\n  updateTime?: string;\n  /** Output only. SHA-256 hash of the uploaded bytes. The hash value is encoded in base64 format. */\n  sha256Hash?: string;\n  /** Output only. The URI of the `File`. */\n  uri?: string;\n  /** Output only. The URI of the `File`, only set for downloadable (generated) files. */\n  downloadUri?: string;\n  /** Output only. Processing state of the File. */\n  state?: FileState;\n  /** Output only. The source of the `File`. */\n  source?: FileSource;\n  /** Output only. Metadata for a video. */\n  videoMetadata?: Record<string, unknown>;\n  /** Output only. Error status if File processing failed. */\n  error?: FileStatus;\n}\n\n/** Response for the list files method. */\nexport class ListFilesResponse {\n  /** Used to retain the full HTTP response. */\n  sdkHttpResponse?: HttpResponse;\n  /** A token that can be sent as a `page_token` into a subsequent `ListFiles` call. */\n  nextPageToken?: string;\n  /** The list of `File`s. */\n  files?: File[];\n}\n\n/** Used to override the default configuration. */\nexport declare interface CreateFileConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n}\n\n/** Generates the parameters for the private _create method. */\nexport declare interface CreateFileParameters {\n  /** The file to be uploaded.\n            mime_type: (Required) The MIME type of the file. Must be provided.\n            name: (Optional) The name of the file in the destination (e.g.\n            'files/sample-image').\n            display_name: (Optional) The display name of the file.\n       */\n  file: File;\n  /** Used to override the default configuration. */\n  config?: CreateFileConfig;\n}\n\n/** Response for the create file method. */\nexport class CreateFileResponse {\n  /** Used to retain the full HTTP response. */\n  sdkHttpResponse?: HttpResponse;\n}\n\n/** Used to override the default configuration. */\nexport declare interface GetFileConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n}\n\n/** Generates the parameters for the get method. */\nexport declare interface GetFileParameters {\n  /** The name identifier for the file to retrieve. */\n  name: string;\n  /** Used to override the default configuration. */\n  config?: GetFileConfig;\n}\n\n/** Used to override the default configuration. */\nexport declare interface DeleteFileConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n}\n\n/** Generates the parameters for the get method. */\nexport declare interface DeleteFileParameters {\n  /** The name identifier for the file to be deleted. */\n  name: string;\n  /** Used to override the default configuration. */\n  config?: DeleteFileConfig;\n}\n\n/** Response for the delete file method. */\nexport class DeleteFileResponse {\n  /** Used to retain the full HTTP response. */\n  sdkHttpResponse?: HttpResponse;\n}\n\n/** Config for inlined request. */\nexport declare interface InlinedRequest {\n  /** ID of the model to use. For a list of models, see `Google models\n      <https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models>`_. */\n  model?: string;\n  /** Content of the request.\n   */\n  contents?: ContentListUnion;\n  /** The metadata to be associated with the request. */\n  metadata?: Record<string, string>;\n  /** Configuration that contains optional model parameters.\n   */\n  config?: GenerateContentConfig;\n}\n\n/** Config for `src` parameter. */\nexport declare interface BatchJobSource {\n  /** Storage format of the input files. Must be one of:\n      'jsonl', 'bigquery'.\n       */\n  format?: string;\n  /** The Google Cloud Storage URIs to input files.\n   */\n  gcsUri?: string[];\n  /** The BigQuery URI to input table.\n   */\n  bigqueryUri?: string;\n  /** The Gemini Developer API's file resource name of the input data\n      (e.g. \"files/12345\").\n       */\n  fileName?: string;\n  /** The Gemini Developer API's inlined input data to run batch job.\n   */\n  inlinedRequests?: InlinedRequest[];\n}\n\n/** Job error. */\nexport declare interface JobError {\n  /** A list of messages that carry the error details. There is a common set of message types for APIs to use. */\n  details?: string[];\n  /** The status code. */\n  code?: number;\n  /** A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the `details` field. */\n  message?: string;\n}\n\n/** Config for `inlined_responses` parameter. */\nexport class InlinedResponse {\n  /** The response to the request.\n   */\n  response?: GenerateContentResponse;\n  /** The error encountered while processing the request.\n   */\n  error?: JobError;\n}\n\n/** Config for `response` parameter. */\nexport class SingleEmbedContentResponse {\n  /** The response to the request.\n   */\n  embedding?: ContentEmbedding;\n  /** The error encountered while processing the request.\n   */\n  tokenCount?: string;\n}\n\n/** Config for `inlined_embedding_responses` parameter. */\nexport class InlinedEmbedContentResponse {\n  /** The response to the request.\n   */\n  response?: SingleEmbedContentResponse;\n  /** The error encountered while processing the request.\n   */\n  error?: JobError;\n}\n\n/** Config for `des` parameter. */\nexport declare interface BatchJobDestination {\n  /** Storage format of the output files. Must be one of:\n      'jsonl', 'bigquery'.\n       */\n  format?: string;\n  /** The Google Cloud Storage URI to the output file.\n   */\n  gcsUri?: string;\n  /** The BigQuery URI to the output table.\n   */\n  bigqueryUri?: string;\n  /** The Gemini Developer API's file resource name of the output data\n      (e.g. \"files/12345\"). The file will be a JSONL file with a single response\n      per line. The responses will be GenerateContentResponse messages formatted\n      as JSON. The responses will be written in the same order as the input\n      requests.\n       */\n  fileName?: string;\n  /** The responses to the requests in the batch. Returned when the batch was\n      built using inlined requests. The responses will be in the same order as\n      the input requests.\n       */\n  inlinedResponses?: InlinedResponse[];\n  /** The responses to the requests in the batch. Returned when the batch was\n      built using inlined requests. The responses will be in the same order as\n      the input requests.\n       */\n  inlinedEmbedContentResponses?: InlinedEmbedContentResponse[];\n}\n\n/** Config for optional parameters. */\nexport declare interface CreateBatchJobConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n  /** The user-defined name of this BatchJob.\n   */\n  displayName?: string;\n  /** GCS or BigQuery URI prefix for the output predictions. Example:\n      \"gs://path/to/output/data\" or \"bq://projectId.bqDatasetId.bqTableId\".\n       */\n  dest?: BatchJobDestinationUnion;\n}\n\n/** Config for batches.create parameters. */\nexport declare interface CreateBatchJobParameters {\n  /** The name of the model to produces the predictions via the BatchJob.\n   */\n  model?: string;\n  /** GCS URI(-s) or BigQuery URI to your input data to run batch job.\n      Example: \"gs://path/to/input/data\" or \"bq://projectId.bqDatasetId.bqTableId\".\n       */\n  src: BatchJobSourceUnion;\n  /** Optional parameters for creating a BatchJob.\n   */\n  config?: CreateBatchJobConfig;\n}\n\n/** Config for batches.create return value. */\nexport declare interface BatchJob {\n  /** The resource name of the BatchJob. Output only.\".\n   */\n  name?: string;\n  /** The display name of the BatchJob.\n   */\n  displayName?: string;\n  /** The state of the BatchJob.\n   */\n  state?: JobState;\n  /** Output only. Only populated when the job's state is JOB_STATE_FAILED or JOB_STATE_CANCELLED. */\n  error?: JobError;\n  /** The time when the BatchJob was created.\n   */\n  createTime?: string;\n  /** Output only. Time when the Job for the first time entered the `JOB_STATE_RUNNING` state. */\n  startTime?: string;\n  /** The time when the BatchJob was completed.\n   */\n  endTime?: string;\n  /** The time when the BatchJob was last updated.\n   */\n  updateTime?: string;\n  /** The name of the model that produces the predictions via the BatchJob.\n   */\n  model?: string;\n  /** Configuration for the input data.\n   */\n  src?: BatchJobSource;\n  /** Configuration for the output data.\n   */\n  dest?: BatchJobDestination;\n}\n\n/** Parameters for the embed_content method. */\nexport declare interface EmbedContentBatch {\n  /** The content to embed. Only the `parts.text` fields will be counted.\n   */\n  contents?: ContentListUnion;\n  /** Configuration that contains optional parameters.\n   */\n  config?: EmbedContentConfig;\n}\n\nexport declare interface EmbeddingsBatchJobSource {\n  /** The Gemini Developer API's file resource name of the input data\n      (e.g. \"files/12345\").\n       */\n  fileName?: string;\n  /** The Gemini Developer API's inlined input data to run batch job.\n   */\n  inlinedRequests?: EmbedContentBatch;\n}\n\n/** Config for optional parameters. */\nexport declare interface CreateEmbeddingsBatchJobConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n  /** The user-defined name of this BatchJob.\n   */\n  displayName?: string;\n}\n\n/** Config for batches.create parameters. */\nexport declare interface CreateEmbeddingsBatchJobParameters {\n  /** The name of the model to produces the predictions via the BatchJob.\n   */\n  model?: string;\n  /** input data to run batch job\".\n   */\n  src: EmbeddingsBatchJobSource;\n  /** Optional parameters for creating a BatchJob.\n   */\n  config?: CreateEmbeddingsBatchJobConfig;\n}\n\n/** Optional parameters. */\nexport declare interface GetBatchJobConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n}\n\n/** Config for batches.get parameters. */\nexport declare interface GetBatchJobParameters {\n  /** A fully-qualified BatchJob resource name or ID.\n    Example: \"projects/.../locations/.../batchPredictionJobs/456\"\n    or \"456\" when project and location are initialized in the client.\n     */\n  name: string;\n  /** Optional parameters for the request. */\n  config?: GetBatchJobConfig;\n}\n\n/** Optional parameters. */\nexport declare interface CancelBatchJobConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n}\n\n/** Config for batches.cancel parameters. */\nexport declare interface CancelBatchJobParameters {\n  /** A fully-qualified BatchJob resource name or ID.\n    Example: \"projects/.../locations/.../batchPredictionJobs/456\"\n    or \"456\" when project and location are initialized in the client.\n     */\n  name: string;\n  /** Optional parameters for the request. */\n  config?: CancelBatchJobConfig;\n}\n\n/** Config for optional parameters. */\nexport declare interface ListBatchJobsConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n  pageSize?: number;\n  pageToken?: string;\n  filter?: string;\n}\n\n/** Config for batches.list parameters. */\nexport declare interface ListBatchJobsParameters {\n  config?: ListBatchJobsConfig;\n}\n\n/** Config for batches.list return value. */\nexport class ListBatchJobsResponse {\n  /** Used to retain the full HTTP response. */\n  sdkHttpResponse?: HttpResponse;\n  nextPageToken?: string;\n  batchJobs?: BatchJob[];\n}\n\n/** Optional parameters for models.get method. */\nexport declare interface DeleteBatchJobConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n}\n\n/** Config for batches.delete parameters. */\nexport declare interface DeleteBatchJobParameters {\n  /** A fully-qualified BatchJob resource name or ID.\n    Example: \"projects/.../locations/.../batchPredictionJobs/456\"\n    or \"456\" when project and location are initialized in the client.\n     */\n  name: string;\n  /** Optional parameters for the request. */\n  config?: DeleteBatchJobConfig;\n}\n\n/** The return value of delete operation. */\nexport declare interface DeleteResourceJob {\n  /** Used to retain the full HTTP response. */\n  sdkHttpResponse?: HttpResponse;\n  name?: string;\n  done?: boolean;\n  error?: JobError;\n}\n\nexport declare interface GetOperationConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n}\n\n/** Parameters for the GET method. */\nexport declare interface GetOperationParameters {\n  /** The server-assigned name for the operation. */\n  operationName: string;\n  /** Used to override the default configuration. */\n  config?: GetOperationConfig;\n}\n\nexport declare interface FetchPredictOperationConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n}\n\n/** Parameters for the fetchPredictOperation method. */\nexport declare interface FetchPredictOperationParameters {\n  /** The server-assigned name for the operation. */\n  operationName: string;\n  resourceName: string;\n  /** Used to override the default configuration. */\n  config?: FetchPredictOperationConfig;\n}\n\nexport declare interface TestTableItem {\n  /** The name of the test. This is used to derive the replay id. */\n  name?: string;\n  /** The parameters to the test. Use pydantic models. */\n  parameters?: Record<string, unknown>;\n  /** Expects an exception for MLDev matching the string. */\n  exceptionIfMldev?: string;\n  /** Expects an exception for Vertex matching the string. */\n  exceptionIfVertex?: string;\n  /** Use if you don't want to use the default replay id which is derived from the test name. */\n  overrideReplayId?: string;\n  /** True if the parameters contain an unsupported union type. This test  will be skipped for languages that do not support the union type. */\n  hasUnion?: boolean;\n  /** When set to a reason string, this test will be skipped in the API mode. Use this flag for tests that can not be reproduced with the real API. E.g. a test that deletes a resource. */\n  skipInApiMode?: string;\n  /** Keys to ignore when comparing the request and response. This is useful for tests that are not deterministic. */\n  ignoreKeys?: string[];\n}\n\nexport declare interface TestTableFile {\n  comment?: string;\n  testMethod?: string;\n  parameterNames?: string[];\n  testTable?: TestTableItem[];\n}\n\n/** Represents a single request in a replay. */\nexport declare interface ReplayRequest {\n  method?: string;\n  url?: string;\n  headers?: Record<string, string>;\n  bodySegments?: Record<string, unknown>[];\n}\n\n/** Represents a single response in a replay. */\nexport class ReplayResponse {\n  statusCode?: number;\n  headers?: Record<string, string>;\n  bodySegments?: Record<string, unknown>[];\n  sdkResponseSegments?: Record<string, unknown>[];\n}\n\n/** Represents a single interaction, request and response in a replay. */\nexport declare interface ReplayInteraction {\n  request?: ReplayRequest;\n  response?: ReplayResponse;\n}\n\n/** Represents a recorded session. */\nexport declare interface ReplayFile {\n  replayId?: string;\n  interactions?: ReplayInteraction[];\n}\n\n/** Used to override the default configuration. */\nexport declare interface UploadFileConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n  /** The name of the file in the destination (e.g., 'files/sample-image'. If not provided one will be generated. */\n  name?: string;\n  /** mime_type: The MIME type of the file. If not provided, it will be inferred from the file extension. */\n  mimeType?: string;\n  /** Optional display name of the file. */\n  displayName?: string;\n}\n\n/** Used to override the default configuration. */\nexport declare interface DownloadFileConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n}\n\n/** Parameters used to download a file. */\nexport declare interface DownloadFileParameters {\n  /** The file to download. It can be a file name, a file object or a generated video. */\n  file: DownloadableFileUnion;\n  /** Location where the file should be downloaded to. */\n  downloadPath: string;\n  /** Configuration to for the download operation. */\n  config?: DownloadFileConfig;\n}\n\n/** Configuration for upscaling an image.\n\nFor more information on this configuration, refer to\nthe `Imagen API reference documentation\n<https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/imagen-api>`_. */\nexport declare interface UpscaleImageConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n  /** Cloud Storage URI used to store the generated images. */\n  outputGcsUri?: string;\n  /** Whether to include a reason for filtered-out images in the\n      response. */\n  includeRaiReason?: boolean;\n  /** The image format that the output should be saved as. */\n  outputMimeType?: string;\n  /** The level of compression. Only applicable if the\n      ``output_mime_type`` is ``image/jpeg``. */\n  outputCompressionQuality?: number;\n  /** Whether to add an image enhancing step before upscaling.\n      It is expected to suppress the noise and JPEG compression artifacts\n      from the input image. */\n  enhanceInputImage?: boolean;\n  /** With a higher image preservation factor, the original image\n      pixels are more respected. With a lower image preservation factor, the\n      output image will have be more different from the input image, but\n      with finer details and less noise. */\n  imagePreservationFactor?: number;\n  /** User specified labels to track billing usage. */\n  labels?: Record<string, string>;\n}\n\n/** User-facing config UpscaleImageParameters. */\nexport declare interface UpscaleImageParameters {\n  /** The model to use. */\n  model: string;\n  /** The input image to upscale. */\n  image: Image;\n  /** The factor to upscale the image (x2 or x4). */\n  upscaleFactor: string;\n  /** Configuration for upscaling. */\n  config?: UpscaleImageConfig;\n}\n\n/** A raw reference image.\n\nA raw reference image represents the base image to edit, provided by the user.\nIt can optionally be provided in addition to a mask reference image or\na style reference image. */\nexport class RawReferenceImage {\n  /** The reference image for the editing operation. */\n  referenceImage?: Image;\n  /** The id of the reference image. */\n  referenceId?: number;\n  /** The type of the reference image. Only set by the SDK. */\n  referenceType?: string;\n  /** Internal method to convert to ReferenceImageAPIInternal. */\n  toReferenceImageAPI(): ReferenceImageAPIInternal {\n    const referenceImageAPI = {\n      referenceType: 'REFERENCE_TYPE_RAW',\n      referenceImage: this.referenceImage,\n      referenceId: this.referenceId,\n    };\n    return referenceImageAPI;\n  }\n}\n\n/** A mask reference image.\n\nThis encapsulates either a mask image provided by the user and configs for\nthe user provided mask, or only config parameters for the model to generate\na mask.\n\nA mask image is an image whose non-zero values indicate where to edit the base\nimage. If the user provides a mask image, the mask must be in the same\ndimensions as the raw image. */\nexport class MaskReferenceImage {\n  /** The reference image for the editing operation. */\n  referenceImage?: Image;\n  /** The id of the reference image. */\n  referenceId?: number;\n  /** The type of the reference image. Only set by the SDK. */\n  referenceType?: string;\n  /** Configuration for the mask reference image. */\n  config?: MaskReferenceConfig;\n  /** Internal method to convert to ReferenceImageAPIInternal. */\n  toReferenceImageAPI(): ReferenceImageAPIInternal {\n    const referenceImageAPI = {\n      referenceType: 'REFERENCE_TYPE_MASK',\n      referenceImage: this.referenceImage,\n      referenceId: this.referenceId,\n      maskImageConfig: this.config,\n    };\n    return referenceImageAPI;\n  }\n}\n\n/** A control reference image.\n\nThe image of the control reference image is either a control image provided\nby the user, or a regular image which the backend will use to generate a\ncontrol image of. In the case of the latter, the\nenable_control_image_computation field in the config should be set to True.\n\nA control image is an image that represents a sketch image of areas for the\nmodel to fill in based on the prompt. */\nexport class ControlReferenceImage {\n  /** The reference image for the editing operation. */\n  referenceImage?: Image;\n  /** The id of the reference image. */\n  referenceId?: number;\n  /** The type of the reference image. Only set by the SDK. */\n  referenceType?: string;\n  /** Configuration for the control reference image. */\n  config?: ControlReferenceConfig;\n  /** Internal method to convert to ReferenceImageAPIInternal. */\n  toReferenceImageAPI(): ReferenceImageAPIInternal {\n    const referenceImageAPI = {\n      referenceType: 'REFERENCE_TYPE_CONTROL',\n      referenceImage: this.referenceImage,\n      referenceId: this.referenceId,\n      controlImageConfig: this.config,\n    };\n    return referenceImageAPI;\n  }\n}\n\n/** A style reference image.\n\nThis encapsulates a style reference image provided by the user, and\nadditionally optional config parameters for the style reference image.\n\nA raw reference image can also be provided as a destination for the style to\nbe applied to. */\nexport class StyleReferenceImage {\n  /** The reference image for the editing operation. */\n  referenceImage?: Image;\n  /** The id of the reference image. */\n  referenceId?: number;\n  /** The type of the reference image. Only set by the SDK. */\n  referenceType?: string;\n  /** Configuration for the style reference image. */\n  config?: StyleReferenceConfig;\n  /** Internal method to convert to ReferenceImageAPIInternal. */\n  toReferenceImageAPI(): ReferenceImageAPIInternal {\n    const referenceImageAPI = {\n      referenceType: 'REFERENCE_TYPE_STYLE',\n      referenceImage: this.referenceImage,\n      referenceId: this.referenceId,\n      styleImageConfig: this.config,\n    };\n    return referenceImageAPI;\n  }\n}\n\n/** A subject reference image.\n\nThis encapsulates a subject reference image provided by the user, and\nadditionally optional config parameters for the subject reference image.\n\nA raw reference image can also be provided as a destination for the subject to\nbe applied to. */\nexport class SubjectReferenceImage {\n  /** The reference image for the editing operation. */\n  referenceImage?: Image;\n  /** The id of the reference image. */\n  referenceId?: number;\n  /** The type of the reference image. Only set by the SDK. */\n  referenceType?: string;\n  /** Configuration for the subject reference image. */\n  config?: SubjectReferenceConfig;\n  /* Internal method to convert to ReferenceImageAPIInternal. */\n  toReferenceImageAPI(): ReferenceImageAPIInternal {\n    const referenceImageAPI = {\n      referenceType: 'REFERENCE_TYPE_SUBJECT',\n      referenceImage: this.referenceImage,\n      referenceId: this.referenceId,\n      subjectImageConfig: this.config,\n    };\n    return referenceImageAPI;\n  }\n}\n\n/** A content reference image.\n\nA content reference image represents a subject to reference (ex. person,\nproduct, animal) provided by the user. It can optionally be provided in\naddition to a style reference image (ex. background, style reference). */\nexport class ContentReferenceImage {\n  /** The reference image for the editing operation. */\n  referenceImage?: Image;\n  /** The id of the reference image. */\n  referenceId?: number;\n  /** The type of the reference image. Only set by the SDK. */\n  referenceType?: string;\n  /** Internal method to convert to ReferenceImageAPIInternal. */\n  toReferenceImageAPI(): ReferenceImageAPIInternal {\n    const referenceImageAPI = {\n      referenceType: 'REFERENCE_TYPE_CONTENT',\n      referenceImage: this.referenceImage,\n      referenceId: this.referenceId,\n    };\n    return referenceImageAPI;\n  }\n}\n\n/** Sent in response to a `LiveGenerateContentSetup` message from the client. */\nexport declare interface LiveServerSetupComplete {\n  /** The session id of the live session. */\n  sessionId?: string;\n}\n\n/** Audio transcription in Server Conent. */\nexport declare interface Transcription {\n  /** Transcription text.\n   */\n  text?: string;\n  /** The bool indicates the end of the transcription.\n   */\n  finished?: boolean;\n}\n\n/** Incremental server update generated by the model in response to client messages.\n\nContent is generated as quickly as possible, and not in real time. Clients\nmay choose to buffer and play it out in real time. */\nexport declare interface LiveServerContent {\n  /** The content that the model has generated as part of the current conversation with the user. */\n  modelTurn?: Content;\n  /** If true, indicates that the model is done generating. Generation will only start in response to additional client messages. Can be set alongside `content`, indicating that the `content` is the last in the turn. */\n  turnComplete?: boolean;\n  /** If true, indicates that a client message has interrupted current model generation. If the client is playing out the content in realtime, this is a good signal to stop and empty the current queue. */\n  interrupted?: boolean;\n  /** Metadata returned to client when grounding is enabled. */\n  groundingMetadata?: GroundingMetadata;\n  /** If true, indicates that the model is done generating. When model is\n      interrupted while generating there will be no generation_complete message\n      in interrupted turn, it will go through interrupted > turn_complete.\n      When model assumes realtime playback there will be delay between\n      generation_complete and turn_complete that is caused by model\n      waiting for playback to finish. If true, indicates that the model\n      has finished generating all content. This is a signal to the client\n      that it can stop sending messages. */\n  generationComplete?: boolean;\n  /** Input transcription. The transcription is independent to the model\n      turn which means it doesnt imply any ordering between transcription and\n      model turn. */\n  inputTranscription?: Transcription;\n  /** Output transcription. The transcription is independent to the model\n      turn which means it doesnt imply any ordering between transcription and\n      model turn.\n       */\n  outputTranscription?: Transcription;\n  /** Metadata related to url context retrieval tool. */\n  urlContextMetadata?: UrlContextMetadata;\n  /** Reason for the turn is complete. */\n  turnCompleteReason?: TurnCompleteReason;\n  /** If true, indicates that the model is not generating content because\n      it is waiting for more input from the user, e.g. because it expects the\n      user to continue talking. */\n  waitingForInput?: boolean;\n}\n\n/** Request for the client to execute the `function_calls` and return the responses with the matching `id`s. */\nexport declare interface LiveServerToolCall {\n  /** The function call to be executed. */\n  functionCalls?: FunctionCall[];\n}\n\n/** Notification for the client that a previously issued `ToolCallMessage` with the specified `id`s should have been not executed and should be cancelled.\n\nIf there were side-effects to those tool calls, clients may attempt to undo\nthe tool calls. This message occurs only in cases where the clients interrupt\nserver turns. */\nexport declare interface LiveServerToolCallCancellation {\n  /** The ids of the tool calls to be cancelled. */\n  ids?: string[];\n}\n\n/** Usage metadata about response(s). */\nexport declare interface UsageMetadata {\n  /** Number of tokens in the prompt. When `cached_content` is set, this is still the total effective prompt size meaning this includes the number of tokens in the cached content. */\n  promptTokenCount?: number;\n  /** Number of tokens in the cached part of the prompt (the cached content). */\n  cachedContentTokenCount?: number;\n  /** Total number of tokens across all the generated response candidates. */\n  responseTokenCount?: number;\n  /** Number of tokens present in tool-use prompt(s). */\n  toolUsePromptTokenCount?: number;\n  /** Number of tokens of thoughts for thinking models. */\n  thoughtsTokenCount?: number;\n  /** Total token count for prompt, response candidates, and tool-use prompts(if present). */\n  totalTokenCount?: number;\n  /** List of modalities that were processed in the request input. */\n  promptTokensDetails?: ModalityTokenCount[];\n  /** List of modalities that were processed in the cache input. */\n  cacheTokensDetails?: ModalityTokenCount[];\n  /** List of modalities that were returned in the response. */\n  responseTokensDetails?: ModalityTokenCount[];\n  /** List of modalities that were processed in the tool-use prompt. */\n  toolUsePromptTokensDetails?: ModalityTokenCount[];\n  /** Traffic type. This shows whether a request consumes Pay-As-You-Go\n or Provisioned Throughput quota. */\n  trafficType?: TrafficType;\n}\n\n/** Server will not be able to service client soon. */\nexport declare interface LiveServerGoAway {\n  /** The remaining time before the connection will be terminated as ABORTED. The minimal time returned here is specified differently together with the rate limits for a given model. */\n  timeLeft?: string;\n}\n\n/** Update of the session resumption state.\n\nOnly sent if `session_resumption` was set in the connection config. */\nexport declare interface LiveServerSessionResumptionUpdate {\n  /** New handle that represents state that can be resumed. Empty if `resumable`=false. */\n  newHandle?: string;\n  /** True if session can be resumed at this point. It might be not possible to resume session at some points. In that case we send update empty new_handle and resumable=false. Example of such case could be model executing function calls or just generating. Resuming session (using previous session token) in such state will result in some data loss. */\n  resumable?: boolean;\n  /** Index of last message sent by client that is included in state represented by this SessionResumptionToken. Only sent when `SessionResumptionConfig.transparent` is set.\n\nPresence of this index allows users to transparently reconnect and avoid issue of losing some part of realtime audio input/video. If client wishes to temporarily disconnect (for example as result of receiving GoAway) they can do it without losing state by buffering messages sent since last `SessionResmumptionTokenUpdate`. This field will enable them to limit buffering (avoid keeping all requests in RAM).\n\nNote: This should not be used for when resuming a session at some time later -- in those cases partial audio and video frames arelikely not needed. */\n  lastConsumedClientMessageIndex?: string;\n}\n\n/** Response message for API call. */\nexport class LiveServerMessage {\n  /** Sent in response to a `LiveClientSetup` message from the client. */\n  setupComplete?: LiveServerSetupComplete;\n  /** Content generated by the model in response to client messages. */\n  serverContent?: LiveServerContent;\n  /** Request for the client to execute the `function_calls` and return the responses with the matching `id`s. */\n  toolCall?: LiveServerToolCall;\n  /** Notification for the client that a previously issued `ToolCallMessage` with the specified `id`s should have been not executed and should be cancelled. */\n  toolCallCancellation?: LiveServerToolCallCancellation;\n  /** Usage metadata about model response(s). */\n  usageMetadata?: UsageMetadata;\n  /** Server will disconnect soon. */\n  goAway?: LiveServerGoAway;\n  /** Update of the session resumption state. */\n  sessionResumptionUpdate?: LiveServerSessionResumptionUpdate;\n  /**\n   * Returns the concatenation of all text parts from the server content if present.\n   *\n   * @remarks\n   * If there are non-text parts in the response, the concatenation of all text\n   * parts will be returned, and a warning will be logged.\n   */\n  get text(): string | undefined {\n    let text = '';\n    let anyTextPartFound = false;\n    const nonTextParts = [];\n    for (const part of this.serverContent?.modelTurn?.parts ?? []) {\n      for (const [fieldName, fieldValue] of Object.entries(part)) {\n        if (\n          fieldName !== 'text' &&\n          fieldName !== 'thought' &&\n          fieldValue !== null\n        ) {\n          nonTextParts.push(fieldName);\n        }\n      }\n      if (typeof part.text === 'string') {\n        if (typeof part.thought === 'boolean' && part.thought) {\n          continue;\n        }\n        anyTextPartFound = true;\n        text += part.text;\n      }\n    }\n    if (nonTextParts.length > 0) {\n      console.warn(\n        `there are non-text parts ${nonTextParts} in the response, returning concatenation of all text parts. Please refer to the non text parts for a full response from model.`,\n      );\n    }\n    // part.text === '' is different from part.text is null\n    return anyTextPartFound ? text : undefined;\n  }\n\n  /**\n   * Returns the concatenation of all inline data parts from the server content if present.\n   *\n   * @remarks\n   * If there are non-inline data parts in the\n   * response, the concatenation of all inline data parts will be returned, and\n   * a warning will be logged.\n   */\n  get data(): string | undefined {\n    let data = '';\n    const nonDataParts = [];\n    for (const part of this.serverContent?.modelTurn?.parts ?? []) {\n      for (const [fieldName, fieldValue] of Object.entries(part)) {\n        if (fieldName !== 'inlineData' && fieldValue !== null) {\n          nonDataParts.push(fieldName);\n        }\n      }\n      if (part.inlineData && typeof part.inlineData.data === 'string') {\n        data += atob(part.inlineData.data);\n      }\n    }\n    if (nonDataParts.length > 0) {\n      console.warn(\n        `there are non-data parts ${nonDataParts} in the response, returning concatenation of all data parts. Please refer to the non data parts for a full response from model.`,\n      );\n    }\n    return data.length > 0 ? btoa(data) : undefined;\n  }\n}\n\n/** Parameters of the fromAPIResponse method of the Operation class. */\nexport declare interface OperationFromAPIResponseParameters {\n  /** The API response to be converted to an Operation. */\n  apiResponse: Record<string, unknown>;\n  /** Whether the API response is from Vertex AI. */\n  isVertexAI: boolean;\n}\n\n/**\n * Config for thinking feature.\n *\n * @deprecated This interface will be deprecated. Please use `ThinkingConfig` instead.\n */\nexport declare interface GenerationConfigThinkingConfig\n  extends ThinkingConfig {}\n\n/** Configures automatic detection of activity. */\nexport declare interface AutomaticActivityDetection {\n  /** If enabled, detected voice and text input count as activity. If disabled, the client must send activity signals. */\n  disabled?: boolean;\n  /** Determines how likely speech is to be detected. */\n  startOfSpeechSensitivity?: StartSensitivity;\n  /** Determines how likely detected speech is ended. */\n  endOfSpeechSensitivity?: EndSensitivity;\n  /** The required duration of detected speech before start-of-speech is committed. The lower this value the more sensitive the start-of-speech detection is and the shorter speech can be recognized. However, this also increases the probability of false positives. */\n  prefixPaddingMs?: number;\n  /** The required duration of detected non-speech (e.g. silence) before end-of-speech is committed. The larger this value, the longer speech gaps can be without interrupting the user's activity but this will increase the model's latency. */\n  silenceDurationMs?: number;\n}\n\n/** Marks the end of user activity.\n\nThis can only be sent if automatic (i.e. server-side) activity detection is\ndisabled. */\nexport declare interface RealtimeInputConfig {\n  /** If not set, automatic activity detection is enabled by default. If automatic voice detection is disabled, the client must send activity signals. */\n  automaticActivityDetection?: AutomaticActivityDetection;\n  /** Defines what effect activity has. */\n  activityHandling?: ActivityHandling;\n  /** Defines which input is included in the user's turn. */\n  turnCoverage?: TurnCoverage;\n}\n\n/** Configuration of session resumption mechanism.\n\nIncluded in `LiveConnectConfig.session_resumption`. If included server\nwill send `LiveServerSessionResumptionUpdate` messages. */\nexport declare interface SessionResumptionConfig {\n  /** Session resumption handle of previous session (session to restore).\n\nIf not present new session will be started. */\n  handle?: string;\n  /** If set the server will send `last_consumed_client_message_index` in the `session_resumption_update` messages to allow for transparent reconnections. */\n  transparent?: boolean;\n}\n\n/** Context window will be truncated by keeping only suffix of it.\n\nContext window will always be cut at start of USER role turn. System\ninstructions and `BidiGenerateContentSetup.prefix_turns` will not be\nsubject to the sliding window mechanism, they will always stay at the\nbeginning of context window. */\nexport declare interface SlidingWindow {\n  /** Session reduction target -- how many tokens we should keep. Window shortening operation has some latency costs, so we should avoid running it on every turn. Should be < trigger_tokens. If not set, trigger_tokens/2 is assumed. */\n  targetTokens?: string;\n}\n\n/** Enables context window compression -- mechanism managing model context window so it does not exceed given length. */\nexport declare interface ContextWindowCompressionConfig {\n  /** Number of tokens (before running turn) that triggers context window compression mechanism. */\n  triggerTokens?: string;\n  /** Sliding window compression mechanism. */\n  slidingWindow?: SlidingWindow;\n}\n\n/** The audio transcription configuration in Setup. */\nexport declare interface AudioTranscriptionConfig {}\n\n/** Config for proactivity features. */\nexport declare interface ProactivityConfig {\n  /** If enabled, the model can reject responding to the last prompt. For\n        example, this allows the model to ignore out of context speech or to stay\n        silent if the user did not make a request, yet. */\n  proactiveAudio?: boolean;\n}\n\n/** Message contains configuration that will apply for the duration of the streaming session. */\nexport declare interface LiveClientSetup {\n  /** \n      The fully qualified name of the publisher model or tuned model endpoint to\n      use.\n       */\n  model?: string;\n  /** The generation configuration for the session.\n      Note: only a subset of fields are supported.\n       */\n  generationConfig?: GenerationConfig;\n  /** The user provided system instructions for the model.\n      Note: only text should be used in parts and content in each part will be\n      in a separate paragraph. */\n  systemInstruction?: ContentUnion;\n  /**  A list of `Tools` the model may use to generate the next response.\n\n      A `Tool` is a piece of code that enables the system to interact with\n      external systems to perform an action, or set of actions, outside of\n      knowledge and scope of the model. */\n  tools?: ToolListUnion;\n  /** Configures the realtime input behavior in BidiGenerateContent. */\n  realtimeInputConfig?: RealtimeInputConfig;\n  /** Configures session resumption mechanism.\n\n          If included server will send SessionResumptionUpdate messages. */\n  sessionResumption?: SessionResumptionConfig;\n  /** Configures context window compression mechanism.\n\n      If included, server will compress context window to fit into given length. */\n  contextWindowCompression?: ContextWindowCompressionConfig;\n  /** The transcription of the input aligns with the input audio language.\n   */\n  inputAudioTranscription?: AudioTranscriptionConfig;\n  /** The transcription of the output aligns with the language code\n      specified for the output audio.\n       */\n  outputAudioTranscription?: AudioTranscriptionConfig;\n  /** Configures the proactivity of the model. This allows the model to respond proactively to\n    the input and to ignore irrelevant input. */\n  proactivity?: ProactivityConfig;\n}\n\n/** Incremental update of the current conversation delivered from the client.\n\nAll the content here will unconditionally be appended to the conversation\nhistory and used as part of the prompt to the model to generate content.\n\nA message here will interrupt any current model generation. */\nexport declare interface LiveClientContent {\n  /** The content appended to the current conversation with the model.\n\n      For single-turn queries, this is a single instance. For multi-turn\n      queries, this is a repeated field that contains conversation history and\n      latest request.\n       */\n  turns?: Content[];\n  /** If true, indicates that the server content generation should start with\n  the currently accumulated prompt. Otherwise, the server will await\n  additional messages before starting generation. */\n  turnComplete?: boolean;\n}\n\n/** Marks the start of user activity.\n\nThis can only be sent if automatic (i.e. server-side) activity detection is\ndisabled. */\nexport declare interface ActivityStart {}\n\n/** Marks the end of user activity.\n\nThis can only be sent if automatic (i.e. server-side) activity detection is\ndisabled. */\nexport declare interface ActivityEnd {}\n\n/** User input that is sent in real time.\n\nThis is different from `LiveClientContent` in a few ways:\n\n  - Can be sent continuously without interruption to model generation.\n  - If there is a need to mix data interleaved across the\n    `LiveClientContent` and the `LiveClientRealtimeInput`, server attempts to\n    optimize for best response, but there are no guarantees.\n  - End of turn is not explicitly specified, but is rather derived from user\n    activity (for example, end of speech).\n  - Even before the end of turn, the data is processed incrementally\n    to optimize for a fast start of the response from the model.\n  - Is always assumed to be the user's input (cannot be used to populate\n    conversation history). */\nexport declare interface LiveClientRealtimeInput {\n  /** Inlined bytes data for media input. */\n  mediaChunks?: Blob[];\n  /** The realtime audio input stream. */\n  audio?: Blob;\n  /** \nIndicates that the audio stream has ended, e.g. because the microphone was\nturned off.\n\nThis should only be sent when automatic activity detection is enabled\n(which is the default).\n\nThe client can reopen the stream by sending an audio message.\n */\n  audioStreamEnd?: boolean;\n  /** The realtime video input stream. */\n  video?: Blob;\n  /** The realtime text input stream. */\n  text?: string;\n  /** Marks the start of user activity. */\n  activityStart?: ActivityStart;\n  /** Marks the end of user activity. */\n  activityEnd?: ActivityEnd;\n}\n\n/** Client generated response to a `ToolCall` received from the server.\n\nIndividual `FunctionResponse` objects are matched to the respective\n`FunctionCall` objects by the `id` field.\n\nNote that in the unary and server-streaming GenerateContent APIs function\ncalling happens by exchanging the `Content` parts, while in the bidi\nGenerateContent APIs function calling happens over this dedicated set of\nmessages. */\nexport class LiveClientToolResponse {\n  /** The response to the function calls. */\n  functionResponses?: FunctionResponse[];\n}\n\n/** Parameters for sending realtime input to the live API. */\nexport declare interface LiveSendRealtimeInputParameters {\n  /** Realtime input to send to the session. */\n  media?: BlobImageUnion;\n  /** The realtime audio input stream. */\n  audio?: Blob;\n  /** \nIndicates that the audio stream has ended, e.g. because the microphone was\nturned off.\n\nThis should only be sent when automatic activity detection is enabled\n(which is the default).\n\nThe client can reopen the stream by sending an audio message.\n */\n  audioStreamEnd?: boolean;\n  /** The realtime video input stream. */\n  video?: BlobImageUnion;\n  /** The realtime text input stream. */\n  text?: string;\n  /** Marks the start of user activity. */\n  activityStart?: ActivityStart;\n  /** Marks the end of user activity. */\n  activityEnd?: ActivityEnd;\n}\n\n/** Messages sent by the client in the API call. */\nexport declare interface LiveClientMessage {\n  /** Message to be sent by the system when connecting to the API. SDK users should not send this message. */\n  setup?: LiveClientSetup;\n  /** Incremental update of the current conversation delivered from the client. */\n  clientContent?: LiveClientContent;\n  /** User input that is sent in real time. */\n  realtimeInput?: LiveClientRealtimeInput;\n  /** Response to a `ToolCallMessage` received from the server. */\n  toolResponse?: LiveClientToolResponse;\n}\n\n/** Session config for the API connection. */\nexport declare interface LiveConnectConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n  /** The generation configuration for the session. */\n  generationConfig?: GenerationConfig;\n  /** The requested modalities of the response. Represents the set of\n      modalities that the model can return. Defaults to AUDIO if not specified.\n       */\n  responseModalities?: Modality[];\n  /** Value that controls the degree of randomness in token selection.\n      Lower temperatures are good for prompts that require a less open-ended or\n      creative response, while higher temperatures can lead to more diverse or\n      creative results.\n       */\n  temperature?: number;\n  /** Tokens are selected from the most to least probable until the sum\n      of their probabilities equals this value. Use a lower value for less\n      random responses and a higher value for more random responses.\n       */\n  topP?: number;\n  /** For each token selection step, the ``top_k`` tokens with the\n      highest probabilities are sampled. Then tokens are further filtered based\n      on ``top_p`` with the final token selected using temperature sampling. Use\n      a lower number for less random responses and a higher number for more\n      random responses.\n       */\n  topK?: number;\n  /** Maximum number of tokens that can be generated in the response.\n   */\n  maxOutputTokens?: number;\n  /** If specified, the media resolution specified will be used.\n   */\n  mediaResolution?: MediaResolution;\n  /** When ``seed`` is fixed to a specific number, the model makes a best\n      effort to provide the same response for repeated requests. By default, a\n      random number is used.\n       */\n  seed?: number;\n  /** The speech generation configuration.\n   */\n  speechConfig?: SpeechConfig;\n  /** Config for thinking features.\n      An error will be returned if this field is set for models that don't\n      support thinking.\n       */\n  thinkingConfig?: ThinkingConfig;\n  /** If enabled, the model will detect emotions and adapt its responses accordingly. */\n  enableAffectiveDialog?: boolean;\n  /** The user provided system instructions for the model.\n      Note: only text should be used in parts and content in each part will be\n      in a separate paragraph. */\n  systemInstruction?: ContentUnion;\n  /** A list of `Tools` the model may use to generate the next response.\n\n      A `Tool` is a piece of code that enables the system to interact with\n      external systems to perform an action, or set of actions, outside of\n      knowledge and scope of the model. */\n  tools?: ToolListUnion;\n  /** Configures session resumption mechanism.\n\nIf included the server will send SessionResumptionUpdate messages. */\n  sessionResumption?: SessionResumptionConfig;\n  /** The transcription of the input aligns with the input audio language.\n   */\n  inputAudioTranscription?: AudioTranscriptionConfig;\n  /** The transcription of the output aligns with the language code\n      specified for the output audio.\n       */\n  outputAudioTranscription?: AudioTranscriptionConfig;\n  /** Configures the realtime input behavior in BidiGenerateContent. */\n  realtimeInputConfig?: RealtimeInputConfig;\n  /** Configures context window compression mechanism.\n\n      If included, server will compress context window to fit into given length. */\n  contextWindowCompression?: ContextWindowCompressionConfig;\n  /** Configures the proactivity of the model. This allows the model to respond proactively to\n    the input and to ignore irrelevant input. */\n  proactivity?: ProactivityConfig;\n}\n\n/** Parameters for connecting to the live API. */\nexport declare interface LiveConnectParameters {\n  /** ID of the model to use. For a list of models, see `Google models\n    <https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models>`_. */\n  model: string;\n  /** callbacks */\n  callbacks: LiveCallbacks;\n  /** Optional configuration parameters for the request.\n   */\n  config?: LiveConnectConfig;\n}\n\n/** Parameters for initializing a new chat session.\n\nThese parameters are used when creating a chat session with the\n`chats.create()` method. */\nexport declare interface CreateChatParameters {\n  /** The name of the model to use for the chat session.\n\n      For example: 'gemini-2.0-flash', 'gemini-2.0-flash-lite', etc. See Gemini API\n      docs to find the available models.\n       */\n  model: string;\n  /** Config for the entire chat session.\n\n      This config applies to all requests within the session\n      unless overridden by a per-request `config` in `SendMessageParameters`.\n       */\n  config?: GenerateContentConfig;\n  /** The initial conversation history for the chat session.\n\n      This allows you to start the chat with a pre-existing history. The history\n      must be a list of `Content` alternating between 'user' and 'model' roles.\n      It should start with a 'user' message.\n       */\n  history?: Content[];\n}\n\n/** Parameters for sending a message within a chat session.\n\nThese parameters are used with the `chat.sendMessage()` method. */\nexport declare interface SendMessageParameters {\n  /** The message to send to the model.\n\n      The SDK will combine all parts into a single 'user' content to send to\n      the model.\n       */\n  message: PartListUnion;\n  /**  Config for this specific request.\n\n      Please note that the per-request config does not change the chat level\n      config, nor inherit from it. If you intend to use some values from the\n      chat's default config, you must explicitly copy them into this per-request\n      config.\n       */\n  config?: GenerateContentConfig;\n}\n\n/** Parameters for sending client content to the live API. */\nexport declare interface LiveSendClientContentParameters {\n  /** Client content to send to the session. */\n  turns?: ContentListUnion;\n  /** If true, indicates that the server content generation should start with\n  the currently accumulated prompt. Otherwise, the server will await\n  additional messages before starting generation. */\n  turnComplete?: boolean;\n}\n\n/** Parameters for sending tool responses to the live API. */\nexport class LiveSendToolResponseParameters {\n  /** Tool responses to send to the session. */\n  functionResponses: FunctionResponse[] | FunctionResponse = [];\n}\n\n/** Message to be sent by the system when connecting to the API. */\nexport declare interface LiveMusicClientSetup {\n  /** The model's resource name. Format: `models/{model}`. */\n  model?: string;\n}\n\n/** Maps a prompt to a relative weight to steer music generation. */\nexport declare interface WeightedPrompt {\n  /** Text prompt. */\n  text?: string;\n  /** Weight of the prompt. The weight is used to control the relative\n      importance of the prompt. Higher weights are more important than lower\n      weights.\n\n      Weight must not be 0. Weights of all weighted_prompts in this\n      LiveMusicClientContent message will be normalized. */\n  weight?: number;\n}\n\n/** User input to start or steer the music. */\nexport declare interface LiveMusicClientContent {\n  /** Weighted prompts as the model input. */\n  weightedPrompts?: WeightedPrompt[];\n}\n\n/** Configuration for music generation. */\nexport declare interface LiveMusicGenerationConfig {\n  /** Controls the variance in audio generation. Higher values produce\n      higher variance. Range is [0.0, 3.0]. */\n  temperature?: number;\n  /** Controls how the model selects tokens for output. Samples the topK\n      tokens with the highest probabilities. Range is [1, 1000]. */\n  topK?: number;\n  /** Seeds audio generation. If not set, the request uses a randomly\n      generated seed. */\n  seed?: number;\n  /** Controls how closely the model follows prompts.\n      Higher guidance follows more closely, but will make transitions more\n      abrupt. Range is [0.0, 6.0]. */\n  guidance?: number;\n  /** Beats per minute. Range is [60, 200]. */\n  bpm?: number;\n  /** Density of sounds. Range is [0.0, 1.0]. */\n  density?: number;\n  /** Brightness of the music. Range is [0.0, 1.0]. */\n  brightness?: number;\n  /** Scale of the generated music. */\n  scale?: Scale;\n  /** Whether the audio output should contain bass. */\n  muteBass?: boolean;\n  /** Whether the audio output should contain drums. */\n  muteDrums?: boolean;\n  /** Whether the audio output should contain only bass and drums. */\n  onlyBassAndDrums?: boolean;\n  /** The mode of music generation. Default mode is QUALITY. */\n  musicGenerationMode?: MusicGenerationMode;\n}\n\n/** Messages sent by the client in the LiveMusicClientMessage call. */\nexport declare interface LiveMusicClientMessage {\n  /** Message to be sent in the first (and only in the first) `LiveMusicClientMessage`.\n      Clients should wait for a `LiveMusicSetupComplete` message before\n      sending any additional messages. */\n  setup?: LiveMusicClientSetup;\n  /** User input to influence music generation. */\n  clientContent?: LiveMusicClientContent;\n  /** Configuration for music generation. */\n  musicGenerationConfig?: LiveMusicGenerationConfig;\n  /** Playback control signal for the music generation. */\n  playbackControl?: LiveMusicPlaybackControl;\n}\n\n/** Sent in response to a `LiveMusicClientSetup` message from the client. */\nexport declare interface LiveMusicServerSetupComplete {}\n\n/** Prompts and config used for generating this audio chunk. */\nexport declare interface LiveMusicSourceMetadata {\n  /** Weighted prompts for generating this audio chunk. */\n  clientContent?: LiveMusicClientContent;\n  /** Music generation config for generating this audio chunk. */\n  musicGenerationConfig?: LiveMusicGenerationConfig;\n}\n\n/** Representation of an audio chunk. */\nexport declare interface AudioChunk {\n  /** Raw bytes of audio data.\n   * @remarks Encoded as base64 string. */\n  data?: string;\n  /** MIME type of the audio chunk. */\n  mimeType?: string;\n  /** Prompts and config used for generating this audio chunk. */\n  sourceMetadata?: LiveMusicSourceMetadata;\n}\n\n/** Server update generated by the model in response to client messages.\n\nContent is generated as quickly as possible, and not in real time.\nClients may choose to buffer and play it out in real time. */\nexport declare interface LiveMusicServerContent {\n  /** The audio chunks that the model has generated. */\n  audioChunks?: AudioChunk[];\n}\n\n/** A prompt that was filtered with the reason. */\nexport declare interface LiveMusicFilteredPrompt {\n  /** The text prompt that was filtered. */\n  text?: string;\n  /** The reason the prompt was filtered. */\n  filteredReason?: string;\n}\n\n/** Response message for the LiveMusicClientMessage call. */\nexport class LiveMusicServerMessage {\n  /** Message sent in response to a `LiveMusicClientSetup` message from the client.\n      Clients should wait for this message before sending any additional messages. */\n  setupComplete?: LiveMusicServerSetupComplete;\n  /** Content generated by the model in response to client messages. */\n  serverContent?: LiveMusicServerContent;\n  /** A prompt that was filtered with the reason. */\n  filteredPrompt?: LiveMusicFilteredPrompt;\n  /**\n   * Returns the first audio chunk from the server content, if present.\n   *\n   * @remarks\n   * If there are no audio chunks in the response, undefined will be returned.\n   */\n  get audioChunk(): AudioChunk | undefined {\n    if (\n      this.serverContent &&\n      this.serverContent.audioChunks &&\n      this.serverContent.audioChunks.length > 0\n    ) {\n      return this.serverContent.audioChunks[0];\n    }\n    return undefined;\n  }\n}\n\n/** Callbacks for the realtime music API. */\nexport interface LiveMusicCallbacks {\n  /**\n   * Called when a message is received from the server.\n   */\n  onmessage: (e: LiveMusicServerMessage) => void;\n  /**\n   * Called when an error occurs.\n   */\n  onerror?: ((e: ErrorEvent) => void) | null;\n  /**\n   * Called when the websocket connection is closed.\n   */\n  onclose?: ((e: CloseEvent) => void) | null;\n}\n\n/** Parameters for the upload file method. */\nexport interface UploadFileParameters {\n  /** The string path to the file to be uploaded or a Blob object. */\n  file: string | globalThis.Blob;\n  /** Configuration that contains optional parameters. */\n  config?: UploadFileConfig;\n}\n\n/**\n * CallableTool is an invokable tool that can be executed with external\n * application (e.g., via Model Context Protocol) or local functions with\n * function calling.\n */\nexport interface CallableTool {\n  /**\n   * Returns tool that can be called by Gemini.\n   */\n  tool(): Promise<Tool>;\n  /**\n   * Executes the callable tool with the given function call arguments and\n   * returns the response parts from the tool execution.\n   */\n  callTool(functionCalls: FunctionCall[]): Promise<Part[]>;\n}\n\n/**\n * CallableToolConfig is the configuration for a callable tool.\n */\nexport interface CallableToolConfig {\n  /**\n   * Specifies the model's behavior after invoking this tool.\n   */\n  behavior?: Behavior;\n  /**\n   * Timeout for remote calls in milliseconds. Note this timeout applies only to\n   * tool remote calls, and not making HTTP requests to the API. */\n  timeout?: number;\n}\n\n/** Parameters for connecting to the live API. */\nexport declare interface LiveMusicConnectParameters {\n  /** The model's resource name. */\n  model: string;\n  /** Callbacks invoked on server events. */\n  callbacks: LiveMusicCallbacks;\n}\n\n/** Parameters for setting config for the live music API. */\nexport declare interface LiveMusicSetConfigParameters {\n  /** Configuration for music generation. */\n  musicGenerationConfig: LiveMusicGenerationConfig;\n}\n\n/** Parameters for setting weighted prompts for the live music API. */\nexport declare interface LiveMusicSetWeightedPromptsParameters {\n  /** A map of text prompts to weights to use for the generation request. */\n  weightedPrompts: WeightedPrompt[];\n}\n\n/** Config for auth_tokens.create parameters. */\nexport declare interface AuthToken {\n  /** The name of the auth token. */\n  name?: string;\n}\n\n/** Config for LiveConnectConstraints for Auth Token creation. */\nexport declare interface LiveConnectConstraints {\n  /** ID of the model to configure in the ephemeral token for Live API.\n      For a list of models, see `Gemini models\n      <https://ai.google.dev/gemini-api/docs/models>`. */\n  model?: string;\n  /** Configuration specific to Live API connections created using this token. */\n  config?: LiveConnectConfig;\n}\n\n/** Optional parameters. */\nexport declare interface CreateAuthTokenConfig {\n  /** Used to override HTTP request options. */\n  httpOptions?: HttpOptions;\n  /** Abort signal which can be used to cancel the request.\n\n  NOTE: AbortSignal is a client-only operation. Using it to cancel an\n  operation will not cancel the request in the service. You will still\n  be charged usage for any applicable operations.\n       */\n  abortSignal?: AbortSignal;\n  /** An optional time after which, when using the resulting token,\n      messages in Live API sessions will be rejected. (Gemini may\n      preemptively close the session after this time.)\n\n      If not set then this defaults to 30 minutes in the future. If set, this\n      value must be less than 20 hours in the future. */\n  expireTime?: string;\n  /** The time after which new Live API sessions using the token\n      resulting from this request will be rejected.\n\n      If not set this defaults to 60 seconds in the future. If set, this value\n      must be less than 20 hours in the future. */\n  newSessionExpireTime?: string;\n  /** The number of times the token can be used. If this value is zero\n      then no limit is applied. Default is 1. Resuming a Live API session does\n      not count as a use. */\n  uses?: number;\n  /** Configuration specific to Live API connections created using this token. */\n  liveConnectConstraints?: LiveConnectConstraints;\n  /** Additional fields to lock in the effective LiveConnectParameters. */\n  lockAdditionalFields?: string[];\n}\n\n/** Config for auth_tokens.create parameters. */\nexport declare interface CreateAuthTokenParameters {\n  /** Optional parameters for the request. */\n  config?: CreateAuthTokenConfig;\n}\n\n/** Parameters for the get method of the operations module. */\nexport declare interface OperationGetParameters<T, U extends Operation<T>> {\n  /** Used to override the default configuration. */\n  config?: GetOperationConfig;\n  /** The operation to be retrieved. */\n  operation: U;\n}\n\n/** Supervised fine-tuning job creation parameters - optional fields. */\nexport declare interface CreateTuningJobParameters {\n  /** The base model that is being tuned, e.g., \"gemini-2.5-flash\". */\n  baseModel: string;\n  /** Cloud Storage path to file containing training dataset for tuning. The dataset must be formatted as a JSONL file. */\n  trainingDataset: TuningDataset;\n  /** Configuration for the tuning job. */\n  config?: CreateTuningJobConfig;\n}\n\nexport type BlobImageUnion = Blob;\n\nexport type PartUnion = Part | string;\n\nexport type PartListUnion = PartUnion[] | PartUnion;\n\nexport type ContentUnion = Content | PartUnion[] | PartUnion;\n\nexport type ContentListUnion = Content | Content[] | PartUnion | PartUnion[];\n\nexport type SchemaUnion = Schema | unknown;\n\nexport type SpeechConfigUnion = SpeechConfig | string;\n\nexport type ToolUnion = Tool | CallableTool;\n\nexport type ToolListUnion = ToolUnion[];\n\nexport type DownloadableFileUnion = string | File | GeneratedVideo | Video;\n\nexport type BatchJobSourceUnion = BatchJobSource | InlinedRequest[] | string;\n\nexport type BatchJobDestinationUnion = BatchJobDestination | string;\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\nimport type {Tool as McpTool} from '@modelcontextprotocol/sdk/types';\n\nimport {ApiClient} from './_api_client.js';\nimport * as baseTransformers from './_base_transformers.js';\nimport * as types from './types.js';\n\nexport function tModel(apiClient: ApiClient, model: string | unknown): string {\n  if (!model || typeof model !== 'string') {\n    throw new Error('model is required and must be a string');\n  }\n\n  if (apiClient.isVertexAI()) {\n    if (\n      model.startsWith('publishers/') ||\n      model.startsWith('projects/') ||\n      model.startsWith('models/')\n    ) {\n      return model;\n    } else if (model.indexOf('/') >= 0) {\n      const parts = model.split('/', 2);\n      return `publishers/${parts[0]}/models/${parts[1]}`;\n    } else {\n      return `publishers/google/models/${model}`;\n    }\n  } else {\n    if (model.startsWith('models/') || model.startsWith('tunedModels/')) {\n      return model;\n    } else {\n      return `models/${model}`;\n    }\n  }\n}\n\nexport function tCachesModel(\n  apiClient: ApiClient,\n  model: string | unknown,\n): string {\n  const transformedModel = tModel(apiClient, model as string);\n  if (!transformedModel) {\n    return '';\n  }\n\n  if (transformedModel.startsWith('publishers/') && apiClient.isVertexAI()) {\n    // vertex caches only support model name start with projects.\n    return `projects/${apiClient.getProject()}/locations/${apiClient.getLocation()}/${transformedModel}`;\n  } else if (transformedModel.startsWith('models/') && apiClient.isVertexAI()) {\n    return `projects/${apiClient.getProject()}/locations/${apiClient.getLocation()}/publishers/google/${transformedModel}`;\n  } else {\n    return transformedModel;\n  }\n}\n\nexport function tBlobs(\n  blobs: types.BlobImageUnion | types.BlobImageUnion[],\n): types.Blob[] {\n  if (Array.isArray(blobs)) {\n    return blobs.map((blob) => tBlob(blob));\n  } else {\n    return [tBlob(blobs)];\n  }\n}\n\nexport function tBlob(blob: types.BlobImageUnion): types.Blob {\n  if (typeof blob === 'object' && blob !== null) {\n    return blob;\n  }\n\n  throw new Error(\n    `Could not parse input as Blob. Unsupported blob type: ${typeof blob}`,\n  );\n}\n\nexport function tImageBlob(blob: types.BlobImageUnion): types.Blob {\n  const transformedBlob = tBlob(blob);\n  if (\n    transformedBlob.mimeType &&\n    transformedBlob.mimeType.startsWith('image/')\n  ) {\n    return transformedBlob;\n  }\n  throw new Error(`Unsupported mime type: ${transformedBlob.mimeType!}`);\n}\n\nexport function tAudioBlob(blob: types.Blob): types.Blob {\n  const transformedBlob = tBlob(blob);\n  if (\n    transformedBlob.mimeType &&\n    transformedBlob.mimeType.startsWith('audio/')\n  ) {\n    return transformedBlob;\n  }\n  throw new Error(`Unsupported mime type: ${transformedBlob.mimeType!}`);\n}\n\nexport function tPart(origin?: types.PartUnion | null): types.Part {\n  if (origin === null || origin === undefined) {\n    throw new Error('PartUnion is required');\n  }\n  if (typeof origin === 'object') {\n    return origin;\n  }\n  if (typeof origin === 'string') {\n    return {text: origin};\n  }\n  throw new Error(`Unsupported part type: ${typeof origin}`);\n}\n\nexport function tParts(origin?: types.PartListUnion | null): types.Part[] {\n  if (\n    origin === null ||\n    origin === undefined ||\n    (Array.isArray(origin) && origin.length === 0)\n  ) {\n    throw new Error('PartListUnion is required');\n  }\n  if (Array.isArray(origin)) {\n    return origin.map((item) => tPart(item as types.PartUnion)!);\n  }\n  return [tPart(origin)!];\n}\n\nfunction _isContent(origin: unknown): boolean {\n  return (\n    origin !== null &&\n    origin !== undefined &&\n    typeof origin === 'object' &&\n    'parts' in origin &&\n    Array.isArray(origin.parts)\n  );\n}\n\nfunction _isFunctionCallPart(origin: unknown): boolean {\n  return (\n    origin !== null &&\n    origin !== undefined &&\n    typeof origin === 'object' &&\n    'functionCall' in origin\n  );\n}\n\nfunction _isFunctionResponsePart(origin: unknown): boolean {\n  return (\n    origin !== null &&\n    origin !== undefined &&\n    typeof origin === 'object' &&\n    'functionResponse' in origin\n  );\n}\n\nexport function tContent(origin?: types.ContentUnion): types.Content {\n  if (origin === null || origin === undefined) {\n    throw new Error('ContentUnion is required');\n  }\n  if (_isContent(origin)) {\n    // _isContent is a utility function that checks if the\n    // origin is a Content.\n    return origin as types.Content;\n  }\n\n  return {\n    role: 'user',\n    parts: tParts(origin as types.PartListUnion)!,\n  };\n}\n\nexport function tContentsForEmbed(\n  apiClient: ApiClient,\n  origin: types.ContentListUnion,\n): types.ContentUnion[] {\n  if (!origin) {\n    return [];\n  }\n  if (apiClient.isVertexAI() && Array.isArray(origin)) {\n    return origin.flatMap((item) => {\n      const content = tContent(item as types.ContentUnion);\n      if (\n        content.parts &&\n        content.parts.length > 0 &&\n        content.parts[0].text !== undefined\n      ) {\n        return [content.parts[0].text];\n      }\n      return [];\n    });\n  } else if (apiClient.isVertexAI()) {\n    const content = tContent(origin as types.ContentUnion);\n    if (\n      content.parts &&\n      content.parts.length > 0 &&\n      content.parts[0].text !== undefined\n    ) {\n      return [content.parts[0].text];\n    }\n    return [];\n  }\n  if (Array.isArray(origin)) {\n    return origin.map((item) => tContent(item as types.ContentUnion)!);\n  }\n  return [tContent(origin as types.ContentUnion)!];\n}\n\nexport function tContents(origin?: types.ContentListUnion): types.Content[] {\n  if (\n    origin === null ||\n    origin === undefined ||\n    (Array.isArray(origin) && origin.length === 0)\n  ) {\n    throw new Error('contents are required');\n  }\n  if (!Array.isArray(origin)) {\n    // If it's not an array, it's a single content or a single PartUnion.\n    if (_isFunctionCallPart(origin) || _isFunctionResponsePart(origin)) {\n      throw new Error(\n        'To specify functionCall or functionResponse parts, please wrap them in a Content object, specifying the role for them',\n      );\n    }\n    return [tContent(origin as types.ContentUnion)];\n  }\n\n  const result: types.Content[] = [];\n  const accumulatedParts: types.PartUnion[] = [];\n  const isContentArray = _isContent(origin[0]);\n\n  for (const item of origin) {\n    const isContent = _isContent(item);\n\n    if (isContent != isContentArray) {\n      throw new Error(\n        'Mixing Content and Parts is not supported, please group the parts into a the appropriate Content objects and specify the roles for them',\n      );\n    }\n\n    if (isContent) {\n      // `isContent` contains the result of _isContent, which is a utility\n      // function that checks if the item is a Content.\n      result.push(item as types.Content);\n    } else if (_isFunctionCallPart(item) || _isFunctionResponsePart(item)) {\n      throw new Error(\n        'To specify functionCall or functionResponse parts, please wrap them, and any other parts, in Content objects as appropriate, specifying the role for them',\n      );\n    } else {\n      accumulatedParts.push(item as types.PartUnion);\n    }\n  }\n\n  if (!isContentArray) {\n    result.push({role: 'user', parts: tParts(accumulatedParts)});\n  }\n  return result;\n}\n\n/*\nTransform the type field from an array of types to an array of anyOf fields.\nExample:\n  {type: ['STRING', 'NUMBER']}\nwill be transformed to\n  {anyOf: [{type: 'STRING'}, {type: 'NUMBER'}]}\n*/\nfunction flattenTypeArrayToAnyOf(\n  typeList: string[],\n  resultingSchema: types.Schema,\n) {\n  if (typeList.includes('null')) {\n    resultingSchema['nullable'] = true;\n  }\n  const listWithoutNull = typeList.filter((type) => type !== 'null');\n\n  if (listWithoutNull.length === 1) {\n    resultingSchema['type'] = Object.values(types.Type).includes(\n      listWithoutNull[0].toUpperCase() as types.Type,\n    )\n      ? (listWithoutNull[0].toUpperCase() as types.Type)\n      : types.Type.TYPE_UNSPECIFIED;\n  } else {\n    resultingSchema['anyOf'] = [];\n    for (const i of listWithoutNull) {\n      resultingSchema['anyOf'].push({\n        'type': Object.values(types.Type).includes(\n          i.toUpperCase() as types.Type,\n        )\n          ? (i.toUpperCase() as types.Type)\n          : types.Type.TYPE_UNSPECIFIED,\n      });\n    }\n  }\n}\n\nexport function processJsonSchema(\n  _jsonSchema: types.Schema | Record<string, unknown>,\n): types.Schema {\n  const genAISchema: types.Schema = {};\n  const schemaFieldNames = ['items'];\n  const listSchemaFieldNames = ['anyOf'];\n  const dictSchemaFieldNames = ['properties'];\n\n  if (_jsonSchema['type'] && _jsonSchema['anyOf']) {\n    throw new Error('type and anyOf cannot be both populated.');\n  }\n\n  /*\n  This is to handle the nullable array or object. The _jsonSchema will\n  be in the format of {anyOf: [{type: 'null'}, {type: 'object'}]}. The\n  logic is to check if anyOf has 2 elements and one of the element is null,\n  if so, the anyOf field is unnecessary, so we need to get rid of the anyOf\n  field and make the schema nullable. Then use the other element as the new\n  _jsonSchema for processing. This is because the backend doesn't have a null\n  type.\n  This has to be checked before we process any other fields.\n  For example:\n    const objectNullable = z.object({\n      nullableArray: z.array(z.string()).nullable(),\n    });\n  Will have the raw _jsonSchema as:\n  {\n    type: 'OBJECT',\n    properties: {\n        nullableArray: {\n           anyOf: [\n              {type: 'null'},\n              {\n                type: 'array',\n                items: {type: 'string'},\n              },\n            ],\n        }\n    },\n    required: [ 'nullableArray' ],\n  }\n  Will result in following schema compatible with Gemini API:\n    {\n      type: 'OBJECT',\n      properties: {\n         nullableArray: {\n            nullable: true,\n            type: 'ARRAY',\n            items: {type: 'string'},\n         }\n      },\n      required: [ 'nullableArray' ],\n    }\n  */\n  const incomingAnyOf = _jsonSchema['anyOf'] as Record<string, unknown>[];\n  if (incomingAnyOf != null && incomingAnyOf.length == 2) {\n    if (incomingAnyOf[0]!['type'] === 'null') {\n      genAISchema['nullable'] = true;\n      _jsonSchema = incomingAnyOf![1];\n    } else if (incomingAnyOf[1]!['type'] === 'null') {\n      genAISchema['nullable'] = true;\n      _jsonSchema = incomingAnyOf![0];\n    }\n  }\n\n  if (_jsonSchema['type'] instanceof Array) {\n    flattenTypeArrayToAnyOf(_jsonSchema['type'], genAISchema);\n  }\n\n  for (const [fieldName, fieldValue] of Object.entries(_jsonSchema)) {\n    // Skip if the fieldvalue is undefined or null.\n    if (fieldValue == null) {\n      continue;\n    }\n\n    if (fieldName == 'type') {\n      if (fieldValue === 'null') {\n        throw new Error(\n          'type: null can not be the only possible type for the field.',\n        );\n      }\n      if (fieldValue instanceof Array) {\n        // we have already handled the type field with array of types in the\n        // beginning of this function.\n        continue;\n      }\n      genAISchema['type'] = Object.values(types.Type).includes(\n        fieldValue.toUpperCase() as types.Type,\n      )\n        ? fieldValue.toUpperCase()\n        : types.Type.TYPE_UNSPECIFIED;\n    } else if (schemaFieldNames.includes(fieldName)) {\n      (genAISchema as Record<string, unknown>)[fieldName] =\n        processJsonSchema(fieldValue);\n    } else if (listSchemaFieldNames.includes(fieldName)) {\n      const listSchemaFieldValue: Array<types.Schema> = [];\n      for (const item of fieldValue) {\n        if (item['type'] == 'null') {\n          genAISchema['nullable'] = true;\n          continue;\n        }\n        listSchemaFieldValue.push(\n          processJsonSchema(item as Record<string, unknown>),\n        );\n      }\n      (genAISchema as Record<string, unknown>)[fieldName] =\n        listSchemaFieldValue;\n    } else if (dictSchemaFieldNames.includes(fieldName)) {\n      const dictSchemaFieldValue: Record<string, types.Schema> = {};\n      for (const [key, value] of Object.entries(\n        fieldValue as Record<string, unknown>,\n      )) {\n        dictSchemaFieldValue[key] = processJsonSchema(\n          value as Record<string, unknown>,\n        );\n      }\n      (genAISchema as Record<string, unknown>)[fieldName] =\n        dictSchemaFieldValue;\n    } else {\n      // additionalProperties is not included in JSONSchema, skipping it.\n      if (fieldName === 'additionalProperties') {\n        continue;\n      }\n      (genAISchema as Record<string, unknown>)[fieldName] = fieldValue;\n    }\n  }\n  return genAISchema;\n}\n\n// we take the unknown in the schema field because we want enable user to pass\n// the output of major schema declaration tools without casting. Tools such as\n// zodToJsonSchema, typebox, zodToJsonSchema function can return JsonSchema7Type\n// or object, see details in\n// https://github.com/StefanTerdell/zod-to-json-schema/blob/70525efe555cd226691e093d171370a3b10921d1/src/zodToJsonSchema.ts#L7\n// typebox can return unknown, see details in\n// https://github.com/sinclairzx81/typebox/blob/5a5431439f7d5ca6b494d0d18fbfd7b1a356d67c/src/type/create/type.ts#L35\n// Note: proper json schemas with the $schema field set never arrive to this\n// transformer. Schemas with $schema are routed to the equivalent API json\n// schema field.\nexport function tSchema(schema: types.Schema | unknown): types.Schema {\n  return processJsonSchema(schema as types.Schema);\n}\n\nexport function tSpeechConfig(\n  speechConfig: types.SpeechConfigUnion,\n): types.SpeechConfig {\n  if (typeof speechConfig === 'object') {\n    return speechConfig;\n  } else if (typeof speechConfig === 'string') {\n    return {\n      voiceConfig: {\n        prebuiltVoiceConfig: {\n          voiceName: speechConfig,\n        },\n      },\n    };\n  } else {\n    throw new Error(`Unsupported speechConfig type: ${typeof speechConfig}`);\n  }\n}\n\nexport function tLiveSpeechConfig(\n  speechConfig: types.SpeechConfig | object,\n): types.SpeechConfig {\n  if ('multiSpeakerVoiceConfig' in speechConfig) {\n    throw new Error(\n      'multiSpeakerVoiceConfig is not supported in the live API.',\n    );\n  }\n  return speechConfig;\n}\n\nexport function tTool(tool: types.Tool): types.Tool {\n  if (tool.functionDeclarations) {\n    for (const functionDeclaration of tool.functionDeclarations) {\n      if (functionDeclaration.parameters) {\n        if (!Object.keys(functionDeclaration.parameters).includes('$schema')) {\n          functionDeclaration.parameters = processJsonSchema(\n            functionDeclaration.parameters,\n          );\n        } else {\n          if (!functionDeclaration.parametersJsonSchema) {\n            functionDeclaration.parametersJsonSchema =\n              functionDeclaration.parameters;\n            delete functionDeclaration.parameters;\n          }\n        }\n      }\n      if (functionDeclaration.response) {\n        if (!Object.keys(functionDeclaration.response).includes('$schema')) {\n          functionDeclaration.response = processJsonSchema(\n            functionDeclaration.response,\n          );\n        } else {\n          if (!functionDeclaration.responseJsonSchema) {\n            functionDeclaration.responseJsonSchema =\n              functionDeclaration.response;\n            delete functionDeclaration.response;\n          }\n        }\n      }\n    }\n  }\n  return tool;\n}\n\nexport function tTools(tools: types.ToolListUnion | unknown): types.Tool[] {\n  // Check if the incoming type is defined.\n  if (tools === undefined || tools === null) {\n    throw new Error('tools is required');\n  }\n  if (!Array.isArray(tools)) {\n    throw new Error('tools is required and must be an array of Tools');\n  }\n  const result: types.Tool[] = [];\n  for (const tool of tools) {\n    result.push(tool as types.Tool);\n  }\n  return result;\n}\n\n/**\n * Prepends resource name with project, location, resource_prefix if needed.\n *\n * @param client The API client.\n * @param resourceName The resource name.\n * @param resourcePrefix The resource prefix.\n * @param splitsAfterPrefix The number of splits after the prefix.\n * @returns The completed resource name.\n *\n * Examples:\n *\n * ```\n * resource_name = '123'\n * resource_prefix = 'cachedContents'\n * splits_after_prefix = 1\n * client.vertexai = True\n * client.project = 'bar'\n * client.location = 'us-west1'\n * _resource_name(client, resource_name, resource_prefix, splits_after_prefix)\n * returns: 'projects/bar/locations/us-west1/cachedContents/123'\n * ```\n *\n * ```\n * resource_name = 'projects/foo/locations/us-central1/cachedContents/123'\n * resource_prefix = 'cachedContents'\n * splits_after_prefix = 1\n * client.vertexai = True\n * client.project = 'bar'\n * client.location = 'us-west1'\n * _resource_name(client, resource_name, resource_prefix, splits_after_prefix)\n * returns: 'projects/foo/locations/us-central1/cachedContents/123'\n * ```\n *\n * ```\n * resource_name = '123'\n * resource_prefix = 'cachedContents'\n * splits_after_prefix = 1\n * client.vertexai = False\n * _resource_name(client, resource_name, resource_prefix, splits_after_prefix)\n * returns 'cachedContents/123'\n * ```\n *\n * ```\n * resource_name = 'some/wrong/cachedContents/resource/name/123'\n * resource_prefix = 'cachedContents'\n * splits_after_prefix = 1\n * client.vertexai = False\n * # client.vertexai = True\n * _resource_name(client, resource_name, resource_prefix, splits_after_prefix)\n * -> 'some/wrong/resource/name/123'\n * ```\n */\nfunction resourceName(\n  client: ApiClient,\n  resourceName: string,\n  resourcePrefix: string,\n  splitsAfterPrefix: number = 1,\n): string {\n  const shouldAppendPrefix =\n    !resourceName.startsWith(`${resourcePrefix}/`) &&\n    resourceName.split('/').length === splitsAfterPrefix;\n  if (client.isVertexAI()) {\n    if (resourceName.startsWith('projects/')) {\n      return resourceName;\n    } else if (resourceName.startsWith('locations/')) {\n      return `projects/${client.getProject()}/${resourceName}`;\n    } else if (resourceName.startsWith(`${resourcePrefix}/`)) {\n      return `projects/${client.getProject()}/locations/${client.getLocation()}/${resourceName}`;\n    } else if (shouldAppendPrefix) {\n      return `projects/${client.getProject()}/locations/${client.getLocation()}/${resourcePrefix}/${resourceName}`;\n    } else {\n      return resourceName;\n    }\n  }\n  if (shouldAppendPrefix) {\n    return `${resourcePrefix}/${resourceName}`;\n  }\n  return resourceName;\n}\n\nexport function tCachedContentName(\n  apiClient: ApiClient,\n  name: string | unknown,\n): string {\n  if (typeof name !== 'string') {\n    throw new Error('name must be a string');\n  }\n  return resourceName(apiClient, name, 'cachedContents');\n}\n\nexport function tTuningJobStatus(status: string | unknown): string {\n  switch (status) {\n    case 'STATE_UNSPECIFIED':\n      return 'JOB_STATE_UNSPECIFIED';\n    case 'CREATING':\n      return 'JOB_STATE_RUNNING';\n    case 'ACTIVE':\n      return 'JOB_STATE_SUCCEEDED';\n    case 'FAILED':\n      return 'JOB_STATE_FAILED';\n    default:\n      return status as string;\n  }\n}\n\nexport function tBytes(fromImageBytes: string | unknown): string {\n  return baseTransformers.tBytes(fromImageBytes);\n}\n\nfunction _isFile(origin: unknown): boolean {\n  return (\n    origin !== null &&\n    origin !== undefined &&\n    typeof origin === 'object' &&\n    'name' in origin\n  );\n}\n\nexport function isGeneratedVideo(origin: unknown): boolean {\n  return (\n    origin !== null &&\n    origin !== undefined &&\n    typeof origin === 'object' &&\n    'video' in origin\n  );\n}\n\nexport function isVideo(origin: unknown): boolean {\n  return (\n    origin !== null &&\n    origin !== undefined &&\n    typeof origin === 'object' &&\n    'uri' in origin\n  );\n}\n\nexport function tFileName(\n  fromName: string | types.File | types.GeneratedVideo | types.Video,\n): string | undefined {\n  let name: string | undefined;\n\n  if (_isFile(fromName)) {\n    name = (fromName as types.File).name;\n  }\n  if (isVideo(fromName)) {\n    name = (fromName as types.Video).uri;\n    if (name === undefined) {\n      return undefined;\n    }\n  }\n  if (isGeneratedVideo(fromName)) {\n    name = (fromName as types.GeneratedVideo).video?.uri;\n    if (name === undefined) {\n      return undefined;\n    }\n  }\n  if (typeof fromName === 'string') {\n    name = fromName;\n  }\n\n  if (name === undefined) {\n    throw new Error('Could not extract file name from the provided input.');\n  }\n\n  if (name.startsWith('https://')) {\n    const suffix = name.split('files/')[1];\n    const match = suffix.match(/[a-z0-9]+/);\n    if (match === null) {\n      throw new Error(`Could not extract file name from URI ${name}`);\n    }\n    name = match[0];\n  } else if (name.startsWith('files/')) {\n    name = name.split('files/')[1];\n  }\n  return name;\n}\n\nexport function tModelsUrl(\n  apiClient: ApiClient,\n  baseModels: boolean | unknown,\n): string {\n  let res: string;\n  if (apiClient.isVertexAI()) {\n    res = baseModels ? 'publishers/google/models' : 'models';\n  } else {\n    res = baseModels ? 'models' : 'tunedModels';\n  }\n  return res;\n}\n\nexport function tExtractModels(response: unknown): Record<string, unknown>[] {\n  for (const key of ['models', 'tunedModels', 'publisherModels']) {\n    if (hasField(response, key)) {\n      return (response as Record<string, unknown>)[key] as Record<\n        string,\n        unknown\n      >[];\n    }\n  }\n  return [];\n}\n\nfunction hasField(data: unknown, fieldName: string): boolean {\n  return data !== null && typeof data === 'object' && fieldName in data;\n}\n\nexport function mcpToGeminiTool(\n  mcpTool: McpTool,\n  config: types.CallableToolConfig = {},\n): types.Tool {\n  const mcpToolSchema = mcpTool as Record<string, unknown>;\n  const functionDeclaration: Record<string, unknown> = {\n    name: mcpToolSchema['name'],\n    description: mcpToolSchema['description'],\n    parametersJsonSchema: mcpToolSchema['inputSchema'],\n  };\n  if (mcpToolSchema['outputSchema']) {\n    functionDeclaration['responseJsonSchema'] = mcpToolSchema['outputSchema'];\n  }\n  if (config.behavior) {\n    functionDeclaration['behavior'] = config.behavior;\n  }\n\n  const geminiTool = {\n    functionDeclarations: [\n      functionDeclaration as unknown as types.FunctionDeclaration,\n    ],\n  };\n\n  return geminiTool;\n}\n\n/**\n * Converts a list of MCP tools to a single Gemini tool with a list of function\n * declarations.\n */\nexport function mcpToolsToGeminiTool(\n  mcpTools: McpTool[],\n  config: types.CallableToolConfig = {},\n): types.Tool {\n  const functionDeclarations: types.FunctionDeclaration[] = [];\n  const toolNames = new Set<string>();\n  for (const mcpTool of mcpTools) {\n    const mcpToolName = mcpTool.name as string;\n    if (toolNames.has(mcpToolName)) {\n      throw new Error(\n        `Duplicate function name ${\n          mcpToolName\n        } found in MCP tools. Please ensure function names are unique.`,\n      );\n    }\n    toolNames.add(mcpToolName);\n    const geminiTool = mcpToGeminiTool(mcpTool, config);\n    if (geminiTool.functionDeclarations) {\n      functionDeclarations.push(...geminiTool.functionDeclarations);\n    }\n  }\n\n  return {functionDeclarations: functionDeclarations};\n}\n\n// Transforms a source input into a BatchJobSource object with validation.\nexport function tBatchJobSource(\n  client: ApiClient,\n  src: string | types.InlinedRequest[] | types.BatchJobSource,\n): types.BatchJobSource {\n  let sourceObj: types.BatchJobSource;\n\n  if (typeof src === 'string') {\n    if (client.isVertexAI()) {\n      if (src.startsWith('gs://')) {\n        sourceObj = {format: 'jsonl', gcsUri: [src]};\n      } else if (src.startsWith('bq://')) {\n        sourceObj = {format: 'bigquery', bigqueryUri: src};\n      } else {\n        throw new Error(`Unsupported string source for Vertex AI: ${src}`);\n      }\n    } else {\n      // MLDEV\n      if (src.startsWith('files/')) {\n        sourceObj = {fileName: src}; // Default to fileName for string input\n      } else {\n        throw new Error(`Unsupported string source for Gemini API: ${src}`);\n      }\n    }\n  } else if (Array.isArray(src)) {\n    if (client.isVertexAI()) {\n      throw new Error('InlinedRequest[] is not supported in Vertex AI.');\n    }\n    sourceObj = {inlinedRequests: src};\n  } else {\n    // It's already a BatchJobSource object\n    sourceObj = src;\n  }\n\n  // Validation logic\n  const vertexSourcesCount = [sourceObj.gcsUri, sourceObj.bigqueryUri].filter(\n    Boolean,\n  ).length;\n\n  const mldevSourcesCount = [\n    sourceObj.inlinedRequests,\n    sourceObj.fileName,\n  ].filter(Boolean).length;\n\n  if (client.isVertexAI()) {\n    if (mldevSourcesCount > 0 || vertexSourcesCount !== 1) {\n      throw new Error(\n        'Exactly one of `gcsUri` or `bigqueryUri` must be set for Vertex AI.',\n      );\n    }\n  } else {\n    // MLDEV\n    if (vertexSourcesCount > 0 || mldevSourcesCount !== 1) {\n      throw new Error(\n        'Exactly one of `inlinedRequests`, `fileName`, ' +\n          'must be set for Gemini API.',\n      );\n    }\n  }\n\n  return sourceObj;\n}\n\nexport function tEmbeddingBatchJobSource(\n  client: ApiClient,\n  src: types.EmbeddingsBatchJobSource,\n): types.EmbeddingsBatchJobSource {\n  if (client.isVertexAI()) {\n    throw new Error('Embedding batch jobs are not supported in Vertex AI.');\n  }\n\n  const sourceObj: types.EmbeddingsBatchJobSource = {...src};\n\n  const mldevSources =\n    Number(!!sourceObj.inlinedRequests) + Number(!!sourceObj.fileName);\n\n  if (mldevSources !== 1) {\n    throw new Error(\n      'Exactly one of `inlinedRequests` or `fileName` must be set for Embedding Batch Jobs in the Gemini API.',\n    );\n  }\n  return sourceObj;\n}\n\nexport function tBatchJobDestination(\n  dest: string | types.BatchJobDestination,\n): types.BatchJobDestination {\n  if (typeof dest !== 'string') {\n    return dest as types.BatchJobDestination;\n  }\n  const destString = dest as string;\n  if (destString.startsWith('gs://')) {\n    return {\n      format: 'jsonl',\n      gcsUri: destString,\n    };\n  } else if (destString.startsWith('bq://')) {\n    return {\n      format: 'bigquery',\n      bigqueryUri: destString,\n    };\n  } else {\n    throw new Error(`Unsupported destination: ${destString}`);\n  }\n}\n\nexport function tRecvBatchJobDestination(\n  dest: unknown,\n): types.BatchJobDestination {\n  // Ensure dest is a non-null object before proceeding.\n  if (typeof dest !== 'object' || dest === null) {\n    // If the input is not an object, it cannot be a valid BatchJobDestination\n    // based on the operations performed. Return it cast, or handle as an error.\n    // Casting an empty object might be a safe default.\n    return {} as types.BatchJobDestination;\n  }\n\n  // Cast to Record<string, unknown> to allow string property access.\n  const obj = dest as Record<string, unknown>;\n\n  // Safely access nested properties.\n  const inlineResponsesVal = obj['inlinedResponses'];\n  if (typeof inlineResponsesVal !== 'object' || inlineResponsesVal === null) {\n    return dest as types.BatchJobDestination;\n  }\n  const inlineResponsesObj = inlineResponsesVal as Record<string, unknown>;\n\n  const responsesArray = inlineResponsesObj['inlinedResponses'];\n  if (!Array.isArray(responsesArray) || responsesArray.length === 0) {\n    return dest as types.BatchJobDestination;\n  }\n\n  // Check if any response has the 'embedding' property.\n  let hasEmbedding = false;\n  for (const responseItem of responsesArray) {\n    if (typeof responseItem !== 'object' || responseItem === null) {\n      continue;\n    }\n    const responseItemObj = responseItem as Record<string, unknown>;\n\n    const responseVal = responseItemObj['response'];\n    if (typeof responseVal !== 'object' || responseVal === null) {\n      continue;\n    }\n    const responseObj = responseVal as Record<string, unknown>;\n\n    // Check for the existence of the 'embedding' key.\n    if (responseObj['embedding'] !== undefined) {\n      hasEmbedding = true;\n      break;\n    }\n  }\n\n  // Perform the transformation if an embedding was found.\n  if (hasEmbedding) {\n    obj['inlinedEmbedContentResponses'] = obj['inlinedResponses'];\n    delete obj['inlinedResponses'];\n  }\n\n  // Cast the (potentially) modified object to the target type.\n  return dest as types.BatchJobDestination;\n}\n\nexport function tBatchJobName(apiClient: ApiClient, name: unknown): string {\n  const nameString = name as string;\n  if (!apiClient.isVertexAI()) {\n    const mldevPattern = /batches\\/[^/]+$/;\n\n    if (mldevPattern.test(nameString)) {\n      return nameString.split('/').pop() as string;\n    } else {\n      throw new Error(`Invalid batch job name: ${nameString}.`);\n    }\n  }\n\n  const vertexPattern =\n    /^projects\\/[^/]+\\/locations\\/[^/]+\\/batchPredictionJobs\\/[^/]+$/;\n\n  if (vertexPattern.test(nameString)) {\n    return nameString.split('/').pop() as string;\n  } else if (/^\\d+$/.test(nameString)) {\n    return nameString;\n  } else {\n    throw new Error(`Invalid batch job name: ${nameString}.`);\n  }\n}\n\nexport function tJobState(state: unknown): string {\n  const stateString = state as string;\n  if (stateString === 'BATCH_STATE_UNSPECIFIED') {\n    return 'JOB_STATE_UNSPECIFIED';\n  } else if (stateString === 'BATCH_STATE_PENDING') {\n    return 'JOB_STATE_PENDING';\n  } else if (stateString === 'BATCH_STATE_RUNNING') {\n    return 'JOB_STATE_RUNNING';\n  } else if (stateString === 'BATCH_STATE_SUCCEEDED') {\n    return 'JOB_STATE_SUCCEEDED';\n  } else if (stateString === 'BATCH_STATE_FAILED') {\n    return 'JOB_STATE_FAILED';\n  } else if (stateString === 'BATCH_STATE_CANCELLED') {\n    return 'JOB_STATE_CANCELLED';\n  } else if (stateString === 'BATCH_STATE_EXPIRED') {\n    return 'JOB_STATE_EXPIRED';\n  } else {\n    return stateString;\n  }\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\n// Code generated by the Google Gen AI SDK generator DO NOT EDIT.\n\nimport {ApiClient} from '../_api_client.js';\nimport * as common from '../_common.js';\nimport * as t from '../_transformers.js';\nimport type * as types from '../types.js';\n\nexport function batchJobDestinationFromMldev(\n  fromObject: types.BatchJobDestination,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromFileName = common.getValueByPath(fromObject, ['responsesFile']);\n  if (fromFileName != null) {\n    common.setValueByPath(toObject, ['fileName'], fromFileName);\n  }\n\n  const fromInlinedResponses = common.getValueByPath(fromObject, [\n    'inlinedResponses',\n    'inlinedResponses',\n  ]);\n  if (fromInlinedResponses != null) {\n    let transformedList = fromInlinedResponses;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return inlinedResponseFromMldev(item);\n      });\n    }\n    common.setValueByPath(toObject, ['inlinedResponses'], transformedList);\n  }\n\n  const fromInlinedEmbedContentResponses = common.getValueByPath(fromObject, [\n    'inlinedEmbedContentResponses',\n    'inlinedResponses',\n  ]);\n  if (fromInlinedEmbedContentResponses != null) {\n    let transformedList = fromInlinedEmbedContentResponses;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(\n      toObject,\n      ['inlinedEmbedContentResponses'],\n      transformedList,\n    );\n  }\n\n  return toObject;\n}\n\nexport function batchJobDestinationFromVertex(\n  fromObject: types.BatchJobDestination,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromFormat = common.getValueByPath(fromObject, ['predictionsFormat']);\n  if (fromFormat != null) {\n    common.setValueByPath(toObject, ['format'], fromFormat);\n  }\n\n  const fromGcsUri = common.getValueByPath(fromObject, [\n    'gcsDestination',\n    'outputUriPrefix',\n  ]);\n  if (fromGcsUri != null) {\n    common.setValueByPath(toObject, ['gcsUri'], fromGcsUri);\n  }\n\n  const fromBigqueryUri = common.getValueByPath(fromObject, [\n    'bigqueryDestination',\n    'outputUri',\n  ]);\n  if (fromBigqueryUri != null) {\n    common.setValueByPath(toObject, ['bigqueryUri'], fromBigqueryUri);\n  }\n\n  return toObject;\n}\n\nexport function batchJobDestinationToVertex(\n  fromObject: types.BatchJobDestination,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromFormat = common.getValueByPath(fromObject, ['format']);\n  if (fromFormat != null) {\n    common.setValueByPath(toObject, ['predictionsFormat'], fromFormat);\n  }\n\n  const fromGcsUri = common.getValueByPath(fromObject, ['gcsUri']);\n  if (fromGcsUri != null) {\n    common.setValueByPath(\n      toObject,\n      ['gcsDestination', 'outputUriPrefix'],\n      fromGcsUri,\n    );\n  }\n\n  const fromBigqueryUri = common.getValueByPath(fromObject, ['bigqueryUri']);\n  if (fromBigqueryUri != null) {\n    common.setValueByPath(\n      toObject,\n      ['bigqueryDestination', 'outputUri'],\n      fromBigqueryUri,\n    );\n  }\n\n  if (common.getValueByPath(fromObject, ['fileName']) !== undefined) {\n    throw new Error('fileName parameter is not supported in Vertex AI.');\n  }\n\n  if (common.getValueByPath(fromObject, ['inlinedResponses']) !== undefined) {\n    throw new Error(\n      'inlinedResponses parameter is not supported in Vertex AI.',\n    );\n  }\n\n  if (\n    common.getValueByPath(fromObject, ['inlinedEmbedContentResponses']) !==\n    undefined\n  ) {\n    throw new Error(\n      'inlinedEmbedContentResponses parameter is not supported in Vertex AI.',\n    );\n  }\n\n  return toObject;\n}\n\nexport function batchJobFromMldev(\n  fromObject: types.BatchJob,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(toObject, ['name'], fromName);\n  }\n\n  const fromDisplayName = common.getValueByPath(fromObject, [\n    'metadata',\n    'displayName',\n  ]);\n  if (fromDisplayName != null) {\n    common.setValueByPath(toObject, ['displayName'], fromDisplayName);\n  }\n\n  const fromState = common.getValueByPath(fromObject, ['metadata', 'state']);\n  if (fromState != null) {\n    common.setValueByPath(toObject, ['state'], t.tJobState(fromState));\n  }\n\n  const fromCreateTime = common.getValueByPath(fromObject, [\n    'metadata',\n    'createTime',\n  ]);\n  if (fromCreateTime != null) {\n    common.setValueByPath(toObject, ['createTime'], fromCreateTime);\n  }\n\n  const fromEndTime = common.getValueByPath(fromObject, [\n    'metadata',\n    'endTime',\n  ]);\n  if (fromEndTime != null) {\n    common.setValueByPath(toObject, ['endTime'], fromEndTime);\n  }\n\n  const fromUpdateTime = common.getValueByPath(fromObject, [\n    'metadata',\n    'updateTime',\n  ]);\n  if (fromUpdateTime != null) {\n    common.setValueByPath(toObject, ['updateTime'], fromUpdateTime);\n  }\n\n  const fromModel = common.getValueByPath(fromObject, ['metadata', 'model']);\n  if (fromModel != null) {\n    common.setValueByPath(toObject, ['model'], fromModel);\n  }\n\n  const fromDest = common.getValueByPath(fromObject, ['metadata', 'output']);\n  if (fromDest != null) {\n    common.setValueByPath(\n      toObject,\n      ['dest'],\n      batchJobDestinationFromMldev(t.tRecvBatchJobDestination(fromDest)),\n    );\n  }\n\n  return toObject;\n}\n\nexport function batchJobFromVertex(\n  fromObject: types.BatchJob,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(toObject, ['name'], fromName);\n  }\n\n  const fromDisplayName = common.getValueByPath(fromObject, ['displayName']);\n  if (fromDisplayName != null) {\n    common.setValueByPath(toObject, ['displayName'], fromDisplayName);\n  }\n\n  const fromState = common.getValueByPath(fromObject, ['state']);\n  if (fromState != null) {\n    common.setValueByPath(toObject, ['state'], t.tJobState(fromState));\n  }\n\n  const fromError = common.getValueByPath(fromObject, ['error']);\n  if (fromError != null) {\n    common.setValueByPath(toObject, ['error'], fromError);\n  }\n\n  const fromCreateTime = common.getValueByPath(fromObject, ['createTime']);\n  if (fromCreateTime != null) {\n    common.setValueByPath(toObject, ['createTime'], fromCreateTime);\n  }\n\n  const fromStartTime = common.getValueByPath(fromObject, ['startTime']);\n  if (fromStartTime != null) {\n    common.setValueByPath(toObject, ['startTime'], fromStartTime);\n  }\n\n  const fromEndTime = common.getValueByPath(fromObject, ['endTime']);\n  if (fromEndTime != null) {\n    common.setValueByPath(toObject, ['endTime'], fromEndTime);\n  }\n\n  const fromUpdateTime = common.getValueByPath(fromObject, ['updateTime']);\n  if (fromUpdateTime != null) {\n    common.setValueByPath(toObject, ['updateTime'], fromUpdateTime);\n  }\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(toObject, ['model'], fromModel);\n  }\n\n  const fromSrc = common.getValueByPath(fromObject, ['inputConfig']);\n  if (fromSrc != null) {\n    common.setValueByPath(toObject, ['src'], batchJobSourceFromVertex(fromSrc));\n  }\n\n  const fromDest = common.getValueByPath(fromObject, ['outputConfig']);\n  if (fromDest != null) {\n    common.setValueByPath(\n      toObject,\n      ['dest'],\n      batchJobDestinationFromVertex(t.tRecvBatchJobDestination(fromDest)),\n    );\n  }\n\n  return toObject;\n}\n\nexport function batchJobSourceFromVertex(\n  fromObject: types.BatchJobSource,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromFormat = common.getValueByPath(fromObject, ['instancesFormat']);\n  if (fromFormat != null) {\n    common.setValueByPath(toObject, ['format'], fromFormat);\n  }\n\n  const fromGcsUri = common.getValueByPath(fromObject, ['gcsSource', 'uris']);\n  if (fromGcsUri != null) {\n    common.setValueByPath(toObject, ['gcsUri'], fromGcsUri);\n  }\n\n  const fromBigqueryUri = common.getValueByPath(fromObject, [\n    'bigquerySource',\n    'inputUri',\n  ]);\n  if (fromBigqueryUri != null) {\n    common.setValueByPath(toObject, ['bigqueryUri'], fromBigqueryUri);\n  }\n\n  return toObject;\n}\n\nexport function batchJobSourceToMldev(\n  apiClient: ApiClient,\n  fromObject: types.BatchJobSource,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  if (common.getValueByPath(fromObject, ['format']) !== undefined) {\n    throw new Error('format parameter is not supported in Gemini API.');\n  }\n\n  if (common.getValueByPath(fromObject, ['gcsUri']) !== undefined) {\n    throw new Error('gcsUri parameter is not supported in Gemini API.');\n  }\n\n  if (common.getValueByPath(fromObject, ['bigqueryUri']) !== undefined) {\n    throw new Error('bigqueryUri parameter is not supported in Gemini API.');\n  }\n\n  const fromFileName = common.getValueByPath(fromObject, ['fileName']);\n  if (fromFileName != null) {\n    common.setValueByPath(toObject, ['fileName'], fromFileName);\n  }\n\n  const fromInlinedRequests = common.getValueByPath(fromObject, [\n    'inlinedRequests',\n  ]);\n  if (fromInlinedRequests != null) {\n    let transformedList = fromInlinedRequests;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return inlinedRequestToMldev(apiClient, item);\n      });\n    }\n    common.setValueByPath(toObject, ['requests', 'requests'], transformedList);\n  }\n\n  return toObject;\n}\n\nexport function batchJobSourceToVertex(\n  fromObject: types.BatchJobSource,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromFormat = common.getValueByPath(fromObject, ['format']);\n  if (fromFormat != null) {\n    common.setValueByPath(toObject, ['instancesFormat'], fromFormat);\n  }\n\n  const fromGcsUri = common.getValueByPath(fromObject, ['gcsUri']);\n  if (fromGcsUri != null) {\n    common.setValueByPath(toObject, ['gcsSource', 'uris'], fromGcsUri);\n  }\n\n  const fromBigqueryUri = common.getValueByPath(fromObject, ['bigqueryUri']);\n  if (fromBigqueryUri != null) {\n    common.setValueByPath(\n      toObject,\n      ['bigquerySource', 'inputUri'],\n      fromBigqueryUri,\n    );\n  }\n\n  if (common.getValueByPath(fromObject, ['fileName']) !== undefined) {\n    throw new Error('fileName parameter is not supported in Vertex AI.');\n  }\n\n  if (common.getValueByPath(fromObject, ['inlinedRequests']) !== undefined) {\n    throw new Error('inlinedRequests parameter is not supported in Vertex AI.');\n  }\n\n  return toObject;\n}\n\nexport function blobToMldev(fromObject: types.Blob): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  if (common.getValueByPath(fromObject, ['displayName']) !== undefined) {\n    throw new Error('displayName parameter is not supported in Gemini API.');\n  }\n\n  const fromData = common.getValueByPath(fromObject, ['data']);\n  if (fromData != null) {\n    common.setValueByPath(toObject, ['data'], fromData);\n  }\n\n  const fromMimeType = common.getValueByPath(fromObject, ['mimeType']);\n  if (fromMimeType != null) {\n    common.setValueByPath(toObject, ['mimeType'], fromMimeType);\n  }\n\n  return toObject;\n}\n\nexport function cancelBatchJobParametersToMldev(\n  apiClient: ApiClient,\n  fromObject: types.CancelBatchJobParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'name'],\n      t.tBatchJobName(apiClient, fromName),\n    );\n  }\n\n  return toObject;\n}\n\nexport function cancelBatchJobParametersToVertex(\n  apiClient: ApiClient,\n  fromObject: types.CancelBatchJobParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'name'],\n      t.tBatchJobName(apiClient, fromName),\n    );\n  }\n\n  return toObject;\n}\n\nexport function candidateFromMldev(\n  fromObject: types.Candidate,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromContent = common.getValueByPath(fromObject, ['content']);\n  if (fromContent != null) {\n    common.setValueByPath(toObject, ['content'], fromContent);\n  }\n\n  const fromCitationMetadata = common.getValueByPath(fromObject, [\n    'citationMetadata',\n  ]);\n  if (fromCitationMetadata != null) {\n    common.setValueByPath(\n      toObject,\n      ['citationMetadata'],\n      citationMetadataFromMldev(fromCitationMetadata),\n    );\n  }\n\n  const fromTokenCount = common.getValueByPath(fromObject, ['tokenCount']);\n  if (fromTokenCount != null) {\n    common.setValueByPath(toObject, ['tokenCount'], fromTokenCount);\n  }\n\n  const fromFinishReason = common.getValueByPath(fromObject, ['finishReason']);\n  if (fromFinishReason != null) {\n    common.setValueByPath(toObject, ['finishReason'], fromFinishReason);\n  }\n\n  const fromUrlContextMetadata = common.getValueByPath(fromObject, [\n    'urlContextMetadata',\n  ]);\n  if (fromUrlContextMetadata != null) {\n    common.setValueByPath(\n      toObject,\n      ['urlContextMetadata'],\n      fromUrlContextMetadata,\n    );\n  }\n\n  const fromAvgLogprobs = common.getValueByPath(fromObject, ['avgLogprobs']);\n  if (fromAvgLogprobs != null) {\n    common.setValueByPath(toObject, ['avgLogprobs'], fromAvgLogprobs);\n  }\n\n  const fromGroundingMetadata = common.getValueByPath(fromObject, [\n    'groundingMetadata',\n  ]);\n  if (fromGroundingMetadata != null) {\n    common.setValueByPath(\n      toObject,\n      ['groundingMetadata'],\n      fromGroundingMetadata,\n    );\n  }\n\n  const fromIndex = common.getValueByPath(fromObject, ['index']);\n  if (fromIndex != null) {\n    common.setValueByPath(toObject, ['index'], fromIndex);\n  }\n\n  const fromLogprobsResult = common.getValueByPath(fromObject, [\n    'logprobsResult',\n  ]);\n  if (fromLogprobsResult != null) {\n    common.setValueByPath(toObject, ['logprobsResult'], fromLogprobsResult);\n  }\n\n  const fromSafetyRatings = common.getValueByPath(fromObject, [\n    'safetyRatings',\n  ]);\n  if (fromSafetyRatings != null) {\n    let transformedList = fromSafetyRatings;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(toObject, ['safetyRatings'], transformedList);\n  }\n\n  return toObject;\n}\n\nexport function citationMetadataFromMldev(\n  fromObject: types.CitationMetadata,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromCitations = common.getValueByPath(fromObject, ['citationSources']);\n  if (fromCitations != null) {\n    let transformedList = fromCitations;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(toObject, ['citations'], transformedList);\n  }\n\n  return toObject;\n}\n\nexport function contentToMldev(\n  fromObject: types.Content,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromParts = common.getValueByPath(fromObject, ['parts']);\n  if (fromParts != null) {\n    let transformedList = fromParts;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return partToMldev(item);\n      });\n    }\n    common.setValueByPath(toObject, ['parts'], transformedList);\n  }\n\n  const fromRole = common.getValueByPath(fromObject, ['role']);\n  if (fromRole != null) {\n    common.setValueByPath(toObject, ['role'], fromRole);\n  }\n\n  return toObject;\n}\n\nexport function createBatchJobConfigToMldev(\n  fromObject: types.CreateBatchJobConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromDisplayName = common.getValueByPath(fromObject, ['displayName']);\n  if (parentObject !== undefined && fromDisplayName != null) {\n    common.setValueByPath(\n      parentObject,\n      ['batch', 'displayName'],\n      fromDisplayName,\n    );\n  }\n\n  if (common.getValueByPath(fromObject, ['dest']) !== undefined) {\n    throw new Error('dest parameter is not supported in Gemini API.');\n  }\n\n  return toObject;\n}\n\nexport function createBatchJobConfigToVertex(\n  fromObject: types.CreateBatchJobConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromDisplayName = common.getValueByPath(fromObject, ['displayName']);\n  if (parentObject !== undefined && fromDisplayName != null) {\n    common.setValueByPath(parentObject, ['displayName'], fromDisplayName);\n  }\n\n  const fromDest = common.getValueByPath(fromObject, ['dest']);\n  if (parentObject !== undefined && fromDest != null) {\n    common.setValueByPath(\n      parentObject,\n      ['outputConfig'],\n      batchJobDestinationToVertex(t.tBatchJobDestination(fromDest)),\n    );\n  }\n\n  return toObject;\n}\n\nexport function createBatchJobParametersToMldev(\n  apiClient: ApiClient,\n  fromObject: types.CreateBatchJobParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'model'],\n      t.tModel(apiClient, fromModel),\n    );\n  }\n\n  const fromSrc = common.getValueByPath(fromObject, ['src']);\n  if (fromSrc != null) {\n    common.setValueByPath(\n      toObject,\n      ['batch', 'inputConfig'],\n      batchJobSourceToMldev(apiClient, t.tBatchJobSource(apiClient, fromSrc)),\n    );\n  }\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    createBatchJobConfigToMldev(fromConfig, toObject);\n  }\n\n  return toObject;\n}\n\nexport function createBatchJobParametersToVertex(\n  apiClient: ApiClient,\n  fromObject: types.CreateBatchJobParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(toObject, ['model'], t.tModel(apiClient, fromModel));\n  }\n\n  const fromSrc = common.getValueByPath(fromObject, ['src']);\n  if (fromSrc != null) {\n    common.setValueByPath(\n      toObject,\n      ['inputConfig'],\n      batchJobSourceToVertex(t.tBatchJobSource(apiClient, fromSrc)),\n    );\n  }\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    createBatchJobConfigToVertex(fromConfig, toObject);\n  }\n\n  return toObject;\n}\n\nexport function createEmbeddingsBatchJobConfigToMldev(\n  fromObject: types.CreateEmbeddingsBatchJobConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromDisplayName = common.getValueByPath(fromObject, ['displayName']);\n  if (parentObject !== undefined && fromDisplayName != null) {\n    common.setValueByPath(\n      parentObject,\n      ['batch', 'displayName'],\n      fromDisplayName,\n    );\n  }\n\n  return toObject;\n}\n\nexport function createEmbeddingsBatchJobParametersToMldev(\n  apiClient: ApiClient,\n  fromObject: types.CreateEmbeddingsBatchJobParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'model'],\n      t.tModel(apiClient, fromModel),\n    );\n  }\n\n  const fromSrc = common.getValueByPath(fromObject, ['src']);\n  if (fromSrc != null) {\n    common.setValueByPath(\n      toObject,\n      ['batch', 'inputConfig'],\n      embeddingsBatchJobSourceToMldev(apiClient, fromSrc),\n    );\n  }\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    createEmbeddingsBatchJobConfigToMldev(fromConfig, toObject);\n  }\n\n  return toObject;\n}\n\nexport function deleteBatchJobParametersToMldev(\n  apiClient: ApiClient,\n  fromObject: types.DeleteBatchJobParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'name'],\n      t.tBatchJobName(apiClient, fromName),\n    );\n  }\n\n  return toObject;\n}\n\nexport function deleteBatchJobParametersToVertex(\n  apiClient: ApiClient,\n  fromObject: types.DeleteBatchJobParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'name'],\n      t.tBatchJobName(apiClient, fromName),\n    );\n  }\n\n  return toObject;\n}\n\nexport function deleteResourceJobFromMldev(\n  fromObject: types.DeleteResourceJob,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSdkHttpResponse = common.getValueByPath(fromObject, [\n    'sdkHttpResponse',\n  ]);\n  if (fromSdkHttpResponse != null) {\n    common.setValueByPath(toObject, ['sdkHttpResponse'], fromSdkHttpResponse);\n  }\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(toObject, ['name'], fromName);\n  }\n\n  const fromDone = common.getValueByPath(fromObject, ['done']);\n  if (fromDone != null) {\n    common.setValueByPath(toObject, ['done'], fromDone);\n  }\n\n  const fromError = common.getValueByPath(fromObject, ['error']);\n  if (fromError != null) {\n    common.setValueByPath(toObject, ['error'], fromError);\n  }\n\n  return toObject;\n}\n\nexport function deleteResourceJobFromVertex(\n  fromObject: types.DeleteResourceJob,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSdkHttpResponse = common.getValueByPath(fromObject, [\n    'sdkHttpResponse',\n  ]);\n  if (fromSdkHttpResponse != null) {\n    common.setValueByPath(toObject, ['sdkHttpResponse'], fromSdkHttpResponse);\n  }\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(toObject, ['name'], fromName);\n  }\n\n  const fromDone = common.getValueByPath(fromObject, ['done']);\n  if (fromDone != null) {\n    common.setValueByPath(toObject, ['done'], fromDone);\n  }\n\n  const fromError = common.getValueByPath(fromObject, ['error']);\n  if (fromError != null) {\n    common.setValueByPath(toObject, ['error'], fromError);\n  }\n\n  return toObject;\n}\n\nexport function embedContentBatchToMldev(\n  apiClient: ApiClient,\n  fromObject: types.EmbedContentBatch,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromContents = common.getValueByPath(fromObject, ['contents']);\n  if (fromContents != null) {\n    let transformedList = t.tContentsForEmbed(apiClient, fromContents);\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(\n      toObject,\n      ['requests[]', 'request', 'content'],\n      transformedList,\n    );\n  }\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    common.setValueByPath(\n      toObject,\n      ['_self'],\n      embedContentConfigToMldev(fromConfig, toObject),\n    );\n    common.moveValueByPath(toObject, {'requests[].*': 'requests[].request.*'});\n  }\n\n  return toObject;\n}\n\nexport function embedContentConfigToMldev(\n  fromObject: types.EmbedContentConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromTaskType = common.getValueByPath(fromObject, ['taskType']);\n  if (parentObject !== undefined && fromTaskType != null) {\n    common.setValueByPath(\n      parentObject,\n      ['requests[]', 'taskType'],\n      fromTaskType,\n    );\n  }\n\n  const fromTitle = common.getValueByPath(fromObject, ['title']);\n  if (parentObject !== undefined && fromTitle != null) {\n    common.setValueByPath(parentObject, ['requests[]', 'title'], fromTitle);\n  }\n\n  const fromOutputDimensionality = common.getValueByPath(fromObject, [\n    'outputDimensionality',\n  ]);\n  if (parentObject !== undefined && fromOutputDimensionality != null) {\n    common.setValueByPath(\n      parentObject,\n      ['requests[]', 'outputDimensionality'],\n      fromOutputDimensionality,\n    );\n  }\n\n  if (common.getValueByPath(fromObject, ['mimeType']) !== undefined) {\n    throw new Error('mimeType parameter is not supported in Gemini API.');\n  }\n\n  if (common.getValueByPath(fromObject, ['autoTruncate']) !== undefined) {\n    throw new Error('autoTruncate parameter is not supported in Gemini API.');\n  }\n\n  return toObject;\n}\n\nexport function embeddingsBatchJobSourceToMldev(\n  apiClient: ApiClient,\n  fromObject: types.EmbeddingsBatchJobSource,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromFileName = common.getValueByPath(fromObject, ['fileName']);\n  if (fromFileName != null) {\n    common.setValueByPath(toObject, ['file_name'], fromFileName);\n  }\n\n  const fromInlinedRequests = common.getValueByPath(fromObject, [\n    'inlinedRequests',\n  ]);\n  if (fromInlinedRequests != null) {\n    common.setValueByPath(\n      toObject,\n      ['requests'],\n      embedContentBatchToMldev(apiClient, fromInlinedRequests),\n    );\n  }\n\n  return toObject;\n}\n\nexport function fileDataToMldev(\n  fromObject: types.FileData,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  if (common.getValueByPath(fromObject, ['displayName']) !== undefined) {\n    throw new Error('displayName parameter is not supported in Gemini API.');\n  }\n\n  const fromFileUri = common.getValueByPath(fromObject, ['fileUri']);\n  if (fromFileUri != null) {\n    common.setValueByPath(toObject, ['fileUri'], fromFileUri);\n  }\n\n  const fromMimeType = common.getValueByPath(fromObject, ['mimeType']);\n  if (fromMimeType != null) {\n    common.setValueByPath(toObject, ['mimeType'], fromMimeType);\n  }\n\n  return toObject;\n}\n\nexport function generateContentConfigToMldev(\n  apiClient: ApiClient,\n  fromObject: types.GenerateContentConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSystemInstruction = common.getValueByPath(fromObject, [\n    'systemInstruction',\n  ]);\n  if (parentObject !== undefined && fromSystemInstruction != null) {\n    common.setValueByPath(\n      parentObject,\n      ['systemInstruction'],\n      contentToMldev(t.tContent(fromSystemInstruction)),\n    );\n  }\n\n  const fromTemperature = common.getValueByPath(fromObject, ['temperature']);\n  if (fromTemperature != null) {\n    common.setValueByPath(toObject, ['temperature'], fromTemperature);\n  }\n\n  const fromTopP = common.getValueByPath(fromObject, ['topP']);\n  if (fromTopP != null) {\n    common.setValueByPath(toObject, ['topP'], fromTopP);\n  }\n\n  const fromTopK = common.getValueByPath(fromObject, ['topK']);\n  if (fromTopK != null) {\n    common.setValueByPath(toObject, ['topK'], fromTopK);\n  }\n\n  const fromCandidateCount = common.getValueByPath(fromObject, [\n    'candidateCount',\n  ]);\n  if (fromCandidateCount != null) {\n    common.setValueByPath(toObject, ['candidateCount'], fromCandidateCount);\n  }\n\n  const fromMaxOutputTokens = common.getValueByPath(fromObject, [\n    'maxOutputTokens',\n  ]);\n  if (fromMaxOutputTokens != null) {\n    common.setValueByPath(toObject, ['maxOutputTokens'], fromMaxOutputTokens);\n  }\n\n  const fromStopSequences = common.getValueByPath(fromObject, [\n    'stopSequences',\n  ]);\n  if (fromStopSequences != null) {\n    common.setValueByPath(toObject, ['stopSequences'], fromStopSequences);\n  }\n\n  const fromResponseLogprobs = common.getValueByPath(fromObject, [\n    'responseLogprobs',\n  ]);\n  if (fromResponseLogprobs != null) {\n    common.setValueByPath(toObject, ['responseLogprobs'], fromResponseLogprobs);\n  }\n\n  const fromLogprobs = common.getValueByPath(fromObject, ['logprobs']);\n  if (fromLogprobs != null) {\n    common.setValueByPath(toObject, ['logprobs'], fromLogprobs);\n  }\n\n  const fromPresencePenalty = common.getValueByPath(fromObject, [\n    'presencePenalty',\n  ]);\n  if (fromPresencePenalty != null) {\n    common.setValueByPath(toObject, ['presencePenalty'], fromPresencePenalty);\n  }\n\n  const fromFrequencyPenalty = common.getValueByPath(fromObject, [\n    'frequencyPenalty',\n  ]);\n  if (fromFrequencyPenalty != null) {\n    common.setValueByPath(toObject, ['frequencyPenalty'], fromFrequencyPenalty);\n  }\n\n  const fromSeed = common.getValueByPath(fromObject, ['seed']);\n  if (fromSeed != null) {\n    common.setValueByPath(toObject, ['seed'], fromSeed);\n  }\n\n  const fromResponseMimeType = common.getValueByPath(fromObject, [\n    'responseMimeType',\n  ]);\n  if (fromResponseMimeType != null) {\n    common.setValueByPath(toObject, ['responseMimeType'], fromResponseMimeType);\n  }\n\n  const fromResponseSchema = common.getValueByPath(fromObject, [\n    'responseSchema',\n  ]);\n  if (fromResponseSchema != null) {\n    common.setValueByPath(\n      toObject,\n      ['responseSchema'],\n      t.tSchema(fromResponseSchema),\n    );\n  }\n\n  const fromResponseJsonSchema = common.getValueByPath(fromObject, [\n    'responseJsonSchema',\n  ]);\n  if (fromResponseJsonSchema != null) {\n    common.setValueByPath(\n      toObject,\n      ['responseJsonSchema'],\n      fromResponseJsonSchema,\n    );\n  }\n\n  if (common.getValueByPath(fromObject, ['routingConfig']) !== undefined) {\n    throw new Error('routingConfig parameter is not supported in Gemini API.');\n  }\n\n  if (\n    common.getValueByPath(fromObject, ['modelSelectionConfig']) !== undefined\n  ) {\n    throw new Error(\n      'modelSelectionConfig parameter is not supported in Gemini API.',\n    );\n  }\n\n  const fromSafetySettings = common.getValueByPath(fromObject, [\n    'safetySettings',\n  ]);\n  if (parentObject !== undefined && fromSafetySettings != null) {\n    let transformedList = fromSafetySettings;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return safetySettingToMldev(item);\n      });\n    }\n    common.setValueByPath(parentObject, ['safetySettings'], transformedList);\n  }\n\n  const fromTools = common.getValueByPath(fromObject, ['tools']);\n  if (parentObject !== undefined && fromTools != null) {\n    let transformedList = t.tTools(fromTools);\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return toolToMldev(t.tTool(item));\n      });\n    }\n    common.setValueByPath(parentObject, ['tools'], transformedList);\n  }\n\n  const fromToolConfig = common.getValueByPath(fromObject, ['toolConfig']);\n  if (parentObject !== undefined && fromToolConfig != null) {\n    common.setValueByPath(parentObject, ['toolConfig'], fromToolConfig);\n  }\n\n  if (common.getValueByPath(fromObject, ['labels']) !== undefined) {\n    throw new Error('labels parameter is not supported in Gemini API.');\n  }\n\n  const fromCachedContent = common.getValueByPath(fromObject, [\n    'cachedContent',\n  ]);\n  if (parentObject !== undefined && fromCachedContent != null) {\n    common.setValueByPath(\n      parentObject,\n      ['cachedContent'],\n      t.tCachedContentName(apiClient, fromCachedContent),\n    );\n  }\n\n  const fromResponseModalities = common.getValueByPath(fromObject, [\n    'responseModalities',\n  ]);\n  if (fromResponseModalities != null) {\n    common.setValueByPath(\n      toObject,\n      ['responseModalities'],\n      fromResponseModalities,\n    );\n  }\n\n  const fromMediaResolution = common.getValueByPath(fromObject, [\n    'mediaResolution',\n  ]);\n  if (fromMediaResolution != null) {\n    common.setValueByPath(toObject, ['mediaResolution'], fromMediaResolution);\n  }\n\n  const fromSpeechConfig = common.getValueByPath(fromObject, ['speechConfig']);\n  if (fromSpeechConfig != null) {\n    common.setValueByPath(\n      toObject,\n      ['speechConfig'],\n      t.tSpeechConfig(fromSpeechConfig),\n    );\n  }\n\n  if (common.getValueByPath(fromObject, ['audioTimestamp']) !== undefined) {\n    throw new Error('audioTimestamp parameter is not supported in Gemini API.');\n  }\n\n  const fromThinkingConfig = common.getValueByPath(fromObject, [\n    'thinkingConfig',\n  ]);\n  if (fromThinkingConfig != null) {\n    common.setValueByPath(toObject, ['thinkingConfig'], fromThinkingConfig);\n  }\n\n  const fromImageConfig = common.getValueByPath(fromObject, ['imageConfig']);\n  if (fromImageConfig != null) {\n    common.setValueByPath(toObject, ['imageConfig'], fromImageConfig);\n  }\n\n  return toObject;\n}\n\nexport function generateContentResponseFromMldev(\n  fromObject: types.GenerateContentResponse,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSdkHttpResponse = common.getValueByPath(fromObject, [\n    'sdkHttpResponse',\n  ]);\n  if (fromSdkHttpResponse != null) {\n    common.setValueByPath(toObject, ['sdkHttpResponse'], fromSdkHttpResponse);\n  }\n\n  const fromCandidates = common.getValueByPath(fromObject, ['candidates']);\n  if (fromCandidates != null) {\n    let transformedList = fromCandidates;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return candidateFromMldev(item);\n      });\n    }\n    common.setValueByPath(toObject, ['candidates'], transformedList);\n  }\n\n  const fromModelVersion = common.getValueByPath(fromObject, ['modelVersion']);\n  if (fromModelVersion != null) {\n    common.setValueByPath(toObject, ['modelVersion'], fromModelVersion);\n  }\n\n  const fromPromptFeedback = common.getValueByPath(fromObject, [\n    'promptFeedback',\n  ]);\n  if (fromPromptFeedback != null) {\n    common.setValueByPath(toObject, ['promptFeedback'], fromPromptFeedback);\n  }\n\n  const fromResponseId = common.getValueByPath(fromObject, ['responseId']);\n  if (fromResponseId != null) {\n    common.setValueByPath(toObject, ['responseId'], fromResponseId);\n  }\n\n  const fromUsageMetadata = common.getValueByPath(fromObject, [\n    'usageMetadata',\n  ]);\n  if (fromUsageMetadata != null) {\n    common.setValueByPath(toObject, ['usageMetadata'], fromUsageMetadata);\n  }\n\n  return toObject;\n}\n\nexport function getBatchJobParametersToMldev(\n  apiClient: ApiClient,\n  fromObject: types.GetBatchJobParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'name'],\n      t.tBatchJobName(apiClient, fromName),\n    );\n  }\n\n  return toObject;\n}\n\nexport function getBatchJobParametersToVertex(\n  apiClient: ApiClient,\n  fromObject: types.GetBatchJobParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'name'],\n      t.tBatchJobName(apiClient, fromName),\n    );\n  }\n\n  return toObject;\n}\n\nexport function googleMapsToMldev(\n  fromObject: types.GoogleMaps,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  if (common.getValueByPath(fromObject, ['authConfig']) !== undefined) {\n    throw new Error('authConfig parameter is not supported in Gemini API.');\n  }\n\n  const fromEnableWidget = common.getValueByPath(fromObject, ['enableWidget']);\n  if (fromEnableWidget != null) {\n    common.setValueByPath(toObject, ['enableWidget'], fromEnableWidget);\n  }\n\n  return toObject;\n}\n\nexport function googleSearchToMldev(\n  fromObject: types.GoogleSearch,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromTimeRangeFilter = common.getValueByPath(fromObject, [\n    'timeRangeFilter',\n  ]);\n  if (fromTimeRangeFilter != null) {\n    common.setValueByPath(toObject, ['timeRangeFilter'], fromTimeRangeFilter);\n  }\n\n  if (common.getValueByPath(fromObject, ['excludeDomains']) !== undefined) {\n    throw new Error('excludeDomains parameter is not supported in Gemini API.');\n  }\n\n  return toObject;\n}\n\nexport function inlinedRequestToMldev(\n  apiClient: ApiClient,\n  fromObject: types.InlinedRequest,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(\n      toObject,\n      ['request', 'model'],\n      t.tModel(apiClient, fromModel),\n    );\n  }\n\n  const fromContents = common.getValueByPath(fromObject, ['contents']);\n  if (fromContents != null) {\n    let transformedList = t.tContents(fromContents);\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return contentToMldev(item);\n      });\n    }\n    common.setValueByPath(toObject, ['request', 'contents'], transformedList);\n  }\n\n  const fromMetadata = common.getValueByPath(fromObject, ['metadata']);\n  if (fromMetadata != null) {\n    common.setValueByPath(toObject, ['metadata'], fromMetadata);\n  }\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    common.setValueByPath(\n      toObject,\n      ['request', 'generationConfig'],\n      generateContentConfigToMldev(\n        apiClient,\n        fromConfig,\n        common.getValueByPath(toObject, ['request'], {}) as Record<\n          string,\n          unknown\n        >,\n      ),\n    );\n  }\n\n  return toObject;\n}\n\nexport function inlinedResponseFromMldev(\n  fromObject: types.InlinedResponse,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromResponse = common.getValueByPath(fromObject, ['response']);\n  if (fromResponse != null) {\n    common.setValueByPath(\n      toObject,\n      ['response'],\n      generateContentResponseFromMldev(\n        fromResponse as types.GenerateContentResponse,\n      ),\n    );\n  }\n\n  const fromError = common.getValueByPath(fromObject, ['error']);\n  if (fromError != null) {\n    common.setValueByPath(toObject, ['error'], fromError);\n  }\n\n  return toObject;\n}\n\nexport function listBatchJobsConfigToMldev(\n  fromObject: types.ListBatchJobsConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromPageSize = common.getValueByPath(fromObject, ['pageSize']);\n  if (parentObject !== undefined && fromPageSize != null) {\n    common.setValueByPath(parentObject, ['_query', 'pageSize'], fromPageSize);\n  }\n\n  const fromPageToken = common.getValueByPath(fromObject, ['pageToken']);\n  if (parentObject !== undefined && fromPageToken != null) {\n    common.setValueByPath(parentObject, ['_query', 'pageToken'], fromPageToken);\n  }\n\n  if (common.getValueByPath(fromObject, ['filter']) !== undefined) {\n    throw new Error('filter parameter is not supported in Gemini API.');\n  }\n\n  return toObject;\n}\n\nexport function listBatchJobsConfigToVertex(\n  fromObject: types.ListBatchJobsConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromPageSize = common.getValueByPath(fromObject, ['pageSize']);\n  if (parentObject !== undefined && fromPageSize != null) {\n    common.setValueByPath(parentObject, ['_query', 'pageSize'], fromPageSize);\n  }\n\n  const fromPageToken = common.getValueByPath(fromObject, ['pageToken']);\n  if (parentObject !== undefined && fromPageToken != null) {\n    common.setValueByPath(parentObject, ['_query', 'pageToken'], fromPageToken);\n  }\n\n  const fromFilter = common.getValueByPath(fromObject, ['filter']);\n  if (parentObject !== undefined && fromFilter != null) {\n    common.setValueByPath(parentObject, ['_query', 'filter'], fromFilter);\n  }\n\n  return toObject;\n}\n\nexport function listBatchJobsParametersToMldev(\n  fromObject: types.ListBatchJobsParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    listBatchJobsConfigToMldev(fromConfig, toObject);\n  }\n\n  return toObject;\n}\n\nexport function listBatchJobsParametersToVertex(\n  fromObject: types.ListBatchJobsParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    listBatchJobsConfigToVertex(fromConfig, toObject);\n  }\n\n  return toObject;\n}\n\nexport function listBatchJobsResponseFromMldev(\n  fromObject: types.ListBatchJobsResponse,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSdkHttpResponse = common.getValueByPath(fromObject, [\n    'sdkHttpResponse',\n  ]);\n  if (fromSdkHttpResponse != null) {\n    common.setValueByPath(toObject, ['sdkHttpResponse'], fromSdkHttpResponse);\n  }\n\n  const fromNextPageToken = common.getValueByPath(fromObject, [\n    'nextPageToken',\n  ]);\n  if (fromNextPageToken != null) {\n    common.setValueByPath(toObject, ['nextPageToken'], fromNextPageToken);\n  }\n\n  const fromBatchJobs = common.getValueByPath(fromObject, ['operations']);\n  if (fromBatchJobs != null) {\n    let transformedList = fromBatchJobs;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return batchJobFromMldev(item);\n      });\n    }\n    common.setValueByPath(toObject, ['batchJobs'], transformedList);\n  }\n\n  return toObject;\n}\n\nexport function listBatchJobsResponseFromVertex(\n  fromObject: types.ListBatchJobsResponse,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSdkHttpResponse = common.getValueByPath(fromObject, [\n    'sdkHttpResponse',\n  ]);\n  if (fromSdkHttpResponse != null) {\n    common.setValueByPath(toObject, ['sdkHttpResponse'], fromSdkHttpResponse);\n  }\n\n  const fromNextPageToken = common.getValueByPath(fromObject, [\n    'nextPageToken',\n  ]);\n  if (fromNextPageToken != null) {\n    common.setValueByPath(toObject, ['nextPageToken'], fromNextPageToken);\n  }\n\n  const fromBatchJobs = common.getValueByPath(fromObject, [\n    'batchPredictionJobs',\n  ]);\n  if (fromBatchJobs != null) {\n    let transformedList = fromBatchJobs;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return batchJobFromVertex(item);\n      });\n    }\n    common.setValueByPath(toObject, ['batchJobs'], transformedList);\n  }\n\n  return toObject;\n}\n\nexport function partToMldev(fromObject: types.Part): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromVideoMetadata = common.getValueByPath(fromObject, [\n    'videoMetadata',\n  ]);\n  if (fromVideoMetadata != null) {\n    common.setValueByPath(toObject, ['videoMetadata'], fromVideoMetadata);\n  }\n\n  const fromThought = common.getValueByPath(fromObject, ['thought']);\n  if (fromThought != null) {\n    common.setValueByPath(toObject, ['thought'], fromThought);\n  }\n\n  const fromInlineData = common.getValueByPath(fromObject, ['inlineData']);\n  if (fromInlineData != null) {\n    common.setValueByPath(\n      toObject,\n      ['inlineData'],\n      blobToMldev(fromInlineData),\n    );\n  }\n\n  const fromFileData = common.getValueByPath(fromObject, ['fileData']);\n  if (fromFileData != null) {\n    common.setValueByPath(\n      toObject,\n      ['fileData'],\n      fileDataToMldev(fromFileData),\n    );\n  }\n\n  const fromThoughtSignature = common.getValueByPath(fromObject, [\n    'thoughtSignature',\n  ]);\n  if (fromThoughtSignature != null) {\n    common.setValueByPath(toObject, ['thoughtSignature'], fromThoughtSignature);\n  }\n\n  const fromFunctionCall = common.getValueByPath(fromObject, ['functionCall']);\n  if (fromFunctionCall != null) {\n    common.setValueByPath(toObject, ['functionCall'], fromFunctionCall);\n  }\n\n  const fromCodeExecutionResult = common.getValueByPath(fromObject, [\n    'codeExecutionResult',\n  ]);\n  if (fromCodeExecutionResult != null) {\n    common.setValueByPath(\n      toObject,\n      ['codeExecutionResult'],\n      fromCodeExecutionResult,\n    );\n  }\n\n  const fromExecutableCode = common.getValueByPath(fromObject, [\n    'executableCode',\n  ]);\n  if (fromExecutableCode != null) {\n    common.setValueByPath(toObject, ['executableCode'], fromExecutableCode);\n  }\n\n  const fromFunctionResponse = common.getValueByPath(fromObject, [\n    'functionResponse',\n  ]);\n  if (fromFunctionResponse != null) {\n    common.setValueByPath(toObject, ['functionResponse'], fromFunctionResponse);\n  }\n\n  const fromText = common.getValueByPath(fromObject, ['text']);\n  if (fromText != null) {\n    common.setValueByPath(toObject, ['text'], fromText);\n  }\n\n  return toObject;\n}\n\nexport function safetySettingToMldev(\n  fromObject: types.SafetySetting,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  if (common.getValueByPath(fromObject, ['method']) !== undefined) {\n    throw new Error('method parameter is not supported in Gemini API.');\n  }\n\n  const fromCategory = common.getValueByPath(fromObject, ['category']);\n  if (fromCategory != null) {\n    common.setValueByPath(toObject, ['category'], fromCategory);\n  }\n\n  const fromThreshold = common.getValueByPath(fromObject, ['threshold']);\n  if (fromThreshold != null) {\n    common.setValueByPath(toObject, ['threshold'], fromThreshold);\n  }\n\n  return toObject;\n}\n\nexport function toolToMldev(fromObject: types.Tool): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromFunctionDeclarations = common.getValueByPath(fromObject, [\n    'functionDeclarations',\n  ]);\n  if (fromFunctionDeclarations != null) {\n    let transformedList = fromFunctionDeclarations;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(toObject, ['functionDeclarations'], transformedList);\n  }\n\n  if (common.getValueByPath(fromObject, ['retrieval']) !== undefined) {\n    throw new Error('retrieval parameter is not supported in Gemini API.');\n  }\n\n  const fromGoogleSearch = common.getValueByPath(fromObject, ['googleSearch']);\n  if (fromGoogleSearch != null) {\n    common.setValueByPath(\n      toObject,\n      ['googleSearch'],\n      googleSearchToMldev(fromGoogleSearch),\n    );\n  }\n\n  const fromGoogleSearchRetrieval = common.getValueByPath(fromObject, [\n    'googleSearchRetrieval',\n  ]);\n  if (fromGoogleSearchRetrieval != null) {\n    common.setValueByPath(\n      toObject,\n      ['googleSearchRetrieval'],\n      fromGoogleSearchRetrieval,\n    );\n  }\n\n  if (\n    common.getValueByPath(fromObject, ['enterpriseWebSearch']) !== undefined\n  ) {\n    throw new Error(\n      'enterpriseWebSearch parameter is not supported in Gemini API.',\n    );\n  }\n\n  const fromGoogleMaps = common.getValueByPath(fromObject, ['googleMaps']);\n  if (fromGoogleMaps != null) {\n    common.setValueByPath(\n      toObject,\n      ['googleMaps'],\n      googleMapsToMldev(fromGoogleMaps),\n    );\n  }\n\n  const fromUrlContext = common.getValueByPath(fromObject, ['urlContext']);\n  if (fromUrlContext != null) {\n    common.setValueByPath(toObject, ['urlContext'], fromUrlContext);\n  }\n\n  const fromComputerUse = common.getValueByPath(fromObject, ['computerUse']);\n  if (fromComputerUse != null) {\n    common.setValueByPath(toObject, ['computerUse'], fromComputerUse);\n  }\n\n  const fromCodeExecution = common.getValueByPath(fromObject, [\n    'codeExecution',\n  ]);\n  if (fromCodeExecution != null) {\n    common.setValueByPath(toObject, ['codeExecution'], fromCodeExecution);\n  }\n\n  return toObject;\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\n/**\n * Pagers for the GenAI List APIs.\n */\n\nimport * as types from '../src/types';\n\nexport enum PagedItem {\n  PAGED_ITEM_BATCH_JOBS = 'batchJobs',\n  PAGED_ITEM_MODELS = 'models',\n  PAGED_ITEM_TUNING_JOBS = 'tuningJobs',\n  PAGED_ITEM_FILES = 'files',\n  PAGED_ITEM_CACHED_CONTENTS = 'cachedContents',\n}\n\ninterface PagedItemConfig {\n  config?: {\n    pageToken?: string;\n    pageSize?: number;\n  };\n}\n\ninterface PagedItemResponse<T> {\n  nextPageToken?: string;\n  sdkHttpResponse?: types.HttpResponse;\n  batchJobs?: T[];\n  models?: T[];\n  tuningJobs?: T[];\n  files?: T[];\n  cachedContents?: T[];\n}\n\n/**\n * Pager class for iterating through paginated results.\n */\nexport class Pager<T> implements AsyncIterable<T> {\n  private nameInternal!: PagedItem;\n  private pageInternal: T[] = [];\n  private paramsInternal: PagedItemConfig = {};\n  private pageInternalSize!: number;\n  private sdkHttpResponseInternal?: types.HttpResponse;\n  protected requestInternal!: (\n    params: PagedItemConfig,\n  ) => Promise<PagedItemResponse<T>>;\n  protected idxInternal!: number;\n\n  constructor(\n    name: PagedItem,\n    request: (params: PagedItemConfig) => Promise<PagedItemResponse<T>>,\n    response: PagedItemResponse<T>,\n    params: PagedItemConfig,\n  ) {\n    this.requestInternal = request;\n    this.init(name, response, params);\n  }\n\n  private init(\n    name: PagedItem,\n    response: PagedItemResponse<T>,\n    params: PagedItemConfig,\n  ) {\n    this.nameInternal = name;\n    this.pageInternal = response[this.nameInternal] || [];\n\n    this.sdkHttpResponseInternal = response?.sdkHttpResponse;\n    this.idxInternal = 0;\n    let requestParams: PagedItemConfig = {config: {}};\n    if (!params || Object.keys(params).length === 0) {\n      requestParams = {config: {}};\n    } else if (typeof params === 'object') {\n      requestParams = {...params};\n    } else {\n      requestParams = params;\n    }\n    if (requestParams['config']) {\n      requestParams['config']['pageToken'] = response['nextPageToken'];\n    }\n    this.paramsInternal = requestParams;\n    this.pageInternalSize =\n      requestParams['config']?.['pageSize'] ?? this.pageInternal.length;\n  }\n\n  private initNextPage(response: PagedItemResponse<T>): void {\n    this.init(this.nameInternal, response, this.paramsInternal);\n  }\n\n  /**\n   * Returns the current page, which is a list of items.\n   *\n   * @remarks\n   * The first page is retrieved when the pager is created. The returned list of\n   * items could be a subset of the entire list.\n   */\n  get page(): T[] {\n    return this.pageInternal;\n  }\n\n  /**\n   * Returns the type of paged item (for example, ``batch_jobs``).\n   */\n  get name(): PagedItem {\n    return this.nameInternal;\n  }\n\n  /**\n   * Returns the length of the page fetched each time by this pager.\n   *\n   * @remarks\n   * The number of items in the page is less than or equal to the page length.\n   */\n  get pageSize(): number {\n    return this.pageInternalSize;\n  }\n\n  /**\n   * Returns the headers of the API response.\n   */\n  get sdkHttpResponse(): types.HttpResponse | undefined {\n    return this.sdkHttpResponseInternal;\n  }\n\n  /**\n   * Returns the parameters when making the API request for the next page.\n   *\n   * @remarks\n   * Parameters contain a set of optional configs that can be\n   * used to customize the API request. For example, the `pageToken` parameter\n   * contains the token to request the next page.\n   */\n  get params(): PagedItemConfig {\n    return this.paramsInternal;\n  }\n\n  /**\n   * Returns the total number of items in the current page.\n   */\n  get pageLength(): number {\n    return this.pageInternal.length;\n  }\n\n  /**\n   * Returns the item at the given index.\n   */\n  getItem(index: number): T {\n    return this.pageInternal[index];\n  }\n\n  /**\n   * Returns an async iterator that support iterating through all items\n   * retrieved from the API.\n   *\n   * @remarks\n   * The iterator will automatically fetch the next page if there are more items\n   * to fetch from the API.\n   *\n   * @example\n   *\n   * ```ts\n   * const pager = await ai.files.list({config: {pageSize: 10}});\n   * for await (const file of pager) {\n   *   console.log(file.name);\n   * }\n   * ```\n   */\n  [Symbol.asyncIterator](): AsyncIterator<T> {\n    return {\n      next: async () => {\n        if (this.idxInternal >= this.pageLength) {\n          if (this.hasNextPage()) {\n            await this.nextPage();\n          } else {\n            return {value: undefined, done: true};\n          }\n        }\n        const item = this.getItem(this.idxInternal);\n        this.idxInternal += 1;\n        return {value: item, done: false};\n      },\n      return: async () => {\n        return {value: undefined, done: true};\n      },\n    };\n  }\n\n  /**\n   * Fetches the next page of items. This makes a new API request.\n   *\n   * @throws {Error} If there are no more pages to fetch.\n   *\n   * @example\n   *\n   * ```ts\n   * const pager = await ai.files.list({config: {pageSize: 10}});\n   * let page = pager.page;\n   * while (true) {\n   *   for (const file of page) {\n   *     console.log(file.name);\n   *   }\n   *   if (!pager.hasNextPage()) {\n   *     break;\n   *   }\n   *   page = await pager.nextPage();\n   * }\n   * ```\n   */\n  async nextPage(): Promise<T[]> {\n    if (!this.hasNextPage()) {\n      throw new Error('No more pages to fetch.');\n    }\n    const response = await this.requestInternal(this.params);\n    this.initNextPage(response);\n    return this.page;\n  }\n\n  /**\n   * Returns true if there are more pages to fetch from the API.\n   */\n  hasNextPage(): boolean {\n    if (this.params['config']?.['pageToken'] !== undefined) {\n      return true;\n    }\n    return false;\n  }\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\n// Code generated by the Google Gen AI SDK generator DO NOT EDIT.\n\nimport {ApiClient} from './_api_client.js';\nimport * as common from './_common.js';\nimport {BaseModule} from './_common.js';\nimport * as converters from './converters/_batches_converters.js';\nimport {PagedItem, Pager} from './pagers.js';\nimport * as types from './types.js';\n\nexport class Batches extends BaseModule {\n  constructor(private readonly apiClient: ApiClient) {\n    super();\n  }\n\n  /**\n   * Create batch job.\n   *\n   * @param params - The parameters for create batch job request.\n   * @return The created batch job.\n   *\n   * @example\n   * ```ts\n   * const response = await ai.batches.create({\n   *   model: 'gemini-2.0-flash',\n   *   src: {gcsUri: 'gs://bucket/path/to/file.jsonl', format: 'jsonl'},\n   *   config: {\n   *     dest: {gcsUri: 'gs://bucket/path/output/directory', format: 'jsonl'},\n   *   }\n   * });\n   * console.log(response);\n   * ```\n   */\n  create = async (\n    params: types.CreateBatchJobParameters,\n  ): Promise<types.BatchJob> => {\n    if (this.apiClient.isVertexAI()) {\n      // Format destination if not provided\n      // Cast params.src as Vertex AI path does not handle InlinedRequest[]\n      params.config = this.formatDestination(\n        params.src as string | types.BatchJobSource,\n        params.config,\n      );\n    }\n    return this.createInternal(params);\n  };\n\n  /**\n   * **Experimental** Creates an embedding batch job.\n   *\n   * @param params - The parameters for create embedding batch job request.\n   * @return The created batch job.\n   *\n   * @example\n   * ```ts\n   * const response = await ai.batches.createEmbeddings({\n   *   model: 'text-embedding-004',\n   *   src: {fileName: 'files/my_embedding_input'},\n   * });\n   * console.log(response);\n   * ```\n   */\n  createEmbeddings = async (\n    params: types.CreateEmbeddingsBatchJobParameters,\n  ): Promise<types.BatchJob> => {\n    console.warn(\n      'batches.createEmbeddings() is experimental and may change without notice.',\n    );\n\n    if (this.apiClient.isVertexAI()) {\n      throw new Error('Vertex AI does not support batches.createEmbeddings.');\n    }\n\n    return this.createEmbeddingsInternal(params);\n  };\n\n  /**\n   * Lists batch job configurations.\n   *\n   * @param params - The parameters for the list request.\n   * @return The paginated results of the list of batch jobs.\n   *\n   * @example\n   * ```ts\n   * const batchJobs = await ai.batches.list({config: {'pageSize': 2}});\n   * for await (const batchJob of batchJobs) {\n   *   console.log(batchJob);\n   * }\n   * ```\n   */\n  list = async (\n    params: types.ListBatchJobsParameters = {},\n  ): Promise<Pager<types.BatchJob>> => {\n    return new Pager<types.BatchJob>(\n      PagedItem.PAGED_ITEM_BATCH_JOBS,\n      (x: types.ListBatchJobsParameters) => this.listInternal(x),\n      await this.listInternal(params),\n      params,\n    );\n  };\n\n  // Helper function to handle inlined generate content requests\n  private createInlinedGenerateContentRequest(\n    params: types.CreateBatchJobParameters,\n  ): {path: string; body: Record<string, unknown>} {\n    const body = converters.createBatchJobParametersToMldev(\n      this.apiClient, // Use instance apiClient\n      params,\n    );\n\n    const urlParams = body['_url'] as Record<string, unknown>;\n    const path = common.formatMap('{model}:batchGenerateContent', urlParams);\n\n    const batch = body['batch'] as {[key: string]: unknown};\n    const inputConfig = batch['inputConfig'] as {[key: string]: unknown};\n    const requestsWrapper = inputConfig['requests'] as {\n      [key: string]: unknown;\n    };\n    const requests = requestsWrapper['requests'] as Array<{\n      [key: string]: unknown;\n    }>;\n    const newRequests = [];\n\n    for (const request of requests) {\n      const requestDict = {...request}; // Clone\n      if (requestDict['systemInstruction']) {\n        const systemInstructionValue = requestDict['systemInstruction'];\n        delete requestDict['systemInstruction'];\n        const requestContent = requestDict['request'] as {\n          [key: string]: unknown;\n        };\n        requestContent['systemInstruction'] = systemInstructionValue;\n        requestDict['request'] = requestContent;\n      }\n      newRequests.push(requestDict);\n    }\n    requestsWrapper['requests'] = newRequests;\n\n    delete body['config'];\n    delete body['_url'];\n    delete body['_query'];\n\n    return {path, body};\n  }\n\n  // Helper function to get the first GCS URI\n  private getGcsUri(src: string | types.BatchJobSource): string | undefined {\n    if (typeof src === 'string') {\n      return src.startsWith('gs://') ? src : undefined;\n    }\n    if (!Array.isArray(src) && src.gcsUri && src.gcsUri.length > 0) {\n      return src.gcsUri[0];\n    }\n    return undefined;\n  }\n\n  // Helper function to get the BigQuery URI\n  private getBigqueryUri(\n    src: string | types.BatchJobSource,\n  ): string | undefined {\n    if (typeof src === 'string') {\n      return src.startsWith('bq://') ? src : undefined;\n    }\n    if (!Array.isArray(src)) {\n      return src.bigqueryUri;\n    }\n    return undefined;\n  }\n\n  // Function to format the destination configuration for Vertex AI\n  private formatDestination(\n    src: string | types.BatchJobSource,\n    config?: types.CreateBatchJobConfig,\n  ): types.CreateBatchJobConfig {\n    const newConfig = config ? {...config} : {};\n\n    const timestampStr = Date.now().toString();\n\n    if (!newConfig.displayName) {\n      newConfig.displayName = `genaiBatchJob_${timestampStr}`;\n    }\n\n    if (newConfig.dest === undefined) {\n      const gcsUri = this.getGcsUri(src);\n      const bigqueryUri = this.getBigqueryUri(src);\n\n      if (gcsUri) {\n        if (gcsUri.endsWith('.jsonl')) {\n          // For .jsonl files, remove suffix and add /dest\n          newConfig.dest = `${gcsUri.slice(0, -6)}/dest`;\n        } else {\n          // Fallback for other GCS URIs\n          newConfig.dest = `${gcsUri}_dest_${timestampStr}`;\n        }\n      } else if (bigqueryUri) {\n        newConfig.dest = `${bigqueryUri}_dest_${timestampStr}`;\n      } else {\n        throw new Error(\n          'Unsupported source for Vertex AI: No GCS or BigQuery URI found.',\n        );\n      }\n    }\n    return newConfig;\n  }\n\n  /**\n   * Internal method to create batch job.\n   *\n   * @param params - The parameters for create batch job request.\n   * @return The created batch job.\n   *\n   */\n  private async createInternal(\n    params: types.CreateBatchJobParameters,\n  ): Promise<types.BatchJob> {\n    let response: Promise<types.BatchJob>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      const body = converters.createBatchJobParametersToVertex(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        'batchPredictionJobs',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'POST',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json();\n        }) as Promise<types.BatchJob>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.batchJobFromVertex(apiResponse);\n\n        return resp as types.BatchJob;\n      });\n    } else {\n      const body = converters.createBatchJobParametersToMldev(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        '{model}:batchGenerateContent',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'POST',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json();\n        }) as Promise<types.BatchJob>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.batchJobFromMldev(apiResponse);\n\n        return resp as types.BatchJob;\n      });\n    }\n  }\n\n  /**\n   * Internal method to create batch job.\n   *\n   * @param params - The parameters for create batch job request.\n   * @return The created batch job.\n   *\n   */\n  private async createEmbeddingsInternal(\n    params: types.CreateEmbeddingsBatchJobParameters,\n  ): Promise<types.BatchJob> {\n    let response: Promise<types.BatchJob>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      throw new Error(\n        'This method is only supported by the Gemini Developer API.',\n      );\n    } else {\n      const body = converters.createEmbeddingsBatchJobParametersToMldev(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        '{model}:asyncBatchEmbedContent',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'POST',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json();\n        }) as Promise<types.BatchJob>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.batchJobFromMldev(apiResponse);\n\n        return resp as types.BatchJob;\n      });\n    }\n  }\n\n  /**\n   * Gets batch job configurations.\n   *\n   * @param params - The parameters for the get request.\n   * @return The batch job.\n   *\n   * @example\n   * ```ts\n   * await ai.batches.get({name: '...'}); // The server-generated resource name.\n   * ```\n   */\n  async get(params: types.GetBatchJobParameters): Promise<types.BatchJob> {\n    let response: Promise<types.BatchJob>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      const body = converters.getBatchJobParametersToVertex(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        'batchPredictionJobs/{name}',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'GET',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json();\n        }) as Promise<types.BatchJob>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.batchJobFromVertex(apiResponse);\n\n        return resp as types.BatchJob;\n      });\n    } else {\n      const body = converters.getBatchJobParametersToMldev(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        'batches/{name}',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'GET',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json();\n        }) as Promise<types.BatchJob>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.batchJobFromMldev(apiResponse);\n\n        return resp as types.BatchJob;\n      });\n    }\n  }\n\n  /**\n   * Cancels a batch job.\n   *\n   * @param params - The parameters for the cancel request.\n   * @return The empty response returned by the API.\n   *\n   * @example\n   * ```ts\n   * await ai.batches.cancel({name: '...'}); // The server-generated resource name.\n   * ```\n   */\n  async cancel(params: types.CancelBatchJobParameters): Promise<void> {\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      const body = converters.cancelBatchJobParametersToVertex(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        'batchPredictionJobs/{name}:cancel',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      await this.apiClient.request({\n        path: path,\n        queryParams: queryParams,\n        body: JSON.stringify(body),\n        httpMethod: 'POST',\n        httpOptions: params.config?.httpOptions,\n        abortSignal: params.config?.abortSignal,\n      });\n    } else {\n      const body = converters.cancelBatchJobParametersToMldev(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        'batches/{name}:cancel',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      await this.apiClient.request({\n        path: path,\n        queryParams: queryParams,\n        body: JSON.stringify(body),\n        httpMethod: 'POST',\n        httpOptions: params.config?.httpOptions,\n        abortSignal: params.config?.abortSignal,\n      });\n    }\n  }\n\n  private async listInternal(\n    params: types.ListBatchJobsParameters,\n  ): Promise<types.ListBatchJobsResponse> {\n    let response: Promise<types.ListBatchJobsResponse>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      const body = converters.listBatchJobsParametersToVertex(params);\n      path = common.formatMap(\n        'batchPredictionJobs',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'GET',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json().then((jsonResponse) => {\n            const response = jsonResponse as types.ListBatchJobsResponse;\n            response.sdkHttpResponse = {\n              headers: httpResponse.headers,\n            } as types.HttpResponse;\n            return response;\n          });\n        }) as Promise<types.ListBatchJobsResponse>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.listBatchJobsResponseFromVertex(apiResponse);\n        const typedResp = new types.ListBatchJobsResponse();\n        Object.assign(typedResp, resp);\n        return typedResp;\n      });\n    } else {\n      const body = converters.listBatchJobsParametersToMldev(params);\n      path = common.formatMap(\n        'batches',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'GET',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json().then((jsonResponse) => {\n            const response = jsonResponse as types.ListBatchJobsResponse;\n            response.sdkHttpResponse = {\n              headers: httpResponse.headers,\n            } as types.HttpResponse;\n            return response;\n          });\n        }) as Promise<types.ListBatchJobsResponse>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.listBatchJobsResponseFromMldev(apiResponse);\n        const typedResp = new types.ListBatchJobsResponse();\n        Object.assign(typedResp, resp);\n        return typedResp;\n      });\n    }\n  }\n\n  /**\n   * Deletes a batch job.\n   *\n   * @param params - The parameters for the delete request.\n   * @return The empty response returned by the API.\n   *\n   * @example\n   * ```ts\n   * await ai.batches.delete({name: '...'}); // The server-generated resource name.\n   * ```\n   */\n  async delete(\n    params: types.DeleteBatchJobParameters,\n  ): Promise<types.DeleteResourceJob> {\n    let response: Promise<types.DeleteResourceJob>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      const body = converters.deleteBatchJobParametersToVertex(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        'batchPredictionJobs/{name}',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'DELETE',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json().then((jsonResponse) => {\n            const response = jsonResponse as types.DeleteResourceJob;\n            response.sdkHttpResponse = {\n              headers: httpResponse.headers,\n            } as types.HttpResponse;\n            return response;\n          });\n        }) as Promise<types.DeleteResourceJob>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.deleteResourceJobFromVertex(apiResponse);\n\n        return resp as types.DeleteResourceJob;\n      });\n    } else {\n      const body = converters.deleteBatchJobParametersToMldev(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        'batches/{name}',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'DELETE',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json().then((jsonResponse) => {\n            const response = jsonResponse as types.DeleteResourceJob;\n            response.sdkHttpResponse = {\n              headers: httpResponse.headers,\n            } as types.HttpResponse;\n            return response;\n          });\n        }) as Promise<types.DeleteResourceJob>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.deleteResourceJobFromMldev(apiResponse);\n\n        return resp as types.DeleteResourceJob;\n      });\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\n// Code generated by the Google Gen AI SDK generator DO NOT EDIT.\n\nimport {ApiClient} from '../_api_client.js';\nimport * as common from '../_common.js';\nimport * as t from '../_transformers.js';\nimport type * as types from '../types.js';\n\nexport function blobToMldev(fromObject: types.Blob): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  if (common.getValueByPath(fromObject, ['displayName']) !== undefined) {\n    throw new Error('displayName parameter is not supported in Gemini API.');\n  }\n\n  const fromData = common.getValueByPath(fromObject, ['data']);\n  if (fromData != null) {\n    common.setValueByPath(toObject, ['data'], fromData);\n  }\n\n  const fromMimeType = common.getValueByPath(fromObject, ['mimeType']);\n  if (fromMimeType != null) {\n    common.setValueByPath(toObject, ['mimeType'], fromMimeType);\n  }\n\n  return toObject;\n}\n\nexport function contentToMldev(\n  fromObject: types.Content,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromParts = common.getValueByPath(fromObject, ['parts']);\n  if (fromParts != null) {\n    let transformedList = fromParts;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return partToMldev(item);\n      });\n    }\n    common.setValueByPath(toObject, ['parts'], transformedList);\n  }\n\n  const fromRole = common.getValueByPath(fromObject, ['role']);\n  if (fromRole != null) {\n    common.setValueByPath(toObject, ['role'], fromRole);\n  }\n\n  return toObject;\n}\n\nexport function createCachedContentConfigToMldev(\n  fromObject: types.CreateCachedContentConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromTtl = common.getValueByPath(fromObject, ['ttl']);\n  if (parentObject !== undefined && fromTtl != null) {\n    common.setValueByPath(parentObject, ['ttl'], fromTtl);\n  }\n\n  const fromExpireTime = common.getValueByPath(fromObject, ['expireTime']);\n  if (parentObject !== undefined && fromExpireTime != null) {\n    common.setValueByPath(parentObject, ['expireTime'], fromExpireTime);\n  }\n\n  const fromDisplayName = common.getValueByPath(fromObject, ['displayName']);\n  if (parentObject !== undefined && fromDisplayName != null) {\n    common.setValueByPath(parentObject, ['displayName'], fromDisplayName);\n  }\n\n  const fromContents = common.getValueByPath(fromObject, ['contents']);\n  if (parentObject !== undefined && fromContents != null) {\n    let transformedList = t.tContents(fromContents);\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return contentToMldev(item);\n      });\n    }\n    common.setValueByPath(parentObject, ['contents'], transformedList);\n  }\n\n  const fromSystemInstruction = common.getValueByPath(fromObject, [\n    'systemInstruction',\n  ]);\n  if (parentObject !== undefined && fromSystemInstruction != null) {\n    common.setValueByPath(\n      parentObject,\n      ['systemInstruction'],\n      contentToMldev(t.tContent(fromSystemInstruction)),\n    );\n  }\n\n  const fromTools = common.getValueByPath(fromObject, ['tools']);\n  if (parentObject !== undefined && fromTools != null) {\n    let transformedList = fromTools;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return toolToMldev(item);\n      });\n    }\n    common.setValueByPath(parentObject, ['tools'], transformedList);\n  }\n\n  const fromToolConfig = common.getValueByPath(fromObject, ['toolConfig']);\n  if (parentObject !== undefined && fromToolConfig != null) {\n    common.setValueByPath(parentObject, ['toolConfig'], fromToolConfig);\n  }\n\n  if (common.getValueByPath(fromObject, ['kmsKeyName']) !== undefined) {\n    throw new Error('kmsKeyName parameter is not supported in Gemini API.');\n  }\n\n  return toObject;\n}\n\nexport function createCachedContentConfigToVertex(\n  fromObject: types.CreateCachedContentConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromTtl = common.getValueByPath(fromObject, ['ttl']);\n  if (parentObject !== undefined && fromTtl != null) {\n    common.setValueByPath(parentObject, ['ttl'], fromTtl);\n  }\n\n  const fromExpireTime = common.getValueByPath(fromObject, ['expireTime']);\n  if (parentObject !== undefined && fromExpireTime != null) {\n    common.setValueByPath(parentObject, ['expireTime'], fromExpireTime);\n  }\n\n  const fromDisplayName = common.getValueByPath(fromObject, ['displayName']);\n  if (parentObject !== undefined && fromDisplayName != null) {\n    common.setValueByPath(parentObject, ['displayName'], fromDisplayName);\n  }\n\n  const fromContents = common.getValueByPath(fromObject, ['contents']);\n  if (parentObject !== undefined && fromContents != null) {\n    let transformedList = t.tContents(fromContents);\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(parentObject, ['contents'], transformedList);\n  }\n\n  const fromSystemInstruction = common.getValueByPath(fromObject, [\n    'systemInstruction',\n  ]);\n  if (parentObject !== undefined && fromSystemInstruction != null) {\n    common.setValueByPath(\n      parentObject,\n      ['systemInstruction'],\n      t.tContent(fromSystemInstruction),\n    );\n  }\n\n  const fromTools = common.getValueByPath(fromObject, ['tools']);\n  if (parentObject !== undefined && fromTools != null) {\n    let transformedList = fromTools;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return toolToVertex(item);\n      });\n    }\n    common.setValueByPath(parentObject, ['tools'], transformedList);\n  }\n\n  const fromToolConfig = common.getValueByPath(fromObject, ['toolConfig']);\n  if (parentObject !== undefined && fromToolConfig != null) {\n    common.setValueByPath(parentObject, ['toolConfig'], fromToolConfig);\n  }\n\n  const fromKmsKeyName = common.getValueByPath(fromObject, ['kmsKeyName']);\n  if (parentObject !== undefined && fromKmsKeyName != null) {\n    common.setValueByPath(\n      parentObject,\n      ['encryption_spec', 'kmsKeyName'],\n      fromKmsKeyName,\n    );\n  }\n\n  return toObject;\n}\n\nexport function createCachedContentParametersToMldev(\n  apiClient: ApiClient,\n  fromObject: types.CreateCachedContentParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(\n      toObject,\n      ['model'],\n      t.tCachesModel(apiClient, fromModel),\n    );\n  }\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    createCachedContentConfigToMldev(fromConfig, toObject);\n  }\n\n  return toObject;\n}\n\nexport function createCachedContentParametersToVertex(\n  apiClient: ApiClient,\n  fromObject: types.CreateCachedContentParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(\n      toObject,\n      ['model'],\n      t.tCachesModel(apiClient, fromModel),\n    );\n  }\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    createCachedContentConfigToVertex(fromConfig, toObject);\n  }\n\n  return toObject;\n}\n\nexport function deleteCachedContentParametersToMldev(\n  apiClient: ApiClient,\n  fromObject: types.DeleteCachedContentParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'name'],\n      t.tCachedContentName(apiClient, fromName),\n    );\n  }\n\n  return toObject;\n}\n\nexport function deleteCachedContentParametersToVertex(\n  apiClient: ApiClient,\n  fromObject: types.DeleteCachedContentParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'name'],\n      t.tCachedContentName(apiClient, fromName),\n    );\n  }\n\n  return toObject;\n}\n\nexport function deleteCachedContentResponseFromMldev(\n  fromObject: types.DeleteCachedContentResponse,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSdkHttpResponse = common.getValueByPath(fromObject, [\n    'sdkHttpResponse',\n  ]);\n  if (fromSdkHttpResponse != null) {\n    common.setValueByPath(toObject, ['sdkHttpResponse'], fromSdkHttpResponse);\n  }\n\n  return toObject;\n}\n\nexport function deleteCachedContentResponseFromVertex(\n  fromObject: types.DeleteCachedContentResponse,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSdkHttpResponse = common.getValueByPath(fromObject, [\n    'sdkHttpResponse',\n  ]);\n  if (fromSdkHttpResponse != null) {\n    common.setValueByPath(toObject, ['sdkHttpResponse'], fromSdkHttpResponse);\n  }\n\n  return toObject;\n}\n\nexport function fileDataToMldev(\n  fromObject: types.FileData,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  if (common.getValueByPath(fromObject, ['displayName']) !== undefined) {\n    throw new Error('displayName parameter is not supported in Gemini API.');\n  }\n\n  const fromFileUri = common.getValueByPath(fromObject, ['fileUri']);\n  if (fromFileUri != null) {\n    common.setValueByPath(toObject, ['fileUri'], fromFileUri);\n  }\n\n  const fromMimeType = common.getValueByPath(fromObject, ['mimeType']);\n  if (fromMimeType != null) {\n    common.setValueByPath(toObject, ['mimeType'], fromMimeType);\n  }\n\n  return toObject;\n}\n\nexport function functionDeclarationToVertex(\n  fromObject: types.FunctionDeclaration,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  if (common.getValueByPath(fromObject, ['behavior']) !== undefined) {\n    throw new Error('behavior parameter is not supported in Vertex AI.');\n  }\n\n  const fromDescription = common.getValueByPath(fromObject, ['description']);\n  if (fromDescription != null) {\n    common.setValueByPath(toObject, ['description'], fromDescription);\n  }\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(toObject, ['name'], fromName);\n  }\n\n  const fromParameters = common.getValueByPath(fromObject, ['parameters']);\n  if (fromParameters != null) {\n    common.setValueByPath(toObject, ['parameters'], fromParameters);\n  }\n\n  const fromParametersJsonSchema = common.getValueByPath(fromObject, [\n    'parametersJsonSchema',\n  ]);\n  if (fromParametersJsonSchema != null) {\n    common.setValueByPath(\n      toObject,\n      ['parametersJsonSchema'],\n      fromParametersJsonSchema,\n    );\n  }\n\n  const fromResponse = common.getValueByPath(fromObject, ['response']);\n  if (fromResponse != null) {\n    common.setValueByPath(toObject, ['response'], fromResponse);\n  }\n\n  const fromResponseJsonSchema = common.getValueByPath(fromObject, [\n    'responseJsonSchema',\n  ]);\n  if (fromResponseJsonSchema != null) {\n    common.setValueByPath(\n      toObject,\n      ['responseJsonSchema'],\n      fromResponseJsonSchema,\n    );\n  }\n\n  return toObject;\n}\n\nexport function getCachedContentParametersToMldev(\n  apiClient: ApiClient,\n  fromObject: types.GetCachedContentParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'name'],\n      t.tCachedContentName(apiClient, fromName),\n    );\n  }\n\n  return toObject;\n}\n\nexport function getCachedContentParametersToVertex(\n  apiClient: ApiClient,\n  fromObject: types.GetCachedContentParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'name'],\n      t.tCachedContentName(apiClient, fromName),\n    );\n  }\n\n  return toObject;\n}\n\nexport function googleMapsToMldev(\n  fromObject: types.GoogleMaps,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  if (common.getValueByPath(fromObject, ['authConfig']) !== undefined) {\n    throw new Error('authConfig parameter is not supported in Gemini API.');\n  }\n\n  const fromEnableWidget = common.getValueByPath(fromObject, ['enableWidget']);\n  if (fromEnableWidget != null) {\n    common.setValueByPath(toObject, ['enableWidget'], fromEnableWidget);\n  }\n\n  return toObject;\n}\n\nexport function googleSearchToMldev(\n  fromObject: types.GoogleSearch,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromTimeRangeFilter = common.getValueByPath(fromObject, [\n    'timeRangeFilter',\n  ]);\n  if (fromTimeRangeFilter != null) {\n    common.setValueByPath(toObject, ['timeRangeFilter'], fromTimeRangeFilter);\n  }\n\n  if (common.getValueByPath(fromObject, ['excludeDomains']) !== undefined) {\n    throw new Error('excludeDomains parameter is not supported in Gemini API.');\n  }\n\n  return toObject;\n}\n\nexport function listCachedContentsConfigToMldev(\n  fromObject: types.ListCachedContentsConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromPageSize = common.getValueByPath(fromObject, ['pageSize']);\n  if (parentObject !== undefined && fromPageSize != null) {\n    common.setValueByPath(parentObject, ['_query', 'pageSize'], fromPageSize);\n  }\n\n  const fromPageToken = common.getValueByPath(fromObject, ['pageToken']);\n  if (parentObject !== undefined && fromPageToken != null) {\n    common.setValueByPath(parentObject, ['_query', 'pageToken'], fromPageToken);\n  }\n\n  return toObject;\n}\n\nexport function listCachedContentsConfigToVertex(\n  fromObject: types.ListCachedContentsConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromPageSize = common.getValueByPath(fromObject, ['pageSize']);\n  if (parentObject !== undefined && fromPageSize != null) {\n    common.setValueByPath(parentObject, ['_query', 'pageSize'], fromPageSize);\n  }\n\n  const fromPageToken = common.getValueByPath(fromObject, ['pageToken']);\n  if (parentObject !== undefined && fromPageToken != null) {\n    common.setValueByPath(parentObject, ['_query', 'pageToken'], fromPageToken);\n  }\n\n  return toObject;\n}\n\nexport function listCachedContentsParametersToMldev(\n  fromObject: types.ListCachedContentsParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    listCachedContentsConfigToMldev(fromConfig, toObject);\n  }\n\n  return toObject;\n}\n\nexport function listCachedContentsParametersToVertex(\n  fromObject: types.ListCachedContentsParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    listCachedContentsConfigToVertex(fromConfig, toObject);\n  }\n\n  return toObject;\n}\n\nexport function listCachedContentsResponseFromMldev(\n  fromObject: types.ListCachedContentsResponse,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSdkHttpResponse = common.getValueByPath(fromObject, [\n    'sdkHttpResponse',\n  ]);\n  if (fromSdkHttpResponse != null) {\n    common.setValueByPath(toObject, ['sdkHttpResponse'], fromSdkHttpResponse);\n  }\n\n  const fromNextPageToken = common.getValueByPath(fromObject, [\n    'nextPageToken',\n  ]);\n  if (fromNextPageToken != null) {\n    common.setValueByPath(toObject, ['nextPageToken'], fromNextPageToken);\n  }\n\n  const fromCachedContents = common.getValueByPath(fromObject, [\n    'cachedContents',\n  ]);\n  if (fromCachedContents != null) {\n    let transformedList = fromCachedContents;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(toObject, ['cachedContents'], transformedList);\n  }\n\n  return toObject;\n}\n\nexport function listCachedContentsResponseFromVertex(\n  fromObject: types.ListCachedContentsResponse,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSdkHttpResponse = common.getValueByPath(fromObject, [\n    'sdkHttpResponse',\n  ]);\n  if (fromSdkHttpResponse != null) {\n    common.setValueByPath(toObject, ['sdkHttpResponse'], fromSdkHttpResponse);\n  }\n\n  const fromNextPageToken = common.getValueByPath(fromObject, [\n    'nextPageToken',\n  ]);\n  if (fromNextPageToken != null) {\n    common.setValueByPath(toObject, ['nextPageToken'], fromNextPageToken);\n  }\n\n  const fromCachedContents = common.getValueByPath(fromObject, [\n    'cachedContents',\n  ]);\n  if (fromCachedContents != null) {\n    let transformedList = fromCachedContents;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(toObject, ['cachedContents'], transformedList);\n  }\n\n  return toObject;\n}\n\nexport function partToMldev(fromObject: types.Part): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromVideoMetadata = common.getValueByPath(fromObject, [\n    'videoMetadata',\n  ]);\n  if (fromVideoMetadata != null) {\n    common.setValueByPath(toObject, ['videoMetadata'], fromVideoMetadata);\n  }\n\n  const fromThought = common.getValueByPath(fromObject, ['thought']);\n  if (fromThought != null) {\n    common.setValueByPath(toObject, ['thought'], fromThought);\n  }\n\n  const fromInlineData = common.getValueByPath(fromObject, ['inlineData']);\n  if (fromInlineData != null) {\n    common.setValueByPath(\n      toObject,\n      ['inlineData'],\n      blobToMldev(fromInlineData),\n    );\n  }\n\n  const fromFileData = common.getValueByPath(fromObject, ['fileData']);\n  if (fromFileData != null) {\n    common.setValueByPath(\n      toObject,\n      ['fileData'],\n      fileDataToMldev(fromFileData),\n    );\n  }\n\n  const fromThoughtSignature = common.getValueByPath(fromObject, [\n    'thoughtSignature',\n  ]);\n  if (fromThoughtSignature != null) {\n    common.setValueByPath(toObject, ['thoughtSignature'], fromThoughtSignature);\n  }\n\n  const fromFunctionCall = common.getValueByPath(fromObject, ['functionCall']);\n  if (fromFunctionCall != null) {\n    common.setValueByPath(toObject, ['functionCall'], fromFunctionCall);\n  }\n\n  const fromCodeExecutionResult = common.getValueByPath(fromObject, [\n    'codeExecutionResult',\n  ]);\n  if (fromCodeExecutionResult != null) {\n    common.setValueByPath(\n      toObject,\n      ['codeExecutionResult'],\n      fromCodeExecutionResult,\n    );\n  }\n\n  const fromExecutableCode = common.getValueByPath(fromObject, [\n    'executableCode',\n  ]);\n  if (fromExecutableCode != null) {\n    common.setValueByPath(toObject, ['executableCode'], fromExecutableCode);\n  }\n\n  const fromFunctionResponse = common.getValueByPath(fromObject, [\n    'functionResponse',\n  ]);\n  if (fromFunctionResponse != null) {\n    common.setValueByPath(toObject, ['functionResponse'], fromFunctionResponse);\n  }\n\n  const fromText = common.getValueByPath(fromObject, ['text']);\n  if (fromText != null) {\n    common.setValueByPath(toObject, ['text'], fromText);\n  }\n\n  return toObject;\n}\n\nexport function toolToMldev(fromObject: types.Tool): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromFunctionDeclarations = common.getValueByPath(fromObject, [\n    'functionDeclarations',\n  ]);\n  if (fromFunctionDeclarations != null) {\n    let transformedList = fromFunctionDeclarations;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(toObject, ['functionDeclarations'], transformedList);\n  }\n\n  if (common.getValueByPath(fromObject, ['retrieval']) !== undefined) {\n    throw new Error('retrieval parameter is not supported in Gemini API.');\n  }\n\n  const fromGoogleSearch = common.getValueByPath(fromObject, ['googleSearch']);\n  if (fromGoogleSearch != null) {\n    common.setValueByPath(\n      toObject,\n      ['googleSearch'],\n      googleSearchToMldev(fromGoogleSearch),\n    );\n  }\n\n  const fromGoogleSearchRetrieval = common.getValueByPath(fromObject, [\n    'googleSearchRetrieval',\n  ]);\n  if (fromGoogleSearchRetrieval != null) {\n    common.setValueByPath(\n      toObject,\n      ['googleSearchRetrieval'],\n      fromGoogleSearchRetrieval,\n    );\n  }\n\n  if (\n    common.getValueByPath(fromObject, ['enterpriseWebSearch']) !== undefined\n  ) {\n    throw new Error(\n      'enterpriseWebSearch parameter is not supported in Gemini API.',\n    );\n  }\n\n  const fromGoogleMaps = common.getValueByPath(fromObject, ['googleMaps']);\n  if (fromGoogleMaps != null) {\n    common.setValueByPath(\n      toObject,\n      ['googleMaps'],\n      googleMapsToMldev(fromGoogleMaps),\n    );\n  }\n\n  const fromUrlContext = common.getValueByPath(fromObject, ['urlContext']);\n  if (fromUrlContext != null) {\n    common.setValueByPath(toObject, ['urlContext'], fromUrlContext);\n  }\n\n  const fromComputerUse = common.getValueByPath(fromObject, ['computerUse']);\n  if (fromComputerUse != null) {\n    common.setValueByPath(toObject, ['computerUse'], fromComputerUse);\n  }\n\n  const fromCodeExecution = common.getValueByPath(fromObject, [\n    'codeExecution',\n  ]);\n  if (fromCodeExecution != null) {\n    common.setValueByPath(toObject, ['codeExecution'], fromCodeExecution);\n  }\n\n  return toObject;\n}\n\nexport function toolToVertex(fromObject: types.Tool): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromFunctionDeclarations = common.getValueByPath(fromObject, [\n    'functionDeclarations',\n  ]);\n  if (fromFunctionDeclarations != null) {\n    let transformedList = fromFunctionDeclarations;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return functionDeclarationToVertex(item);\n      });\n    }\n    common.setValueByPath(toObject, ['functionDeclarations'], transformedList);\n  }\n\n  const fromRetrieval = common.getValueByPath(fromObject, ['retrieval']);\n  if (fromRetrieval != null) {\n    common.setValueByPath(toObject, ['retrieval'], fromRetrieval);\n  }\n\n  const fromGoogleSearch = common.getValueByPath(fromObject, ['googleSearch']);\n  if (fromGoogleSearch != null) {\n    common.setValueByPath(toObject, ['googleSearch'], fromGoogleSearch);\n  }\n\n  const fromGoogleSearchRetrieval = common.getValueByPath(fromObject, [\n    'googleSearchRetrieval',\n  ]);\n  if (fromGoogleSearchRetrieval != null) {\n    common.setValueByPath(\n      toObject,\n      ['googleSearchRetrieval'],\n      fromGoogleSearchRetrieval,\n    );\n  }\n\n  const fromEnterpriseWebSearch = common.getValueByPath(fromObject, [\n    'enterpriseWebSearch',\n  ]);\n  if (fromEnterpriseWebSearch != null) {\n    common.setValueByPath(\n      toObject,\n      ['enterpriseWebSearch'],\n      fromEnterpriseWebSearch,\n    );\n  }\n\n  const fromGoogleMaps = common.getValueByPath(fromObject, ['googleMaps']);\n  if (fromGoogleMaps != null) {\n    common.setValueByPath(toObject, ['googleMaps'], fromGoogleMaps);\n  }\n\n  const fromUrlContext = common.getValueByPath(fromObject, ['urlContext']);\n  if (fromUrlContext != null) {\n    common.setValueByPath(toObject, ['urlContext'], fromUrlContext);\n  }\n\n  const fromComputerUse = common.getValueByPath(fromObject, ['computerUse']);\n  if (fromComputerUse != null) {\n    common.setValueByPath(toObject, ['computerUse'], fromComputerUse);\n  }\n\n  const fromCodeExecution = common.getValueByPath(fromObject, [\n    'codeExecution',\n  ]);\n  if (fromCodeExecution != null) {\n    common.setValueByPath(toObject, ['codeExecution'], fromCodeExecution);\n  }\n\n  return toObject;\n}\n\nexport function updateCachedContentConfigToMldev(\n  fromObject: types.UpdateCachedContentConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromTtl = common.getValueByPath(fromObject, ['ttl']);\n  if (parentObject !== undefined && fromTtl != null) {\n    common.setValueByPath(parentObject, ['ttl'], fromTtl);\n  }\n\n  const fromExpireTime = common.getValueByPath(fromObject, ['expireTime']);\n  if (parentObject !== undefined && fromExpireTime != null) {\n    common.setValueByPath(parentObject, ['expireTime'], fromExpireTime);\n  }\n\n  return toObject;\n}\n\nexport function updateCachedContentConfigToVertex(\n  fromObject: types.UpdateCachedContentConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromTtl = common.getValueByPath(fromObject, ['ttl']);\n  if (parentObject !== undefined && fromTtl != null) {\n    common.setValueByPath(parentObject, ['ttl'], fromTtl);\n  }\n\n  const fromExpireTime = common.getValueByPath(fromObject, ['expireTime']);\n  if (parentObject !== undefined && fromExpireTime != null) {\n    common.setValueByPath(parentObject, ['expireTime'], fromExpireTime);\n  }\n\n  return toObject;\n}\n\nexport function updateCachedContentParametersToMldev(\n  apiClient: ApiClient,\n  fromObject: types.UpdateCachedContentParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'name'],\n      t.tCachedContentName(apiClient, fromName),\n    );\n  }\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    updateCachedContentConfigToMldev(fromConfig, toObject);\n  }\n\n  return toObject;\n}\n\nexport function updateCachedContentParametersToVertex(\n  apiClient: ApiClient,\n  fromObject: types.UpdateCachedContentParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'name'],\n      t.tCachedContentName(apiClient, fromName),\n    );\n  }\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    updateCachedContentConfigToVertex(fromConfig, toObject);\n  }\n\n  return toObject;\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\n// Code generated by the Google Gen AI SDK generator DO NOT EDIT.\n\nimport {ApiClient} from './_api_client.js';\nimport * as common from './_common.js';\nimport {BaseModule} from './_common.js';\nimport * as converters from './converters/_caches_converters.js';\nimport {PagedItem, Pager} from './pagers.js';\nimport * as types from './types.js';\n\nexport class Caches extends BaseModule {\n  constructor(private readonly apiClient: ApiClient) {\n    super();\n  }\n\n  /**\n   * Lists cached content configurations.\n   *\n   * @param params - The parameters for the list request.\n   * @return The paginated results of the list of cached contents.\n   *\n   * @example\n   * ```ts\n   * const cachedContents = await ai.caches.list({config: {'pageSize': 2}});\n   * for await (const cachedContent of cachedContents) {\n   *   console.log(cachedContent);\n   * }\n   * ```\n   */\n  list = async (\n    params: types.ListCachedContentsParameters = {},\n  ): Promise<Pager<types.CachedContent>> => {\n    return new Pager<types.CachedContent>(\n      PagedItem.PAGED_ITEM_CACHED_CONTENTS,\n      (x: types.ListCachedContentsParameters) => this.listInternal(x),\n      await this.listInternal(params),\n      params,\n    );\n  };\n\n  /**\n   * Creates a cached contents resource.\n   *\n   * @remarks\n   * Context caching is only supported for specific models. See [Gemini\n   * Developer API reference](https://ai.google.dev/gemini-api/docs/caching?lang=node/context-cac)\n   * and [Vertex AI reference](https://cloud.google.com/vertex-ai/generative-ai/docs/context-cache/context-cache-overview#supported_models)\n   * for more information.\n   *\n   * @param params - The parameters for the create request.\n   * @return The created cached content.\n   *\n   * @example\n   * ```ts\n   * const contents = ...; // Initialize the content to cache.\n   * const response = await ai.caches.create({\n   *   model: 'gemini-2.0-flash-001',\n   *   config: {\n   *    'contents': contents,\n   *    'displayName': 'test cache',\n   *    'systemInstruction': 'What is the sum of the two pdfs?',\n   *    'ttl': '86400s',\n   *  }\n   * });\n   * ```\n   */\n  async create(\n    params: types.CreateCachedContentParameters,\n  ): Promise<types.CachedContent> {\n    let response: Promise<types.CachedContent>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      const body = converters.createCachedContentParametersToVertex(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        'cachedContents',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'POST',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json();\n        }) as Promise<types.CachedContent>;\n\n      return response.then((resp) => {\n        return resp as types.CachedContent;\n      });\n    } else {\n      const body = converters.createCachedContentParametersToMldev(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        'cachedContents',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'POST',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json();\n        }) as Promise<types.CachedContent>;\n\n      return response.then((resp) => {\n        return resp as types.CachedContent;\n      });\n    }\n  }\n\n  /**\n   * Gets cached content configurations.\n   *\n   * @param params - The parameters for the get request.\n   * @return The cached content.\n   *\n   * @example\n   * ```ts\n   * await ai.caches.get({name: '...'}); // The server-generated resource name.\n   * ```\n   */\n  async get(\n    params: types.GetCachedContentParameters,\n  ): Promise<types.CachedContent> {\n    let response: Promise<types.CachedContent>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      const body = converters.getCachedContentParametersToVertex(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        '{name}',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'GET',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json();\n        }) as Promise<types.CachedContent>;\n\n      return response.then((resp) => {\n        return resp as types.CachedContent;\n      });\n    } else {\n      const body = converters.getCachedContentParametersToMldev(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        '{name}',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'GET',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json();\n        }) as Promise<types.CachedContent>;\n\n      return response.then((resp) => {\n        return resp as types.CachedContent;\n      });\n    }\n  }\n\n  /**\n   * Deletes cached content.\n   *\n   * @param params - The parameters for the delete request.\n   * @return The empty response returned by the API.\n   *\n   * @example\n   * ```ts\n   * await ai.caches.delete({name: '...'}); // The server-generated resource name.\n   * ```\n   */\n  async delete(\n    params: types.DeleteCachedContentParameters,\n  ): Promise<types.DeleteCachedContentResponse> {\n    let response: Promise<types.DeleteCachedContentResponse>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      const body = converters.deleteCachedContentParametersToVertex(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        '{name}',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'DELETE',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json().then((jsonResponse) => {\n            const response = jsonResponse as types.DeleteCachedContentResponse;\n            response.sdkHttpResponse = {\n              headers: httpResponse.headers,\n            } as types.HttpResponse;\n            return response;\n          });\n        }) as Promise<types.DeleteCachedContentResponse>;\n\n      return response.then((apiResponse) => {\n        const resp =\n          converters.deleteCachedContentResponseFromVertex(apiResponse);\n        const typedResp = new types.DeleteCachedContentResponse();\n        Object.assign(typedResp, resp);\n        return typedResp;\n      });\n    } else {\n      const body = converters.deleteCachedContentParametersToMldev(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        '{name}',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'DELETE',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json().then((jsonResponse) => {\n            const response = jsonResponse as types.DeleteCachedContentResponse;\n            response.sdkHttpResponse = {\n              headers: httpResponse.headers,\n            } as types.HttpResponse;\n            return response;\n          });\n        }) as Promise<types.DeleteCachedContentResponse>;\n\n      return response.then((apiResponse) => {\n        const resp =\n          converters.deleteCachedContentResponseFromMldev(apiResponse);\n        const typedResp = new types.DeleteCachedContentResponse();\n        Object.assign(typedResp, resp);\n        return typedResp;\n      });\n    }\n  }\n\n  /**\n   * Updates cached content configurations.\n   *\n   * @param params - The parameters for the update request.\n   * @return The updated cached content.\n   *\n   * @example\n   * ```ts\n   * const response = await ai.caches.update({\n   *   name: '...',  // The server-generated resource name.\n   *   config: {'ttl': '7600s'}\n   * });\n   * ```\n   */\n  async update(\n    params: types.UpdateCachedContentParameters,\n  ): Promise<types.CachedContent> {\n    let response: Promise<types.CachedContent>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      const body = converters.updateCachedContentParametersToVertex(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        '{name}',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'PATCH',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json();\n        }) as Promise<types.CachedContent>;\n\n      return response.then((resp) => {\n        return resp as types.CachedContent;\n      });\n    } else {\n      const body = converters.updateCachedContentParametersToMldev(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        '{name}',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'PATCH',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json();\n        }) as Promise<types.CachedContent>;\n\n      return response.then((resp) => {\n        return resp as types.CachedContent;\n      });\n    }\n  }\n\n  private async listInternal(\n    params: types.ListCachedContentsParameters,\n  ): Promise<types.ListCachedContentsResponse> {\n    let response: Promise<types.ListCachedContentsResponse>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      const body = converters.listCachedContentsParametersToVertex(params);\n      path = common.formatMap(\n        'cachedContents',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'GET',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json().then((jsonResponse) => {\n            const response = jsonResponse as types.ListCachedContentsResponse;\n            response.sdkHttpResponse = {\n              headers: httpResponse.headers,\n            } as types.HttpResponse;\n            return response;\n          });\n        }) as Promise<types.ListCachedContentsResponse>;\n\n      return response.then((apiResponse) => {\n        const resp =\n          converters.listCachedContentsResponseFromVertex(apiResponse);\n        const typedResp = new types.ListCachedContentsResponse();\n        Object.assign(typedResp, resp);\n        return typedResp;\n      });\n    } else {\n      const body = converters.listCachedContentsParametersToMldev(params);\n      path = common.formatMap(\n        'cachedContents',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'GET',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json().then((jsonResponse) => {\n            const response = jsonResponse as types.ListCachedContentsResponse;\n            response.sdkHttpResponse = {\n              headers: httpResponse.headers,\n            } as types.HttpResponse;\n            return response;\n          });\n        }) as Promise<types.ListCachedContentsResponse>;\n\n      return response.then((apiResponse) => {\n        const resp =\n          converters.listCachedContentsResponseFromMldev(apiResponse);\n        const typedResp = new types.ListCachedContentsResponse();\n        Object.assign(typedResp, resp);\n        return typedResp;\n      });\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\nimport {ApiClient} from './_api_client.js';\nimport * as t from './_transformers.js';\nimport {Models} from './models.js';\nimport * as types from './types.js';\n\n/**\n * Returns true if the response is valid, false otherwise.\n */\nfunction isValidResponse(response: types.GenerateContentResponse): boolean {\n  if (response.candidates == undefined || response.candidates.length === 0) {\n    return false;\n  }\n  const content = response.candidates[0]?.content;\n  if (content === undefined) {\n    return false;\n  }\n  return isValidContent(content);\n}\n\nfunction isValidContent(content: types.Content): boolean {\n  if (content.parts === undefined || content.parts.length === 0) {\n    return false;\n  }\n  for (const part of content.parts) {\n    if (part === undefined || Object.keys(part).length === 0) {\n      return false;\n    }\n  }\n  return true;\n}\n\n/**\n * Validates the history contains the correct roles.\n *\n * @throws Error if the history does not start with a user turn.\n * @throws Error if the history contains an invalid role.\n */\nfunction validateHistory(history: types.Content[]) {\n  // Empty history is valid.\n  if (history.length === 0) {\n    return;\n  }\n  for (const content of history) {\n    if (content.role !== 'user' && content.role !== 'model') {\n      throw new Error(`Role must be user or model, but got ${content.role}.`);\n    }\n  }\n}\n\n/**\n * Extracts the curated (valid) history from a comprehensive history.\n *\n * @remarks\n * The model may sometimes generate invalid or empty contents(e.g., due to safty\n * filters or recitation). Extracting valid turns from the history\n * ensures that subsequent requests could be accpeted by the model.\n */\nfunction extractCuratedHistory(\n  comprehensiveHistory: types.Content[],\n): types.Content[] {\n  if (comprehensiveHistory === undefined || comprehensiveHistory.length === 0) {\n    return [];\n  }\n  const curatedHistory: types.Content[] = [];\n  const length = comprehensiveHistory.length;\n  let i = 0;\n  while (i < length) {\n    if (comprehensiveHistory[i].role === 'user') {\n      curatedHistory.push(comprehensiveHistory[i]);\n      i++;\n    } else {\n      const modelOutput: types.Content[] = [];\n      let isValid = true;\n      while (i < length && comprehensiveHistory[i].role === 'model') {\n        modelOutput.push(comprehensiveHistory[i]);\n        if (isValid && !isValidContent(comprehensiveHistory[i])) {\n          isValid = false;\n        }\n        i++;\n      }\n      if (isValid) {\n        curatedHistory.push(...modelOutput);\n      } else {\n        // Remove the last user input when model content is invalid.\n        curatedHistory.pop();\n      }\n    }\n  }\n  return curatedHistory;\n}\n\n/**\n * A utility class to create a chat session.\n */\nexport class Chats {\n  private readonly modelsModule: Models;\n  private readonly apiClient: ApiClient;\n\n  constructor(modelsModule: Models, apiClient: ApiClient) {\n    this.modelsModule = modelsModule;\n    this.apiClient = apiClient;\n  }\n\n  /**\n   * Creates a new chat session.\n   *\n   * @remarks\n   * The config in the params will be used for all requests within the chat\n   * session unless overridden by a per-request `config` in\n   * @see {@link types.SendMessageParameters#config}.\n   *\n   * @param params - Parameters for creating a chat session.\n   * @returns A new chat session.\n   *\n   * @example\n   * ```ts\n   * const chat = ai.chats.create({\n   *   model: 'gemini-2.0-flash'\n   *   config: {\n   *     temperature: 0.5,\n   *     maxOutputTokens: 1024,\n   *   }\n   * });\n   * ```\n   */\n  create(params: types.CreateChatParameters) {\n    return new Chat(\n      this.apiClient,\n      this.modelsModule,\n      params.model,\n      params.config,\n      // Deep copy the history to avoid mutating the history outside of the\n      // chat session.\n      structuredClone(params.history),\n    );\n  }\n}\n\n/**\n * Chat session that enables sending messages to the model with previous\n * conversation context.\n *\n * @remarks\n * The session maintains all the turns between user and model.\n */\nexport class Chat {\n  // A promise to represent the current state of the message being sent to the\n  // model.\n  private sendPromise: Promise<void> = Promise.resolve();\n\n  constructor(\n    private readonly apiClient: ApiClient,\n    private readonly modelsModule: Models,\n    private readonly model: string,\n    private readonly config: types.GenerateContentConfig = {},\n    private history: types.Content[] = [],\n  ) {\n    validateHistory(history);\n  }\n\n  /**\n   * Sends a message to the model and returns the response.\n   *\n   * @remarks\n   * This method will wait for the previous message to be processed before\n   * sending the next message.\n   *\n   * @see {@link Chat#sendMessageStream} for streaming method.\n   * @param params - parameters for sending messages within a chat session.\n   * @returns The model's response.\n   *\n   * @example\n   * ```ts\n   * const chat = ai.chats.create({model: 'gemini-2.0-flash'});\n   * const response = await chat.sendMessage({\n   *   message: 'Why is the sky blue?'\n   * });\n   * console.log(response.text);\n   * ```\n   */\n  async sendMessage(\n    params: types.SendMessageParameters,\n  ): Promise<types.GenerateContentResponse> {\n    await this.sendPromise;\n    const inputContent = t.tContent(params.message);\n    const responsePromise = this.modelsModule.generateContent({\n      model: this.model,\n      contents: this.getHistory(true).concat(inputContent),\n      config: params.config ?? this.config,\n    });\n    this.sendPromise = (async () => {\n      const response = await responsePromise;\n      const outputContent = response.candidates?.[0]?.content;\n\n      // Because the AFC input contains the entire curated chat history in\n      // addition to the new user input, we need to truncate the AFC history\n      // to deduplicate the existing chat history.\n      const fullAutomaticFunctionCallingHistory =\n        response.automaticFunctionCallingHistory;\n      const index = this.getHistory(true).length;\n\n      let automaticFunctionCallingHistory: types.Content[] = [];\n      if (fullAutomaticFunctionCallingHistory != null) {\n        automaticFunctionCallingHistory =\n          fullAutomaticFunctionCallingHistory.slice(index) ?? [];\n      }\n\n      const modelOutput = outputContent ? [outputContent] : [];\n      this.recordHistory(\n        inputContent,\n        modelOutput,\n        automaticFunctionCallingHistory,\n      );\n      return;\n    })();\n    await this.sendPromise.catch(() => {\n      // Resets sendPromise to avoid subsequent calls failing\n      this.sendPromise = Promise.resolve();\n    });\n    return responsePromise;\n  }\n\n  /**\n   * Sends a message to the model and returns the response in chunks.\n   *\n   * @remarks\n   * This method will wait for the previous message to be processed before\n   * sending the next message.\n   *\n   * @see {@link Chat#sendMessage} for non-streaming method.\n   * @param params - parameters for sending the message.\n   * @return The model's response.\n   *\n   * @example\n   * ```ts\n   * const chat = ai.chats.create({model: 'gemini-2.0-flash'});\n   * const response = await chat.sendMessageStream({\n   *   message: 'Why is the sky blue?'\n   * });\n   * for await (const chunk of response) {\n   *   console.log(chunk.text);\n   * }\n   * ```\n   */\n  async sendMessageStream(\n    params: types.SendMessageParameters,\n  ): Promise<AsyncGenerator<types.GenerateContentResponse>> {\n    await this.sendPromise;\n    const inputContent = t.tContent(params.message);\n    const streamResponse = this.modelsModule.generateContentStream({\n      model: this.model,\n      contents: this.getHistory(true).concat(inputContent),\n      config: params.config ?? this.config,\n    });\n    // Resolve the internal tracking of send completion promise - `sendPromise`\n    // for both success and failure response. The actual failure is still\n    // propagated by the `await streamResponse`.\n    this.sendPromise = streamResponse\n      .then(() => undefined)\n      .catch(() => undefined);\n    const response = await streamResponse;\n    const result = this.processStreamResponse(response, inputContent);\n    return result;\n  }\n\n  /**\n   * Returns the chat history.\n   *\n   * @remarks\n   * The history is a list of contents alternating between user and model.\n   *\n   * There are two types of history:\n   * - The `curated history` contains only the valid turns between user and\n   * model, which will be included in the subsequent requests sent to the model.\n   * - The `comprehensive history` contains all turns, including invalid or\n   *   empty model outputs, providing a complete record of the history.\n   *\n   * The history is updated after receiving the response from the model,\n   * for streaming response, it means receiving the last chunk of the response.\n   *\n   * The `comprehensive history` is returned by default. To get the `curated\n   * history`, set the `curated` parameter to `true`.\n   *\n   * @param curated - whether to return the curated history or the comprehensive\n   *     history.\n   * @return History contents alternating between user and model for the entire\n   *     chat session.\n   */\n  getHistory(curated: boolean = false): types.Content[] {\n    const history = curated\n      ? extractCuratedHistory(this.history)\n      : this.history;\n    // Deep copy the history to avoid mutating the history outside of the\n    // chat session.\n    return structuredClone(history);\n  }\n\n  private async *processStreamResponse(\n    streamResponse: AsyncGenerator<types.GenerateContentResponse>,\n    inputContent: types.Content,\n  ) {\n    const outputContent: types.Content[] = [];\n    for await (const chunk of streamResponse) {\n      if (isValidResponse(chunk)) {\n        const content = chunk.candidates?.[0]?.content;\n        if (content !== undefined) {\n          outputContent.push(content);\n        }\n      }\n      yield chunk;\n    }\n    this.recordHistory(inputContent, outputContent);\n  }\n\n  private recordHistory(\n    userInput: types.Content,\n    modelOutput: types.Content[],\n    automaticFunctionCallingHistory?: types.Content[],\n  ) {\n    let outputContents: types.Content[] = [];\n    if (\n      modelOutput.length > 0 &&\n      modelOutput.every((content) => content.role !== undefined)\n    ) {\n      outputContents = modelOutput;\n    } else {\n      // Appends an empty content when model returns empty response, so that the\n      // history is always alternating between user and model.\n      outputContents.push({\n        role: 'model',\n        parts: [],\n      } as types.Content);\n    }\n    if (\n      automaticFunctionCallingHistory &&\n      automaticFunctionCallingHistory.length > 0\n    ) {\n      this.history.push(\n        ...extractCuratedHistory(automaticFunctionCallingHistory!),\n      );\n    } else {\n      this.history.push(userInput);\n    }\n    this.history.push(...outputContents);\n  }\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\n/**\n * Details for errors from calling the API.\n */\nexport interface ApiErrorInfo {\n  /** The error message. */\n  message: string;\n  /** The HTTP status code. */\n  status: number;\n}\n\n/**\n * API errors raised by the GenAI API.\n */\nexport class ApiError extends Error {\n  /** HTTP status code */\n  status: number;\n\n  constructor(options: ApiErrorInfo) {\n    super(options.message);\n    this.name = 'ApiError';\n    this.status = options.status;\n    Object.setPrototypeOf(this, ApiError.prototype);\n  }\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\n// Code generated by the Google Gen AI SDK generator DO NOT EDIT.\n\nimport * as common from '../_common.js';\nimport * as t from '../_transformers.js';\nimport type * as types from '../types.js';\n\nexport function createFileParametersToMldev(\n  fromObject: types.CreateFileParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromFile = common.getValueByPath(fromObject, ['file']);\n  if (fromFile != null) {\n    common.setValueByPath(toObject, ['file'], fromFile);\n  }\n\n  return toObject;\n}\n\nexport function createFileResponseFromMldev(\n  fromObject: types.CreateFileResponse,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSdkHttpResponse = common.getValueByPath(fromObject, [\n    'sdkHttpResponse',\n  ]);\n  if (fromSdkHttpResponse != null) {\n    common.setValueByPath(toObject, ['sdkHttpResponse'], fromSdkHttpResponse);\n  }\n\n  return toObject;\n}\n\nexport function deleteFileParametersToMldev(\n  fromObject: types.DeleteFileParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(toObject, ['_url', 'file'], t.tFileName(fromName));\n  }\n\n  return toObject;\n}\n\nexport function deleteFileResponseFromMldev(\n  fromObject: types.DeleteFileResponse,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSdkHttpResponse = common.getValueByPath(fromObject, [\n    'sdkHttpResponse',\n  ]);\n  if (fromSdkHttpResponse != null) {\n    common.setValueByPath(toObject, ['sdkHttpResponse'], fromSdkHttpResponse);\n  }\n\n  return toObject;\n}\n\nexport function getFileParametersToMldev(\n  fromObject: types.GetFileParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(toObject, ['_url', 'file'], t.tFileName(fromName));\n  }\n\n  return toObject;\n}\n\nexport function listFilesConfigToMldev(\n  fromObject: types.ListFilesConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromPageSize = common.getValueByPath(fromObject, ['pageSize']);\n  if (parentObject !== undefined && fromPageSize != null) {\n    common.setValueByPath(parentObject, ['_query', 'pageSize'], fromPageSize);\n  }\n\n  const fromPageToken = common.getValueByPath(fromObject, ['pageToken']);\n  if (parentObject !== undefined && fromPageToken != null) {\n    common.setValueByPath(parentObject, ['_query', 'pageToken'], fromPageToken);\n  }\n\n  return toObject;\n}\n\nexport function listFilesParametersToMldev(\n  fromObject: types.ListFilesParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    listFilesConfigToMldev(fromConfig, toObject);\n  }\n\n  return toObject;\n}\n\nexport function listFilesResponseFromMldev(\n  fromObject: types.ListFilesResponse,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSdkHttpResponse = common.getValueByPath(fromObject, [\n    'sdkHttpResponse',\n  ]);\n  if (fromSdkHttpResponse != null) {\n    common.setValueByPath(toObject, ['sdkHttpResponse'], fromSdkHttpResponse);\n  }\n\n  const fromNextPageToken = common.getValueByPath(fromObject, [\n    'nextPageToken',\n  ]);\n  if (fromNextPageToken != null) {\n    common.setValueByPath(toObject, ['nextPageToken'], fromNextPageToken);\n  }\n\n  const fromFiles = common.getValueByPath(fromObject, ['files']);\n  if (fromFiles != null) {\n    let transformedList = fromFiles;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(toObject, ['files'], transformedList);\n  }\n\n  return toObject;\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\n// Code generated by the Google Gen AI SDK generator DO NOT EDIT.\n\nimport {ApiClient} from './_api_client.js';\nimport * as common from './_common.js';\nimport {BaseModule} from './_common.js';\nimport * as converters from './converters/_files_converters.js';\nimport {PagedItem, Pager} from './pagers.js';\nimport * as types from './types.js';\n\nexport class Files extends BaseModule {\n  constructor(private readonly apiClient: ApiClient) {\n    super();\n  }\n\n  /**\n   * Lists all current project files from the service.\n   *\n   * @param params - The parameters for the list request\n   * @return The paginated results of the list of files\n   *\n   * @example\n   * The following code prints the names of all files from the service, the\n   * size of each page is 10.\n   *\n   * ```ts\n   * const listResponse = await ai.files.list({config: {'pageSize': 10}});\n   * for await (const file of listResponse) {\n   *   console.log(file.name);\n   * }\n   * ```\n   */\n  list = async (\n    params: types.ListFilesParameters = {},\n  ): Promise<Pager<types.File>> => {\n    return new Pager<types.File>(\n      PagedItem.PAGED_ITEM_FILES,\n      (x: types.ListFilesParameters) => this.listInternal(x),\n      await this.listInternal(params),\n      params,\n    );\n  };\n\n  /**\n   * Uploads a file asynchronously to the Gemini API.\n   * This method is not available in Vertex AI.\n   * Supported upload sources:\n   * - Node.js: File path (string) or Blob object.\n   * - Browser: Blob object (e.g., File).\n   *\n   * @remarks\n   * The `mimeType` can be specified in the `config` parameter. If omitted:\n   *  - For file path (string) inputs, the `mimeType` will be inferred from the\n   *     file extension.\n   *  - For Blob object inputs, the `mimeType` will be set to the Blob's `type`\n   *     property.\n   * Somex eamples for file extension to mimeType mapping:\n   * .txt -> text/plain\n   * .json -> application/json\n   * .jpg  -> image/jpeg\n   * .png -> image/png\n   * .mp3 -> audio/mpeg\n   * .mp4 -> video/mp4\n   *\n   * This section can contain multiple paragraphs and code examples.\n   *\n   * @param params - Optional parameters specified in the\n   *        `types.UploadFileParameters` interface.\n   *         @see {@link types.UploadFileParameters#config} for the optional\n   *         config in the parameters.\n   * @return A promise that resolves to a `types.File` object.\n   * @throws An error if called on a Vertex AI client.\n   * @throws An error if the `mimeType` is not provided and can not be inferred,\n   * the `mimeType` can be provided in the `params.config` parameter.\n   * @throws An error occurs if a suitable upload location cannot be established.\n   *\n   * @example\n   * The following code uploads a file to Gemini API.\n   *\n   * ```ts\n   * const file = await ai.files.upload({file: 'file.txt', config: {\n   *   mimeType: 'text/plain',\n   * }});\n   * console.log(file.name);\n   * ```\n   */\n  async upload(params: types.UploadFileParameters): Promise<types.File> {\n    if (this.apiClient.isVertexAI()) {\n      throw new Error(\n        'Vertex AI does not support uploading files. You can share files through a GCS bucket.',\n      );\n    }\n\n    return this.apiClient\n      .uploadFile(params.file, params.config)\n      .then((resp) => {\n        return resp as types.File;\n      });\n  }\n\n  /**\n   * Downloads a remotely stored file asynchronously to a location specified in\n   * the `params` object. This method only works on Node environment, to\n   * download files in the browser, use a browser compliant method like an <a>\n   * tag.\n   *\n   * @param params - The parameters for the download request.\n   *\n   * @example\n   * The following code downloads an example file named \"files/mehozpxf877d\" as\n   * \"file.txt\".\n   *\n   * ```ts\n   * await ai.files.download({file: file.name, downloadPath: 'file.txt'});\n   * ```\n   */\n\n  async download(params: types.DownloadFileParameters): Promise<void> {\n    await this.apiClient.downloadFile(params);\n  }\n\n  private async listInternal(\n    params: types.ListFilesParameters,\n  ): Promise<types.ListFilesResponse> {\n    let response: Promise<types.ListFilesResponse>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      throw new Error(\n        'This method is only supported by the Gemini Developer API.',\n      );\n    } else {\n      const body = converters.listFilesParametersToMldev(params);\n      path = common.formatMap('files', body['_url'] as Record<string, unknown>);\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'GET',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json().then((jsonResponse) => {\n            const response = jsonResponse as types.ListFilesResponse;\n            response.sdkHttpResponse = {\n              headers: httpResponse.headers,\n            } as types.HttpResponse;\n            return response;\n          });\n        }) as Promise<types.ListFilesResponse>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.listFilesResponseFromMldev(apiResponse);\n        const typedResp = new types.ListFilesResponse();\n        Object.assign(typedResp, resp);\n        return typedResp;\n      });\n    }\n  }\n\n  private async createInternal(\n    params: types.CreateFileParameters,\n  ): Promise<types.CreateFileResponse> {\n    let response: Promise<types.CreateFileResponse>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      throw new Error(\n        'This method is only supported by the Gemini Developer API.',\n      );\n    } else {\n      const body = converters.createFileParametersToMldev(params);\n      path = common.formatMap(\n        'upload/v1beta/files',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'POST',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json();\n        }) as Promise<types.CreateFileResponse>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.createFileResponseFromMldev(apiResponse);\n        const typedResp = new types.CreateFileResponse();\n        Object.assign(typedResp, resp);\n        return typedResp;\n      });\n    }\n  }\n\n  /**\n   * Retrieves the file information from the service.\n   *\n   * @param params - The parameters for the get request\n   * @return The Promise that resolves to the types.File object requested.\n   *\n   * @example\n   * ```ts\n   * const config: GetFileParameters = {\n   *   name: fileName,\n   * };\n   * file = await ai.files.get(config);\n   * console.log(file.name);\n   * ```\n   */\n  async get(params: types.GetFileParameters): Promise<types.File> {\n    let response: Promise<types.File>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      throw new Error(\n        'This method is only supported by the Gemini Developer API.',\n      );\n    } else {\n      const body = converters.getFileParametersToMldev(params);\n      path = common.formatMap(\n        'files/{file}',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'GET',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json();\n        }) as Promise<types.File>;\n\n      return response.then((resp) => {\n        return resp as types.File;\n      });\n    }\n  }\n\n  /**\n   * Deletes a remotely stored file.\n   *\n   * @param params - The parameters for the delete request.\n   * @return The DeleteFileResponse, the response for the delete method.\n   *\n   * @example\n   * The following code deletes an example file named \"files/mehozpxf877d\".\n   *\n   * ```ts\n   * await ai.files.delete({name: file.name});\n   * ```\n   */\n  async delete(\n    params: types.DeleteFileParameters,\n  ): Promise<types.DeleteFileResponse> {\n    let response: Promise<types.DeleteFileResponse>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      throw new Error(\n        'This method is only supported by the Gemini Developer API.',\n      );\n    } else {\n      const body = converters.deleteFileParametersToMldev(params);\n      path = common.formatMap(\n        'files/{file}',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'DELETE',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json().then((jsonResponse) => {\n            const response = jsonResponse as types.DeleteFileResponse;\n            response.sdkHttpResponse = {\n              headers: httpResponse.headers,\n            } as types.HttpResponse;\n            return response;\n          });\n        }) as Promise<types.DeleteFileResponse>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.deleteFileResponseFromMldev(apiResponse);\n        const typedResp = new types.DeleteFileResponse();\n        Object.assign(typedResp, resp);\n        return typedResp;\n      });\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\n// Code generated by the Google Gen AI SDK generator DO NOT EDIT.\n\nimport {ApiClient} from '../_api_client.js';\nimport * as common from '../_common.js';\nimport * as t from '../_transformers.js';\nimport type * as types from '../types.js';\n\nexport function blobToMldev(fromObject: types.Blob): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  if (common.getValueByPath(fromObject, ['displayName']) !== undefined) {\n    throw new Error('displayName parameter is not supported in Gemini API.');\n  }\n\n  const fromData = common.getValueByPath(fromObject, ['data']);\n  if (fromData != null) {\n    common.setValueByPath(toObject, ['data'], fromData);\n  }\n\n  const fromMimeType = common.getValueByPath(fromObject, ['mimeType']);\n  if (fromMimeType != null) {\n    common.setValueByPath(toObject, ['mimeType'], fromMimeType);\n  }\n\n  return toObject;\n}\n\nexport function contentToMldev(\n  fromObject: types.Content,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromParts = common.getValueByPath(fromObject, ['parts']);\n  if (fromParts != null) {\n    let transformedList = fromParts;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return partToMldev(item);\n      });\n    }\n    common.setValueByPath(toObject, ['parts'], transformedList);\n  }\n\n  const fromRole = common.getValueByPath(fromObject, ['role']);\n  if (fromRole != null) {\n    common.setValueByPath(toObject, ['role'], fromRole);\n  }\n\n  return toObject;\n}\n\nexport function fileDataToMldev(\n  fromObject: types.FileData,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  if (common.getValueByPath(fromObject, ['displayName']) !== undefined) {\n    throw new Error('displayName parameter is not supported in Gemini API.');\n  }\n\n  const fromFileUri = common.getValueByPath(fromObject, ['fileUri']);\n  if (fromFileUri != null) {\n    common.setValueByPath(toObject, ['fileUri'], fromFileUri);\n  }\n\n  const fromMimeType = common.getValueByPath(fromObject, ['mimeType']);\n  if (fromMimeType != null) {\n    common.setValueByPath(toObject, ['mimeType'], fromMimeType);\n  }\n\n  return toObject;\n}\n\nexport function functionDeclarationToVertex(\n  fromObject: types.FunctionDeclaration,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  if (common.getValueByPath(fromObject, ['behavior']) !== undefined) {\n    throw new Error('behavior parameter is not supported in Vertex AI.');\n  }\n\n  const fromDescription = common.getValueByPath(fromObject, ['description']);\n  if (fromDescription != null) {\n    common.setValueByPath(toObject, ['description'], fromDescription);\n  }\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(toObject, ['name'], fromName);\n  }\n\n  const fromParameters = common.getValueByPath(fromObject, ['parameters']);\n  if (fromParameters != null) {\n    common.setValueByPath(toObject, ['parameters'], fromParameters);\n  }\n\n  const fromParametersJsonSchema = common.getValueByPath(fromObject, [\n    'parametersJsonSchema',\n  ]);\n  if (fromParametersJsonSchema != null) {\n    common.setValueByPath(\n      toObject,\n      ['parametersJsonSchema'],\n      fromParametersJsonSchema,\n    );\n  }\n\n  const fromResponse = common.getValueByPath(fromObject, ['response']);\n  if (fromResponse != null) {\n    common.setValueByPath(toObject, ['response'], fromResponse);\n  }\n\n  const fromResponseJsonSchema = common.getValueByPath(fromObject, [\n    'responseJsonSchema',\n  ]);\n  if (fromResponseJsonSchema != null) {\n    common.setValueByPath(\n      toObject,\n      ['responseJsonSchema'],\n      fromResponseJsonSchema,\n    );\n  }\n\n  return toObject;\n}\n\nexport function generationConfigToVertex(\n  fromObject: types.GenerationConfig,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModelSelectionConfig = common.getValueByPath(fromObject, [\n    'modelSelectionConfig',\n  ]);\n  if (fromModelSelectionConfig != null) {\n    common.setValueByPath(toObject, ['modelConfig'], fromModelSelectionConfig);\n  }\n\n  const fromAudioTimestamp = common.getValueByPath(fromObject, [\n    'audioTimestamp',\n  ]);\n  if (fromAudioTimestamp != null) {\n    common.setValueByPath(toObject, ['audioTimestamp'], fromAudioTimestamp);\n  }\n\n  const fromCandidateCount = common.getValueByPath(fromObject, [\n    'candidateCount',\n  ]);\n  if (fromCandidateCount != null) {\n    common.setValueByPath(toObject, ['candidateCount'], fromCandidateCount);\n  }\n\n  const fromEnableAffectiveDialog = common.getValueByPath(fromObject, [\n    'enableAffectiveDialog',\n  ]);\n  if (fromEnableAffectiveDialog != null) {\n    common.setValueByPath(\n      toObject,\n      ['enableAffectiveDialog'],\n      fromEnableAffectiveDialog,\n    );\n  }\n\n  const fromFrequencyPenalty = common.getValueByPath(fromObject, [\n    'frequencyPenalty',\n  ]);\n  if (fromFrequencyPenalty != null) {\n    common.setValueByPath(toObject, ['frequencyPenalty'], fromFrequencyPenalty);\n  }\n\n  const fromLogprobs = common.getValueByPath(fromObject, ['logprobs']);\n  if (fromLogprobs != null) {\n    common.setValueByPath(toObject, ['logprobs'], fromLogprobs);\n  }\n\n  const fromMaxOutputTokens = common.getValueByPath(fromObject, [\n    'maxOutputTokens',\n  ]);\n  if (fromMaxOutputTokens != null) {\n    common.setValueByPath(toObject, ['maxOutputTokens'], fromMaxOutputTokens);\n  }\n\n  const fromMediaResolution = common.getValueByPath(fromObject, [\n    'mediaResolution',\n  ]);\n  if (fromMediaResolution != null) {\n    common.setValueByPath(toObject, ['mediaResolution'], fromMediaResolution);\n  }\n\n  const fromPresencePenalty = common.getValueByPath(fromObject, [\n    'presencePenalty',\n  ]);\n  if (fromPresencePenalty != null) {\n    common.setValueByPath(toObject, ['presencePenalty'], fromPresencePenalty);\n  }\n\n  const fromResponseJsonSchema = common.getValueByPath(fromObject, [\n    'responseJsonSchema',\n  ]);\n  if (fromResponseJsonSchema != null) {\n    common.setValueByPath(\n      toObject,\n      ['responseJsonSchema'],\n      fromResponseJsonSchema,\n    );\n  }\n\n  const fromResponseLogprobs = common.getValueByPath(fromObject, [\n    'responseLogprobs',\n  ]);\n  if (fromResponseLogprobs != null) {\n    common.setValueByPath(toObject, ['responseLogprobs'], fromResponseLogprobs);\n  }\n\n  const fromResponseMimeType = common.getValueByPath(fromObject, [\n    'responseMimeType',\n  ]);\n  if (fromResponseMimeType != null) {\n    common.setValueByPath(toObject, ['responseMimeType'], fromResponseMimeType);\n  }\n\n  const fromResponseModalities = common.getValueByPath(fromObject, [\n    'responseModalities',\n  ]);\n  if (fromResponseModalities != null) {\n    common.setValueByPath(\n      toObject,\n      ['responseModalities'],\n      fromResponseModalities,\n    );\n  }\n\n  const fromResponseSchema = common.getValueByPath(fromObject, [\n    'responseSchema',\n  ]);\n  if (fromResponseSchema != null) {\n    common.setValueByPath(toObject, ['responseSchema'], fromResponseSchema);\n  }\n\n  const fromRoutingConfig = common.getValueByPath(fromObject, [\n    'routingConfig',\n  ]);\n  if (fromRoutingConfig != null) {\n    common.setValueByPath(toObject, ['routingConfig'], fromRoutingConfig);\n  }\n\n  const fromSeed = common.getValueByPath(fromObject, ['seed']);\n  if (fromSeed != null) {\n    common.setValueByPath(toObject, ['seed'], fromSeed);\n  }\n\n  const fromSpeechConfig = common.getValueByPath(fromObject, ['speechConfig']);\n  if (fromSpeechConfig != null) {\n    common.setValueByPath(\n      toObject,\n      ['speechConfig'],\n      speechConfigToVertex(fromSpeechConfig),\n    );\n  }\n\n  const fromStopSequences = common.getValueByPath(fromObject, [\n    'stopSequences',\n  ]);\n  if (fromStopSequences != null) {\n    common.setValueByPath(toObject, ['stopSequences'], fromStopSequences);\n  }\n\n  const fromTemperature = common.getValueByPath(fromObject, ['temperature']);\n  if (fromTemperature != null) {\n    common.setValueByPath(toObject, ['temperature'], fromTemperature);\n  }\n\n  const fromThinkingConfig = common.getValueByPath(fromObject, [\n    'thinkingConfig',\n  ]);\n  if (fromThinkingConfig != null) {\n    common.setValueByPath(toObject, ['thinkingConfig'], fromThinkingConfig);\n  }\n\n  const fromTopK = common.getValueByPath(fromObject, ['topK']);\n  if (fromTopK != null) {\n    common.setValueByPath(toObject, ['topK'], fromTopK);\n  }\n\n  const fromTopP = common.getValueByPath(fromObject, ['topP']);\n  if (fromTopP != null) {\n    common.setValueByPath(toObject, ['topP'], fromTopP);\n  }\n\n  if (\n    common.getValueByPath(fromObject, ['enableEnhancedCivicAnswers']) !==\n    undefined\n  ) {\n    throw new Error(\n      'enableEnhancedCivicAnswers parameter is not supported in Vertex AI.',\n    );\n  }\n\n  return toObject;\n}\n\nexport function googleMapsToMldev(\n  fromObject: types.GoogleMaps,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  if (common.getValueByPath(fromObject, ['authConfig']) !== undefined) {\n    throw new Error('authConfig parameter is not supported in Gemini API.');\n  }\n\n  const fromEnableWidget = common.getValueByPath(fromObject, ['enableWidget']);\n  if (fromEnableWidget != null) {\n    common.setValueByPath(toObject, ['enableWidget'], fromEnableWidget);\n  }\n\n  return toObject;\n}\n\nexport function googleSearchToMldev(\n  fromObject: types.GoogleSearch,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromTimeRangeFilter = common.getValueByPath(fromObject, [\n    'timeRangeFilter',\n  ]);\n  if (fromTimeRangeFilter != null) {\n    common.setValueByPath(toObject, ['timeRangeFilter'], fromTimeRangeFilter);\n  }\n\n  if (common.getValueByPath(fromObject, ['excludeDomains']) !== undefined) {\n    throw new Error('excludeDomains parameter is not supported in Gemini API.');\n  }\n\n  return toObject;\n}\n\nexport function liveClientContentToMldev(\n  fromObject: types.LiveClientContent,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromTurns = common.getValueByPath(fromObject, ['turns']);\n  if (fromTurns != null) {\n    let transformedList = fromTurns;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return contentToMldev(item);\n      });\n    }\n    common.setValueByPath(toObject, ['turns'], transformedList);\n  }\n\n  const fromTurnComplete = common.getValueByPath(fromObject, ['turnComplete']);\n  if (fromTurnComplete != null) {\n    common.setValueByPath(toObject, ['turnComplete'], fromTurnComplete);\n  }\n\n  return toObject;\n}\n\nexport function liveClientMessageToMldev(\n  fromObject: types.LiveClientMessage,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSetup = common.getValueByPath(fromObject, ['setup']);\n  if (fromSetup != null) {\n    common.setValueByPath(\n      toObject,\n      ['setup'],\n      liveClientSetupToMldev(fromSetup),\n    );\n  }\n\n  const fromClientContent = common.getValueByPath(fromObject, [\n    'clientContent',\n  ]);\n  if (fromClientContent != null) {\n    common.setValueByPath(\n      toObject,\n      ['clientContent'],\n      liveClientContentToMldev(fromClientContent),\n    );\n  }\n\n  const fromRealtimeInput = common.getValueByPath(fromObject, [\n    'realtimeInput',\n  ]);\n  if (fromRealtimeInput != null) {\n    common.setValueByPath(\n      toObject,\n      ['realtimeInput'],\n      liveClientRealtimeInputToMldev(fromRealtimeInput),\n    );\n  }\n\n  const fromToolResponse = common.getValueByPath(fromObject, ['toolResponse']);\n  if (fromToolResponse != null) {\n    common.setValueByPath(toObject, ['toolResponse'], fromToolResponse);\n  }\n\n  return toObject;\n}\n\nexport function liveClientMessageToVertex(\n  fromObject: types.LiveClientMessage,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSetup = common.getValueByPath(fromObject, ['setup']);\n  if (fromSetup != null) {\n    common.setValueByPath(\n      toObject,\n      ['setup'],\n      liveClientSetupToVertex(fromSetup),\n    );\n  }\n\n  const fromClientContent = common.getValueByPath(fromObject, [\n    'clientContent',\n  ]);\n  if (fromClientContent != null) {\n    common.setValueByPath(toObject, ['clientContent'], fromClientContent);\n  }\n\n  const fromRealtimeInput = common.getValueByPath(fromObject, [\n    'realtimeInput',\n  ]);\n  if (fromRealtimeInput != null) {\n    common.setValueByPath(\n      toObject,\n      ['realtimeInput'],\n      liveClientRealtimeInputToVertex(fromRealtimeInput),\n    );\n  }\n\n  const fromToolResponse = common.getValueByPath(fromObject, ['toolResponse']);\n  if (fromToolResponse != null) {\n    common.setValueByPath(toObject, ['toolResponse'], fromToolResponse);\n  }\n\n  return toObject;\n}\n\nexport function liveClientRealtimeInputToMldev(\n  fromObject: types.LiveClientRealtimeInput,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromMediaChunks = common.getValueByPath(fromObject, ['mediaChunks']);\n  if (fromMediaChunks != null) {\n    let transformedList = fromMediaChunks;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return blobToMldev(item);\n      });\n    }\n    common.setValueByPath(toObject, ['mediaChunks'], transformedList);\n  }\n\n  const fromAudio = common.getValueByPath(fromObject, ['audio']);\n  if (fromAudio != null) {\n    common.setValueByPath(toObject, ['audio'], blobToMldev(fromAudio));\n  }\n\n  const fromAudioStreamEnd = common.getValueByPath(fromObject, [\n    'audioStreamEnd',\n  ]);\n  if (fromAudioStreamEnd != null) {\n    common.setValueByPath(toObject, ['audioStreamEnd'], fromAudioStreamEnd);\n  }\n\n  const fromVideo = common.getValueByPath(fromObject, ['video']);\n  if (fromVideo != null) {\n    common.setValueByPath(toObject, ['video'], blobToMldev(fromVideo));\n  }\n\n  const fromText = common.getValueByPath(fromObject, ['text']);\n  if (fromText != null) {\n    common.setValueByPath(toObject, ['text'], fromText);\n  }\n\n  const fromActivityStart = common.getValueByPath(fromObject, [\n    'activityStart',\n  ]);\n  if (fromActivityStart != null) {\n    common.setValueByPath(toObject, ['activityStart'], fromActivityStart);\n  }\n\n  const fromActivityEnd = common.getValueByPath(fromObject, ['activityEnd']);\n  if (fromActivityEnd != null) {\n    common.setValueByPath(toObject, ['activityEnd'], fromActivityEnd);\n  }\n\n  return toObject;\n}\n\nexport function liveClientRealtimeInputToVertex(\n  fromObject: types.LiveClientRealtimeInput,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromMediaChunks = common.getValueByPath(fromObject, ['mediaChunks']);\n  if (fromMediaChunks != null) {\n    let transformedList = fromMediaChunks;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(toObject, ['mediaChunks'], transformedList);\n  }\n\n  const fromAudio = common.getValueByPath(fromObject, ['audio']);\n  if (fromAudio != null) {\n    common.setValueByPath(toObject, ['audio'], fromAudio);\n  }\n\n  if (common.getValueByPath(fromObject, ['audioStreamEnd']) !== undefined) {\n    throw new Error('audioStreamEnd parameter is not supported in Vertex AI.');\n  }\n\n  const fromVideo = common.getValueByPath(fromObject, ['video']);\n  if (fromVideo != null) {\n    common.setValueByPath(toObject, ['video'], fromVideo);\n  }\n\n  const fromText = common.getValueByPath(fromObject, ['text']);\n  if (fromText != null) {\n    common.setValueByPath(toObject, ['text'], fromText);\n  }\n\n  const fromActivityStart = common.getValueByPath(fromObject, [\n    'activityStart',\n  ]);\n  if (fromActivityStart != null) {\n    common.setValueByPath(toObject, ['activityStart'], fromActivityStart);\n  }\n\n  const fromActivityEnd = common.getValueByPath(fromObject, ['activityEnd']);\n  if (fromActivityEnd != null) {\n    common.setValueByPath(toObject, ['activityEnd'], fromActivityEnd);\n  }\n\n  return toObject;\n}\n\nexport function liveClientSetupToMldev(\n  fromObject: types.LiveClientSetup,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(toObject, ['model'], fromModel);\n  }\n\n  const fromGenerationConfig = common.getValueByPath(fromObject, [\n    'generationConfig',\n  ]);\n  if (fromGenerationConfig != null) {\n    common.setValueByPath(toObject, ['generationConfig'], fromGenerationConfig);\n  }\n\n  const fromSystemInstruction = common.getValueByPath(fromObject, [\n    'systemInstruction',\n  ]);\n  if (fromSystemInstruction != null) {\n    common.setValueByPath(\n      toObject,\n      ['systemInstruction'],\n      contentToMldev(t.tContent(fromSystemInstruction)),\n    );\n  }\n\n  const fromTools = common.getValueByPath(fromObject, ['tools']);\n  if (fromTools != null) {\n    let transformedList = t.tTools(fromTools);\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return toolToMldev(t.tTool(item));\n      });\n    }\n    common.setValueByPath(toObject, ['tools'], transformedList);\n  }\n\n  const fromRealtimeInputConfig = common.getValueByPath(fromObject, [\n    'realtimeInputConfig',\n  ]);\n  if (fromRealtimeInputConfig != null) {\n    common.setValueByPath(\n      toObject,\n      ['realtimeInputConfig'],\n      fromRealtimeInputConfig,\n    );\n  }\n\n  const fromSessionResumption = common.getValueByPath(fromObject, [\n    'sessionResumption',\n  ]);\n  if (fromSessionResumption != null) {\n    common.setValueByPath(\n      toObject,\n      ['sessionResumption'],\n      sessionResumptionConfigToMldev(fromSessionResumption),\n    );\n  }\n\n  const fromContextWindowCompression = common.getValueByPath(fromObject, [\n    'contextWindowCompression',\n  ]);\n  if (fromContextWindowCompression != null) {\n    common.setValueByPath(\n      toObject,\n      ['contextWindowCompression'],\n      fromContextWindowCompression,\n    );\n  }\n\n  const fromInputAudioTranscription = common.getValueByPath(fromObject, [\n    'inputAudioTranscription',\n  ]);\n  if (fromInputAudioTranscription != null) {\n    common.setValueByPath(\n      toObject,\n      ['inputAudioTranscription'],\n      fromInputAudioTranscription,\n    );\n  }\n\n  const fromOutputAudioTranscription = common.getValueByPath(fromObject, [\n    'outputAudioTranscription',\n  ]);\n  if (fromOutputAudioTranscription != null) {\n    common.setValueByPath(\n      toObject,\n      ['outputAudioTranscription'],\n      fromOutputAudioTranscription,\n    );\n  }\n\n  const fromProactivity = common.getValueByPath(fromObject, ['proactivity']);\n  if (fromProactivity != null) {\n    common.setValueByPath(toObject, ['proactivity'], fromProactivity);\n  }\n\n  return toObject;\n}\n\nexport function liveClientSetupToVertex(\n  fromObject: types.LiveClientSetup,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(toObject, ['model'], fromModel);\n  }\n\n  const fromGenerationConfig = common.getValueByPath(fromObject, [\n    'generationConfig',\n  ]);\n  if (fromGenerationConfig != null) {\n    common.setValueByPath(\n      toObject,\n      ['generationConfig'],\n      generationConfigToVertex(fromGenerationConfig),\n    );\n  }\n\n  const fromSystemInstruction = common.getValueByPath(fromObject, [\n    'systemInstruction',\n  ]);\n  if (fromSystemInstruction != null) {\n    common.setValueByPath(\n      toObject,\n      ['systemInstruction'],\n      t.tContent(fromSystemInstruction),\n    );\n  }\n\n  const fromTools = common.getValueByPath(fromObject, ['tools']);\n  if (fromTools != null) {\n    let transformedList = t.tTools(fromTools);\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return toolToVertex(t.tTool(item));\n      });\n    }\n    common.setValueByPath(toObject, ['tools'], transformedList);\n  }\n\n  const fromRealtimeInputConfig = common.getValueByPath(fromObject, [\n    'realtimeInputConfig',\n  ]);\n  if (fromRealtimeInputConfig != null) {\n    common.setValueByPath(\n      toObject,\n      ['realtimeInputConfig'],\n      fromRealtimeInputConfig,\n    );\n  }\n\n  const fromSessionResumption = common.getValueByPath(fromObject, [\n    'sessionResumption',\n  ]);\n  if (fromSessionResumption != null) {\n    common.setValueByPath(\n      toObject,\n      ['sessionResumption'],\n      fromSessionResumption,\n    );\n  }\n\n  const fromContextWindowCompression = common.getValueByPath(fromObject, [\n    'contextWindowCompression',\n  ]);\n  if (fromContextWindowCompression != null) {\n    common.setValueByPath(\n      toObject,\n      ['contextWindowCompression'],\n      fromContextWindowCompression,\n    );\n  }\n\n  const fromInputAudioTranscription = common.getValueByPath(fromObject, [\n    'inputAudioTranscription',\n  ]);\n  if (fromInputAudioTranscription != null) {\n    common.setValueByPath(\n      toObject,\n      ['inputAudioTranscription'],\n      fromInputAudioTranscription,\n    );\n  }\n\n  const fromOutputAudioTranscription = common.getValueByPath(fromObject, [\n    'outputAudioTranscription',\n  ]);\n  if (fromOutputAudioTranscription != null) {\n    common.setValueByPath(\n      toObject,\n      ['outputAudioTranscription'],\n      fromOutputAudioTranscription,\n    );\n  }\n\n  const fromProactivity = common.getValueByPath(fromObject, ['proactivity']);\n  if (fromProactivity != null) {\n    common.setValueByPath(toObject, ['proactivity'], fromProactivity);\n  }\n\n  return toObject;\n}\n\nexport function liveConnectConfigToMldev(\n  fromObject: types.LiveConnectConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromGenerationConfig = common.getValueByPath(fromObject, [\n    'generationConfig',\n  ]);\n  if (parentObject !== undefined && fromGenerationConfig != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig'],\n      fromGenerationConfig,\n    );\n  }\n\n  const fromResponseModalities = common.getValueByPath(fromObject, [\n    'responseModalities',\n  ]);\n  if (parentObject !== undefined && fromResponseModalities != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig', 'responseModalities'],\n      fromResponseModalities,\n    );\n  }\n\n  const fromTemperature = common.getValueByPath(fromObject, ['temperature']);\n  if (parentObject !== undefined && fromTemperature != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig', 'temperature'],\n      fromTemperature,\n    );\n  }\n\n  const fromTopP = common.getValueByPath(fromObject, ['topP']);\n  if (parentObject !== undefined && fromTopP != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig', 'topP'],\n      fromTopP,\n    );\n  }\n\n  const fromTopK = common.getValueByPath(fromObject, ['topK']);\n  if (parentObject !== undefined && fromTopK != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig', 'topK'],\n      fromTopK,\n    );\n  }\n\n  const fromMaxOutputTokens = common.getValueByPath(fromObject, [\n    'maxOutputTokens',\n  ]);\n  if (parentObject !== undefined && fromMaxOutputTokens != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig', 'maxOutputTokens'],\n      fromMaxOutputTokens,\n    );\n  }\n\n  const fromMediaResolution = common.getValueByPath(fromObject, [\n    'mediaResolution',\n  ]);\n  if (parentObject !== undefined && fromMediaResolution != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig', 'mediaResolution'],\n      fromMediaResolution,\n    );\n  }\n\n  const fromSeed = common.getValueByPath(fromObject, ['seed']);\n  if (parentObject !== undefined && fromSeed != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig', 'seed'],\n      fromSeed,\n    );\n  }\n\n  const fromSpeechConfig = common.getValueByPath(fromObject, ['speechConfig']);\n  if (parentObject !== undefined && fromSpeechConfig != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig', 'speechConfig'],\n      t.tLiveSpeechConfig(fromSpeechConfig),\n    );\n  }\n\n  const fromThinkingConfig = common.getValueByPath(fromObject, [\n    'thinkingConfig',\n  ]);\n  if (parentObject !== undefined && fromThinkingConfig != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig', 'thinkingConfig'],\n      fromThinkingConfig,\n    );\n  }\n\n  const fromEnableAffectiveDialog = common.getValueByPath(fromObject, [\n    'enableAffectiveDialog',\n  ]);\n  if (parentObject !== undefined && fromEnableAffectiveDialog != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig', 'enableAffectiveDialog'],\n      fromEnableAffectiveDialog,\n    );\n  }\n\n  const fromSystemInstruction = common.getValueByPath(fromObject, [\n    'systemInstruction',\n  ]);\n  if (parentObject !== undefined && fromSystemInstruction != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'systemInstruction'],\n      contentToMldev(t.tContent(fromSystemInstruction)),\n    );\n  }\n\n  const fromTools = common.getValueByPath(fromObject, ['tools']);\n  if (parentObject !== undefined && fromTools != null) {\n    let transformedList = t.tTools(fromTools);\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return toolToMldev(t.tTool(item));\n      });\n    }\n    common.setValueByPath(parentObject, ['setup', 'tools'], transformedList);\n  }\n\n  const fromSessionResumption = common.getValueByPath(fromObject, [\n    'sessionResumption',\n  ]);\n  if (parentObject !== undefined && fromSessionResumption != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'sessionResumption'],\n      sessionResumptionConfigToMldev(fromSessionResumption),\n    );\n  }\n\n  const fromInputAudioTranscription = common.getValueByPath(fromObject, [\n    'inputAudioTranscription',\n  ]);\n  if (parentObject !== undefined && fromInputAudioTranscription != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'inputAudioTranscription'],\n      fromInputAudioTranscription,\n    );\n  }\n\n  const fromOutputAudioTranscription = common.getValueByPath(fromObject, [\n    'outputAudioTranscription',\n  ]);\n  if (parentObject !== undefined && fromOutputAudioTranscription != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'outputAudioTranscription'],\n      fromOutputAudioTranscription,\n    );\n  }\n\n  const fromRealtimeInputConfig = common.getValueByPath(fromObject, [\n    'realtimeInputConfig',\n  ]);\n  if (parentObject !== undefined && fromRealtimeInputConfig != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'realtimeInputConfig'],\n      fromRealtimeInputConfig,\n    );\n  }\n\n  const fromContextWindowCompression = common.getValueByPath(fromObject, [\n    'contextWindowCompression',\n  ]);\n  if (parentObject !== undefined && fromContextWindowCompression != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'contextWindowCompression'],\n      fromContextWindowCompression,\n    );\n  }\n\n  const fromProactivity = common.getValueByPath(fromObject, ['proactivity']);\n  if (parentObject !== undefined && fromProactivity != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'proactivity'],\n      fromProactivity,\n    );\n  }\n\n  return toObject;\n}\n\nexport function liveConnectConfigToVertex(\n  fromObject: types.LiveConnectConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromGenerationConfig = common.getValueByPath(fromObject, [\n    'generationConfig',\n  ]);\n  if (parentObject !== undefined && fromGenerationConfig != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig'],\n      generationConfigToVertex(fromGenerationConfig),\n    );\n  }\n\n  const fromResponseModalities = common.getValueByPath(fromObject, [\n    'responseModalities',\n  ]);\n  if (parentObject !== undefined && fromResponseModalities != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig', 'responseModalities'],\n      fromResponseModalities,\n    );\n  }\n\n  const fromTemperature = common.getValueByPath(fromObject, ['temperature']);\n  if (parentObject !== undefined && fromTemperature != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig', 'temperature'],\n      fromTemperature,\n    );\n  }\n\n  const fromTopP = common.getValueByPath(fromObject, ['topP']);\n  if (parentObject !== undefined && fromTopP != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig', 'topP'],\n      fromTopP,\n    );\n  }\n\n  const fromTopK = common.getValueByPath(fromObject, ['topK']);\n  if (parentObject !== undefined && fromTopK != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig', 'topK'],\n      fromTopK,\n    );\n  }\n\n  const fromMaxOutputTokens = common.getValueByPath(fromObject, [\n    'maxOutputTokens',\n  ]);\n  if (parentObject !== undefined && fromMaxOutputTokens != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig', 'maxOutputTokens'],\n      fromMaxOutputTokens,\n    );\n  }\n\n  const fromMediaResolution = common.getValueByPath(fromObject, [\n    'mediaResolution',\n  ]);\n  if (parentObject !== undefined && fromMediaResolution != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig', 'mediaResolution'],\n      fromMediaResolution,\n    );\n  }\n\n  const fromSeed = common.getValueByPath(fromObject, ['seed']);\n  if (parentObject !== undefined && fromSeed != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig', 'seed'],\n      fromSeed,\n    );\n  }\n\n  const fromSpeechConfig = common.getValueByPath(fromObject, ['speechConfig']);\n  if (parentObject !== undefined && fromSpeechConfig != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig', 'speechConfig'],\n      speechConfigToVertex(t.tLiveSpeechConfig(fromSpeechConfig)),\n    );\n  }\n\n  const fromThinkingConfig = common.getValueByPath(fromObject, [\n    'thinkingConfig',\n  ]);\n  if (parentObject !== undefined && fromThinkingConfig != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig', 'thinkingConfig'],\n      fromThinkingConfig,\n    );\n  }\n\n  const fromEnableAffectiveDialog = common.getValueByPath(fromObject, [\n    'enableAffectiveDialog',\n  ]);\n  if (parentObject !== undefined && fromEnableAffectiveDialog != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig', 'enableAffectiveDialog'],\n      fromEnableAffectiveDialog,\n    );\n  }\n\n  const fromSystemInstruction = common.getValueByPath(fromObject, [\n    'systemInstruction',\n  ]);\n  if (parentObject !== undefined && fromSystemInstruction != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'systemInstruction'],\n      t.tContent(fromSystemInstruction),\n    );\n  }\n\n  const fromTools = common.getValueByPath(fromObject, ['tools']);\n  if (parentObject !== undefined && fromTools != null) {\n    let transformedList = t.tTools(fromTools);\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return toolToVertex(t.tTool(item));\n      });\n    }\n    common.setValueByPath(parentObject, ['setup', 'tools'], transformedList);\n  }\n\n  const fromSessionResumption = common.getValueByPath(fromObject, [\n    'sessionResumption',\n  ]);\n  if (parentObject !== undefined && fromSessionResumption != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'sessionResumption'],\n      fromSessionResumption,\n    );\n  }\n\n  const fromInputAudioTranscription = common.getValueByPath(fromObject, [\n    'inputAudioTranscription',\n  ]);\n  if (parentObject !== undefined && fromInputAudioTranscription != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'inputAudioTranscription'],\n      fromInputAudioTranscription,\n    );\n  }\n\n  const fromOutputAudioTranscription = common.getValueByPath(fromObject, [\n    'outputAudioTranscription',\n  ]);\n  if (parentObject !== undefined && fromOutputAudioTranscription != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'outputAudioTranscription'],\n      fromOutputAudioTranscription,\n    );\n  }\n\n  const fromRealtimeInputConfig = common.getValueByPath(fromObject, [\n    'realtimeInputConfig',\n  ]);\n  if (parentObject !== undefined && fromRealtimeInputConfig != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'realtimeInputConfig'],\n      fromRealtimeInputConfig,\n    );\n  }\n\n  const fromContextWindowCompression = common.getValueByPath(fromObject, [\n    'contextWindowCompression',\n  ]);\n  if (parentObject !== undefined && fromContextWindowCompression != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'contextWindowCompression'],\n      fromContextWindowCompression,\n    );\n  }\n\n  const fromProactivity = common.getValueByPath(fromObject, ['proactivity']);\n  if (parentObject !== undefined && fromProactivity != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'proactivity'],\n      fromProactivity,\n    );\n  }\n\n  return toObject;\n}\n\nexport function liveConnectParametersToMldev(\n  apiClient: ApiClient,\n  fromObject: types.LiveConnectParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(\n      toObject,\n      ['setup', 'model'],\n      t.tModel(apiClient, fromModel),\n    );\n  }\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    common.setValueByPath(\n      toObject,\n      ['config'],\n      liveConnectConfigToMldev(fromConfig, toObject),\n    );\n  }\n\n  return toObject;\n}\n\nexport function liveConnectParametersToVertex(\n  apiClient: ApiClient,\n  fromObject: types.LiveConnectParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(\n      toObject,\n      ['setup', 'model'],\n      t.tModel(apiClient, fromModel),\n    );\n  }\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    common.setValueByPath(\n      toObject,\n      ['config'],\n      liveConnectConfigToVertex(fromConfig, toObject),\n    );\n  }\n\n  return toObject;\n}\n\nexport function liveMusicClientMessageToVertex(\n  fromObject: types.LiveMusicClientMessage,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  if (common.getValueByPath(fromObject, ['setup']) !== undefined) {\n    throw new Error('setup parameter is not supported in Vertex AI.');\n  }\n\n  if (common.getValueByPath(fromObject, ['clientContent']) !== undefined) {\n    throw new Error('clientContent parameter is not supported in Vertex AI.');\n  }\n\n  if (\n    common.getValueByPath(fromObject, ['musicGenerationConfig']) !== undefined\n  ) {\n    throw new Error(\n      'musicGenerationConfig parameter is not supported in Vertex AI.',\n    );\n  }\n\n  if (common.getValueByPath(fromObject, ['playbackControl']) !== undefined) {\n    throw new Error('playbackControl parameter is not supported in Vertex AI.');\n  }\n\n  return toObject;\n}\n\nexport function liveMusicConnectParametersToMldev(\n  fromObject: types.LiveMusicConnectParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(toObject, ['setup', 'model'], fromModel);\n  }\n\n  const fromCallbacks = common.getValueByPath(fromObject, ['callbacks']);\n  if (fromCallbacks != null) {\n    common.setValueByPath(toObject, ['callbacks'], fromCallbacks);\n  }\n\n  return toObject;\n}\n\nexport function liveMusicConnectParametersToVertex(\n  fromObject: types.LiveMusicConnectParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  if (common.getValueByPath(fromObject, ['model']) !== undefined) {\n    throw new Error('model parameter is not supported in Vertex AI.');\n  }\n\n  if (common.getValueByPath(fromObject, ['callbacks']) !== undefined) {\n    throw new Error('callbacks parameter is not supported in Vertex AI.');\n  }\n\n  return toObject;\n}\n\nexport function liveMusicSetConfigParametersToMldev(\n  fromObject: types.LiveMusicSetConfigParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromMusicGenerationConfig = common.getValueByPath(fromObject, [\n    'musicGenerationConfig',\n  ]);\n  if (fromMusicGenerationConfig != null) {\n    common.setValueByPath(\n      toObject,\n      ['musicGenerationConfig'],\n      fromMusicGenerationConfig,\n    );\n  }\n\n  return toObject;\n}\n\nexport function liveMusicSetConfigParametersToVertex(\n  fromObject: types.LiveMusicSetConfigParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  if (\n    common.getValueByPath(fromObject, ['musicGenerationConfig']) !== undefined\n  ) {\n    throw new Error(\n      'musicGenerationConfig parameter is not supported in Vertex AI.',\n    );\n  }\n\n  return toObject;\n}\n\nexport function liveMusicSetWeightedPromptsParametersToMldev(\n  fromObject: types.LiveMusicSetWeightedPromptsParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromWeightedPrompts = common.getValueByPath(fromObject, [\n    'weightedPrompts',\n  ]);\n  if (fromWeightedPrompts != null) {\n    let transformedList = fromWeightedPrompts;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(toObject, ['weightedPrompts'], transformedList);\n  }\n\n  return toObject;\n}\n\nexport function liveMusicSetWeightedPromptsParametersToVertex(\n  fromObject: types.LiveMusicSetWeightedPromptsParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  if (common.getValueByPath(fromObject, ['weightedPrompts']) !== undefined) {\n    throw new Error('weightedPrompts parameter is not supported in Vertex AI.');\n  }\n\n  return toObject;\n}\n\nexport function liveSendRealtimeInputParametersToMldev(\n  fromObject: types.LiveSendRealtimeInputParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromMedia = common.getValueByPath(fromObject, ['media']);\n  if (fromMedia != null) {\n    let transformedList = t.tBlobs(fromMedia);\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return blobToMldev(item);\n      });\n    }\n    common.setValueByPath(toObject, ['mediaChunks'], transformedList);\n  }\n\n  const fromAudio = common.getValueByPath(fromObject, ['audio']);\n  if (fromAudio != null) {\n    common.setValueByPath(\n      toObject,\n      ['audio'],\n      blobToMldev(t.tAudioBlob(fromAudio)),\n    );\n  }\n\n  const fromAudioStreamEnd = common.getValueByPath(fromObject, [\n    'audioStreamEnd',\n  ]);\n  if (fromAudioStreamEnd != null) {\n    common.setValueByPath(toObject, ['audioStreamEnd'], fromAudioStreamEnd);\n  }\n\n  const fromVideo = common.getValueByPath(fromObject, ['video']);\n  if (fromVideo != null) {\n    common.setValueByPath(\n      toObject,\n      ['video'],\n      blobToMldev(t.tImageBlob(fromVideo)),\n    );\n  }\n\n  const fromText = common.getValueByPath(fromObject, ['text']);\n  if (fromText != null) {\n    common.setValueByPath(toObject, ['text'], fromText);\n  }\n\n  const fromActivityStart = common.getValueByPath(fromObject, [\n    'activityStart',\n  ]);\n  if (fromActivityStart != null) {\n    common.setValueByPath(toObject, ['activityStart'], fromActivityStart);\n  }\n\n  const fromActivityEnd = common.getValueByPath(fromObject, ['activityEnd']);\n  if (fromActivityEnd != null) {\n    common.setValueByPath(toObject, ['activityEnd'], fromActivityEnd);\n  }\n\n  return toObject;\n}\n\nexport function liveSendRealtimeInputParametersToVertex(\n  fromObject: types.LiveSendRealtimeInputParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromMedia = common.getValueByPath(fromObject, ['media']);\n  if (fromMedia != null) {\n    let transformedList = t.tBlobs(fromMedia);\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(toObject, ['mediaChunks'], transformedList);\n  }\n\n  const fromAudio = common.getValueByPath(fromObject, ['audio']);\n  if (fromAudio != null) {\n    common.setValueByPath(toObject, ['audio'], t.tAudioBlob(fromAudio));\n  }\n\n  const fromAudioStreamEnd = common.getValueByPath(fromObject, [\n    'audioStreamEnd',\n  ]);\n  if (fromAudioStreamEnd != null) {\n    common.setValueByPath(toObject, ['audioStreamEnd'], fromAudioStreamEnd);\n  }\n\n  const fromVideo = common.getValueByPath(fromObject, ['video']);\n  if (fromVideo != null) {\n    common.setValueByPath(toObject, ['video'], t.tImageBlob(fromVideo));\n  }\n\n  const fromText = common.getValueByPath(fromObject, ['text']);\n  if (fromText != null) {\n    common.setValueByPath(toObject, ['text'], fromText);\n  }\n\n  const fromActivityStart = common.getValueByPath(fromObject, [\n    'activityStart',\n  ]);\n  if (fromActivityStart != null) {\n    common.setValueByPath(toObject, ['activityStart'], fromActivityStart);\n  }\n\n  const fromActivityEnd = common.getValueByPath(fromObject, ['activityEnd']);\n  if (fromActivityEnd != null) {\n    common.setValueByPath(toObject, ['activityEnd'], fromActivityEnd);\n  }\n\n  return toObject;\n}\n\nexport function liveServerMessageFromVertex(\n  fromObject: types.LiveServerMessage,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSetupComplete = common.getValueByPath(fromObject, [\n    'setupComplete',\n  ]);\n  if (fromSetupComplete != null) {\n    common.setValueByPath(toObject, ['setupComplete'], fromSetupComplete);\n  }\n\n  const fromServerContent = common.getValueByPath(fromObject, [\n    'serverContent',\n  ]);\n  if (fromServerContent != null) {\n    common.setValueByPath(toObject, ['serverContent'], fromServerContent);\n  }\n\n  const fromToolCall = common.getValueByPath(fromObject, ['toolCall']);\n  if (fromToolCall != null) {\n    common.setValueByPath(toObject, ['toolCall'], fromToolCall);\n  }\n\n  const fromToolCallCancellation = common.getValueByPath(fromObject, [\n    'toolCallCancellation',\n  ]);\n  if (fromToolCallCancellation != null) {\n    common.setValueByPath(\n      toObject,\n      ['toolCallCancellation'],\n      fromToolCallCancellation,\n    );\n  }\n\n  const fromUsageMetadata = common.getValueByPath(fromObject, [\n    'usageMetadata',\n  ]);\n  if (fromUsageMetadata != null) {\n    common.setValueByPath(\n      toObject,\n      ['usageMetadata'],\n      usageMetadataFromVertex(fromUsageMetadata),\n    );\n  }\n\n  const fromGoAway = common.getValueByPath(fromObject, ['goAway']);\n  if (fromGoAway != null) {\n    common.setValueByPath(toObject, ['goAway'], fromGoAway);\n  }\n\n  const fromSessionResumptionUpdate = common.getValueByPath(fromObject, [\n    'sessionResumptionUpdate',\n  ]);\n  if (fromSessionResumptionUpdate != null) {\n    common.setValueByPath(\n      toObject,\n      ['sessionResumptionUpdate'],\n      fromSessionResumptionUpdate,\n    );\n  }\n\n  return toObject;\n}\n\nexport function partToMldev(fromObject: types.Part): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromVideoMetadata = common.getValueByPath(fromObject, [\n    'videoMetadata',\n  ]);\n  if (fromVideoMetadata != null) {\n    common.setValueByPath(toObject, ['videoMetadata'], fromVideoMetadata);\n  }\n\n  const fromThought = common.getValueByPath(fromObject, ['thought']);\n  if (fromThought != null) {\n    common.setValueByPath(toObject, ['thought'], fromThought);\n  }\n\n  const fromInlineData = common.getValueByPath(fromObject, ['inlineData']);\n  if (fromInlineData != null) {\n    common.setValueByPath(\n      toObject,\n      ['inlineData'],\n      blobToMldev(fromInlineData),\n    );\n  }\n\n  const fromFileData = common.getValueByPath(fromObject, ['fileData']);\n  if (fromFileData != null) {\n    common.setValueByPath(\n      toObject,\n      ['fileData'],\n      fileDataToMldev(fromFileData),\n    );\n  }\n\n  const fromThoughtSignature = common.getValueByPath(fromObject, [\n    'thoughtSignature',\n  ]);\n  if (fromThoughtSignature != null) {\n    common.setValueByPath(toObject, ['thoughtSignature'], fromThoughtSignature);\n  }\n\n  const fromFunctionCall = common.getValueByPath(fromObject, ['functionCall']);\n  if (fromFunctionCall != null) {\n    common.setValueByPath(toObject, ['functionCall'], fromFunctionCall);\n  }\n\n  const fromCodeExecutionResult = common.getValueByPath(fromObject, [\n    'codeExecutionResult',\n  ]);\n  if (fromCodeExecutionResult != null) {\n    common.setValueByPath(\n      toObject,\n      ['codeExecutionResult'],\n      fromCodeExecutionResult,\n    );\n  }\n\n  const fromExecutableCode = common.getValueByPath(fromObject, [\n    'executableCode',\n  ]);\n  if (fromExecutableCode != null) {\n    common.setValueByPath(toObject, ['executableCode'], fromExecutableCode);\n  }\n\n  const fromFunctionResponse = common.getValueByPath(fromObject, [\n    'functionResponse',\n  ]);\n  if (fromFunctionResponse != null) {\n    common.setValueByPath(toObject, ['functionResponse'], fromFunctionResponse);\n  }\n\n  const fromText = common.getValueByPath(fromObject, ['text']);\n  if (fromText != null) {\n    common.setValueByPath(toObject, ['text'], fromText);\n  }\n\n  return toObject;\n}\n\nexport function sessionResumptionConfigToMldev(\n  fromObject: types.SessionResumptionConfig,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromHandle = common.getValueByPath(fromObject, ['handle']);\n  if (fromHandle != null) {\n    common.setValueByPath(toObject, ['handle'], fromHandle);\n  }\n\n  if (common.getValueByPath(fromObject, ['transparent']) !== undefined) {\n    throw new Error('transparent parameter is not supported in Gemini API.');\n  }\n\n  return toObject;\n}\n\nexport function speechConfigToVertex(\n  fromObject: types.SpeechConfig,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromVoiceConfig = common.getValueByPath(fromObject, ['voiceConfig']);\n  if (fromVoiceConfig != null) {\n    common.setValueByPath(toObject, ['voiceConfig'], fromVoiceConfig);\n  }\n\n  if (\n    common.getValueByPath(fromObject, ['multiSpeakerVoiceConfig']) !== undefined\n  ) {\n    throw new Error(\n      'multiSpeakerVoiceConfig parameter is not supported in Vertex AI.',\n    );\n  }\n\n  const fromLanguageCode = common.getValueByPath(fromObject, ['languageCode']);\n  if (fromLanguageCode != null) {\n    common.setValueByPath(toObject, ['languageCode'], fromLanguageCode);\n  }\n\n  return toObject;\n}\n\nexport function toolToMldev(fromObject: types.Tool): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromFunctionDeclarations = common.getValueByPath(fromObject, [\n    'functionDeclarations',\n  ]);\n  if (fromFunctionDeclarations != null) {\n    let transformedList = fromFunctionDeclarations;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(toObject, ['functionDeclarations'], transformedList);\n  }\n\n  if (common.getValueByPath(fromObject, ['retrieval']) !== undefined) {\n    throw new Error('retrieval parameter is not supported in Gemini API.');\n  }\n\n  const fromGoogleSearch = common.getValueByPath(fromObject, ['googleSearch']);\n  if (fromGoogleSearch != null) {\n    common.setValueByPath(\n      toObject,\n      ['googleSearch'],\n      googleSearchToMldev(fromGoogleSearch),\n    );\n  }\n\n  const fromGoogleSearchRetrieval = common.getValueByPath(fromObject, [\n    'googleSearchRetrieval',\n  ]);\n  if (fromGoogleSearchRetrieval != null) {\n    common.setValueByPath(\n      toObject,\n      ['googleSearchRetrieval'],\n      fromGoogleSearchRetrieval,\n    );\n  }\n\n  if (\n    common.getValueByPath(fromObject, ['enterpriseWebSearch']) !== undefined\n  ) {\n    throw new Error(\n      'enterpriseWebSearch parameter is not supported in Gemini API.',\n    );\n  }\n\n  const fromGoogleMaps = common.getValueByPath(fromObject, ['googleMaps']);\n  if (fromGoogleMaps != null) {\n    common.setValueByPath(\n      toObject,\n      ['googleMaps'],\n      googleMapsToMldev(fromGoogleMaps),\n    );\n  }\n\n  const fromUrlContext = common.getValueByPath(fromObject, ['urlContext']);\n  if (fromUrlContext != null) {\n    common.setValueByPath(toObject, ['urlContext'], fromUrlContext);\n  }\n\n  const fromComputerUse = common.getValueByPath(fromObject, ['computerUse']);\n  if (fromComputerUse != null) {\n    common.setValueByPath(toObject, ['computerUse'], fromComputerUse);\n  }\n\n  const fromCodeExecution = common.getValueByPath(fromObject, [\n    'codeExecution',\n  ]);\n  if (fromCodeExecution != null) {\n    common.setValueByPath(toObject, ['codeExecution'], fromCodeExecution);\n  }\n\n  return toObject;\n}\n\nexport function toolToVertex(fromObject: types.Tool): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromFunctionDeclarations = common.getValueByPath(fromObject, [\n    'functionDeclarations',\n  ]);\n  if (fromFunctionDeclarations != null) {\n    let transformedList = fromFunctionDeclarations;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return functionDeclarationToVertex(item);\n      });\n    }\n    common.setValueByPath(toObject, ['functionDeclarations'], transformedList);\n  }\n\n  const fromRetrieval = common.getValueByPath(fromObject, ['retrieval']);\n  if (fromRetrieval != null) {\n    common.setValueByPath(toObject, ['retrieval'], fromRetrieval);\n  }\n\n  const fromGoogleSearch = common.getValueByPath(fromObject, ['googleSearch']);\n  if (fromGoogleSearch != null) {\n    common.setValueByPath(toObject, ['googleSearch'], fromGoogleSearch);\n  }\n\n  const fromGoogleSearchRetrieval = common.getValueByPath(fromObject, [\n    'googleSearchRetrieval',\n  ]);\n  if (fromGoogleSearchRetrieval != null) {\n    common.setValueByPath(\n      toObject,\n      ['googleSearchRetrieval'],\n      fromGoogleSearchRetrieval,\n    );\n  }\n\n  const fromEnterpriseWebSearch = common.getValueByPath(fromObject, [\n    'enterpriseWebSearch',\n  ]);\n  if (fromEnterpriseWebSearch != null) {\n    common.setValueByPath(\n      toObject,\n      ['enterpriseWebSearch'],\n      fromEnterpriseWebSearch,\n    );\n  }\n\n  const fromGoogleMaps = common.getValueByPath(fromObject, ['googleMaps']);\n  if (fromGoogleMaps != null) {\n    common.setValueByPath(toObject, ['googleMaps'], fromGoogleMaps);\n  }\n\n  const fromUrlContext = common.getValueByPath(fromObject, ['urlContext']);\n  if (fromUrlContext != null) {\n    common.setValueByPath(toObject, ['urlContext'], fromUrlContext);\n  }\n\n  const fromComputerUse = common.getValueByPath(fromObject, ['computerUse']);\n  if (fromComputerUse != null) {\n    common.setValueByPath(toObject, ['computerUse'], fromComputerUse);\n  }\n\n  const fromCodeExecution = common.getValueByPath(fromObject, [\n    'codeExecution',\n  ]);\n  if (fromCodeExecution != null) {\n    common.setValueByPath(toObject, ['codeExecution'], fromCodeExecution);\n  }\n\n  return toObject;\n}\n\nexport function usageMetadataFromVertex(\n  fromObject: types.UsageMetadata,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromPromptTokenCount = common.getValueByPath(fromObject, [\n    'promptTokenCount',\n  ]);\n  if (fromPromptTokenCount != null) {\n    common.setValueByPath(toObject, ['promptTokenCount'], fromPromptTokenCount);\n  }\n\n  const fromCachedContentTokenCount = common.getValueByPath(fromObject, [\n    'cachedContentTokenCount',\n  ]);\n  if (fromCachedContentTokenCount != null) {\n    common.setValueByPath(\n      toObject,\n      ['cachedContentTokenCount'],\n      fromCachedContentTokenCount,\n    );\n  }\n\n  const fromResponseTokenCount = common.getValueByPath(fromObject, [\n    'candidatesTokenCount',\n  ]);\n  if (fromResponseTokenCount != null) {\n    common.setValueByPath(\n      toObject,\n      ['responseTokenCount'],\n      fromResponseTokenCount,\n    );\n  }\n\n  const fromToolUsePromptTokenCount = common.getValueByPath(fromObject, [\n    'toolUsePromptTokenCount',\n  ]);\n  if (fromToolUsePromptTokenCount != null) {\n    common.setValueByPath(\n      toObject,\n      ['toolUsePromptTokenCount'],\n      fromToolUsePromptTokenCount,\n    );\n  }\n\n  const fromThoughtsTokenCount = common.getValueByPath(fromObject, [\n    'thoughtsTokenCount',\n  ]);\n  if (fromThoughtsTokenCount != null) {\n    common.setValueByPath(\n      toObject,\n      ['thoughtsTokenCount'],\n      fromThoughtsTokenCount,\n    );\n  }\n\n  const fromTotalTokenCount = common.getValueByPath(fromObject, [\n    'totalTokenCount',\n  ]);\n  if (fromTotalTokenCount != null) {\n    common.setValueByPath(toObject, ['totalTokenCount'], fromTotalTokenCount);\n  }\n\n  const fromPromptTokensDetails = common.getValueByPath(fromObject, [\n    'promptTokensDetails',\n  ]);\n  if (fromPromptTokensDetails != null) {\n    let transformedList = fromPromptTokensDetails;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(toObject, ['promptTokensDetails'], transformedList);\n  }\n\n  const fromCacheTokensDetails = common.getValueByPath(fromObject, [\n    'cacheTokensDetails',\n  ]);\n  if (fromCacheTokensDetails != null) {\n    let transformedList = fromCacheTokensDetails;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(toObject, ['cacheTokensDetails'], transformedList);\n  }\n\n  const fromResponseTokensDetails = common.getValueByPath(fromObject, [\n    'candidatesTokensDetails',\n  ]);\n  if (fromResponseTokensDetails != null) {\n    let transformedList = fromResponseTokensDetails;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(toObject, ['responseTokensDetails'], transformedList);\n  }\n\n  const fromToolUsePromptTokensDetails = common.getValueByPath(fromObject, [\n    'toolUsePromptTokensDetails',\n  ]);\n  if (fromToolUsePromptTokensDetails != null) {\n    let transformedList = fromToolUsePromptTokensDetails;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(\n      toObject,\n      ['toolUsePromptTokensDetails'],\n      transformedList,\n    );\n  }\n\n  const fromTrafficType = common.getValueByPath(fromObject, ['trafficType']);\n  if (fromTrafficType != null) {\n    common.setValueByPath(toObject, ['trafficType'], fromTrafficType);\n  }\n\n  return toObject;\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\n// Code generated by the Google Gen AI SDK generator DO NOT EDIT.\n\nimport {ApiClient} from '../_api_client.js';\nimport * as common from '../_common.js';\nimport type * as _internal_types from '../_internal_types.js';\nimport * as t from '../_transformers.js';\nimport type * as types from '../types.js';\n\nexport function blobToMldev(fromObject: types.Blob): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  if (common.getValueByPath(fromObject, ['displayName']) !== undefined) {\n    throw new Error('displayName parameter is not supported in Gemini API.');\n  }\n\n  const fromData = common.getValueByPath(fromObject, ['data']);\n  if (fromData != null) {\n    common.setValueByPath(toObject, ['data'], fromData);\n  }\n\n  const fromMimeType = common.getValueByPath(fromObject, ['mimeType']);\n  if (fromMimeType != null) {\n    common.setValueByPath(toObject, ['mimeType'], fromMimeType);\n  }\n\n  return toObject;\n}\n\nexport function candidateFromMldev(\n  fromObject: types.Candidate,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromContent = common.getValueByPath(fromObject, ['content']);\n  if (fromContent != null) {\n    common.setValueByPath(toObject, ['content'], fromContent);\n  }\n\n  const fromCitationMetadata = common.getValueByPath(fromObject, [\n    'citationMetadata',\n  ]);\n  if (fromCitationMetadata != null) {\n    common.setValueByPath(\n      toObject,\n      ['citationMetadata'],\n      citationMetadataFromMldev(fromCitationMetadata),\n    );\n  }\n\n  const fromTokenCount = common.getValueByPath(fromObject, ['tokenCount']);\n  if (fromTokenCount != null) {\n    common.setValueByPath(toObject, ['tokenCount'], fromTokenCount);\n  }\n\n  const fromFinishReason = common.getValueByPath(fromObject, ['finishReason']);\n  if (fromFinishReason != null) {\n    common.setValueByPath(toObject, ['finishReason'], fromFinishReason);\n  }\n\n  const fromUrlContextMetadata = common.getValueByPath(fromObject, [\n    'urlContextMetadata',\n  ]);\n  if (fromUrlContextMetadata != null) {\n    common.setValueByPath(\n      toObject,\n      ['urlContextMetadata'],\n      fromUrlContextMetadata,\n    );\n  }\n\n  const fromAvgLogprobs = common.getValueByPath(fromObject, ['avgLogprobs']);\n  if (fromAvgLogprobs != null) {\n    common.setValueByPath(toObject, ['avgLogprobs'], fromAvgLogprobs);\n  }\n\n  const fromGroundingMetadata = common.getValueByPath(fromObject, [\n    'groundingMetadata',\n  ]);\n  if (fromGroundingMetadata != null) {\n    common.setValueByPath(\n      toObject,\n      ['groundingMetadata'],\n      fromGroundingMetadata,\n    );\n  }\n\n  const fromIndex = common.getValueByPath(fromObject, ['index']);\n  if (fromIndex != null) {\n    common.setValueByPath(toObject, ['index'], fromIndex);\n  }\n\n  const fromLogprobsResult = common.getValueByPath(fromObject, [\n    'logprobsResult',\n  ]);\n  if (fromLogprobsResult != null) {\n    common.setValueByPath(toObject, ['logprobsResult'], fromLogprobsResult);\n  }\n\n  const fromSafetyRatings = common.getValueByPath(fromObject, [\n    'safetyRatings',\n  ]);\n  if (fromSafetyRatings != null) {\n    let transformedList = fromSafetyRatings;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(toObject, ['safetyRatings'], transformedList);\n  }\n\n  return toObject;\n}\n\nexport function citationMetadataFromMldev(\n  fromObject: types.CitationMetadata,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromCitations = common.getValueByPath(fromObject, ['citationSources']);\n  if (fromCitations != null) {\n    let transformedList = fromCitations;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(toObject, ['citations'], transformedList);\n  }\n\n  return toObject;\n}\n\nexport function computeTokensParametersToVertex(\n  apiClient: ApiClient,\n  fromObject: types.ComputeTokensParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'model'],\n      t.tModel(apiClient, fromModel),\n    );\n  }\n\n  const fromContents = common.getValueByPath(fromObject, ['contents']);\n  if (fromContents != null) {\n    let transformedList = t.tContents(fromContents);\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(toObject, ['contents'], transformedList);\n  }\n\n  return toObject;\n}\n\nexport function computeTokensResponseFromVertex(\n  fromObject: types.ComputeTokensResponse,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSdkHttpResponse = common.getValueByPath(fromObject, [\n    'sdkHttpResponse',\n  ]);\n  if (fromSdkHttpResponse != null) {\n    common.setValueByPath(toObject, ['sdkHttpResponse'], fromSdkHttpResponse);\n  }\n\n  const fromTokensInfo = common.getValueByPath(fromObject, ['tokensInfo']);\n  if (fromTokensInfo != null) {\n    let transformedList = fromTokensInfo;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(toObject, ['tokensInfo'], transformedList);\n  }\n\n  return toObject;\n}\n\nexport function contentEmbeddingFromVertex(\n  fromObject: types.ContentEmbedding,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromValues = common.getValueByPath(fromObject, ['values']);\n  if (fromValues != null) {\n    common.setValueByPath(toObject, ['values'], fromValues);\n  }\n\n  const fromStatistics = common.getValueByPath(fromObject, ['statistics']);\n  if (fromStatistics != null) {\n    common.setValueByPath(\n      toObject,\n      ['statistics'],\n      contentEmbeddingStatisticsFromVertex(fromStatistics),\n    );\n  }\n\n  return toObject;\n}\n\nexport function contentEmbeddingStatisticsFromVertex(\n  fromObject: types.ContentEmbeddingStatistics,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromTruncated = common.getValueByPath(fromObject, ['truncated']);\n  if (fromTruncated != null) {\n    common.setValueByPath(toObject, ['truncated'], fromTruncated);\n  }\n\n  const fromTokenCount = common.getValueByPath(fromObject, ['token_count']);\n  if (fromTokenCount != null) {\n    common.setValueByPath(toObject, ['tokenCount'], fromTokenCount);\n  }\n\n  return toObject;\n}\n\nexport function contentToMldev(\n  fromObject: types.Content,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromParts = common.getValueByPath(fromObject, ['parts']);\n  if (fromParts != null) {\n    let transformedList = fromParts;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return partToMldev(item);\n      });\n    }\n    common.setValueByPath(toObject, ['parts'], transformedList);\n  }\n\n  const fromRole = common.getValueByPath(fromObject, ['role']);\n  if (fromRole != null) {\n    common.setValueByPath(toObject, ['role'], fromRole);\n  }\n\n  return toObject;\n}\n\nexport function controlReferenceConfigToVertex(\n  fromObject: types.ControlReferenceConfig,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromControlType = common.getValueByPath(fromObject, ['controlType']);\n  if (fromControlType != null) {\n    common.setValueByPath(toObject, ['controlType'], fromControlType);\n  }\n\n  const fromEnableControlImageComputation = common.getValueByPath(fromObject, [\n    'enableControlImageComputation',\n  ]);\n  if (fromEnableControlImageComputation != null) {\n    common.setValueByPath(\n      toObject,\n      ['computeControl'],\n      fromEnableControlImageComputation,\n    );\n  }\n\n  return toObject;\n}\n\nexport function countTokensConfigToMldev(\n  fromObject: types.CountTokensConfig,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  if (common.getValueByPath(fromObject, ['systemInstruction']) !== undefined) {\n    throw new Error(\n      'systemInstruction parameter is not supported in Gemini API.',\n    );\n  }\n\n  if (common.getValueByPath(fromObject, ['tools']) !== undefined) {\n    throw new Error('tools parameter is not supported in Gemini API.');\n  }\n\n  if (common.getValueByPath(fromObject, ['generationConfig']) !== undefined) {\n    throw new Error(\n      'generationConfig parameter is not supported in Gemini API.',\n    );\n  }\n\n  return toObject;\n}\n\nexport function countTokensConfigToVertex(\n  fromObject: types.CountTokensConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSystemInstruction = common.getValueByPath(fromObject, [\n    'systemInstruction',\n  ]);\n  if (parentObject !== undefined && fromSystemInstruction != null) {\n    common.setValueByPath(\n      parentObject,\n      ['systemInstruction'],\n      t.tContent(fromSystemInstruction),\n    );\n  }\n\n  const fromTools = common.getValueByPath(fromObject, ['tools']);\n  if (parentObject !== undefined && fromTools != null) {\n    let transformedList = fromTools;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return toolToVertex(item);\n      });\n    }\n    common.setValueByPath(parentObject, ['tools'], transformedList);\n  }\n\n  const fromGenerationConfig = common.getValueByPath(fromObject, [\n    'generationConfig',\n  ]);\n  if (parentObject !== undefined && fromGenerationConfig != null) {\n    common.setValueByPath(\n      parentObject,\n      ['generationConfig'],\n      generationConfigToVertex(fromGenerationConfig),\n    );\n  }\n\n  return toObject;\n}\n\nexport function countTokensParametersToMldev(\n  apiClient: ApiClient,\n  fromObject: types.CountTokensParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'model'],\n      t.tModel(apiClient, fromModel),\n    );\n  }\n\n  const fromContents = common.getValueByPath(fromObject, ['contents']);\n  if (fromContents != null) {\n    let transformedList = t.tContents(fromContents);\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return contentToMldev(item);\n      });\n    }\n    common.setValueByPath(toObject, ['contents'], transformedList);\n  }\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    countTokensConfigToMldev(fromConfig);\n  }\n\n  return toObject;\n}\n\nexport function countTokensParametersToVertex(\n  apiClient: ApiClient,\n  fromObject: types.CountTokensParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'model'],\n      t.tModel(apiClient, fromModel),\n    );\n  }\n\n  const fromContents = common.getValueByPath(fromObject, ['contents']);\n  if (fromContents != null) {\n    let transformedList = t.tContents(fromContents);\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(toObject, ['contents'], transformedList);\n  }\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    countTokensConfigToVertex(fromConfig, toObject);\n  }\n\n  return toObject;\n}\n\nexport function countTokensResponseFromMldev(\n  fromObject: types.CountTokensResponse,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSdkHttpResponse = common.getValueByPath(fromObject, [\n    'sdkHttpResponse',\n  ]);\n  if (fromSdkHttpResponse != null) {\n    common.setValueByPath(toObject, ['sdkHttpResponse'], fromSdkHttpResponse);\n  }\n\n  const fromTotalTokens = common.getValueByPath(fromObject, ['totalTokens']);\n  if (fromTotalTokens != null) {\n    common.setValueByPath(toObject, ['totalTokens'], fromTotalTokens);\n  }\n\n  const fromCachedContentTokenCount = common.getValueByPath(fromObject, [\n    'cachedContentTokenCount',\n  ]);\n  if (fromCachedContentTokenCount != null) {\n    common.setValueByPath(\n      toObject,\n      ['cachedContentTokenCount'],\n      fromCachedContentTokenCount,\n    );\n  }\n\n  return toObject;\n}\n\nexport function countTokensResponseFromVertex(\n  fromObject: types.CountTokensResponse,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSdkHttpResponse = common.getValueByPath(fromObject, [\n    'sdkHttpResponse',\n  ]);\n  if (fromSdkHttpResponse != null) {\n    common.setValueByPath(toObject, ['sdkHttpResponse'], fromSdkHttpResponse);\n  }\n\n  const fromTotalTokens = common.getValueByPath(fromObject, ['totalTokens']);\n  if (fromTotalTokens != null) {\n    common.setValueByPath(toObject, ['totalTokens'], fromTotalTokens);\n  }\n\n  return toObject;\n}\n\nexport function deleteModelParametersToMldev(\n  apiClient: ApiClient,\n  fromObject: types.DeleteModelParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'name'],\n      t.tModel(apiClient, fromModel),\n    );\n  }\n\n  return toObject;\n}\n\nexport function deleteModelParametersToVertex(\n  apiClient: ApiClient,\n  fromObject: types.DeleteModelParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'name'],\n      t.tModel(apiClient, fromModel),\n    );\n  }\n\n  return toObject;\n}\n\nexport function deleteModelResponseFromMldev(\n  fromObject: types.DeleteModelResponse,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSdkHttpResponse = common.getValueByPath(fromObject, [\n    'sdkHttpResponse',\n  ]);\n  if (fromSdkHttpResponse != null) {\n    common.setValueByPath(toObject, ['sdkHttpResponse'], fromSdkHttpResponse);\n  }\n\n  return toObject;\n}\n\nexport function deleteModelResponseFromVertex(\n  fromObject: types.DeleteModelResponse,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSdkHttpResponse = common.getValueByPath(fromObject, [\n    'sdkHttpResponse',\n  ]);\n  if (fromSdkHttpResponse != null) {\n    common.setValueByPath(toObject, ['sdkHttpResponse'], fromSdkHttpResponse);\n  }\n\n  return toObject;\n}\n\nexport function editImageConfigToVertex(\n  fromObject: types.EditImageConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromOutputGcsUri = common.getValueByPath(fromObject, ['outputGcsUri']);\n  if (parentObject !== undefined && fromOutputGcsUri != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'storageUri'],\n      fromOutputGcsUri,\n    );\n  }\n\n  const fromNegativePrompt = common.getValueByPath(fromObject, [\n    'negativePrompt',\n  ]);\n  if (parentObject !== undefined && fromNegativePrompt != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'negativePrompt'],\n      fromNegativePrompt,\n    );\n  }\n\n  const fromNumberOfImages = common.getValueByPath(fromObject, [\n    'numberOfImages',\n  ]);\n  if (parentObject !== undefined && fromNumberOfImages != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'sampleCount'],\n      fromNumberOfImages,\n    );\n  }\n\n  const fromAspectRatio = common.getValueByPath(fromObject, ['aspectRatio']);\n  if (parentObject !== undefined && fromAspectRatio != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'aspectRatio'],\n      fromAspectRatio,\n    );\n  }\n\n  const fromGuidanceScale = common.getValueByPath(fromObject, [\n    'guidanceScale',\n  ]);\n  if (parentObject !== undefined && fromGuidanceScale != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'guidanceScale'],\n      fromGuidanceScale,\n    );\n  }\n\n  const fromSeed = common.getValueByPath(fromObject, ['seed']);\n  if (parentObject !== undefined && fromSeed != null) {\n    common.setValueByPath(parentObject, ['parameters', 'seed'], fromSeed);\n  }\n\n  const fromSafetyFilterLevel = common.getValueByPath(fromObject, [\n    'safetyFilterLevel',\n  ]);\n  if (parentObject !== undefined && fromSafetyFilterLevel != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'safetySetting'],\n      fromSafetyFilterLevel,\n    );\n  }\n\n  const fromPersonGeneration = common.getValueByPath(fromObject, [\n    'personGeneration',\n  ]);\n  if (parentObject !== undefined && fromPersonGeneration != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'personGeneration'],\n      fromPersonGeneration,\n    );\n  }\n\n  const fromIncludeSafetyAttributes = common.getValueByPath(fromObject, [\n    'includeSafetyAttributes',\n  ]);\n  if (parentObject !== undefined && fromIncludeSafetyAttributes != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'includeSafetyAttributes'],\n      fromIncludeSafetyAttributes,\n    );\n  }\n\n  const fromIncludeRaiReason = common.getValueByPath(fromObject, [\n    'includeRaiReason',\n  ]);\n  if (parentObject !== undefined && fromIncludeRaiReason != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'includeRaiReason'],\n      fromIncludeRaiReason,\n    );\n  }\n\n  const fromLanguage = common.getValueByPath(fromObject, ['language']);\n  if (parentObject !== undefined && fromLanguage != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'language'],\n      fromLanguage,\n    );\n  }\n\n  const fromOutputMimeType = common.getValueByPath(fromObject, [\n    'outputMimeType',\n  ]);\n  if (parentObject !== undefined && fromOutputMimeType != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'outputOptions', 'mimeType'],\n      fromOutputMimeType,\n    );\n  }\n\n  const fromOutputCompressionQuality = common.getValueByPath(fromObject, [\n    'outputCompressionQuality',\n  ]);\n  if (parentObject !== undefined && fromOutputCompressionQuality != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'outputOptions', 'compressionQuality'],\n      fromOutputCompressionQuality,\n    );\n  }\n\n  const fromAddWatermark = common.getValueByPath(fromObject, ['addWatermark']);\n  if (parentObject !== undefined && fromAddWatermark != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'addWatermark'],\n      fromAddWatermark,\n    );\n  }\n\n  const fromLabels = common.getValueByPath(fromObject, ['labels']);\n  if (parentObject !== undefined && fromLabels != null) {\n    common.setValueByPath(parentObject, ['labels'], fromLabels);\n  }\n\n  const fromEditMode = common.getValueByPath(fromObject, ['editMode']);\n  if (parentObject !== undefined && fromEditMode != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'editMode'],\n      fromEditMode,\n    );\n  }\n\n  const fromBaseSteps = common.getValueByPath(fromObject, ['baseSteps']);\n  if (parentObject !== undefined && fromBaseSteps != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'editConfig', 'baseSteps'],\n      fromBaseSteps,\n    );\n  }\n\n  return toObject;\n}\n\nexport function editImageParametersInternalToVertex(\n  apiClient: ApiClient,\n  fromObject: _internal_types.EditImageParametersInternal,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'model'],\n      t.tModel(apiClient, fromModel),\n    );\n  }\n\n  const fromPrompt = common.getValueByPath(fromObject, ['prompt']);\n  if (fromPrompt != null) {\n    common.setValueByPath(toObject, ['instances[0]', 'prompt'], fromPrompt);\n  }\n\n  const fromReferenceImages = common.getValueByPath(fromObject, [\n    'referenceImages',\n  ]);\n  if (fromReferenceImages != null) {\n    let transformedList = fromReferenceImages;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return referenceImageAPIInternalToVertex(item);\n      });\n    }\n    common.setValueByPath(\n      toObject,\n      ['instances[0]', 'referenceImages'],\n      transformedList,\n    );\n  }\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    editImageConfigToVertex(fromConfig, toObject);\n  }\n\n  return toObject;\n}\n\nexport function editImageResponseFromVertex(\n  fromObject: types.EditImageResponse,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSdkHttpResponse = common.getValueByPath(fromObject, [\n    'sdkHttpResponse',\n  ]);\n  if (fromSdkHttpResponse != null) {\n    common.setValueByPath(toObject, ['sdkHttpResponse'], fromSdkHttpResponse);\n  }\n\n  const fromGeneratedImages = common.getValueByPath(fromObject, [\n    'predictions',\n  ]);\n  if (fromGeneratedImages != null) {\n    let transformedList = fromGeneratedImages;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return generatedImageFromVertex(item);\n      });\n    }\n    common.setValueByPath(toObject, ['generatedImages'], transformedList);\n  }\n\n  return toObject;\n}\n\nexport function embedContentConfigToMldev(\n  fromObject: types.EmbedContentConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromTaskType = common.getValueByPath(fromObject, ['taskType']);\n  if (parentObject !== undefined && fromTaskType != null) {\n    common.setValueByPath(\n      parentObject,\n      ['requests[]', 'taskType'],\n      fromTaskType,\n    );\n  }\n\n  const fromTitle = common.getValueByPath(fromObject, ['title']);\n  if (parentObject !== undefined && fromTitle != null) {\n    common.setValueByPath(parentObject, ['requests[]', 'title'], fromTitle);\n  }\n\n  const fromOutputDimensionality = common.getValueByPath(fromObject, [\n    'outputDimensionality',\n  ]);\n  if (parentObject !== undefined && fromOutputDimensionality != null) {\n    common.setValueByPath(\n      parentObject,\n      ['requests[]', 'outputDimensionality'],\n      fromOutputDimensionality,\n    );\n  }\n\n  if (common.getValueByPath(fromObject, ['mimeType']) !== undefined) {\n    throw new Error('mimeType parameter is not supported in Gemini API.');\n  }\n\n  if (common.getValueByPath(fromObject, ['autoTruncate']) !== undefined) {\n    throw new Error('autoTruncate parameter is not supported in Gemini API.');\n  }\n\n  return toObject;\n}\n\nexport function embedContentConfigToVertex(\n  fromObject: types.EmbedContentConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromTaskType = common.getValueByPath(fromObject, ['taskType']);\n  if (parentObject !== undefined && fromTaskType != null) {\n    common.setValueByPath(\n      parentObject,\n      ['instances[]', 'task_type'],\n      fromTaskType,\n    );\n  }\n\n  const fromTitle = common.getValueByPath(fromObject, ['title']);\n  if (parentObject !== undefined && fromTitle != null) {\n    common.setValueByPath(parentObject, ['instances[]', 'title'], fromTitle);\n  }\n\n  const fromOutputDimensionality = common.getValueByPath(fromObject, [\n    'outputDimensionality',\n  ]);\n  if (parentObject !== undefined && fromOutputDimensionality != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'outputDimensionality'],\n      fromOutputDimensionality,\n    );\n  }\n\n  const fromMimeType = common.getValueByPath(fromObject, ['mimeType']);\n  if (parentObject !== undefined && fromMimeType != null) {\n    common.setValueByPath(\n      parentObject,\n      ['instances[]', 'mimeType'],\n      fromMimeType,\n    );\n  }\n\n  const fromAutoTruncate = common.getValueByPath(fromObject, ['autoTruncate']);\n  if (parentObject !== undefined && fromAutoTruncate != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'autoTruncate'],\n      fromAutoTruncate,\n    );\n  }\n\n  return toObject;\n}\n\nexport function embedContentParametersToMldev(\n  apiClient: ApiClient,\n  fromObject: types.EmbedContentParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'model'],\n      t.tModel(apiClient, fromModel),\n    );\n  }\n\n  const fromContents = common.getValueByPath(fromObject, ['contents']);\n  if (fromContents != null) {\n    let transformedList = t.tContentsForEmbed(apiClient, fromContents);\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(toObject, ['requests[]', 'content'], transformedList);\n  }\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    embedContentConfigToMldev(fromConfig, toObject);\n  }\n\n  const fromModelForEmbedContent = common.getValueByPath(fromObject, ['model']);\n  if (fromModelForEmbedContent !== undefined) {\n    common.setValueByPath(\n      toObject,\n      ['requests[]', 'model'],\n      t.tModel(apiClient, fromModelForEmbedContent),\n    );\n  }\n\n  return toObject;\n}\n\nexport function embedContentParametersToVertex(\n  apiClient: ApiClient,\n  fromObject: types.EmbedContentParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'model'],\n      t.tModel(apiClient, fromModel),\n    );\n  }\n\n  const fromContents = common.getValueByPath(fromObject, ['contents']);\n  if (fromContents != null) {\n    let transformedList = t.tContentsForEmbed(apiClient, fromContents);\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(\n      toObject,\n      ['instances[]', 'content'],\n      transformedList,\n    );\n  }\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    embedContentConfigToVertex(fromConfig, toObject);\n  }\n\n  return toObject;\n}\n\nexport function embedContentResponseFromMldev(\n  fromObject: types.EmbedContentResponse,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSdkHttpResponse = common.getValueByPath(fromObject, [\n    'sdkHttpResponse',\n  ]);\n  if (fromSdkHttpResponse != null) {\n    common.setValueByPath(toObject, ['sdkHttpResponse'], fromSdkHttpResponse);\n  }\n\n  const fromEmbeddings = common.getValueByPath(fromObject, ['embeddings']);\n  if (fromEmbeddings != null) {\n    let transformedList = fromEmbeddings;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(toObject, ['embeddings'], transformedList);\n  }\n\n  const fromMetadata = common.getValueByPath(fromObject, ['metadata']);\n  if (fromMetadata != null) {\n    common.setValueByPath(toObject, ['metadata'], fromMetadata);\n  }\n\n  return toObject;\n}\n\nexport function embedContentResponseFromVertex(\n  fromObject: types.EmbedContentResponse,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSdkHttpResponse = common.getValueByPath(fromObject, [\n    'sdkHttpResponse',\n  ]);\n  if (fromSdkHttpResponse != null) {\n    common.setValueByPath(toObject, ['sdkHttpResponse'], fromSdkHttpResponse);\n  }\n\n  const fromEmbeddings = common.getValueByPath(fromObject, [\n    'predictions[]',\n    'embeddings',\n  ]);\n  if (fromEmbeddings != null) {\n    let transformedList = fromEmbeddings;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return contentEmbeddingFromVertex(item);\n      });\n    }\n    common.setValueByPath(toObject, ['embeddings'], transformedList);\n  }\n\n  const fromMetadata = common.getValueByPath(fromObject, ['metadata']);\n  if (fromMetadata != null) {\n    common.setValueByPath(toObject, ['metadata'], fromMetadata);\n  }\n\n  return toObject;\n}\n\nexport function endpointFromVertex(\n  fromObject: types.Endpoint,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromName = common.getValueByPath(fromObject, ['endpoint']);\n  if (fromName != null) {\n    common.setValueByPath(toObject, ['name'], fromName);\n  }\n\n  const fromDeployedModelId = common.getValueByPath(fromObject, [\n    'deployedModelId',\n  ]);\n  if (fromDeployedModelId != null) {\n    common.setValueByPath(toObject, ['deployedModelId'], fromDeployedModelId);\n  }\n\n  return toObject;\n}\n\nexport function fileDataToMldev(\n  fromObject: types.FileData,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  if (common.getValueByPath(fromObject, ['displayName']) !== undefined) {\n    throw new Error('displayName parameter is not supported in Gemini API.');\n  }\n\n  const fromFileUri = common.getValueByPath(fromObject, ['fileUri']);\n  if (fromFileUri != null) {\n    common.setValueByPath(toObject, ['fileUri'], fromFileUri);\n  }\n\n  const fromMimeType = common.getValueByPath(fromObject, ['mimeType']);\n  if (fromMimeType != null) {\n    common.setValueByPath(toObject, ['mimeType'], fromMimeType);\n  }\n\n  return toObject;\n}\n\nexport function functionDeclarationToVertex(\n  fromObject: types.FunctionDeclaration,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  if (common.getValueByPath(fromObject, ['behavior']) !== undefined) {\n    throw new Error('behavior parameter is not supported in Vertex AI.');\n  }\n\n  const fromDescription = common.getValueByPath(fromObject, ['description']);\n  if (fromDescription != null) {\n    common.setValueByPath(toObject, ['description'], fromDescription);\n  }\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(toObject, ['name'], fromName);\n  }\n\n  const fromParameters = common.getValueByPath(fromObject, ['parameters']);\n  if (fromParameters != null) {\n    common.setValueByPath(toObject, ['parameters'], fromParameters);\n  }\n\n  const fromParametersJsonSchema = common.getValueByPath(fromObject, [\n    'parametersJsonSchema',\n  ]);\n  if (fromParametersJsonSchema != null) {\n    common.setValueByPath(\n      toObject,\n      ['parametersJsonSchema'],\n      fromParametersJsonSchema,\n    );\n  }\n\n  const fromResponse = common.getValueByPath(fromObject, ['response']);\n  if (fromResponse != null) {\n    common.setValueByPath(toObject, ['response'], fromResponse);\n  }\n\n  const fromResponseJsonSchema = common.getValueByPath(fromObject, [\n    'responseJsonSchema',\n  ]);\n  if (fromResponseJsonSchema != null) {\n    common.setValueByPath(\n      toObject,\n      ['responseJsonSchema'],\n      fromResponseJsonSchema,\n    );\n  }\n\n  return toObject;\n}\n\nexport function generateContentConfigToMldev(\n  apiClient: ApiClient,\n  fromObject: types.GenerateContentConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSystemInstruction = common.getValueByPath(fromObject, [\n    'systemInstruction',\n  ]);\n  if (parentObject !== undefined && fromSystemInstruction != null) {\n    common.setValueByPath(\n      parentObject,\n      ['systemInstruction'],\n      contentToMldev(t.tContent(fromSystemInstruction)),\n    );\n  }\n\n  const fromTemperature = common.getValueByPath(fromObject, ['temperature']);\n  if (fromTemperature != null) {\n    common.setValueByPath(toObject, ['temperature'], fromTemperature);\n  }\n\n  const fromTopP = common.getValueByPath(fromObject, ['topP']);\n  if (fromTopP != null) {\n    common.setValueByPath(toObject, ['topP'], fromTopP);\n  }\n\n  const fromTopK = common.getValueByPath(fromObject, ['topK']);\n  if (fromTopK != null) {\n    common.setValueByPath(toObject, ['topK'], fromTopK);\n  }\n\n  const fromCandidateCount = common.getValueByPath(fromObject, [\n    'candidateCount',\n  ]);\n  if (fromCandidateCount != null) {\n    common.setValueByPath(toObject, ['candidateCount'], fromCandidateCount);\n  }\n\n  const fromMaxOutputTokens = common.getValueByPath(fromObject, [\n    'maxOutputTokens',\n  ]);\n  if (fromMaxOutputTokens != null) {\n    common.setValueByPath(toObject, ['maxOutputTokens'], fromMaxOutputTokens);\n  }\n\n  const fromStopSequences = common.getValueByPath(fromObject, [\n    'stopSequences',\n  ]);\n  if (fromStopSequences != null) {\n    common.setValueByPath(toObject, ['stopSequences'], fromStopSequences);\n  }\n\n  const fromResponseLogprobs = common.getValueByPath(fromObject, [\n    'responseLogprobs',\n  ]);\n  if (fromResponseLogprobs != null) {\n    common.setValueByPath(toObject, ['responseLogprobs'], fromResponseLogprobs);\n  }\n\n  const fromLogprobs = common.getValueByPath(fromObject, ['logprobs']);\n  if (fromLogprobs != null) {\n    common.setValueByPath(toObject, ['logprobs'], fromLogprobs);\n  }\n\n  const fromPresencePenalty = common.getValueByPath(fromObject, [\n    'presencePenalty',\n  ]);\n  if (fromPresencePenalty != null) {\n    common.setValueByPath(toObject, ['presencePenalty'], fromPresencePenalty);\n  }\n\n  const fromFrequencyPenalty = common.getValueByPath(fromObject, [\n    'frequencyPenalty',\n  ]);\n  if (fromFrequencyPenalty != null) {\n    common.setValueByPath(toObject, ['frequencyPenalty'], fromFrequencyPenalty);\n  }\n\n  const fromSeed = common.getValueByPath(fromObject, ['seed']);\n  if (fromSeed != null) {\n    common.setValueByPath(toObject, ['seed'], fromSeed);\n  }\n\n  const fromResponseMimeType = common.getValueByPath(fromObject, [\n    'responseMimeType',\n  ]);\n  if (fromResponseMimeType != null) {\n    common.setValueByPath(toObject, ['responseMimeType'], fromResponseMimeType);\n  }\n\n  const fromResponseSchema = common.getValueByPath(fromObject, [\n    'responseSchema',\n  ]);\n  if (fromResponseSchema != null) {\n    common.setValueByPath(\n      toObject,\n      ['responseSchema'],\n      t.tSchema(fromResponseSchema),\n    );\n  }\n\n  const fromResponseJsonSchema = common.getValueByPath(fromObject, [\n    'responseJsonSchema',\n  ]);\n  if (fromResponseJsonSchema != null) {\n    common.setValueByPath(\n      toObject,\n      ['responseJsonSchema'],\n      fromResponseJsonSchema,\n    );\n  }\n\n  if (common.getValueByPath(fromObject, ['routingConfig']) !== undefined) {\n    throw new Error('routingConfig parameter is not supported in Gemini API.');\n  }\n\n  if (\n    common.getValueByPath(fromObject, ['modelSelectionConfig']) !== undefined\n  ) {\n    throw new Error(\n      'modelSelectionConfig parameter is not supported in Gemini API.',\n    );\n  }\n\n  const fromSafetySettings = common.getValueByPath(fromObject, [\n    'safetySettings',\n  ]);\n  if (parentObject !== undefined && fromSafetySettings != null) {\n    let transformedList = fromSafetySettings;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return safetySettingToMldev(item);\n      });\n    }\n    common.setValueByPath(parentObject, ['safetySettings'], transformedList);\n  }\n\n  const fromTools = common.getValueByPath(fromObject, ['tools']);\n  if (parentObject !== undefined && fromTools != null) {\n    let transformedList = t.tTools(fromTools);\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return toolToMldev(t.tTool(item));\n      });\n    }\n    common.setValueByPath(parentObject, ['tools'], transformedList);\n  }\n\n  const fromToolConfig = common.getValueByPath(fromObject, ['toolConfig']);\n  if (parentObject !== undefined && fromToolConfig != null) {\n    common.setValueByPath(parentObject, ['toolConfig'], fromToolConfig);\n  }\n\n  if (common.getValueByPath(fromObject, ['labels']) !== undefined) {\n    throw new Error('labels parameter is not supported in Gemini API.');\n  }\n\n  const fromCachedContent = common.getValueByPath(fromObject, [\n    'cachedContent',\n  ]);\n  if (parentObject !== undefined && fromCachedContent != null) {\n    common.setValueByPath(\n      parentObject,\n      ['cachedContent'],\n      t.tCachedContentName(apiClient, fromCachedContent),\n    );\n  }\n\n  const fromResponseModalities = common.getValueByPath(fromObject, [\n    'responseModalities',\n  ]);\n  if (fromResponseModalities != null) {\n    common.setValueByPath(\n      toObject,\n      ['responseModalities'],\n      fromResponseModalities,\n    );\n  }\n\n  const fromMediaResolution = common.getValueByPath(fromObject, [\n    'mediaResolution',\n  ]);\n  if (fromMediaResolution != null) {\n    common.setValueByPath(toObject, ['mediaResolution'], fromMediaResolution);\n  }\n\n  const fromSpeechConfig = common.getValueByPath(fromObject, ['speechConfig']);\n  if (fromSpeechConfig != null) {\n    common.setValueByPath(\n      toObject,\n      ['speechConfig'],\n      t.tSpeechConfig(fromSpeechConfig),\n    );\n  }\n\n  if (common.getValueByPath(fromObject, ['audioTimestamp']) !== undefined) {\n    throw new Error('audioTimestamp parameter is not supported in Gemini API.');\n  }\n\n  const fromThinkingConfig = common.getValueByPath(fromObject, [\n    'thinkingConfig',\n  ]);\n  if (fromThinkingConfig != null) {\n    common.setValueByPath(toObject, ['thinkingConfig'], fromThinkingConfig);\n  }\n\n  const fromImageConfig = common.getValueByPath(fromObject, ['imageConfig']);\n  if (fromImageConfig != null) {\n    common.setValueByPath(toObject, ['imageConfig'], fromImageConfig);\n  }\n\n  return toObject;\n}\n\nexport function generateContentConfigToVertex(\n  apiClient: ApiClient,\n  fromObject: types.GenerateContentConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSystemInstruction = common.getValueByPath(fromObject, [\n    'systemInstruction',\n  ]);\n  if (parentObject !== undefined && fromSystemInstruction != null) {\n    common.setValueByPath(\n      parentObject,\n      ['systemInstruction'],\n      t.tContent(fromSystemInstruction),\n    );\n  }\n\n  const fromTemperature = common.getValueByPath(fromObject, ['temperature']);\n  if (fromTemperature != null) {\n    common.setValueByPath(toObject, ['temperature'], fromTemperature);\n  }\n\n  const fromTopP = common.getValueByPath(fromObject, ['topP']);\n  if (fromTopP != null) {\n    common.setValueByPath(toObject, ['topP'], fromTopP);\n  }\n\n  const fromTopK = common.getValueByPath(fromObject, ['topK']);\n  if (fromTopK != null) {\n    common.setValueByPath(toObject, ['topK'], fromTopK);\n  }\n\n  const fromCandidateCount = common.getValueByPath(fromObject, [\n    'candidateCount',\n  ]);\n  if (fromCandidateCount != null) {\n    common.setValueByPath(toObject, ['candidateCount'], fromCandidateCount);\n  }\n\n  const fromMaxOutputTokens = common.getValueByPath(fromObject, [\n    'maxOutputTokens',\n  ]);\n  if (fromMaxOutputTokens != null) {\n    common.setValueByPath(toObject, ['maxOutputTokens'], fromMaxOutputTokens);\n  }\n\n  const fromStopSequences = common.getValueByPath(fromObject, [\n    'stopSequences',\n  ]);\n  if (fromStopSequences != null) {\n    common.setValueByPath(toObject, ['stopSequences'], fromStopSequences);\n  }\n\n  const fromResponseLogprobs = common.getValueByPath(fromObject, [\n    'responseLogprobs',\n  ]);\n  if (fromResponseLogprobs != null) {\n    common.setValueByPath(toObject, ['responseLogprobs'], fromResponseLogprobs);\n  }\n\n  const fromLogprobs = common.getValueByPath(fromObject, ['logprobs']);\n  if (fromLogprobs != null) {\n    common.setValueByPath(toObject, ['logprobs'], fromLogprobs);\n  }\n\n  const fromPresencePenalty = common.getValueByPath(fromObject, [\n    'presencePenalty',\n  ]);\n  if (fromPresencePenalty != null) {\n    common.setValueByPath(toObject, ['presencePenalty'], fromPresencePenalty);\n  }\n\n  const fromFrequencyPenalty = common.getValueByPath(fromObject, [\n    'frequencyPenalty',\n  ]);\n  if (fromFrequencyPenalty != null) {\n    common.setValueByPath(toObject, ['frequencyPenalty'], fromFrequencyPenalty);\n  }\n\n  const fromSeed = common.getValueByPath(fromObject, ['seed']);\n  if (fromSeed != null) {\n    common.setValueByPath(toObject, ['seed'], fromSeed);\n  }\n\n  const fromResponseMimeType = common.getValueByPath(fromObject, [\n    'responseMimeType',\n  ]);\n  if (fromResponseMimeType != null) {\n    common.setValueByPath(toObject, ['responseMimeType'], fromResponseMimeType);\n  }\n\n  const fromResponseSchema = common.getValueByPath(fromObject, [\n    'responseSchema',\n  ]);\n  if (fromResponseSchema != null) {\n    common.setValueByPath(\n      toObject,\n      ['responseSchema'],\n      t.tSchema(fromResponseSchema),\n    );\n  }\n\n  const fromResponseJsonSchema = common.getValueByPath(fromObject, [\n    'responseJsonSchema',\n  ]);\n  if (fromResponseJsonSchema != null) {\n    common.setValueByPath(\n      toObject,\n      ['responseJsonSchema'],\n      fromResponseJsonSchema,\n    );\n  }\n\n  const fromRoutingConfig = common.getValueByPath(fromObject, [\n    'routingConfig',\n  ]);\n  if (fromRoutingConfig != null) {\n    common.setValueByPath(toObject, ['routingConfig'], fromRoutingConfig);\n  }\n\n  const fromModelSelectionConfig = common.getValueByPath(fromObject, [\n    'modelSelectionConfig',\n  ]);\n  if (fromModelSelectionConfig != null) {\n    common.setValueByPath(toObject, ['modelConfig'], fromModelSelectionConfig);\n  }\n\n  const fromSafetySettings = common.getValueByPath(fromObject, [\n    'safetySettings',\n  ]);\n  if (parentObject !== undefined && fromSafetySettings != null) {\n    let transformedList = fromSafetySettings;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(parentObject, ['safetySettings'], transformedList);\n  }\n\n  const fromTools = common.getValueByPath(fromObject, ['tools']);\n  if (parentObject !== undefined && fromTools != null) {\n    let transformedList = t.tTools(fromTools);\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return toolToVertex(t.tTool(item));\n      });\n    }\n    common.setValueByPath(parentObject, ['tools'], transformedList);\n  }\n\n  const fromToolConfig = common.getValueByPath(fromObject, ['toolConfig']);\n  if (parentObject !== undefined && fromToolConfig != null) {\n    common.setValueByPath(parentObject, ['toolConfig'], fromToolConfig);\n  }\n\n  const fromLabels = common.getValueByPath(fromObject, ['labels']);\n  if (parentObject !== undefined && fromLabels != null) {\n    common.setValueByPath(parentObject, ['labels'], fromLabels);\n  }\n\n  const fromCachedContent = common.getValueByPath(fromObject, [\n    'cachedContent',\n  ]);\n  if (parentObject !== undefined && fromCachedContent != null) {\n    common.setValueByPath(\n      parentObject,\n      ['cachedContent'],\n      t.tCachedContentName(apiClient, fromCachedContent),\n    );\n  }\n\n  const fromResponseModalities = common.getValueByPath(fromObject, [\n    'responseModalities',\n  ]);\n  if (fromResponseModalities != null) {\n    common.setValueByPath(\n      toObject,\n      ['responseModalities'],\n      fromResponseModalities,\n    );\n  }\n\n  const fromMediaResolution = common.getValueByPath(fromObject, [\n    'mediaResolution',\n  ]);\n  if (fromMediaResolution != null) {\n    common.setValueByPath(toObject, ['mediaResolution'], fromMediaResolution);\n  }\n\n  const fromSpeechConfig = common.getValueByPath(fromObject, ['speechConfig']);\n  if (fromSpeechConfig != null) {\n    common.setValueByPath(\n      toObject,\n      ['speechConfig'],\n      speechConfigToVertex(t.tSpeechConfig(fromSpeechConfig)),\n    );\n  }\n\n  const fromAudioTimestamp = common.getValueByPath(fromObject, [\n    'audioTimestamp',\n  ]);\n  if (fromAudioTimestamp != null) {\n    common.setValueByPath(toObject, ['audioTimestamp'], fromAudioTimestamp);\n  }\n\n  const fromThinkingConfig = common.getValueByPath(fromObject, [\n    'thinkingConfig',\n  ]);\n  if (fromThinkingConfig != null) {\n    common.setValueByPath(toObject, ['thinkingConfig'], fromThinkingConfig);\n  }\n\n  const fromImageConfig = common.getValueByPath(fromObject, ['imageConfig']);\n  if (fromImageConfig != null) {\n    common.setValueByPath(toObject, ['imageConfig'], fromImageConfig);\n  }\n\n  return toObject;\n}\n\nexport function generateContentParametersToMldev(\n  apiClient: ApiClient,\n  fromObject: types.GenerateContentParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'model'],\n      t.tModel(apiClient, fromModel),\n    );\n  }\n\n  const fromContents = common.getValueByPath(fromObject, ['contents']);\n  if (fromContents != null) {\n    let transformedList = t.tContents(fromContents);\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return contentToMldev(item);\n      });\n    }\n    common.setValueByPath(toObject, ['contents'], transformedList);\n  }\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    common.setValueByPath(\n      toObject,\n      ['generationConfig'],\n      generateContentConfigToMldev(apiClient, fromConfig, toObject),\n    );\n  }\n\n  return toObject;\n}\n\nexport function generateContentParametersToVertex(\n  apiClient: ApiClient,\n  fromObject: types.GenerateContentParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'model'],\n      t.tModel(apiClient, fromModel),\n    );\n  }\n\n  const fromContents = common.getValueByPath(fromObject, ['contents']);\n  if (fromContents != null) {\n    let transformedList = t.tContents(fromContents);\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(toObject, ['contents'], transformedList);\n  }\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    common.setValueByPath(\n      toObject,\n      ['generationConfig'],\n      generateContentConfigToVertex(apiClient, fromConfig, toObject),\n    );\n  }\n\n  return toObject;\n}\n\nexport function generateContentResponseFromMldev(\n  fromObject: types.GenerateContentResponse,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSdkHttpResponse = common.getValueByPath(fromObject, [\n    'sdkHttpResponse',\n  ]);\n  if (fromSdkHttpResponse != null) {\n    common.setValueByPath(toObject, ['sdkHttpResponse'], fromSdkHttpResponse);\n  }\n\n  const fromCandidates = common.getValueByPath(fromObject, ['candidates']);\n  if (fromCandidates != null) {\n    let transformedList = fromCandidates;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return candidateFromMldev(item);\n      });\n    }\n    common.setValueByPath(toObject, ['candidates'], transformedList);\n  }\n\n  const fromModelVersion = common.getValueByPath(fromObject, ['modelVersion']);\n  if (fromModelVersion != null) {\n    common.setValueByPath(toObject, ['modelVersion'], fromModelVersion);\n  }\n\n  const fromPromptFeedback = common.getValueByPath(fromObject, [\n    'promptFeedback',\n  ]);\n  if (fromPromptFeedback != null) {\n    common.setValueByPath(toObject, ['promptFeedback'], fromPromptFeedback);\n  }\n\n  const fromResponseId = common.getValueByPath(fromObject, ['responseId']);\n  if (fromResponseId != null) {\n    common.setValueByPath(toObject, ['responseId'], fromResponseId);\n  }\n\n  const fromUsageMetadata = common.getValueByPath(fromObject, [\n    'usageMetadata',\n  ]);\n  if (fromUsageMetadata != null) {\n    common.setValueByPath(toObject, ['usageMetadata'], fromUsageMetadata);\n  }\n\n  return toObject;\n}\n\nexport function generateContentResponseFromVertex(\n  fromObject: types.GenerateContentResponse,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSdkHttpResponse = common.getValueByPath(fromObject, [\n    'sdkHttpResponse',\n  ]);\n  if (fromSdkHttpResponse != null) {\n    common.setValueByPath(toObject, ['sdkHttpResponse'], fromSdkHttpResponse);\n  }\n\n  const fromCandidates = common.getValueByPath(fromObject, ['candidates']);\n  if (fromCandidates != null) {\n    let transformedList = fromCandidates;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(toObject, ['candidates'], transformedList);\n  }\n\n  const fromCreateTime = common.getValueByPath(fromObject, ['createTime']);\n  if (fromCreateTime != null) {\n    common.setValueByPath(toObject, ['createTime'], fromCreateTime);\n  }\n\n  const fromModelVersion = common.getValueByPath(fromObject, ['modelVersion']);\n  if (fromModelVersion != null) {\n    common.setValueByPath(toObject, ['modelVersion'], fromModelVersion);\n  }\n\n  const fromPromptFeedback = common.getValueByPath(fromObject, [\n    'promptFeedback',\n  ]);\n  if (fromPromptFeedback != null) {\n    common.setValueByPath(toObject, ['promptFeedback'], fromPromptFeedback);\n  }\n\n  const fromResponseId = common.getValueByPath(fromObject, ['responseId']);\n  if (fromResponseId != null) {\n    common.setValueByPath(toObject, ['responseId'], fromResponseId);\n  }\n\n  const fromUsageMetadata = common.getValueByPath(fromObject, [\n    'usageMetadata',\n  ]);\n  if (fromUsageMetadata != null) {\n    common.setValueByPath(toObject, ['usageMetadata'], fromUsageMetadata);\n  }\n\n  return toObject;\n}\n\nexport function generateImagesConfigToMldev(\n  fromObject: types.GenerateImagesConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  if (common.getValueByPath(fromObject, ['outputGcsUri']) !== undefined) {\n    throw new Error('outputGcsUri parameter is not supported in Gemini API.');\n  }\n\n  if (common.getValueByPath(fromObject, ['negativePrompt']) !== undefined) {\n    throw new Error('negativePrompt parameter is not supported in Gemini API.');\n  }\n\n  const fromNumberOfImages = common.getValueByPath(fromObject, [\n    'numberOfImages',\n  ]);\n  if (parentObject !== undefined && fromNumberOfImages != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'sampleCount'],\n      fromNumberOfImages,\n    );\n  }\n\n  const fromAspectRatio = common.getValueByPath(fromObject, ['aspectRatio']);\n  if (parentObject !== undefined && fromAspectRatio != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'aspectRatio'],\n      fromAspectRatio,\n    );\n  }\n\n  const fromGuidanceScale = common.getValueByPath(fromObject, [\n    'guidanceScale',\n  ]);\n  if (parentObject !== undefined && fromGuidanceScale != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'guidanceScale'],\n      fromGuidanceScale,\n    );\n  }\n\n  if (common.getValueByPath(fromObject, ['seed']) !== undefined) {\n    throw new Error('seed parameter is not supported in Gemini API.');\n  }\n\n  const fromSafetyFilterLevel = common.getValueByPath(fromObject, [\n    'safetyFilterLevel',\n  ]);\n  if (parentObject !== undefined && fromSafetyFilterLevel != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'safetySetting'],\n      fromSafetyFilterLevel,\n    );\n  }\n\n  const fromPersonGeneration = common.getValueByPath(fromObject, [\n    'personGeneration',\n  ]);\n  if (parentObject !== undefined && fromPersonGeneration != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'personGeneration'],\n      fromPersonGeneration,\n    );\n  }\n\n  const fromIncludeSafetyAttributes = common.getValueByPath(fromObject, [\n    'includeSafetyAttributes',\n  ]);\n  if (parentObject !== undefined && fromIncludeSafetyAttributes != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'includeSafetyAttributes'],\n      fromIncludeSafetyAttributes,\n    );\n  }\n\n  const fromIncludeRaiReason = common.getValueByPath(fromObject, [\n    'includeRaiReason',\n  ]);\n  if (parentObject !== undefined && fromIncludeRaiReason != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'includeRaiReason'],\n      fromIncludeRaiReason,\n    );\n  }\n\n  const fromLanguage = common.getValueByPath(fromObject, ['language']);\n  if (parentObject !== undefined && fromLanguage != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'language'],\n      fromLanguage,\n    );\n  }\n\n  const fromOutputMimeType = common.getValueByPath(fromObject, [\n    'outputMimeType',\n  ]);\n  if (parentObject !== undefined && fromOutputMimeType != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'outputOptions', 'mimeType'],\n      fromOutputMimeType,\n    );\n  }\n\n  const fromOutputCompressionQuality = common.getValueByPath(fromObject, [\n    'outputCompressionQuality',\n  ]);\n  if (parentObject !== undefined && fromOutputCompressionQuality != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'outputOptions', 'compressionQuality'],\n      fromOutputCompressionQuality,\n    );\n  }\n\n  if (common.getValueByPath(fromObject, ['addWatermark']) !== undefined) {\n    throw new Error('addWatermark parameter is not supported in Gemini API.');\n  }\n\n  if (common.getValueByPath(fromObject, ['labels']) !== undefined) {\n    throw new Error('labels parameter is not supported in Gemini API.');\n  }\n\n  const fromImageSize = common.getValueByPath(fromObject, ['imageSize']);\n  if (parentObject !== undefined && fromImageSize != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'sampleImageSize'],\n      fromImageSize,\n    );\n  }\n\n  if (common.getValueByPath(fromObject, ['enhancePrompt']) !== undefined) {\n    throw new Error('enhancePrompt parameter is not supported in Gemini API.');\n  }\n\n  return toObject;\n}\n\nexport function generateImagesConfigToVertex(\n  fromObject: types.GenerateImagesConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromOutputGcsUri = common.getValueByPath(fromObject, ['outputGcsUri']);\n  if (parentObject !== undefined && fromOutputGcsUri != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'storageUri'],\n      fromOutputGcsUri,\n    );\n  }\n\n  const fromNegativePrompt = common.getValueByPath(fromObject, [\n    'negativePrompt',\n  ]);\n  if (parentObject !== undefined && fromNegativePrompt != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'negativePrompt'],\n      fromNegativePrompt,\n    );\n  }\n\n  const fromNumberOfImages = common.getValueByPath(fromObject, [\n    'numberOfImages',\n  ]);\n  if (parentObject !== undefined && fromNumberOfImages != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'sampleCount'],\n      fromNumberOfImages,\n    );\n  }\n\n  const fromAspectRatio = common.getValueByPath(fromObject, ['aspectRatio']);\n  if (parentObject !== undefined && fromAspectRatio != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'aspectRatio'],\n      fromAspectRatio,\n    );\n  }\n\n  const fromGuidanceScale = common.getValueByPath(fromObject, [\n    'guidanceScale',\n  ]);\n  if (parentObject !== undefined && fromGuidanceScale != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'guidanceScale'],\n      fromGuidanceScale,\n    );\n  }\n\n  const fromSeed = common.getValueByPath(fromObject, ['seed']);\n  if (parentObject !== undefined && fromSeed != null) {\n    common.setValueByPath(parentObject, ['parameters', 'seed'], fromSeed);\n  }\n\n  const fromSafetyFilterLevel = common.getValueByPath(fromObject, [\n    'safetyFilterLevel',\n  ]);\n  if (parentObject !== undefined && fromSafetyFilterLevel != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'safetySetting'],\n      fromSafetyFilterLevel,\n    );\n  }\n\n  const fromPersonGeneration = common.getValueByPath(fromObject, [\n    'personGeneration',\n  ]);\n  if (parentObject !== undefined && fromPersonGeneration != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'personGeneration'],\n      fromPersonGeneration,\n    );\n  }\n\n  const fromIncludeSafetyAttributes = common.getValueByPath(fromObject, [\n    'includeSafetyAttributes',\n  ]);\n  if (parentObject !== undefined && fromIncludeSafetyAttributes != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'includeSafetyAttributes'],\n      fromIncludeSafetyAttributes,\n    );\n  }\n\n  const fromIncludeRaiReason = common.getValueByPath(fromObject, [\n    'includeRaiReason',\n  ]);\n  if (parentObject !== undefined && fromIncludeRaiReason != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'includeRaiReason'],\n      fromIncludeRaiReason,\n    );\n  }\n\n  const fromLanguage = common.getValueByPath(fromObject, ['language']);\n  if (parentObject !== undefined && fromLanguage != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'language'],\n      fromLanguage,\n    );\n  }\n\n  const fromOutputMimeType = common.getValueByPath(fromObject, [\n    'outputMimeType',\n  ]);\n  if (parentObject !== undefined && fromOutputMimeType != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'outputOptions', 'mimeType'],\n      fromOutputMimeType,\n    );\n  }\n\n  const fromOutputCompressionQuality = common.getValueByPath(fromObject, [\n    'outputCompressionQuality',\n  ]);\n  if (parentObject !== undefined && fromOutputCompressionQuality != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'outputOptions', 'compressionQuality'],\n      fromOutputCompressionQuality,\n    );\n  }\n\n  const fromAddWatermark = common.getValueByPath(fromObject, ['addWatermark']);\n  if (parentObject !== undefined && fromAddWatermark != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'addWatermark'],\n      fromAddWatermark,\n    );\n  }\n\n  const fromLabels = common.getValueByPath(fromObject, ['labels']);\n  if (parentObject !== undefined && fromLabels != null) {\n    common.setValueByPath(parentObject, ['labels'], fromLabels);\n  }\n\n  const fromImageSize = common.getValueByPath(fromObject, ['imageSize']);\n  if (parentObject !== undefined && fromImageSize != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'sampleImageSize'],\n      fromImageSize,\n    );\n  }\n\n  const fromEnhancePrompt = common.getValueByPath(fromObject, [\n    'enhancePrompt',\n  ]);\n  if (parentObject !== undefined && fromEnhancePrompt != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'enhancePrompt'],\n      fromEnhancePrompt,\n    );\n  }\n\n  return toObject;\n}\n\nexport function generateImagesParametersToMldev(\n  apiClient: ApiClient,\n  fromObject: types.GenerateImagesParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'model'],\n      t.tModel(apiClient, fromModel),\n    );\n  }\n\n  const fromPrompt = common.getValueByPath(fromObject, ['prompt']);\n  if (fromPrompt != null) {\n    common.setValueByPath(toObject, ['instances[0]', 'prompt'], fromPrompt);\n  }\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    generateImagesConfigToMldev(fromConfig, toObject);\n  }\n\n  return toObject;\n}\n\nexport function generateImagesParametersToVertex(\n  apiClient: ApiClient,\n  fromObject: types.GenerateImagesParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'model'],\n      t.tModel(apiClient, fromModel),\n    );\n  }\n\n  const fromPrompt = common.getValueByPath(fromObject, ['prompt']);\n  if (fromPrompt != null) {\n    common.setValueByPath(toObject, ['instances[0]', 'prompt'], fromPrompt);\n  }\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    generateImagesConfigToVertex(fromConfig, toObject);\n  }\n\n  return toObject;\n}\n\nexport function generateImagesResponseFromMldev(\n  fromObject: types.GenerateImagesResponse,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSdkHttpResponse = common.getValueByPath(fromObject, [\n    'sdkHttpResponse',\n  ]);\n  if (fromSdkHttpResponse != null) {\n    common.setValueByPath(toObject, ['sdkHttpResponse'], fromSdkHttpResponse);\n  }\n\n  const fromGeneratedImages = common.getValueByPath(fromObject, [\n    'predictions',\n  ]);\n  if (fromGeneratedImages != null) {\n    let transformedList = fromGeneratedImages;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return generatedImageFromMldev(item);\n      });\n    }\n    common.setValueByPath(toObject, ['generatedImages'], transformedList);\n  }\n\n  const fromPositivePromptSafetyAttributes = common.getValueByPath(fromObject, [\n    'positivePromptSafetyAttributes',\n  ]);\n  if (fromPositivePromptSafetyAttributes != null) {\n    common.setValueByPath(\n      toObject,\n      ['positivePromptSafetyAttributes'],\n      safetyAttributesFromMldev(fromPositivePromptSafetyAttributes),\n    );\n  }\n\n  return toObject;\n}\n\nexport function generateImagesResponseFromVertex(\n  fromObject: types.GenerateImagesResponse,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSdkHttpResponse = common.getValueByPath(fromObject, [\n    'sdkHttpResponse',\n  ]);\n  if (fromSdkHttpResponse != null) {\n    common.setValueByPath(toObject, ['sdkHttpResponse'], fromSdkHttpResponse);\n  }\n\n  const fromGeneratedImages = common.getValueByPath(fromObject, [\n    'predictions',\n  ]);\n  if (fromGeneratedImages != null) {\n    let transformedList = fromGeneratedImages;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return generatedImageFromVertex(item);\n      });\n    }\n    common.setValueByPath(toObject, ['generatedImages'], transformedList);\n  }\n\n  const fromPositivePromptSafetyAttributes = common.getValueByPath(fromObject, [\n    'positivePromptSafetyAttributes',\n  ]);\n  if (fromPositivePromptSafetyAttributes != null) {\n    common.setValueByPath(\n      toObject,\n      ['positivePromptSafetyAttributes'],\n      safetyAttributesFromVertex(fromPositivePromptSafetyAttributes),\n    );\n  }\n\n  return toObject;\n}\n\nexport function generateVideosConfigToMldev(\n  fromObject: types.GenerateVideosConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromNumberOfVideos = common.getValueByPath(fromObject, [\n    'numberOfVideos',\n  ]);\n  if (parentObject !== undefined && fromNumberOfVideos != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'sampleCount'],\n      fromNumberOfVideos,\n    );\n  }\n\n  if (common.getValueByPath(fromObject, ['outputGcsUri']) !== undefined) {\n    throw new Error('outputGcsUri parameter is not supported in Gemini API.');\n  }\n\n  if (common.getValueByPath(fromObject, ['fps']) !== undefined) {\n    throw new Error('fps parameter is not supported in Gemini API.');\n  }\n\n  const fromDurationSeconds = common.getValueByPath(fromObject, [\n    'durationSeconds',\n  ]);\n  if (parentObject !== undefined && fromDurationSeconds != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'durationSeconds'],\n      fromDurationSeconds,\n    );\n  }\n\n  if (common.getValueByPath(fromObject, ['seed']) !== undefined) {\n    throw new Error('seed parameter is not supported in Gemini API.');\n  }\n\n  const fromAspectRatio = common.getValueByPath(fromObject, ['aspectRatio']);\n  if (parentObject !== undefined && fromAspectRatio != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'aspectRatio'],\n      fromAspectRatio,\n    );\n  }\n\n  const fromResolution = common.getValueByPath(fromObject, ['resolution']);\n  if (parentObject !== undefined && fromResolution != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'resolution'],\n      fromResolution,\n    );\n  }\n\n  const fromPersonGeneration = common.getValueByPath(fromObject, [\n    'personGeneration',\n  ]);\n  if (parentObject !== undefined && fromPersonGeneration != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'personGeneration'],\n      fromPersonGeneration,\n    );\n  }\n\n  if (common.getValueByPath(fromObject, ['pubsubTopic']) !== undefined) {\n    throw new Error('pubsubTopic parameter is not supported in Gemini API.');\n  }\n\n  const fromNegativePrompt = common.getValueByPath(fromObject, [\n    'negativePrompt',\n  ]);\n  if (parentObject !== undefined && fromNegativePrompt != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'negativePrompt'],\n      fromNegativePrompt,\n    );\n  }\n\n  const fromEnhancePrompt = common.getValueByPath(fromObject, [\n    'enhancePrompt',\n  ]);\n  if (parentObject !== undefined && fromEnhancePrompt != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'enhancePrompt'],\n      fromEnhancePrompt,\n    );\n  }\n\n  if (common.getValueByPath(fromObject, ['generateAudio']) !== undefined) {\n    throw new Error('generateAudio parameter is not supported in Gemini API.');\n  }\n\n  const fromLastFrame = common.getValueByPath(fromObject, ['lastFrame']);\n  if (parentObject !== undefined && fromLastFrame != null) {\n    common.setValueByPath(\n      parentObject,\n      ['instances[0]', 'lastFrame'],\n      imageToMldev(fromLastFrame),\n    );\n  }\n\n  const fromReferenceImages = common.getValueByPath(fromObject, [\n    'referenceImages',\n  ]);\n  if (parentObject !== undefined && fromReferenceImages != null) {\n    let transformedList = fromReferenceImages;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return videoGenerationReferenceImageToMldev(item);\n      });\n    }\n    common.setValueByPath(\n      parentObject,\n      ['instances[0]', 'referenceImages'],\n      transformedList,\n    );\n  }\n\n  if (common.getValueByPath(fromObject, ['mask']) !== undefined) {\n    throw new Error('mask parameter is not supported in Gemini API.');\n  }\n\n  if (common.getValueByPath(fromObject, ['compressionQuality']) !== undefined) {\n    throw new Error(\n      'compressionQuality parameter is not supported in Gemini API.',\n    );\n  }\n\n  return toObject;\n}\n\nexport function generateVideosConfigToVertex(\n  fromObject: types.GenerateVideosConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromNumberOfVideos = common.getValueByPath(fromObject, [\n    'numberOfVideos',\n  ]);\n  if (parentObject !== undefined && fromNumberOfVideos != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'sampleCount'],\n      fromNumberOfVideos,\n    );\n  }\n\n  const fromOutputGcsUri = common.getValueByPath(fromObject, ['outputGcsUri']);\n  if (parentObject !== undefined && fromOutputGcsUri != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'storageUri'],\n      fromOutputGcsUri,\n    );\n  }\n\n  const fromFps = common.getValueByPath(fromObject, ['fps']);\n  if (parentObject !== undefined && fromFps != null) {\n    common.setValueByPath(parentObject, ['parameters', 'fps'], fromFps);\n  }\n\n  const fromDurationSeconds = common.getValueByPath(fromObject, [\n    'durationSeconds',\n  ]);\n  if (parentObject !== undefined && fromDurationSeconds != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'durationSeconds'],\n      fromDurationSeconds,\n    );\n  }\n\n  const fromSeed = common.getValueByPath(fromObject, ['seed']);\n  if (parentObject !== undefined && fromSeed != null) {\n    common.setValueByPath(parentObject, ['parameters', 'seed'], fromSeed);\n  }\n\n  const fromAspectRatio = common.getValueByPath(fromObject, ['aspectRatio']);\n  if (parentObject !== undefined && fromAspectRatio != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'aspectRatio'],\n      fromAspectRatio,\n    );\n  }\n\n  const fromResolution = common.getValueByPath(fromObject, ['resolution']);\n  if (parentObject !== undefined && fromResolution != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'resolution'],\n      fromResolution,\n    );\n  }\n\n  const fromPersonGeneration = common.getValueByPath(fromObject, [\n    'personGeneration',\n  ]);\n  if (parentObject !== undefined && fromPersonGeneration != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'personGeneration'],\n      fromPersonGeneration,\n    );\n  }\n\n  const fromPubsubTopic = common.getValueByPath(fromObject, ['pubsubTopic']);\n  if (parentObject !== undefined && fromPubsubTopic != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'pubsubTopic'],\n      fromPubsubTopic,\n    );\n  }\n\n  const fromNegativePrompt = common.getValueByPath(fromObject, [\n    'negativePrompt',\n  ]);\n  if (parentObject !== undefined && fromNegativePrompt != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'negativePrompt'],\n      fromNegativePrompt,\n    );\n  }\n\n  const fromEnhancePrompt = common.getValueByPath(fromObject, [\n    'enhancePrompt',\n  ]);\n  if (parentObject !== undefined && fromEnhancePrompt != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'enhancePrompt'],\n      fromEnhancePrompt,\n    );\n  }\n\n  const fromGenerateAudio = common.getValueByPath(fromObject, [\n    'generateAudio',\n  ]);\n  if (parentObject !== undefined && fromGenerateAudio != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'generateAudio'],\n      fromGenerateAudio,\n    );\n  }\n\n  const fromLastFrame = common.getValueByPath(fromObject, ['lastFrame']);\n  if (parentObject !== undefined && fromLastFrame != null) {\n    common.setValueByPath(\n      parentObject,\n      ['instances[0]', 'lastFrame'],\n      imageToVertex(fromLastFrame),\n    );\n  }\n\n  const fromReferenceImages = common.getValueByPath(fromObject, [\n    'referenceImages',\n  ]);\n  if (parentObject !== undefined && fromReferenceImages != null) {\n    let transformedList = fromReferenceImages;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return videoGenerationReferenceImageToVertex(item);\n      });\n    }\n    common.setValueByPath(\n      parentObject,\n      ['instances[0]', 'referenceImages'],\n      transformedList,\n    );\n  }\n\n  const fromMask = common.getValueByPath(fromObject, ['mask']);\n  if (parentObject !== undefined && fromMask != null) {\n    common.setValueByPath(\n      parentObject,\n      ['instances[0]', 'mask'],\n      videoGenerationMaskToVertex(fromMask),\n    );\n  }\n\n  const fromCompressionQuality = common.getValueByPath(fromObject, [\n    'compressionQuality',\n  ]);\n  if (parentObject !== undefined && fromCompressionQuality != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'compressionQuality'],\n      fromCompressionQuality,\n    );\n  }\n\n  return toObject;\n}\n\nexport function generateVideosOperationFromMldev(\n  fromObject: types.GenerateVideosOperation,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(toObject, ['name'], fromName);\n  }\n\n  const fromMetadata = common.getValueByPath(fromObject, ['metadata']);\n  if (fromMetadata != null) {\n    common.setValueByPath(toObject, ['metadata'], fromMetadata);\n  }\n\n  const fromDone = common.getValueByPath(fromObject, ['done']);\n  if (fromDone != null) {\n    common.setValueByPath(toObject, ['done'], fromDone);\n  }\n\n  const fromError = common.getValueByPath(fromObject, ['error']);\n  if (fromError != null) {\n    common.setValueByPath(toObject, ['error'], fromError);\n  }\n\n  const fromResponse = common.getValueByPath(fromObject, [\n    'response',\n    'generateVideoResponse',\n  ]);\n  if (fromResponse != null) {\n    common.setValueByPath(\n      toObject,\n      ['response'],\n      generateVideosResponseFromMldev(fromResponse),\n    );\n  }\n\n  return toObject;\n}\n\nexport function generateVideosOperationFromVertex(\n  fromObject: types.GenerateVideosOperation,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(toObject, ['name'], fromName);\n  }\n\n  const fromMetadata = common.getValueByPath(fromObject, ['metadata']);\n  if (fromMetadata != null) {\n    common.setValueByPath(toObject, ['metadata'], fromMetadata);\n  }\n\n  const fromDone = common.getValueByPath(fromObject, ['done']);\n  if (fromDone != null) {\n    common.setValueByPath(toObject, ['done'], fromDone);\n  }\n\n  const fromError = common.getValueByPath(fromObject, ['error']);\n  if (fromError != null) {\n    common.setValueByPath(toObject, ['error'], fromError);\n  }\n\n  const fromResponse = common.getValueByPath(fromObject, ['response']);\n  if (fromResponse != null) {\n    common.setValueByPath(\n      toObject,\n      ['response'],\n      generateVideosResponseFromVertex(fromResponse),\n    );\n  }\n\n  return toObject;\n}\n\nexport function generateVideosParametersToMldev(\n  apiClient: ApiClient,\n  fromObject: types.GenerateVideosParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'model'],\n      t.tModel(apiClient, fromModel),\n    );\n  }\n\n  const fromPrompt = common.getValueByPath(fromObject, ['prompt']);\n  if (fromPrompt != null) {\n    common.setValueByPath(toObject, ['instances[0]', 'prompt'], fromPrompt);\n  }\n\n  const fromImage = common.getValueByPath(fromObject, ['image']);\n  if (fromImage != null) {\n    common.setValueByPath(\n      toObject,\n      ['instances[0]', 'image'],\n      imageToMldev(fromImage),\n    );\n  }\n\n  const fromVideo = common.getValueByPath(fromObject, ['video']);\n  if (fromVideo != null) {\n    common.setValueByPath(\n      toObject,\n      ['instances[0]', 'video'],\n      videoToMldev(fromVideo),\n    );\n  }\n\n  const fromSource = common.getValueByPath(fromObject, ['source']);\n  if (fromSource != null) {\n    generateVideosSourceToMldev(fromSource, toObject);\n  }\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    generateVideosConfigToMldev(fromConfig, toObject);\n  }\n\n  return toObject;\n}\n\nexport function generateVideosParametersToVertex(\n  apiClient: ApiClient,\n  fromObject: types.GenerateVideosParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'model'],\n      t.tModel(apiClient, fromModel),\n    );\n  }\n\n  const fromPrompt = common.getValueByPath(fromObject, ['prompt']);\n  if (fromPrompt != null) {\n    common.setValueByPath(toObject, ['instances[0]', 'prompt'], fromPrompt);\n  }\n\n  const fromImage = common.getValueByPath(fromObject, ['image']);\n  if (fromImage != null) {\n    common.setValueByPath(\n      toObject,\n      ['instances[0]', 'image'],\n      imageToVertex(fromImage),\n    );\n  }\n\n  const fromVideo = common.getValueByPath(fromObject, ['video']);\n  if (fromVideo != null) {\n    common.setValueByPath(\n      toObject,\n      ['instances[0]', 'video'],\n      videoToVertex(fromVideo),\n    );\n  }\n\n  const fromSource = common.getValueByPath(fromObject, ['source']);\n  if (fromSource != null) {\n    generateVideosSourceToVertex(fromSource, toObject);\n  }\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    generateVideosConfigToVertex(fromConfig, toObject);\n  }\n\n  return toObject;\n}\n\nexport function generateVideosResponseFromMldev(\n  fromObject: types.GenerateVideosResponse,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromGeneratedVideos = common.getValueByPath(fromObject, [\n    'generatedSamples',\n  ]);\n  if (fromGeneratedVideos != null) {\n    let transformedList = fromGeneratedVideos;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return generatedVideoFromMldev(item);\n      });\n    }\n    common.setValueByPath(toObject, ['generatedVideos'], transformedList);\n  }\n\n  const fromRaiMediaFilteredCount = common.getValueByPath(fromObject, [\n    'raiMediaFilteredCount',\n  ]);\n  if (fromRaiMediaFilteredCount != null) {\n    common.setValueByPath(\n      toObject,\n      ['raiMediaFilteredCount'],\n      fromRaiMediaFilteredCount,\n    );\n  }\n\n  const fromRaiMediaFilteredReasons = common.getValueByPath(fromObject, [\n    'raiMediaFilteredReasons',\n  ]);\n  if (fromRaiMediaFilteredReasons != null) {\n    common.setValueByPath(\n      toObject,\n      ['raiMediaFilteredReasons'],\n      fromRaiMediaFilteredReasons,\n    );\n  }\n\n  return toObject;\n}\n\nexport function generateVideosResponseFromVertex(\n  fromObject: types.GenerateVideosResponse,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromGeneratedVideos = common.getValueByPath(fromObject, ['videos']);\n  if (fromGeneratedVideos != null) {\n    let transformedList = fromGeneratedVideos;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return generatedVideoFromVertex(item);\n      });\n    }\n    common.setValueByPath(toObject, ['generatedVideos'], transformedList);\n  }\n\n  const fromRaiMediaFilteredCount = common.getValueByPath(fromObject, [\n    'raiMediaFilteredCount',\n  ]);\n  if (fromRaiMediaFilteredCount != null) {\n    common.setValueByPath(\n      toObject,\n      ['raiMediaFilteredCount'],\n      fromRaiMediaFilteredCount,\n    );\n  }\n\n  const fromRaiMediaFilteredReasons = common.getValueByPath(fromObject, [\n    'raiMediaFilteredReasons',\n  ]);\n  if (fromRaiMediaFilteredReasons != null) {\n    common.setValueByPath(\n      toObject,\n      ['raiMediaFilteredReasons'],\n      fromRaiMediaFilteredReasons,\n    );\n  }\n\n  return toObject;\n}\n\nexport function generateVideosSourceToMldev(\n  fromObject: types.GenerateVideosSource,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromPrompt = common.getValueByPath(fromObject, ['prompt']);\n  if (parentObject !== undefined && fromPrompt != null) {\n    common.setValueByPath(parentObject, ['instances[0]', 'prompt'], fromPrompt);\n  }\n\n  const fromImage = common.getValueByPath(fromObject, ['image']);\n  if (parentObject !== undefined && fromImage != null) {\n    common.setValueByPath(\n      parentObject,\n      ['instances[0]', 'image'],\n      imageToMldev(fromImage),\n    );\n  }\n\n  const fromVideo = common.getValueByPath(fromObject, ['video']);\n  if (parentObject !== undefined && fromVideo != null) {\n    common.setValueByPath(\n      parentObject,\n      ['instances[0]', 'video'],\n      videoToMldev(fromVideo),\n    );\n  }\n\n  return toObject;\n}\n\nexport function generateVideosSourceToVertex(\n  fromObject: types.GenerateVideosSource,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromPrompt = common.getValueByPath(fromObject, ['prompt']);\n  if (parentObject !== undefined && fromPrompt != null) {\n    common.setValueByPath(parentObject, ['instances[0]', 'prompt'], fromPrompt);\n  }\n\n  const fromImage = common.getValueByPath(fromObject, ['image']);\n  if (parentObject !== undefined && fromImage != null) {\n    common.setValueByPath(\n      parentObject,\n      ['instances[0]', 'image'],\n      imageToVertex(fromImage),\n    );\n  }\n\n  const fromVideo = common.getValueByPath(fromObject, ['video']);\n  if (parentObject !== undefined && fromVideo != null) {\n    common.setValueByPath(\n      parentObject,\n      ['instances[0]', 'video'],\n      videoToVertex(fromVideo),\n    );\n  }\n\n  return toObject;\n}\n\nexport function generatedImageFromMldev(\n  fromObject: types.GeneratedImage,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromImage = common.getValueByPath(fromObject, ['_self']);\n  if (fromImage != null) {\n    common.setValueByPath(toObject, ['image'], imageFromMldev(fromImage));\n  }\n\n  const fromRaiFilteredReason = common.getValueByPath(fromObject, [\n    'raiFilteredReason',\n  ]);\n  if (fromRaiFilteredReason != null) {\n    common.setValueByPath(\n      toObject,\n      ['raiFilteredReason'],\n      fromRaiFilteredReason,\n    );\n  }\n\n  const fromSafetyAttributes = common.getValueByPath(fromObject, ['_self']);\n  if (fromSafetyAttributes != null) {\n    common.setValueByPath(\n      toObject,\n      ['safetyAttributes'],\n      safetyAttributesFromMldev(fromSafetyAttributes),\n    );\n  }\n\n  return toObject;\n}\n\nexport function generatedImageFromVertex(\n  fromObject: types.GeneratedImage,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromImage = common.getValueByPath(fromObject, ['_self']);\n  if (fromImage != null) {\n    common.setValueByPath(toObject, ['image'], imageFromVertex(fromImage));\n  }\n\n  const fromRaiFilteredReason = common.getValueByPath(fromObject, [\n    'raiFilteredReason',\n  ]);\n  if (fromRaiFilteredReason != null) {\n    common.setValueByPath(\n      toObject,\n      ['raiFilteredReason'],\n      fromRaiFilteredReason,\n    );\n  }\n\n  const fromSafetyAttributes = common.getValueByPath(fromObject, ['_self']);\n  if (fromSafetyAttributes != null) {\n    common.setValueByPath(\n      toObject,\n      ['safetyAttributes'],\n      safetyAttributesFromVertex(fromSafetyAttributes),\n    );\n  }\n\n  const fromEnhancedPrompt = common.getValueByPath(fromObject, ['prompt']);\n  if (fromEnhancedPrompt != null) {\n    common.setValueByPath(toObject, ['enhancedPrompt'], fromEnhancedPrompt);\n  }\n\n  return toObject;\n}\n\nexport function generatedImageMaskFromVertex(\n  fromObject: types.GeneratedImageMask,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromMask = common.getValueByPath(fromObject, ['_self']);\n  if (fromMask != null) {\n    common.setValueByPath(toObject, ['mask'], imageFromVertex(fromMask));\n  }\n\n  const fromLabels = common.getValueByPath(fromObject, ['labels']);\n  if (fromLabels != null) {\n    let transformedList = fromLabels;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(toObject, ['labels'], transformedList);\n  }\n\n  return toObject;\n}\n\nexport function generatedVideoFromMldev(\n  fromObject: types.GeneratedVideo,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromVideo = common.getValueByPath(fromObject, ['video']);\n  if (fromVideo != null) {\n    common.setValueByPath(toObject, ['video'], videoFromMldev(fromVideo));\n  }\n\n  return toObject;\n}\n\nexport function generatedVideoFromVertex(\n  fromObject: types.GeneratedVideo,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromVideo = common.getValueByPath(fromObject, ['_self']);\n  if (fromVideo != null) {\n    common.setValueByPath(toObject, ['video'], videoFromVertex(fromVideo));\n  }\n\n  return toObject;\n}\n\nexport function generationConfigToVertex(\n  fromObject: types.GenerationConfig,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModelSelectionConfig = common.getValueByPath(fromObject, [\n    'modelSelectionConfig',\n  ]);\n  if (fromModelSelectionConfig != null) {\n    common.setValueByPath(toObject, ['modelConfig'], fromModelSelectionConfig);\n  }\n\n  const fromAudioTimestamp = common.getValueByPath(fromObject, [\n    'audioTimestamp',\n  ]);\n  if (fromAudioTimestamp != null) {\n    common.setValueByPath(toObject, ['audioTimestamp'], fromAudioTimestamp);\n  }\n\n  const fromCandidateCount = common.getValueByPath(fromObject, [\n    'candidateCount',\n  ]);\n  if (fromCandidateCount != null) {\n    common.setValueByPath(toObject, ['candidateCount'], fromCandidateCount);\n  }\n\n  const fromEnableAffectiveDialog = common.getValueByPath(fromObject, [\n    'enableAffectiveDialog',\n  ]);\n  if (fromEnableAffectiveDialog != null) {\n    common.setValueByPath(\n      toObject,\n      ['enableAffectiveDialog'],\n      fromEnableAffectiveDialog,\n    );\n  }\n\n  const fromFrequencyPenalty = common.getValueByPath(fromObject, [\n    'frequencyPenalty',\n  ]);\n  if (fromFrequencyPenalty != null) {\n    common.setValueByPath(toObject, ['frequencyPenalty'], fromFrequencyPenalty);\n  }\n\n  const fromLogprobs = common.getValueByPath(fromObject, ['logprobs']);\n  if (fromLogprobs != null) {\n    common.setValueByPath(toObject, ['logprobs'], fromLogprobs);\n  }\n\n  const fromMaxOutputTokens = common.getValueByPath(fromObject, [\n    'maxOutputTokens',\n  ]);\n  if (fromMaxOutputTokens != null) {\n    common.setValueByPath(toObject, ['maxOutputTokens'], fromMaxOutputTokens);\n  }\n\n  const fromMediaResolution = common.getValueByPath(fromObject, [\n    'mediaResolution',\n  ]);\n  if (fromMediaResolution != null) {\n    common.setValueByPath(toObject, ['mediaResolution'], fromMediaResolution);\n  }\n\n  const fromPresencePenalty = common.getValueByPath(fromObject, [\n    'presencePenalty',\n  ]);\n  if (fromPresencePenalty != null) {\n    common.setValueByPath(toObject, ['presencePenalty'], fromPresencePenalty);\n  }\n\n  const fromResponseJsonSchema = common.getValueByPath(fromObject, [\n    'responseJsonSchema',\n  ]);\n  if (fromResponseJsonSchema != null) {\n    common.setValueByPath(\n      toObject,\n      ['responseJsonSchema'],\n      fromResponseJsonSchema,\n    );\n  }\n\n  const fromResponseLogprobs = common.getValueByPath(fromObject, [\n    'responseLogprobs',\n  ]);\n  if (fromResponseLogprobs != null) {\n    common.setValueByPath(toObject, ['responseLogprobs'], fromResponseLogprobs);\n  }\n\n  const fromResponseMimeType = common.getValueByPath(fromObject, [\n    'responseMimeType',\n  ]);\n  if (fromResponseMimeType != null) {\n    common.setValueByPath(toObject, ['responseMimeType'], fromResponseMimeType);\n  }\n\n  const fromResponseModalities = common.getValueByPath(fromObject, [\n    'responseModalities',\n  ]);\n  if (fromResponseModalities != null) {\n    common.setValueByPath(\n      toObject,\n      ['responseModalities'],\n      fromResponseModalities,\n    );\n  }\n\n  const fromResponseSchema = common.getValueByPath(fromObject, [\n    'responseSchema',\n  ]);\n  if (fromResponseSchema != null) {\n    common.setValueByPath(toObject, ['responseSchema'], fromResponseSchema);\n  }\n\n  const fromRoutingConfig = common.getValueByPath(fromObject, [\n    'routingConfig',\n  ]);\n  if (fromRoutingConfig != null) {\n    common.setValueByPath(toObject, ['routingConfig'], fromRoutingConfig);\n  }\n\n  const fromSeed = common.getValueByPath(fromObject, ['seed']);\n  if (fromSeed != null) {\n    common.setValueByPath(toObject, ['seed'], fromSeed);\n  }\n\n  const fromSpeechConfig = common.getValueByPath(fromObject, ['speechConfig']);\n  if (fromSpeechConfig != null) {\n    common.setValueByPath(\n      toObject,\n      ['speechConfig'],\n      speechConfigToVertex(fromSpeechConfig),\n    );\n  }\n\n  const fromStopSequences = common.getValueByPath(fromObject, [\n    'stopSequences',\n  ]);\n  if (fromStopSequences != null) {\n    common.setValueByPath(toObject, ['stopSequences'], fromStopSequences);\n  }\n\n  const fromTemperature = common.getValueByPath(fromObject, ['temperature']);\n  if (fromTemperature != null) {\n    common.setValueByPath(toObject, ['temperature'], fromTemperature);\n  }\n\n  const fromThinkingConfig = common.getValueByPath(fromObject, [\n    'thinkingConfig',\n  ]);\n  if (fromThinkingConfig != null) {\n    common.setValueByPath(toObject, ['thinkingConfig'], fromThinkingConfig);\n  }\n\n  const fromTopK = common.getValueByPath(fromObject, ['topK']);\n  if (fromTopK != null) {\n    common.setValueByPath(toObject, ['topK'], fromTopK);\n  }\n\n  const fromTopP = common.getValueByPath(fromObject, ['topP']);\n  if (fromTopP != null) {\n    common.setValueByPath(toObject, ['topP'], fromTopP);\n  }\n\n  if (\n    common.getValueByPath(fromObject, ['enableEnhancedCivicAnswers']) !==\n    undefined\n  ) {\n    throw new Error(\n      'enableEnhancedCivicAnswers parameter is not supported in Vertex AI.',\n    );\n  }\n\n  return toObject;\n}\n\nexport function getModelParametersToMldev(\n  apiClient: ApiClient,\n  fromObject: types.GetModelParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'name'],\n      t.tModel(apiClient, fromModel),\n    );\n  }\n\n  return toObject;\n}\n\nexport function getModelParametersToVertex(\n  apiClient: ApiClient,\n  fromObject: types.GetModelParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'name'],\n      t.tModel(apiClient, fromModel),\n    );\n  }\n\n  return toObject;\n}\n\nexport function googleMapsToMldev(\n  fromObject: types.GoogleMaps,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  if (common.getValueByPath(fromObject, ['authConfig']) !== undefined) {\n    throw new Error('authConfig parameter is not supported in Gemini API.');\n  }\n\n  const fromEnableWidget = common.getValueByPath(fromObject, ['enableWidget']);\n  if (fromEnableWidget != null) {\n    common.setValueByPath(toObject, ['enableWidget'], fromEnableWidget);\n  }\n\n  return toObject;\n}\n\nexport function googleSearchToMldev(\n  fromObject: types.GoogleSearch,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromTimeRangeFilter = common.getValueByPath(fromObject, [\n    'timeRangeFilter',\n  ]);\n  if (fromTimeRangeFilter != null) {\n    common.setValueByPath(toObject, ['timeRangeFilter'], fromTimeRangeFilter);\n  }\n\n  if (common.getValueByPath(fromObject, ['excludeDomains']) !== undefined) {\n    throw new Error('excludeDomains parameter is not supported in Gemini API.');\n  }\n\n  return toObject;\n}\n\nexport function imageFromMldev(\n  fromObject: types.Image,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromImageBytes = common.getValueByPath(fromObject, [\n    'bytesBase64Encoded',\n  ]);\n  if (fromImageBytes != null) {\n    common.setValueByPath(toObject, ['imageBytes'], t.tBytes(fromImageBytes));\n  }\n\n  const fromMimeType = common.getValueByPath(fromObject, ['mimeType']);\n  if (fromMimeType != null) {\n    common.setValueByPath(toObject, ['mimeType'], fromMimeType);\n  }\n\n  return toObject;\n}\n\nexport function imageFromVertex(\n  fromObject: types.Image,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromGcsUri = common.getValueByPath(fromObject, ['gcsUri']);\n  if (fromGcsUri != null) {\n    common.setValueByPath(toObject, ['gcsUri'], fromGcsUri);\n  }\n\n  const fromImageBytes = common.getValueByPath(fromObject, [\n    'bytesBase64Encoded',\n  ]);\n  if (fromImageBytes != null) {\n    common.setValueByPath(toObject, ['imageBytes'], t.tBytes(fromImageBytes));\n  }\n\n  const fromMimeType = common.getValueByPath(fromObject, ['mimeType']);\n  if (fromMimeType != null) {\n    common.setValueByPath(toObject, ['mimeType'], fromMimeType);\n  }\n\n  return toObject;\n}\n\nexport function imageToMldev(fromObject: types.Image): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  if (common.getValueByPath(fromObject, ['gcsUri']) !== undefined) {\n    throw new Error('gcsUri parameter is not supported in Gemini API.');\n  }\n\n  const fromImageBytes = common.getValueByPath(fromObject, ['imageBytes']);\n  if (fromImageBytes != null) {\n    common.setValueByPath(\n      toObject,\n      ['bytesBase64Encoded'],\n      t.tBytes(fromImageBytes),\n    );\n  }\n\n  const fromMimeType = common.getValueByPath(fromObject, ['mimeType']);\n  if (fromMimeType != null) {\n    common.setValueByPath(toObject, ['mimeType'], fromMimeType);\n  }\n\n  return toObject;\n}\n\nexport function imageToVertex(\n  fromObject: types.Image,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromGcsUri = common.getValueByPath(fromObject, ['gcsUri']);\n  if (fromGcsUri != null) {\n    common.setValueByPath(toObject, ['gcsUri'], fromGcsUri);\n  }\n\n  const fromImageBytes = common.getValueByPath(fromObject, ['imageBytes']);\n  if (fromImageBytes != null) {\n    common.setValueByPath(\n      toObject,\n      ['bytesBase64Encoded'],\n      t.tBytes(fromImageBytes),\n    );\n  }\n\n  const fromMimeType = common.getValueByPath(fromObject, ['mimeType']);\n  if (fromMimeType != null) {\n    common.setValueByPath(toObject, ['mimeType'], fromMimeType);\n  }\n\n  return toObject;\n}\n\nexport function listModelsConfigToMldev(\n  apiClient: ApiClient,\n  fromObject: types.ListModelsConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromPageSize = common.getValueByPath(fromObject, ['pageSize']);\n  if (parentObject !== undefined && fromPageSize != null) {\n    common.setValueByPath(parentObject, ['_query', 'pageSize'], fromPageSize);\n  }\n\n  const fromPageToken = common.getValueByPath(fromObject, ['pageToken']);\n  if (parentObject !== undefined && fromPageToken != null) {\n    common.setValueByPath(parentObject, ['_query', 'pageToken'], fromPageToken);\n  }\n\n  const fromFilter = common.getValueByPath(fromObject, ['filter']);\n  if (parentObject !== undefined && fromFilter != null) {\n    common.setValueByPath(parentObject, ['_query', 'filter'], fromFilter);\n  }\n\n  const fromQueryBase = common.getValueByPath(fromObject, ['queryBase']);\n  if (parentObject !== undefined && fromQueryBase != null) {\n    common.setValueByPath(\n      parentObject,\n      ['_url', 'models_url'],\n      t.tModelsUrl(apiClient, fromQueryBase),\n    );\n  }\n\n  return toObject;\n}\n\nexport function listModelsConfigToVertex(\n  apiClient: ApiClient,\n  fromObject: types.ListModelsConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromPageSize = common.getValueByPath(fromObject, ['pageSize']);\n  if (parentObject !== undefined && fromPageSize != null) {\n    common.setValueByPath(parentObject, ['_query', 'pageSize'], fromPageSize);\n  }\n\n  const fromPageToken = common.getValueByPath(fromObject, ['pageToken']);\n  if (parentObject !== undefined && fromPageToken != null) {\n    common.setValueByPath(parentObject, ['_query', 'pageToken'], fromPageToken);\n  }\n\n  const fromFilter = common.getValueByPath(fromObject, ['filter']);\n  if (parentObject !== undefined && fromFilter != null) {\n    common.setValueByPath(parentObject, ['_query', 'filter'], fromFilter);\n  }\n\n  const fromQueryBase = common.getValueByPath(fromObject, ['queryBase']);\n  if (parentObject !== undefined && fromQueryBase != null) {\n    common.setValueByPath(\n      parentObject,\n      ['_url', 'models_url'],\n      t.tModelsUrl(apiClient, fromQueryBase),\n    );\n  }\n\n  return toObject;\n}\n\nexport function listModelsParametersToMldev(\n  apiClient: ApiClient,\n  fromObject: types.ListModelsParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    listModelsConfigToMldev(apiClient, fromConfig, toObject);\n  }\n\n  return toObject;\n}\n\nexport function listModelsParametersToVertex(\n  apiClient: ApiClient,\n  fromObject: types.ListModelsParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    listModelsConfigToVertex(apiClient, fromConfig, toObject);\n  }\n\n  return toObject;\n}\n\nexport function listModelsResponseFromMldev(\n  fromObject: types.ListModelsResponse,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSdkHttpResponse = common.getValueByPath(fromObject, [\n    'sdkHttpResponse',\n  ]);\n  if (fromSdkHttpResponse != null) {\n    common.setValueByPath(toObject, ['sdkHttpResponse'], fromSdkHttpResponse);\n  }\n\n  const fromNextPageToken = common.getValueByPath(fromObject, [\n    'nextPageToken',\n  ]);\n  if (fromNextPageToken != null) {\n    common.setValueByPath(toObject, ['nextPageToken'], fromNextPageToken);\n  }\n\n  const fromModels = common.getValueByPath(fromObject, ['_self']);\n  if (fromModels != null) {\n    let transformedList = t.tExtractModels(fromModels);\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return modelFromMldev(item);\n      });\n    }\n    common.setValueByPath(toObject, ['models'], transformedList);\n  }\n\n  return toObject;\n}\n\nexport function listModelsResponseFromVertex(\n  fromObject: types.ListModelsResponse,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSdkHttpResponse = common.getValueByPath(fromObject, [\n    'sdkHttpResponse',\n  ]);\n  if (fromSdkHttpResponse != null) {\n    common.setValueByPath(toObject, ['sdkHttpResponse'], fromSdkHttpResponse);\n  }\n\n  const fromNextPageToken = common.getValueByPath(fromObject, [\n    'nextPageToken',\n  ]);\n  if (fromNextPageToken != null) {\n    common.setValueByPath(toObject, ['nextPageToken'], fromNextPageToken);\n  }\n\n  const fromModels = common.getValueByPath(fromObject, ['_self']);\n  if (fromModels != null) {\n    let transformedList = t.tExtractModels(fromModels);\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return modelFromVertex(item);\n      });\n    }\n    common.setValueByPath(toObject, ['models'], transformedList);\n  }\n\n  return toObject;\n}\n\nexport function maskReferenceConfigToVertex(\n  fromObject: types.MaskReferenceConfig,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromMaskMode = common.getValueByPath(fromObject, ['maskMode']);\n  if (fromMaskMode != null) {\n    common.setValueByPath(toObject, ['maskMode'], fromMaskMode);\n  }\n\n  const fromSegmentationClasses = common.getValueByPath(fromObject, [\n    'segmentationClasses',\n  ]);\n  if (fromSegmentationClasses != null) {\n    common.setValueByPath(toObject, ['maskClasses'], fromSegmentationClasses);\n  }\n\n  const fromMaskDilation = common.getValueByPath(fromObject, ['maskDilation']);\n  if (fromMaskDilation != null) {\n    common.setValueByPath(toObject, ['dilation'], fromMaskDilation);\n  }\n\n  return toObject;\n}\n\nexport function modelFromMldev(\n  fromObject: types.Model,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(toObject, ['name'], fromName);\n  }\n\n  const fromDisplayName = common.getValueByPath(fromObject, ['displayName']);\n  if (fromDisplayName != null) {\n    common.setValueByPath(toObject, ['displayName'], fromDisplayName);\n  }\n\n  const fromDescription = common.getValueByPath(fromObject, ['description']);\n  if (fromDescription != null) {\n    common.setValueByPath(toObject, ['description'], fromDescription);\n  }\n\n  const fromVersion = common.getValueByPath(fromObject, ['version']);\n  if (fromVersion != null) {\n    common.setValueByPath(toObject, ['version'], fromVersion);\n  }\n\n  const fromTunedModelInfo = common.getValueByPath(fromObject, ['_self']);\n  if (fromTunedModelInfo != null) {\n    common.setValueByPath(\n      toObject,\n      ['tunedModelInfo'],\n      tunedModelInfoFromMldev(fromTunedModelInfo),\n    );\n  }\n\n  const fromInputTokenLimit = common.getValueByPath(fromObject, [\n    'inputTokenLimit',\n  ]);\n  if (fromInputTokenLimit != null) {\n    common.setValueByPath(toObject, ['inputTokenLimit'], fromInputTokenLimit);\n  }\n\n  const fromOutputTokenLimit = common.getValueByPath(fromObject, [\n    'outputTokenLimit',\n  ]);\n  if (fromOutputTokenLimit != null) {\n    common.setValueByPath(toObject, ['outputTokenLimit'], fromOutputTokenLimit);\n  }\n\n  const fromSupportedActions = common.getValueByPath(fromObject, [\n    'supportedGenerationMethods',\n  ]);\n  if (fromSupportedActions != null) {\n    common.setValueByPath(toObject, ['supportedActions'], fromSupportedActions);\n  }\n\n  return toObject;\n}\n\nexport function modelFromVertex(\n  fromObject: types.Model,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(toObject, ['name'], fromName);\n  }\n\n  const fromDisplayName = common.getValueByPath(fromObject, ['displayName']);\n  if (fromDisplayName != null) {\n    common.setValueByPath(toObject, ['displayName'], fromDisplayName);\n  }\n\n  const fromDescription = common.getValueByPath(fromObject, ['description']);\n  if (fromDescription != null) {\n    common.setValueByPath(toObject, ['description'], fromDescription);\n  }\n\n  const fromVersion = common.getValueByPath(fromObject, ['versionId']);\n  if (fromVersion != null) {\n    common.setValueByPath(toObject, ['version'], fromVersion);\n  }\n\n  const fromEndpoints = common.getValueByPath(fromObject, ['deployedModels']);\n  if (fromEndpoints != null) {\n    let transformedList = fromEndpoints;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return endpointFromVertex(item);\n      });\n    }\n    common.setValueByPath(toObject, ['endpoints'], transformedList);\n  }\n\n  const fromLabels = common.getValueByPath(fromObject, ['labels']);\n  if (fromLabels != null) {\n    common.setValueByPath(toObject, ['labels'], fromLabels);\n  }\n\n  const fromTunedModelInfo = common.getValueByPath(fromObject, ['_self']);\n  if (fromTunedModelInfo != null) {\n    common.setValueByPath(\n      toObject,\n      ['tunedModelInfo'],\n      tunedModelInfoFromVertex(fromTunedModelInfo),\n    );\n  }\n\n  const fromDefaultCheckpointId = common.getValueByPath(fromObject, [\n    'defaultCheckpointId',\n  ]);\n  if (fromDefaultCheckpointId != null) {\n    common.setValueByPath(\n      toObject,\n      ['defaultCheckpointId'],\n      fromDefaultCheckpointId,\n    );\n  }\n\n  const fromCheckpoints = common.getValueByPath(fromObject, ['checkpoints']);\n  if (fromCheckpoints != null) {\n    let transformedList = fromCheckpoints;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(toObject, ['checkpoints'], transformedList);\n  }\n\n  return toObject;\n}\n\nexport function partToMldev(fromObject: types.Part): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromVideoMetadata = common.getValueByPath(fromObject, [\n    'videoMetadata',\n  ]);\n  if (fromVideoMetadata != null) {\n    common.setValueByPath(toObject, ['videoMetadata'], fromVideoMetadata);\n  }\n\n  const fromThought = common.getValueByPath(fromObject, ['thought']);\n  if (fromThought != null) {\n    common.setValueByPath(toObject, ['thought'], fromThought);\n  }\n\n  const fromInlineData = common.getValueByPath(fromObject, ['inlineData']);\n  if (fromInlineData != null) {\n    common.setValueByPath(\n      toObject,\n      ['inlineData'],\n      blobToMldev(fromInlineData),\n    );\n  }\n\n  const fromFileData = common.getValueByPath(fromObject, ['fileData']);\n  if (fromFileData != null) {\n    common.setValueByPath(\n      toObject,\n      ['fileData'],\n      fileDataToMldev(fromFileData),\n    );\n  }\n\n  const fromThoughtSignature = common.getValueByPath(fromObject, [\n    'thoughtSignature',\n  ]);\n  if (fromThoughtSignature != null) {\n    common.setValueByPath(toObject, ['thoughtSignature'], fromThoughtSignature);\n  }\n\n  const fromFunctionCall = common.getValueByPath(fromObject, ['functionCall']);\n  if (fromFunctionCall != null) {\n    common.setValueByPath(toObject, ['functionCall'], fromFunctionCall);\n  }\n\n  const fromCodeExecutionResult = common.getValueByPath(fromObject, [\n    'codeExecutionResult',\n  ]);\n  if (fromCodeExecutionResult != null) {\n    common.setValueByPath(\n      toObject,\n      ['codeExecutionResult'],\n      fromCodeExecutionResult,\n    );\n  }\n\n  const fromExecutableCode = common.getValueByPath(fromObject, [\n    'executableCode',\n  ]);\n  if (fromExecutableCode != null) {\n    common.setValueByPath(toObject, ['executableCode'], fromExecutableCode);\n  }\n\n  const fromFunctionResponse = common.getValueByPath(fromObject, [\n    'functionResponse',\n  ]);\n  if (fromFunctionResponse != null) {\n    common.setValueByPath(toObject, ['functionResponse'], fromFunctionResponse);\n  }\n\n  const fromText = common.getValueByPath(fromObject, ['text']);\n  if (fromText != null) {\n    common.setValueByPath(toObject, ['text'], fromText);\n  }\n\n  return toObject;\n}\n\nexport function productImageToVertex(\n  fromObject: types.ProductImage,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromProductImage = common.getValueByPath(fromObject, ['productImage']);\n  if (fromProductImage != null) {\n    common.setValueByPath(toObject, ['image'], imageToVertex(fromProductImage));\n  }\n\n  return toObject;\n}\n\nexport function recontextImageConfigToVertex(\n  fromObject: types.RecontextImageConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromNumberOfImages = common.getValueByPath(fromObject, [\n    'numberOfImages',\n  ]);\n  if (parentObject !== undefined && fromNumberOfImages != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'sampleCount'],\n      fromNumberOfImages,\n    );\n  }\n\n  const fromBaseSteps = common.getValueByPath(fromObject, ['baseSteps']);\n  if (parentObject !== undefined && fromBaseSteps != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'editConfig', 'baseSteps'],\n      fromBaseSteps,\n    );\n  }\n\n  const fromOutputGcsUri = common.getValueByPath(fromObject, ['outputGcsUri']);\n  if (parentObject !== undefined && fromOutputGcsUri != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'storageUri'],\n      fromOutputGcsUri,\n    );\n  }\n\n  const fromSeed = common.getValueByPath(fromObject, ['seed']);\n  if (parentObject !== undefined && fromSeed != null) {\n    common.setValueByPath(parentObject, ['parameters', 'seed'], fromSeed);\n  }\n\n  const fromSafetyFilterLevel = common.getValueByPath(fromObject, [\n    'safetyFilterLevel',\n  ]);\n  if (parentObject !== undefined && fromSafetyFilterLevel != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'safetySetting'],\n      fromSafetyFilterLevel,\n    );\n  }\n\n  const fromPersonGeneration = common.getValueByPath(fromObject, [\n    'personGeneration',\n  ]);\n  if (parentObject !== undefined && fromPersonGeneration != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'personGeneration'],\n      fromPersonGeneration,\n    );\n  }\n\n  const fromAddWatermark = common.getValueByPath(fromObject, ['addWatermark']);\n  if (parentObject !== undefined && fromAddWatermark != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'addWatermark'],\n      fromAddWatermark,\n    );\n  }\n\n  const fromOutputMimeType = common.getValueByPath(fromObject, [\n    'outputMimeType',\n  ]);\n  if (parentObject !== undefined && fromOutputMimeType != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'outputOptions', 'mimeType'],\n      fromOutputMimeType,\n    );\n  }\n\n  const fromOutputCompressionQuality = common.getValueByPath(fromObject, [\n    'outputCompressionQuality',\n  ]);\n  if (parentObject !== undefined && fromOutputCompressionQuality != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'outputOptions', 'compressionQuality'],\n      fromOutputCompressionQuality,\n    );\n  }\n\n  const fromEnhancePrompt = common.getValueByPath(fromObject, [\n    'enhancePrompt',\n  ]);\n  if (parentObject !== undefined && fromEnhancePrompt != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'enhancePrompt'],\n      fromEnhancePrompt,\n    );\n  }\n\n  const fromLabels = common.getValueByPath(fromObject, ['labels']);\n  if (parentObject !== undefined && fromLabels != null) {\n    common.setValueByPath(parentObject, ['labels'], fromLabels);\n  }\n\n  return toObject;\n}\n\nexport function recontextImageParametersToVertex(\n  apiClient: ApiClient,\n  fromObject: types.RecontextImageParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'model'],\n      t.tModel(apiClient, fromModel),\n    );\n  }\n\n  const fromSource = common.getValueByPath(fromObject, ['source']);\n  if (fromSource != null) {\n    recontextImageSourceToVertex(fromSource, toObject);\n  }\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    recontextImageConfigToVertex(fromConfig, toObject);\n  }\n\n  return toObject;\n}\n\nexport function recontextImageResponseFromVertex(\n  fromObject: types.RecontextImageResponse,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromGeneratedImages = common.getValueByPath(fromObject, [\n    'predictions',\n  ]);\n  if (fromGeneratedImages != null) {\n    let transformedList = fromGeneratedImages;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return generatedImageFromVertex(item);\n      });\n    }\n    common.setValueByPath(toObject, ['generatedImages'], transformedList);\n  }\n\n  return toObject;\n}\n\nexport function recontextImageSourceToVertex(\n  fromObject: types.RecontextImageSource,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromPrompt = common.getValueByPath(fromObject, ['prompt']);\n  if (parentObject !== undefined && fromPrompt != null) {\n    common.setValueByPath(parentObject, ['instances[0]', 'prompt'], fromPrompt);\n  }\n\n  const fromPersonImage = common.getValueByPath(fromObject, ['personImage']);\n  if (parentObject !== undefined && fromPersonImage != null) {\n    common.setValueByPath(\n      parentObject,\n      ['instances[0]', 'personImage', 'image'],\n      imageToVertex(fromPersonImage),\n    );\n  }\n\n  const fromProductImages = common.getValueByPath(fromObject, [\n    'productImages',\n  ]);\n  if (parentObject !== undefined && fromProductImages != null) {\n    let transformedList = fromProductImages;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return productImageToVertex(item);\n      });\n    }\n    common.setValueByPath(\n      parentObject,\n      ['instances[0]', 'productImages'],\n      transformedList,\n    );\n  }\n\n  return toObject;\n}\n\nexport function referenceImageAPIInternalToVertex(\n  fromObject: _internal_types.ReferenceImageAPIInternal,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromReferenceImage = common.getValueByPath(fromObject, [\n    'referenceImage',\n  ]);\n  if (fromReferenceImage != null) {\n    common.setValueByPath(\n      toObject,\n      ['referenceImage'],\n      imageToVertex(fromReferenceImage),\n    );\n  }\n\n  const fromReferenceId = common.getValueByPath(fromObject, ['referenceId']);\n  if (fromReferenceId != null) {\n    common.setValueByPath(toObject, ['referenceId'], fromReferenceId);\n  }\n\n  const fromReferenceType = common.getValueByPath(fromObject, [\n    'referenceType',\n  ]);\n  if (fromReferenceType != null) {\n    common.setValueByPath(toObject, ['referenceType'], fromReferenceType);\n  }\n\n  const fromMaskImageConfig = common.getValueByPath(fromObject, [\n    'maskImageConfig',\n  ]);\n  if (fromMaskImageConfig != null) {\n    common.setValueByPath(\n      toObject,\n      ['maskImageConfig'],\n      maskReferenceConfigToVertex(fromMaskImageConfig),\n    );\n  }\n\n  const fromControlImageConfig = common.getValueByPath(fromObject, [\n    'controlImageConfig',\n  ]);\n  if (fromControlImageConfig != null) {\n    common.setValueByPath(\n      toObject,\n      ['controlImageConfig'],\n      controlReferenceConfigToVertex(fromControlImageConfig),\n    );\n  }\n\n  const fromStyleImageConfig = common.getValueByPath(fromObject, [\n    'styleImageConfig',\n  ]);\n  if (fromStyleImageConfig != null) {\n    common.setValueByPath(toObject, ['styleImageConfig'], fromStyleImageConfig);\n  }\n\n  const fromSubjectImageConfig = common.getValueByPath(fromObject, [\n    'subjectImageConfig',\n  ]);\n  if (fromSubjectImageConfig != null) {\n    common.setValueByPath(\n      toObject,\n      ['subjectImageConfig'],\n      fromSubjectImageConfig,\n    );\n  }\n\n  return toObject;\n}\n\nexport function safetyAttributesFromMldev(\n  fromObject: types.SafetyAttributes,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromCategories = common.getValueByPath(fromObject, [\n    'safetyAttributes',\n    'categories',\n  ]);\n  if (fromCategories != null) {\n    common.setValueByPath(toObject, ['categories'], fromCategories);\n  }\n\n  const fromScores = common.getValueByPath(fromObject, [\n    'safetyAttributes',\n    'scores',\n  ]);\n  if (fromScores != null) {\n    common.setValueByPath(toObject, ['scores'], fromScores);\n  }\n\n  const fromContentType = common.getValueByPath(fromObject, ['contentType']);\n  if (fromContentType != null) {\n    common.setValueByPath(toObject, ['contentType'], fromContentType);\n  }\n\n  return toObject;\n}\n\nexport function safetyAttributesFromVertex(\n  fromObject: types.SafetyAttributes,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromCategories = common.getValueByPath(fromObject, [\n    'safetyAttributes',\n    'categories',\n  ]);\n  if (fromCategories != null) {\n    common.setValueByPath(toObject, ['categories'], fromCategories);\n  }\n\n  const fromScores = common.getValueByPath(fromObject, [\n    'safetyAttributes',\n    'scores',\n  ]);\n  if (fromScores != null) {\n    common.setValueByPath(toObject, ['scores'], fromScores);\n  }\n\n  const fromContentType = common.getValueByPath(fromObject, ['contentType']);\n  if (fromContentType != null) {\n    common.setValueByPath(toObject, ['contentType'], fromContentType);\n  }\n\n  return toObject;\n}\n\nexport function safetySettingToMldev(\n  fromObject: types.SafetySetting,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  if (common.getValueByPath(fromObject, ['method']) !== undefined) {\n    throw new Error('method parameter is not supported in Gemini API.');\n  }\n\n  const fromCategory = common.getValueByPath(fromObject, ['category']);\n  if (fromCategory != null) {\n    common.setValueByPath(toObject, ['category'], fromCategory);\n  }\n\n  const fromThreshold = common.getValueByPath(fromObject, ['threshold']);\n  if (fromThreshold != null) {\n    common.setValueByPath(toObject, ['threshold'], fromThreshold);\n  }\n\n  return toObject;\n}\n\nexport function scribbleImageToVertex(\n  fromObject: types.ScribbleImage,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromImage = common.getValueByPath(fromObject, ['image']);\n  if (fromImage != null) {\n    common.setValueByPath(toObject, ['image'], imageToVertex(fromImage));\n  }\n\n  return toObject;\n}\n\nexport function segmentImageConfigToVertex(\n  fromObject: types.SegmentImageConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromMode = common.getValueByPath(fromObject, ['mode']);\n  if (parentObject !== undefined && fromMode != null) {\n    common.setValueByPath(parentObject, ['parameters', 'mode'], fromMode);\n  }\n\n  const fromMaxPredictions = common.getValueByPath(fromObject, [\n    'maxPredictions',\n  ]);\n  if (parentObject !== undefined && fromMaxPredictions != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'maxPredictions'],\n      fromMaxPredictions,\n    );\n  }\n\n  const fromConfidenceThreshold = common.getValueByPath(fromObject, [\n    'confidenceThreshold',\n  ]);\n  if (parentObject !== undefined && fromConfidenceThreshold != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'confidenceThreshold'],\n      fromConfidenceThreshold,\n    );\n  }\n\n  const fromMaskDilation = common.getValueByPath(fromObject, ['maskDilation']);\n  if (parentObject !== undefined && fromMaskDilation != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'maskDilation'],\n      fromMaskDilation,\n    );\n  }\n\n  const fromBinaryColorThreshold = common.getValueByPath(fromObject, [\n    'binaryColorThreshold',\n  ]);\n  if (parentObject !== undefined && fromBinaryColorThreshold != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'binaryColorThreshold'],\n      fromBinaryColorThreshold,\n    );\n  }\n\n  const fromLabels = common.getValueByPath(fromObject, ['labels']);\n  if (parentObject !== undefined && fromLabels != null) {\n    common.setValueByPath(parentObject, ['labels'], fromLabels);\n  }\n\n  return toObject;\n}\n\nexport function segmentImageParametersToVertex(\n  apiClient: ApiClient,\n  fromObject: types.SegmentImageParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'model'],\n      t.tModel(apiClient, fromModel),\n    );\n  }\n\n  const fromSource = common.getValueByPath(fromObject, ['source']);\n  if (fromSource != null) {\n    segmentImageSourceToVertex(fromSource, toObject);\n  }\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    segmentImageConfigToVertex(fromConfig, toObject);\n  }\n\n  return toObject;\n}\n\nexport function segmentImageResponseFromVertex(\n  fromObject: types.SegmentImageResponse,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromGeneratedMasks = common.getValueByPath(fromObject, ['predictions']);\n  if (fromGeneratedMasks != null) {\n    let transformedList = fromGeneratedMasks;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return generatedImageMaskFromVertex(item);\n      });\n    }\n    common.setValueByPath(toObject, ['generatedMasks'], transformedList);\n  }\n\n  return toObject;\n}\n\nexport function segmentImageSourceToVertex(\n  fromObject: types.SegmentImageSource,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromPrompt = common.getValueByPath(fromObject, ['prompt']);\n  if (parentObject !== undefined && fromPrompt != null) {\n    common.setValueByPath(parentObject, ['instances[0]', 'prompt'], fromPrompt);\n  }\n\n  const fromImage = common.getValueByPath(fromObject, ['image']);\n  if (parentObject !== undefined && fromImage != null) {\n    common.setValueByPath(\n      parentObject,\n      ['instances[0]', 'image'],\n      imageToVertex(fromImage),\n    );\n  }\n\n  const fromScribbleImage = common.getValueByPath(fromObject, [\n    'scribbleImage',\n  ]);\n  if (parentObject !== undefined && fromScribbleImage != null) {\n    common.setValueByPath(\n      parentObject,\n      ['instances[0]', 'scribble'],\n      scribbleImageToVertex(fromScribbleImage),\n    );\n  }\n\n  return toObject;\n}\n\nexport function speechConfigToVertex(\n  fromObject: types.SpeechConfig,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromVoiceConfig = common.getValueByPath(fromObject, ['voiceConfig']);\n  if (fromVoiceConfig != null) {\n    common.setValueByPath(toObject, ['voiceConfig'], fromVoiceConfig);\n  }\n\n  if (\n    common.getValueByPath(fromObject, ['multiSpeakerVoiceConfig']) !== undefined\n  ) {\n    throw new Error(\n      'multiSpeakerVoiceConfig parameter is not supported in Vertex AI.',\n    );\n  }\n\n  const fromLanguageCode = common.getValueByPath(fromObject, ['languageCode']);\n  if (fromLanguageCode != null) {\n    common.setValueByPath(toObject, ['languageCode'], fromLanguageCode);\n  }\n\n  return toObject;\n}\n\nexport function toolToMldev(fromObject: types.Tool): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromFunctionDeclarations = common.getValueByPath(fromObject, [\n    'functionDeclarations',\n  ]);\n  if (fromFunctionDeclarations != null) {\n    let transformedList = fromFunctionDeclarations;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(toObject, ['functionDeclarations'], transformedList);\n  }\n\n  if (common.getValueByPath(fromObject, ['retrieval']) !== undefined) {\n    throw new Error('retrieval parameter is not supported in Gemini API.');\n  }\n\n  const fromGoogleSearch = common.getValueByPath(fromObject, ['googleSearch']);\n  if (fromGoogleSearch != null) {\n    common.setValueByPath(\n      toObject,\n      ['googleSearch'],\n      googleSearchToMldev(fromGoogleSearch),\n    );\n  }\n\n  const fromGoogleSearchRetrieval = common.getValueByPath(fromObject, [\n    'googleSearchRetrieval',\n  ]);\n  if (fromGoogleSearchRetrieval != null) {\n    common.setValueByPath(\n      toObject,\n      ['googleSearchRetrieval'],\n      fromGoogleSearchRetrieval,\n    );\n  }\n\n  if (\n    common.getValueByPath(fromObject, ['enterpriseWebSearch']) !== undefined\n  ) {\n    throw new Error(\n      'enterpriseWebSearch parameter is not supported in Gemini API.',\n    );\n  }\n\n  const fromGoogleMaps = common.getValueByPath(fromObject, ['googleMaps']);\n  if (fromGoogleMaps != null) {\n    common.setValueByPath(\n      toObject,\n      ['googleMaps'],\n      googleMapsToMldev(fromGoogleMaps),\n    );\n  }\n\n  const fromUrlContext = common.getValueByPath(fromObject, ['urlContext']);\n  if (fromUrlContext != null) {\n    common.setValueByPath(toObject, ['urlContext'], fromUrlContext);\n  }\n\n  const fromComputerUse = common.getValueByPath(fromObject, ['computerUse']);\n  if (fromComputerUse != null) {\n    common.setValueByPath(toObject, ['computerUse'], fromComputerUse);\n  }\n\n  const fromCodeExecution = common.getValueByPath(fromObject, [\n    'codeExecution',\n  ]);\n  if (fromCodeExecution != null) {\n    common.setValueByPath(toObject, ['codeExecution'], fromCodeExecution);\n  }\n\n  return toObject;\n}\n\nexport function toolToVertex(fromObject: types.Tool): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromFunctionDeclarations = common.getValueByPath(fromObject, [\n    'functionDeclarations',\n  ]);\n  if (fromFunctionDeclarations != null) {\n    let transformedList = fromFunctionDeclarations;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return functionDeclarationToVertex(item);\n      });\n    }\n    common.setValueByPath(toObject, ['functionDeclarations'], transformedList);\n  }\n\n  const fromRetrieval = common.getValueByPath(fromObject, ['retrieval']);\n  if (fromRetrieval != null) {\n    common.setValueByPath(toObject, ['retrieval'], fromRetrieval);\n  }\n\n  const fromGoogleSearch = common.getValueByPath(fromObject, ['googleSearch']);\n  if (fromGoogleSearch != null) {\n    common.setValueByPath(toObject, ['googleSearch'], fromGoogleSearch);\n  }\n\n  const fromGoogleSearchRetrieval = common.getValueByPath(fromObject, [\n    'googleSearchRetrieval',\n  ]);\n  if (fromGoogleSearchRetrieval != null) {\n    common.setValueByPath(\n      toObject,\n      ['googleSearchRetrieval'],\n      fromGoogleSearchRetrieval,\n    );\n  }\n\n  const fromEnterpriseWebSearch = common.getValueByPath(fromObject, [\n    'enterpriseWebSearch',\n  ]);\n  if (fromEnterpriseWebSearch != null) {\n    common.setValueByPath(\n      toObject,\n      ['enterpriseWebSearch'],\n      fromEnterpriseWebSearch,\n    );\n  }\n\n  const fromGoogleMaps = common.getValueByPath(fromObject, ['googleMaps']);\n  if (fromGoogleMaps != null) {\n    common.setValueByPath(toObject, ['googleMaps'], fromGoogleMaps);\n  }\n\n  const fromUrlContext = common.getValueByPath(fromObject, ['urlContext']);\n  if (fromUrlContext != null) {\n    common.setValueByPath(toObject, ['urlContext'], fromUrlContext);\n  }\n\n  const fromComputerUse = common.getValueByPath(fromObject, ['computerUse']);\n  if (fromComputerUse != null) {\n    common.setValueByPath(toObject, ['computerUse'], fromComputerUse);\n  }\n\n  const fromCodeExecution = common.getValueByPath(fromObject, [\n    'codeExecution',\n  ]);\n  if (fromCodeExecution != null) {\n    common.setValueByPath(toObject, ['codeExecution'], fromCodeExecution);\n  }\n\n  return toObject;\n}\n\nexport function tunedModelInfoFromMldev(\n  fromObject: types.TunedModelInfo,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromBaseModel = common.getValueByPath(fromObject, ['baseModel']);\n  if (fromBaseModel != null) {\n    common.setValueByPath(toObject, ['baseModel'], fromBaseModel);\n  }\n\n  const fromCreateTime = common.getValueByPath(fromObject, ['createTime']);\n  if (fromCreateTime != null) {\n    common.setValueByPath(toObject, ['createTime'], fromCreateTime);\n  }\n\n  const fromUpdateTime = common.getValueByPath(fromObject, ['updateTime']);\n  if (fromUpdateTime != null) {\n    common.setValueByPath(toObject, ['updateTime'], fromUpdateTime);\n  }\n\n  return toObject;\n}\n\nexport function tunedModelInfoFromVertex(\n  fromObject: types.TunedModelInfo,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromBaseModel = common.getValueByPath(fromObject, [\n    'labels',\n    'google-vertex-llm-tuning-base-model-id',\n  ]);\n  if (fromBaseModel != null) {\n    common.setValueByPath(toObject, ['baseModel'], fromBaseModel);\n  }\n\n  const fromCreateTime = common.getValueByPath(fromObject, ['createTime']);\n  if (fromCreateTime != null) {\n    common.setValueByPath(toObject, ['createTime'], fromCreateTime);\n  }\n\n  const fromUpdateTime = common.getValueByPath(fromObject, ['updateTime']);\n  if (fromUpdateTime != null) {\n    common.setValueByPath(toObject, ['updateTime'], fromUpdateTime);\n  }\n\n  return toObject;\n}\n\nexport function updateModelConfigToMldev(\n  fromObject: types.UpdateModelConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromDisplayName = common.getValueByPath(fromObject, ['displayName']);\n  if (parentObject !== undefined && fromDisplayName != null) {\n    common.setValueByPath(parentObject, ['displayName'], fromDisplayName);\n  }\n\n  const fromDescription = common.getValueByPath(fromObject, ['description']);\n  if (parentObject !== undefined && fromDescription != null) {\n    common.setValueByPath(parentObject, ['description'], fromDescription);\n  }\n\n  const fromDefaultCheckpointId = common.getValueByPath(fromObject, [\n    'defaultCheckpointId',\n  ]);\n  if (parentObject !== undefined && fromDefaultCheckpointId != null) {\n    common.setValueByPath(\n      parentObject,\n      ['defaultCheckpointId'],\n      fromDefaultCheckpointId,\n    );\n  }\n\n  return toObject;\n}\n\nexport function updateModelConfigToVertex(\n  fromObject: types.UpdateModelConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromDisplayName = common.getValueByPath(fromObject, ['displayName']);\n  if (parentObject !== undefined && fromDisplayName != null) {\n    common.setValueByPath(parentObject, ['displayName'], fromDisplayName);\n  }\n\n  const fromDescription = common.getValueByPath(fromObject, ['description']);\n  if (parentObject !== undefined && fromDescription != null) {\n    common.setValueByPath(parentObject, ['description'], fromDescription);\n  }\n\n  const fromDefaultCheckpointId = common.getValueByPath(fromObject, [\n    'defaultCheckpointId',\n  ]);\n  if (parentObject !== undefined && fromDefaultCheckpointId != null) {\n    common.setValueByPath(\n      parentObject,\n      ['defaultCheckpointId'],\n      fromDefaultCheckpointId,\n    );\n  }\n\n  return toObject;\n}\n\nexport function updateModelParametersToMldev(\n  apiClient: ApiClient,\n  fromObject: types.UpdateModelParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'name'],\n      t.tModel(apiClient, fromModel),\n    );\n  }\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    updateModelConfigToMldev(fromConfig, toObject);\n  }\n\n  return toObject;\n}\n\nexport function updateModelParametersToVertex(\n  apiClient: ApiClient,\n  fromObject: types.UpdateModelParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'model'],\n      t.tModel(apiClient, fromModel),\n    );\n  }\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    updateModelConfigToVertex(fromConfig, toObject);\n  }\n\n  return toObject;\n}\n\nexport function upscaleImageAPIConfigInternalToVertex(\n  fromObject: _internal_types.UpscaleImageAPIConfigInternal,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromOutputGcsUri = common.getValueByPath(fromObject, ['outputGcsUri']);\n  if (parentObject !== undefined && fromOutputGcsUri != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'storageUri'],\n      fromOutputGcsUri,\n    );\n  }\n\n  const fromIncludeRaiReason = common.getValueByPath(fromObject, [\n    'includeRaiReason',\n  ]);\n  if (parentObject !== undefined && fromIncludeRaiReason != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'includeRaiReason'],\n      fromIncludeRaiReason,\n    );\n  }\n\n  const fromOutputMimeType = common.getValueByPath(fromObject, [\n    'outputMimeType',\n  ]);\n  if (parentObject !== undefined && fromOutputMimeType != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'outputOptions', 'mimeType'],\n      fromOutputMimeType,\n    );\n  }\n\n  const fromOutputCompressionQuality = common.getValueByPath(fromObject, [\n    'outputCompressionQuality',\n  ]);\n  if (parentObject !== undefined && fromOutputCompressionQuality != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'outputOptions', 'compressionQuality'],\n      fromOutputCompressionQuality,\n    );\n  }\n\n  const fromEnhanceInputImage = common.getValueByPath(fromObject, [\n    'enhanceInputImage',\n  ]);\n  if (parentObject !== undefined && fromEnhanceInputImage != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'upscaleConfig', 'enhanceInputImage'],\n      fromEnhanceInputImage,\n    );\n  }\n\n  const fromImagePreservationFactor = common.getValueByPath(fromObject, [\n    'imagePreservationFactor',\n  ]);\n  if (parentObject !== undefined && fromImagePreservationFactor != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'upscaleConfig', 'imagePreservationFactor'],\n      fromImagePreservationFactor,\n    );\n  }\n\n  const fromLabels = common.getValueByPath(fromObject, ['labels']);\n  if (parentObject !== undefined && fromLabels != null) {\n    common.setValueByPath(parentObject, ['labels'], fromLabels);\n  }\n\n  const fromNumberOfImages = common.getValueByPath(fromObject, [\n    'numberOfImages',\n  ]);\n  if (parentObject !== undefined && fromNumberOfImages != null) {\n    common.setValueByPath(\n      parentObject,\n      ['parameters', 'sampleCount'],\n      fromNumberOfImages,\n    );\n  }\n\n  const fromMode = common.getValueByPath(fromObject, ['mode']);\n  if (parentObject !== undefined && fromMode != null) {\n    common.setValueByPath(parentObject, ['parameters', 'mode'], fromMode);\n  }\n\n  return toObject;\n}\n\nexport function upscaleImageAPIParametersInternalToVertex(\n  apiClient: ApiClient,\n  fromObject: _internal_types.UpscaleImageAPIParametersInternal,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(\n      toObject,\n      ['_url', 'model'],\n      t.tModel(apiClient, fromModel),\n    );\n  }\n\n  const fromImage = common.getValueByPath(fromObject, ['image']);\n  if (fromImage != null) {\n    common.setValueByPath(\n      toObject,\n      ['instances[0]', 'image'],\n      imageToVertex(fromImage),\n    );\n  }\n\n  const fromUpscaleFactor = common.getValueByPath(fromObject, [\n    'upscaleFactor',\n  ]);\n  if (fromUpscaleFactor != null) {\n    common.setValueByPath(\n      toObject,\n      ['parameters', 'upscaleConfig', 'upscaleFactor'],\n      fromUpscaleFactor,\n    );\n  }\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    upscaleImageAPIConfigInternalToVertex(fromConfig, toObject);\n  }\n\n  return toObject;\n}\n\nexport function upscaleImageResponseFromVertex(\n  fromObject: types.UpscaleImageResponse,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSdkHttpResponse = common.getValueByPath(fromObject, [\n    'sdkHttpResponse',\n  ]);\n  if (fromSdkHttpResponse != null) {\n    common.setValueByPath(toObject, ['sdkHttpResponse'], fromSdkHttpResponse);\n  }\n\n  const fromGeneratedImages = common.getValueByPath(fromObject, [\n    'predictions',\n  ]);\n  if (fromGeneratedImages != null) {\n    let transformedList = fromGeneratedImages;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return generatedImageFromVertex(item);\n      });\n    }\n    common.setValueByPath(toObject, ['generatedImages'], transformedList);\n  }\n\n  return toObject;\n}\n\nexport function videoFromMldev(\n  fromObject: types.Video,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromUri = common.getValueByPath(fromObject, ['uri']);\n  if (fromUri != null) {\n    common.setValueByPath(toObject, ['uri'], fromUri);\n  }\n\n  const fromVideoBytes = common.getValueByPath(fromObject, ['encodedVideo']);\n  if (fromVideoBytes != null) {\n    common.setValueByPath(toObject, ['videoBytes'], t.tBytes(fromVideoBytes));\n  }\n\n  const fromMimeType = common.getValueByPath(fromObject, ['encoding']);\n  if (fromMimeType != null) {\n    common.setValueByPath(toObject, ['mimeType'], fromMimeType);\n  }\n\n  return toObject;\n}\n\nexport function videoFromVertex(\n  fromObject: types.Video,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromUri = common.getValueByPath(fromObject, ['gcsUri']);\n  if (fromUri != null) {\n    common.setValueByPath(toObject, ['uri'], fromUri);\n  }\n\n  const fromVideoBytes = common.getValueByPath(fromObject, [\n    'bytesBase64Encoded',\n  ]);\n  if (fromVideoBytes != null) {\n    common.setValueByPath(toObject, ['videoBytes'], t.tBytes(fromVideoBytes));\n  }\n\n  const fromMimeType = common.getValueByPath(fromObject, ['mimeType']);\n  if (fromMimeType != null) {\n    common.setValueByPath(toObject, ['mimeType'], fromMimeType);\n  }\n\n  return toObject;\n}\n\nexport function videoGenerationMaskToVertex(\n  fromObject: types.VideoGenerationMask,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromImage = common.getValueByPath(fromObject, ['image']);\n  if (fromImage != null) {\n    common.setValueByPath(toObject, ['_self'], imageToVertex(fromImage));\n  }\n\n  const fromMaskMode = common.getValueByPath(fromObject, ['maskMode']);\n  if (fromMaskMode != null) {\n    common.setValueByPath(toObject, ['maskMode'], fromMaskMode);\n  }\n\n  return toObject;\n}\n\nexport function videoGenerationReferenceImageToMldev(\n  fromObject: types.VideoGenerationReferenceImage,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromImage = common.getValueByPath(fromObject, ['image']);\n  if (fromImage != null) {\n    common.setValueByPath(toObject, ['image'], imageToMldev(fromImage));\n  }\n\n  const fromReferenceType = common.getValueByPath(fromObject, [\n    'referenceType',\n  ]);\n  if (fromReferenceType != null) {\n    common.setValueByPath(toObject, ['referenceType'], fromReferenceType);\n  }\n\n  return toObject;\n}\n\nexport function videoGenerationReferenceImageToVertex(\n  fromObject: types.VideoGenerationReferenceImage,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromImage = common.getValueByPath(fromObject, ['image']);\n  if (fromImage != null) {\n    common.setValueByPath(toObject, ['image'], imageToVertex(fromImage));\n  }\n\n  const fromReferenceType = common.getValueByPath(fromObject, [\n    'referenceType',\n  ]);\n  if (fromReferenceType != null) {\n    common.setValueByPath(toObject, ['referenceType'], fromReferenceType);\n  }\n\n  return toObject;\n}\n\nexport function videoToMldev(fromObject: types.Video): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromUri = common.getValueByPath(fromObject, ['uri']);\n  if (fromUri != null) {\n    common.setValueByPath(toObject, ['uri'], fromUri);\n  }\n\n  const fromVideoBytes = common.getValueByPath(fromObject, ['videoBytes']);\n  if (fromVideoBytes != null) {\n    common.setValueByPath(toObject, ['encodedVideo'], t.tBytes(fromVideoBytes));\n  }\n\n  const fromMimeType = common.getValueByPath(fromObject, ['mimeType']);\n  if (fromMimeType != null) {\n    common.setValueByPath(toObject, ['encoding'], fromMimeType);\n  }\n\n  return toObject;\n}\n\nexport function videoToVertex(\n  fromObject: types.Video,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromUri = common.getValueByPath(fromObject, ['uri']);\n  if (fromUri != null) {\n    common.setValueByPath(toObject, ['gcsUri'], fromUri);\n  }\n\n  const fromVideoBytes = common.getValueByPath(fromObject, ['videoBytes']);\n  if (fromVideoBytes != null) {\n    common.setValueByPath(\n      toObject,\n      ['bytesBase64Encoded'],\n      t.tBytes(fromVideoBytes),\n    );\n  }\n\n  const fromMimeType = common.getValueByPath(fromObject, ['mimeType']);\n  if (fromMimeType != null) {\n    common.setValueByPath(toObject, ['mimeType'], fromMimeType);\n  }\n\n  return toObject;\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\nimport {Auth} from './_auth.js';\nimport * as common from './_common.js';\nimport {Downloader} from './_downloader.js';\nimport {Uploader} from './_uploader.js';\nimport {ApiError} from './errors.js';\nimport {\n  DownloadFileParameters,\n  File,\n  HttpOptions,\n  HttpResponse,\n  UploadFileConfig,\n} from './types.js';\n\nconst CONTENT_TYPE_HEADER = 'Content-Type';\nconst SERVER_TIMEOUT_HEADER = 'X-Server-Timeout';\nconst USER_AGENT_HEADER = 'User-Agent';\nexport const GOOGLE_API_CLIENT_HEADER = 'x-goog-api-client';\nexport const SDK_VERSION = '1.27.0'; // x-release-please-version\nconst LIBRARY_LABEL = `google-genai-sdk/${SDK_VERSION}`;\nconst VERTEX_AI_API_DEFAULT_VERSION = 'v1beta1';\nconst GOOGLE_AI_API_DEFAULT_VERSION = 'v1beta';\nconst responseLineRE = /^\\s*data: (.*)(?:\\n\\n|\\r\\r|\\r\\n\\r\\n)/;\n\n/**\n * Options for initializing the ApiClient. The ApiClient uses the parameters\n * for authentication purposes as well as to infer if SDK should send the\n * request to Vertex AI or Gemini API.\n */\nexport interface ApiClientInitOptions {\n  /**\n   * The object used for adding authentication headers to API requests.\n   */\n  auth: Auth;\n  /**\n   * The uploader to use for uploading files. This field is required for\n   * creating a client, will be set through the Node_client or Web_client.\n   */\n  uploader: Uploader;\n  /**\n   * Optional. The downloader to use for downloading files. This field is\n   * required for creating a client, will be set through the Node_client or\n   * Web_client.\n   */\n  downloader: Downloader;\n  /**\n   * Optional. The Google Cloud project ID for Vertex AI users.\n   * It is not the numeric project name.\n   * If not provided, SDK will try to resolve it from runtime environment.\n   */\n  project?: string;\n  /**\n   * Optional. The Google Cloud project location for Vertex AI users.\n   * If not provided, SDK will try to resolve it from runtime environment.\n   */\n  location?: string;\n  /**\n   * The API Key. This is required for Gemini API users.\n   */\n  apiKey?: string;\n  /**\n   * Optional. Set to true if you intend to call Vertex AI endpoints.\n   * If unset, default SDK behavior is to call Gemini API.\n   */\n  vertexai?: boolean;\n  /**\n   * Optional. The API version for the endpoint.\n   * If unset, SDK will choose a default api version.\n   */\n  apiVersion?: string;\n  /**\n   * Optional. A set of customizable configuration for HTTP requests.\n   */\n  httpOptions?: HttpOptions;\n  /**\n   * Optional. An extra string to append at the end of the User-Agent header.\n   *\n   * This can be used to e.g specify the runtime and its version.\n   */\n  userAgentExtra?: string;\n}\n\n/**\n * Represents the necessary information to send a request to an API endpoint.\n * This interface defines the structure for constructing and executing HTTP\n * requests.\n */\nexport interface HttpRequest {\n  /**\n   * URL path from the modules, this path is appended to the base API URL to\n   * form the complete request URL.\n   *\n   * If you wish to set full URL, use httpOptions.baseUrl instead. Example to\n   * set full URL in the request:\n   *\n   * const request: HttpRequest = {\n   *   path: '',\n   *   httpOptions: {\n   *     baseUrl: 'https://<custom-full-url>',\n   *     apiVersion: '',\n   *   },\n   *   httpMethod: 'GET',\n   * };\n   *\n   * The result URL will be: https://<custom-full-url>\n   *\n   */\n  path: string;\n  /**\n   * Optional query parameters to be appended to the request URL.\n   */\n  queryParams?: Record<string, string>;\n  /**\n   * Optional request body in json string or Blob format, GET request doesn't\n   * need a request body.\n   */\n  body?: string | Blob;\n  /**\n   * The HTTP method to be used for the request.\n   */\n  httpMethod: 'GET' | 'POST' | 'PATCH' | 'DELETE';\n  /**\n   * Optional set of customizable configuration for HTTP requests.\n   */\n  httpOptions?: HttpOptions;\n  /**\n   * Optional abort signal which can be used to cancel the request.\n   */\n  abortSignal?: AbortSignal;\n}\n\n/**\n * The ApiClient class is used to send requests to the Gemini API or Vertex AI\n * endpoints.\n */\nexport class ApiClient {\n  readonly clientOptions: ApiClientInitOptions;\n\n  constructor(opts: ApiClientInitOptions) {\n    this.clientOptions = {\n      ...opts,\n      project: opts.project,\n      location: opts.location,\n      apiKey: opts.apiKey,\n      vertexai: opts.vertexai,\n    };\n\n    const initHttpOptions: HttpOptions = {};\n\n    if (this.clientOptions.vertexai) {\n      initHttpOptions.apiVersion =\n        this.clientOptions.apiVersion ?? VERTEX_AI_API_DEFAULT_VERSION;\n      initHttpOptions.baseUrl = this.baseUrlFromProjectLocation();\n      this.normalizeAuthParameters();\n    } else {\n      // Gemini API\n      initHttpOptions.apiVersion =\n        this.clientOptions.apiVersion ?? GOOGLE_AI_API_DEFAULT_VERSION;\n      initHttpOptions.baseUrl = `https://generativelanguage.googleapis.com/`;\n    }\n\n    initHttpOptions.headers = this.getDefaultHeaders();\n\n    this.clientOptions.httpOptions = initHttpOptions;\n\n    if (opts.httpOptions) {\n      this.clientOptions.httpOptions = this.patchHttpOptions(\n        initHttpOptions,\n        opts.httpOptions,\n      );\n    }\n  }\n\n  /**\n   * Determines the base URL for Vertex AI based on project and location.\n   * Uses the global endpoint if location is 'global' or if project/location\n   * are not specified (implying API key usage).\n   * @private\n   */\n  private baseUrlFromProjectLocation(): string {\n    if (\n      this.clientOptions.project &&\n      this.clientOptions.location &&\n      this.clientOptions.location !== 'global'\n    ) {\n      // Regional endpoint\n      return `https://${this.clientOptions.location}-aiplatform.googleapis.com/`;\n    }\n    // Global endpoint (covers 'global' location and API key usage)\n    return `https://aiplatform.googleapis.com/`;\n  }\n\n  /**\n   * Normalizes authentication parameters for Vertex AI.\n   * If project and location are provided, API key is cleared.\n   * If project and location are not provided (implying API key usage),\n   * project and location are cleared.\n   * @private\n   */\n  private normalizeAuthParameters(): void {\n    if (this.clientOptions.project && this.clientOptions.location) {\n      // Using project/location for auth, clear potential API key\n      this.clientOptions.apiKey = undefined;\n      return;\n    }\n    // Using API key for auth (or no auth provided yet), clear project/location\n    this.clientOptions.project = undefined;\n    this.clientOptions.location = undefined;\n  }\n\n  isVertexAI(): boolean {\n    return this.clientOptions.vertexai ?? false;\n  }\n\n  getProject() {\n    return this.clientOptions.project;\n  }\n\n  getLocation() {\n    return this.clientOptions.location;\n  }\n\n  getApiVersion() {\n    if (\n      this.clientOptions.httpOptions &&\n      this.clientOptions.httpOptions.apiVersion !== undefined\n    ) {\n      return this.clientOptions.httpOptions.apiVersion;\n    }\n    throw new Error('API version is not set.');\n  }\n\n  getBaseUrl() {\n    if (\n      this.clientOptions.httpOptions &&\n      this.clientOptions.httpOptions.baseUrl !== undefined\n    ) {\n      return this.clientOptions.httpOptions.baseUrl;\n    }\n    throw new Error('Base URL is not set.');\n  }\n\n  getRequestUrl() {\n    return this.getRequestUrlInternal(this.clientOptions.httpOptions);\n  }\n\n  getHeaders() {\n    if (\n      this.clientOptions.httpOptions &&\n      this.clientOptions.httpOptions.headers !== undefined\n    ) {\n      return this.clientOptions.httpOptions.headers;\n    } else {\n      throw new Error('Headers are not set.');\n    }\n  }\n\n  private getRequestUrlInternal(httpOptions?: HttpOptions) {\n    if (\n      !httpOptions ||\n      httpOptions.baseUrl === undefined ||\n      httpOptions.apiVersion === undefined\n    ) {\n      throw new Error('HTTP options are not correctly set.');\n    }\n    const baseUrl = httpOptions.baseUrl.endsWith('/')\n      ? httpOptions.baseUrl.slice(0, -1)\n      : httpOptions.baseUrl;\n    const urlElement: Array<string> = [baseUrl];\n    if (httpOptions.apiVersion && httpOptions.apiVersion !== '') {\n      urlElement.push(httpOptions.apiVersion);\n    }\n    return urlElement.join('/');\n  }\n\n  getBaseResourcePath() {\n    return `projects/${this.clientOptions.project}/locations/${\n      this.clientOptions.location\n    }`;\n  }\n\n  getApiKey() {\n    return this.clientOptions.apiKey;\n  }\n\n  getWebsocketBaseUrl() {\n    const baseUrl = this.getBaseUrl();\n    const urlParts = new URL(baseUrl);\n    urlParts.protocol = urlParts.protocol == 'http:' ? 'ws' : 'wss';\n    return urlParts.toString();\n  }\n\n  setBaseUrl(url: string) {\n    if (this.clientOptions.httpOptions) {\n      this.clientOptions.httpOptions.baseUrl = url;\n    } else {\n      throw new Error('HTTP options are not correctly set.');\n    }\n  }\n\n  private constructUrl(\n    path: string,\n    httpOptions: HttpOptions,\n    prependProjectLocation: boolean,\n  ): URL {\n    const urlElement: Array<string> = [this.getRequestUrlInternal(httpOptions)];\n    if (prependProjectLocation) {\n      urlElement.push(this.getBaseResourcePath());\n    }\n    if (path !== '') {\n      urlElement.push(path);\n    }\n    const url = new URL(`${urlElement.join('/')}`);\n\n    return url;\n  }\n\n  private shouldPrependVertexProjectPath(request: HttpRequest): boolean {\n    if (this.clientOptions.apiKey) {\n      return false;\n    }\n    if (!this.clientOptions.vertexai) {\n      return false;\n    }\n    if (request.path.startsWith('projects/')) {\n      // Assume the path already starts with\n      // `projects/<project>/location/<location>`.\n      return false;\n    }\n    if (\n      request.httpMethod === 'GET' &&\n      request.path.startsWith('publishers/google/models')\n    ) {\n      // These paths are used by Vertex's models.get and models.list\n      // calls. For base models Vertex does not accept a project/location\n      // prefix (for tuned model the prefix is required).\n      return false;\n    }\n    return true;\n  }\n\n  async request(request: HttpRequest): Promise<HttpResponse> {\n    let patchedHttpOptions = this.clientOptions.httpOptions!;\n    if (request.httpOptions) {\n      patchedHttpOptions = this.patchHttpOptions(\n        this.clientOptions.httpOptions!,\n        request.httpOptions,\n      );\n    }\n\n    const prependProjectLocation = this.shouldPrependVertexProjectPath(request);\n    const url = this.constructUrl(\n      request.path,\n      patchedHttpOptions,\n      prependProjectLocation,\n    );\n    if (request.queryParams) {\n      for (const [key, value] of Object.entries(request.queryParams)) {\n        url.searchParams.append(key, String(value));\n      }\n    }\n    let requestInit: RequestInit = {};\n    if (request.httpMethod === 'GET') {\n      if (request.body && request.body !== '{}') {\n        throw new Error(\n          'Request body should be empty for GET request, but got non empty request body',\n        );\n      }\n    } else {\n      requestInit.body = request.body;\n    }\n    requestInit = await this.includeExtraHttpOptionsToRequestInit(\n      requestInit,\n      patchedHttpOptions,\n      url.toString(),\n      request.abortSignal,\n    );\n    return this.unaryApiCall(url, requestInit, request.httpMethod);\n  }\n\n  private patchHttpOptions(\n    baseHttpOptions: HttpOptions,\n    requestHttpOptions: HttpOptions,\n  ): HttpOptions {\n    const patchedHttpOptions = JSON.parse(\n      JSON.stringify(baseHttpOptions),\n    ) as HttpOptions;\n\n    for (const [key, value] of Object.entries(requestHttpOptions)) {\n      // Records compile to objects.\n      if (typeof value === 'object') {\n        // @ts-expect-error TS2345TS7053: Element implicitly has an 'any' type\n        // because expression of type 'string' can't be used to index type\n        // 'HttpOptions'.\n        patchedHttpOptions[key] = {...patchedHttpOptions[key], ...value};\n      } else if (value !== undefined) {\n        // @ts-expect-error TS2345TS7053: Element implicitly has an 'any' type\n        // because expression of type 'string' can't be used to index type\n        // 'HttpOptions'.\n        patchedHttpOptions[key] = value;\n      }\n    }\n    return patchedHttpOptions;\n  }\n\n  async requestStream(\n    request: HttpRequest,\n  ): Promise<AsyncGenerator<HttpResponse>> {\n    let patchedHttpOptions = this.clientOptions.httpOptions!;\n    if (request.httpOptions) {\n      patchedHttpOptions = this.patchHttpOptions(\n        this.clientOptions.httpOptions!,\n        request.httpOptions,\n      );\n    }\n\n    const prependProjectLocation = this.shouldPrependVertexProjectPath(request);\n    const url = this.constructUrl(\n      request.path,\n      patchedHttpOptions,\n      prependProjectLocation,\n    );\n    if (!url.searchParams.has('alt') || url.searchParams.get('alt') !== 'sse') {\n      url.searchParams.set('alt', 'sse');\n    }\n    let requestInit: RequestInit = {};\n    requestInit.body = request.body;\n    requestInit = await this.includeExtraHttpOptionsToRequestInit(\n      requestInit,\n      patchedHttpOptions,\n      url.toString(),\n      request.abortSignal,\n    );\n    return this.streamApiCall(url, requestInit, request.httpMethod);\n  }\n\n  private async includeExtraHttpOptionsToRequestInit(\n    requestInit: RequestInit,\n    httpOptions: HttpOptions,\n    url: string,\n    abortSignal?: AbortSignal,\n  ): Promise<RequestInit> {\n    if ((httpOptions && httpOptions.timeout) || abortSignal) {\n      const abortController = new AbortController();\n      const signal = abortController.signal;\n      if (httpOptions.timeout && httpOptions?.timeout > 0) {\n        const timeoutHandle = setTimeout(\n          () => abortController.abort(),\n          httpOptions.timeout,\n        );\n        if (\n          timeoutHandle &&\n          typeof (timeoutHandle as unknown as NodeJS.Timeout).unref ===\n            'function'\n        ) {\n          // call unref to prevent nodejs process from hanging, see\n          // https://nodejs.org/api/timers.html#timeoutunref\n          timeoutHandle.unref();\n        }\n      }\n      if (abortSignal) {\n        abortSignal.addEventListener('abort', () => {\n          abortController.abort();\n        });\n      }\n      requestInit.signal = signal;\n    }\n    if (httpOptions && httpOptions.extraBody !== null) {\n      includeExtraBodyToRequestInit(\n        requestInit,\n        httpOptions.extraBody as Record<string, unknown>,\n      );\n    }\n    requestInit.headers = await this.getHeadersInternal(httpOptions, url);\n    return requestInit;\n  }\n\n  private async unaryApiCall(\n    url: URL,\n    requestInit: RequestInit,\n    httpMethod: 'GET' | 'POST' | 'PATCH' | 'DELETE',\n  ): Promise<HttpResponse> {\n    return this.apiCall(url.toString(), {\n      ...requestInit,\n      method: httpMethod,\n    })\n      .then(async (response) => {\n        await throwErrorIfNotOK(response);\n        return new HttpResponse(response);\n      })\n      .catch((e) => {\n        if (e instanceof Error) {\n          throw e;\n        } else {\n          throw new Error(JSON.stringify(e));\n        }\n      });\n  }\n\n  private async streamApiCall(\n    url: URL,\n    requestInit: RequestInit,\n    httpMethod: 'GET' | 'POST' | 'PATCH' | 'DELETE',\n  ): Promise<AsyncGenerator<HttpResponse>> {\n    return this.apiCall(url.toString(), {\n      ...requestInit,\n      method: httpMethod,\n    })\n      .then(async (response) => {\n        await throwErrorIfNotOK(response);\n        return this.processStreamResponse(response);\n      })\n      .catch((e) => {\n        if (e instanceof Error) {\n          throw e;\n        } else {\n          throw new Error(JSON.stringify(e));\n        }\n      });\n  }\n\n  async *processStreamResponse(\n    response: Response,\n  ): AsyncGenerator<HttpResponse> {\n    const reader = response?.body?.getReader();\n    const decoder = new TextDecoder('utf-8');\n    if (!reader) {\n      throw new Error('Response body is empty');\n    }\n\n    try {\n      let buffer = '';\n      while (true) {\n        const {done, value} = await reader.read();\n        if (done) {\n          if (buffer.trim().length > 0) {\n            throw new Error('Incomplete JSON segment at the end');\n          }\n          break;\n        }\n        const chunkString = decoder.decode(value, {stream: true});\n\n        // Parse and throw an error if the chunk contains an error.\n        try {\n          const chunkJson = JSON.parse(chunkString) as Record<string, unknown>;\n          if ('error' in chunkJson) {\n            const errorJson = JSON.parse(\n              JSON.stringify(chunkJson['error']),\n            ) as Record<string, unknown>;\n            const status = errorJson['status'] as string;\n            const code = errorJson['code'] as number;\n            const errorMessage = `got status: ${status}. ${JSON.stringify(\n              chunkJson,\n            )}`;\n            if (code >= 400 && code < 600) {\n              const apiError = new ApiError({\n                message: errorMessage,\n                status: code,\n              });\n              throw apiError;\n            }\n          }\n        } catch (e: unknown) {\n          const error = e as Error;\n          if (error.name === 'ApiError') {\n            throw e;\n          }\n        }\n        buffer += chunkString;\n        let match = buffer.match(responseLineRE);\n        while (match) {\n          const processedChunkString = match[1];\n          try {\n            const partialResponse = new Response(processedChunkString, {\n              headers: response?.headers,\n              status: response?.status,\n              statusText: response?.statusText,\n            });\n            yield new HttpResponse(partialResponse);\n            buffer = buffer.slice(match[0].length);\n            match = buffer.match(responseLineRE);\n          } catch (e) {\n            throw new Error(\n              `exception parsing stream chunk ${processedChunkString}. ${e}`,\n            );\n          }\n        }\n      }\n    } finally {\n      reader.releaseLock();\n    }\n  }\n  private async apiCall(\n    url: string,\n    requestInit: RequestInit,\n  ): Promise<Response> {\n    return fetch(url, requestInit).catch((e) => {\n      throw new Error(`exception ${e} sending request`);\n    });\n  }\n\n  getDefaultHeaders(): Record<string, string> {\n    const headers: Record<string, string> = {};\n\n    const versionHeaderValue =\n      LIBRARY_LABEL + ' ' + this.clientOptions.userAgentExtra;\n\n    headers[USER_AGENT_HEADER] = versionHeaderValue;\n    headers[GOOGLE_API_CLIENT_HEADER] = versionHeaderValue;\n    headers[CONTENT_TYPE_HEADER] = 'application/json';\n\n    return headers;\n  }\n\n  private async getHeadersInternal(\n    httpOptions: HttpOptions | undefined,\n    url: string,\n  ): Promise<Headers> {\n    const headers = new Headers();\n    if (httpOptions && httpOptions.headers) {\n      for (const [key, value] of Object.entries(httpOptions.headers)) {\n        headers.append(key, value);\n      }\n      // Append a timeout header if it is set, note that the timeout option is\n      // in milliseconds but the header is in seconds.\n      if (httpOptions.timeout && httpOptions.timeout > 0) {\n        headers.append(\n          SERVER_TIMEOUT_HEADER,\n          String(Math.ceil(httpOptions.timeout / 1000)),\n        );\n      }\n    }\n    await this.clientOptions.auth.addAuthHeaders(headers, url);\n    return headers;\n  }\n\n  /**\n   * Uploads a file asynchronously using Gemini API only, this is not supported\n   * in Vertex AI.\n   *\n   * @param file The string path to the file to be uploaded or a Blob object.\n   * @param config Optional parameters specified in the `UploadFileConfig`\n   *     interface. @see {@link UploadFileConfig}\n   * @return A promise that resolves to a `File` object.\n   * @throws An error if called on a Vertex AI client.\n   * @throws An error if the `mimeType` is not provided and can not be inferred,\n   */\n  async uploadFile(\n    file: string | Blob,\n    config?: UploadFileConfig,\n  ): Promise<File> {\n    const fileToUpload: File = {};\n    if (config != null) {\n      fileToUpload.mimeType = config.mimeType;\n      fileToUpload.name = config.name;\n      fileToUpload.displayName = config.displayName;\n    }\n\n    if (fileToUpload.name && !fileToUpload.name.startsWith('files/')) {\n      fileToUpload.name = `files/${fileToUpload.name}`;\n    }\n\n    const uploader = this.clientOptions.uploader;\n    const fileStat = await uploader.stat(file);\n    fileToUpload.sizeBytes = String(fileStat.size);\n    const mimeType = config?.mimeType ?? fileStat.type;\n    if (mimeType === undefined || mimeType === '') {\n      throw new Error(\n        'Can not determine mimeType. Please provide mimeType in the config.',\n      );\n    }\n    fileToUpload.mimeType = mimeType;\n\n    const uploadUrl = await this.fetchUploadUrl(fileToUpload, config);\n    return uploader.upload(file, uploadUrl, this);\n  }\n\n  /**\n   * Downloads a file asynchronously to the specified path.\n   *\n   * @params params - The parameters for the download request, see {@link\n   * DownloadFileParameters}\n   */\n  async downloadFile(params: DownloadFileParameters): Promise<void> {\n    const downloader = this.clientOptions.downloader;\n    await downloader.download(params, this);\n  }\n\n  private async fetchUploadUrl(\n    file: File,\n    config?: UploadFileConfig,\n  ): Promise<string> {\n    let httpOptions: HttpOptions = {};\n    if (config?.httpOptions) {\n      httpOptions = config.httpOptions;\n    } else {\n      httpOptions = {\n        apiVersion: '', // api-version is set in the path.\n        headers: {\n          'Content-Type': 'application/json',\n          'X-Goog-Upload-Protocol': 'resumable',\n          'X-Goog-Upload-Command': 'start',\n          'X-Goog-Upload-Header-Content-Length': `${file.sizeBytes}`,\n          'X-Goog-Upload-Header-Content-Type': `${file.mimeType}`,\n        },\n      };\n    }\n\n    const body: Record<string, File> = {\n      'file': file,\n    };\n    const httpResponse = await this.request({\n      path: common.formatMap(\n        'upload/v1beta/files',\n        body['_url'] as Record<string, unknown>,\n      ),\n      body: JSON.stringify(body),\n      httpMethod: 'POST',\n      httpOptions,\n    });\n\n    if (!httpResponse || !httpResponse?.headers) {\n      throw new Error(\n        'Server did not return an HttpResponse or the returned HttpResponse did not have headers.',\n      );\n    }\n\n    const uploadUrl: string | undefined =\n      httpResponse?.headers?.['x-goog-upload-url'];\n    if (uploadUrl === undefined) {\n      throw new Error(\n        'Failed to get upload url. Server did not return the x-google-upload-url in the headers',\n      );\n    }\n    return uploadUrl;\n  }\n}\n\nasync function throwErrorIfNotOK(response: Response | undefined) {\n  if (response === undefined) {\n    throw new Error('response is undefined');\n  }\n  if (!response.ok) {\n    const status: number = response.status;\n    let errorBody: Record<string, unknown>;\n    if (response.headers.get('content-type')?.includes('application/json')) {\n      errorBody = await response.json();\n    } else {\n      errorBody = {\n        error: {\n          message: await response.text(),\n          code: response.status,\n          status: response.statusText,\n        },\n      };\n    }\n    const errorMessage = JSON.stringify(errorBody);\n    if (status >= 400 && status < 600) {\n      const apiError = new ApiError({\n        message: errorMessage,\n        status: status,\n      });\n      throw apiError;\n    }\n    throw new Error(errorMessage);\n  }\n}\n\n/**\n * Recursively updates the `requestInit.body` with values from an `extraBody` object.\n *\n * If `requestInit.body` is a string, it's assumed to be JSON and will be parsed.\n * The `extraBody` is then deeply merged into this parsed object.\n * If `requestInit.body` is a Blob, `extraBody` will be ignored, and a warning logged,\n * as merging structured data into an opaque Blob is not supported.\n *\n * The function does not enforce that updated values from `extraBody` have the\n * same type as existing values in `requestInit.body`. Type mismatches during\n * the merge will result in a warning, but the value from `extraBody` will overwrite\n * the original. `extraBody` users are responsible for ensuring `extraBody` has the correct structure.\n *\n * @param requestInit The RequestInit object whose body will be updated.\n * @param extraBody The object containing updates to be merged into `requestInit.body`.\n */\nexport function includeExtraBodyToRequestInit(\n  requestInit: RequestInit,\n  extraBody: Record<string, unknown>,\n) {\n  if (!extraBody || Object.keys(extraBody).length === 0) {\n    return;\n  }\n\n  if (requestInit.body instanceof Blob) {\n    console.warn(\n      'includeExtraBodyToRequestInit: extraBody provided but current request body is a Blob. extraBody will be ignored as merging is not supported for Blob bodies.',\n    );\n    return;\n  }\n\n  let currentBodyObject: Record<string, unknown> = {};\n\n  // If adding new type to HttpRequest.body, please check the code below to\n  // see if we need to update the logic.\n  if (typeof requestInit.body === 'string' && requestInit.body.length > 0) {\n    try {\n      const parsedBody = JSON.parse(requestInit.body);\n      if (\n        typeof parsedBody === 'object' &&\n        parsedBody !== null &&\n        !Array.isArray(parsedBody)\n      ) {\n        currentBodyObject = parsedBody as Record<string, unknown>;\n      } else {\n        console.warn(\n          'includeExtraBodyToRequestInit: Original request body is valid JSON but not a non-array object. Skip applying extraBody to the request body.',\n        );\n        return;\n      }\n      /*  eslint-disable-next-line @typescript-eslint/no-unused-vars */\n    } catch (e) {\n      console.warn(\n        'includeExtraBodyToRequestInit: Original request body is not valid JSON. Skip applying extraBody to the request body.',\n      );\n      return;\n    }\n  }\n\n  function deepMerge(\n    target: Record<string, unknown>,\n    source: Record<string, unknown>,\n  ): Record<string, unknown> {\n    const output = {...target};\n    for (const key in source) {\n      if (Object.prototype.hasOwnProperty.call(source, key)) {\n        const sourceValue = source[key];\n        const targetValue = output[key];\n        if (\n          sourceValue &&\n          typeof sourceValue === 'object' &&\n          !Array.isArray(sourceValue) &&\n          targetValue &&\n          typeof targetValue === 'object' &&\n          !Array.isArray(targetValue)\n        ) {\n          output[key] = deepMerge(\n            targetValue as Record<string, unknown>,\n            sourceValue as Record<string, unknown>,\n          );\n        } else {\n          if (\n            targetValue &&\n            sourceValue &&\n            typeof targetValue !== typeof sourceValue\n          ) {\n            console.warn(\n              `includeExtraBodyToRequestInit:deepMerge: Type mismatch for key \"${key}\". Original type: ${typeof targetValue}, New type: ${typeof sourceValue}. Overwriting.`,\n            );\n          }\n          output[key] = sourceValue;\n        }\n      }\n    }\n    return output;\n  }\n\n  const mergedBody = deepMerge(currentBodyObject, extraBody);\n  requestInit.body = JSON.stringify(mergedBody);\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\nimport type {Client as McpClient} from '@modelcontextprotocol/sdk/client/index.js';\nimport type {Tool as McpTool} from '@modelcontextprotocol/sdk/types.js';\n\nimport {GOOGLE_API_CLIENT_HEADER} from '../_api_client.js';\nimport {mcpToolsToGeminiTool} from '../_transformers.js';\nimport {\n  CallableTool,\n  CallableToolConfig,\n  FunctionCall,\n  Part,\n  Tool,\n  ToolListUnion,\n} from '../types.js';\n\n// TODO: b/416041229 - Determine how to retrieve the MCP package version.\nexport const MCP_LABEL = 'mcp_used/unknown';\n\n// Whether MCP tool usage is detected from mcpToTool. This is used for\n// telemetry.\nlet hasMcpToolUsageFromMcpToTool = false;\n\n// Checks whether the list of tools contains any MCP tools.\nexport function hasMcpToolUsage(tools: ToolListUnion): boolean {\n  for (const tool of tools) {\n    if (isMcpCallableTool(tool)) {\n      return true;\n    }\n    if (typeof tool === 'object' && 'inputSchema' in tool) {\n      return true;\n    }\n  }\n\n  return hasMcpToolUsageFromMcpToTool;\n}\n\n// Sets the MCP version label in the Google API client header.\nexport function setMcpUsageHeader(headers: Record<string, string>) {\n  const existingHeader = headers[GOOGLE_API_CLIENT_HEADER] ?? '';\n  headers[GOOGLE_API_CLIENT_HEADER] = (\n    existingHeader + ` ${MCP_LABEL}`\n  ).trimStart();\n}\n\n// Returns true if the object is a MCP CallableTool, otherwise false.\nfunction isMcpCallableTool(object: unknown): boolean {\n  return (\n    object !== null &&\n    typeof object === 'object' &&\n    object instanceof McpCallableTool\n  );\n}\n\n// List all tools from the MCP client.\nasync function* listAllTools(\n  mcpClient: McpClient,\n  maxTools: number = 100,\n): AsyncGenerator<McpTool> {\n  let cursor: string | undefined = undefined;\n  let numTools = 0;\n  while (numTools < maxTools) {\n    const t = await mcpClient.listTools({cursor});\n    for (const tool of t.tools) {\n      yield tool;\n      numTools++;\n    }\n    if (!t.nextCursor) {\n      break;\n    }\n    cursor = t.nextCursor;\n  }\n}\n\n/**\n * McpCallableTool can be used for model inference and invoking MCP clients with\n * given function call arguments.\n *\n * @experimental Built-in MCP support is an experimental feature, may change in future\n * versions.\n */\nexport class McpCallableTool implements CallableTool {\n  private readonly mcpClients;\n  private mcpTools: McpTool[] = [];\n  private functionNameToMcpClient: Record<string, McpClient> = {};\n  private readonly config: CallableToolConfig;\n\n  private constructor(\n    mcpClients: McpClient[] = [],\n    config: CallableToolConfig,\n  ) {\n    this.mcpClients = mcpClients;\n    this.config = config;\n  }\n\n  /**\n   * Creates a McpCallableTool.\n   */\n  public static create(\n    mcpClients: McpClient[],\n    config: CallableToolConfig,\n  ): McpCallableTool {\n    return new McpCallableTool(mcpClients, config);\n  }\n\n  /**\n   * Validates the function names are not duplicate and initialize the function\n   * name to MCP client mapping.\n   *\n   * @throws {Error} if the MCP tools from the MCP clients have duplicate tool\n   *     names.\n   */\n  async initialize() {\n    if (this.mcpTools.length > 0) {\n      return;\n    }\n\n    const functionMap: Record<string, McpClient> = {};\n    const mcpTools: McpTool[] = [];\n    for (const mcpClient of this.mcpClients) {\n      for await (const mcpTool of listAllTools(mcpClient)) {\n        mcpTools.push(mcpTool);\n        const mcpToolName = mcpTool.name as string;\n        if (functionMap[mcpToolName]) {\n          throw new Error(\n            `Duplicate function name ${\n              mcpToolName\n            } found in MCP tools. Please ensure function names are unique.`,\n          );\n        }\n        functionMap[mcpToolName] = mcpClient;\n      }\n    }\n    this.mcpTools = mcpTools;\n    this.functionNameToMcpClient = functionMap;\n  }\n\n  public async tool(): Promise<Tool> {\n    await this.initialize();\n    return mcpToolsToGeminiTool(this.mcpTools, this.config);\n  }\n\n  public async callTool(functionCalls: FunctionCall[]): Promise<Part[]> {\n    await this.initialize();\n    const functionCallResponseParts: Part[] = [];\n    for (const functionCall of functionCalls) {\n      if (functionCall.name! in this.functionNameToMcpClient) {\n        const mcpClient = this.functionNameToMcpClient[functionCall.name!];\n        let requestOptions = undefined;\n        // TODO: b/424238654 - Add support for finer grained timeout control.\n        if (this.config.timeout) {\n          requestOptions = {\n            timeout: this.config.timeout,\n          };\n        }\n        const callToolResponse = await mcpClient.callTool(\n          {\n            name: functionCall.name!,\n            arguments: functionCall.args,\n          },\n          // Set the result schema to undefined to allow MCP to rely on the\n          // default schema.\n          undefined,\n          requestOptions,\n        );\n        functionCallResponseParts.push({\n          functionResponse: {\n            name: functionCall.name,\n            response: callToolResponse.isError\n              ? {error: callToolResponse}\n              : (callToolResponse as Record<string, unknown>),\n          },\n        });\n      }\n    }\n    return functionCallResponseParts;\n  }\n}\n\nfunction isMcpClient(client: unknown): client is McpClient {\n  return (\n    client !== null &&\n    typeof client === 'object' &&\n    'listTools' in client &&\n    typeof client.listTools === 'function'\n  );\n}\n\n/**\n * Creates a McpCallableTool from MCP clients and an optional config.\n *\n * The callable tool can invoke the MCP clients with given function call\n * arguments. (often for automatic function calling).\n * Use the config to modify tool parameters such as behavior.\n *\n * @experimental Built-in MCP support is an experimental feature, may change in future\n * versions.\n */\nexport function mcpToTool(\n  ...args: [...McpClient[], CallableToolConfig | McpClient]\n): CallableTool {\n  // Set MCP usage for telemetry.\n  hasMcpToolUsageFromMcpToTool = true;\n  if (args.length === 0) {\n    throw new Error('No MCP clients provided');\n  }\n  const maybeConfig = args[args.length - 1];\n  if (isMcpClient(maybeConfig)) {\n    return McpCallableTool.create(args as McpClient[], {});\n  }\n  return McpCallableTool.create(\n    args.slice(0, args.length - 1) as McpClient[],\n    maybeConfig,\n  );\n}\n\n/**\n * Sets the MCP tool usage flag from calling mcpToTool. This is used for\n * telemetry.\n */\nexport function setMcpToolUsageFromMcpToTool(mcpToolUsage: boolean) {\n  hasMcpToolUsageFromMcpToTool = mcpToolUsage;\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\n/**\n * Live music client.\n *\n * @experimental\n */\n\nimport {ApiClient} from './_api_client.js';\nimport {Auth} from './_auth.js';\nimport * as t from './_transformers.js';\nimport {WebSocket, WebSocketCallbacks, WebSocketFactory} from './_websocket.js';\nimport * as converters from './converters/_live_converters.js';\nimport * as types from './types.js';\n\n/**\n * Handles incoming messages from the WebSocket.\n *\n * @remarks\n * This function is responsible for parsing incoming messages, transforming them\n * into LiveMusicServerMessage, and then calling the onmessage callback.\n * Note that the first message which is received from the server is a\n * setupComplete message.\n *\n * @param apiClient The ApiClient instance.\n * @param onmessage The user-provided onmessage callback (if any).\n * @param event The MessageEvent from the WebSocket.\n */\nasync function handleWebSocketMessage(\n  apiClient: ApiClient,\n  onmessage: (msg: types.LiveMusicServerMessage) => void,\n  event: MessageEvent,\n): Promise<void> {\n  const serverMessage: types.LiveMusicServerMessage =\n    new types.LiveMusicServerMessage();\n  let data: types.LiveMusicServerMessage;\n  if (event.data instanceof Blob) {\n    data = JSON.parse(await event.data.text()) as types.LiveMusicServerMessage;\n  } else {\n    data = JSON.parse(event.data) as types.LiveMusicServerMessage;\n  }\n  Object.assign(serverMessage, data);\n  onmessage(serverMessage);\n}\n\n/**\n   LiveMusic class encapsulates the configuration for live music\n   generation via Lyria Live models.\n\n   @experimental\n  */\nexport class LiveMusic {\n  constructor(\n    private readonly apiClient: ApiClient,\n    private readonly auth: Auth,\n    private readonly webSocketFactory: WebSocketFactory,\n  ) {}\n\n  /**\n     Establishes a connection to the specified model and returns a\n     LiveMusicSession object representing that connection.\n\n     @experimental\n\n     @remarks\n\n     @param params - The parameters for establishing a connection to the model.\n     @return A live session.\n\n     @example\n     ```ts\n     let model = 'models/lyria-realtime-exp';\n     const session = await ai.live.music.connect({\n       model: model,\n       callbacks: {\n         onmessage: (e: MessageEvent) => {\n           console.log('Received message from the server: %s\\n', debug(e.data));\n         },\n         onerror: (e: ErrorEvent) => {\n           console.log('Error occurred: %s\\n', debug(e.error));\n         },\n         onclose: (e: CloseEvent) => {\n           console.log('Connection closed.');\n         },\n       },\n     });\n     ```\n    */\n  async connect(\n    params: types.LiveMusicConnectParameters,\n  ): Promise<LiveMusicSession> {\n    if (this.apiClient.isVertexAI()) {\n      throw new Error('Live music is not supported for Vertex AI.');\n    }\n    console.warn(\n      'Live music generation is experimental and may change in future versions.',\n    );\n\n    const websocketBaseUrl = this.apiClient.getWebsocketBaseUrl();\n    const apiVersion = this.apiClient.getApiVersion();\n    const headers = mapToHeaders(this.apiClient.getDefaultHeaders());\n    const apiKey = this.apiClient.getApiKey();\n    const url = `${websocketBaseUrl}/ws/google.ai.generativelanguage.${\n      apiVersion\n    }.GenerativeService.BidiGenerateMusic?key=${apiKey}`;\n\n    let onopenResolve: (value: unknown) => void = () => {};\n    const onopenPromise = new Promise((resolve: (value: unknown) => void) => {\n      onopenResolve = resolve;\n    });\n\n    const callbacks: types.LiveMusicCallbacks = params.callbacks;\n\n    const onopenAwaitedCallback = function () {\n      onopenResolve({});\n    };\n\n    const apiClient = this.apiClient;\n    const websocketCallbacks: WebSocketCallbacks = {\n      onopen: onopenAwaitedCallback,\n      onmessage: (event: MessageEvent) => {\n        void handleWebSocketMessage(apiClient, callbacks.onmessage, event);\n      },\n      onerror:\n        callbacks?.onerror ??\n        function (e: ErrorEvent) {\n          void e;\n        },\n      onclose:\n        callbacks?.onclose ??\n        function (e: CloseEvent) {\n          void e;\n        },\n    };\n\n    const conn = this.webSocketFactory.create(\n      url,\n      headersToMap(headers),\n      websocketCallbacks,\n    );\n    conn.connect();\n    // Wait for the websocket to open before sending requests.\n    await onopenPromise;\n\n    const model = t.tModel(this.apiClient, params.model);\n    const setup = {model};\n    const clientMessage = {setup};\n    conn.send(JSON.stringify(clientMessage));\n\n    return new LiveMusicSession(conn, this.apiClient);\n  }\n}\n\n/**\n   Represents a connection to the API.\n\n   @experimental\n  */\nexport class LiveMusicSession {\n  constructor(\n    readonly conn: WebSocket,\n    private readonly apiClient: ApiClient,\n  ) {}\n\n  /**\n    Sets inputs to steer music generation. Updates the session's current\n    weighted prompts.\n\n    @param params - Contains one property, `weightedPrompts`.\n\n      - `weightedPrompts` to send to the model; weights are normalized to\n        sum to 1.0.\n\n    @experimental\n   */\n  async setWeightedPrompts(\n    params: types.LiveMusicSetWeightedPromptsParameters,\n  ) {\n    if (\n      !params.weightedPrompts ||\n      Object.keys(params.weightedPrompts).length === 0\n    ) {\n      throw new Error(\n        'Weighted prompts must be set and contain at least one entry.',\n      );\n    }\n    const clientContent =\n      converters.liveMusicSetWeightedPromptsParametersToMldev(params);\n    this.conn.send(JSON.stringify({clientContent}));\n  }\n\n  /**\n    Sets a configuration to the model. Updates the session's current\n    music generation config.\n\n    @param params - Contains one property, `musicGenerationConfig`.\n\n      - `musicGenerationConfig` to set in the model. Passing an empty or\n    undefined config to the model will reset the config to defaults.\n\n    @experimental\n   */\n  async setMusicGenerationConfig(params: types.LiveMusicSetConfigParameters) {\n    if (!params.musicGenerationConfig) {\n      params.musicGenerationConfig = {};\n    }\n    const setConfigParameters =\n      converters.liveMusicSetConfigParametersToMldev(params);\n    this.conn.send(JSON.stringify(setConfigParameters));\n  }\n\n  private sendPlaybackControl(playbackControl: types.LiveMusicPlaybackControl) {\n    const clientMessage = {playbackControl};\n    this.conn.send(JSON.stringify(clientMessage));\n  }\n\n  /**\n   * Start the music stream.\n   *\n   * @experimental\n   */\n  play() {\n    this.sendPlaybackControl(types.LiveMusicPlaybackControl.PLAY);\n  }\n\n  /**\n   * Temporarily halt the music stream. Use `play` to resume from the current\n   * position.\n   *\n   * @experimental\n   */\n  pause() {\n    this.sendPlaybackControl(types.LiveMusicPlaybackControl.PAUSE);\n  }\n\n  /**\n   * Stop the music stream and reset the state. Retains the current prompts\n   * and config.\n   *\n   * @experimental\n   */\n  stop() {\n    this.sendPlaybackControl(types.LiveMusicPlaybackControl.STOP);\n  }\n\n  /**\n   * Resets the context of the music generation without stopping it.\n   * Retains the current prompts and config.\n   *\n   * @experimental\n   */\n  resetContext() {\n    this.sendPlaybackControl(types.LiveMusicPlaybackControl.RESET_CONTEXT);\n  }\n\n  /**\n     Terminates the WebSocket connection.\n\n     @experimental\n   */\n  close() {\n    this.conn.close();\n  }\n}\n\n// Converts an headers object to a \"map\" object as expected by the WebSocket\n// constructor. We use this as the Auth interface works with Headers objects\n// while the WebSocket constructor takes a map.\nfunction headersToMap(headers: Headers): Record<string, string> {\n  const headerMap: Record<string, string> = {};\n  headers.forEach((value, key) => {\n    headerMap[key] = value;\n  });\n  return headerMap;\n}\n\n// Converts a \"map\" object to a headers object. We use this as the Auth\n// interface works with Headers objects while the API client default headers\n// returns a map.\nfunction mapToHeaders(map: Record<string, string>): Headers {\n  const headers = new Headers();\n  for (const [key, value] of Object.entries(map)) {\n    headers.append(key, value);\n  }\n  return headers;\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\n/**\n * Live client.\n *\n * @experimental\n */\n\nimport {ApiClient} from './_api_client.js';\nimport {Auth} from './_auth.js';\nimport * as t from './_transformers.js';\nimport {WebSocket, WebSocketCallbacks, WebSocketFactory} from './_websocket.js';\nimport * as converters from './converters/_live_converters.js';\nimport {contentToMldev} from './converters/_models_converters.js';\nimport {hasMcpToolUsage, setMcpUsageHeader} from './mcp/_mcp.js';\nimport {LiveMusic} from './music.js';\nimport * as types from './types.js';\n\nconst FUNCTION_RESPONSE_REQUIRES_ID =\n  'FunctionResponse request must have an `id` field from the response of a ToolCall.FunctionalCalls in Google AI.';\n\n/**\n * Handles incoming messages from the WebSocket.\n *\n * @remarks\n * This function is responsible for parsing incoming messages, transforming them\n * into LiveServerMessages, and then calling the onmessage callback. Note that\n * the first message which is received from the server is a setupComplete\n * message.\n *\n * @param apiClient The ApiClient instance.\n * @param onmessage The user-provided onmessage callback (if any).\n * @param event The MessageEvent from the WebSocket.\n */\nasync function handleWebSocketMessage(\n  apiClient: ApiClient,\n  onmessage: (msg: types.LiveServerMessage) => void,\n  event: MessageEvent,\n): Promise<void> {\n  const serverMessage: types.LiveServerMessage = new types.LiveServerMessage();\n  let jsonData: string;\n  if (event.data instanceof Blob) {\n    jsonData = await event.data.text();\n  } else if (event.data instanceof ArrayBuffer) {\n    jsonData = new TextDecoder().decode(event.data);\n  } else {\n    jsonData = event.data;\n  }\n\n  const data = JSON.parse(jsonData) as types.LiveServerMessage;\n\n  if (apiClient.isVertexAI()) {\n    const resp = converters.liveServerMessageFromVertex(data);\n    Object.assign(serverMessage, resp);\n  } else {\n    const resp = data;\n    Object.assign(serverMessage, resp);\n  }\n\n  onmessage(serverMessage);\n}\n\n/**\n   Live class encapsulates the configuration for live interaction with the\n   Generative Language API. It embeds ApiClient for general API settings.\n\n   @experimental\n  */\nexport class Live {\n  public readonly music: LiveMusic;\n\n  constructor(\n    private readonly apiClient: ApiClient,\n    private readonly auth: Auth,\n    private readonly webSocketFactory: WebSocketFactory,\n  ) {\n    this.music = new LiveMusic(\n      this.apiClient,\n      this.auth,\n      this.webSocketFactory,\n    );\n  }\n\n  /**\n     Establishes a connection to the specified model with the given\n     configuration and returns a Session object representing that connection.\n\n     @experimental Built-in MCP support is an experimental feature, may change in\n     future versions.\n\n     @remarks\n\n     @param params - The parameters for establishing a connection to the model.\n     @return A live session.\n\n     @example\n     ```ts\n     let model: string;\n     if (GOOGLE_GENAI_USE_VERTEXAI) {\n       model = 'gemini-2.0-flash-live-preview-04-09';\n     } else {\n       model = 'gemini-live-2.5-flash-preview';\n     }\n     const session = await ai.live.connect({\n       model: model,\n       config: {\n         responseModalities: [Modality.AUDIO],\n       },\n       callbacks: {\n         onopen: () => {\n           console.log('Connected to the socket.');\n         },\n         onmessage: (e: MessageEvent) => {\n           console.log('Received message from the server: %s\\n', debug(e.data));\n         },\n         onerror: (e: ErrorEvent) => {\n           console.log('Error occurred: %s\\n', debug(e.error));\n         },\n         onclose: (e: CloseEvent) => {\n           console.log('Connection closed.');\n         },\n       },\n     });\n     ```\n    */\n  async connect(params: types.LiveConnectParameters): Promise<Session> {\n    // TODO: b/404946746 - Support per request HTTP options.\n    if (params.config && params.config.httpOptions) {\n      throw new Error(\n        'The Live module does not support httpOptions at request-level in' +\n          ' LiveConnectConfig yet. Please use the client-level httpOptions' +\n          ' configuration instead.',\n      );\n    }\n    const websocketBaseUrl = this.apiClient.getWebsocketBaseUrl();\n    const apiVersion = this.apiClient.getApiVersion();\n    let url: string;\n    const clientHeaders = this.apiClient.getHeaders();\n    if (\n      params.config &&\n      params.config.tools &&\n      hasMcpToolUsage(params.config.tools)\n    ) {\n      setMcpUsageHeader(clientHeaders);\n    }\n    const headers = mapToHeaders(clientHeaders);\n    if (this.apiClient.isVertexAI()) {\n      url = `${websocketBaseUrl}/ws/google.cloud.aiplatform.${\n        apiVersion\n      }.LlmBidiService/BidiGenerateContent`;\n      await this.auth.addAuthHeaders(headers, url);\n    } else {\n      const apiKey = this.apiClient.getApiKey();\n\n      let method = 'BidiGenerateContent';\n      let keyName = 'key';\n      if (apiKey?.startsWith('auth_tokens/')) {\n        console.warn(\n          'Warning: Ephemeral token support is experimental and may change in future versions.',\n        );\n        if (apiVersion !== 'v1alpha') {\n          console.warn(\n            \"Warning: The SDK's ephemeral token support is in v1alpha only. Please use const ai = new GoogleGenAI({apiKey: token.name, httpOptions: { apiVersion: 'v1alpha' }}); before session connection.\",\n          );\n        }\n        method = 'BidiGenerateContentConstrained';\n        keyName = 'access_token';\n      }\n\n      url = `${websocketBaseUrl}/ws/google.ai.generativelanguage.${\n        apiVersion\n      }.GenerativeService.${method}?${keyName}=${apiKey}`;\n    }\n\n    let onopenResolve: (value: unknown) => void = () => {};\n    const onopenPromise = new Promise((resolve: (value: unknown) => void) => {\n      onopenResolve = resolve;\n    });\n\n    const callbacks: types.LiveCallbacks = params.callbacks;\n\n    const onopenAwaitedCallback = function () {\n      callbacks?.onopen?.();\n      onopenResolve({});\n    };\n\n    const apiClient = this.apiClient;\n\n    const websocketCallbacks: WebSocketCallbacks = {\n      onopen: onopenAwaitedCallback,\n      onmessage: (event: MessageEvent) => {\n        void handleWebSocketMessage(apiClient, callbacks.onmessage, event);\n      },\n      onerror:\n        callbacks?.onerror ??\n        function (e: ErrorEvent) {\n          void e;\n        },\n      onclose:\n        callbacks?.onclose ??\n        function (e: CloseEvent) {\n          void e;\n        },\n    };\n\n    const conn = this.webSocketFactory.create(\n      url,\n      headersToMap(headers),\n      websocketCallbacks,\n    );\n    conn.connect();\n    // Wait for the websocket to open before sending requests.\n    await onopenPromise;\n\n    let transformedModel = t.tModel(this.apiClient, params.model);\n    if (\n      this.apiClient.isVertexAI() &&\n      transformedModel.startsWith('publishers/')\n    ) {\n      const project = this.apiClient.getProject();\n      const location = this.apiClient.getLocation();\n      transformedModel =\n        `projects/${project}/locations/${location}/` + transformedModel;\n    }\n\n    let clientMessage: Record<string, unknown> = {};\n\n    if (\n      this.apiClient.isVertexAI() &&\n      params.config?.responseModalities === undefined\n    ) {\n      // Set default to AUDIO to align with MLDev API.\n      if (params.config === undefined) {\n        params.config = {responseModalities: [types.Modality.AUDIO]};\n      } else {\n        params.config.responseModalities = [types.Modality.AUDIO];\n      }\n    }\n    if (params.config?.generationConfig) {\n      // Raise deprecation warning for generationConfig.\n      console.warn(\n        'Setting `LiveConnectConfig.generation_config` is deprecated, please set the fields on `LiveConnectConfig` directly. This will become an error in a future version (not before Q3 2025).',\n      );\n    }\n    const inputTools = params.config?.tools ?? [];\n    const convertedTools: types.Tool[] = [];\n    for (const tool of inputTools) {\n      if (this.isCallableTool(tool)) {\n        const callableTool = tool as types.CallableTool;\n        convertedTools.push(await callableTool.tool());\n      } else {\n        convertedTools.push(tool as types.Tool);\n      }\n    }\n    if (convertedTools.length > 0) {\n      params.config!.tools = convertedTools;\n    }\n    const liveConnectParameters: types.LiveConnectParameters = {\n      model: transformedModel,\n      config: params.config,\n      callbacks: params.callbacks,\n    };\n    if (this.apiClient.isVertexAI()) {\n      clientMessage = converters.liveConnectParametersToVertex(\n        this.apiClient,\n        liveConnectParameters,\n      );\n    } else {\n      clientMessage = converters.liveConnectParametersToMldev(\n        this.apiClient,\n        liveConnectParameters,\n      );\n    }\n    delete clientMessage['config'];\n    conn.send(JSON.stringify(clientMessage));\n    return new Session(conn, this.apiClient);\n  }\n\n  // TODO: b/416041229 - Abstract this method to a common place.\n  private isCallableTool(tool: types.ToolUnion): boolean {\n    return 'callTool' in tool && typeof tool.callTool === 'function';\n  }\n}\n\nconst defaultLiveSendClientContentParamerters: types.LiveSendClientContentParameters =\n  {\n    turnComplete: true,\n  };\n\n/**\n   Represents a connection to the API.\n\n   @experimental\n  */\nexport class Session {\n  constructor(\n    readonly conn: WebSocket,\n    private readonly apiClient: ApiClient,\n  ) {}\n\n  private tLiveClientContent(\n    apiClient: ApiClient,\n    params: types.LiveSendClientContentParameters,\n  ): types.LiveClientMessage {\n    if (params.turns !== null && params.turns !== undefined) {\n      let contents: types.Content[] = [];\n      try {\n        contents = t.tContents(params.turns as types.ContentListUnion);\n        if (!apiClient.isVertexAI()) {\n          contents = contents.map((item) => contentToMldev(item));\n        }\n      } catch {\n        throw new Error(\n          `Failed to parse client content \"turns\", type: '${typeof params.turns}'`,\n        );\n      }\n      return {\n        clientContent: {turns: contents, turnComplete: params.turnComplete},\n      };\n    }\n\n    return {\n      clientContent: {turnComplete: params.turnComplete},\n    };\n  }\n\n  private tLiveClienttToolResponse(\n    apiClient: ApiClient,\n    params: types.LiveSendToolResponseParameters,\n  ): types.LiveClientMessage {\n    let functionResponses: types.FunctionResponse[] = [];\n\n    if (params.functionResponses == null) {\n      throw new Error('functionResponses is required.');\n    }\n\n    if (!Array.isArray(params.functionResponses)) {\n      functionResponses = [params.functionResponses];\n    } else {\n      functionResponses = params.functionResponses;\n    }\n\n    if (functionResponses.length === 0) {\n      throw new Error('functionResponses is required.');\n    }\n\n    for (const functionResponse of functionResponses) {\n      if (\n        typeof functionResponse !== 'object' ||\n        functionResponse === null ||\n        !('name' in functionResponse) ||\n        !('response' in functionResponse)\n      ) {\n        throw new Error(\n          `Could not parse function response, type '${typeof functionResponse}'.`,\n        );\n      }\n      if (!apiClient.isVertexAI() && !('id' in functionResponse)) {\n        throw new Error(FUNCTION_RESPONSE_REQUIRES_ID);\n      }\n    }\n\n    const clientMessage: types.LiveClientMessage = {\n      toolResponse: {functionResponses: functionResponses},\n    };\n    return clientMessage;\n  }\n\n  /**\n    Send a message over the established connection.\n\n    @param params - Contains two **optional** properties, `turns` and\n        `turnComplete`.\n\n      - `turns` will be converted to a `Content[]`\n      - `turnComplete: true` [default] indicates that you are done sending\n        content and expect a response. If `turnComplete: false`, the server\n        will wait for additional messages before starting generation.\n\n    @experimental\n\n    @remarks\n    There are two ways to send messages to the live API:\n    `sendClientContent` and `sendRealtimeInput`.\n\n    `sendClientContent` messages are added to the model context **in order**.\n    Having a conversation using `sendClientContent` messages is roughly\n    equivalent to using the `Chat.sendMessageStream`, except that the state of\n    the `chat` history is stored on the API server instead of locally.\n\n    Because of `sendClientContent`'s order guarantee, the model cannot respons\n    as quickly to `sendClientContent` messages as to `sendRealtimeInput`\n    messages. This makes the biggest difference when sending objects that have\n    significant preprocessing time (typically images).\n\n    The `sendClientContent` message sends a `Content[]`\n    which has more options than the `Blob` sent by `sendRealtimeInput`.\n\n    So the main use-cases for `sendClientContent` over `sendRealtimeInput` are:\n\n    - Sending anything that can't be represented as a `Blob` (text,\n    `sendClientContent({turns=\"Hello?\"}`)).\n    - Managing turns when not using audio input and voice activity detection.\n      (`sendClientContent({turnComplete:true})` or the short form\n    `sendClientContent()`)\n    - Prefilling a conversation context\n      ```\n      sendClientContent({\n          turns: [\n            Content({role:user, parts:...}),\n            Content({role:user, parts:...}),\n            ...\n          ]\n      })\n      ```\n    @experimental\n   */\n  sendClientContent(params: types.LiveSendClientContentParameters) {\n    params = {\n      ...defaultLiveSendClientContentParamerters,\n      ...params,\n    };\n\n    const clientMessage: types.LiveClientMessage = this.tLiveClientContent(\n      this.apiClient,\n      params,\n    );\n    this.conn.send(JSON.stringify(clientMessage));\n  }\n\n  /**\n    Send a realtime message over the established connection.\n\n    @param params - Contains one property, `media`.\n\n      - `media` will be converted to a `Blob`\n\n    @experimental\n\n    @remarks\n    Use `sendRealtimeInput` for realtime audio chunks and video frames (images).\n\n    With `sendRealtimeInput` the api will respond to audio automatically\n    based on voice activity detection (VAD).\n\n    `sendRealtimeInput` is optimized for responsivness at the expense of\n    deterministic ordering guarantees. Audio and video tokens are to the\n    context when they become available.\n\n    Note: The Call signature expects a `Blob` object, but only a subset\n    of audio and image mimetypes are allowed.\n   */\n  sendRealtimeInput(params: types.LiveSendRealtimeInputParameters) {\n    let clientMessage: types.LiveClientMessage = {};\n\n    if (this.apiClient.isVertexAI()) {\n      clientMessage = {\n        'realtimeInput':\n          converters.liveSendRealtimeInputParametersToVertex(params),\n      };\n    } else {\n      clientMessage = {\n        'realtimeInput':\n          converters.liveSendRealtimeInputParametersToMldev(params),\n      };\n    }\n    this.conn.send(JSON.stringify(clientMessage));\n  }\n\n  /**\n    Send a function response message over the established connection.\n\n    @param params - Contains property `functionResponses`.\n\n      - `functionResponses` will be converted to a `functionResponses[]`\n\n    @remarks\n    Use `sendFunctionResponse` to reply to `LiveServerToolCall` from the server.\n\n    Use {@link types.LiveConnectConfig#tools} to configure the callable functions.\n\n    @experimental\n   */\n  sendToolResponse(params: types.LiveSendToolResponseParameters) {\n    if (params.functionResponses == null) {\n      throw new Error('Tool response parameters are required.');\n    }\n\n    const clientMessage: types.LiveClientMessage =\n      this.tLiveClienttToolResponse(this.apiClient, params);\n    this.conn.send(JSON.stringify(clientMessage));\n  }\n\n  /**\n     Terminates the WebSocket connection.\n\n     @experimental\n\n     @example\n     ```ts\n     let model: string;\n     if (GOOGLE_GENAI_USE_VERTEXAI) {\n       model = 'gemini-2.0-flash-live-preview-04-09';\n     } else {\n       model = 'gemini-live-2.5-flash-preview';\n     }\n     const session = await ai.live.connect({\n       model: model,\n       config: {\n         responseModalities: [Modality.AUDIO],\n       }\n     });\n\n     session.close();\n     ```\n   */\n  close() {\n    this.conn.close();\n  }\n}\n\n// Converts an headers object to a \"map\" object as expected by the WebSocket\n// constructor. We use this as the Auth interface works with Headers objects\n// while the WebSocket constructor takes a map.\nfunction headersToMap(headers: Headers): Record<string, string> {\n  const headerMap: Record<string, string> = {};\n  headers.forEach((value, key) => {\n    headerMap[key] = value;\n  });\n  return headerMap;\n}\n\n// Converts a \"map\" object to a headers object. We use this as the Auth\n// interface works with Headers objects while the API client default headers\n// returns a map.\nfunction mapToHeaders(map: Record<string, string>): Headers {\n  const headers = new Headers();\n  for (const [key, value] of Object.entries(map)) {\n    headers.append(key, value);\n  }\n  return headers;\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\nimport * as types from './types.js';\n\nexport const DEFAULT_MAX_REMOTE_CALLS = 10;\n\n/** Returns whether automatic function calling is disabled. */\nexport function shouldDisableAfc(\n  config: types.GenerateContentConfig | undefined,\n): boolean {\n  if (config?.automaticFunctionCalling?.disable) {\n    return true;\n  }\n\n  let callableToolsPresent = false;\n  for (const tool of config?.tools ?? []) {\n    if (isCallableTool(tool)) {\n      callableToolsPresent = true;\n      break;\n    }\n  }\n  if (!callableToolsPresent) {\n    return true;\n  }\n\n  const maxCalls = config?.automaticFunctionCalling?.maximumRemoteCalls;\n  if (\n    (maxCalls && (maxCalls < 0 || !Number.isInteger(maxCalls))) ||\n    maxCalls == 0\n  ) {\n    console.warn(\n      'Invalid maximumRemoteCalls value provided for automatic function calling. Disabled automatic function calling. Please provide a valid integer value greater than 0. maximumRemoteCalls provided:',\n      maxCalls,\n    );\n    return true;\n  }\n  return false;\n}\n\nexport function isCallableTool(tool: types.ToolUnion): boolean {\n  return 'callTool' in tool && typeof tool.callTool === 'function';\n}\n\n// Checks whether the list of tools contains any CallableTools. Will return true\n// if there is at least one CallableTool.\nexport function hasCallableTools(\n  params: types.GenerateContentParameters,\n): boolean {\n  return params.config?.tools?.some((tool) => isCallableTool(tool)) ?? false;\n}\n\n// Checks whether the list of tools contains any non-callable tools. Will return\n// true if there is at least one non-Callable tool.\nexport function hasNonCallableTools(\n  params: types.GenerateContentParameters,\n): boolean {\n  return params.config?.tools?.some((tool) => !isCallableTool(tool)) ?? false;\n}\n\n/**\n * Returns whether to append automatic function calling history to the\n * response.\n */\nexport function shouldAppendAfcHistory(\n  config: types.GenerateContentConfig | undefined,\n): boolean {\n  return !config?.automaticFunctionCalling?.ignoreCallHistory;\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\n// Code generated by the Google Gen AI SDK generator DO NOT EDIT.\n\nimport {\n  DEFAULT_MAX_REMOTE_CALLS,\n  hasCallableTools,\n  hasNonCallableTools,\n  isCallableTool,\n  shouldAppendAfcHistory,\n  shouldDisableAfc,\n} from './_afc.js';\nimport {ApiClient} from './_api_client.js';\nimport * as common from './_common.js';\nimport {BaseModule} from './_common.js';\nimport * as _internal_types from './_internal_types.js';\nimport {tContents} from './_transformers.js';\nimport * as converters from './converters/_models_converters.js';\nimport {hasMcpToolUsage, setMcpUsageHeader} from './mcp/_mcp.js';\nimport {PagedItem, Pager} from './pagers.js';\nimport * as types from './types.js';\n\nexport class Models extends BaseModule {\n  constructor(private readonly apiClient: ApiClient) {\n    super();\n  }\n\n  /**\n   * Makes an API request to generate content with a given model.\n   *\n   * For the `model` parameter, supported formats for Vertex AI API include:\n   * - The Gemini model ID, for example: 'gemini-2.0-flash'\n   * - The full resource name starts with 'projects/', for example:\n   *  'projects/my-project-id/locations/us-central1/publishers/google/models/gemini-2.0-flash'\n   * - The partial resource name with 'publishers/', for example:\n   *  'publishers/google/models/gemini-2.0-flash' or\n   *  'publishers/meta/models/llama-3.1-405b-instruct-maas'\n   * - `/` separated publisher and model name, for example:\n   * 'google/gemini-2.0-flash' or 'meta/llama-3.1-405b-instruct-maas'\n   *\n   * For the `model` parameter, supported formats for Gemini API include:\n   * - The Gemini model ID, for example: 'gemini-2.0-flash'\n   * - The model name starts with 'models/', for example:\n   *  'models/gemini-2.0-flash'\n   * - For tuned models, the model name starts with 'tunedModels/',\n   * for example:\n   * 'tunedModels/1234567890123456789'\n   *\n   * Some models support multimodal input and output.\n   *\n   * @param params - The parameters for generating content.\n   * @return The response from generating content.\n   *\n   * @example\n   * ```ts\n   * const response = await ai.models.generateContent({\n   *   model: 'gemini-2.0-flash',\n   *   contents: 'why is the sky blue?',\n   *   config: {\n   *     candidateCount: 2,\n   *   }\n   * });\n   * console.log(response);\n   * ```\n   */\n  generateContent = async (\n    params: types.GenerateContentParameters,\n  ): Promise<types.GenerateContentResponse> => {\n    const transformedParams = await this.processParamsMaybeAddMcpUsage(params);\n    this.maybeMoveToResponseJsonSchem(params);\n    if (!hasCallableTools(params) || shouldDisableAfc(params.config)) {\n      return await this.generateContentInternal(transformedParams);\n    }\n\n    if (hasNonCallableTools(params)) {\n      throw new Error(\n        'Automatic function calling with CallableTools and Tools is not yet supported.',\n      );\n    }\n\n    let response: types.GenerateContentResponse;\n    let functionResponseContent: types.Content;\n    const automaticFunctionCallingHistory: types.Content[] = tContents(\n      transformedParams.contents,\n    );\n    const maxRemoteCalls =\n      transformedParams.config?.automaticFunctionCalling?.maximumRemoteCalls ??\n      DEFAULT_MAX_REMOTE_CALLS;\n    let remoteCalls = 0;\n    while (remoteCalls < maxRemoteCalls) {\n      response = await this.generateContentInternal(transformedParams);\n      if (!response.functionCalls || response.functionCalls!.length === 0) {\n        break;\n      }\n\n      const responseContent: types.Content = response.candidates![0].content!;\n      const functionResponseParts: types.Part[] = [];\n      for (const tool of params.config?.tools ?? []) {\n        if (isCallableTool(tool)) {\n          const callableTool = tool as types.CallableTool;\n          const parts = await callableTool.callTool(response.functionCalls!);\n          functionResponseParts.push(...parts);\n        }\n      }\n\n      remoteCalls++;\n\n      functionResponseContent = {\n        role: 'user',\n        parts: functionResponseParts,\n      };\n\n      transformedParams.contents = tContents(transformedParams.contents);\n      (transformedParams.contents as types.Content[]).push(responseContent);\n      (transformedParams.contents as types.Content[]).push(\n        functionResponseContent,\n      );\n\n      if (shouldAppendAfcHistory(transformedParams.config)) {\n        automaticFunctionCallingHistory.push(responseContent);\n        automaticFunctionCallingHistory.push(functionResponseContent);\n      }\n    }\n    if (shouldAppendAfcHistory(transformedParams.config)) {\n      response!.automaticFunctionCallingHistory =\n        automaticFunctionCallingHistory;\n    }\n    return response!;\n  };\n\n  /**\n   * This logic is needed for GenerateContentConfig only.\n   * Previously we made GenerateContentConfig.responseSchema field to accept\n   * unknown. Since v1.9.0, we switch to use backend JSON schema support.\n   * To maintain backward compatibility, we move the data that was treated as\n   * JSON schema from the responseSchema field to the responseJsonSchema field.\n   */\n  private maybeMoveToResponseJsonSchem(\n    params: types.GenerateContentParameters,\n  ): void {\n    if (params.config && params.config.responseSchema) {\n      if (!params.config.responseJsonSchema) {\n        if (Object.keys(params.config.responseSchema).includes('$schema')) {\n          params.config.responseJsonSchema = params.config.responseSchema;\n          delete params.config.responseSchema;\n        }\n      }\n    }\n    return;\n  }\n\n  /**\n   * Makes an API request to generate content with a given model and yields the\n   * response in chunks.\n   *\n   * For the `model` parameter, supported formats for Vertex AI API include:\n   * - The Gemini model ID, for example: 'gemini-2.0-flash'\n   * - The full resource name starts with 'projects/', for example:\n   *  'projects/my-project-id/locations/us-central1/publishers/google/models/gemini-2.0-flash'\n   * - The partial resource name with 'publishers/', for example:\n   *  'publishers/google/models/gemini-2.0-flash' or\n   *  'publishers/meta/models/llama-3.1-405b-instruct-maas'\n   * - `/` separated publisher and model name, for example:\n   * 'google/gemini-2.0-flash' or 'meta/llama-3.1-405b-instruct-maas'\n   *\n   * For the `model` parameter, supported formats for Gemini API include:\n   * - The Gemini model ID, for example: 'gemini-2.0-flash'\n   * - The model name starts with 'models/', for example:\n   *  'models/gemini-2.0-flash'\n   * - For tuned models, the model name starts with 'tunedModels/',\n   * for example:\n   *  'tunedModels/1234567890123456789'\n   *\n   * Some models support multimodal input and output.\n   *\n   * @param params - The parameters for generating content with streaming response.\n   * @return The response from generating content.\n   *\n   * @example\n   * ```ts\n   * const response = await ai.models.generateContentStream({\n   *   model: 'gemini-2.0-flash',\n   *   contents: 'why is the sky blue?',\n   *   config: {\n   *     maxOutputTokens: 200,\n   *   }\n   * });\n   * for await (const chunk of response) {\n   *   console.log(chunk);\n   * }\n   * ```\n   */\n  generateContentStream = async (\n    params: types.GenerateContentParameters,\n  ): Promise<AsyncGenerator<types.GenerateContentResponse>> => {\n    this.maybeMoveToResponseJsonSchem(params);\n    if (shouldDisableAfc(params.config)) {\n      const transformedParams =\n        await this.processParamsMaybeAddMcpUsage(params);\n      return await this.generateContentStreamInternal(transformedParams);\n    } else {\n      return await this.processAfcStream(params);\n    }\n  };\n\n  /**\n   * Transforms the CallableTools in the parameters to be simply Tools, it\n   * copies the params into a new object and replaces the tools, it does not\n   * modify the original params. Also sets the MCP usage header if there are\n   * MCP tools in the parameters.\n   */\n  private async processParamsMaybeAddMcpUsage(\n    params: types.GenerateContentParameters,\n  ): Promise<types.GenerateContentParameters> {\n    const tools = params.config?.tools;\n    if (!tools) {\n      return params;\n    }\n    const transformedTools = await Promise.all(\n      tools.map(async (tool) => {\n        if (isCallableTool(tool)) {\n          const callableTool = tool as types.CallableTool;\n          return await callableTool.tool();\n        }\n        return tool;\n      }),\n    );\n    const newParams: types.GenerateContentParameters = {\n      model: params.model,\n      contents: params.contents,\n      config: {\n        ...params.config,\n        tools: transformedTools,\n      },\n    };\n    newParams.config!.tools = transformedTools;\n\n    if (\n      params.config &&\n      params.config.tools &&\n      hasMcpToolUsage(params.config.tools)\n    ) {\n      const headers = params.config.httpOptions?.headers ?? {};\n      let newHeaders = {...headers};\n      if (Object.keys(newHeaders).length === 0) {\n        newHeaders = this.apiClient.getDefaultHeaders();\n      }\n      setMcpUsageHeader(newHeaders);\n      newParams.config!.httpOptions = {\n        ...params.config.httpOptions,\n        headers: newHeaders,\n      };\n    }\n    return newParams;\n  }\n\n  private async initAfcToolsMap(\n    params: types.GenerateContentParameters,\n  ): Promise<Map<string, types.CallableTool>> {\n    const afcTools: Map<string, types.CallableTool> = new Map();\n    for (const tool of params.config?.tools ?? []) {\n      if (isCallableTool(tool)) {\n        const callableTool = tool as types.CallableTool;\n        const toolDeclaration = await callableTool.tool();\n        for (const declaration of toolDeclaration.functionDeclarations ?? []) {\n          if (!declaration.name) {\n            throw new Error('Function declaration name is required.');\n          }\n          if (afcTools.has(declaration.name)) {\n            throw new Error(\n              `Duplicate tool declaration name: ${declaration.name}`,\n            );\n          }\n          afcTools.set(declaration.name, callableTool);\n        }\n      }\n    }\n    return afcTools;\n  }\n\n  private async processAfcStream(\n    params: types.GenerateContentParameters,\n  ): Promise<AsyncGenerator<types.GenerateContentResponse>> {\n    const maxRemoteCalls =\n      params.config?.automaticFunctionCalling?.maximumRemoteCalls ??\n      DEFAULT_MAX_REMOTE_CALLS;\n    let wereFunctionsCalled = false;\n    let remoteCallCount = 0;\n    const afcToolsMap = await this.initAfcToolsMap(params);\n    return (async function* (\n      models: Models,\n      afcTools: Map<string, types.CallableTool>,\n      params: types.GenerateContentParameters,\n    ) {\n      while (remoteCallCount < maxRemoteCalls) {\n        if (wereFunctionsCalled) {\n          remoteCallCount++;\n          wereFunctionsCalled = false;\n        }\n        const transformedParams =\n          await models.processParamsMaybeAddMcpUsage(params);\n        const response =\n          await models.generateContentStreamInternal(transformedParams);\n\n        const functionResponses: types.Part[] = [];\n        const responseContents: types.Content[] = [];\n\n        for await (const chunk of response) {\n          yield chunk;\n          if (chunk.candidates && chunk.candidates[0]?.content) {\n            responseContents.push(chunk.candidates[0].content);\n            for (const part of chunk.candidates[0].content.parts ?? []) {\n              if (remoteCallCount < maxRemoteCalls && part.functionCall) {\n                if (!part.functionCall.name) {\n                  throw new Error(\n                    'Function call name was not returned by the model.',\n                  );\n                }\n                if (!afcTools.has(part.functionCall.name)) {\n                  throw new Error(\n                    `Automatic function calling was requested, but not all the tools the model used implement the CallableTool interface. Available tools: ${afcTools.keys()}, mising tool: ${\n                      part.functionCall.name\n                    }`,\n                  );\n                } else {\n                  const responseParts = await afcTools\n                    .get(part.functionCall.name)!\n                    .callTool([part.functionCall]);\n                  functionResponses.push(...responseParts);\n                }\n              }\n            }\n          }\n        }\n\n        if (functionResponses.length > 0) {\n          wereFunctionsCalled = true;\n          const typedResponseChunk = new types.GenerateContentResponse();\n          typedResponseChunk.candidates = [\n            {\n              content: {\n                role: 'user',\n                parts: functionResponses,\n              },\n            },\n          ];\n\n          yield typedResponseChunk;\n\n          const newContents: types.Content[] = [];\n          newContents.push(...responseContents);\n          newContents.push({\n            role: 'user',\n            parts: functionResponses,\n          });\n          const updatedContents = tContents(params.contents).concat(\n            newContents,\n          );\n\n          params.contents = updatedContents;\n        } else {\n          break;\n        }\n      }\n    })(this, afcToolsMap, params);\n  }\n\n  /**\n   * Generates an image based on a text description and configuration.\n   *\n   * @param params - The parameters for generating images.\n   * @return The response from the API.\n   *\n   * @example\n   * ```ts\n   * const response = await client.models.generateImages({\n   *  model: 'imagen-3.0-generate-002',\n   *  prompt: 'Robot holding a red skateboard',\n   *  config: {\n   *    numberOfImages: 1,\n   *    includeRaiReason: true,\n   *  },\n   * });\n   * console.log(response?.generatedImages?.[0]?.image?.imageBytes);\n   * ```\n   */\n  generateImages = async (\n    params: types.GenerateImagesParameters,\n  ): Promise<types.GenerateImagesResponse> => {\n    return await this.generateImagesInternal(params).then((apiResponse) => {\n      let positivePromptSafetyAttributes;\n      const generatedImages = [];\n\n      if (apiResponse?.generatedImages) {\n        for (const generatedImage of apiResponse.generatedImages) {\n          if (\n            generatedImage &&\n            generatedImage?.safetyAttributes &&\n            generatedImage?.safetyAttributes?.contentType === 'Positive Prompt'\n          ) {\n            positivePromptSafetyAttributes = generatedImage?.safetyAttributes;\n          } else {\n            generatedImages.push(generatedImage);\n          }\n        }\n      }\n      let response: types.GenerateImagesResponse;\n\n      if (positivePromptSafetyAttributes) {\n        response = {\n          generatedImages: generatedImages,\n          positivePromptSafetyAttributes: positivePromptSafetyAttributes,\n          sdkHttpResponse: apiResponse.sdkHttpResponse,\n        };\n      } else {\n        response = {\n          generatedImages: generatedImages,\n          sdkHttpResponse: apiResponse.sdkHttpResponse,\n        };\n      }\n      return response;\n    });\n  };\n\n  list = async (\n    params?: types.ListModelsParameters,\n  ): Promise<Pager<types.Model>> => {\n    const defaultConfig: types.ListModelsConfig = {\n      queryBase: true,\n    };\n    const actualConfig: types.ListModelsConfig = {\n      ...defaultConfig,\n      ...params?.config,\n    };\n    const actualParams: types.ListModelsParameters = {\n      config: actualConfig,\n    };\n\n    if (this.apiClient.isVertexAI()) {\n      if (!actualParams.config!.queryBase) {\n        if (actualParams.config?.filter) {\n          throw new Error(\n            'Filtering tuned models list for Vertex AI is not currently supported',\n          );\n        } else {\n          actualParams.config!.filter = 'labels.tune-type:*';\n        }\n      }\n    }\n\n    return new Pager<types.Model>(\n      PagedItem.PAGED_ITEM_MODELS,\n      (x: types.ListModelsParameters) => this.listInternal(x),\n      await this.listInternal(actualParams),\n      actualParams,\n    );\n  };\n\n  /**\n   * Edits an image based on a prompt, list of reference images, and configuration.\n   *\n   * @param params - The parameters for editing an image.\n   * @return The response from the API.\n   *\n   * @example\n   * ```ts\n   * const response = await client.models.editImage({\n   *  model: 'imagen-3.0-capability-001',\n   *  prompt: 'Generate an image containing a mug with the product logo [1] visible on the side of the mug.',\n   *  referenceImages: [subjectReferenceImage]\n   *  config: {\n   *    numberOfImages: 1,\n   *    includeRaiReason: true,\n   *  },\n   * });\n   * console.log(response?.generatedImages?.[0]?.image?.imageBytes);\n   * ```\n   */\n  editImage = async (\n    params: types.EditImageParameters,\n  ): Promise<types.EditImageResponse> => {\n    const paramsInternal: _internal_types.EditImageParametersInternal = {\n      model: params.model,\n      prompt: params.prompt,\n      referenceImages: [],\n      config: params.config,\n    };\n    if (params.referenceImages) {\n      if (params.referenceImages) {\n        paramsInternal.referenceImages = params.referenceImages.map((img) =>\n          img.toReferenceImageAPI(),\n        );\n      }\n    }\n    return await this.editImageInternal(paramsInternal);\n  };\n\n  /**\n   * Upscales an image based on an image, upscale factor, and configuration.\n   * Only supported in Vertex AI currently.\n   *\n   * @param params - The parameters for upscaling an image.\n   * @return The response from the API.\n   *\n   * @example\n   * ```ts\n   * const response = await client.models.upscaleImage({\n   *  model: 'imagen-3.0-generate-002',\n   *  image: image,\n   *  upscaleFactor: 'x2',\n   *  config: {\n   *    includeRaiReason: true,\n   *  },\n   * });\n   * console.log(response?.generatedImages?.[0]?.image?.imageBytes);\n   * ```\n   */\n  upscaleImage = async (\n    params: types.UpscaleImageParameters,\n  ): Promise<types.UpscaleImageResponse> => {\n    let apiConfig: _internal_types.UpscaleImageAPIConfigInternal = {\n      numberOfImages: 1,\n      mode: 'upscale',\n    };\n\n    if (params.config) {\n      apiConfig = {...apiConfig, ...params.config};\n    }\n\n    const apiParams: _internal_types.UpscaleImageAPIParametersInternal = {\n      model: params.model,\n      image: params.image,\n      upscaleFactor: params.upscaleFactor,\n      config: apiConfig,\n    };\n    return await this.upscaleImageInternal(apiParams);\n  };\n\n  /**\n   *  Generates videos based on a text description and configuration.\n   *\n   * @param params - The parameters for generating videos.\n   * @return A Promise<GenerateVideosOperation> which allows you to track the progress and eventually retrieve the generated videos using the operations.get method.\n   *\n   * @example\n   * ```ts\n   * const operation = await ai.models.generateVideos({\n   *  model: 'veo-2.0-generate-001',\n   *  source: {\n   *    prompt: 'A neon hologram of a cat driving at top speed',\n   *  },\n   *  config: {\n   *    numberOfVideos: 1\n   * });\n   *\n   * while (!operation.done) {\n   *   await new Promise(resolve => setTimeout(resolve, 10000));\n   *   operation = await ai.operations.getVideosOperation({operation: operation});\n   * }\n   *\n   * console.log(operation.response?.generatedVideos?.[0]?.video?.uri);\n   * ```\n   */\n\n  generateVideos = async (\n    params: types.GenerateVideosParameters,\n  ): Promise<types.GenerateVideosOperation> => {\n    if ((params.prompt || params.image || params.video) && params.source) {\n      throw new Error(\n        'Source and prompt/image/video are mutually exclusive. Please only use source.',\n      );\n    }\n    // Gemini API does not support video bytes.\n    if (!this.apiClient.isVertexAI()) {\n      if (params.video?.uri && params.video?.videoBytes) {\n        params.video = {\n          uri: params.video.uri,\n          mimeType: params.video.mimeType,\n        };\n      } else if (\n        params.source?.video?.uri &&\n        params.source?.video?.videoBytes\n      ) {\n        params.source.video = {\n          uri: params.source.video.uri,\n          mimeType: params.source.video.mimeType,\n        };\n      }\n    }\n    return await this.generateVideosInternal(params);\n  };\n\n  private async generateContentInternal(\n    params: types.GenerateContentParameters,\n  ): Promise<types.GenerateContentResponse> {\n    let response: Promise<types.GenerateContentResponse>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      const body = converters.generateContentParametersToVertex(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        '{model}:generateContent',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'POST',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json().then((jsonResponse) => {\n            const response = jsonResponse as types.GenerateContentResponse;\n            response.sdkHttpResponse = {\n              headers: httpResponse.headers,\n            } as types.HttpResponse;\n            return response;\n          });\n        }) as Promise<types.GenerateContentResponse>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.generateContentResponseFromVertex(apiResponse);\n        const typedResp = new types.GenerateContentResponse();\n        Object.assign(typedResp, resp);\n        return typedResp;\n      });\n    } else {\n      const body = converters.generateContentParametersToMldev(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        '{model}:generateContent',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'POST',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json().then((jsonResponse) => {\n            const response = jsonResponse as types.GenerateContentResponse;\n            response.sdkHttpResponse = {\n              headers: httpResponse.headers,\n            } as types.HttpResponse;\n            return response;\n          });\n        }) as Promise<types.GenerateContentResponse>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.generateContentResponseFromMldev(apiResponse);\n        const typedResp = new types.GenerateContentResponse();\n        Object.assign(typedResp, resp);\n        return typedResp;\n      });\n    }\n  }\n\n  private async generateContentStreamInternal(\n    params: types.GenerateContentParameters,\n  ): Promise<AsyncGenerator<types.GenerateContentResponse>> {\n    let response: Promise<AsyncGenerator<types.HttpResponse>>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      const body = converters.generateContentParametersToVertex(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        '{model}:streamGenerateContent?alt=sse',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      const apiClient = this.apiClient;\n      response = apiClient.requestStream({\n        path: path,\n        queryParams: queryParams,\n        body: JSON.stringify(body),\n        httpMethod: 'POST',\n        httpOptions: params.config?.httpOptions,\n        abortSignal: params.config?.abortSignal,\n      }) as Promise<AsyncGenerator<types.HttpResponse>>;\n\n      return response.then(async function* (\n        apiResponse: AsyncGenerator<types.HttpResponse>,\n      ) {\n        for await (const chunk of apiResponse) {\n          const resp = converters.generateContentResponseFromVertex(\n            (await chunk.json()) as types.GenerateContentResponse,\n          );\n\n          resp['sdkHttpResponse'] = {\n            headers: chunk.headers,\n          } as types.HttpResponse;\n\n          const typedResp = new types.GenerateContentResponse();\n          Object.assign(typedResp, resp);\n          yield typedResp;\n        }\n      });\n    } else {\n      const body = converters.generateContentParametersToMldev(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        '{model}:streamGenerateContent?alt=sse',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      const apiClient = this.apiClient;\n      response = apiClient.requestStream({\n        path: path,\n        queryParams: queryParams,\n        body: JSON.stringify(body),\n        httpMethod: 'POST',\n        httpOptions: params.config?.httpOptions,\n        abortSignal: params.config?.abortSignal,\n      }) as Promise<AsyncGenerator<types.HttpResponse>>;\n\n      return response.then(async function* (\n        apiResponse: AsyncGenerator<types.HttpResponse>,\n      ) {\n        for await (const chunk of apiResponse) {\n          const resp = converters.generateContentResponseFromMldev(\n            (await chunk.json()) as types.GenerateContentResponse,\n          );\n\n          resp['sdkHttpResponse'] = {\n            headers: chunk.headers,\n          } as types.HttpResponse;\n\n          const typedResp = new types.GenerateContentResponse();\n          Object.assign(typedResp, resp);\n          yield typedResp;\n        }\n      });\n    }\n  }\n\n  /**\n   * Calculates embeddings for the given contents. Only text is supported.\n   *\n   * @param params - The parameters for embedding contents.\n   * @return The response from the API.\n   *\n   * @example\n   * ```ts\n   * const response = await ai.models.embedContent({\n   *  model: 'text-embedding-004',\n   *  contents: [\n   *    'What is your name?',\n   *    'What is your favorite color?',\n   *  ],\n   *  config: {\n   *    outputDimensionality: 64,\n   *  },\n   * });\n   * console.log(response);\n   * ```\n   */\n  async embedContent(\n    params: types.EmbedContentParameters,\n  ): Promise<types.EmbedContentResponse> {\n    let response: Promise<types.EmbedContentResponse>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      const body = converters.embedContentParametersToVertex(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        '{model}:predict',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'POST',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json().then((jsonResponse) => {\n            const response = jsonResponse as types.EmbedContentResponse;\n            response.sdkHttpResponse = {\n              headers: httpResponse.headers,\n            } as types.HttpResponse;\n            return response;\n          });\n        }) as Promise<types.EmbedContentResponse>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.embedContentResponseFromVertex(apiResponse);\n        const typedResp = new types.EmbedContentResponse();\n        Object.assign(typedResp, resp);\n        return typedResp;\n      });\n    } else {\n      const body = converters.embedContentParametersToMldev(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        '{model}:batchEmbedContents',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'POST',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json().then((jsonResponse) => {\n            const response = jsonResponse as types.EmbedContentResponse;\n            response.sdkHttpResponse = {\n              headers: httpResponse.headers,\n            } as types.HttpResponse;\n            return response;\n          });\n        }) as Promise<types.EmbedContentResponse>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.embedContentResponseFromMldev(apiResponse);\n        const typedResp = new types.EmbedContentResponse();\n        Object.assign(typedResp, resp);\n        return typedResp;\n      });\n    }\n  }\n\n  /**\n   * Private method for generating images.\n   */\n  private async generateImagesInternal(\n    params: types.GenerateImagesParameters,\n  ): Promise<types.GenerateImagesResponse> {\n    let response: Promise<types.GenerateImagesResponse>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      const body = converters.generateImagesParametersToVertex(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        '{model}:predict',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'POST',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json().then((jsonResponse) => {\n            const response = jsonResponse as types.GenerateImagesResponse;\n            response.sdkHttpResponse = {\n              headers: httpResponse.headers,\n            } as types.HttpResponse;\n            return response;\n          });\n        }) as Promise<types.GenerateImagesResponse>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.generateImagesResponseFromVertex(apiResponse);\n        const typedResp = new types.GenerateImagesResponse();\n        Object.assign(typedResp, resp);\n        return typedResp;\n      });\n    } else {\n      const body = converters.generateImagesParametersToMldev(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        '{model}:predict',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'POST',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json().then((jsonResponse) => {\n            const response = jsonResponse as types.GenerateImagesResponse;\n            response.sdkHttpResponse = {\n              headers: httpResponse.headers,\n            } as types.HttpResponse;\n            return response;\n          });\n        }) as Promise<types.GenerateImagesResponse>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.generateImagesResponseFromMldev(apiResponse);\n        const typedResp = new types.GenerateImagesResponse();\n        Object.assign(typedResp, resp);\n        return typedResp;\n      });\n    }\n  }\n\n  /**\n   * Private method for editing an image.\n   */\n  private async editImageInternal(\n    params: _internal_types.EditImageParametersInternal,\n  ): Promise<types.EditImageResponse> {\n    let response: Promise<types.EditImageResponse>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      const body = converters.editImageParametersInternalToVertex(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        '{model}:predict',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'POST',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json().then((jsonResponse) => {\n            const response = jsonResponse as types.EditImageResponse;\n            response.sdkHttpResponse = {\n              headers: httpResponse.headers,\n            } as types.HttpResponse;\n            return response;\n          });\n        }) as Promise<types.EditImageResponse>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.editImageResponseFromVertex(apiResponse);\n        const typedResp = new types.EditImageResponse();\n        Object.assign(typedResp, resp);\n        return typedResp;\n      });\n    } else {\n      throw new Error('This method is only supported by the Vertex AI.');\n    }\n  }\n\n  /**\n   * Private method for upscaling an image.\n   */\n  private async upscaleImageInternal(\n    params: _internal_types.UpscaleImageAPIParametersInternal,\n  ): Promise<types.UpscaleImageResponse> {\n    let response: Promise<types.UpscaleImageResponse>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      const body = converters.upscaleImageAPIParametersInternalToVertex(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        '{model}:predict',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'POST',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json().then((jsonResponse) => {\n            const response = jsonResponse as types.UpscaleImageResponse;\n            response.sdkHttpResponse = {\n              headers: httpResponse.headers,\n            } as types.HttpResponse;\n            return response;\n          });\n        }) as Promise<types.UpscaleImageResponse>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.upscaleImageResponseFromVertex(apiResponse);\n        const typedResp = new types.UpscaleImageResponse();\n        Object.assign(typedResp, resp);\n        return typedResp;\n      });\n    } else {\n      throw new Error('This method is only supported by the Vertex AI.');\n    }\n  }\n\n  /**\n   * Recontextualizes an image.\n   *\n   * There are two types of recontextualization currently supported:\n   * 1) Imagen Product Recontext - Generate images of products in new scenes\n   *    and contexts.\n   * 2) Virtual Try-On: Generate images of persons modeling fashion products.\n   *\n   * @param params - The parameters for recontextualizing an image.\n   * @return The response from the API.\n   *\n   * @example\n   * ```ts\n   * const response1 = await ai.models.recontextImage({\n   *  model: 'imagen-product-recontext-preview-06-30',\n   *  source: {\n   *    prompt: 'In a modern kitchen setting.',\n   *    productImages: [productImage],\n   *  },\n   *  config: {\n   *    numberOfImages: 1,\n   *  },\n   * });\n   * console.log(response1?.generatedImages?.[0]?.image?.imageBytes);\n   *\n   * const response2 = await ai.models.recontextImage({\n   *  model: 'virtual-try-on-preview-08-04',\n   *  source: {\n   *    personImage: personImage,\n   *    productImages: [productImage],\n   *  },\n   *  config: {\n   *    numberOfImages: 1,\n   *  },\n   * });\n   * console.log(response2?.generatedImages?.[0]?.image?.imageBytes);\n   * ```\n   */\n  async recontextImage(\n    params: types.RecontextImageParameters,\n  ): Promise<types.RecontextImageResponse> {\n    let response: Promise<types.RecontextImageResponse>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      const body = converters.recontextImageParametersToVertex(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        '{model}:predict',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'POST',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json();\n        }) as Promise<types.RecontextImageResponse>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.recontextImageResponseFromVertex(apiResponse);\n        const typedResp = new types.RecontextImageResponse();\n        Object.assign(typedResp, resp);\n        return typedResp;\n      });\n    } else {\n      throw new Error('This method is only supported by the Vertex AI.');\n    }\n  }\n\n  /**\n   * Segments an image, creating a mask of a specified area.\n   *\n   * @param params - The parameters for segmenting an image.\n   * @return The response from the API.\n   *\n   * @example\n   * ```ts\n   * const response = await ai.models.segmentImage({\n   *  model: 'image-segmentation-001',\n   *  source: {\n   *    image: image,\n   *  },\n   *  config: {\n   *    mode: 'foreground',\n   *  },\n   * });\n   * console.log(response?.generatedMasks?.[0]?.mask?.imageBytes);\n   * ```\n   */\n  async segmentImage(\n    params: types.SegmentImageParameters,\n  ): Promise<types.SegmentImageResponse> {\n    let response: Promise<types.SegmentImageResponse>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      const body = converters.segmentImageParametersToVertex(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        '{model}:predict',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'POST',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json();\n        }) as Promise<types.SegmentImageResponse>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.segmentImageResponseFromVertex(apiResponse);\n        const typedResp = new types.SegmentImageResponse();\n        Object.assign(typedResp, resp);\n        return typedResp;\n      });\n    } else {\n      throw new Error('This method is only supported by the Vertex AI.');\n    }\n  }\n\n  /**\n   * Fetches information about a model by name.\n   *\n   * @example\n   * ```ts\n   * const modelInfo = await ai.models.get({model: 'gemini-2.0-flash'});\n   * ```\n   */\n  async get(params: types.GetModelParameters): Promise<types.Model> {\n    let response: Promise<types.Model>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      const body = converters.getModelParametersToVertex(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        '{name}',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'GET',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json();\n        }) as Promise<types.Model>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.modelFromVertex(apiResponse);\n\n        return resp as types.Model;\n      });\n    } else {\n      const body = converters.getModelParametersToMldev(this.apiClient, params);\n      path = common.formatMap(\n        '{name}',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'GET',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json();\n        }) as Promise<types.Model>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.modelFromMldev(apiResponse);\n\n        return resp as types.Model;\n      });\n    }\n  }\n\n  private async listInternal(\n    params: types.ListModelsParameters,\n  ): Promise<types.ListModelsResponse> {\n    let response: Promise<types.ListModelsResponse>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      const body = converters.listModelsParametersToVertex(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        '{models_url}',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'GET',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json().then((jsonResponse) => {\n            const response = jsonResponse as types.ListModelsResponse;\n            response.sdkHttpResponse = {\n              headers: httpResponse.headers,\n            } as types.HttpResponse;\n            return response;\n          });\n        }) as Promise<types.ListModelsResponse>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.listModelsResponseFromVertex(apiResponse);\n        const typedResp = new types.ListModelsResponse();\n        Object.assign(typedResp, resp);\n        return typedResp;\n      });\n    } else {\n      const body = converters.listModelsParametersToMldev(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        '{models_url}',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'GET',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json().then((jsonResponse) => {\n            const response = jsonResponse as types.ListModelsResponse;\n            response.sdkHttpResponse = {\n              headers: httpResponse.headers,\n            } as types.HttpResponse;\n            return response;\n          });\n        }) as Promise<types.ListModelsResponse>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.listModelsResponseFromMldev(apiResponse);\n        const typedResp = new types.ListModelsResponse();\n        Object.assign(typedResp, resp);\n        return typedResp;\n      });\n    }\n  }\n\n  /**\n   * Updates a tuned model by its name.\n   *\n   * @param params - The parameters for updating the model.\n   * @return The response from the API.\n   *\n   * @example\n   * ```ts\n   * const response = await ai.models.update({\n   *   model: 'tuned-model-name',\n   *   config: {\n   *     displayName: 'New display name',\n   *     description: 'New description',\n   *   },\n   * });\n   * ```\n   */\n  async update(params: types.UpdateModelParameters): Promise<types.Model> {\n    let response: Promise<types.Model>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      const body = converters.updateModelParametersToVertex(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        '{model}',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'PATCH',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json();\n        }) as Promise<types.Model>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.modelFromVertex(apiResponse);\n\n        return resp as types.Model;\n      });\n    } else {\n      const body = converters.updateModelParametersToMldev(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        '{name}',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'PATCH',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json();\n        }) as Promise<types.Model>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.modelFromMldev(apiResponse);\n\n        return resp as types.Model;\n      });\n    }\n  }\n\n  /**\n   * Deletes a tuned model by its name.\n   *\n   * @param params - The parameters for deleting the model.\n   * @return The response from the API.\n   *\n   * @example\n   * ```ts\n   * const response = await ai.models.delete({model: 'tuned-model-name'});\n   * ```\n   */\n  async delete(\n    params: types.DeleteModelParameters,\n  ): Promise<types.DeleteModelResponse> {\n    let response: Promise<types.DeleteModelResponse>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      const body = converters.deleteModelParametersToVertex(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        '{name}',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'DELETE',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json().then((jsonResponse) => {\n            const response = jsonResponse as types.DeleteModelResponse;\n            response.sdkHttpResponse = {\n              headers: httpResponse.headers,\n            } as types.HttpResponse;\n            return response;\n          });\n        }) as Promise<types.DeleteModelResponse>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.deleteModelResponseFromVertex(apiResponse);\n        const typedResp = new types.DeleteModelResponse();\n        Object.assign(typedResp, resp);\n        return typedResp;\n      });\n    } else {\n      const body = converters.deleteModelParametersToMldev(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        '{name}',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'DELETE',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json().then((jsonResponse) => {\n            const response = jsonResponse as types.DeleteModelResponse;\n            response.sdkHttpResponse = {\n              headers: httpResponse.headers,\n            } as types.HttpResponse;\n            return response;\n          });\n        }) as Promise<types.DeleteModelResponse>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.deleteModelResponseFromMldev(apiResponse);\n        const typedResp = new types.DeleteModelResponse();\n        Object.assign(typedResp, resp);\n        return typedResp;\n      });\n    }\n  }\n\n  /**\n   * Counts the number of tokens in the given contents. Multimodal input is\n   * supported for Gemini models.\n   *\n   * @param params - The parameters for counting tokens.\n   * @return The response from the API.\n   *\n   * @example\n   * ```ts\n   * const response = await ai.models.countTokens({\n   *  model: 'gemini-2.0-flash',\n   *  contents: 'The quick brown fox jumps over the lazy dog.'\n   * });\n   * console.log(response);\n   * ```\n   */\n  async countTokens(\n    params: types.CountTokensParameters,\n  ): Promise<types.CountTokensResponse> {\n    let response: Promise<types.CountTokensResponse>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      const body = converters.countTokensParametersToVertex(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        '{model}:countTokens',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'POST',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json().then((jsonResponse) => {\n            const response = jsonResponse as types.CountTokensResponse;\n            response.sdkHttpResponse = {\n              headers: httpResponse.headers,\n            } as types.HttpResponse;\n            return response;\n          });\n        }) as Promise<types.CountTokensResponse>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.countTokensResponseFromVertex(apiResponse);\n        const typedResp = new types.CountTokensResponse();\n        Object.assign(typedResp, resp);\n        return typedResp;\n      });\n    } else {\n      const body = converters.countTokensParametersToMldev(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        '{model}:countTokens',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'POST',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json().then((jsonResponse) => {\n            const response = jsonResponse as types.CountTokensResponse;\n            response.sdkHttpResponse = {\n              headers: httpResponse.headers,\n            } as types.HttpResponse;\n            return response;\n          });\n        }) as Promise<types.CountTokensResponse>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.countTokensResponseFromMldev(apiResponse);\n        const typedResp = new types.CountTokensResponse();\n        Object.assign(typedResp, resp);\n        return typedResp;\n      });\n    }\n  }\n\n  /**\n   * Given a list of contents, returns a corresponding TokensInfo containing\n   * the list of tokens and list of token ids.\n   *\n   * This method is not supported by the Gemini Developer API.\n   *\n   * @param params - The parameters for computing tokens.\n   * @return The response from the API.\n   *\n   * @example\n   * ```ts\n   * const response = await ai.models.computeTokens({\n   *  model: 'gemini-2.0-flash',\n   *  contents: 'What is your name?'\n   * });\n   * console.log(response);\n   * ```\n   */\n  async computeTokens(\n    params: types.ComputeTokensParameters,\n  ): Promise<types.ComputeTokensResponse> {\n    let response: Promise<types.ComputeTokensResponse>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      const body = converters.computeTokensParametersToVertex(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        '{model}:computeTokens',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'POST',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json().then((jsonResponse) => {\n            const response = jsonResponse as types.ComputeTokensResponse;\n            response.sdkHttpResponse = {\n              headers: httpResponse.headers,\n            } as types.HttpResponse;\n            return response;\n          });\n        }) as Promise<types.ComputeTokensResponse>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.computeTokensResponseFromVertex(apiResponse);\n        const typedResp = new types.ComputeTokensResponse();\n        Object.assign(typedResp, resp);\n        return typedResp;\n      });\n    } else {\n      throw new Error('This method is only supported by the Vertex AI.');\n    }\n  }\n\n  /**\n   * Private method for generating videos.\n   */\n  private async generateVideosInternal(\n    params: types.GenerateVideosParameters,\n  ): Promise<types.GenerateVideosOperation> {\n    let response: Promise<types.GenerateVideosOperation>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      const body = converters.generateVideosParametersToVertex(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        '{model}:predictLongRunning',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'POST',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json();\n        }) as Promise<types.GenerateVideosOperation>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.generateVideosOperationFromVertex(apiResponse);\n        const typedResp = new types.GenerateVideosOperation();\n        Object.assign(typedResp, resp);\n        return typedResp;\n      });\n    } else {\n      const body = converters.generateVideosParametersToMldev(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        '{model}:predictLongRunning',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'POST',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json();\n        }) as Promise<types.GenerateVideosOperation>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.generateVideosOperationFromMldev(apiResponse);\n        const typedResp = new types.GenerateVideosOperation();\n        Object.assign(typedResp, resp);\n        return typedResp;\n      });\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\n// Code generated by the Google Gen AI SDK generator DO NOT EDIT.\n\nimport {ApiClient} from './_api_client.js';\nimport * as common from './_common.js';\nimport {BaseModule} from './_common.js';\nimport * as converters from './converters/_operations_converters.js';\nimport * as types from './types.js';\n\nexport class Operations extends BaseModule {\n  constructor(private readonly apiClient: ApiClient) {\n    super();\n  }\n\n  /**\n   * Gets the status of a long-running operation.\n   *\n   * @param parameters The parameters for the get operation request.\n   * @return The updated Operation object, with the latest status or result.\n   */\n  async getVideosOperation(\n    parameters: types.OperationGetParameters<\n      types.GenerateVideosResponse,\n      types.GenerateVideosOperation\n    >,\n  ): Promise<types.GenerateVideosOperation> {\n    const operation = parameters.operation;\n    const config = parameters.config;\n\n    if (operation.name === undefined || operation.name === '') {\n      throw new Error('Operation name is required.');\n    }\n\n    if (this.apiClient.isVertexAI()) {\n      const resourceName = operation.name.split('/operations/')[0];\n      let httpOptions: types.HttpOptions | undefined = undefined;\n\n      if (config && 'httpOptions' in config) {\n        httpOptions = config.httpOptions;\n      }\n\n      const rawOperation = await this.fetchPredictVideosOperationInternal({\n        operationName: operation.name,\n        resourceName: resourceName,\n        config: {httpOptions: httpOptions},\n      });\n\n      return operation._fromAPIResponse({\n        apiResponse: rawOperation,\n        isVertexAI: true,\n      });\n    } else {\n      const rawOperation = await this.getVideosOperationInternal({\n        operationName: operation.name,\n        config: config,\n      });\n      return operation._fromAPIResponse({\n        apiResponse: rawOperation,\n        isVertexAI: false,\n      });\n    }\n  }\n\n  /**\n   * Gets the status of a long-running operation.\n   *\n   * @param parameters The parameters for the get operation request.\n   * @return The updated Operation object, with the latest status or result.\n   */\n  async get<T, U extends types.Operation<T>>(\n    parameters: types.OperationGetParameters<T, U>,\n  ): Promise<types.Operation<T>> {\n    const operation = parameters.operation;\n    const config = parameters.config;\n\n    if (operation.name === undefined || operation.name === '') {\n      throw new Error('Operation name is required.');\n    }\n\n    if (this.apiClient.isVertexAI()) {\n      const resourceName = operation.name.split('/operations/')[0];\n      let httpOptions: types.HttpOptions | undefined = undefined;\n\n      if (config && 'httpOptions' in config) {\n        httpOptions = config.httpOptions;\n      }\n\n      const rawOperation = await this.fetchPredictVideosOperationInternal({\n        operationName: operation.name,\n        resourceName: resourceName,\n        config: {httpOptions: httpOptions},\n      });\n\n      return operation._fromAPIResponse({\n        apiResponse: rawOperation,\n        isVertexAI: true,\n      });\n    } else {\n      const rawOperation = await this.getVideosOperationInternal({\n        operationName: operation.name,\n        config: config,\n      });\n      return operation._fromAPIResponse({\n        apiResponse: rawOperation,\n        isVertexAI: false,\n      });\n    }\n  }\n\n  private async getVideosOperationInternal(\n    params: types.GetOperationParameters,\n  ): Promise<Record<string, unknown>> {\n    let response: Promise<Record<string, unknown>>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      const body = converters.getOperationParametersToVertex(params);\n      path = common.formatMap(\n        '{operationName}',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'GET',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json();\n        }) as Promise<Record<string, unknown>>;\n\n      return response;\n    } else {\n      const body = converters.getOperationParametersToMldev(params);\n      path = common.formatMap(\n        '{operationName}',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'GET',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json();\n        }) as Promise<Record<string, unknown>>;\n\n      return response;\n    }\n  }\n\n  private async fetchPredictVideosOperationInternal(\n    params: types.FetchPredictOperationParameters,\n  ): Promise<Record<string, unknown>> {\n    let response: Promise<Record<string, unknown>>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      const body = converters.fetchPredictOperationParametersToVertex(params);\n      path = common.formatMap(\n        '{resourceName}:fetchPredictOperation',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'POST',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json();\n        }) as Promise<Record<string, unknown>>;\n\n      return response;\n    } else {\n      throw new Error('This method is only supported by the Vertex AI.');\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\n// Code generated by the Google Gen AI SDK generator DO NOT EDIT.\n\nimport {ApiClient} from '../_api_client.js';\nimport * as common from '../_common.js';\nimport * as t from '../_transformers.js';\nimport type * as types from '../types.js';\n\nexport function blobToMldev(fromObject: types.Blob): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  if (common.getValueByPath(fromObject, ['displayName']) !== undefined) {\n    throw new Error('displayName parameter is not supported in Gemini API.');\n  }\n\n  const fromData = common.getValueByPath(fromObject, ['data']);\n  if (fromData != null) {\n    common.setValueByPath(toObject, ['data'], fromData);\n  }\n\n  const fromMimeType = common.getValueByPath(fromObject, ['mimeType']);\n  if (fromMimeType != null) {\n    common.setValueByPath(toObject, ['mimeType'], fromMimeType);\n  }\n\n  return toObject;\n}\n\nexport function contentToMldev(\n  fromObject: types.Content,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromParts = common.getValueByPath(fromObject, ['parts']);\n  if (fromParts != null) {\n    let transformedList = fromParts;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return partToMldev(item);\n      });\n    }\n    common.setValueByPath(toObject, ['parts'], transformedList);\n  }\n\n  const fromRole = common.getValueByPath(fromObject, ['role']);\n  if (fromRole != null) {\n    common.setValueByPath(toObject, ['role'], fromRole);\n  }\n\n  return toObject;\n}\n\nexport function createAuthTokenConfigToMldev(\n  apiClient: ApiClient,\n  fromObject: types.CreateAuthTokenConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromExpireTime = common.getValueByPath(fromObject, ['expireTime']);\n  if (parentObject !== undefined && fromExpireTime != null) {\n    common.setValueByPath(parentObject, ['expireTime'], fromExpireTime);\n  }\n\n  const fromNewSessionExpireTime = common.getValueByPath(fromObject, [\n    'newSessionExpireTime',\n  ]);\n  if (parentObject !== undefined && fromNewSessionExpireTime != null) {\n    common.setValueByPath(\n      parentObject,\n      ['newSessionExpireTime'],\n      fromNewSessionExpireTime,\n    );\n  }\n\n  const fromUses = common.getValueByPath(fromObject, ['uses']);\n  if (parentObject !== undefined && fromUses != null) {\n    common.setValueByPath(parentObject, ['uses'], fromUses);\n  }\n\n  const fromLiveConnectConstraints = common.getValueByPath(fromObject, [\n    'liveConnectConstraints',\n  ]);\n  if (parentObject !== undefined && fromLiveConnectConstraints != null) {\n    common.setValueByPath(\n      parentObject,\n      ['bidiGenerateContentSetup'],\n      liveConnectConstraintsToMldev(apiClient, fromLiveConnectConstraints),\n    );\n  }\n\n  const fromLockAdditionalFields = common.getValueByPath(fromObject, [\n    'lockAdditionalFields',\n  ]);\n  if (parentObject !== undefined && fromLockAdditionalFields != null) {\n    common.setValueByPath(\n      parentObject,\n      ['fieldMask'],\n      fromLockAdditionalFields,\n    );\n  }\n\n  return toObject;\n}\n\nexport function createAuthTokenParametersToMldev(\n  apiClient: ApiClient,\n  fromObject: types.CreateAuthTokenParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    common.setValueByPath(\n      toObject,\n      ['config'],\n      createAuthTokenConfigToMldev(apiClient, fromConfig, toObject),\n    );\n  }\n\n  return toObject;\n}\n\nexport function createAuthTokenParametersToVertex(\n  fromObject: types.CreateAuthTokenParameters,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  if (common.getValueByPath(fromObject, ['config']) !== undefined) {\n    throw new Error('config parameter is not supported in Vertex AI.');\n  }\n\n  return toObject;\n}\n\nexport function fileDataToMldev(\n  fromObject: types.FileData,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  if (common.getValueByPath(fromObject, ['displayName']) !== undefined) {\n    throw new Error('displayName parameter is not supported in Gemini API.');\n  }\n\n  const fromFileUri = common.getValueByPath(fromObject, ['fileUri']);\n  if (fromFileUri != null) {\n    common.setValueByPath(toObject, ['fileUri'], fromFileUri);\n  }\n\n  const fromMimeType = common.getValueByPath(fromObject, ['mimeType']);\n  if (fromMimeType != null) {\n    common.setValueByPath(toObject, ['mimeType'], fromMimeType);\n  }\n\n  return toObject;\n}\n\nexport function googleMapsToMldev(\n  fromObject: types.GoogleMaps,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  if (common.getValueByPath(fromObject, ['authConfig']) !== undefined) {\n    throw new Error('authConfig parameter is not supported in Gemini API.');\n  }\n\n  const fromEnableWidget = common.getValueByPath(fromObject, ['enableWidget']);\n  if (fromEnableWidget != null) {\n    common.setValueByPath(toObject, ['enableWidget'], fromEnableWidget);\n  }\n\n  return toObject;\n}\n\nexport function googleSearchToMldev(\n  fromObject: types.GoogleSearch,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromTimeRangeFilter = common.getValueByPath(fromObject, [\n    'timeRangeFilter',\n  ]);\n  if (fromTimeRangeFilter != null) {\n    common.setValueByPath(toObject, ['timeRangeFilter'], fromTimeRangeFilter);\n  }\n\n  if (common.getValueByPath(fromObject, ['excludeDomains']) !== undefined) {\n    throw new Error('excludeDomains parameter is not supported in Gemini API.');\n  }\n\n  return toObject;\n}\n\nexport function liveConnectConfigToMldev(\n  fromObject: types.LiveConnectConfig,\n  parentObject: Record<string, unknown>,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromGenerationConfig = common.getValueByPath(fromObject, [\n    'generationConfig',\n  ]);\n  if (parentObject !== undefined && fromGenerationConfig != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig'],\n      fromGenerationConfig,\n    );\n  }\n\n  const fromResponseModalities = common.getValueByPath(fromObject, [\n    'responseModalities',\n  ]);\n  if (parentObject !== undefined && fromResponseModalities != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig', 'responseModalities'],\n      fromResponseModalities,\n    );\n  }\n\n  const fromTemperature = common.getValueByPath(fromObject, ['temperature']);\n  if (parentObject !== undefined && fromTemperature != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig', 'temperature'],\n      fromTemperature,\n    );\n  }\n\n  const fromTopP = common.getValueByPath(fromObject, ['topP']);\n  if (parentObject !== undefined && fromTopP != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig', 'topP'],\n      fromTopP,\n    );\n  }\n\n  const fromTopK = common.getValueByPath(fromObject, ['topK']);\n  if (parentObject !== undefined && fromTopK != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig', 'topK'],\n      fromTopK,\n    );\n  }\n\n  const fromMaxOutputTokens = common.getValueByPath(fromObject, [\n    'maxOutputTokens',\n  ]);\n  if (parentObject !== undefined && fromMaxOutputTokens != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig', 'maxOutputTokens'],\n      fromMaxOutputTokens,\n    );\n  }\n\n  const fromMediaResolution = common.getValueByPath(fromObject, [\n    'mediaResolution',\n  ]);\n  if (parentObject !== undefined && fromMediaResolution != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig', 'mediaResolution'],\n      fromMediaResolution,\n    );\n  }\n\n  const fromSeed = common.getValueByPath(fromObject, ['seed']);\n  if (parentObject !== undefined && fromSeed != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig', 'seed'],\n      fromSeed,\n    );\n  }\n\n  const fromSpeechConfig = common.getValueByPath(fromObject, ['speechConfig']);\n  if (parentObject !== undefined && fromSpeechConfig != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig', 'speechConfig'],\n      t.tLiveSpeechConfig(fromSpeechConfig),\n    );\n  }\n\n  const fromThinkingConfig = common.getValueByPath(fromObject, [\n    'thinkingConfig',\n  ]);\n  if (parentObject !== undefined && fromThinkingConfig != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig', 'thinkingConfig'],\n      fromThinkingConfig,\n    );\n  }\n\n  const fromEnableAffectiveDialog = common.getValueByPath(fromObject, [\n    'enableAffectiveDialog',\n  ]);\n  if (parentObject !== undefined && fromEnableAffectiveDialog != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'generationConfig', 'enableAffectiveDialog'],\n      fromEnableAffectiveDialog,\n    );\n  }\n\n  const fromSystemInstruction = common.getValueByPath(fromObject, [\n    'systemInstruction',\n  ]);\n  if (parentObject !== undefined && fromSystemInstruction != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'systemInstruction'],\n      contentToMldev(t.tContent(fromSystemInstruction)),\n    );\n  }\n\n  const fromTools = common.getValueByPath(fromObject, ['tools']);\n  if (parentObject !== undefined && fromTools != null) {\n    let transformedList = t.tTools(fromTools);\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return toolToMldev(t.tTool(item));\n      });\n    }\n    common.setValueByPath(parentObject, ['setup', 'tools'], transformedList);\n  }\n\n  const fromSessionResumption = common.getValueByPath(fromObject, [\n    'sessionResumption',\n  ]);\n  if (parentObject !== undefined && fromSessionResumption != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'sessionResumption'],\n      sessionResumptionConfigToMldev(fromSessionResumption),\n    );\n  }\n\n  const fromInputAudioTranscription = common.getValueByPath(fromObject, [\n    'inputAudioTranscription',\n  ]);\n  if (parentObject !== undefined && fromInputAudioTranscription != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'inputAudioTranscription'],\n      fromInputAudioTranscription,\n    );\n  }\n\n  const fromOutputAudioTranscription = common.getValueByPath(fromObject, [\n    'outputAudioTranscription',\n  ]);\n  if (parentObject !== undefined && fromOutputAudioTranscription != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'outputAudioTranscription'],\n      fromOutputAudioTranscription,\n    );\n  }\n\n  const fromRealtimeInputConfig = common.getValueByPath(fromObject, [\n    'realtimeInputConfig',\n  ]);\n  if (parentObject !== undefined && fromRealtimeInputConfig != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'realtimeInputConfig'],\n      fromRealtimeInputConfig,\n    );\n  }\n\n  const fromContextWindowCompression = common.getValueByPath(fromObject, [\n    'contextWindowCompression',\n  ]);\n  if (parentObject !== undefined && fromContextWindowCompression != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'contextWindowCompression'],\n      fromContextWindowCompression,\n    );\n  }\n\n  const fromProactivity = common.getValueByPath(fromObject, ['proactivity']);\n  if (parentObject !== undefined && fromProactivity != null) {\n    common.setValueByPath(\n      parentObject,\n      ['setup', 'proactivity'],\n      fromProactivity,\n    );\n  }\n\n  return toObject;\n}\n\nexport function liveConnectConstraintsToMldev(\n  apiClient: ApiClient,\n  fromObject: types.LiveConnectConstraints,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['model']);\n  if (fromModel != null) {\n    common.setValueByPath(\n      toObject,\n      ['setup', 'model'],\n      t.tModel(apiClient, fromModel),\n    );\n  }\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    common.setValueByPath(\n      toObject,\n      ['config'],\n      liveConnectConfigToMldev(fromConfig, toObject),\n    );\n  }\n\n  return toObject;\n}\n\nexport function partToMldev(fromObject: types.Part): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromVideoMetadata = common.getValueByPath(fromObject, [\n    'videoMetadata',\n  ]);\n  if (fromVideoMetadata != null) {\n    common.setValueByPath(toObject, ['videoMetadata'], fromVideoMetadata);\n  }\n\n  const fromThought = common.getValueByPath(fromObject, ['thought']);\n  if (fromThought != null) {\n    common.setValueByPath(toObject, ['thought'], fromThought);\n  }\n\n  const fromInlineData = common.getValueByPath(fromObject, ['inlineData']);\n  if (fromInlineData != null) {\n    common.setValueByPath(\n      toObject,\n      ['inlineData'],\n      blobToMldev(fromInlineData),\n    );\n  }\n\n  const fromFileData = common.getValueByPath(fromObject, ['fileData']);\n  if (fromFileData != null) {\n    common.setValueByPath(\n      toObject,\n      ['fileData'],\n      fileDataToMldev(fromFileData),\n    );\n  }\n\n  const fromThoughtSignature = common.getValueByPath(fromObject, [\n    'thoughtSignature',\n  ]);\n  if (fromThoughtSignature != null) {\n    common.setValueByPath(toObject, ['thoughtSignature'], fromThoughtSignature);\n  }\n\n  const fromFunctionCall = common.getValueByPath(fromObject, ['functionCall']);\n  if (fromFunctionCall != null) {\n    common.setValueByPath(toObject, ['functionCall'], fromFunctionCall);\n  }\n\n  const fromCodeExecutionResult = common.getValueByPath(fromObject, [\n    'codeExecutionResult',\n  ]);\n  if (fromCodeExecutionResult != null) {\n    common.setValueByPath(\n      toObject,\n      ['codeExecutionResult'],\n      fromCodeExecutionResult,\n    );\n  }\n\n  const fromExecutableCode = common.getValueByPath(fromObject, [\n    'executableCode',\n  ]);\n  if (fromExecutableCode != null) {\n    common.setValueByPath(toObject, ['executableCode'], fromExecutableCode);\n  }\n\n  const fromFunctionResponse = common.getValueByPath(fromObject, [\n    'functionResponse',\n  ]);\n  if (fromFunctionResponse != null) {\n    common.setValueByPath(toObject, ['functionResponse'], fromFunctionResponse);\n  }\n\n  const fromText = common.getValueByPath(fromObject, ['text']);\n  if (fromText != null) {\n    common.setValueByPath(toObject, ['text'], fromText);\n  }\n\n  return toObject;\n}\n\nexport function sessionResumptionConfigToMldev(\n  fromObject: types.SessionResumptionConfig,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromHandle = common.getValueByPath(fromObject, ['handle']);\n  if (fromHandle != null) {\n    common.setValueByPath(toObject, ['handle'], fromHandle);\n  }\n\n  if (common.getValueByPath(fromObject, ['transparent']) !== undefined) {\n    throw new Error('transparent parameter is not supported in Gemini API.');\n  }\n\n  return toObject;\n}\n\nexport function toolToMldev(fromObject: types.Tool): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromFunctionDeclarations = common.getValueByPath(fromObject, [\n    'functionDeclarations',\n  ]);\n  if (fromFunctionDeclarations != null) {\n    let transformedList = fromFunctionDeclarations;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(toObject, ['functionDeclarations'], transformedList);\n  }\n\n  if (common.getValueByPath(fromObject, ['retrieval']) !== undefined) {\n    throw new Error('retrieval parameter is not supported in Gemini API.');\n  }\n\n  const fromGoogleSearch = common.getValueByPath(fromObject, ['googleSearch']);\n  if (fromGoogleSearch != null) {\n    common.setValueByPath(\n      toObject,\n      ['googleSearch'],\n      googleSearchToMldev(fromGoogleSearch),\n    );\n  }\n\n  const fromGoogleSearchRetrieval = common.getValueByPath(fromObject, [\n    'googleSearchRetrieval',\n  ]);\n  if (fromGoogleSearchRetrieval != null) {\n    common.setValueByPath(\n      toObject,\n      ['googleSearchRetrieval'],\n      fromGoogleSearchRetrieval,\n    );\n  }\n\n  if (\n    common.getValueByPath(fromObject, ['enterpriseWebSearch']) !== undefined\n  ) {\n    throw new Error(\n      'enterpriseWebSearch parameter is not supported in Gemini API.',\n    );\n  }\n\n  const fromGoogleMaps = common.getValueByPath(fromObject, ['googleMaps']);\n  if (fromGoogleMaps != null) {\n    common.setValueByPath(\n      toObject,\n      ['googleMaps'],\n      googleMapsToMldev(fromGoogleMaps),\n    );\n  }\n\n  const fromUrlContext = common.getValueByPath(fromObject, ['urlContext']);\n  if (fromUrlContext != null) {\n    common.setValueByPath(toObject, ['urlContext'], fromUrlContext);\n  }\n\n  const fromComputerUse = common.getValueByPath(fromObject, ['computerUse']);\n  if (fromComputerUse != null) {\n    common.setValueByPath(toObject, ['computerUse'], fromComputerUse);\n  }\n\n  const fromCodeExecution = common.getValueByPath(fromObject, [\n    'codeExecution',\n  ]);\n  if (fromCodeExecution != null) {\n    common.setValueByPath(toObject, ['codeExecution'], fromCodeExecution);\n  }\n\n  return toObject;\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\nimport {ApiClient} from './_api_client.js';\nimport * as common from './_common.js';\nimport {BaseModule} from './_common.js';\nimport * as converters from './converters/_tokens_converters.js';\nimport * as types from './types.js';\n\n/**\n * Returns a comma-separated list of field masks from a given object.\n *\n * @param setup The object to extract field masks from.\n * @return A comma-separated list of field masks.\n */\nfunction getFieldMasks(setup: Record<string, unknown>): string {\n  const fields: string[] = [];\n\n  for (const key in setup) {\n    if (Object.prototype.hasOwnProperty.call(setup, key)) {\n      const value = setup[key];\n      // 2nd layer, recursively get field masks see TODO(b/418290100)\n      if (\n        typeof value === 'object' &&\n        value != null &&\n        Object.keys(value).length > 0\n      ) {\n        const field = Object.keys(value).map((kk) => `${key}.${kk}`);\n        fields.push(...field);\n      } else {\n        fields.push(key); // 1st layer\n      }\n    }\n  }\n\n  return fields.join(',');\n}\n\n/**\n * Converts bidiGenerateContentSetup.\n * @param requestDict - The request dictionary.\n * @param config - The configuration object.\n * @return - The modified request dictionary.\n */\nfunction convertBidiSetupToTokenSetup(\n  requestDict: Record<string, unknown>,\n  config?: {lockAdditionalFields?: string[]},\n): Record<string, unknown> {\n  // Convert bidiGenerateContentSetup from bidiGenerateContentSetup.setup.\n  let setupForMaskGeneration: Record<string, unknown> | null = null;\n  const bidiGenerateContentSetupValue = requestDict['bidiGenerateContentSetup'];\n  if (\n    typeof bidiGenerateContentSetupValue === 'object' &&\n    bidiGenerateContentSetupValue !== null &&\n    'setup' in bidiGenerateContentSetupValue\n  ) {\n    // Now we know bidiGenerateContentSetupValue is an object and has a 'setup'\n    // property.\n    const innerSetup = (bidiGenerateContentSetupValue as {setup: unknown})\n      .setup;\n\n    if (typeof innerSetup === 'object' && innerSetup !== null) {\n      // Valid inner setup found.\n      requestDict['bidiGenerateContentSetup'] = innerSetup;\n      setupForMaskGeneration = innerSetup as Record<string, unknown>;\n    } else {\n      // `bidiGenerateContentSetupValue.setup` is not a valid object; treat as\n      // if bidiGenerateContentSetup is invalid.\n      delete requestDict['bidiGenerateContentSetup'];\n    }\n  } else if (bidiGenerateContentSetupValue !== undefined) {\n    // `bidiGenerateContentSetup` exists but not in the expected\n    // shape {setup: {...}}; treat as invalid.\n    delete requestDict['bidiGenerateContentSetup'];\n  }\n\n  const preExistingFieldMask = requestDict['fieldMask'];\n  // Handle mask generation setup.\n  if (setupForMaskGeneration) {\n    const generatedMaskFromBidi = getFieldMasks(setupForMaskGeneration);\n\n    if (\n      Array.isArray(config?.lockAdditionalFields) &&\n      config?.lockAdditionalFields.length === 0\n    ) {\n      // Case 1: lockAdditionalFields is an empty array. Lock only fields from\n      // bidi setup.\n      if (generatedMaskFromBidi) {\n        // Only assign if mask is not empty\n        requestDict['fieldMask'] = generatedMaskFromBidi;\n      } else {\n        delete requestDict['fieldMask']; // If mask is empty, effectively no\n        // specific fields locked by bidi\n      }\n    } else if (\n      config?.lockAdditionalFields &&\n      config.lockAdditionalFields.length > 0 &&\n      preExistingFieldMask !== null &&\n      Array.isArray(preExistingFieldMask) &&\n      preExistingFieldMask.length > 0\n    ) {\n      // Case 2: Lock fields from bidi setup + additional fields\n      // (preExistingFieldMask).\n\n      const generationConfigFields = [\n        'temperature',\n        'topK',\n        'topP',\n        'maxOutputTokens',\n        'responseModalities',\n        'seed',\n        'speechConfig',\n      ];\n\n      let mappedFieldsFromPreExisting: string[] = [];\n      if (preExistingFieldMask.length > 0) {\n        mappedFieldsFromPreExisting = preExistingFieldMask.map((field) => {\n          if (generationConfigFields.includes(field)) {\n            return `generationConfig.${field}`;\n          }\n          return field; // Keep original field name if not in\n          // generationConfigFields\n        });\n      }\n\n      const finalMaskParts: string[] = [];\n      if (generatedMaskFromBidi) {\n        finalMaskParts.push(generatedMaskFromBidi);\n      }\n      if (mappedFieldsFromPreExisting.length > 0) {\n        finalMaskParts.push(...mappedFieldsFromPreExisting);\n      }\n\n      if (finalMaskParts.length > 0) {\n        requestDict['fieldMask'] = finalMaskParts.join(',');\n      } else {\n        // If no fields from bidi and no valid additional fields from\n        // pre-existing mask.\n        delete requestDict['fieldMask'];\n      }\n    } else {\n      // Case 3: \"Lock all fields\" (meaning, don't send a field_mask, let server\n      // defaults apply or all are mutable). This is hit if:\n      //  - `config.lockAdditionalFields` is undefined.\n      //  - `config.lockAdditionalFields` is non-empty, BUT\n      //  `preExistingFieldMask` is null, not a string, or an empty string.\n      delete requestDict['fieldMask'];\n    }\n  } else {\n    // No valid `bidiGenerateContentSetup` was found or extracted.\n    // \"Lock additional null fields if any\".\n    if (\n      preExistingFieldMask !== null &&\n      Array.isArray(preExistingFieldMask) &&\n      preExistingFieldMask.length > 0\n    ) {\n      // If there's a pre-existing field mask, it's a string, and it's not\n      // empty, then we should lock all fields.\n      requestDict['fieldMask'] = preExistingFieldMask.join(',');\n    } else {\n      delete requestDict['fieldMask'];\n    }\n  }\n\n  return requestDict;\n}\n\nexport class Tokens extends BaseModule {\n  constructor(private readonly apiClient: ApiClient) {\n    super();\n  }\n  /**\n   * Creates an ephemeral auth token resource.\n   *\n   * @experimental\n   *\n   * @remarks\n   * Ephemeral auth tokens is only supported in the Gemini Developer API.\n   * It can be used for the session connection to the Live constrained API.\n   * Support in v1alpha only.\n   *\n   * @param params - The parameters for the create request.\n   * @return The created auth token.\n   *\n   * @example\n   * ```ts\n   * const ai = new GoogleGenAI({\n   *     apiKey: token.name,\n   *     httpOptions: { apiVersion: 'v1alpha' }  // Support in v1alpha only.\n   * });\n   *\n   * // Case 1: If LiveEphemeralParameters is unset, unlock LiveConnectConfig\n   * // when using the token in Live API sessions. Each session connection can\n   * // use a different configuration.\n   * const config: CreateAuthTokenConfig = {\n   *     uses: 3,\n   *     expireTime: '2025-05-01T00:00:00Z',\n   * }\n   * const token = await ai.tokens.create(config);\n   *\n   * // Case 2: If LiveEphemeralParameters is set, lock all fields in\n   * // LiveConnectConfig when using the token in Live API sessions. For\n   * // example, changing `outputAudioTranscription` in the Live API\n   * // connection will be ignored by the API.\n   * const config: CreateAuthTokenConfig =\n   *     uses: 3,\n   *     expireTime: '2025-05-01T00:00:00Z',\n   *     LiveEphemeralParameters: {\n   *        model: 'gemini-2.0-flash-001',\n   *        config: {\n   *           'responseModalities': ['AUDIO'],\n   *           'systemInstruction': 'Always answer in English.',\n   *        }\n   *     }\n   * }\n   * const token = await ai.tokens.create(config);\n   *\n   * // Case 3: If LiveEphemeralParameters is set and lockAdditionalFields is\n   * // set, lock LiveConnectConfig with set and additional fields (e.g.\n   * // responseModalities, systemInstruction, temperature in this example) when\n   * // using the token in Live API sessions.\n   * const config: CreateAuthTokenConfig =\n   *     uses: 3,\n   *     expireTime: '2025-05-01T00:00:00Z',\n   *     LiveEphemeralParameters: {\n   *        model: 'gemini-2.0-flash-001',\n   *        config: {\n   *           'responseModalities': ['AUDIO'],\n   *           'systemInstruction': 'Always answer in English.',\n   *        }\n   *     },\n   *     lockAdditionalFields: ['temperature'],\n   * }\n   * const token = await ai.tokens.create(config);\n   *\n   * // Case 4: If LiveEphemeralParameters is set and lockAdditionalFields is\n   * // empty array, lock LiveConnectConfig with set fields (e.g.\n   * // responseModalities, systemInstruction in this example) when using the\n   * // token in Live API sessions.\n   * const config: CreateAuthTokenConfig =\n   *     uses: 3,\n   *     expireTime: '2025-05-01T00:00:00Z',\n   *     LiveEphemeralParameters: {\n   *        model: 'gemini-2.0-flash-001',\n   *        config: {\n   *           'responseModalities': ['AUDIO'],\n   *           'systemInstruction': 'Always answer in English.',\n   *        }\n   *     },\n   *     lockAdditionalFields: [],\n   * }\n   * const token = await ai.tokens.create(config);\n   * ```\n   */\n\n  async create(\n    params: types.CreateAuthTokenParameters,\n  ): Promise<types.AuthToken> {\n    let response: Promise<types.AuthToken>;\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      throw new Error(\n        'The client.tokens.create method is only supported by the Gemini Developer API.',\n      );\n    } else {\n      const body = converters.createAuthTokenParametersToMldev(\n        this.apiClient,\n        params,\n      );\n      path = common.formatMap(\n        'auth_tokens',\n        body['_url'] as Record<string, unknown>,\n      );\n\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['config'];\n      delete body['_url'];\n      delete body['_query'];\n\n      const transformedBody = convertBidiSetupToTokenSetup(body, params.config);\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(transformedBody),\n          httpMethod: 'POST',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json();\n        }) as Promise<types.AuthToken>;\n\n      return response.then((resp) => {\n        return resp as types.AuthToken;\n      });\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\nimport {GoogleAuth, GoogleAuthOptions} from 'google-auth-library';\n\nimport {Auth} from '../_auth.js';\n\nexport const GOOGLE_API_KEY_HEADER = 'x-goog-api-key';\nconst REQUIRED_VERTEX_AI_SCOPE =\n  'https://www.googleapis.com/auth/cloud-platform';\n\nexport interface NodeAuthOptions {\n  /**\n   * The API Key. This is required for Gemini API users.\n   */\n  apiKey?: string;\n  /**\n   * Optional. These are the authentication options provided by google-auth-library for Vertex AI users.\n   * Complete list of authentication options are documented in the\n   * GoogleAuthOptions interface:\n   * https://github.com/googleapis/google-auth-library-nodejs/blob/main/src/auth/googleauth.ts.\n   */\n  googleAuthOptions?: GoogleAuthOptions;\n}\n\nexport class NodeAuth implements Auth {\n  private readonly googleAuth?: GoogleAuth;\n  private readonly apiKey?: string;\n\n  constructor(opts: NodeAuthOptions) {\n    if (opts.apiKey !== undefined) {\n      this.apiKey = opts.apiKey;\n      return;\n    }\n    const vertexAuthOptions = buildGoogleAuthOptions(opts.googleAuthOptions);\n    this.googleAuth = new GoogleAuth(vertexAuthOptions);\n  }\n\n  async addAuthHeaders(headers: Headers, url?: string): Promise<void> {\n    if (this.apiKey !== undefined) {\n      if (this.apiKey.startsWith('auth_tokens/')) {\n        throw new Error('Ephemeral tokens are only supported by the live API.');\n      }\n      this.addKeyHeader(headers);\n      return;\n    }\n\n    return this.addGoogleAuthHeaders(headers, url);\n  }\n\n  private addKeyHeader(headers: Headers) {\n    if (headers.get(GOOGLE_API_KEY_HEADER) !== null) {\n      return;\n    }\n    if (this.apiKey === undefined) {\n      // This should never happen, this method is only called\n      // when apiKey is set.\n      throw new Error('Trying to set API key header but apiKey is not set');\n    }\n    headers.append(GOOGLE_API_KEY_HEADER, this.apiKey);\n  }\n\n  private async addGoogleAuthHeaders(\n    headers: Headers,\n    url?: string,\n  ): Promise<void> {\n    if (this.googleAuth === undefined) {\n      // This should never happen, addGoogleAuthHeaders should only be\n      // called when there is no apiKey set and in these cases googleAuth\n      // is set.\n      throw new Error(\n        'Trying to set google-auth headers but googleAuth is unset',\n      );\n    }\n    const authHeaders = await this.googleAuth.getRequestHeaders(url);\n    for (const [key, value] of authHeaders) {\n      if (headers.get(key) !== null) {\n        continue;\n      }\n      headers.append(key, value);\n    }\n  }\n}\n\nfunction buildGoogleAuthOptions(\n  googleAuthOptions?: GoogleAuthOptions,\n): GoogleAuthOptions {\n  let authOptions: GoogleAuthOptions;\n  if (!googleAuthOptions) {\n    authOptions = {\n      scopes: [REQUIRED_VERTEX_AI_SCOPE],\n    };\n    return authOptions;\n  } else {\n    authOptions = googleAuthOptions;\n    if (!authOptions.scopes) {\n      authOptions.scopes = [REQUIRED_VERTEX_AI_SCOPE];\n      return authOptions;\n    } else if (\n      (typeof authOptions.scopes === 'string' &&\n        authOptions.scopes !== REQUIRED_VERTEX_AI_SCOPE) ||\n      (Array.isArray(authOptions.scopes) &&\n        authOptions.scopes.indexOf(REQUIRED_VERTEX_AI_SCOPE) < 0)\n    ) {\n      throw new Error(\n        `Invalid auth scopes. Scopes must include: ${REQUIRED_VERTEX_AI_SCOPE}`,\n      );\n    }\n    return authOptions;\n  }\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\nimport {createWriteStream, writeFile} from 'fs';\nimport {Readable} from 'node:stream';\nimport type {ReadableStream} from 'node:stream/web';\n\nimport {ApiClient} from '../_api_client.js';\nimport {Downloader} from '../_downloader.js';\nimport {isGeneratedVideo, isVideo, tFileName} from '../_transformers.js';\nimport {\n  DownloadFileParameters,\n  GeneratedVideo,\n  HttpResponse,\n  Video,\n} from '../types.js';\n\nexport class NodeDownloader implements Downloader {\n  async download(\n    params: DownloadFileParameters,\n    apiClient: ApiClient,\n  ): Promise<void> {\n    if (params.downloadPath) {\n      const response = await downloadFile(params, apiClient);\n      if (response instanceof HttpResponse) {\n        const writer = createWriteStream(params.downloadPath);\n        Readable.fromWeb(\n          response.responseInternal.body as ReadableStream<Uint8Array>,\n        ).pipe(writer);\n      } else {\n        writeFile(\n          params.downloadPath,\n          response as string,\n          {encoding: 'base64'},\n          (error) => {\n            if (error) {\n              throw new Error(\n                `Failed to write file to ${params.downloadPath}: ${error}`,\n              );\n            }\n          },\n        );\n      }\n    }\n  }\n}\n\nasync function downloadFile(\n  params: DownloadFileParameters,\n  apiClient: ApiClient,\n): Promise<HttpResponse | string> {\n  const name = tFileName(params.file);\n  if (name !== undefined) {\n    return await apiClient.request({\n      path: `files/${name}:download`,\n      httpMethod: 'GET',\n      queryParams: {\n        'alt': 'media',\n      },\n      httpOptions: params.config?.httpOptions,\n      abortSignal: params.config?.abortSignal,\n    });\n  } else if (isGeneratedVideo(params.file)) {\n    const videoBytes = (params.file as GeneratedVideo).video?.videoBytes;\n    if (typeof videoBytes === 'string') {\n      return videoBytes;\n    } else {\n      throw new Error(\n        'Failed to download generated video, Uri or videoBytes not found.',\n      );\n    }\n  } else if (isVideo(params.file)) {\n    const videoBytes = (params.file as Video).videoBytes;\n    if (typeof videoBytes === 'string') {\n      return videoBytes;\n    } else {\n      throw new Error('Failed to download video, Uri or videoBytes not found.');\n    }\n  } else {\n    throw new Error('Unsupported file type');\n  }\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\nimport * as NodeWs from 'ws';\n\nimport {\n  WebSocket,\n  WebSocketCallbacks,\n  WebSocketFactory,\n} from '../_websocket.js';\n\nexport class NodeWebSocketFactory implements WebSocketFactory {\n  create(\n    url: string,\n    headers: Record<string, string>,\n    callbacks: WebSocketCallbacks,\n  ): WebSocket {\n    return new NodeWebSocket(url, headers, callbacks);\n  }\n}\n\nexport class NodeWebSocket implements WebSocket {\n  private ws?: NodeWs.WebSocket;\n\n  constructor(\n    private readonly url: string,\n    private readonly headers: Record<string, string>,\n    private readonly callbacks: WebSocketCallbacks,\n  ) {}\n\n  connect(): void {\n    this.ws = new NodeWs.WebSocket(this.url, {headers: this.headers});\n\n    this.ws.onopen = this.callbacks.onopen;\n    this.ws.onerror = this.callbacks.onerror;\n    this.ws.onclose = this.callbacks.onclose;\n    this.ws.onmessage = this.callbacks.onmessage;\n  }\n\n  send(message: string) {\n    if (this.ws === undefined) {\n      throw new Error('WebSocket is not connected');\n    }\n\n    this.ws.send(message);\n  }\n\n  close() {\n    if (this.ws === undefined) {\n      throw new Error('WebSocket is not connected');\n    }\n\n    this.ws.close();\n  }\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\n// Code generated by the Google Gen AI SDK generator DO NOT EDIT.\n\nimport * as common from '../_common.js';\nimport * as t from '../_transformers.js';\nimport type * as types from '../types.js';\n\nexport function cancelTuningJobParametersToMldev(\n  fromObject: types.CancelTuningJobParameters,\n  _rootObject?: unknown,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(toObject, ['_url', 'name'], fromName);\n  }\n\n  return toObject;\n}\n\nexport function cancelTuningJobParametersToVertex(\n  fromObject: types.CancelTuningJobParameters,\n  _rootObject?: unknown,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(toObject, ['_url', 'name'], fromName);\n  }\n\n  return toObject;\n}\n\nexport function createTuningJobConfigToMldev(\n  fromObject: types.CreateTuningJobConfig,\n  parentObject: Record<string, unknown>,\n  _rootObject?: unknown,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  if (common.getValueByPath(fromObject, ['validationDataset']) !== undefined) {\n    throw new Error(\n      'validationDataset parameter is not supported in Gemini API.',\n    );\n  }\n\n  const fromTunedModelDisplayName = common.getValueByPath(fromObject, [\n    'tunedModelDisplayName',\n  ]);\n  if (parentObject !== undefined && fromTunedModelDisplayName != null) {\n    common.setValueByPath(\n      parentObject,\n      ['displayName'],\n      fromTunedModelDisplayName,\n    );\n  }\n\n  if (common.getValueByPath(fromObject, ['description']) !== undefined) {\n    throw new Error('description parameter is not supported in Gemini API.');\n  }\n\n  const fromEpochCount = common.getValueByPath(fromObject, ['epochCount']);\n  if (parentObject !== undefined && fromEpochCount != null) {\n    common.setValueByPath(\n      parentObject,\n      ['tuningTask', 'hyperparameters', 'epochCount'],\n      fromEpochCount,\n    );\n  }\n\n  const fromLearningRateMultiplier = common.getValueByPath(fromObject, [\n    'learningRateMultiplier',\n  ]);\n  if (fromLearningRateMultiplier != null) {\n    common.setValueByPath(\n      toObject,\n      ['tuningTask', 'hyperparameters', 'learningRateMultiplier'],\n      fromLearningRateMultiplier,\n    );\n  }\n\n  if (\n    common.getValueByPath(fromObject, ['exportLastCheckpointOnly']) !==\n    undefined\n  ) {\n    throw new Error(\n      'exportLastCheckpointOnly parameter is not supported in Gemini API.',\n    );\n  }\n\n  if (\n    common.getValueByPath(fromObject, ['preTunedModelCheckpointId']) !==\n    undefined\n  ) {\n    throw new Error(\n      'preTunedModelCheckpointId parameter is not supported in Gemini API.',\n    );\n  }\n\n  if (common.getValueByPath(fromObject, ['adapterSize']) !== undefined) {\n    throw new Error('adapterSize parameter is not supported in Gemini API.');\n  }\n\n  const fromBatchSize = common.getValueByPath(fromObject, ['batchSize']);\n  if (parentObject !== undefined && fromBatchSize != null) {\n    common.setValueByPath(\n      parentObject,\n      ['tuningTask', 'hyperparameters', 'batchSize'],\n      fromBatchSize,\n    );\n  }\n\n  const fromLearningRate = common.getValueByPath(fromObject, ['learningRate']);\n  if (parentObject !== undefined && fromLearningRate != null) {\n    common.setValueByPath(\n      parentObject,\n      ['tuningTask', 'hyperparameters', 'learningRate'],\n      fromLearningRate,\n    );\n  }\n\n  if (common.getValueByPath(fromObject, ['labels']) !== undefined) {\n    throw new Error('labels parameter is not supported in Gemini API.');\n  }\n\n  return toObject;\n}\n\nexport function createTuningJobConfigToVertex(\n  fromObject: types.CreateTuningJobConfig,\n  parentObject: Record<string, unknown>,\n  rootObject?: unknown,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromValidationDataset = common.getValueByPath(fromObject, [\n    'validationDataset',\n  ]);\n  if (parentObject !== undefined && fromValidationDataset != null) {\n    common.setValueByPath(\n      parentObject,\n      ['supervisedTuningSpec'],\n      tuningValidationDatasetToVertex(fromValidationDataset, rootObject),\n    );\n  }\n\n  const fromTunedModelDisplayName = common.getValueByPath(fromObject, [\n    'tunedModelDisplayName',\n  ]);\n  if (parentObject !== undefined && fromTunedModelDisplayName != null) {\n    common.setValueByPath(\n      parentObject,\n      ['tunedModelDisplayName'],\n      fromTunedModelDisplayName,\n    );\n  }\n\n  const fromDescription = common.getValueByPath(fromObject, ['description']);\n  if (parentObject !== undefined && fromDescription != null) {\n    common.setValueByPath(parentObject, ['description'], fromDescription);\n  }\n\n  const fromEpochCount = common.getValueByPath(fromObject, ['epochCount']);\n  if (parentObject !== undefined && fromEpochCount != null) {\n    common.setValueByPath(\n      parentObject,\n      ['supervisedTuningSpec', 'hyperParameters', 'epochCount'],\n      fromEpochCount,\n    );\n  }\n\n  const fromLearningRateMultiplier = common.getValueByPath(fromObject, [\n    'learningRateMultiplier',\n  ]);\n  if (parentObject !== undefined && fromLearningRateMultiplier != null) {\n    common.setValueByPath(\n      parentObject,\n      ['supervisedTuningSpec', 'hyperParameters', 'learningRateMultiplier'],\n      fromLearningRateMultiplier,\n    );\n  }\n\n  const fromExportLastCheckpointOnly = common.getValueByPath(fromObject, [\n    'exportLastCheckpointOnly',\n  ]);\n  if (parentObject !== undefined && fromExportLastCheckpointOnly != null) {\n    common.setValueByPath(\n      parentObject,\n      ['supervisedTuningSpec', 'exportLastCheckpointOnly'],\n      fromExportLastCheckpointOnly,\n    );\n  }\n\n  const fromAdapterSize = common.getValueByPath(fromObject, ['adapterSize']);\n  if (parentObject !== undefined && fromAdapterSize != null) {\n    common.setValueByPath(\n      parentObject,\n      ['supervisedTuningSpec', 'hyperParameters', 'adapterSize'],\n      fromAdapterSize,\n    );\n  }\n\n  if (common.getValueByPath(fromObject, ['batchSize']) !== undefined) {\n    throw new Error('batchSize parameter is not supported in Vertex AI.');\n  }\n\n  if (common.getValueByPath(fromObject, ['learningRate']) !== undefined) {\n    throw new Error('learningRate parameter is not supported in Vertex AI.');\n  }\n\n  const fromLabels = common.getValueByPath(fromObject, ['labels']);\n  if (parentObject !== undefined && fromLabels != null) {\n    common.setValueByPath(parentObject, ['labels'], fromLabels);\n  }\n\n  return toObject;\n}\n\nexport function createTuningJobParametersPrivateToMldev(\n  fromObject: types.CreateTuningJobParametersPrivate,\n  rootObject?: unknown,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromBaseModel = common.getValueByPath(fromObject, ['baseModel']);\n  if (fromBaseModel != null) {\n    common.setValueByPath(toObject, ['baseModel'], fromBaseModel);\n  }\n\n  const fromPreTunedModel = common.getValueByPath(fromObject, [\n    'preTunedModel',\n  ]);\n  if (fromPreTunedModel != null) {\n    common.setValueByPath(toObject, ['preTunedModel'], fromPreTunedModel);\n  }\n\n  const fromTrainingDataset = common.getValueByPath(fromObject, [\n    'trainingDataset',\n  ]);\n  if (fromTrainingDataset != null) {\n    common.setValueByPath(\n      toObject,\n      ['tuningTask', 'trainingData'],\n      tuningDatasetToMldev(fromTrainingDataset, rootObject),\n    );\n  }\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    createTuningJobConfigToMldev(fromConfig, toObject, rootObject);\n  }\n\n  return toObject;\n}\n\nexport function createTuningJobParametersPrivateToVertex(\n  fromObject: types.CreateTuningJobParametersPrivate,\n  rootObject?: unknown,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromBaseModel = common.getValueByPath(fromObject, ['baseModel']);\n  if (fromBaseModel != null) {\n    common.setValueByPath(toObject, ['baseModel'], fromBaseModel);\n  }\n\n  const fromPreTunedModel = common.getValueByPath(fromObject, [\n    'preTunedModel',\n  ]);\n  if (fromPreTunedModel != null) {\n    common.setValueByPath(toObject, ['preTunedModel'], fromPreTunedModel);\n  }\n\n  const fromTrainingDataset = common.getValueByPath(fromObject, [\n    'trainingDataset',\n  ]);\n  if (fromTrainingDataset != null) {\n    tuningDatasetToVertex(fromTrainingDataset, toObject, rootObject);\n  }\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    createTuningJobConfigToVertex(fromConfig, toObject, rootObject);\n  }\n\n  return toObject;\n}\n\nexport function getTuningJobParametersToMldev(\n  fromObject: types.GetTuningJobParameters,\n  _rootObject?: unknown,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(toObject, ['_url', 'name'], fromName);\n  }\n\n  return toObject;\n}\n\nexport function getTuningJobParametersToVertex(\n  fromObject: types.GetTuningJobParameters,\n  _rootObject?: unknown,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(toObject, ['_url', 'name'], fromName);\n  }\n\n  return toObject;\n}\n\nexport function listTuningJobsConfigToMldev(\n  fromObject: types.ListTuningJobsConfig,\n  parentObject: Record<string, unknown>,\n  _rootObject?: unknown,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromPageSize = common.getValueByPath(fromObject, ['pageSize']);\n  if (parentObject !== undefined && fromPageSize != null) {\n    common.setValueByPath(parentObject, ['_query', 'pageSize'], fromPageSize);\n  }\n\n  const fromPageToken = common.getValueByPath(fromObject, ['pageToken']);\n  if (parentObject !== undefined && fromPageToken != null) {\n    common.setValueByPath(parentObject, ['_query', 'pageToken'], fromPageToken);\n  }\n\n  const fromFilter = common.getValueByPath(fromObject, ['filter']);\n  if (parentObject !== undefined && fromFilter != null) {\n    common.setValueByPath(parentObject, ['_query', 'filter'], fromFilter);\n  }\n\n  return toObject;\n}\n\nexport function listTuningJobsConfigToVertex(\n  fromObject: types.ListTuningJobsConfig,\n  parentObject: Record<string, unknown>,\n  _rootObject?: unknown,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromPageSize = common.getValueByPath(fromObject, ['pageSize']);\n  if (parentObject !== undefined && fromPageSize != null) {\n    common.setValueByPath(parentObject, ['_query', 'pageSize'], fromPageSize);\n  }\n\n  const fromPageToken = common.getValueByPath(fromObject, ['pageToken']);\n  if (parentObject !== undefined && fromPageToken != null) {\n    common.setValueByPath(parentObject, ['_query', 'pageToken'], fromPageToken);\n  }\n\n  const fromFilter = common.getValueByPath(fromObject, ['filter']);\n  if (parentObject !== undefined && fromFilter != null) {\n    common.setValueByPath(parentObject, ['_query', 'filter'], fromFilter);\n  }\n\n  return toObject;\n}\n\nexport function listTuningJobsParametersToMldev(\n  fromObject: types.ListTuningJobsParameters,\n  rootObject?: unknown,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    listTuningJobsConfigToMldev(fromConfig, toObject, rootObject);\n  }\n\n  return toObject;\n}\n\nexport function listTuningJobsParametersToVertex(\n  fromObject: types.ListTuningJobsParameters,\n  rootObject?: unknown,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromConfig = common.getValueByPath(fromObject, ['config']);\n  if (fromConfig != null) {\n    listTuningJobsConfigToVertex(fromConfig, toObject, rootObject);\n  }\n\n  return toObject;\n}\n\nexport function listTuningJobsResponseFromMldev(\n  fromObject: types.ListTuningJobsResponse,\n  rootObject?: unknown,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSdkHttpResponse = common.getValueByPath(fromObject, [\n    'sdkHttpResponse',\n  ]);\n  if (fromSdkHttpResponse != null) {\n    common.setValueByPath(toObject, ['sdkHttpResponse'], fromSdkHttpResponse);\n  }\n\n  const fromNextPageToken = common.getValueByPath(fromObject, [\n    'nextPageToken',\n  ]);\n  if (fromNextPageToken != null) {\n    common.setValueByPath(toObject, ['nextPageToken'], fromNextPageToken);\n  }\n\n  const fromTuningJobs = common.getValueByPath(fromObject, ['tunedModels']);\n  if (fromTuningJobs != null) {\n    let transformedList = fromTuningJobs;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return tuningJobFromMldev(item, rootObject);\n      });\n    }\n    common.setValueByPath(toObject, ['tuningJobs'], transformedList);\n  }\n\n  return toObject;\n}\n\nexport function listTuningJobsResponseFromVertex(\n  fromObject: types.ListTuningJobsResponse,\n  rootObject?: unknown,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSdkHttpResponse = common.getValueByPath(fromObject, [\n    'sdkHttpResponse',\n  ]);\n  if (fromSdkHttpResponse != null) {\n    common.setValueByPath(toObject, ['sdkHttpResponse'], fromSdkHttpResponse);\n  }\n\n  const fromNextPageToken = common.getValueByPath(fromObject, [\n    'nextPageToken',\n  ]);\n  if (fromNextPageToken != null) {\n    common.setValueByPath(toObject, ['nextPageToken'], fromNextPageToken);\n  }\n\n  const fromTuningJobs = common.getValueByPath(fromObject, ['tuningJobs']);\n  if (fromTuningJobs != null) {\n    let transformedList = fromTuningJobs;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return tuningJobFromVertex(item, rootObject);\n      });\n    }\n    common.setValueByPath(toObject, ['tuningJobs'], transformedList);\n  }\n\n  return toObject;\n}\n\nexport function tunedModelFromMldev(\n  fromObject: types.TunedModel,\n  _rootObject?: unknown,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromModel = common.getValueByPath(fromObject, ['name']);\n  if (fromModel != null) {\n    common.setValueByPath(toObject, ['model'], fromModel);\n  }\n\n  const fromEndpoint = common.getValueByPath(fromObject, ['name']);\n  if (fromEndpoint != null) {\n    common.setValueByPath(toObject, ['endpoint'], fromEndpoint);\n  }\n\n  return toObject;\n}\n\nexport function tuningDatasetToMldev(\n  fromObject: types.TuningDataset,\n  _rootObject?: unknown,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  if (common.getValueByPath(fromObject, ['gcsUri']) !== undefined) {\n    throw new Error('gcsUri parameter is not supported in Gemini API.');\n  }\n\n  if (\n    common.getValueByPath(fromObject, ['vertexDatasetResource']) !== undefined\n  ) {\n    throw new Error(\n      'vertexDatasetResource parameter is not supported in Gemini API.',\n    );\n  }\n\n  const fromExamples = common.getValueByPath(fromObject, ['examples']);\n  if (fromExamples != null) {\n    let transformedList = fromExamples;\n    if (Array.isArray(transformedList)) {\n      transformedList = transformedList.map((item) => {\n        return item;\n      });\n    }\n    common.setValueByPath(toObject, ['examples', 'examples'], transformedList);\n  }\n\n  return toObject;\n}\n\nexport function tuningDatasetToVertex(\n  fromObject: types.TuningDataset,\n  parentObject: Record<string, unknown>,\n  _rootObject?: unknown,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromGcsUri = common.getValueByPath(fromObject, ['gcsUri']);\n  if (parentObject !== undefined && fromGcsUri != null) {\n    common.setValueByPath(\n      parentObject,\n      ['supervisedTuningSpec', 'trainingDatasetUri'],\n      fromGcsUri,\n    );\n  }\n\n  const fromVertexDatasetResource = common.getValueByPath(fromObject, [\n    'vertexDatasetResource',\n  ]);\n  if (parentObject !== undefined && fromVertexDatasetResource != null) {\n    common.setValueByPath(\n      parentObject,\n      ['supervisedTuningSpec', 'trainingDatasetUri'],\n      fromVertexDatasetResource,\n    );\n  }\n\n  if (common.getValueByPath(fromObject, ['examples']) !== undefined) {\n    throw new Error('examples parameter is not supported in Vertex AI.');\n  }\n\n  return toObject;\n}\n\nexport function tuningJobFromMldev(\n  fromObject: types.TuningJob,\n  rootObject?: unknown,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSdkHttpResponse = common.getValueByPath(fromObject, [\n    'sdkHttpResponse',\n  ]);\n  if (fromSdkHttpResponse != null) {\n    common.setValueByPath(toObject, ['sdkHttpResponse'], fromSdkHttpResponse);\n  }\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(toObject, ['name'], fromName);\n  }\n\n  const fromState = common.getValueByPath(fromObject, ['state']);\n  if (fromState != null) {\n    common.setValueByPath(toObject, ['state'], t.tTuningJobStatus(fromState));\n  }\n\n  const fromCreateTime = common.getValueByPath(fromObject, ['createTime']);\n  if (fromCreateTime != null) {\n    common.setValueByPath(toObject, ['createTime'], fromCreateTime);\n  }\n\n  const fromStartTime = common.getValueByPath(fromObject, [\n    'tuningTask',\n    'startTime',\n  ]);\n  if (fromStartTime != null) {\n    common.setValueByPath(toObject, ['startTime'], fromStartTime);\n  }\n\n  const fromEndTime = common.getValueByPath(fromObject, [\n    'tuningTask',\n    'completeTime',\n  ]);\n  if (fromEndTime != null) {\n    common.setValueByPath(toObject, ['endTime'], fromEndTime);\n  }\n\n  const fromUpdateTime = common.getValueByPath(fromObject, ['updateTime']);\n  if (fromUpdateTime != null) {\n    common.setValueByPath(toObject, ['updateTime'], fromUpdateTime);\n  }\n\n  const fromDescription = common.getValueByPath(fromObject, ['description']);\n  if (fromDescription != null) {\n    common.setValueByPath(toObject, ['description'], fromDescription);\n  }\n\n  const fromBaseModel = common.getValueByPath(fromObject, ['baseModel']);\n  if (fromBaseModel != null) {\n    common.setValueByPath(toObject, ['baseModel'], fromBaseModel);\n  }\n\n  const fromTunedModel = common.getValueByPath(fromObject, ['_self']);\n  if (fromTunedModel != null) {\n    common.setValueByPath(\n      toObject,\n      ['tunedModel'],\n      tunedModelFromMldev(fromTunedModel, rootObject),\n    );\n  }\n\n  return toObject;\n}\n\nexport function tuningJobFromVertex(\n  fromObject: types.TuningJob,\n  _rootObject?: unknown,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSdkHttpResponse = common.getValueByPath(fromObject, [\n    'sdkHttpResponse',\n  ]);\n  if (fromSdkHttpResponse != null) {\n    common.setValueByPath(toObject, ['sdkHttpResponse'], fromSdkHttpResponse);\n  }\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(toObject, ['name'], fromName);\n  }\n\n  const fromState = common.getValueByPath(fromObject, ['state']);\n  if (fromState != null) {\n    common.setValueByPath(toObject, ['state'], t.tTuningJobStatus(fromState));\n  }\n\n  const fromCreateTime = common.getValueByPath(fromObject, ['createTime']);\n  if (fromCreateTime != null) {\n    common.setValueByPath(toObject, ['createTime'], fromCreateTime);\n  }\n\n  const fromStartTime = common.getValueByPath(fromObject, ['startTime']);\n  if (fromStartTime != null) {\n    common.setValueByPath(toObject, ['startTime'], fromStartTime);\n  }\n\n  const fromEndTime = common.getValueByPath(fromObject, ['endTime']);\n  if (fromEndTime != null) {\n    common.setValueByPath(toObject, ['endTime'], fromEndTime);\n  }\n\n  const fromUpdateTime = common.getValueByPath(fromObject, ['updateTime']);\n  if (fromUpdateTime != null) {\n    common.setValueByPath(toObject, ['updateTime'], fromUpdateTime);\n  }\n\n  const fromError = common.getValueByPath(fromObject, ['error']);\n  if (fromError != null) {\n    common.setValueByPath(toObject, ['error'], fromError);\n  }\n\n  const fromDescription = common.getValueByPath(fromObject, ['description']);\n  if (fromDescription != null) {\n    common.setValueByPath(toObject, ['description'], fromDescription);\n  }\n\n  const fromBaseModel = common.getValueByPath(fromObject, ['baseModel']);\n  if (fromBaseModel != null) {\n    common.setValueByPath(toObject, ['baseModel'], fromBaseModel);\n  }\n\n  const fromTunedModel = common.getValueByPath(fromObject, ['tunedModel']);\n  if (fromTunedModel != null) {\n    common.setValueByPath(toObject, ['tunedModel'], fromTunedModel);\n  }\n\n  const fromPreTunedModel = common.getValueByPath(fromObject, [\n    'preTunedModel',\n  ]);\n  if (fromPreTunedModel != null) {\n    common.setValueByPath(toObject, ['preTunedModel'], fromPreTunedModel);\n  }\n\n  const fromSupervisedTuningSpec = common.getValueByPath(fromObject, [\n    'supervisedTuningSpec',\n  ]);\n  if (fromSupervisedTuningSpec != null) {\n    common.setValueByPath(\n      toObject,\n      ['supervisedTuningSpec'],\n      fromSupervisedTuningSpec,\n    );\n  }\n\n  const fromTuningDataStats = common.getValueByPath(fromObject, [\n    'tuningDataStats',\n  ]);\n  if (fromTuningDataStats != null) {\n    common.setValueByPath(toObject, ['tuningDataStats'], fromTuningDataStats);\n  }\n\n  const fromEncryptionSpec = common.getValueByPath(fromObject, [\n    'encryptionSpec',\n  ]);\n  if (fromEncryptionSpec != null) {\n    common.setValueByPath(toObject, ['encryptionSpec'], fromEncryptionSpec);\n  }\n\n  const fromPartnerModelTuningSpec = common.getValueByPath(fromObject, [\n    'partnerModelTuningSpec',\n  ]);\n  if (fromPartnerModelTuningSpec != null) {\n    common.setValueByPath(\n      toObject,\n      ['partnerModelTuningSpec'],\n      fromPartnerModelTuningSpec,\n    );\n  }\n\n  const fromCustomBaseModel = common.getValueByPath(fromObject, [\n    'customBaseModel',\n  ]);\n  if (fromCustomBaseModel != null) {\n    common.setValueByPath(toObject, ['customBaseModel'], fromCustomBaseModel);\n  }\n\n  const fromExperiment = common.getValueByPath(fromObject, ['experiment']);\n  if (fromExperiment != null) {\n    common.setValueByPath(toObject, ['experiment'], fromExperiment);\n  }\n\n  const fromLabels = common.getValueByPath(fromObject, ['labels']);\n  if (fromLabels != null) {\n    common.setValueByPath(toObject, ['labels'], fromLabels);\n  }\n\n  const fromOutputUri = common.getValueByPath(fromObject, ['outputUri']);\n  if (fromOutputUri != null) {\n    common.setValueByPath(toObject, ['outputUri'], fromOutputUri);\n  }\n\n  const fromPipelineJob = common.getValueByPath(fromObject, ['pipelineJob']);\n  if (fromPipelineJob != null) {\n    common.setValueByPath(toObject, ['pipelineJob'], fromPipelineJob);\n  }\n\n  const fromServiceAccount = common.getValueByPath(fromObject, [\n    'serviceAccount',\n  ]);\n  if (fromServiceAccount != null) {\n    common.setValueByPath(toObject, ['serviceAccount'], fromServiceAccount);\n  }\n\n  const fromTunedModelDisplayName = common.getValueByPath(fromObject, [\n    'tunedModelDisplayName',\n  ]);\n  if (fromTunedModelDisplayName != null) {\n    common.setValueByPath(\n      toObject,\n      ['tunedModelDisplayName'],\n      fromTunedModelDisplayName,\n    );\n  }\n\n  const fromVeoTuningSpec = common.getValueByPath(fromObject, [\n    'veoTuningSpec',\n  ]);\n  if (fromVeoTuningSpec != null) {\n    common.setValueByPath(toObject, ['veoTuningSpec'], fromVeoTuningSpec);\n  }\n\n  return toObject;\n}\n\nexport function tuningOperationFromMldev(\n  fromObject: types.TuningOperation,\n  _rootObject?: unknown,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromSdkHttpResponse = common.getValueByPath(fromObject, [\n    'sdkHttpResponse',\n  ]);\n  if (fromSdkHttpResponse != null) {\n    common.setValueByPath(toObject, ['sdkHttpResponse'], fromSdkHttpResponse);\n  }\n\n  const fromName = common.getValueByPath(fromObject, ['name']);\n  if (fromName != null) {\n    common.setValueByPath(toObject, ['name'], fromName);\n  }\n\n  const fromMetadata = common.getValueByPath(fromObject, ['metadata']);\n  if (fromMetadata != null) {\n    common.setValueByPath(toObject, ['metadata'], fromMetadata);\n  }\n\n  const fromDone = common.getValueByPath(fromObject, ['done']);\n  if (fromDone != null) {\n    common.setValueByPath(toObject, ['done'], fromDone);\n  }\n\n  const fromError = common.getValueByPath(fromObject, ['error']);\n  if (fromError != null) {\n    common.setValueByPath(toObject, ['error'], fromError);\n  }\n\n  return toObject;\n}\n\nexport function tuningValidationDatasetToVertex(\n  fromObject: types.TuningValidationDataset,\n  _rootObject?: unknown,\n): Record<string, unknown> {\n  const toObject: Record<string, unknown> = {};\n\n  const fromGcsUri = common.getValueByPath(fromObject, ['gcsUri']);\n  if (fromGcsUri != null) {\n    common.setValueByPath(toObject, ['validationDatasetUri'], fromGcsUri);\n  }\n\n  const fromVertexDatasetResource = common.getValueByPath(fromObject, [\n    'vertexDatasetResource',\n  ]);\n  if (fromVertexDatasetResource != null) {\n    common.setValueByPath(\n      toObject,\n      ['validationDatasetUri'],\n      fromVertexDatasetResource,\n    );\n  }\n\n  return toObject;\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\n// Code generated by the Google Gen AI SDK generator DO NOT EDIT.\n\nimport {ApiClient} from './_api_client.js';\nimport * as common from './_common.js';\nimport {BaseModule} from './_common.js';\nimport * as converters from './converters/_tunings_converters.js';\nimport {PagedItem, Pager} from './pagers.js';\nimport * as types from './types.js';\n\nexport class Tunings extends BaseModule {\n  constructor(private readonly apiClient: ApiClient) {\n    super();\n  }\n\n  /**\n   * Gets a TuningJob.\n   *\n   * @param name - The resource name of the tuning job.\n   * @return - A TuningJob object.\n   *\n   * @experimental - The SDK's tuning implementation is experimental, and may\n   * change in future versions.\n   */\n  get = async (\n    params: types.GetTuningJobParameters,\n  ): Promise<types.TuningJob> => {\n    return await this.getInternal(params);\n  };\n\n  /**\n   * Lists tuning jobs.\n   *\n   * @param config - The configuration for the list request.\n   * @return - A list of tuning jobs.\n   *\n   * @experimental - The SDK's tuning implementation is experimental, and may\n   * change in future versions.\n   */\n  list = async (\n    params: types.ListTuningJobsParameters = {},\n  ): Promise<Pager<types.TuningJob>> => {\n    return new Pager<types.TuningJob>(\n      PagedItem.PAGED_ITEM_TUNING_JOBS,\n      (x: types.ListTuningJobsParameters) => this.listInternal(x),\n      await this.listInternal(params),\n      params,\n    );\n  };\n\n  /**\n   * Creates a supervised fine-tuning job.\n   *\n   * @param params - The parameters for the tuning job.\n   * @return - A TuningJob operation.\n   *\n   * @experimental - The SDK's tuning implementation is experimental, and may\n   * change in future versions.\n   */\n  tune = async (\n    params: types.CreateTuningJobParameters,\n  ): Promise<types.TuningJob> => {\n    if (this.apiClient.isVertexAI()) {\n      if (params.baseModel.startsWith('projects/')) {\n        const preTunedModel: types.PreTunedModel = {\n          tunedModelName: params.baseModel,\n        };\n        if (params.config?.preTunedModelCheckpointId) {\n          preTunedModel.checkpointId = params.config.preTunedModelCheckpointId;\n        }\n        const paramsPrivate: types.CreateTuningJobParametersPrivate = {\n          ...params,\n          preTunedModel: preTunedModel,\n        };\n        paramsPrivate.baseModel = undefined;\n        return await this.tuneInternal(paramsPrivate);\n      } else {\n        const paramsPrivate: types.CreateTuningJobParametersPrivate = {\n          ...params,\n        };\n        return await this.tuneInternal(paramsPrivate);\n      }\n    } else {\n      const paramsPrivate: types.CreateTuningJobParametersPrivate = {\n        ...params,\n      };\n      const operation = await this.tuneMldevInternal(paramsPrivate);\n      let tunedModelName = '';\n      if (\n        operation['metadata'] !== undefined &&\n        operation['metadata']['tunedModel'] !== undefined\n      ) {\n        tunedModelName = operation['metadata']['tunedModel'] as string;\n      } else if (\n        operation['name'] !== undefined &&\n        operation['name'].includes('/operations/')\n      ) {\n        tunedModelName = operation['name'].split('/operations/')[0];\n      }\n      const tuningJob: types.TuningJob = {\n        name: tunedModelName,\n        state: types.JobState.JOB_STATE_QUEUED,\n      };\n\n      return tuningJob;\n    }\n  };\n\n  private async getInternal(\n    params: types.GetTuningJobParameters,\n  ): Promise<types.TuningJob> {\n    let response: Promise<types.TuningJob>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      const body = converters.getTuningJobParametersToVertex(params, params);\n      path = common.formatMap(\n        '{name}',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'GET',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json().then((jsonResponse) => {\n            const response = jsonResponse as types.TuningJob;\n            response.sdkHttpResponse = {\n              headers: httpResponse.headers,\n            } as types.HttpResponse;\n            return response;\n          });\n        }) as Promise<types.TuningJob>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.tuningJobFromVertex(apiResponse);\n\n        return resp as types.TuningJob;\n      });\n    } else {\n      const body = converters.getTuningJobParametersToMldev(params, params);\n      path = common.formatMap(\n        '{name}',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'GET',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json().then((jsonResponse) => {\n            const response = jsonResponse as types.TuningJob;\n            response.sdkHttpResponse = {\n              headers: httpResponse.headers,\n            } as types.HttpResponse;\n            return response;\n          });\n        }) as Promise<types.TuningJob>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.tuningJobFromMldev(apiResponse);\n\n        return resp as types.TuningJob;\n      });\n    }\n  }\n\n  private async listInternal(\n    params: types.ListTuningJobsParameters,\n  ): Promise<types.ListTuningJobsResponse> {\n    let response: Promise<types.ListTuningJobsResponse>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      const body = converters.listTuningJobsParametersToVertex(params, params);\n      path = common.formatMap(\n        'tuningJobs',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'GET',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json().then((jsonResponse) => {\n            const response = jsonResponse as types.ListTuningJobsResponse;\n            response.sdkHttpResponse = {\n              headers: httpResponse.headers,\n            } as types.HttpResponse;\n            return response;\n          });\n        }) as Promise<types.ListTuningJobsResponse>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.listTuningJobsResponseFromVertex(apiResponse);\n        const typedResp = new types.ListTuningJobsResponse();\n        Object.assign(typedResp, resp);\n        return typedResp;\n      });\n    } else {\n      const body = converters.listTuningJobsParametersToMldev(params, params);\n      path = common.formatMap(\n        'tunedModels',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'GET',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json().then((jsonResponse) => {\n            const response = jsonResponse as types.ListTuningJobsResponse;\n            response.sdkHttpResponse = {\n              headers: httpResponse.headers,\n            } as types.HttpResponse;\n            return response;\n          });\n        }) as Promise<types.ListTuningJobsResponse>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.listTuningJobsResponseFromMldev(apiResponse);\n        const typedResp = new types.ListTuningJobsResponse();\n        Object.assign(typedResp, resp);\n        return typedResp;\n      });\n    }\n  }\n\n  /**\n   * Cancels a tuning job.\n   *\n   * @param params - The parameters for the cancel request.\n   * @return The empty response returned by the API.\n   *\n   * @example\n   * ```ts\n   * await ai.tunings.cancel({name: '...'}); // The server-generated resource name.\n   * ```\n   */\n  async cancel(params: types.CancelTuningJobParameters): Promise<void> {\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      const body = converters.cancelTuningJobParametersToVertex(params, params);\n      path = common.formatMap(\n        '{name}:cancel',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      await this.apiClient.request({\n        path: path,\n        queryParams: queryParams,\n        body: JSON.stringify(body),\n        httpMethod: 'POST',\n        httpOptions: params.config?.httpOptions,\n        abortSignal: params.config?.abortSignal,\n      });\n    } else {\n      const body = converters.cancelTuningJobParametersToMldev(params, params);\n      path = common.formatMap(\n        '{name}:cancel',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      await this.apiClient.request({\n        path: path,\n        queryParams: queryParams,\n        body: JSON.stringify(body),\n        httpMethod: 'POST',\n        httpOptions: params.config?.httpOptions,\n        abortSignal: params.config?.abortSignal,\n      });\n    }\n  }\n\n  private async tuneInternal(\n    params: types.CreateTuningJobParametersPrivate,\n  ): Promise<types.TuningJob> {\n    let response: Promise<types.TuningJob>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      const body = converters.createTuningJobParametersPrivateToVertex(\n        params,\n        params,\n      );\n      path = common.formatMap(\n        'tuningJobs',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'POST',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json().then((jsonResponse) => {\n            const response = jsonResponse as types.TuningJob;\n            response.sdkHttpResponse = {\n              headers: httpResponse.headers,\n            } as types.HttpResponse;\n            return response;\n          });\n        }) as Promise<types.TuningJob>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.tuningJobFromVertex(apiResponse);\n\n        return resp as types.TuningJob;\n      });\n    } else {\n      throw new Error('This method is only supported by the Vertex AI.');\n    }\n  }\n\n  private async tuneMldevInternal(\n    params: types.CreateTuningJobParametersPrivate,\n  ): Promise<types.TuningOperation> {\n    let response: Promise<types.TuningOperation>;\n\n    let path: string = '';\n    let queryParams: Record<string, string> = {};\n    if (this.apiClient.isVertexAI()) {\n      throw new Error(\n        'This method is only supported by the Gemini Developer API.',\n      );\n    } else {\n      const body = converters.createTuningJobParametersPrivateToMldev(\n        params,\n        params,\n      );\n      path = common.formatMap(\n        'tunedModels',\n        body['_url'] as Record<string, unknown>,\n      );\n      queryParams = body['_query'] as Record<string, string>;\n      delete body['_url'];\n      delete body['_query'];\n\n      response = this.apiClient\n        .request({\n          path: path,\n          queryParams: queryParams,\n          body: JSON.stringify(body),\n          httpMethod: 'POST',\n          httpOptions: params.config?.httpOptions,\n          abortSignal: params.config?.abortSignal,\n        })\n        .then((httpResponse) => {\n          return httpResponse.json().then((jsonResponse) => {\n            const response = jsonResponse as types.TuningOperation;\n            response.sdkHttpResponse = {\n              headers: httpResponse.headers,\n            } as types.HttpResponse;\n            return response;\n          });\n        }) as Promise<types.TuningOperation>;\n\n      return response.then((apiResponse) => {\n        const resp = converters.tuningOperationFromMldev(apiResponse);\n\n        return resp as types.TuningOperation;\n      });\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\nimport {ApiClient} from '../_api_client.js';\nimport {FileStat, Uploader} from '../_uploader.js';\nimport {File, HttpResponse} from '../types.js';\n\nimport {crossError} from './_cross_error.js';\n\nexport const MAX_CHUNK_SIZE = 1024 * 1024 * 8; // bytes\nexport const MAX_RETRY_COUNT = 3;\nexport const INITIAL_RETRY_DELAY_MS = 1000;\nexport const DELAY_MULTIPLIER = 2;\nexport const X_GOOG_UPLOAD_STATUS_HEADER_FIELD = 'x-goog-upload-status';\n\nexport class CrossUploader implements Uploader {\n  async upload(\n    file: string | Blob,\n    uploadUrl: string,\n    apiClient: ApiClient,\n  ): Promise<File> {\n    if (typeof file === 'string') {\n      throw crossError();\n    } else {\n      return uploadBlob(file, uploadUrl, apiClient);\n    }\n  }\n\n  async stat(file: string | Blob): Promise<FileStat> {\n    if (typeof file === 'string') {\n      throw crossError();\n    } else {\n      return getBlobStat(file);\n    }\n  }\n}\n\nexport async function uploadBlob(\n  file: Blob,\n  uploadUrl: string,\n  apiClient: ApiClient,\n): Promise<File> {\n  let fileSize = 0;\n  let offset = 0;\n  let response: HttpResponse = new HttpResponse(new Response());\n  let uploadCommand = 'upload';\n  fileSize = file.size;\n  while (offset < fileSize) {\n    const chunkSize = Math.min(MAX_CHUNK_SIZE, fileSize - offset);\n    const chunk = file.slice(offset, offset + chunkSize);\n    if (offset + chunkSize >= fileSize) {\n      uploadCommand += ', finalize';\n    }\n    let retryCount = 0;\n    let currentDelayMs = INITIAL_RETRY_DELAY_MS;\n    while (retryCount < MAX_RETRY_COUNT) {\n      response = await apiClient.request({\n        path: '',\n        body: chunk,\n        httpMethod: 'POST',\n        httpOptions: {\n          apiVersion: '',\n          baseUrl: uploadUrl,\n          headers: {\n            'X-Goog-Upload-Command': uploadCommand,\n            'X-Goog-Upload-Offset': String(offset),\n            'Content-Length': String(chunkSize),\n          },\n        },\n      });\n      if (response?.headers?.[X_GOOG_UPLOAD_STATUS_HEADER_FIELD]) {\n        break;\n      }\n      retryCount++;\n      await sleep(currentDelayMs);\n      currentDelayMs = currentDelayMs * DELAY_MULTIPLIER;\n    }\n    offset += chunkSize;\n    // The `x-goog-upload-status` header field can be `active`, `final` and\n    //`cancelled` in resposne.\n    if (response?.headers?.[X_GOOG_UPLOAD_STATUS_HEADER_FIELD] !== 'active') {\n      break;\n    }\n    // TODO(b/401391430) Investigate why the upload status is not finalized\n    // even though all content has been uploaded.\n    if (fileSize <= offset) {\n      throw new Error(\n        'All content has been uploaded, but the upload status is not finalized.',\n      );\n    }\n  }\n  const responseJson = (await response?.json()) as Record<\n    string,\n    File | unknown\n  >;\n  if (response?.headers?.[X_GOOG_UPLOAD_STATUS_HEADER_FIELD] !== 'final') {\n    throw new Error('Failed to upload file: Upload status is not finalized.');\n  }\n  return responseJson['file'] as File;\n}\n\nexport async function getBlobStat(file: Blob): Promise<FileStat> {\n  const fileStat: FileStat = {size: file.size, type: file.type};\n  return fileStat;\n}\n\nexport function sleep(ms: number): Promise<void> {\n  return new Promise((resolvePromise) => setTimeout(resolvePromise, ms));\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\nimport * as fs from 'fs/promises';\n\nimport {ApiClient} from '../_api_client.js';\nimport {FileStat, Uploader} from '../_uploader.js';\nimport {\n  DELAY_MULTIPLIER,\n  INITIAL_RETRY_DELAY_MS,\n  MAX_CHUNK_SIZE,\n  MAX_RETRY_COUNT,\n  X_GOOG_UPLOAD_STATUS_HEADER_FIELD,\n  getBlobStat,\n  sleep,\n  uploadBlob,\n} from '../cross/_cross_uploader.js';\nimport {File, HttpResponse} from '../types.js';\n\nexport class NodeUploader implements Uploader {\n  async stat(file: string | Blob): Promise<FileStat> {\n    const fileStat: FileStat = {size: 0, type: undefined};\n    if (typeof file === 'string') {\n      const originalStat = await fs.stat(file);\n      fileStat.size = originalStat.size;\n      fileStat.type = this.inferMimeType(file);\n      return fileStat;\n    } else {\n      return await getBlobStat(file);\n    }\n  }\n\n  async upload(\n    file: string | Blob,\n    uploadUrl: string,\n    apiClient: ApiClient,\n  ): Promise<File> {\n    if (typeof file === 'string') {\n      return await this.uploadFileFromPath(file, uploadUrl, apiClient);\n    } else {\n      return uploadBlob(file, uploadUrl, apiClient);\n    }\n  }\n\n  /**\n   * Infers the MIME type of a file based on its extension.\n   *\n   * @param filePath The path to the file.\n   * @returns The MIME type of the file, or undefined if it cannot be inferred.\n   */\n  private inferMimeType(filePath: string): string | undefined {\n    // Get the file extension.\n    const fileExtension = filePath.slice(filePath.lastIndexOf('.') + 1);\n\n    // Create a map of file extensions to MIME types.\n    const mimeTypes: {[key: string]: string} = {\n      'aac': 'audio/aac',\n      'abw': 'application/x-abiword',\n      'arc': 'application/x-freearc',\n      'avi': 'video/x-msvideo',\n      'azw': 'application/vnd.amazon.ebook',\n      'bin': 'application/octet-stream',\n      'bmp': 'image/bmp',\n      'bz': 'application/x-bzip',\n      'bz2': 'application/x-bzip2',\n      'csh': 'application/x-csh',\n      'css': 'text/css',\n      'csv': 'text/csv',\n      'doc': 'application/msword',\n      'docx':\n        'application/vnd.openxmlformats-officedocument.wordprocessingml.document',\n      'eot': 'application/vnd.ms-fontobject',\n      'epub': 'application/epub+zip',\n      'gz': 'application/gzip',\n      'gif': 'image/gif',\n      'htm': 'text/html',\n      'html': 'text/html',\n      'ico': 'image/vnd.microsoft.icon',\n      'ics': 'text/calendar',\n      'jar': 'application/java-archive',\n      'jpeg': 'image/jpeg',\n      'jpg': 'image/jpeg',\n      'js': 'text/javascript',\n      'json': 'application/json',\n      'jsonld': 'application/ld+json',\n      'kml': 'application/vnd.google-earth.kml+xml',\n      'kmz': 'application/vnd.google-earth.kmz+xml',\n      'mjs': 'text/javascript',\n      'mp3': 'audio/mpeg',\n      'mp4': 'video/mp4',\n      'mpeg': 'video/mpeg',\n      'mpkg': 'application/vnd.apple.installer+xml',\n      'odt': 'application/vnd.oasis.opendocument.text',\n      'oga': 'audio/ogg',\n      'ogv': 'video/ogg',\n      'ogx': 'application/ogg',\n      'opus': 'audio/opus',\n      'otf': 'font/otf',\n      'png': 'image/png',\n      'pdf': 'application/pdf',\n      'php': 'application/x-httpd-php',\n      'ppt': 'application/vnd.ms-powerpoint',\n      'pptx':\n        'application/vnd.openxmlformats-officedocument.presentationml.presentation',\n      'rar': 'application/vnd.rar',\n      'rtf': 'application/rtf',\n      'sh': 'application/x-sh',\n      'svg': 'image/svg+xml',\n      'swf': 'application/x-shockwave-flash',\n      'tar': 'application/x-tar',\n      'tif': 'image/tiff',\n      'tiff': 'image/tiff',\n      'ts': 'video/mp2t',\n      'ttf': 'font/ttf',\n      'txt': 'text/plain',\n      'vsd': 'application/vnd.visio',\n      'wav': 'audio/wav',\n      'weba': 'audio/webm',\n      'webm': 'video/webm',\n      'webp': 'image/webp',\n      'woff': 'font/woff',\n      'woff2': 'font/woff2',\n      'xhtml': 'application/xhtml+xml',\n      'xls': 'application/vnd.ms-excel',\n      'xlsx':\n        'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',\n      'xml': 'application/xml',\n      'xul': 'application/vnd.mozilla.xul+xml',\n      'zip': 'application/zip',\n      '3gp': 'video/3gpp',\n      '3g2': 'video/3gpp2',\n      '7z': 'application/x-7z-compressed',\n    };\n\n    // Look up the MIME type based on the file extension.\n    const mimeType = mimeTypes[fileExtension.toLowerCase()];\n\n    // Return the MIME type.\n    return mimeType;\n  }\n\n  private async uploadFileFromPath(\n    file: string,\n    uploadUrl: string,\n    apiClient: ApiClient,\n  ): Promise<File> {\n    let fileSize = 0;\n    let offset = 0;\n    let response: HttpResponse = new HttpResponse(new Response());\n    let uploadCommand = 'upload';\n    let fileHandle: fs.FileHandle | undefined;\n    try {\n      fileHandle = await fs.open(file, 'r');\n      if (!fileHandle) {\n        throw new Error(`Failed to open file`);\n      }\n      fileSize = (await fileHandle.stat()).size;\n      while (offset < fileSize) {\n        const chunkSize = Math.min(MAX_CHUNK_SIZE, fileSize - offset);\n        if (offset + chunkSize >= fileSize) {\n          uploadCommand += ', finalize';\n        }\n        const buffer = new Uint8Array(chunkSize);\n        const {bytesRead: bytesRead} = await fileHandle.read(\n          buffer,\n          0,\n          chunkSize,\n          offset,\n        );\n\n        if (bytesRead !== chunkSize) {\n          throw new Error(\n            `Failed to read ${chunkSize} bytes from file at offset ${\n              offset\n            }. bytes actually read: ${bytesRead}`,\n          );\n        }\n\n        const chunk = new Blob([buffer]);\n        let retryCount = 0;\n        let currentDelayMs = INITIAL_RETRY_DELAY_MS;\n        while (retryCount < MAX_RETRY_COUNT) {\n          response = await apiClient.request({\n            path: '',\n            body: chunk,\n            httpMethod: 'POST',\n            httpOptions: {\n              apiVersion: '',\n              baseUrl: uploadUrl,\n              headers: {\n                'X-Goog-Upload-Command': uploadCommand,\n                'X-Goog-Upload-Offset': String(offset),\n                'Content-Length': String(bytesRead),\n              },\n            },\n          });\n          if (response?.headers?.[X_GOOG_UPLOAD_STATUS_HEADER_FIELD]) {\n            break;\n          }\n          retryCount++;\n          await sleep(currentDelayMs);\n          currentDelayMs = currentDelayMs * DELAY_MULTIPLIER;\n        }\n        offset += bytesRead;\n        // The `x-goog-upload-status` header field can be `active`, `final` and\n        //`cancelled` in resposne.\n        if (\n          response?.headers?.[X_GOOG_UPLOAD_STATUS_HEADER_FIELD] !== 'active'\n        ) {\n          break;\n        }\n        if (fileSize <= offset) {\n          throw new Error(\n            'All content has been uploaded, but the upload status is not finalized.',\n          );\n        }\n      }\n      const responseJson = (await response?.json()) as Record<\n        string,\n        File | unknown\n      >;\n      if (response?.headers?.[X_GOOG_UPLOAD_STATUS_HEADER_FIELD] !== 'final') {\n        throw new Error(\n          'Failed to upload file: Upload status is not finalized.',\n        );\n      }\n      return responseJson['file'] as File;\n    } finally {\n      // Ensure the file handle is always closed\n      if (fileHandle) {\n        await fileHandle.close();\n      }\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\nimport {GoogleAuthOptions} from 'google-auth-library';\n\nimport {ApiClient} from '../_api_client.js';\nimport {getBaseUrl} from '../_base_url.js';\nimport {Batches} from '../batches.js';\nimport {Caches} from '../caches.js';\nimport {Chats} from '../chats.js';\nimport {GoogleGenAIOptions} from '../client.js';\nimport {Files} from '../files.js';\nimport {Live} from '../live.js';\nimport {Models} from '../models.js';\nimport {NodeAuth} from '../node/_node_auth.js';\nimport {NodeDownloader} from '../node/_node_downloader.js';\nimport {NodeWebSocketFactory} from '../node/_node_websocket.js';\nimport {Operations} from '../operations.js';\nimport {Tokens} from '../tokens.js';\nimport {Tunings} from '../tunings.js';\n\nimport {NodeUploader} from './_node_uploader.js';\n\nconst LANGUAGE_LABEL_PREFIX = 'gl-node/';\n\n/**\n * The Google GenAI SDK.\n *\n * @remarks\n * Provides access to the GenAI features through either the {@link\n * https://cloud.google.com/vertex-ai/docs/reference/rest | Gemini API} or\n * the {@link https://cloud.google.com/vertex-ai/docs/reference/rest | Vertex AI\n * API}.\n *\n * The {@link GoogleGenAIOptions.vertexai} value determines which of the API\n * services to use.\n *\n * When using the Gemini API, a {@link GoogleGenAIOptions.apiKey} must also be\n * set. When using Vertex AI, both {@link GoogleGenAIOptions.project} and {@link\n * GoogleGenAIOptions.location} must be set, or a {@link\n * GoogleGenAIOptions.apiKey} must be set when using Express Mode.\n *\n * Explicitly passed in values in {@link GoogleGenAIOptions} will always take\n * precedence over environment variables. If both project/location and api_key\n * exist in the environment variables, the project/location will be used.\n *\n * @example\n * Initializing the SDK for using the Gemini API:\n * ```ts\n * import {GoogleGenAI} from '@google/genai';\n * const ai = new GoogleGenAI({apiKey: 'GEMINI_API_KEY'});\n * ```\n *\n * @example\n * Initializing the SDK for using the Vertex AI API:\n * ```ts\n * import {GoogleGenAI} from '@google/genai';\n * const ai = new GoogleGenAI({\n *   vertexai: true,\n *   project: 'PROJECT_ID',\n *   location: 'PROJECT_LOCATION'\n * });\n * ```\n *\n */\nexport class GoogleGenAI {\n  protected readonly apiClient: ApiClient;\n  private readonly apiKey?: string;\n  public readonly vertexai: boolean;\n  private readonly googleAuthOptions?: GoogleAuthOptions;\n  private readonly project?: string;\n  private readonly location?: string;\n  private readonly apiVersion?: string;\n  readonly models: Models;\n  readonly live: Live;\n  readonly batches: Batches;\n  readonly chats: Chats;\n  readonly caches: Caches;\n  readonly files: Files;\n  readonly operations: Operations;\n  readonly authTokens: Tokens;\n  readonly tunings: Tunings;\n\n  constructor(options: GoogleGenAIOptions) {\n    // Validate explicitly set initializer values.\n    if ((options.project || options.location) && options.apiKey) {\n      throw new Error(\n        'Project/location and API key are mutually exclusive in the client initializer.',\n      );\n    }\n\n    this.vertexai =\n      options.vertexai ?? getBooleanEnv('GOOGLE_GENAI_USE_VERTEXAI') ?? false;\n    const envApiKey = getApiKeyFromEnv();\n    const envProject = getEnv('GOOGLE_CLOUD_PROJECT');\n    const envLocation = getEnv('GOOGLE_CLOUD_LOCATION');\n\n    this.apiKey = options.apiKey ?? envApiKey;\n    this.project = options.project ?? envProject;\n    this.location = options.location ?? envLocation;\n\n    // Handle when to use Vertex AI in express mode (api key)\n    if (options.vertexai) {\n      if (options.googleAuthOptions?.credentials) {\n        // Explicit credentials take precedence over implicit api_key.\n        console.debug(\n          'The user provided Google Cloud credentials will take precedence' +\n            ' over the API key from the environment variable.',\n        );\n        this.apiKey = undefined;\n      }\n      // Explicit api_key and explicit project/location already handled above.\n      if ((envProject || envLocation) && options.apiKey) {\n        // Explicit api_key takes precedence over implicit project/location.\n        console.debug(\n          'The user provided Vertex AI API key will take precedence over' +\n            ' the project/location from the environment variables.',\n        );\n        this.project = undefined;\n        this.location = undefined;\n      } else if ((options.project || options.location) && envApiKey) {\n        // Explicit project/location takes precedence over implicit api_key.\n        console.debug(\n          'The user provided project/location will take precedence over' +\n            ' the API key from the environment variables.',\n        );\n        this.apiKey = undefined;\n      } else if ((envProject || envLocation) && envApiKey) {\n        // Implicit project/location takes precedence over implicit api_key.\n        console.debug(\n          'The project/location from the environment variables will take' +\n            ' precedence over the API key from the environment variables.',\n        );\n        this.apiKey = undefined;\n      }\n    }\n\n    const baseUrl = getBaseUrl(\n      options.httpOptions,\n      options.vertexai,\n      getEnv('GOOGLE_VERTEX_BASE_URL'),\n      getEnv('GOOGLE_GEMINI_BASE_URL'),\n    );\n    if (baseUrl) {\n      if (options.httpOptions) {\n        options.httpOptions.baseUrl = baseUrl;\n      } else {\n        options.httpOptions = {baseUrl: baseUrl};\n      }\n    }\n\n    this.apiVersion = options.apiVersion;\n    const auth = new NodeAuth({\n      apiKey: this.apiKey,\n      googleAuthOptions: options.googleAuthOptions,\n    });\n    this.apiClient = new ApiClient({\n      auth: auth,\n      project: this.project,\n      location: this.location,\n      apiVersion: this.apiVersion,\n      apiKey: this.apiKey,\n      vertexai: this.vertexai,\n      httpOptions: options.httpOptions,\n      userAgentExtra: LANGUAGE_LABEL_PREFIX + process.version,\n      uploader: new NodeUploader(),\n      downloader: new NodeDownloader(),\n    });\n    this.models = new Models(this.apiClient);\n    this.live = new Live(this.apiClient, auth, new NodeWebSocketFactory());\n    this.batches = new Batches(this.apiClient);\n    this.chats = new Chats(this.models, this.apiClient);\n    this.caches = new Caches(this.apiClient);\n    this.files = new Files(this.apiClient);\n    this.operations = new Operations(this.apiClient);\n    this.authTokens = new Tokens(this.apiClient);\n    this.tunings = new Tunings(this.apiClient);\n  }\n}\n\nfunction getEnv(env: string): string | undefined {\n  return process?.env?.[env]?.trim() ?? undefined;\n}\n\nfunction getBooleanEnv(env: string): boolean {\n  return stringToBoolean(getEnv(env));\n}\n\nfunction stringToBoolean(str?: string): boolean {\n  if (str === undefined) {\n    return false;\n  }\n  return str.toLowerCase() === 'true';\n}\n\nfunction getApiKeyFromEnv(): string | undefined {\n  const envGoogleApiKey = getEnv('GOOGLE_API_KEY');\n  const envGeminiApiKey = getEnv('GEMINI_API_KEY');\n  if (envGoogleApiKey && envGeminiApiKey) {\n    console.warn(\n      'Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.',\n    );\n  }\n  return envGoogleApiKey || envGeminiApiKey || undefined;\n}\n"],"names":["module","exports","require","vendored","ReactServerDOMTurbopackServer","registerServerReference","AppRenderSpan","AppRouteRouteHandlersSpan","BaseServerSpan","LoadComponentsSpan","LogSpanAllowList","MiddlewareSpan","NextNodeServerSpan","NextServerSpan","NextVanillaSpanAllowlist","NodeSpan","RenderSpan","ResolveMetadataSpan","RouterSpan","StartServerSpan","isThenable","promise","then","BubbledError","SpanKind","SpanStatusCode","getTracer","isBubbledError","api","process","env","NEXT_RUNTIME","err","context","propagation","trace","ROOT_CONTEXT","Error","constructor","bubble","result","error","closeSpanWithError","span","setAttribute","recordException","name","setStatus","code","ERROR","message","end","rootSpanAttributesStore","Map","rootSpanIdKey","createContextKey","lastSpanId","getSpanId","clientTraceDataSetter","set","carrier","key","value","push","NextTracerImpl","getTracerInstance","getContext","getTracePropagationData","activeContext","active","entries","inject","getActiveScopeSpan","getSpan","withPropagatedContext","fn","getter","getSpanContext","remoteContext","extract","with","args","type","fnOrOptions","fnOrEmpty","options","spanName","includes","NEXT_OTEL_VERBOSE","hideSpan","spanContext","parentSpan","isRootSpan","isRemote","spanId","attributes","setValue","startActiveSpan","startTime","globalThis","performance","now","undefined","onCleanup","delete","NEXT_OTEL_PERFORMANCE_PREFIX","measure","split","pop","replace","match","toLowerCase","start","Object","length","res","catch","finally","wrap","tracer","optionsObj","apply","arguments","lastArgId","cb","scopeBoundCb","bind","_span","done","startSpan","setSpan","getRootSpanAttributes","getValue","get","setRootSpanAttribute","has","cloneResponse","noop","registry","FinalizationRegistry","weakRef","stream","deref","locked","cancel","original","body","body1","body2","tee","cloned1","Response","status","statusText","headers","defineProperty","url","configurable","enumerable","writable","register","WeakRef","cloned2","createDedupeFetch","simpleCacheKey","headersToExcludeInCacheKey","Set","generateCacheKey","request","filteredHeaders","Array","from","filter","JSON","stringify","method","mode","redirect","credentials","referrer","referrerPolicy","integrity","originalFetch","getCacheEntries","React","cache","dedupeFetch","resource","signal","cacheKey","URL","Request","keepalive","cacheEntries","i","j","response","InvariantError","entry","CachedRouteKind","IncrementalCacheKind","DetachedPromise","resolve","reject","Promise","rej","Batcher","cacheKeyFn","schedulerFn","pending","create","batch","ENCODED_TAGS","OPENING","HTML","Uint8Array","BODY","CLOSED","HEAD","BODY_AND_HTML","META","ICON_MARK","indexOfUint8Array","isEquivalentUint8Arrays","removeFromUint8Array","a","b","completeMatch","tagIndex","subarray","removed","slice","MISSING_ROOT_TAGS_ERROR","DOC_PREFETCH_RANGE_HEADER_VALUE","doesExportedHtmlMatchBuildId","insertBuildIdComment","DOCTYPE_PREFIX","MAX_BUILD_ID_LENGTH","escapeBuildId","buildId","truncated","originalHtml","startsWith","partialHtmlDocument","ACTION_HEADER","FLIGHT_HEADERS","NEXT_ACTION_NOT_FOUND_HEADER","NEXT_DID_POSTPONE_HEADER","NEXT_HMR_REFRESH_HASH_COOKIE","NEXT_HMR_REFRESH_HEADER","NEXT_HTML_REQUEST_ID_HEADER","NEXT_IS_PRERENDER_HEADER","NEXT_REQUEST_ID_HEADER","NEXT_REWRITTEN_PATH_HEADER","NEXT_REWRITTEN_QUERY_HEADER","NEXT_ROUTER_PREFETCH_HEADER","NEXT_ROUTER_SEGMENT_PREFETCH_HEADER","NEXT_ROUTER_STALE_TIME_HEADER","NEXT_ROUTER_STATE_TREE_HEADER","NEXT_RSC_UNION_QUERY","NEXT_URL","RSC_CONTENT_TYPE_HEADER","RSC_HEADER","djb2Hash","hexHash","str","hash","char","charCodeAt","toString","computeCacheBustingSearchParam","prefetchHeader","segmentPrefetchHeader","stateTreeHeader","nextUrlHeader","join","chainStreams","continueDynamicHTMLResume","continueDynamicPrerender","continueFizzStream","continueStaticFallbackPrerender","continueStaticPrerender","createBufferedTransformStream","createDocumentClosingStream","createRootLayoutValidatorStream","renderToInitialFizzStream","streamFromBuffer","streamFromString","streamToBuffer","streamToString","voidCatch","encoder","TextEncoder","streams","ReadableStream","controller","close","readable","TransformStream","pipeTo","preventClose","nextStream","lastStream","enqueue","encode","chunk","reader","getReader","chunks","read","Buffer","concat","decoder","TextDecoder","fatal","string","aborted","decode","maxBufferByteLength","Infinity","bufferedChunks","bufferByteLength","flush","copiedBytes","bufferedChunk","byteLength","scheduleFlush","detached","scheduleImmediate","transform","createPrefetchCommentStream","isBuildTimePrerendering","didTransformFirstChunk","chunkStr","updatedChunkStr","ReactDOMServer","element","streamOptions","renderToReadableStream","createMetadataTransformStream","insert","chunkIndex","isMarkRemoved","iconMarkIndex","closedHeadIndex","iconMarkLength","replaced","insertion","encodedInsertion","insertionLength","createHeadInsertionTransformStream","inserted","hasBytes","index","insertedHeadContent","createClientResumeScriptInsertionTransformStream","segmentPath","cacheBustingHeader","searchStr","NEXT_CLIENT_RESUME_SCRIPT","didAlreadyInsert","headClosingTagIndex","createDeferredSuffixStream","suffix","flushed","createFlightDataInjectionTransformStream","delayDataUntilFirstHtmlChunk","htmlStreamFinished","pull","donePulling","startOrContinuePulling","startPulling","atLeastOneTask","CLOSE_TAG","createMoveSuffixStream","foundSuffix","before","after","createStripDocumentClosingTagsTransform","foundHtml","foundBody","missingTags","map","c","chainTransformers","transformers","transformer","pipeThrough","renderStream","inlinedDataStream","isStaticGeneration","getServerInsertedHTML","getServerInsertedMetadata","validateRootLayout","suffixUnclosed","allReady","prerenderStream","NEXT_REQUEST_META","addRequestMeta","getRequestMeta","removeRequestMeta","setRequestMeta","Symbol","for","req","meta","isNodeNextRequest","isNodeNextResponse","isWebNextRequest","isWebNextResponse","NextRequestAdapter","ResponseAborted","ResponseAbortedName","createAbortController","signalFromNodeResponse","AbortController","once","writableFinished","abort","errored","destroyed","AbortSignal","fromBaseNextRequest","fromWebNextRequest","fromNodeNextRequest","base","NextRequest","fromNodeOutgoingHttpHeaders","duplex","getClientComponentLoaderMetrics","wrapClientComponentLoader","clientComponentLoadStart","clientComponentLoadTimes","clientComponentLoadCount","ComponentMod","__next_app__","loadChunk","metrics","reset","isAbortError","pipeToNodeResponse","e","createWriterFromResponse","waitUntilForEnd","started","drained","onDrain","on","off","finished","WritableStream","write","flushHeaders","startResponse","ok","cause","destroy","writer","RenderResult","EMPTY","metadata","contentType","fromStatic","waitUntil","assignMetadata","assign","isNull","isDynamic","toUnchunkedString","isBuffer","isArray","coerce","unshift","RouteKind","fromResponseCacheEntry","routeKindToIncrementalCacheKind","toResponseCacheEntry","cacheEntry","kind","PAGES","html","pageData","APP_PAGE","postponed","rscData","segmentData","isMiss","isStale","cacheControl","HTML_CONTENT_TYPE_HEADER","routeKind","IMAGE","APP_ROUTE","PAGES_API","ResponseCache","minimal_mode","getBatcher","isOnDemandRevalidate","scheduleOnNextTick","revalidateBatcher","responseGenerator","hasResolved","previousCacheEntry","previousCacheItem","expiresAt","Date","incrementalCache","isFallback","isRoutePPREnabled","isPrefetch","handleGet","previousIncrementalCacheEntry","resolved","incrementalResponseCacheEntry","revalidate","console","handleRevalidate","responseCacheEntry","isRevalidating","Math","min","max","expire","NEXT_PATCH_SYMBOL","createPatchedFetcher","patchFetch","validateRevalidate","validateTags","isEdgeRuntime","isFetchPatched","revalidateVal","route","normalizedRevalidate","INFINITE_CACHE","isNaN","tags","description","validTags","invalidTags","tag","reason","NEXT_CACHE_TAG_MAX_LENGTH","NEXT_CACHE_TAG_MAX_ITEMS","warn","log","trackFetchMetric","workStore","ctx","shouldTrackFetchMetrics","fetchMetrics","timeOrigin","idx","nextFetchId","createCachedPrerenderResponse","incrementalCacheContext","handleUnlock","bodyBuffer","arrayBuffer","fetchedData","fromEntries","FETCH","data","createCachedDynamicResponse","serverComponentsHmrCache","input","cacheSetPromise","pendingRevalidateKey","pendingRevalidates","originFetch","workAsyncStorage","workUnitAsyncStorage","patched","fetch","init","username","password","fetchUrl","href","toUpperCase","isInternal","next","internal","NEXT_OTEL_FETCH_DISABLED","fetchStart","getStore","workUnitStore","cacheSignal","getCacheSignal","beginRead","internalFetch","CLIENT","Boolean","hostname","port","isDraftMode","isRequestInput","field","finalRevalidate","getNextField","originalFetchRevalidate","currentFetchRevalidate","revalidateStore","collectedTags","implicitTags","pageFetchCacheMode","fetchCache","isUsingNoStore","isUnstableNoStore","currentFetchCacheConfig","cacheReason","cacheWarning","isConflictingRevalidate","hasExplicitFetchCacheOptOut","noFetchConfigAndForceDynamic","forceDynamic","_headers","initHeaders","Headers","hasUnCacheableHeader","isUnCacheableMethod","hasNoExplicitCacheConfig","autoNoCache","isImplicitBuildTimeCache","endRead","makeHangingPromise","renderSignal","NODE_ENV","stagedRendering","waitForStage","RenderStage","Dynamic","forceStatic","markCurrentScopeAsDynamic","isCacheableRevalidate","isHmrRefresh","fetchIdx","doOriginalFetch","cacheReasonOverride","requestInputFields","reqInput","reqOptions","_ogBody","otherInput","clonedInit","fetchType","cacheStatus","CACHE_ONE_YEAR","incrementalCacheConfig","isForegroundRevalidate","isHmrRefreshCache","cachedFetchData","lock","softTags","getTimeoutBoundary","pendingRevalidate","__NEXT_CACHE_COMPONENTS","hasNextConfig","revalidatedResult","pendingResponse","responses","__nextPatched","__nextGetStaticStore","_nextOriginalFetch","currentTimeoutBoundary","r","setTimeout","unstable_cache","noStoreFetchIdx","cacheNewResult","keyParts","fixedKey","cachedCb","maybeIncrementalCache","__incrementalCache","fetchUrlPrefix","getFetchUrlPrefix","invocationKey","innerCacheStore","phase","draftMode","getDraftModeProviderForCacheScope","isNestedUnstableCache","cachedResponse","parse","revalidationPromise","run","pathname","searchParams","URLSearchParams","search","sortedSearch","keys","sort","localeCompare","getSortedRouteObjects","getSortedRoutes","UrlNode","urlPath","_insert","smoosh","_smoosh","prefix","childrenPaths","children","slugName","splice","indexOf","restSlugName","optionalRestSlugName","routes","reduce","prev","curr","placeholder","urlPaths","slugNames","isCatchAll","nextSegment","endsWith","segmentName","isOptional","substring","handleSlug","previousSlug","nextSlug","forEach","slug","normalizedPages","root","pagePath","objects","indexes","pathnames","sorted","ensureLeadingSlash","path","DEFAULT_SEGMENT_KEY","PAGE_SEGMENT_KEY","addSearchParamsIfPageSegment","computeSelectedLayoutSegment","getSegmentValue","getSelectedLayoutSegmentPath","isGroupSegment","isParallelRouteSegment","segment","isPageSegment","stringifiedQuery","segments","parallelRouteKey","rawSegment","tree","first","node","parallelRoutes","values","segmentValue","normalizeAppPath","normalizeRscURL","INTERCEPTION_ROUTE_MARKERS","extractInterceptionRouteInformation","isInterceptionRouteAppPath","find","m","interceptingRoute","marker","interceptedRoute","splitInterceptingRoute","isDynamicRoute","TEST_ROUTE","TEST_STRICT_ROUTE","strict","test","refresh","revalidatePath","revalidateTag","updateTag","profile","page","pathWasRevalidated","originalPath","NEXT_CACHE_SOFT_TAG_MAX_LENGTH","normalizedPath","NEXT_CACHE_IMPLICIT_TAG_ID","expression","store","abortAndThrowOnSynchronousRequestDataAccess","postponeWithTracking","dynamicTracking","DynamicServerError","dynamicUsageDescription","dynamicUsageStack","stack","usedDynamic","pendingRevalidatedTags","existingIndex","findIndex","item","cacheLife","cacheLifeProfiles","unstable_noStore","callingExpression","validateCacheLife","stale","__NEXT_USE_CACHE","configuredProfile","trim","explicitRevalidate","explicitExpire","explicitStale","cacheTag","ensureServerEntryExports","actions","action","tBytes","common.getValueByPath","common.setValueByPath","generateVideosOperationFromMldev","generateVideosResponseFromMldev","generateVideosOperationFromVertex","generatedVideoFromMldev","videoFromMldev","generatedVideoFromVertex","t.tBytes","types.Type","baseTransformers.tBytes","t.tJobState","t.tRecvBatchJobDestination","blobToMldev","t.tBatchJobName","candidateFromMldev","citationMetadataFromMldev","contentToMldev","partToMldev","t.tBatchJobDestination","t.tModel","t.tBatchJobSource","t.tContentsForEmbed","embedContentConfigToMldev","common.moveValueByPath","fileDataToMldev","generateContentConfigToMldev","t.tContent","t.tSchema","safetySettingToMldev","t.tTools","toolToMldev","t.tTool","t.tCachedContentName","t.tSpeechConfig","generateContentResponseFromMldev","googleMapsToMldev","googleSearchToMldev","t.tContents","converters.createBatchJobParametersToMldev","common.formatMap","converters.createBatchJobParametersToVertex","converters.batchJobFromVertex","converters.batchJobFromMldev","converters.createEmbeddingsBatchJobParametersToMldev","converters.getBatchJobParametersToVertex","converters.getBatchJobParametersToMldev","converters.cancelBatchJobParametersToVertex","converters.cancelBatchJobParametersToMldev","converters.listBatchJobsParametersToVertex","converters.listBatchJobsResponseFromVertex","types.ListBatchJobsResponse","converters.listBatchJobsParametersToMldev","converters.listBatchJobsResponseFromMldev","converters.deleteBatchJobParametersToVertex","converters.deleteResourceJobFromVertex","converters.deleteBatchJobParametersToMldev","converters.deleteResourceJobFromMldev","toolToVertex","t.tCachesModel","functionDeclarationToVertex","converters.createCachedContentParametersToVertex","converters.createCachedContentParametersToMldev","converters.getCachedContentParametersToVertex","converters.getCachedContentParametersToMldev","converters.deleteCachedContentParametersToVertex","converters.deleteCachedContentResponseFromVertex","types.DeleteCachedContentResponse","converters.deleteCachedContentParametersToMldev","converters.deleteCachedContentResponseFromMldev","converters.updateCachedContentParametersToVertex","converters.updateCachedContentParametersToMldev","converters.listCachedContentsParametersToVertex","converters.listCachedContentsResponseFromVertex","types.ListCachedContentsResponse","converters.listCachedContentsParametersToMldev","converters.listCachedContentsResponseFromMldev","t.tFileName","converters.listFilesParametersToMldev","converters.listFilesResponseFromMldev","types.ListFilesResponse","converters.createFileParametersToMldev","converters.createFileResponseFromMldev","types.CreateFileResponse","converters.getFileParametersToMldev","converters.deleteFileParametersToMldev","converters.deleteFileResponseFromMldev","types.DeleteFileResponse","generationConfigToVertex","speechConfigToVertex","liveConnectConfigToMldev","t.tLiveSpeechConfig","sessionResumptionConfigToMldev","t.tBlobs","t.tAudioBlob","t.tImageBlob","t.tModelsUrl","t.tExtractModels","handleWebSocketMessage","types.LiveMusicServerMessage","mapToHeaders","headersToMap","converters.liveMusicSetWeightedPromptsParametersToMldev","converters.liveMusicSetConfigParametersToMldev","types.LiveMusicPlaybackControl","types.LiveServerMessage","converters.liveServerMessageFromVertex","types.Modality","converters.liveConnectParametersToVertex","converters.liveConnectParametersToMldev","converters.liveSendRealtimeInputParametersToVertex","converters.liveSendRealtimeInputParametersToMldev","types.GenerateContentResponse","converters.generateContentParametersToVertex","converters.generateContentResponseFromVertex","converters.generateContentParametersToMldev","converters.generateContentResponseFromMldev","converters.embedContentParametersToVertex","converters.embedContentResponseFromVertex","types.EmbedContentResponse","converters.embedContentParametersToMldev","converters.embedContentResponseFromMldev","converters.generateImagesParametersToVertex","converters.generateImagesResponseFromVertex","types.GenerateImagesResponse","converters.generateImagesParametersToMldev","converters.generateImagesResponseFromMldev","converters.editImageParametersInternalToVertex","converters.editImageResponseFromVertex","types.EditImageResponse","converters.upscaleImageAPIParametersInternalToVertex","converters.upscaleImageResponseFromVertex","types.UpscaleImageResponse","converters.recontextImageParametersToVertex","converters.recontextImageResponseFromVertex","types.RecontextImageResponse","converters.segmentImageParametersToVertex","converters.segmentImageResponseFromVertex","types.SegmentImageResponse","converters.getModelParametersToVertex","converters.modelFromVertex","converters.getModelParametersToMldev","converters.modelFromMldev","converters.listModelsParametersToVertex","converters.listModelsResponseFromVertex","types.ListModelsResponse","converters.listModelsParametersToMldev","converters.listModelsResponseFromMldev","converters.updateModelParametersToVertex","converters.updateModelParametersToMldev","converters.deleteModelParametersToVertex","converters.deleteModelResponseFromVertex","types.DeleteModelResponse","converters.deleteModelParametersToMldev","converters.deleteModelResponseFromMldev","converters.countTokensParametersToVertex","converters.countTokensResponseFromVertex","types.CountTokensResponse","converters.countTokensParametersToMldev","converters.countTokensResponseFromMldev","converters.computeTokensParametersToVertex","converters.computeTokensResponseFromVertex","types.ComputeTokensResponse","converters.generateVideosParametersToVertex","converters.generateVideosOperationFromVertex","types.GenerateVideosOperation","converters.generateVideosParametersToMldev","converters.generateVideosOperationFromMldev","converters.getOperationParametersToVertex","converters.getOperationParametersToMldev","converters.fetchPredictOperationParametersToVertex","converters.createAuthTokenParametersToMldev","t.tTuningJobStatus","types.JobState","converters.getTuningJobParametersToVertex","converters.tuningJobFromVertex","converters.getTuningJobParametersToMldev","converters.tuningJobFromMldev","converters.listTuningJobsParametersToVertex","converters.listTuningJobsResponseFromVertex","types.ListTuningJobsResponse","converters.listTuningJobsParametersToMldev","converters.listTuningJobsResponseFromMldev","converters.cancelTuningJobParametersToVertex","converters.cancelTuningJobParametersToMldev","converters.createTuningJobParametersPrivateToVertex","converters.createTuningJobParametersPrivateToMldev","converters.tuningOperationFromMldev"],"mappings":"6CAEA,IAAM,EAAe,CAAC,aAAc,cAAe,YAAY,CACzD,EAA0B,aAAhB,OAAO,KAEnB,GAAS,EAAa,IAAI,CAAC,QAE/B,EAAO,OAAO,CAAG,cACf,EACA,aAAc,OAAO,KAAK,CAAC,GAC3B,KAAM,+CACN,EACA,qBAAsB,OAAO,0BAC7B,UAAW,OAAO,aAClB,YAAa,OAAO,eACpB,WAAY,OAAO,aACnB,KAAM,KAAO,CACf,gCCfA,GAAM,cAAE,CAAY,CAAE,CAAA,EAAA,CAAA,CAAA,OAEhB,EAAa,MAAM,CAAC,OAAO,OAAO,CAAC,CAwCzC,SAAS,EAAM,CAAM,CAAE,CAAI,CAAE,CAAM,CAAE,CAAM,CAAE,CAAM,EACjD,IAAK,IAAI,EAAI,EAAG,EAAI,EAAQ,IAAK,AAC/B,CAAM,CAAC,EAAS,EAAE,CAAG,CAAM,CAAC,EAAE,CAAG,CAAI,CAAK,EAAJ,EAAM,AAEhD,CASA,SAAS,EAAQ,CAAM,CAAE,CAAI,EAC3B,IAAK,IAAI,EAAI,EAAG,EAAI,EAAO,MAAM,CAAE,IAAK,AACtC,CAAM,CAAC,EAAE,EAAI,CAAI,CAAK,EAAJ,EAAM,AAE5B,CAyBA,SAAS,EAAS,CAAI,MAKhB,QAFJ,CAFA,EAAS,QAAQ,EAAG,EAEhB,OAAO,QAAQ,CAAC,IAAc,GAAP,AAIvB,aAAgB,YAClB,CAD+B,CACzB,IAAI,EAAW,GACZ,YAAY,MAAM,CAAC,GAC5B,EAAM,EAD6B,EACzB,EAAW,EAAK,MAAM,CAAE,EAAK,UAAU,CAAE,EAAK,UAAU,GAElE,EAAM,OAAO,IAAI,CAAC,GAClB,EAAS,QAAQ,EAAG,GAGf,EACT,CAWA,GATA,EAAO,OAAO,CAAG,CACf,OA5FF,SAAgB,AAAP,CAAW,CAAE,CAAW,EAC/B,GAAoB,IAAhB,EAAK,MAAM,CAAQ,OAAO,EAC9B,GAAoB,IAAhB,EAAK,MAAM,CAAQ,OAAO,CAAI,CAAC,EAAE,CAErC,IAAM,EAAS,OAAO,WAAW,CAAC,GAC9B,EAAS,EAEb,IAAK,IAAI,EAAI,EAAG,EAAI,EAAK,MAAM,CAAE,IAAK,CACpC,IAAM,EAAM,CAAI,CAAC,EAAE,CACnB,EAAO,GAAG,CAAC,EAAK,GAChB,GAAU,EAAI,MAAM,AACtB,QAEA,AAAI,EAAS,EACJ,IAAI,EAAW,EAAO,GADL,GACW,CAAE,EAAO,UAAU,CAAE,GAGnD,CACT,EA2EE,KAAM,EACN,cAtCF,SAAuB,AAAd,CAAiB,SACxB,AAAI,EAAI,MAAM,GAAK,EAAI,MAAM,CAAC,UAAU,CAC/B,CADiC,CAC7B,MAAM,CAGZ,EAAI,MAAM,CAAC,KAAK,CAAC,EAAI,UAAU,CAAE,EAAI,UAAU,CAAG,EAAI,MAAM,CACrE,WAiCE,EACA,OAAQ,CACV,EAGI,CAAC,QAAQ,GAAG,CAAC,iBAAiB,CAChC,CADkC,EAC9B,CACF,IAAM,EAAA,CAAA,0FAEN,EAAO,OAAO,CAAC,IAAI,CAAG,SAAU,CAAM,CAAE,CAAI,CAAE,CAAM,CAAE,CAAM,CAAE,CAAM,EAC9D,EAAS,GAAI,EAAM,EAAQ,EAAM,EAAQ,EAAQ,GAChD,EAAW,IAAI,CAAC,EAAQ,EAAM,EAAQ,EAAQ,EACrD,EAEA,EAAO,OAAO,CAAC,MAAM,CAAG,SAAU,CAAM,CAAE,CAAI,EACxC,EAAO,MAAM,CAAG,GAAI,EAAQ,EAAQ,GACnC,EAAW,MAAM,CAAC,EAAQ,EACjC,CACF,CAAE,MAAO,EAAG,CAEZ,gCC/HF,IAAM,EAAQ,OAAO,SACf,EAAO,OAAO,QAmDpB,EAAO,OAAO,CA7Cd,EA6CiB,IA7CX,AAOJ,YAAY,CAAW,CAAE,CACvB,IAAI,CAAC,EAAM,CAAG,KACZ,IAAI,CAAC,OAAO,GACZ,IAAI,CAAC,EAAK,EACZ,EACA,IAAI,CAAC,WAAW,CAAG,GAAe,IAClC,IAAI,CAAC,IAAI,CAAG,EAAE,CACd,IAAI,CAAC,OAAO,CAAG,CACjB,CAQA,IAAI,CAAG,CAAE,CACP,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,GACf,IAAI,CAAC,EAAK,EACZ,CAOA,CAAC,EAAK,EAAG,CACP,GAAI,IAAI,CAAC,OAAO,GAAK,IAAI,CAAC,WAAW,EAAE,AAEnC,IAAI,CAAC,IAAI,CAAC,MAAM,CAAE,CACpB,IAAM,EAAM,IAAI,CAAC,IAAI,CAAC,KAAK,GAE3B,IAAI,CAAC,OAAO,GACZ,EAAI,IAAI,CAAC,EAAM,CACjB,CACF,CACF,oCC7BI,EArBE,EAAA,EAAA,CAAA,CAAA,MAEA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,aAAE,CAAW,CAAE,CAAA,EAAA,CAAA,CAAA,OAEf,EAAa,MAAM,CAAC,OAAO,OAAO,CAAC,CACnC,EAAU,OAAO,IAAI,CAAC,CAAC,EAAM,EAAM,IAAM,IAAK,EAC9C,EAAqB,OAAO,sBAC5B,EAAe,OAAO,gBACtB,EAAY,OAAO,YACnB,EAAW,OAAO,WAClB,EAAS,OAAO,SAwctB,SAAS,EAAc,CAAK,EAC1B,IAAI,CAAC,EAAS,CAAC,IAAI,CAAC,GACpB,IAAI,CAAC,EAAa,EAAI,EAAM,MAAM,AACpC,CAQA,SAAS,EAAc,CAAK,EAG1B,CAFA,IAAI,CAAC,EAAa,EAAI,EAAM,MAAM,CAGhC,IAAI,CAAC,EAAmB,CAAC,WAAW,CAAG,GACvC,IAAI,CAAC,EAAa,EAAI,IAAI,CAAC,EAAmB,CAAC,WAAW,EAC1D,AACA,IAAI,CAAC,EAAS,CAAC,IAAI,CAAC,IAItB,IAAI,CAAC,EAAO,CAAG,AAAI,WAAW,6BAC9B,IAAI,CAAC,EAAO,CAAC,IAAI,CAAG,oCACpB,IAAI,CAAC,EAAO,CAAC,EAAY,CAAG,KAC5B,IAAI,CAAC,cAAc,CAAC,OAAQ,GAS5B,IAAI,CAAC,KAAK,GACZ,CAQA,SAAS,EAAe,CAAG,EAOzB,CAFA,IAAI,CAAC,EAAmB,CAAC,QAAQ,CAAG,KAEhC,IAAI,CAAC,EAAO,EAAE,AAChB,IAAI,CAAC,EAAU,CAAC,IAAI,CAAC,EAAO,GAI9B,CAAG,CAAC,EAAY,CAAG,KACnB,IAAI,CAAC,EAAU,CAAC,GAClB,CAjEA,EAAO,OAAO,CAlbd,EAkbiB,IAzZf,AAzBI,YAyBQ,CAAO,CAAE,CAAQ,CAAE,CAAU,CAAE,CACzC,IAAI,CAAC,WAAW,CAAG,AAAa,IAChC,IAAI,CAAC,QAAQ,CAAG,GAAW,CAAC,EAC5B,IAAI,CAAC,UAAU,CACb,KAA4B,QAAxB,CAAC,QAAQ,CAAC,SAAS,CAAiB,IAAI,CAAC,QAAQ,CAAC,SAAS,CAAG,KACpE,IAAI,CAAC,SAAS,CAAG,CAAC,CAAC,EACnB,IAAI,CAAC,QAAQ,CAAG,KAChB,IAAI,CAAC,QAAQ,CAAG,KAEhB,IAAI,CAAC,MAAM,CAAG,KAET,IAKH,EAAc,IAAI,GALF,IAEqB,CAGX,GAHxB,IAAI,CAAC,QAAQ,CAAC,gBAAgB,CAC1B,IAAI,CAAC,QAAQ,CAAC,gBAAgB,CAC9B,GACoB,CAE9B,CAKA,WAAW,eAAgB,CACzB,MAAO,oBACT,CAQA,OAAQ,CACN,IAAM,EAAS,CAAC,EAiBhB,OAfI,IAAI,CAAC,QAAQ,CAAC,uBAAuB,EAAE,CACzC,EAAO,0BAA0B,EAAG,CAAA,EAElC,IAAI,CAAC,QAAQ,CAAC,uBAAuB,EAAE,CACzC,EAAO,0BAA0B,EAAG,CAAA,EAElC,IAAI,CAAC,QAAQ,CAAC,mBAAmB,EAAE,CACrC,EAAO,sBAAsB,CAAG,IAAI,CAAC,QAAQ,CAAC,mBAAA,AAAmB,EAE/D,IAAI,CAAC,QAAQ,CAAC,mBAAmB,CACnC,CADqC,CAC9B,sBAAsB,CAAG,IAAI,CAAC,QAAQ,CAAC,mBAAmB,CACnB,MAAM,AAA3C,IAAI,CAAC,QAAQ,CAAC,mBAAmB,EAC1C,GAAO,sBAAsB,EAAG,CAAA,EAG3B,CACT,CASA,OAAO,CAAc,CAAE,CAOrB,OANA,EAAiB,IAAI,CAAC,eAAe,CAAC,GAEtC,IAAI,CAAC,MAAM,CAAG,IAAI,CAAC,SAAS,CACxB,IAAI,CAAC,cAAc,CAAC,GACpB,IAAI,CAAC,cAAc,CAAC,GAEjB,IAAI,CAAC,MAAM,AACpB,CAOA,SAAU,CAMR,GALI,IAAI,CAAC,QAAQ,EAAE,CACjB,IAAI,CAAC,QAAQ,CAAC,KAAK,GACnB,IAAI,CAAC,QAAQ,CAAG,MAGd,IAAI,CAAC,QAAQ,CAAE,CACjB,IAAM,EAAW,IAAI,CAAC,QAAQ,CAAC,EAAU,CAEzC,IAAI,CAAC,QAAQ,CAAC,KAAK,GACnB,IAAI,CAAC,QAAQ,CAAG,KAEZ,GACF,EACE,AAAI,KAFM,CAGR,gEAIR,CACF,CASA,eAAe,CAAM,CAAE,CACrB,IAAM,EAAO,IAAI,CAAC,QAAQ,CACpB,EAAW,EAAO,IAAI,CAAC,AAAC,IAEzB,AAAiC,OAA5B,uBAAuB,GAC3B,EAAO,0BAAA,AAA0B,KAClC,EAAO,sBAAsB,EAC3B,CAA6B,CAA9B,KAAM,mBAAmB,GACc,UAApC,OAAO,EAAK,mBAAmB,IAC9B,EAAK,mBAAmB,CAAG,EAAO,sBAAA,CAAA,CAAuB,IAC9D,AAAoC,iBAA7B,EAAK,mBAAmB,GAC9B,CAAC,EAAO,sBAAA,AAAsB,EAChC,CAOJ,GAAI,CAAC,EACH,MAAM,AAAI,EADG,IACG,gDAqBlB,OAlBI,EAAK,uBAAuB,EAAE,CAChC,EAAS,0BAA0B,EAAG,CAAA,EAEpC,EAAK,uBAAuB,EAAE,CAChC,EAAS,0BAA0B,EAAG,CAAA,EAEA,UAAU,AAA9C,OAAO,EAAK,mBAAmB,GACjC,EAAS,sBAAsB,CAAG,EAAK,mBAAA,AAAmB,EAEpB,UAAU,AAA9C,OAAO,EAAK,mBAAmB,CACjC,EAAS,sBAAsB,CAAG,EAAK,mBAAmB,EAE1D,AAAoC,OAA3B,sBAAsB,GACF,IAA7B,EAAK,mBAAwB,AAAL,GACxB,AACA,OAAO,EAAS,sBAAsB,CAGjC,CACT,CASA,eAAe,CAAQ,CAAE,CACvB,IAAM,EAAS,CAAQ,CAAC,EAAE,CAE1B,IAC4C,IAA1C,IAAI,CAAC,QAAQ,CAAC,uBAAuB,EACrC,EAAO,0BAA0B,CAEjC,CADA,KACM,AAAI,MAAM,qDAGlB,GAAK,CAAD,CAAQ,sBAAsB,CAI3B,CAJ6B,IAKI,IAAtC,IAAI,CAAC,QAAQ,CAAC,mBAAmB,EACa,UAA7C,OAAO,IAAI,CAAC,QAAQ,CAAC,mBAAmB,EACvC,EAAO,sBAAsB,CAAG,IAAI,CAAC,QAAQ,CAAC,mBAAmB,CAEnE,CADA,KACM,AAAI,MACR,2DAEJ,KAXmD,UAA7C,AAAuD,OAAhD,IAAI,CAAC,QAAQ,CAAC,mBAAmB,GAC1C,EAAO,sBAAsB,CAAG,IAAI,CAAC,QAAQ,CAAC,mBAAA,AAAmB,EAYrE,OAAO,CACT,CASA,gBAAgB,CAAc,CAAE,CAkD9B,OAjDA,EAAe,OAAO,CAAC,AAAC,IACtB,OAAO,IAAI,CAAC,GAAQ,OAAO,CAAC,AAAC,IAC3B,IAAI,EAAQ,CAAM,CAAC,EAAI,CAEvB,GAAI,EAAM,MAAM,CAAG,EACjB,CADoB,KACd,AAAI,MAAM,CAAC,WAAW,EAAE,EAAI,+BAA+B,CAAC,EAKpE,GAFA,EAAQ,CAAK,CAAC,EAAE,CAEJ,0BAA0B,CAAlC,EACF,IAAI,CAAU,MAAM,CAClB,IAAM,EAAM,CAAC,EACb,GAAI,CAAC,OAAO,SAAS,CAAC,IAAQ,EAAM,GAAK,EAAM,GAC7C,CADiD,KACvC,AAAJ,UACJ,CAAC,6BAA6B,EAAE,EAAI,GAAG,EAAE,EAAA,CAAO,EAGpD,EAAQ,CACV,MAAO,GAAI,CAAC,IAAI,CAAC,SAAS,CACxB,CAD0B,KACpB,AAAI,UACR,CAAC,6BAA6B,EAAE,EAAI,GAAG,EAAE,EAAA,CAAO,CAEpD,MACK,GAAY,2BAAR,EAAkC,CAC3C,IAAM,EAAM,CAAC,EACb,GAAI,CAAC,OAAO,SAAS,CAAC,IAAQ,EAAM,GAAK,EAAM,GAC7C,CADiD,KAC3C,AAAI,UACR,CAAC,6BAA6B,EAAE,EAAI,GAAG,EAAE,EAAA,CAAO,EAGpD,EAAQ,CACV,MAAO,GACG,+BAAR,GACQ,8BACR,CADA,GAEA,IAAc,IAAV,EAAgB,AAClB,MAAM,AAAI,UACR,CAAC,6BAA6B,EAAE,EAAI,GAAG,EAAE,EAAA,CAAO,CAEpD,MAEA,MAAM,AAAI,MAAM,CAAC,mBAAmB,EAAE,EAAI,CAAC,CAAC,EAG9C,CAAM,CAAC,EAAI,CAAG,CAChB,EACF,GAEO,CACT,CAUA,WAAW,CAAI,CAAE,CAAG,CAAE,CAAQ,CAAE,CAC9B,EAAY,GAAG,CAAC,AAAC,IACf,IAAI,CAAC,WAAW,CAAC,EAAM,EAAK,CAAC,EAAK,KAChC,IACA,EAAS,EAAK,EAChB,EACF,EACF,CAUA,SAAS,CAAI,CAAE,CAAG,CAAE,CAAQ,CAAE,CAC5B,EAAY,GAAG,CAAE,AAAD,IACd,IAAI,CAAC,SAAS,CAAC,EAAM,EAAK,CAAC,EAAK,KAC9B,IACA,EAAS,EAAK,EAChB,EACF,EACF,CAUA,YAAY,CAAI,CAAE,CAAG,CAAE,CAAQ,CAAE,CAC/B,IAAM,EAAW,IAAI,CAAC,SAAS,CAAG,SAAW,SAE7C,GAAI,CAAC,IAAI,CAAC,QAAQ,CAAE,CAClB,IAAM,EAAM,CAAA,EAAG,EAAS,gBAAgB,CAAC,CACnC,EACwB,UAA5B,OAAO,IAAI,CAAC,MAAM,CAAC,EAAI,CACnB,EAAK,oBAAoB,CACzB,IAAI,CAAC,MAAM,CAAC,EAAI,CAEtB,IAAI,CAAC,QAAQ,CAAG,EAAK,gBAAgB,CAAC,CACpC,GAAG,IAAI,CAAC,QAAQ,CAAC,kBAAkB,YACnC,CACF,GACA,IAAI,CAAC,QAAQ,CAAC,EAAmB,CAAG,IAAI,CACxC,IAAI,CAAC,QAAQ,CAAC,EAAa,CAAG,EAC9B,IAAI,CAAC,QAAQ,CAAC,EAAS,CAAG,EAAE,CAC5B,IAAI,CAAC,QAAQ,CAAC,EAAE,CAAC,QAAS,GAC1B,IAAI,CAAC,QAAQ,CAAC,EAAE,CAAC,OAAQ,EAC3B,CAEA,IAAI,CAAC,QAAQ,CAAC,EAAU,CAAG,EAE3B,IAAI,CAAC,QAAQ,CAAC,KAAK,CAAC,GAChB,GAAK,IAAI,CAAC,QAAQ,CAAC,KAAK,CAAC,GAE7B,IAAI,CAAC,QAAQ,CAAC,KAAK,CAAC,KAClB,IAAM,EAAM,IAAI,CAAC,QAAQ,CAAC,EAAO,CAEjC,GAAI,EAAK,CACP,IAAI,CAAC,QAAQ,CAAC,KAAK,GACnB,IAAI,CAAC,QAAQ,CAAG,KAChB,EAAS,GACT,MACF,CAEA,IAAM,EAAO,EAAW,MAAM,CAC5B,IAAI,CAAC,QAAQ,CAAC,EAAS,CACvB,IAAI,CAAC,QAAQ,CAAC,EAAa,EAGzB,IAAI,CAAC,QAAQ,CAAC,cAAc,CAAC,UAAU,EAAE,AAC3C,IAAI,CAAC,QAAQ,CAAC,KAAK,GACnB,IAAI,CAAC,QAAQ,CAAG,OAEhB,IAAI,CAAC,QAAQ,CAAC,EAAa,CAAG,EAC9B,IAAI,CAAC,QAAQ,CAAC,EAAS,CAAG,EAAE,CAExB,GAAO,IAAI,CAAC,MAAM,CAAC,CAAA,EAAG,EAAS,oBAAoB,CAAC,CAAC,EAAE,AACzD,IAAI,CAAC,QAAQ,CAAC,KAAK,IAIvB,EAAS,KAAM,EACjB,EACF,CAUA,UAAU,CAAI,CAAE,CAAG,CAAE,CAAQ,CAAE,CAC7B,IAAM,EAAW,IAAI,CAAC,SAAS,CAAG,SAAW,SAE7C,GAAI,CAAC,IAAI,CAAC,QAAQ,CAAE,CAClB,IAAM,EAAM,CAAA,EAAG,EAAS,gBAAgB,CAAC,CACnC,EACwB,UAA5B,OAAO,IAAI,CAAC,MAAM,CAAC,EAAI,CACnB,EAAK,oBAAoB,CACzB,IAAI,CAAC,MAAM,CAAC,EAAI,CAEtB,IAAI,CAAC,QAAQ,CAAG,EAAK,gBAAgB,CAAC,CACpC,GAAG,IAAI,CAAC,QAAQ,CAAC,kBAAkB,YACnC,CACF,GAEA,IAAI,CAAC,QAAQ,CAAC,EAAa,CAAG,EAC9B,IAAI,CAAC,QAAQ,CAAC,EAAS,CAAG,EAAE,CAE5B,IAAI,CAAC,QAAQ,CAAC,EAAE,CAAC,OAAQ,EAC3B,CAEA,IAAI,CAAC,QAAQ,CAAC,EAAU,CAAG,EAE3B,IAAI,CAAC,QAAQ,CAAC,KAAK,CAAC,GACpB,IAAI,CAAC,QAAQ,CAAC,KAAK,CAAC,EAAK,YAAY,CAAE,KACrC,GAAI,CAAC,IAAI,CAAC,QAAQ,CAIhB,CAJkB,MAOpB,IAAI,EAAO,EAAW,MAAM,CAC1B,IAAI,CAAC,QAAQ,CAAC,EAAS,CACvB,IAAI,CAAC,QAAQ,CAAC,EAAa,EAGzB,IACF,CADO,CACA,IAAI,EAAW,EAAK,MAAM,CAAE,EAAK,UAAU,CAAE,EAAK,MAAM,CAAG,EAAA,EAOpE,IAAI,CAAC,QAAQ,CAAC,EAAU,CAAG,KAE3B,IAAI,CAAC,QAAQ,CAAC,EAAa,CAAG,EAC9B,IAAI,CAAC,QAAQ,CAAC,EAAS,CAAG,EAAE,CAExB,GAAO,IAAI,CAAC,MAAM,CAAC,CAAA,EAAG,EAAS,oBAAoB,CAAC,CAAC,EAAE,AACzD,IAAI,CAAC,QAAQ,CAAC,KAAK,GAGrB,EAAS,KAAM,EACjB,EACF,CACF,gCC1cA,GAAM,QAAE,CAAM,CAAE,CAAA,EAAA,CAAA,CAAA,KAEV,CAAE,SAAO,CAAE,CAAA,EAAA,CAAA,CAAA,OAoDjB,SAAS,EAAa,CAAG,EACvB,IAAM,EAAM,EAAI,MAAM,CAClB,EAAI,EAER,KAAO,EAAI,GACT,CADc,EACV,CAAU,IAAT,CAAG,CAAC,EAAE,AAAG,CAAI,EAAM,EAEtB,CAFyB,QAGpB,GAAI,AAAC,CAAS,KAAN,CAAC,EAAE,AAAG,CAAI,EAAM,IAAM,CAEnC,GACE,EAAI,IAAM,GACV,CAAc,IAAb,CAAG,CAAC,EAAI,EAAE,AAAG,CAAI,EAAM,KACxB,CAAU,IAAT,CAAG,CAAC,EAAE,AAAG,CAAI,EAAM,IAEpB,CAFyB,MAElB,EAGT,GALsC,AAKjC,CACP,MAAO,GAAI,CAAU,IAAT,CAAG,CAAC,EAAE,AAAG,CAAI,EAAM,IAAM,CAEnC,GACE,EAAI,GAAK,GACT,CAAc,IAAb,CAAG,CAAC,EAAI,EAAK,AAAH,CAAO,EAAM,KACxB,CAAc,IAAb,CAAG,CAAC,EAAI,EAAE,AAAG,CAAI,EAAM,KACZ,MAAX,CAAG,CAAC,EAAE,EAAa,CAAc,IAAb,CAAG,CAAC,EAAI,EAAE,AAAG,CAAI,EAAM,KAChC,MAAX,CAAG,CAAC,EAAE,EAAa,CAAc,IAAb,CAAG,CAAC,EAAI,EAAE,AAAG,CAAI,EAAM,IAE5C,CAFkD,MAE3C,EAGT,GAAK,CACP,KAAqC,CAA9B,IAAI,AAAU,IAAT,CAAG,CAAC,EAAE,AANkE,AAM/D,CAAI,EAAM,KAG3B,EAAI,GAAK,GACT,CAAc,IAAb,CAAG,CAAC,EAAI,EAAE,AAAG,CAAI,EAAM,KACxB,CAAc,IAAb,CAAG,CAAC,EAAI,EAAE,AAAG,CAAI,EAAM,KACxB,CAAC,AAAa,KAAV,CAAC,EAAI,EAAE,AAAG,CAAI,EAAM,KACZ,MAAX,CAAG,CAAC,EAAE,EAAa,CAAc,IAAb,CAAG,CAAC,EAAI,EAAE,AAAG,CAAI,EAAM,KAChC,MAAX,CAAG,CAAC,EAAE,EAAa,CAAG,CAAC,EAAI,EAAE,CAAG,KACjC,CAAG,CAAC,EAAE,CAAG,IAOX,CAPgB,MAOT,EAFP,GAAK,CACP,CAN+B,AAWjC,MALS,CAKF,CACT,CA4BA,GAPA,EAAO,OAAO,CAAG,CACf,OAbF,SAAS,AAAO,CAAK,EACnB,OACE,GACiB,UAAjB,OAAO,GACsB,YAA7B,OAAO,EAAM,WAAW,EACF,UAAtB,OAAO,EAAM,IAAI,EACjB,AAAwB,cACxB,KADO,EAAM,MAAM,GACY,SAA9B,CAAK,CAAC,OAAO,WAAW,CAAC,EACM,SAA9B,CAAK,CAAC,OAAO,WAAW,CAAC,AAAK,CAAM,AAE1C,EAIE,kBAhGF,SAAS,AAAkB,CAAI,EAC7B,OACG,GAAQ,KACP,GAAQ,MACR,AAAS,UACA,OAAT,GACS,AAAT,UACD,GAAQ,KAAQ,GAAQ,IAE7B,EAwFE,YAAa,EACb,WApHiB,CACjB,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAC7C,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAC7C,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAC7C,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAC7C,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAC7C,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAC7C,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAC7C,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAC9C,AADgD,AA6GjD,EAEI,EACF,EAAO,IADG,EA/GiD,CAgH7C,CAAC,WAAW,CAAG,SAAU,CAAG,EACxC,OAAO,EAAI,MAAM,CAAG,GAAK,EAAa,GAAO,EAAO,EACtD,OACiC,GAAI,CAAC,QAAQ,GAAG,CAAC,oBAAoB,CACtE,CADwE,EACpE,CACF,IAAM,EAAA,CAAA,8FAEN,EAAO,OAAO,CAAC,WAAW,CAAG,SAAU,CAAG,EACxC,OAAO,EAAI,MAAM,CAAG,GAAK,EAAa,GAAO,EAAY,EAC3D,CACF,CAAE,MAAO,EAAG,CAEZ,gCCpJF,GAAM,CAAE,UAAQ,CAAE,CAAA,EAAA,CAAA,CAAA,OAEZ,EAAA,EAAA,CAAA,CAAA,OACA,cACJ,CAAY,cACZ,CAAY,aACZ,CAAW,YACX,CAAU,CACX,CAAA,EAAA,CAAA,CAAA,OACK,QAAE,CAAM,eAAE,CAAa,QAAE,CAAM,CAAE,CAAA,EAAA,CAAA,CAAA,OACjC,mBAAE,CAAiB,aAAE,CAAW,CAAE,CAAA,EAAA,CAAA,CAAA,OAElC,EAAa,MAAM,CAAC,OAAO,OAAO,CAAC,CAmrBzC,EAAO,OAAO,CApqBd,EAoqBiB,IApqBX,QAAiB,EAiBrB,YAAY,EAAU,CAAC,CAAC,CAAE,CACxB,KAAK,GAEL,IAAI,CAAC,uBAAuB,MACS,IAAnC,EAAQ,sBAAsB,EAC1B,EAAQ,sBAAsB,CAEpC,EADM,EACF,CAAC,WAAW,CAAG,EAAQ,UAAU,EAAI,CAAY,CAAC,EAAE,CACxD,IAAI,CAAC,WAAW,CAAG,EAAQ,UAAU,EAAI,CAAC,EAC1C,IAAI,CAAC,SAAS,CAAG,CAAC,CAAC,EAAQ,QAAQ,CACnC,IAAI,CAAC,WAAW,CAAwB,EAArB,EAAQ,UAAU,CACrC,IAAI,CAAC,mBAAmB,CAAG,CAAC,CAAC,EAAQ,kBAAkB,CACvD,IAAI,CAAC,EAAW,MAAG,EAEnB,IAAI,CAAC,cAAc,CAAG,EACtB,IAAI,CAAC,QAAQ,CAAG,EAAE,CAElB,IAAI,CAAC,WAAW,EAAG,EACnB,IAAI,CAAC,cAAc,CAAG,EACtB,IAAI,CAAC,KAAK,MAAG,EACb,IAAI,CAAC,WAAW,CAAG,EACnB,IAAI,CAAC,OAAO,EAAG,EACf,IAAI,CAAC,IAAI,EAAG,EACZ,IAAI,CAAC,OAAO,CAAG,EAEf,IAAI,CAAC,mBAAmB,CAAG,EAC3B,IAAI,CAAC,cAAc,CAAG,EACtB,IAAI,CAAC,UAAU,CAAG,EAAE,CAEpB,IAAI,CAAC,QAAQ,EAAG,EAChB,IAAI,CAAC,KAAK,CAAG,GACb,IAAI,CAAC,MAAM,EACb,CADgB,AAWhB,OAAO,CAAK,CAAE,CAAQ,CAAE,CAAE,CAAE,CAC1B,GAAqB,AAAjB,QAAI,CAAC,OAAO,KAAa,IAAI,CAAC,MAAM,CAAc,GAAV,IAAiB,IAE7D,IAAI,CAAC,cAAc,EAAI,EAAM,MAAM,CACnC,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,GACnB,IAAI,CAAC,SAAS,CAAC,EACjB,CASA,QAAQ,CAAC,CAAE,CAGT,GAFA,IAAI,CAAC,cAAc,EAAI,EAEnB,IAAM,IAAI,CAAC,QAAQ,CAAC,EAAE,CAAC,MAAM,CAAE,OAAO,IAAI,CAAC,QAAQ,CAAC,KAAK,GAE7D,GAAI,EAAI,IAAI,CAAC,QAAQ,CAAC,EAAE,CAAC,MAAM,CAAE,CAC/B,IAAM,EAAM,IAAI,CAAC,QAAQ,CAAC,EAAE,CAO5B,OANA,IAAI,CAAC,QAAQ,CAAC,EAAE,CAAG,IAAI,EACrB,EAAI,MAAM,CACV,EAAI,UAAU,CAAG,EACjB,EAAI,MAAM,CAAG,GAGR,IAAI,EAAW,EAAI,MAAM,CAAE,EAAI,UAAU,CAAE,EACpD,CAEA,IAAM,EAAM,OAAO,WAAW,CAAC,GAE/B,EAAG,CACD,IAAM,EAAM,IAAI,CAAC,QAAQ,CAAC,EAAE,CACtB,EAAS,EAAI,MAAM,CAAG,CAExB,IAAK,EAAI,MAAM,CACjB,CADmB,CACf,GAAG,CAAC,IAAI,CAAC,QAAQ,CAAC,KAAK,GAAI,IAE/B,EAAI,GAAG,CAAC,IAAI,WAAW,EAAI,MAAM,CAAE,EAAI,UAAU,CAAE,GAAI,GACvD,IAAI,CAAC,QAAQ,CAAC,EAAE,CAAG,IAAI,EACrB,EAAI,MAAM,CACV,EAAI,UAAU,CAAG,EACjB,EAAI,MAAM,CAAG,IAIjB,GAAK,EAAI,MACX,AADiB,OACR,EAAI,EAAG,AAEhB,OAAO,CACT,CAQA,UAAU,CAAE,CAAE,CACZ,IAAI,CAAC,KAAK,EAAG,EAEb,GACE,AADC,OACO,IAAI,CAAC,MAAM,EACjB,KAAK,AAzII,EA0IP,IAAI,CAAC,OAAO,CAAC,GACb,KACF,KAAK,CA3IiB,EA4IpB,IAAI,CAAC,kBAAkB,CAAC,GACxB,KACF,KAAK,CA7IiB,EA8IpB,IAAI,CAAC,kBAAkB,CAAC,GACxB,KACF,KAAK,CA/II,EAgJP,IAAI,CAAC,OAAO,GACZ,KACF,KAAK,CAjJI,EAkJP,IAAI,CAAC,OAAO,CAAC,GACb,KACF,KAAK,GACL,KAAK,EACH,IAAI,CAAC,KAAK,EAAG,EACb,MACJ,OACO,IAAI,CAAC,KAAK,CAEd,AAFgB,AAEjB,IAAK,CAAC,QAAQ,EAAE,GACtB,CAQA,QAAQ,CAAE,CAAE,CACV,GAAI,IAAI,CAAC,cAAc,CAAG,EAAG,CAC3B,IAAI,CAAC,KAAK,EAAG,EACb,MACF,CAEA,IAAM,EAAM,IAAI,CAAC,OAAO,CAAC,GAEzB,GAAI,CAAU,GAAT,CAAG,CAAC,EAAE,AAAG,CAAI,EAAM,EAAM,YAS5B,EARc,CAQX,GARe,CAAC,WAAW,CAC5B,WACA,+BACA,EACA,KACA,8BAOJ,IAAM,EAAa,CAAU,GAAT,CAAG,CAAC,EAAE,AAAG,CAAI,EAAM,GAEvC,GAAI,GAAc,CAAC,IAAI,CAAC,WAAW,CAAC,EAAkB,aAAa,CAAC,CAAE,YASpE,EARc,CAQX,GARe,CAAC,WAAW,CAC5B,WACA,sBACA,EACA,KACA,4BAWJ,GAJA,IAAI,CAAC,IAAI,CAAG,CAAU,IAAT,CAAG,CAAC,EAAK,AAAH,CAAO,EAAM,IAChC,IAAI,CAAC,OAAO,CAAY,GAAT,CAAG,CAAC,EAAE,CACrB,IAAI,CAAC,cAAc,CAAY,IAAT,CAAG,CAAC,EAAE,CAEP,IAAjB,IAAI,CAAC,OAAO,CAAW,CACzB,GAAI,EAAY,YASd,EARc,CAQX,GARe,CAAC,WAAW,CAC5B,WACA,sBACA,EACA,KACA,4BAOJ,GAAI,CAAC,IAAI,CAAC,WAAW,CAAE,YASrB,EARc,CAQX,GARe,CAAC,WAAW,CAC5B,WACA,oBACA,EACA,KACA,0BAOJ,IAAI,CAAC,OAAO,CAAG,IAAI,CAAC,WAAW,AACjC,MAAO,GAAqB,IAAjB,IAAI,CAAC,OAAO,EAA8B,IAAjB,IAAI,CAAC,OAAO,CAAW,CACzD,GAAI,IAAI,CAAC,WAAW,CAAE,YASpB,EARc,CAQX,GARe,CAAC,WAAW,CAC5B,WACA,CAAC,eAAe,EAAE,IAAI,CAAC,OAAO,CAAA,CAAE,EAChC,EACA,KACA,0BAOJ,IAAI,CAAC,WAAW,CAAG,CACrB,KAAuD,CAAhD,IAAI,KAAI,CAAC,OAAO,CAAG,CAAA,KAAQ,IAAI,CAAC,OAAO,CAAG,EAAA,EA0C1C,YASL,EARc,CAQX,GARe,CAAC,WAAW,CAC5B,WACA,CAAC,eAAe,EAAE,IAAI,CAAC,OAAO,CAAA,CAAE,EAChC,EACA,KACA,0BA/CF,GAAI,CAAC,IAAI,CAAC,IAAI,CAAE,YASd,EARc,CAQX,GARe,CAAC,WAAW,CAC5B,WACA,kBACA,GACA,KACA,wBAOJ,GAAI,EAAY,YASd,EARc,CAQX,GARe,CAAC,WAAW,CAC5B,WACA,sBACA,EACA,KACA,4BAOJ,GACE,IAAI,CAAC,cAAc,CAAG,KACJ,IAAjB,IAAI,CAAC,OAAO,EAAqC,IAAxB,IAAI,CAAC,cAAc,CAC7C,YASA,EARc,CAQX,GARe,CAAC,WAAW,CAC5B,WACA,CAAC,uBAAuB,EAAE,IAAI,CAAC,cAAc,CAAA,CAAE,EAC/C,EACA,KACA,yCAMN,CAgBA,GAHI,AAAC,IAAI,CAAC,IAAI,EAAK,EAAD,EAAK,CAAC,WAAW,EAAE,KAAI,CAAC,WAAW,CAAG,IAAI,CAAC,OAAA,AAAO,EACpE,IAAI,CAAC,OAAO,CAAG,CAAU,IAAT,CAAG,CAAC,EAAE,AAAG,CAAI,EAAM,IAE/B,IAAI,CAAC,SAAS,EAAE,AAClB,GAAI,CAAC,IAAI,CAAC,OAAO,CAAE,YASjB,EARc,CAQX,GARe,CAAC,WAAW,CAC5B,WACA,oBACA,EACA,KACA,wBAKJ,MACK,GAAI,IAAI,CAAC,OAAO,CAAE,YASvB,EARc,CAQX,GARe,CAAC,WAAW,CAC5B,WACA,sBACA,EACA,KACA,0BAOwB,OAAxB,IAAI,CAAC,cAAc,CAAU,IAAI,CAAC,MAAM,GAAG,AACd,MAAxB,IAAI,CAAC,cAAc,CAAU,IAAI,CAAC,MAAM,GAAG,AAC/C,IAAI,CAAC,UAAU,CAAC,EACvB,CAQA,mBAAmB,CAAE,CAAE,CACrB,GAAI,IAAI,CAAC,cAAc,CAAG,EAAG,CAC3B,IAAI,CAAC,KAAK,CAAG,GACb,MACF,CAEA,IAAI,CAAC,cAAc,CAAG,IAAI,CAAC,OAAO,CAAC,GAAG,YAAY,CAAC,GACnD,IAAI,CAAC,UAAU,CAAC,EAClB,CAQA,mBAAmB,CAAE,CAAE,CACrB,GAAI,IAAI,CAAC,cAAc,CAAG,EAAG,CAC3B,IAAI,CAAC,KAAK,EAAG,EACb,MACF,CAEA,IAAM,EAAM,IAAI,CAAC,OAAO,CAAC,GACnB,EAAM,EAAI,YAAY,CAAC,EAM7B,CAAI,EAAM,KAAK,GASb,AATgB,CAAC,CACH,CAQX,CATiB,EACF,CAAC,EADM,MAAM,GAAG,AACJ,CAC5B,WACA,0DACA,EACA,KACA,4CAOJ,IAAI,CAAC,cAAc,CAAS,KAAK,GAAG,CAAC,GAAf,AAAkB,EAAM,EAAI,YAAY,CAAC,GAC/D,IAAI,CAAC,UAAU,CAAC,GAClB,CAQA,WAAW,CAAE,CAAE,CACT,AAAJ,IAAQ,CAAC,cAAc,EAAI,IAAI,CAAC,OAAO,CAAG,IACxC,EAD8C,EAC1C,CAAC,mBAAmB,EAAI,IAAI,CAAC,cAAc,CAC3C,IAAI,CAAC,mBAAmB,CAAG,IAAI,CAAC,WAAW,EAAI,IAAI,CAAC,WAAW,CAAG,GAAG,AASvE,EARc,CAQX,GARe,CAAC,WAAW,CAC5B,WACA,6BACA,EACA,KACA,sCAQF,IAAI,CAAC,OAAO,CAAE,IAAI,CAAC,MAAM,GAAG,AAC3B,IAAI,CAAC,MAAM,EAClB,CADqB,AAQrB,SAAU,CACR,GAAI,IAAI,CAAC,cAAc,CAAG,EAAG,CAC3B,IAAI,CAAC,KAAK,EAAG,EACb,MACF,CAEA,IAAI,CAAC,KAAK,CAAG,IAAI,CAAC,OAAO,CAAC,GAC1B,IAAI,CAAC,MAAM,EACb,CAQA,AATgB,QASR,CAAE,CAAE,CACV,IAAI,EAAO,EAEX,GAAI,IAAI,CAAC,cAAc,CAAE,CACvB,GAAI,IAAI,CAAC,cAAc,CAAG,IAAI,CAAC,cAAc,CAAE,CAC7C,IAAI,CAAC,KAAK,EAAG,EACb,MACF,CAEA,EAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,cAAc,EAGrC,IAAI,CAAC,OAAO,EACZ,CAAC,IAAI,CAAC,KAAK,CAAC,EAAE,CAAG,IAAI,CAAC,KAAK,CAAC,EAAE,CAAG,IAAI,CAAC,KAAK,CAAC,EAAE,CAAG,IAAI,CAAC,KAAK,CAAC,EAAA,AAAE,GAAM,GACpE,AACA,EAAO,EAAM,IAAI,CAAC,KAAK,CAE3B,CAEA,GAAI,IAAI,CAAC,OAAO,CAAG,EAAM,YACvB,IAAI,CAAC,cAAc,CAAC,EAAM,GAI5B,GAAI,IAAI,CAAC,WAAW,CAAE,CACpB,IAAI,CAAC,MAAM,GAAG,AACd,IAAI,CAAC,UAAU,CAAC,EAAM,GACtB,MACF,CAEI,EAAK,MAAM,EAAE,CAKf,IAAI,CAAC,cAAc,CAAG,IAAI,CAAC,mBAAmB,CAC9C,IAAI,CAAC,UAAU,CAAC,IAAI,CAAC,IAGvB,IAAI,CAAC,WAAW,CAAC,EACnB,CASA,WAAW,CAAI,CAAE,CAAE,CAAE,CACO,AAE1B,IAF8B,CAAC,WAAW,CAAC,EAAkB,aAAa,CAAC,CAEzD,UAAU,CAAC,EAAM,IAAI,CAAC,IAAI,CAAE,CAAC,EAAK,KAClD,GAAI,EAAK,OAAO,EAAG,GAEnB,GAAI,EAAI,MAAM,CAAE,CAEd,GADA,IAAI,CAAC,cAAc,EAAI,EAAI,MAAM,CAC7B,IAAI,CAAC,cAAc,CAAG,IAAI,CAAC,WAAW,EAAI,IAAI,CAAC,WAAW,CAAG,EAAG,YASlE,EARc,CAQX,GARe,CAAC,WAAW,CAC5B,WACA,6BACA,EACA,KACA,sCAOJ,IAAI,CAAC,UAAU,CAAC,IAAI,CAAC,EACvB,CAEA,IAAI,CAAC,WAAW,CAAC,OACb,IAAI,CAAC,MAAM,EAAe,GAAV,CAAc,CAAC,SAAS,CAAC,EAC/C,EACF,CAQA,YAAY,CAAE,CAAE,CACd,GAAI,CAAC,IAAI,CAAC,IAAI,CAAE,CACd,IAAI,CAAC,MAAM,GAAG,AACd,MACF,CAEA,IAAM,EAAgB,IAAI,CAAC,cAAc,CACnC,EAAY,IAAI,CAAC,UAAU,CAOjC,GALA,IAAI,CAAC,mBAAmB,CAAG,EAC3B,IAAI,CAAC,cAAc,CAAG,EACtB,IAAI,CAAC,WAAW,CAAG,EACnB,IAAI,CAAC,UAAU,CAAG,EAAE,CAEC,IAAjB,IAAI,CAAC,OAAO,CAAQ,CACtB,IAAI,EAGF,EADuB,cAAc,CAAnC,IAAI,CAAC,WAAW,CACX,EAAO,EAAW,GACK,eAAe,CAApC,IAAI,CAAC,WAAW,CAClB,EAAc,EAAO,EAAW,IACT,QAAQ,CAA7B,IAAI,CAAC,WAAW,CAClB,IAAI,KAAK,GAET,EAGL,IAAI,CAAC,uBAAuB,EAAE,AAChC,IAAI,CAAC,IAAI,CAAC,UAAW,GAAM,GAC3B,IAAI,CAAC,MAAM,GAAG,EAEd,IAAI,CAAC,MAAM,GACX,AADc,aACD,KACX,IAAI,CAAC,IAAI,CAAC,UAAW,GAAM,GAC3B,IAAI,CAAC,MAAM,GAAG,AACd,IAAI,CAAC,SAAS,CAAC,EACjB,GAEJ,KAAO,CACL,IAAM,EAAM,EAAO,EAAW,GAE9B,GAAI,CAAC,IAAI,CAAC,mBAAmB,EAAI,CAAC,EAAY,GAAM,YASlD,EARc,CAQX,GARe,CAAC,WAAW,CAC5B,MACA,yBACA,GACA,KACA,wBAtjBQ,IA6jBR,IAAI,CAAC,MAAM,EAAkB,GAAb,CAAiB,CAAC,uBAAuB,EAAE,AAC7D,IAAI,CAAC,IAAI,CAAC,UAAW,GAAK,GAC1B,IAAI,CAAC,MAAM,GAAG,EAEd,IAAI,CAAC,MAAM,CAhkBC,EAgkBE,AACd,aAAa,KACX,IAAI,CAAC,IAAI,CAAC,UAAW,GAAK,GAC1B,IAAI,CAAC,MAAM,GAAG,AACd,IAAI,CAAC,SAAS,CAAC,EACjB,GAEJ,CACF,CASA,eAAe,CAAI,CAAE,CAAE,CAAE,CACvB,GAAqB,IAAjB,IAAI,CAAC,OAAO,CAAW,CACzB,GAAI,AAAgB,GAAG,GAAd,MAAM,CACb,IAAI,CAAC,KAAK,EAAG,EACb,IAAI,CAAC,IAAI,CAAC,WAAY,KAAM,GAC5B,IAAI,CAAC,GAAG,OACH,CACL,IAAM,EAAO,EAAK,YAAY,CAAC,GAE/B,GAAI,CAAC,EAAkB,GAAO,YAS5B,EARc,CAQX,GARe,CAAC,WAAW,CAC5B,WACA,CAAC,oBAAoB,EAAE,EAAA,CAAM,CAC7B,GACA,KACA,8BAOJ,IAAM,EAAM,IAAI,EACd,EAAK,MAAM,CACX,EAAK,UAAU,CAAG,EAClB,EAAK,MAAM,CAAG,GAGhB,GAAI,CAAC,IAAI,CAAC,mBAAmB,EAAI,CAAC,EAAY,GAAM,YASlD,EARc,CAQX,GARe,CAAC,WAAW,CAC5B,MACA,yBACA,GACA,KACA,wBAOJ,IAAI,CAAC,KAAK,EAAG,EACb,IAAI,CAAC,IAAI,CAAC,WAAY,EAAM,GAC5B,IAAI,CAAC,GAAG,EACV,CAEA,IAAI,CAAC,MAAM,GAAG,AACd,MACF,CAEI,IAAI,CAAC,uBAAuB,EAAE,AAChC,IAAI,CAAC,IAAI,CAAkB,IAAjB,IAAI,CAAC,OAAO,CAAY,OAAS,OAAQ,GACnD,IAAI,CAAC,MAAM,GAAG,EAEd,IAAI,CAAC,MAAM,GAAG,AACd,aAAa,KACX,IAAI,CAAC,IAAI,CAAkB,AAAjB,QAAI,CAAC,OAAO,CAAY,OAAS,OAAQ,GACnD,IAAI,CAAC,MAAM,GAAG,AACd,IAAI,CAAC,SAAS,CAAC,EACjB,GAEJ,CAcA,YAAY,CAAS,CAAE,CAAO,CAAE,CAAM,CAAE,CAAU,CAAE,CAAS,CAAE,CAC7D,IAAI,CAAC,KAAK,EAAG,EACb,IAAI,CAAC,QAAQ,EAAG,EAEhB,IAAM,EAAM,IAAI,EACd,EAAS,CAAC,yBAAyB,EAAE,EAAA,CAAS,CAAG,GAMnD,OAHA,MAAM,iBAAiB,CAAC,EAAK,IAAI,CAAC,WAAW,EAC7C,EAAI,IAAI,CAAG,EACX,CAAG,CAAC,EAAY,CAAG,EACZ,CACT,CACF,oCChrBI,EAXE,QAAE,CAAM,CAAE,CAAA,EAAA,CAAA,CAAA,OACV,gBAAE,CAAc,CAAE,CAAA,EAAA,CAAA,CAAA,OAElB,EAAA,EAAA,CAAA,CAAA,OACA,CAAE,cAAY,YAAE,CAAU,MAAE,CAAI,CAAE,CAAA,EAAA,CAAA,CAAA,OAClC,QAAE,CAAM,mBAAE,CAAiB,CAAE,CAAA,EAAA,CAAA,CAAA,OAC7B,CAAE,KAAM,CAAS,UAAE,CAAQ,CAAE,CAAA,EAAA,CAAA,CAAA,OAE7B,EAAc,OAAO,eACrB,EAAa,OAAO,KAAK,CAAC,GAG5B,MASJ,OAAM,EASJ,KAlBsB,OAkBV,CAAM,CAAE,CAAU,CAAE,CAAY,CAAE,CAC5C,IAAI,CAAC,WAAW,CAAG,GAAc,CAAC,EAE9B,IACF,IAAI,CAAC,KADW,QACE,CAAG,EACrB,IAAI,CAAC,WAAW,CAAG,OAAO,KAAK,CAAC,IAGlC,IAAI,CAAC,OAAO,CAAG,EAEf,IAAI,CAAC,cAAc,EAAG,EACtB,IAAI,CAAC,SAAS,EAAG,EAEjB,IAAI,CAAC,cAAc,CAAG,EACtB,IAAI,CAAC,MAAM,CAAG,EAAE,CAChB,IAAI,CAAC,MAAM,GAAG,AACd,IAAI,CAAC,OAAO,CAAG,EACf,IAAI,CAAC,EAAW,MAAG,CACrB,CAuBA,OAAO,MAAM,CAAI,CAAE,CAAO,CAAE,CAE1B,IADI,EAmCA,EAlCA,EAAQ,GACR,EAAS,EACT,EAAc,GAEd,EAAQ,IAAI,EAAE,CAChB,EAAO,EAAQ,UAAU,EAAI,EAEzB,EAAQ,YAAY,CACtB,CADwB,CAChB,YAAY,CAAC,WAEjB,IAEE,KAAe,QAKjB,EAAa,CALe,EAFN,IAOF,KAAK,CAAC,KAAA,EAG5B,CAV0C,CAU3B,EAAY,EAnFZ,CAmFe,GAnFX,EAoFnB,EAAoB,GAGtB,CAAI,CAAC,EAAE,CAAG,CAAU,CAAC,IAAoB,CACzC,CAAI,CAAC,EAAE,CAAG,CAAU,CAAC,IAAoB,CACzC,CAAI,CAAC,EAAE,CAAG,CAAU,CAAC,IAAoB,CACzC,CAAI,CAAC,EAAE,CAAG,CAAU,CAAC,IAAoB,EAG3C,EAAe,AAAD,EAAK,CAAC,EAAE,CAAG,CAAI,CAAC,EAAE,CAAG,CAAI,CAAC,EAAE,CAAG,CAAI,CAAC,EAAA,AAAE,GAAM,EAC1D,EAAS,GAKS,UAAhB,AAA0B,OAAnB,EAKP,EAHA,AAAC,EAAC,EAAQ,IAAI,EAAI,CAAA,CAAW,EACJ,SAAzB,CAAO,CAAC,AACR,EADoB,CAEP,CAAO,CAAC,EAAY,CAGpB,CADb,EAAO,OAAO,IAAI,CAAC,EAAA,EACD,MAAM,EAG1B,EAAa,EAAK,MAAM,CACxB,EAAQ,EAAQ,IAAI,EAAI,EAAQ,QAAQ,EAAI,CAAC,GAG/C,IAAI,EAAgB,EAEhB,GAAc,OAAO,AACvB,GAAU,EACV,EAAgB,KACP,EAAa,KAAK,CAC3B,GAAU,EACV,EAAgB,KAGlB,IAAM,EAAS,OAAO,WAAW,CAAC,EAAQ,EAAa,EAAS,SAchE,CAZA,CAAM,CAAC,CAYH,CAZK,CAAG,EAAQ,GAAG,CAAoB,IAAjB,EAAQ,MAAM,CAAU,EAAQ,MAAM,CAC5D,EAAQ,IAAI,EAAE,EAAM,CAAC,EAAE,EAAI,EAAA,EAE/B,CAAM,CAAC,EAAE,CAAG,EAEU,KAAK,CAAvB,EACF,EAAO,aAAa,CAAC,EAAY,GACN,KAAK,CAAvB,IACT,CAAM,CAAC,EAAE,CAAG,CAAM,CAAC,EAAE,CAAG,EACxB,EAAO,WAAW,CAAC,EAAY,EAAG,IAG/B,EAAQ,IAAI,EAAE,CAEnB,CAAM,CAAC,EAAE,EAAI,IACb,CAAM,CAAC,EAAS,EAAE,CAAG,CAAI,CAAC,EAAE,CAC5B,CAAM,CAAC,EAAS,EAAE,CAAG,CAAI,CAAC,EAAE,CAC5B,CAAM,CAAC,EAAS,EAAE,CAAG,CAAI,CAAC,EAAE,CAC5B,CAAM,CAAC,EAAS,EAAE,CAAG,CAAI,CAAC,EAAE,CAExB,GAAoB,CAAC,EAAQ,EAAK,CAElC,GACF,CAHe,CAGL,EADD,AACO,EAAM,EAAQ,EAAQ,GAC/B,CAAC,EAAO,GAGjB,EAAU,EAAM,EAAM,EAAM,EAAG,GACxB,CAAC,EAAQ,EAAK,EAhBK,CAAC,EAAQ,EAiBrC,AAjB0C,CA4B1C,MAAM,CAAI,CAAE,CAAI,CAAE,CAAI,CAAE,CAAE,CAAE,KACtB,EAEJ,GAAI,KAAS,MACX,EAAM,GADgB,IAEjB,GAAoB,UAAhB,EAA4B,KAArB,GAAsB,EAAkB,GAEnD,IAF0D,IAE7C,IAAT,GAAuB,EAAK,IAAN,EAAY,CAGtC,CAHwC,AAI7C,IAAM,EAAS,OAAO,UAAU,CAAC,GAEjC,GAAI,EAAS,IACX,CADgB,KACV,AAAI,WAAW,kDAIvB,CADA,EAAM,OAAO,WAAW,CAAC,EAAI,EAAA,EACzB,aAAa,CAAC,EAAM,GAEJ,UAAhB,AAA0B,OAAnB,EACT,EAAI,KAAK,CAAC,EAAM,GAEhB,EAAI,GAAG,CAAC,EAAM,EAElB,KAhBE,CADA,EAAM,OAAO,WAAW,CAAC,EAAA,EACrB,aAAa,CAAC,EAAM,QAHxB,MAAM,AAAI,UAAU,oDAqBtB,IAAM,EAAU,CACd,CAAC,EAAY,CAAE,EAAI,MAAM,CACzB,KAAK,EACL,aAAc,IAAI,CAAC,aAAa,MAChC,EACA,WAAY,IAAI,CAAC,WAAW,CAC5B,OAAQ,EACR,UAAU,EACV,KAAM,EACR,MAEI,IAAI,CAAC,MAAM,CACb,IADkB,AACd,CAAC,OAAO,CADe,AACd,CAAC,IAAI,CAAC,QAAQ,CAAE,GAAK,EAAO,EAAS,EAAG,EAErD,IAAI,CAAC,SAAS,CAAC,EAAO,KAAK,CAAC,EAAK,GAAU,EAE/C,CAUA,KAAK,CAAI,CAAE,CAAI,CAAE,CAAE,CAAE,KACf,EACA,EAcJ,GAZoB,UAAU,AAA1B,OAAO,GACT,EAAa,OAAO,UAAU,CAAC,GAC/B,GAAW,GACF,EAAO,IAChB,EAAa,CADU,CACL,IAAI,CACtB,GAAW,IAGX,EAAa,CADb,EAAO,EAAS,EAAA,EACE,MAAM,CACxB,EAAW,EAAS,QAAQ,EAG1B,EAAa,IACf,CADoB,KACd,AAAI,WAAW,oDAGvB,IAAM,EAAU,CACd,CAAC,EAAY,CAAE,EACf,KAAK,EACL,aAAc,IAAI,CAAC,aAAa,MAChC,EACA,WAAY,IAAI,CAAC,WAAW,CAC5B,OAAQ,WACR,EACA,MAAM,CACR,EAEI,EAAO,OAAO,AACZ,IAAI,CAAC,MAAM,CACb,IADkB,AACd,CAAC,OAAO,CADe,AACd,CAAC,IAAI,CAAC,WAAW,CAAE,GAAM,EAAO,EAAS,EAAG,EAEzD,IAAI,CAAC,WAAW,CAAC,GAAM,EAAO,EAAS,OAEhC,IAAI,CAAC,MAAM,CACpB,IAAI,AADqB,CACpB,OAAO,CADsB,AACrB,CAAC,IAAI,CAAC,QAAQ,CAAE,GAAM,EAAO,EAAS,EAAG,EAEtD,IAAI,CAAC,SAAS,CAAC,EAAO,KAAK,CAAC,EAAM,GAAU,EAEhD,CAUA,KAAK,CAAI,CAAE,CAAI,CAAE,CAAE,CAAE,KACf,EACA,EAcJ,GAZoB,UAAhB,AAA0B,OAAnB,GACT,EAAa,OAAO,UAAU,CAAC,GAC/B,EAAW,IACF,EAAO,IAChB,EAAa,CADU,CACL,IAAI,CACtB,GAAW,IAGX,EAAa,CADb,EAAO,EAAS,EAAA,EACE,MAAM,CACxB,EAAW,EAAS,QAAQ,EAG1B,EAAa,IACf,CADoB,KACd,AAAI,WAAW,oDAGvB,IAAM,EAAU,CACd,CAAC,EAAY,CAAE,EACf,IAAK,GACL,aAAc,IAAI,CAAC,aAAa,MAChC,EACA,WAAY,IAAI,CAAC,WAAW,CAC5B,OAAQ,YACR,EACA,KAAM,EACR,EAEI,EAAO,OAAO,AACZ,IAAI,CAAC,MAAM,CACb,IADkB,AACd,CAAC,OAAO,CAAC,AADc,CACb,IAAI,CAAC,WAAW,CAAE,GAAM,EAAO,EAAS,EAAG,EAEzD,IAAI,CAAC,WAAW,CAAC,EAAM,GAAO,EAAS,OAEhC,IAAI,CAAC,MAAM,CACpB,IADyB,AACrB,CAAC,OAAO,CAAC,AADqB,CACpB,IAAI,CAAC,QAAQ,CAAE,GAAM,EAAO,EAAS,EAAG,EAEtD,IAAI,CAAC,SAAS,CAAC,EAAO,KAAK,CAAC,EAAM,GAAU,EAEhD,CAkBA,KAAK,CAAI,CAAE,CAAO,CAAE,CAAE,CAAE,CACtB,IAII,EACA,EALE,EAAoB,IAAI,CAAC,WAAW,CAAC,EAAkB,aAAa,CAAC,CACvE,EAAS,EAAQ,MAAM,CAAG,EAAI,EAC9B,EAAO,EAAQ,QAAQ,CAKP,UAAhB,AAA0B,OAAnB,GACT,EAAa,OAAO,UAAU,CAAC,GAC/B,GAAW,GACF,EAAO,IAChB,EAAa,CADU,CACL,IAAI,CACtB,EAAW,KAGX,EAAa,CADb,EAAO,EAAS,EAAA,EACE,MAAM,CACxB,EAAW,EAAS,QAAQ,EAG1B,IAAI,CAAC,cAAc,EACrB,AADuB,IACnB,CAAC,cAAc,EAAG,EAEpB,GACA,GACA,EAAkB,MAAM,CACtB,EAAkB,SAAS,CACvB,6BACA,6BACL,EACD,CACA,EAAO,GAAc,EAAkB,UAAA,AAAU,EAEnD,IAAI,CAAC,SAAS,CAAG,IAEjB,GAAO,EACP,EAAS,GAGP,EAAQ,GAAG,EAAE,KAAI,CAAC,cAAc,EAAG,CAAA,EAEvC,IAAM,EAAO,CACX,CAAC,EAAY,CAAE,EACf,IAAK,EAAQ,GAAG,CAChB,aAAc,IAAI,CAAC,aAAa,CAChC,KAAM,EAAQ,IAAI,CAClB,WAAY,IAAI,CAAC,WAAW,QAC5B,WACA,OACA,CACF,EAEI,EAAO,OAAO,AACZ,IAAI,CAAC,MAAM,CACb,IAAI,AADc,CACb,OAAO,CADe,AACd,CAAC,IAAI,CAAC,WAAW,CAAE,EAAM,IAAI,CAAC,SAAS,CAAE,EAAM,EAAG,EAE/D,IAAI,CAAC,WAAW,CAAC,EAAM,IAAI,CAAC,SAAS,CAAE,EAAM,OAEtC,IAAI,CAAC,MAAM,CACpB,IADyB,AACrB,CAAC,OAAO,CADsB,AACrB,CAAC,IAAI,CAAC,QAAQ,CAAE,EAAM,IAAI,CAAC,SAAS,CAAE,EAAM,EAAG,EAE5D,IAAI,CAAC,QAAQ,CAAC,EAAM,IAAI,CAAC,SAAS,CAAE,EAAM,EAE9C,CAyBA,YAAY,CAAI,CAAE,CAAQ,CAAE,CAAO,CAAE,CAAE,CAAE,CACvC,IAAI,CAAC,cAAc,EAAI,CAAO,CAAC,EAAY,CAC3C,IAAI,CAAC,MAAM,CA/ZO,EA+ZJ,AAEd,EACG,WAAW,GACX,IAAI,CAAE,AAAD,IACJ,GAAI,IAAI,CAAC,OAAO,CAAC,SAAS,CAAE,CAC1B,IAAM,EAAM,AAAI,MACd,uDAQF,QAAQ,QAAQ,CAAC,EAAe,IAAI,CAAE,EAAK,GAC3C,MACF,CAEA,IAAI,CAAC,cAAc,EAAI,CAAO,CAAC,EAAY,CAC3C,IAAM,EAAO,EAAS,GAEjB,EAKH,IAAI,CAAC,GALQ,KAKA,CAAC,EAAM,EAAU,EAAS,IAJvC,IAAI,CAAC,MAAM,GAAG,AACd,IAAI,CAAC,SAAS,CAAC,EAAO,KAAK,CAAC,EAAM,GAAU,GAC5C,IAAI,CAAC,OAAO,GAIhB,GACC,KAAK,CAAE,AAAD,IAKL,QAAQ,QAAQ,CAAC,EAAS,IAAI,CAAE,EAAK,EACvC,EACJ,CAyBA,SAAS,CAAI,CAAE,CAAQ,CAAE,CAAO,CAAE,CAAE,CAAE,CACpC,GAAI,CAAC,EAAU,YACb,IAAI,CAAC,SAAS,CAAC,EAAO,KAAK,CAAC,EAAM,GAAU,GAI9C,IAAM,EAAoB,IAAI,CAAC,WAAW,CAAC,EAAkB,aAAa,CAAC,CAE3E,IAAI,CAAC,cAAc,EAAI,CAAO,CAAC,EAAY,CAC3C,IAAI,CAAC,MAAM,CAveG,EAueA,AACd,EAAkB,QAAQ,CAAC,EAAM,EAAQ,GAAG,CAAE,CAAC,EAAG,KAChD,AAAI,IAAI,CAAC,OAAO,CAAC,SAAS,CAKxB,CAL0B,CAKZ,IAAI,CAJN,AAAI,CAII,KAHlB,yDAGuB,IAI3B,IAAI,CAAC,cAAc,EAAI,CAAO,CAAC,EAAY,CAC3C,IAAI,CAAC,MAAM,CApfD,EAofI,AACd,EAAQ,QAAQ,EAAG,EACnB,IAAI,CAAC,SAAS,CAAC,EAAO,KAAK,CAAC,EAAK,GAAU,GAC3C,IAAI,CAAC,OAAO,GACd,EACF,CAOA,SAAU,CACR,KAAO,QAAI,CAAC,MAAM,EAAgB,GAAX,CAAe,CAAC,MAAM,CAAC,MAAM,EAAE,CACpD,IAAM,EAAS,IAAI,CAAC,MAAM,CAAC,KAAK,GAEhC,IAAI,CAAC,cAAc,EAAI,CAAM,CAAC,EAAE,CAAC,EAAY,CAC7C,QAAQ,KAAK,CAAC,CAAM,CAAC,EAAE,CAAE,IAAI,CAAE,EAAO,KAAK,CAAC,GAC9C,CACF,CAQA,QAAQ,CAAM,CAAE,CACd,IAAI,CAAC,cAAc,EAAI,CAAM,CAAC,EAAE,CAAC,EAAY,CAC7C,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,EACnB,CASA,UAAU,CAAI,CAAE,CAAE,CAAE,CACE,GAAG,CAAnB,EAAK,MAAM,EACb,IAAI,CAAC,OAAO,CAAC,IAAI,GACjB,IAAI,CAAC,OAAO,CAAC,KAAK,CAAC,CAAI,CAAC,EAAE,EAC1B,IAAI,CAAC,OAAO,CAAC,KAAK,CAAC,CAAI,CAAC,EAAE,CAAE,GAC5B,IAAI,CAAC,OAAO,CAAC,MAAM,IAEnB,IAAI,CAAC,OAAO,CAAC,KAAK,CAAC,CAAI,CAAC,EAAE,CAAE,EAEhC,CACF,CAYA,SAAS,EAAc,CAAM,CAAE,CAAG,CAAE,CAAE,EAClB,YAAd,OAAO,GAAmB,EAAG,GAEjC,IAAK,IAAI,EAAI,EAAG,EAAI,EAAO,MAAM,CAAC,MAAM,CAAE,IAAK,CAC7C,IAAM,EAAS,EAAO,MAAM,CAAC,EAAE,CACzB,EAAW,CAAM,CAAC,EAAO,MAAM,CAAG,EAAE,CAElB,YAApB,OAAO,GAAyB,EAAS,EAC/C,CACF,CAUA,SAAS,EAAQ,CAAM,CAAE,CAAG,CAAE,CAAE,EAC9B,EAAc,EAAQ,EAAK,GAC3B,EAAO,OAAO,CAAC,EACjB,CAhCA,EAAO,OAAO,CAAG,gCCvjBjB,GAAM,CAAE,sBAAoB,CAAE,WAAS,CAAE,CAAA,EAAA,CAAA,CAAA,OAEnC,EAAQ,OAAO,SACf,EAAQ,OAAO,SACf,EAAS,OAAO,UAChB,EAAW,OAAO,YAClB,EAAU,OAAO,WACjB,EAAU,OAAO,WACjB,EAAQ,OAAO,SACf,EAAY,OAAO,YAKzB,OAAM,EAOJ,YAAY,CAAI,CAAE,CAChB,IAAI,CAAC,EAAQ,CAAG,KAChB,IAAI,CAAC,EAAM,CAAG,CAChB,CAKA,IAAI,QAAS,CACX,OAAO,IAAI,CAAC,EAAQ,AACtB,CAKA,IAAI,MAAO,CACT,OAAO,IAAI,CAAC,EACd,AADoB,CAEtB,CAEA,OAAO,cAAc,CAAC,EAAM,SAAS,CAAE,SAAU,CAAE,YAAY,CAAK,GACpE,OAAO,cAAc,CAAC,EAAM,SAAS,CAAE,OAAQ,CAAE,YAAY,CAAK,EAOlE,OAAM,UAAmB,EAcvB,YAAY,CAAI,CAAE,EAAU,CAAC,CAAC,CAAE,CAC9B,KAAK,CAAC,GAEN,IAAI,CAAC,EAAM,CAAG,KAAiB,MAAT,IAAI,CAAiB,EAAI,EAAQ,IAAI,CAC3D,IAAI,CAAC,EAAQ,MAAsB,IAAnB,EAAQ,MAAM,CAAiB,GAAK,EAAQ,MAAM,CAClE,IAAI,CAAC,EAAU,CAAwB,AAArB,WAAQ,CAAyB,OAAjB,EAAyB,EAAQ,QACrE,AAD6E,CAM7E,IAAI,MAAO,CACT,OAAO,IAAI,CAAC,EAAM,AACpB,CAKA,IAAI,QAAS,CACX,OAAO,IAAI,CAAC,EAAQ,AACtB,CAKA,IAAI,UAAW,CACb,OAAO,IAAI,CAAC,EACd,AADwB,CAE1B,CAEA,OAAO,cAAc,CAAC,EAAW,SAAS,CAAE,OAAQ,CAAE,YAAY,CAAK,GACvE,OAAO,cAAc,CAAC,EAAW,SAAS,CAAE,SAAU,CAAE,YAAY,CAAK,GACzE,OAAO,cAAc,CAAC,EAAW,SAAS,CAAE,WAAY,CAAE,YAAY,CAAK,EAO3E,OAAM,UAAmB,EAUvB,YAAY,CAAI,CAAE,EAAU,CAAC,CAAC,CAAE,CAC9B,KAAK,CAAC,GAEN,IAAI,CAAC,EAAO,CAAG,KAAkB,MAAV,KAAK,CAAiB,KAAO,EAAQ,KAAK,CACjE,IAAI,CAAC,EAAS,CAAG,KAAoB,MAAZ,OAAO,CAAiB,GAAK,EAAQ,OAAO,AACvE,CAKA,IAAI,OAAQ,CACV,OAAO,IAAI,CAAC,EAAO,AACrB,CAKA,IAAI,SAAU,CACZ,OAAO,IAAI,CAAC,EAAS,AACvB,CACF,CAEA,OAAO,cAAc,CAAC,EAAW,SAAS,CAAE,QAAS,CAAE,YAAY,CAAK,GACxE,OAAO,cAAc,CAAC,EAAW,SAAS,CAAE,UAAW,CAAE,YAAY,CAAK,EAO1E,OAAM,UAAqB,EASzB,YAAY,CAAI,CAAE,EAAU,CAAC,CAAC,CAAE,CAC9B,KAAK,CAAC,GAEN,IAAI,CAAC,EAAM,MAAoB,IAAjB,EAAQ,IAAI,CAAiB,KAAO,EAAQ,IAAI,AAChE,CAKA,IAAI,MAAO,CACT,OAAO,IAAI,CAAC,EAAM,AACpB,CACF,CAwHA,SAAS,EAAa,CAAQ,CAAE,CAAO,CAAE,CAAK,EACpB,UAApB,OAAO,GAAyB,EAAS,WAAW,CACtD,CADwD,CAC/C,WAAW,CAAC,IAAI,CAAC,EAAU,GAEpC,EAAS,IAAI,CAAC,EAAS,EAE3B,CA5HA,OAAO,cAAc,CAAC,EAAa,SAAS,CAAE,OAAQ,CAAE,YAAY,CAAK,GAsGzE,EAAO,OAAO,CAAG,YACf,EACA,mBACA,EACA,YAlGkB,CAalB,iBAAiB,CAAI,CAAE,CAAO,CAAE,EAAU,CAAC,CAAC,MAWtC,EAVJ,IAAK,IAAM,KAAY,IAAI,CAAC,SAAS,CAAC,GACpC,GAD2C,AAEzC,CAAC,CAAO,CAAC,EAAqB,EAC9B,CAAQ,CAAC,EAAU,GAAK,GACxB,CAAC,CAAQ,CAAC,EAAqB,CAE/B,CADA,MAOJ,GAAa,WAAW,CAApB,EACF,EAAU,SAAS,AAAU,CAAI,CAAE,CAAQ,EACzC,IAAM,EAAQ,IAAI,EAAa,UAAW,CACxC,KAAM,EAAW,EAAO,EAAK,QAAQ,EACvC,GAEA,CAAK,CAAC,EAAQ,CAAG,IAAI,CACrB,EAAa,EAAS,IAAI,CAAE,EAC9B,OACK,GAAa,SAAS,CAAlB,EACT,EAAU,SAAS,AAAQ,CAAI,CAAE,CAAO,EACtC,IAAM,EAAQ,IAAI,EAAW,QAAS,MACpC,EACA,OAAQ,EAAQ,QAAQ,GACxB,SAAU,IAAI,CAAC,mBAAmB,EAAI,IAAI,CAAC,eAAe,AAC5D,GAEA,CAAK,CAAC,EAAQ,CAAG,IAAI,CACrB,EAAa,EAAS,IAAI,CAAE,EAC9B,OACK,GAAa,SAAS,CAAlB,EACT,EAAU,SAAS,AAAQ,CAAK,EAC9B,IAAM,EAAQ,IAAI,EAAW,QAAS,OACpC,EACA,QAAS,EAAM,OACjB,AADwB,GAGxB,CAAK,CAAC,EAAQ,CAAG,IAAI,CACrB,EAAa,EAAS,IAAI,CAAE,EAC9B,OACK,GAAa,QAAQ,CAAjB,EAQT,OAPA,EAAU,SAAS,EACjB,IAAM,EAAQ,IAAI,EAAM,QAExB,CAAK,CAAC,EAAQ,CAAG,IAAI,CACrB,EAAa,EAAS,IAAI,CAAE,EAC9B,EAKF,CAAO,CAAC,EAAqB,CAAG,CAAC,CAAC,CAAO,CAAC,EAAqB,CAC/D,CAAO,CAAC,EAAU,CAAG,EAEjB,EAAQ,IAAI,CACd,CADgB,GACZ,CAAC,IAAI,CAAC,EAAM,GAEhB,IAAI,CAAC,EAAE,CAAC,EAAM,EAElB,EASA,oBAAoB,CAAI,CAAE,CAAO,EAC/B,IAAK,IAAM,KAAY,IAAI,CAAC,SAAS,CAAC,GACpC,GAD2C,AACvC,CAAQ,CAAC,EAAU,GAAK,GAAW,CAAC,CAAQ,CAAC,EAAqB,CAAE,CACtE,IAAI,CAAC,cAAc,CAAC,EAAM,GAC1B,KACF,CAEJ,CACF,eAOE,CACF,gCCjRA,GAAM,YAAE,CAAU,CAAE,CAAA,EAAA,CAAA,CAAA,OAYpB,SAAS,EAAK,CAAI,CAAE,CAAI,CAAE,CAAI,EACxB,AAAe,UAAX,CAAC,EAAK,CAAgB,CAAI,CAAC,EAAK,CAAG,CAAC,EAAK,CAC5C,CAAI,CAAC,EAAK,CAAC,IAAI,CAAC,EACvB,CAyLA,EAAO,OAAO,CAAG,CAAE,OAxBnB,SAAS,AAAO,CAAU,EACxB,OAAO,OAAO,IAAI,CAAC,GAChB,GAAG,CAAC,AAAC,IACJ,IAAI,EAAiB,CAAU,CAAC,EAAU,CAE1C,OADI,AAAC,MAAM,OAAO,CAAC,KAAiB,EAAiB,CAAC,EAAe,EAC9D,EACJ,GAAG,CAAE,AAAD,GACI,CAAC,EAAU,CACf,MAAM,CACL,OAAO,IAAI,CAAC,GAAQ,GAAG,CAAC,AAAC,IACvB,IAAI,EAAS,CAAM,CAAC,EAAE,CAEtB,OADI,AAAC,MAAM,OAAO,CAAC,KAAS,EAAS,CAAC,EAAO,EACtC,EACJ,GAAG,CAAC,AAAC,GAAa,KAAN,EAAa,EAAI,CAAA,EAAG,EAAE,CAAC,EAAE,EAAA,CAAG,EACxC,IAAI,CAAC,KACV,IAED,IAAI,CAAC,OAET,IAAI,CAAC,KACV,GACC,IAAI,CAAC,KACV,EAE2B,MAhL3B,SAAS,AAAM,CAAM,EACnB,IAKI,EACA,EANE,EAAS,OAAO,MAAM,CAAC,MACzB,EAAS,OAAO,MAAM,CAAC,MACvB,GAAe,EACf,EAAa,GACb,GAAW,EAGX,EAAQ,CAAC,EACT,EAAO,CAAC,EACR,EAAM,CAAC,EACP,EAAI,EAER,KAAO,EAAI,EAAO,MAAM,CAAE,IAGxB,AAH6B,GAC7B,EAAO,EAAO,UAAU,CAAC,QAEH,IAAlB,EACF,GAAY,CAAC,CADkB,GAC3B,GAAmC,GAAG,CAAxB,CAAU,CAAC,EAAK,CAC5B,AAAU,CAAC,QAAG,EAAQ,QACrB,GACC,IAAN,CACA,GAAC,AAAS,KAAK,GAAsB,IAAT,AAAN,CAAe,CAAI,CAE7B,CAAC,CADb,GACI,GAAwB,CAAC,IAAX,IAAc,GAAM,OACjC,GAAa,KAAT,AAAc,GAAsB,IAAf,CAAM,AAAc,EAAW,CAC7D,GAAc,CAD2C,AAC1C,GAAG,CAAd,EACF,MAAM,AAAI,YAAY,CAAC,8BAA8B,EAAE,EAAA,CAAG,EAGhD,CAAC,IAAT,IAAY,GAAM,EACtB,IAAM,EAAO,EAAO,KAAK,CAAC,EAAO,GACpB,KAAT,CAAe,EACjB,EAAK,EAAQ,EAAM,GACnB,EAAS,OAAO,MAAM,CAAC,OAEvB,EAAgB,EAGlB,EAAQ,EAAM,CAAC,CACjB,MACE,CADK,KACC,AAAI,YAAY,CAAC,8BAA8B,EAAE,EAAA,CAAG,OAEvD,QAAkB,IAAd,EACT,GAAI,AAAQ,CAAC,CADqB,MACK,GAAG,CAAxB,CAAU,CAAC,EAAK,CAClB,CAAC,IAAX,IAAc,GAAQ,OACrB,GAAa,KAAT,GAA0B,IAAT,EAAe,AAC7B,CAAC,IAAT,GAAwB,CAAC,IAAX,IAAc,GAAM,OACjC,GAAa,KAAT,GAA0B,KAAT,EAAe,CACzC,GAAc,CAAC,GAAG,CAAd,EACF,MAAM,AAAI,YAAY,CAAC,8BAA8B,EAAE,EAAA,CAAG,EAGhD,CAAC,IAAT,IAAY,GAAM,EACtB,EAAK,EAAQ,EAAO,KAAK,CAAC,EAAO,IAAM,GAC1B,KAAT,CAAe,GACjB,EAAK,EAAQ,EAAe,GAC5B,EAAS,OAAO,MAAM,CAAC,MACvB,EAAgB,QAGlB,EAAQ,EAAM,CAAC,CACjB,MAAO,GAAa,KAAT,AAAc,GAAuB,CAAC,GAAjB,CAAM,GAAwB,CAAC,GAAG,CAAZ,EACpD,EAAY,EAAO,KAAK,CAAC,EAAO,GAChC,EAAQ,EAAM,CAAC,OAEf,MAAM,AAAI,YAAY,CAAC,8BAA8B,EAAE,EAAA,CAAG,OAQ5D,GAAI,EAAY,CACd,GAAyB,GAAG,CAAxB,CAAU,CAAC,EAAK,CAClB,MAAM,AAAI,YAAY,CAAC,8BAA8B,EAAE,EAAA,CAAG,EAE9C,CAAC,IAAX,EAAc,EAAQ,EACjB,AAAC,IAAc,GAAe,CAAA,EACvC,GAAa,CACf,MAAO,GAAI,EACT,GAAyB,GAAG,CAAxB,CADe,AACL,CAAC,EAAK,CACJ,CAAC,IAAX,IAAc,GAAQ,OACrB,GAAa,KAAT,AAAc,GAAuB,CAAC,GAAG,AAApB,CAAM,EACpC,GAAW,EACX,EAAM,OACD,GAAI,AAAS,KAAK,EACvB,GAAa,EADiB,KAAI,AAGlC,MAAM,AAAI,YAAY,CAAC,8BAA8B,EAAE,EAAA,CAAG,OAEvD,GAAa,KAAT,GAA8C,KAA7B,CAAmC,CAA5B,UAAU,CAAC,EAAI,GAChD,GAAW,OACN,GAAY,CAAC,IAAT,GAAmC,GAAG,CAAxB,CAAU,CAAC,EAAK,CACzB,CAAC,IAAX,IAAc,GAAQ,OACrB,GAAc,CAAC,IAAX,CAAgB,GAAC,AAAS,QAAiB,IAAT,CAAS,CAAI,CAC5C,CAAC,CAD8C,GACvD,IAAY,GAAM,OACjB,GAAa,KAAT,GAA0B,KAAT,EAAe,CACzC,GAAc,CAAC,GAAG,CAAd,EACF,MAAM,AAAI,YAAY,CAAC,8BAA8B,EAAE,EAAA,CAAG,EAGhD,CAAC,IAAT,IAAY,GAAM,EACtB,IAAI,EAAQ,EAAO,KAAK,CAAC,EAAO,GAC5B,IACF,EAAQ,EAAM,MADE,CACK,CAAC,MAAO,IAC7B,GAAe,GAEjB,EAAK,EAAQ,EAAW,GACX,KAAT,CAAe,GACjB,EAAK,EAAQ,EAAe,GAC5B,EAAS,OAAO,MAAM,CAAC,MACvB,OAAgB,GAGlB,OAAY,EACZ,EAAQ,EAAM,CAAC,CACjB,MACE,CADK,KACC,AAAI,YAAY,CAAC,8BAA8B,EAAE,EAAA,CAAG,EAKhE,GAAc,CAAC,IAAX,GAAgB,GAAqB,KAAT,GAA0B,IAAT,EAAe,AAC9D,MAAM,AAAI,YAAY,2BAGZ,CAAC,IAAT,IAAY,GAAM,EACtB,IAAM,EAAQ,EAAO,KAAK,CAAC,EAAO,GAclC,OAbI,KAAkB,MACpB,EAAK,EAAQ,CADkB,CACX,SAEF,IAAd,EACF,EAAK,EAAQ,CADc,EACP,GACX,EACT,EAAK,EAAQ,EAAW,EAAM,IADP,GACc,CAAC,MAAO,KAE7C,EAAK,EAAQ,EAAW,GAE1B,EAAK,EAAQ,EAAe,IAGvB,CACT,CAiCiC,gCCtMjC,IAAM,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,MACA,EAAA,EAAA,CAAA,CAAA,OACA,aAAE,CAAW,YAAE,CAAU,CAAE,CAAA,EAAA,CAAA,CAAA,OAC3B,QAAE,CAAM,UAAE,CAAQ,CAAE,CAAA,EAAA,CAAA,CAAA,OACpB,KAAE,CAAG,CAAE,CAAA,EAAA,CAAA,CAAA,OAEP,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,QAAE,CAAM,CAAE,CAAA,EAAA,CAAA,CAAA,OAEV,cACJ,CAAY,cACZ,CAAY,MACZ,CAAI,CACJ,sBAAoB,WACpB,CAAS,aACT,CAAW,YACX,CAAU,MACV,CAAI,CACL,CAAA,EAAA,CAAA,CAAA,OACK,CACJ,YAAa,kBAAE,CAAgB,qBAAE,CAAmB,CAAE,CACvD,CAAA,EAAA,CAAA,CAAA,OACK,CAAE,QAAM,OAAE,CAAK,CAAE,CAAA,EAAA,CAAA,CAAA,OACjB,CAAE,UAAQ,CAAE,CAAA,EAAA,CAAA,CAAA,OAGZ,EAAW,OAAO,YAClB,EAAmB,CAAC,EAAG,GAAG,CAC1B,EAAc,CAAC,aAAc,OAAQ,UAAW,SAAS,CACzD,EAAmB,gCAOzB,OAAM,UAAkB,EAQtB,YAAY,CAAO,CAAE,CAAS,CAAE,CAAO,CAAE,CACvC,KAAK,GAEL,IAAI,CAAC,WAAW,CAAG,CAAY,CAAC,EAAE,CAClC,IAAI,CAAC,UAAU,CAAG,KAClB,IAAI,CAAC,mBAAmB,EAAG,EAC3B,IAAI,CAAC,eAAe,EAAG,EACvB,IAAI,CAAC,aAAa,CAAG,EACrB,IAAI,CAAC,WAAW,CAAG,KACnB,IAAI,CAAC,aAAa,EAAG,EACrB,IAAI,CAAC,WAAW,CAAG,CAAC,EACpB,IAAI,CAAC,OAAO,EAAG,EACf,IAAI,CAAC,SAAS,CAAG,GACjB,IAAI,CAAC,WAAW,CAAG,EAAU,UAAU,CACvC,IAAI,CAAC,SAAS,CAAG,KACjB,IAAI,CAAC,OAAO,CAAG,KACf,IAAI,CAAC,OAAO,CAAG,KAEC,MAAM,CAAlB,GACF,IAAI,CAAC,eAAe,CAAG,EACvB,IAAI,CAAC,SAAS,EAAG,EACjB,IAAI,CAAC,UAAU,CAAG,OAEA,IAAd,EACF,EAAY,EAAE,CADa,AAEjB,MAAM,OAAO,CAAC,KACC,OADW,GAChC,OAAO,GAA0B,AAAc,MAAM,IACvD,EAAU,EACV,EAAY,EAAE,EAEd,EAAY,CAAC,EAAU,EAI3B,AAsjBN,SAAS,EAAa,CAAS,CAAE,CAAO,CAAE,CAAS,CAAE,CAAO,EAC1D,IA6BI,EAsBA,EA2BA,EAgEA,EA9IE,EAAO,CACX,wBAAwB,EACxB,UAAU,EACV,gBAAiB,CAAgB,CAAC,EAAE,CACpC,WAAY,MAAM,IAClB,GADyB,iBACL,EACpB,mBAAmB,EACnB,iBAAiB,EACjB,aAAc,GACd,GAAG,CAAO,CACV,gBAAY,EACZ,cAAU,EACV,cAAU,EACV,aAAS,EACT,OAAQ,MACR,UAAM,EACN,UAAM,EACN,UAAM,CACR,EAIA,GAFA,EAAU,SAAS,CAAG,EAAK,QAAQ,CAE/B,CAAC,EAAiB,QAAQ,CAAC,EAAK,eAAe,EACjD,CADoD,KAC1C,AAAJ,WACJ,CAAC,8BAA8B,EAAE,EAAK,eAAe,CAAC,AACnD,CADoD,qBAC/B,EAAE,EAAiB,IAAI,CAAC,MAAM,CAAC,CAAC,AADA,EAO5D,CANM,EAMF,aAAmB,EACrB,EAAY,CADc,MAG1B,GAAI,CACF,EAAY,IAAI,EAAI,EACtB,CAAE,MAAO,EAAG,CACV,MAAM,AAAI,YAAY,CAAC,aAAa,EAAE,EAAA,CAAS,CACjD,CAGyB,SAAS,CAAhC,EAAU,QAAQ,CACpB,EAAU,QAAQ,CAAG,MACZ,AAAuB,UAAU,GAAvB,QAAQ,GAC3B,EAAU,QAAQ,CAAG,MAAA,EAGvB,EAAU,IAAI,CAAG,EAAU,IAAI,CAE/B,IAAM,EAAkC,SAAvB,EAAU,QAAQ,CAC7B,EAAW,AAAuB,eAAb,QAAQ,CAanC,GAV2B,QAAvB,CAAgC,CAAtB,QAAQ,EAAe,GAAa,EAIvC,GAAY,CAAC,EAAU,CAJe,CAAW,MAIlB,CACxC,CAD0C,CACtB,8BACX,EAAU,IAAI,EAAE,CACzB,EAAoB,wCAAA,EANpB,EACE,uDACA,8BAOA,EAAmB,CACrB,IAAM,EAAM,AAAI,YAAY,GAE5B,GAA6B,GAAG,CAA5B,EAAU,UAAU,CAEjB,YACL,EAAkB,EAAW,EAF7B,OAAM,CAKV,CAEA,IAAM,EAAc,EAAW,IAAM,GAC/B,EAAM,EAAY,IAAI,QAAQ,CAAC,UAC/B,EAAU,EAAW,EAAM,OAAO,CAAG,EAAK,OAAO,CACjD,EAAc,IAAI,IA8BxB,GA3BA,EAAK,gBAAgB,CACnB,EAAK,gBAAgB,EAAK,EAAD,CAAY,EAAa,CAAA,CAAU,CAC9D,EAAK,WAAW,CAAG,EAAK,WAAW,EAAI,EACvC,EAAK,IAAI,CAAG,EAAU,IAAI,EAAI,EAC9B,EAAK,IAAI,CAAG,EAAU,QAAQ,CAAC,UAAU,CAAC,KACtC,EAAU,QAAQ,CAAC,KAAK,CAAC,EAAG,CAAC,GAC7B,EAAU,QAAQ,CACtB,EAAK,OAAO,CAAG,CACb,GAAG,EAAK,OAAO,CACf,wBAAyB,EAAK,eAAe,CAC7C,oBAAqB,EACrB,WAAY,UACZ,QAAS,WACX,EACA,EAAK,IAAI,CAAG,EAAU,QAAQ,CAAG,EAAU,MAAM,CACjD,EAAK,OAAO,CAAG,EAAK,gBAAgB,CAEhC,EAAK,iBAAiB,EAAE,CAC1B,EAAoB,IAAI,GACK,IAA3B,EAAK,iBAAiB,CAAY,EAAK,iBAAiB,CAAG,CAAC,GAC5D,EACA,EAAK,UAAU,EAEjB,EAAK,OAAO,CAAC,2BAA2B,CAAG,EAAO,CAChD,CAAC,EAAkB,aAAa,CAAC,CAAE,EAAkB,KAAK,EAC5D,IAEE,EAAU,MAAM,CAAE,CACpB,IAAK,IAAM,KAAY,EAAW,CAChC,GACsB,UAApB,OAAO,GACP,CAAC,EAAiB,IAAI,CAAC,IACvB,EAAY,GAAG,CAAC,GAEhB,MAAM,AAAI,EADV,UAEE,sDAIJ,EAAY,GAAG,CAAC,EAClB,CAEA,EAAK,OAAO,CAAC,yBAAyB,CAAG,EAAU,IAAI,CAAC,IAC1D,CAYA,GAXI,EAAK,MAAM,EAAE,CACX,EAAK,eAAe,CAAG,GACzB,CAD6B,CACxB,OAAO,CAAC,uBAAuB,CAAG,EAAK,MAAM,CAElD,EAAK,OAAO,CAAC,MAAM,CAAG,EAAK,MAAM,GAGjC,EAAU,QAAQ,EAAI,EAAU,QAAA,AAAQ,EAAE,EAC5C,EAAK,IAAI,CAAG,CAAA,EAAG,EAAU,QAAQ,CAAC,CAAC,EAAE,EAAU,QAAQ,CAAA,CAAA,AAAE,EAGvD,EAAU,CACZ,IAAM,EAAQ,EAAK,IAAI,CAAC,KAAK,CAAC,KAE9B,EAAK,UAAU,CAAG,CAAK,CAAC,EAAE,CAC1B,EAAK,IAAI,CAAG,CAAK,CAAC,EAAE,AACtB,CAIA,GAAI,EAAK,eAAe,CAAE,CACxB,GAA6B,IAAzB,EAAU,UAAU,CAAQ,CAC9B,EAAU,YAAY,CAAG,EACzB,EAAU,eAAe,CAAG,EAC5B,EAAU,yBAAyB,CAAG,EAClC,EAAK,UAAU,CACf,EAAU,IAAI,CAElB,IAAM,EAAU,GAAW,EAAQ,OAAO,CAQ1C,GAFA,EAAU,CAAE,GAAG,CAAO,CAAE,QAAS,CAAC,CAAE,EAEhC,EACF,IAAK,GADM,AACA,CAAC,EAAK,EAAM,GAAI,OAAO,OAAO,CAAC,GACxC,EAAQ,IAD0C,GACnC,CAAC,EAAI,WAAW,GAAG,CAAG,CAG3C,MAAO,GAA4C,IAAxC,EAAU,aAAa,CAAC,YAAmB,CACpD,IAAM,EAAa,IACf,EAAU,YAAY,EACpB,EAAK,UAAU,GAAK,EAAU,yBAAyB,EAEzD,CADE,CACQ,YAAY,EAEpB,CADA,CACU,IAAI,GAAK,EAAU,yBAAyB,CAEvD,GAAe,IAAU,eAAe,EAAK,CAAA,CAAD,EAAY,CAK3D,OAAO,EAAK,OAAO,CAAC,aAAa,CACjC,OAAO,EAAK,OAAO,CAAC,MAAM,CAEtB,AAAC,GAAY,OAAO,EAAK,OAAO,CAAC,IAAI,CAEzC,EAAK,IAAI,MAAG,EAEhB,CAOI,EAAK,IAAI,EAAI,CAAC,EAAQ,OAAO,CAAC,aAAa,EAAE,CAC/C,EAAQ,OAAO,CAAC,aAAa,CAC3B,SAAW,OAAO,IAAI,CAAC,EAAK,IAAI,EAAE,QAAQ,CAAC,SAAA,EAG/C,EAAM,EAAU,IAAI,CAAG,EAAQ,GAE3B,EAAU,UAAU,EAAE,AAUxB,EAAU,IAAI,CAAC,WAAY,EAAU,GAAG,CAAE,EAE9C,MACE,CADK,CACC,EAAU,IAAI,CAAG,EAAQ,EAG7B,GAAK,OAAO,EAAE,AAChB,EAAI,EAAE,CAAC,UAAW,KAChB,EAAe,EAAW,EAAK,kCACjC,GAGF,EAAI,EAAE,CAAC,QAAS,AAAC,IACH,OAAR,GAAgB,CAAG,CAAC,EAAS,EAAE,CAEnC,EAAM,EAAU,IAAI,CAAG,KACvB,EAAkB,EAAW,GAC/B,GAEA,EAAI,EAAE,CAAC,WAAY,AAAC,IAClB,IAAM,EAAW,EAAI,OAAO,CAAC,QAAQ,CAC/B,EAAa,EAAI,UAAU,CAEjC,GACE,GACA,EAAK,eAAe,EACpB,GAAc,KACd,EAAa,IACb,KAQI,EAPJ,GAAI,EAAE,EAAU,UAAU,CAAG,EAAK,YAAY,CAAE,YAC9C,EAAe,EAAW,EAAK,8BAIjC,EAAI,KAAK,GAIT,GAAI,CACF,EAAO,IAAI,EAAI,EAAU,EAC3B,CAAE,MAAO,EAAG,CAEV,EAAkB,EADN,AAAI,SACa,GADD,CAAC,aAAa,EAAE,EAAA,CAAU,GAEtD,MACF,CAEA,EAAa,EAAW,EAAM,EAAW,EAC3C,MAAY,AAAD,CAAJ,CAAe,IAAI,CAAC,sBAAuB,EAAK,IACrD,EAD2D,AAEzD,EACA,EACA,CAAC,4BAA4B,EAAE,EAAI,UAAU,CAAA,CAAE,CAGrD,GAEA,EAAI,EAAE,CAAC,UAAW,CAAC,EAAK,EAAQ,SA4B1B,EArBJ,GANA,EAAU,IAAI,CAAC,UAAW,GAMtB,EAAU,UAAU,GAAK,EAAU,UAAU,CAAE,OAEnD,EAAM,EAAU,IAAI,CAAG,KAEvB,IAAM,EAAU,EAAI,OAAO,CAAC,OAAO,CAEnC,QAAgB,IAAZ,GAAmD,cAA1B,EAAQ,WAAW,GAAoB,YAClE,EAAe,EAAW,EAAQ,0BAIpC,IAAM,EAAS,EAAW,QACvB,MAAM,CAAC,EAAM,GACb,MAAM,CAAC,UAEV,GAAI,EAAI,OAAO,CAAC,uBAAuB,GAAK,EAAQ,YAClD,EAAe,EAAW,EAAQ,uCAIpC,IAAM,EAAa,EAAI,OAAO,CAAC,yBAAyB,CAaxD,QAVmB,IAAf,EACG,EAAY,GADW,CACP,CAEV,AAAC,CAFW,CAEC,GAAG,CAAC,KAC1B,EAAY,MAD2B,8BAC3B,EAFZ,EAAY,mDAIL,EAAY,IAAI,EAAE,AAC3B,GAAY,4BAAA,EAGV,EAAW,YACb,EAAe,EAAW,EAAQ,GAIhC,IAAY,EAAU,SAAS,CAAG,CAAA,EAEtC,IAAM,EAAyB,EAAI,OAAO,CAAC,2BAA2B,CAEtE,QAA+B,IAA3B,EAAsC,KASpC,EARJ,GAAI,CAAC,EAAmB,YAItB,EAAe,EAAW,EAFxB,MAEgC,8DADhC,YAOJ,GAAI,CACF,EAAa,EAAM,EACrB,CAAE,MAAO,EAAK,CAEZ,EAAe,EAAW,EADV,MACkB,qCAClC,MACF,CAEA,IAAM,EAAiB,OAAO,IAAI,CAAC,GAEnC,GAC4B,AAA1B,MAAe,MAAM,EACrB,CAAc,CAAC,EAAE,GAAK,EAAkB,aAAa,CACrD,YAEA,EAAe,EAAW,EADV,MACkB,kDAIpC,GAAI,CACF,EAAkB,MAAM,CAAC,CAAU,CAAC,EAAkB,aAAa,CAAC,CACtE,CAAE,MAAO,EAAK,CAEZ,EAAe,EAAW,EADV,MACkB,qCAClC,MACF,CAEA,EAAU,WAAW,CAAC,EAAkB,aAAa,CAAC,CACpD,CACJ,CAEA,EAAU,SAAS,CAAC,EAAQ,EAAM,CAChC,uBAAwB,EAAK,sBAAsB,CACnD,aAAc,EAAK,YAAY,CAC/B,WAAY,EAAK,UAAU,CAC3B,mBAAoB,EAAK,kBAC3B,AAD6C,EAE/C,GAEI,EAAK,aAAa,CACpB,CADsB,CACjB,aAAa,CAAC,EAAK,GAExB,EAAI,GAAG,EAEX,EAz6BmB,IAAI,CAAE,EAAS,EAAW,KAEvC,IAAI,CAAC,SAAS,CAAG,EAAQ,QAAQ,CACjC,IAAI,CAAC,SAAS,EAAG,EAErB,CAQA,IAAI,YAAa,CACf,OAAO,IAAI,CAAC,WACd,AADyB,CAGzB,IAAI,WAAW,CAAI,CAAE,CACd,EAAa,QAAQ,CAAC,KAE3B,EAFkC,EAE9B,CAAC,WAAW,CAAG,EAKf,IAAI,CAAC,SAAS,GAAE,IAAI,CAAC,SAAS,CAAC,WAAW,CAAG,CAAA,EACnD,CAKA,IAAI,gBAAiB,QACnB,AAAK,IAAD,AAAK,CAAC,OAAO,CAEV,CAFY,GAER,CAAC,OAAO,CAAC,cAAc,CAAC,MAAM,CAAG,IAAI,CAAC,OAAO,CAAC,cAAc,CAF7C,IAAI,CAAC,eAGjC,AAHgD,CAQhD,IAAI,YAAa,CACf,OAAO,OAAO,IAAI,CAAC,IAAI,CAAC,WAAW,EAAE,IAAI,EAC3C,CAKA,IAAI,UAAW,CACb,OAAO,IAAI,CAAC,OAAO,AACrB,CAMA,IAAI,SAAU,CACZ,OAAO,IACT,CAMA,IAAI,SAAU,CACZ,OAAO,IACT,CAMA,IAAI,QAAS,CACX,OAAO,IACT,CAMA,IAAI,WAAY,CACd,OAAO,IACT,CAKA,IAAI,UAAW,CACb,OAAO,IAAI,CAAC,SAAS,AACvB,CAKA,IAAI,YAAa,CACf,OAAO,IAAI,CAAC,WAAW,AACzB,CAKA,IAAI,KAAM,CACR,OAAO,IAAI,CAAC,IAAI,AAClB,CAkBA,UAAU,CAAM,CAAE,CAAI,CAAE,CAAO,CAAE,CAC/B,IAAM,EAAW,IAAI,EAAS,CAC5B,uBAAwB,EAAQ,sBAAsB,CACtD,WAAY,IAAI,CAAC,UAAU,CAC3B,WAAY,IAAI,CAAC,WAAW,CAC5B,SAAU,IAAI,CAAC,SAAS,CACxB,WAAY,EAAQ,UAAU,CAC9B,mBAAoB,EAAQ,kBAAkB,AAChD,GAEM,EAAS,IAAI,EAAO,EAAQ,IAAI,CAAC,WAAW,CAAE,EAAQ,YAAY,EAExE,IAAI,CAAC,SAAS,CAAG,EACjB,IAAI,CAAC,OAAO,CAAG,EACf,IAAI,CAAC,OAAO,CAAG,EAEf,CAAQ,CAAC,EAAW,CAAG,IAAI,CAC3B,CAAM,CAAC,EAAW,CAAG,IAAI,CACzB,CAAM,CAAC,EAAW,CAAG,IAAI,CAEzB,EAAS,EAAE,CAAC,WAAY,GACxB,EAAS,EAAE,CAAC,QAAS,GACrB,EAAS,EAAE,CAAC,QAAS,GACrB,EAAS,EAAE,CAAC,UAAW,GACvB,EAAS,EAAE,CAAC,OAAQ,GACpB,EAAS,EAAE,CAAC,OAAQ,GAEpB,EAAO,OAAO,CAAG,EAKb,EAAO,UAAU,EAAE,EAAO,UAAU,CAAC,GACrC,EAAO,UAAU,EAAE,EAAO,UAAU,GAEpC,EAAK,MAAM,CAAG,GAAG,EAAO,OAAO,CAAC,GAEpC,EAAO,EAAE,CAAC,QAAS,GACnB,EAAO,EAAE,CAAC,OAAQ,GAClB,EAAO,EAAE,CAAC,MAAO,GACjB,EAAO,EAAE,CAAC,QAAS,GAEnB,IAAI,CAAC,WAAW,CAAG,EAAU,IAAI,CACjC,IAAI,CAAC,IAAI,CAAC,OACZ,CAOA,WAAY,CACV,GAAI,CAAC,IAAI,CAAC,OAAO,CAAE,CACjB,IAAI,CAAC,WAAW,CAAG,EAAU,MAAM,CACnC,IAAI,CAAC,IAAI,CAAC,QAAS,IAAI,CAAC,UAAU,CAAE,IAAI,CAAC,aAAa,EACtD,MACF,CAEI,IAAI,CAAC,WAAW,CAAC,EAAkB,aAAa,CAAC,EAAE,AACrD,IAAI,CAAC,WAAW,CAAC,EAAkB,aAAa,CAAC,CAAC,OAAO,GAG3D,IAAI,CAAC,SAAS,CAAC,kBAAkB,GACjC,IAAI,CAAC,WAAW,CAAG,EAAU,MAAM,CACnC,IAAI,CAAC,IAAI,CAAC,QAAS,IAAI,CAAC,UAAU,CAAE,IAAI,CAAC,aAAa,CACxD,CAsBA,MAAM,CAAI,CAAE,CAAI,CAAE,CAChB,GAAI,IAAI,CAAC,UAAU,GAAK,EAAU,MAAM,EAAE,AAC1C,GAAI,IAAI,CAAC,UAAU,GAAK,EAAU,UAAU,CAAE,YAE5C,EAAe,IAAI,CAAE,IAAI,CAAC,IAAI,CADlB,CACoB,6DAIlC,GAAI,IAAI,CAAC,UAAU,GAAK,EAAU,OAAO,CAAE,CAEvC,IAAI,CAAC,eAAe,GACnB,CAAD,GAAK,CAAC,mBAAmB,EAAI,IAAI,CAAC,SAAS,CAAC,cAAc,CAAC,YAAY,AAAZ,GAC3D,AACA,IAAI,CAAC,OAAO,CAAC,GAAG,GAGlB,MACF,CAEA,IAAI,CAAC,WAAW,CAAG,EAAU,OAAO,CACpC,IAAI,CAAC,OAAO,CAAC,KAAK,CAAC,EAAM,EAAM,CAAC,IAAI,CAAC,SAAS,CAAE,AAAC,KAK3C,IAEJ,CAFS,GAEL,CAAC,eAAe,EAAG,GAGrB,IAAI,CAAC,mBAAmB,EACxB,IAAI,CAAC,SAAS,CAAC,cAAc,CAAC,YAAY,AAAZ,EAC9B,CACA,IAAI,CAAC,OAAO,CAAC,GAAG,GAEpB,GAEA,EAAc,IAAI,EACpB,CAOA,OAAQ,CAEJ,IAAI,CAAC,UAAU,GAAK,EAAU,UAAU,EACxC,IAAI,CAAC,UAAU,GAAK,EAAU,MAAM,EACpC,CAIF,IAAI,CAAC,OAAO,EAAG,EACf,IAAI,CAAC,OAAO,CAAC,KAAK,GACpB,CAUA,KAAK,CAAI,CAAE,CAAI,CAAE,CAAE,CAAE,CACnB,GAAI,IAAI,CAAC,UAAU,GAAK,EAAU,UAAU,CAC1C,CAD4C,KACtC,AAAI,MAAM,mDAalB,EAVI,AAAgB,YAAY,OAArB,GACT,EAAK,EACL,EAAO,OAAO,GACW,YAAhB,AAA4B,OAArB,IAChB,EAAK,EACL,OAAO,GAGW,UAAhB,OAAO,IAAmB,EAAO,EAAK,QAAQ,EAAA,EAE9C,IAAI,CAAC,UAAU,GAAK,EAAU,IAAI,EAAE,AACtC,EAAe,IAAI,CAAE,EAAM,SAIhB,IAAT,IAAoB,EAAO,CAAC,IAAI,CAAC,SAAA,AAAS,EAC9C,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,GAAQ,EAAc,EAAM,GAChD,CAUA,KAAK,CAAI,CAAE,CAAI,CAAE,CAAE,CAAE,CACnB,GAAI,IAAI,CAAC,UAAU,GAAK,EAAU,UAAU,CAC1C,CAD4C,KAClC,AAAJ,MAAU,mDAalB,EAVoB,YAAhB,AAA4B,OAArB,GACT,EAAK,EACL,EAAO,OAAO,GACW,YAAhB,AAA4B,OAArB,IAChB,EAAK,EACL,OAAO,GAGW,UAAhB,OAAO,IAAmB,EAAO,EAAK,QAAQ,EAAA,EAE9C,IAAI,CAAC,UAAU,GAAK,EAAU,IAAI,EAAE,AACtC,EAAe,IAAI,CAAE,EAAM,SAIhB,IAAT,IAAoB,EAAO,CAAC,IAAI,CAAC,SAAS,AAAT,EACrC,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,GAAQ,EAAc,EAAM,GAChD,CAOA,QAAS,CAEL,IAAI,CAAC,UAAU,GAAK,EAAU,UAAU,EACxC,IAAI,CAAC,UAAU,GAAK,EAAU,MAAM,EACpC,CAIF,IAAI,CAAC,OAAO,EAAG,EACX,AAAC,IAAI,CAAC,SAAS,CAAC,cAAc,CAAC,SAAS,EAAE,IAAI,CAAC,OAAO,CAAC,MAAM,GACnE,CAiBA,KAAK,CAAI,CAAE,CAAO,CAAE,CAAE,CAAE,CACtB,GAAI,IAAI,CAAC,UAAU,GAAK,EAAU,UAAU,CAC1C,CAD4C,KACtC,AAAI,MAAM,oDAUlB,GAPuB,YAAY,AAA/B,OAAO,IACT,EAAK,EACL,EAAU,CAAC,GAGO,UAAhB,OAAO,IAAmB,EAAO,EAAK,QAAQ,EAAA,EAE9C,IAAI,CAAC,UAAU,GAAK,EAAU,IAAI,CAAE,YACtC,EAAe,IAAI,CAAE,EAAM,GAI7B,IAAM,EAAO,CACX,OAAwB,UAAhB,OAAO,EACf,KAAM,CAAC,IAAI,CAAC,SAAS,CACrB,UAAU,EACV,KAAK,EACL,GAAG,CAAO,AACZ,CAEI,CAAC,IAAI,CAAC,WAAW,CAAC,EAAkB,aAAa,CAAC,EAAE,CACtD,EAAK,QAAQ,EAAG,CAAA,EAGlB,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,GAAQ,EAAc,EAAM,EAChD,CAOA,WAAY,CACV,GAAI,IAAI,CAAC,UAAU,GAAK,EAAU,MAAM,EAAE,AAC1C,GAAI,IAAI,CAAC,UAAU,GAAK,EAAU,UAAU,CAAE,YAE5C,EAAe,IAAI,CAAE,IAAI,CAAC,IAAI,CADlB,CACoB,6DAI9B,IAAI,CAAC,OAAO,EAAE,CAChB,IAAI,CAAC,WAAW,CAAG,EAAU,OAAO,CACpC,IAAI,CAAC,OAAO,CAAC,OAAO,IAExB,CACF,CAwhBA,SAAS,EAAkB,CAAS,CAAE,CAAG,EACvC,EAAU,WAAW,CAAG,EAAU,OAAO,CAKzC,EAAU,aAAa,EAAG,EAC1B,EAAU,IAAI,CAAC,QAAS,GACxB,EAAU,SAAS,EACrB,CASA,SAAS,EAAW,CAAO,EAEzB,OADA,EAAQ,IAAI,CAAG,EAAQ,UAAU,CAC1B,EAAI,OAAO,CAAC,EACrB,CASA,SAAS,EAAW,CAAO,EAOzB,OANA,EAAQ,IAAI,MAAG,EAEX,AAAC,EAAQ,UAAU,EAA2B,IAAI,CAA3B,EAAQ,UAAU,GAC3C,EAAQ,UAAU,CAAG,EAAI,IAAI,CAAC,EAAQ,IAAI,EAAI,GAAK,EAAQ,IAAA,AAAI,EAG1D,EAAI,OAAO,CAAC,EACrB,CAWA,SAAS,EAAe,CAAS,CAAE,CAAM,CAAE,CAAO,EAChD,EAAU,WAAW,CAAG,EAAU,OAAO,CAEzC,IAAM,EAAM,AAAI,MAAM,GACtB,MAAM,iBAAiB,CAAC,EAAK,GAEzB,EAAO,SAAS,EAAE,AACpB,CAAM,CAAC,EAAS,EAAG,EACnB,EAAO,KAAK,GAER,EAAO,MAAM,EAAI,CAAC,EAAO,MAAM,CAAC,SAAS,EAAE,AAM7C,EAAO,MAAM,CAAC,OAAO,GAGvB,QAAQ,QAAQ,CAAC,EAAmB,EAAW,KAE/C,EAAO,OAAO,CAAC,GACf,EAAO,IAAI,CAAC,QAAS,EAAU,IAAI,CAAC,IAAI,CAAC,EAAW,UACpD,EAAO,IAAI,CAAC,QAAS,EAAU,SAAS,CAAC,IAAI,CAAC,IAElD,CAWA,SAAS,EAAe,CAAS,CAAE,CAAI,CAAE,CAAE,EACzC,GAAI,EAAM,CACR,IAAM,EAAS,EAAO,GAAQ,EAAK,IAAI,CAAG,EAAS,GAAM,MAAM,CAQ3D,EAAU,OAAO,CAAE,EAAU,OAAO,CAAC,cAAc,EAAI,EACtD,EAAU,eAAe,EAAI,CACpC,CAEA,GAAI,EAAI,CACN,IAAM,EAAM,AAAI,MACd,CAAC,kCAAkC,EAAE,EAAU,UAAU,CAAC,AACvD,CADwD,CACvD,EAAE,CAAW,CAAC,EAAU,UAAU,CAAC,CAAC,CAAC,CADmB,AAClB,EAE5C,CAFI,OAEI,QAAQ,CAAC,EAAI,EACvB,CACF,CASA,SAAS,EAAmB,CAAI,CAAE,CAAM,EACtC,IAAM,EAAY,IAAI,CAAC,EAAW,CAElC,EAAU,mBAAmB,EAAG,EAChC,EAAU,aAAa,CAAG,EAC1B,EAAU,UAAU,CAAG,OAEe,IAAlC,EAAU,KAAmC,EAA5B,CAAC,EAAW,GAEjC,EAAU,OAAO,CAAC,cAAc,CAAC,OAAQ,GACzC,QAAQ,QAAQ,CAAC,EAAQ,EAAU,OAAO,EAE7B,OAAT,EAAe,EAAU,KAAK,GAC7B,EAAU,KAAK,CAAC,EAAM,GAC7B,CAOA,SAAS,IACP,IAAM,EAAY,IAAI,CAAC,EAEnB,AAF8B,CAE7B,EAAU,QAAQ,EAAE,EAAU,OAAO,CAAC,MAAM,EACnD,CAQA,SAAS,EAAgB,CAAG,EAC1B,IAAM,EAAY,IAAI,CAAC,EAAW,MAEI,IAAlC,EAAU,KAAmC,EAA5B,CAAC,EAAW,GAC/B,EAAU,OAAO,CAAC,cAAc,CAAC,OAAQ,GAMzC,QAAQ,QAAQ,CAAC,EAAQ,EAAU,OAAO,EAE1C,EAAU,KAAK,CAAC,CAAG,CAAC,EAAY,GAG7B,EAAU,aAAa,EAAE,CAC5B,EAAU,aAAa,EAAG,EAC1B,EAAU,IAAI,CAAC,QAAS,GAE5B,CAOA,SAAS,IACP,IAAI,CAAC,EAAW,CAAC,SAAS,EAC5B,CASA,SAAS,EAAkB,CAAI,CAAE,CAAQ,EACvC,IAAI,CAAC,EAAW,CAAC,IAAI,CAAC,UAAW,EAAM,EACzC,CAQA,SAAS,EAAe,CAAI,EAC1B,IAAM,EAAY,IAAI,CAAC,EAAW,CAE9B,EAAU,SAAS,EAAE,EAAU,IAAI,CAAC,EAAM,CAAC,IAAI,CAAC,SAAS,CAAE,GAC/D,EAAU,IAAI,CAAC,OAAQ,EACzB,CAQA,SAAS,EAAe,CAAI,EAC1B,IAAI,CAAC,EAAW,CAAC,IAAI,CAAC,OAAQ,EAChC,CAQA,SAAS,EAAO,CAAM,EACpB,EAAO,MAAM,EACf,CAQA,SAAS,EAAc,CAAG,EACxB,IAAM,EAAY,IAAI,CAAC,EAAW,AAE9B,GAAU,UAAU,GAAK,EAAU,MAAM,EAAE,CAC3C,EAAU,UAAU,GAAK,EAAU,IAAI,EAAE,CAC3C,EAAU,WAAW,CAAG,EAAU,OAAO,CACzC,EAAc,IAQhB,IAAI,CAAC,OAAO,CAAC,GAAG,GAEX,EAAU,aAAa,EAAE,CAC5B,EAAU,aAAa,EAAG,EAC1B,EAAU,IAAI,CAAC,QAAS,IAE5B,CAQA,SAAS,EAAc,CAAS,EAC9B,EAAU,WAAW,CAAG,WACtB,EAAU,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,EAAU,OAAO,EAzuC/B,CA0uCjB,GAEJ,CAOA,AAnvC0B,SAmvCjB,IACP,IAQI,EARE,EAAY,IAAI,CAAC,EAAW,CAElC,IAAI,CAAC,cAAc,CAAC,QAAS,GAC7B,IAAI,CAAC,cAAc,CAAC,OAAQ,GAC5B,IAAI,CAAC,cAAc,CAAC,MAAO,GAE3B,EAAU,WAAW,CAAG,EAAU,OAAO,CActC,AAAD,IAAK,CAAC,cAAc,CAAC,UAAU,EAC9B,EAAD,AAAW,mBAAmB,EAC7B,EAAD,AAAW,SAAS,CAAC,cAAc,CAAC,YAAY,EAChD,AAAuC,MACvC,EADC,EAAQ,EAAU,OAAO,CAAC,IAAI,EAAA,CAAE,EAEjC,EAAU,SAAS,CAAC,KAAK,CAAC,GAG5B,EAAU,SAAS,CAAC,GAAG,GAEvB,IAAI,CAAC,EAAW,MAAG,EAEnB,aAAa,EAAU,WAAW,EAGhC,EAAU,SAAS,CAAC,cAAc,CAAC,QAAQ,EAC3C,EAAU,SAAS,CAAC,cAAc,CAAC,YAAY,CAE/C,CADA,CACU,SAAS,IAEnB,EAAU,SAAS,CAAC,EAAE,CAAC,QAAS,GAChC,EAAU,SAAS,CAAC,EAAE,CAAC,SAAU,GAErC,CAQA,SAAS,EAAa,CAAK,EACrB,AAAC,IAAI,CAAC,EAAW,CAAC,SAAS,CAAC,KAAK,CAAC,IACpC,IAD4C,AACxC,CAAC,KAAK,EAEd,CAOA,SAAS,IACP,IAAM,EAAY,IAAI,CAAC,EAAW,CAElC,EAAU,WAAW,CAAG,EAAU,OAAO,CACzC,EAAU,SAAS,CAAC,GAAG,GACvB,IAAI,CAAC,GAAG,EACV,CAOA,SAAS,IACP,IAAM,EAAY,IAAI,CAAC,EAAW,CAElC,IAAI,CAAC,cAAc,CAAC,QAAS,GAC7B,IAAI,CAAC,EAAE,CAAC,QAAS,GAEb,IACF,EAAU,KADG,MACQ,CAAG,EAAU,OAAO,CACzC,IAAI,CAAC,OAAO,GAEhB,CAp3BA,OAAO,cAAc,CAAC,EAAW,aAAc,CAC7C,YAAY,EACZ,MAAO,EAAY,OAAO,CAAC,aAC7B,GAMA,OAAO,cAAc,CAAC,EAAU,SAAS,CAAE,aAAc,CACvD,YAAY,EACZ,MAAO,EAAY,OAAO,CAAC,aAC7B,GAMA,OAAO,cAAc,CAAC,EAAW,OAAQ,CACvC,YAAY,EACZ,MAAO,EAAY,OAAO,CAAC,OAC7B,GAMA,OAAO,cAAc,CAAC,EAAU,SAAS,CAAE,OAAQ,CACjD,YAAY,EACZ,MAAO,EAAY,OAAO,CAAC,OAC7B,GAMA,OAAO,cAAc,CAAC,EAAW,UAAW,CAC1C,YAAY,EACZ,MAAO,EAAY,OAAO,CAAC,UAC7B,GAMA,OAAO,cAAc,CAAC,EAAU,SAAS,CAAE,UAAW,CACpD,YAAY,EACZ,MAAO,EAAY,OAAO,CAAC,UAC7B,GAMA,OAAO,cAAc,CAAC,EAAW,SAAU,CACzC,YAAY,EACZ,MAAO,EAAY,OAAO,CAAC,SAC7B,GAMA,OAAO,cAAc,CAAC,EAAU,SAAS,CAAE,SAAU,CACnD,YAAY,EACZ,MAAO,EAAY,OAAO,CAAC,SAC7B,GAEA,CACE,aACA,iBACA,aACA,WACA,WACA,aACA,MACD,CAAC,OAAO,CAAC,AAAC,IACT,OAAO,cAAc,CAAC,EAAU,SAAS,CAAE,EAAU,CAAE,YAAY,CAAK,EAC1E,GAMA,CAAC,OAAQ,QAAS,QAAS,UAAU,CAAC,OAAO,CAAC,AAAC,IAC7C,OAAO,cAAc,CAAC,EAAU,SAAS,CAAE,CAAC,EAAE,EAAE,EAAA,CAAQ,CAAE,CACxD,YAAY,EACZ,MACE,IAAK,IAAM,KAAY,IAAI,CAAC,SAAS,CAAC,GACpC,GAAI,CAAQ,CADiC,AAChC,EAAqB,CAAE,OAAO,CAAQ,CAAC,EAAU,CAGhE,OAAO,IACT,EACA,IAAI,CAAO,EACT,IAAK,IAAM,KAAY,IAAI,CAAC,SAAS,CAAC,GACpC,GAAI,CAAQ,CADiC,AAChC,EAAqB,CAAE,CAClC,IAAI,CAAC,cAAc,CAAC,EAAQ,GAC5B,KACF,CAGqB,YAAnB,AAA+B,OAAxB,GAEX,IAAI,CAAC,gBAAgB,CAAC,EAAQ,EAAS,CACrC,CAAC,EAAqB,EAAE,CAC1B,EACF,CACF,EACF,GAEA,EAAU,SAAS,CAAC,gBAAgB,CAAG,EACvC,EAAU,SAAS,CAAC,mBAAmB,CAAG,EAE1C,EAAO,OAAO,CAAG,gCCtmBX,EAAA,CAAA,CAAA,OACN,GAAM,CAAE,QAAM,CAAE,CAAA,EAAA,CAAA,CAAA,OAQhB,SAAS,EAAU,CAAM,EACvB,EAAO,IAAI,CAAC,QACd,CAOA,SAAS,IACH,CAAC,IAAI,CAAC,SAAS,EAAI,IAAI,CAAC,cAAc,CAAC,QAAQ,EAAE,AACnD,IAAI,CAAC,OAAO,EAEhB,CAQA,SAAS,EAAc,CAAG,EACxB,IAAI,CAAC,cAAc,CAAC,QAAS,GAC7B,IAAI,CAAC,OAAO,GACwB,AAAhC,GAAmC,KAA/B,CAAC,aAAa,CAAC,UAErB,IAAI,CAAC,IAAI,CAAC,QAAS,EAEvB,CAwHA,EAAO,OAAO,CA9Gd,EA8GiB,OA9GR,AAAsB,CAAE,CAAE,CAAO,EACxC,IAAI,GAAqB,EAEnB,EAAS,IAAI,EAAO,CACxB,GAAG,CAAO,CACV,aAAa,EACb,WAAW,EACX,YAAY,EACZ,mBAAoB,EACtB,GAkGA,OAhGA,EAAG,EAAE,CAAC,UAAW,SAAS,AAAQ,CAAG,CAAE,CAAQ,EAC7C,IAAM,EACJ,CAAC,GAAY,EAAO,cAAc,CAAC,UAAU,CAAG,EAAI,QAAQ,GAAK,CAE/D,CAAC,EAAO,IAAI,CAAC,IAAO,EAAG,KAAK,EAClC,GAEA,EAAG,IAAI,CAAC,QAAS,SAAS,AAAM,CAAG,EAC7B,EAAO,SAAS,EAAE,CAWtB,EAAqB,GACrB,EAAO,OAAO,CAAC,GACjB,GAEA,EAAG,IAAI,CAAC,QAAS,SAAS,EACpB,EAAO,SAAS,EAEpB,AAFsB,EAEf,IAAI,CAAC,KACd,GAEA,EAAO,QAAQ,CAAG,SAAU,CAAG,CAAE,CAAQ,EACvC,GAAI,EAAG,UAAU,GAAK,EAAG,MAAM,CAAE,CAC/B,EAAS,GACT,QAAQ,QAAQ,CAAC,EAAW,GAC5B,MACF,CAEA,IAAI,GAAS,EAEb,EAAG,IAAI,CAAC,QAAS,SAAS,AAAM,CAAG,EACjC,GAAS,EACT,EAAS,EACX,GAEA,EAAG,IAAI,CAAC,QAAS,SAAS,EACpB,AAAC,GAAQ,EAAS,GACtB,QAAQ,QAAQ,CAAC,EAAW,EAC9B,GAEI,GAAoB,EAAG,SAAS,EACtC,EAEA,EAAO,MAAM,CAAG,SAAU,CAAQ,EAChC,AAAI,EAAG,UAAU,GAAK,EAAG,UAAU,CACjC,CADmC,CAChC,IAAI,CAAC,OAAQ,SAAS,EACvB,EAAO,MAAM,CAAC,EAChB,GAQiB,MAAM,CAArB,EAAG,OAAO,GAEV,EAAG,OAAO,CAAC,cAAc,CAAC,QAAQ,EAAE,AACtC,IACI,EAAO,cAAc,CAAC,UAAU,EAAE,EAAO,OAAO,KAEpD,EAAG,OAAO,CAAC,IAAI,CAAC,SAAU,SAAS,EAIjC,GACF,GACA,EAAG,KAAK,IAEZ,EAEA,EAAO,KAAK,CAAG,WACT,EAAG,QAAQ,EAAE,EAAG,MAAM,EAC5B,EAEA,EAAO,MAAM,CAAG,SAAU,CAAK,CAAE,CAAQ,CAAE,CAAQ,EAC7C,AAAJ,EAAO,UAAU,GAAK,EAAG,UAAU,CACjC,CADmC,CAChC,IAAI,CAAC,OAAQ,SAAS,EACvB,EAAO,MAAM,CAAC,EAAO,EAAU,EACjC,GAIF,EAAG,IAAI,CAAC,EAAO,EACjB,EAEA,EAAO,EAAE,CAAC,MAAO,GACjB,EAAO,EAAE,CAAC,QAAS,GACZ,CACT,gCC5JA,GAAM,YAAE,CAAU,CAAE,CAAA,EAAA,CAAA,CAAA,OA2DpB,EAAO,OAAO,CAAG,CAAE,MAlDnB,SAAS,AAAM,CAAM,EACnB,IAAM,EAAY,IAAI,IAClB,EAAQ,CAAC,EACT,EAAM,CAAC,EACP,EAAI,EAER,IAAK,CAAG,EAAI,EAAO,MAAM,CAAE,IAAK,CAC9B,IAAM,EAAO,EAAO,UAAU,CAAC,GAE/B,GAAY,CAAC,IAAT,GAAmC,GAAG,CAAxB,CAAU,CAAC,EAAK,CAClB,CAAC,IAAX,IAAc,GAAQ,OACrB,GACC,IAAN,CACA,GAAC,AAAS,KAAK,GAAsB,IAAf,AAAM,CAAS,CAAI,CAE7B,CAAC,CADb,GACI,GAAwB,CAAC,IAAX,IAAc,GAAM,OACjC,GAAa,KAAT,AAAc,EAAW,CAClC,GAAI,AAAU,CADgB,AACf,GAAG,GAChB,MAAU,AAAJ,YAAgB,CAAC,8BAA8B,EAAE,EAAA,CAAG,EAGhD,CAAC,IAAT,IAAY,GAAM,EAEtB,IAAM,EAAW,EAAO,KAAK,CAAC,EAAO,GAErC,GAAI,EAAU,GAAG,CAAC,GAChB,MAAM,AAAI,EADiB,UACL,CAAC,KAAK,EAAE,EAAS,2BAA2B,CAAC,EAGrE,EAAU,GAAG,CAAC,GACd,EAAQ,EAAM,CAAC,CACjB,MACE,CADK,KACK,AAAJ,YAAgB,CAAC,8BAA8B,EAAE,EAAA,CAAG,CAE9D,CAEA,GAAc,CAAC,IAAX,GAAwB,CAAC,GAAG,CAAZ,EAClB,MAAM,AAAI,YAAY,2BAGxB,IAAM,EAAW,EAAO,KAAK,CAAC,EAAO,GAErC,GAAI,EAAU,GAAG,CAAC,GAChB,MAAM,AAAI,EADiB,UACL,CAAC,KAAK,EAAE,EAAS,2BAA2B,CAAC,EAIrE,OADA,EAAU,GAAG,CAAC,GACP,CACT,CAEyB,gCCzDzB,IAAM,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,QAAE,CAAM,CAAE,CAAA,EAAA,CAAA,CAAA,OACV,YAAE,CAAU,CAAE,CAAA,EAAA,CAAA,CAAA,OAEd,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,MAAE,CAAI,YAAE,CAAU,CAAE,CAAA,EAAA,CAAA,CAAA,OAEpB,EAAW,wBAscjB,SAAS,EAAU,CAAM,EACvB,EAAO,MAAM,GAAG,AAChB,EAAO,IAAI,CAAC,QACd,CAOA,SAAS,IACP,IAAI,CAAC,OAAO,EACd,CAWA,SAAS,EAAe,CAAM,CAAE,CAAI,CAAE,CAAO,CAAE,CAAO,EASpD,EAAU,GAAW,EAAK,YAAY,CAAC,EAAK,CAC5C,EAAU,CACR,WAAY,QACZ,eAAgB,YAChB,iBAAkB,OAAO,UAAU,CAAC,GACpC,GAAG,CAAO,AACZ,EAEA,EAAO,IAAI,CAAC,SAAU,EAAO,OAAO,EAEpC,EAAO,GAAG,CACR,CAAC,SAAS,EAAE,EAAK,CAAC,EAAE,EAAK,YAAY,CAAC,EAAK,CAAC;AAAI,CAAC,CAC/C,OAAO,IAAI,CAAC,GACT,GAAG,CAAC,AAAC,GAAM,CAAA,EAAG,EAAE,EAAE,EAAE,CAAO,CAAC,EAAE,CAAA,CAAE,EAChC,IAAI,CAAC,QACR,WACA,EAEN,CAcA,SAAS,EACP,CAAM,CACN,CAAG,CACH,CAAM,CACN,CAAI,CACJ,CAAO,CACP,CAAO,EAEP,GAAI,EAAO,aAAa,CAAC,iBAAkB,CACzC,IAAM,EAAM,AAAI,MAAM,GACtB,MAAM,iBAAiB,CAAC,EAAK,GAE7B,EAAO,IAAI,CAAC,gBAAiB,EAAK,EAAQ,EAC5C,MACE,CADK,CACU,EAAQ,EAAM,EAAS,EAE1C,CA5GA,EAAO,OAAO,CA/Zd,EA+ZiB,IA/ZX,QAAwB,EAgC5B,YAAY,CAAO,CAAE,CAAQ,CAAE,CAsB7B,GArBA,KAAK,GAsBc,MAAhB,CApBH,EAAU,CACR,wBAAwB,EACxB,UAAU,EACV,WAAY,MAAM,IAClB,GADyB,iBACL,EACpB,mBAAmB,EACnB,gBAAiB,KACjB,eAAgB,GAChB,aAAc,KACd,UAAU,EACV,QAAS,KACT,OAAQ,KACR,KAAM,KACN,KAAM,KACN,KAAM,eACN,EACA,GAAG,CAAO,CACZ,EAGW,IAAI,EAAY,CAAC,EAAQ,MAAM,EAAI,CAAC,EAAQ,QAAQ,EAC5C,MAAhB,EAAQ,AAAgB,IAAZ,GAAa,EAAQ,MAAM,EAAI,EAAQ,QAAA,AAAQ,GAC3D,EAAQ,MAAM,EAAI,EAAQ,QAAQ,CAEnC,CADA,KACM,AAAI,UACR,qEACE,gBAwBN,GApBoB,MAAhB,AAAsB,EAAd,IAAI,EACd,IAAI,CAAC,OAAO,CAAG,EAAK,YAAY,CAAC,CAAC,EAAK,KACrC,IAAM,EAAO,EAAK,YAAY,CAAC,IAAI,CAEnC,EAAI,SAAS,CAAC,IAAK,CACjB,iBAAkB,EAAK,MAAM,CAC7B,eAAgB,YAClB,GACA,EAAI,GAAG,CAAC,EACV,GACA,IAAI,CAAC,OAAO,CAAC,MAAM,CACjB,EAAQ,IAAI,CACZ,EAAQ,IAAI,CACZ,EAAQ,OAAO,CACf,IAEO,EAAQ,MAAM,EAAE,CACzB,IAAI,CAAC,OAAO,CAAG,EAAQ,MAAA,AAAM,EAG3B,IAAI,CAAC,OAAO,CAAE,CAChB,MAAM,EAAiB,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAE,cAE5C,IAAI,CAAC,gBAAgB,CAAG,AAmV9B,SAAS,AAAa,CAAM,CAAE,CAAG,EAC/B,IAAK,IAAM,KAAS,OAAO,IAAI,CAAC,GAAM,EAAO,EAAE,CAAC,EAAO,CAAG,CAAC,EAAM,EAEjE,OAAO,SAAS,EACd,IAAK,IAAM,KAAS,OAAO,IAAI,CAAC,GAC9B,EADoC,AAC7B,cAAc,CAAC,EAAO,CAAG,CAAC,EAAM,CAE3C,CACF,EA3V2C,IAAI,CAAC,OAAO,CAAE,CACjD,UAAW,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAE,aAChC,MAAO,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAE,SAC5B,QAAS,CAAC,EAAK,EAAQ,KACrB,IAAI,CAAC,aAAa,CAAC,EAAK,EAAQ,EAAM,EACxC,CACF,EACF,EAEkC,IAA9B,EAAQ,iBAAiB,GAAW,EAAQ,iBAAiB,CAAG,EAAC,EACjE,EAAQ,cAAc,EAAE,CAC1B,IAAI,CAAC,OAAO,CAAG,IAAI,IACnB,IAAI,CAAC,gBAAgB,EAAG,GAG1B,IAAI,CAAC,OAAO,CAAG,EACf,IAAI,CAAC,MAAM,EACb,CADgB,AAYhB,SAAU,CACR,GAAI,IAAI,CAAC,OAAO,CAAC,QAAQ,CACvB,CADyB,KACnB,AAAI,MAAM,qDAGlB,AAAK,IAAD,AAAK,CAAC,OAAO,CACV,CADY,GACR,CAAC,OAAO,CAAC,OAAO,GADD,IAE5B,CASA,MAAM,CAAE,CAAE,CACR,GA5IW,IA4IP,IAAI,CAAC,MAAM,CAAa,CACtB,GADc,AAEhB,CADM,GACF,CAAC,IAAI,CAAC,QAAS,KACjB,EAAG,AAAI,MAAM,6BACf,GAGF,QAAQ,QAAQ,CAAC,EAAW,IAAI,EAChC,MACF,CAIA,GAFI,GAAI,IAAI,CAAC,IAAI,CAAC,QAAS,GAEvB,QAAI,CAAC,MAAM,CAGf,GAFA,CADoB,GAChB,CAAC,KADwB,CAClB,CA3JC,EA6JR,AAFU,IAEN,CAAC,OAAO,CAAC,QAAQ,EAAI,IAAI,CAAC,OAAO,CAAC,MAAM,CAC1C,CAD4C,GACxC,CAAC,OAAO,EAAE,CAChB,IAAI,CAAC,gBAAgB,GACrB,IAAI,CAAC,gBAAgB,CAAG,IAAI,CAAC,OAAO,CAAG,MAGrC,IAAI,CAAC,OAAO,EAAE,AACX,IAAI,CAAC,OAAO,CAAC,IAAI,CAGpB,CAHsB,GAGlB,CAAC,gBAAgB,EAAG,EAFxB,QAAQ,QAAQ,CAAC,EAAW,IAAI,MAO/B,CACL,IAAM,EAAS,IAAI,CAAC,OAAO,CAE3B,IAAI,CAAC,gBAAgB,GACrB,IAAI,CAAC,gBAAgB,CAAG,IAAI,CAAC,OAAO,CAAG,KAMvC,EAAO,KAAK,CAAC,KACX,EAAU,IAAI,CAChB,EACF,CACF,CASA,aAAa,CAAG,CAAE,CAChB,GAAI,IAAI,CAAC,OAAO,CAAC,IAAI,CAAE,CACrB,IAAM,EAAQ,EAAI,GAAG,CAAC,OAAO,CAAC,KAG9B,GAAI,CAFuB,CAAC,IAAX,EAAe,EAAI,GAAG,CAAC,KAAK,CAAC,EAAG,GAAS,EAAI,GAAG,AAAH,IAE7C,IAAI,CAAC,OAAO,CAAC,IAAI,CAAE,OAAO,CAC7C,CAEA,OAAO,CACT,CAWA,cAAc,CAAG,CAAE,CAAM,CAAE,CAAI,CAAE,CAAE,CAAE,CACnC,EAAO,EAAE,CAAC,QAAS,GAEnB,IAAM,EAAM,EAAI,OAAO,CAAC,oBAAoB,CACtC,EAAU,EAAI,OAAO,CAAC,OAAO,CAC7B,EAAU,CAAC,EAAI,OAAO,CAAC,wBAAwB,CAErD,GAAmB,QAAf,EAAI,MAAM,CAAY,YAExB,EAAkC,IAAI,CAAE,EAAK,EAAQ,IADrC,CAC0C,sBAI5D,GAAI,AAAY,YAAuC,cAA1B,EAAQ,WAAW,GAAoB,YAElE,EAAkC,IAAI,CAAE,EAAK,EAAQ,IADrC,CAC0C,yBAI5D,QAAY,IAAR,GAAqB,CAAC,EAAS,IAAI,CAAC,GAAM,YAE5C,EAAkC,IAAI,CAAE,EAAK,EAAQ,IADrC,CAC0C,8CAI5D,GAAgB,KAAZ,GAA8B,IAAZ,EAAe,YAEnC,EAAkC,IAAI,CAAE,EAAK,EAAQ,IADrC,CAC0C,iDAAS,CACjE,wBAAyB,OAC3B,GAIF,GAAI,CAAC,IAAI,CAAC,YAAY,CAAC,GAAM,YAC3B,EAAe,EAAQ,KAIzB,IAAM,EAAuB,EAAI,OAAO,CAAC,yBAAyB,CAC9D,EAAY,IAAI,IAEpB,QAA6B,IAAzB,EACF,GAAI,CACF,CAFoC,CAExB,EAAY,KAAK,CAAC,EAChC,CAAE,MAAO,EAAK,CAEZ,EAAkC,IAAI,CAAE,EAAK,EAAQ,IADrC,CAC0C,wCAC1D,MACF,CAGF,IAAM,EAAyB,EAAI,OAAO,CAAC,2BAA2B,CAChE,EAAa,CAAC,EAEpB,GACE,IAAI,CAAC,OAAO,CAAC,iBAAiB,OACH,IAA3B,EACA,CACA,IAAM,EAAoB,IAAI,EAC5B,IAAI,CAAC,OAAO,CAAC,iBAAiB,EAC9B,EACA,IAAI,CAAC,OAAO,CAAC,UAAU,EAGzB,GAAI,CACF,IAAM,EAAS,EAAU,KAAK,CAAC,GAE3B,CAAM,CAAC,EAAkB,aAAa,CAAC,EAAE,CAC3C,EAAkB,MAAM,CAAC,CAAM,CAAC,EAAkB,aAAa,CAAC,EAChE,CAAU,CAAC,EAAkB,aAAa,CAAC,CAAG,EAElD,CAAE,MAAO,EAAK,CAGZ,EAAkC,IAAI,CAAE,EAAK,EAAQ,IADnD,CACwD,0DAC1D,MACF,CACF,CAKA,GAAI,IAAI,CAAC,OAAO,CAAC,YAAY,CAAE,CAC7B,IAAM,EAAO,CACX,OACE,EAAI,OAAO,CAAC,CAAA,EAAe,IAAZ,EAAgB,uBAAyB,SAAA,CAAU,CAAC,CACrE,OAAQ,CAAC,CAAC,CAAC,EAAI,MAAM,CAAC,UAAU,EAAI,EAAI,MAAM,CAAC,SAAA,AAAS,MACxD,CACF,EAEA,GAAyC,IAArC,IAAI,CAAC,OAAO,CAAC,YAAY,CAAC,MAAM,CAAQ,YAC1C,IAAI,CAAC,OAAO,CAAC,YAAY,CAAC,EAAM,CAAC,EAAU,EAAM,EAAS,KACxD,GAAI,CAAC,EACH,OAAO,CADM,CACS,EAAQ,GAAQ,IAAK,EAAS,GAGtD,IAAI,CAAC,eAAe,CAClB,EACA,EACA,EACA,EACA,EACA,EACA,EAEJ,GAIF,GAAI,CAAC,IAAI,CAAC,OAAO,CAAC,YAAY,CAAC,GAAO,OAAO,EAAe,EAAQ,IACtE,CAEA,IAAI,CAAC,eAAe,CAAC,EAAY,EAAK,EAAW,EAAK,EAAQ,EAAM,EACtE,CAeA,gBAAgB,CAAU,CAAE,CAAG,CAAE,CAAS,CAAE,CAAG,CAAE,CAAM,CAAE,CAAI,CAAE,CAAE,CAAE,CAIjE,GAAI,CAAC,EAAO,QAAQ,EAAI,CAAC,EAAO,QAAQ,CAAE,OAAO,EAAO,OAAO,GAE/D,GAAI,CAAM,CAAC,EAAW,CACpB,CADsB,KAChB,AAAI,MACR,oEACE,yCAIN,GAAI,IAAI,CAAC,MAAM,CArWH,EAqWM,AAAS,OAAO,EAAe,EAAQ,KAEzD,IAAM,EAAS,EAAW,QACvB,MAAM,CAAC,EAAM,GACb,MAAM,CAAC,UAEJ,EAAU,CACd,mCACA,qBACA,sBACA,CAAC,sBAAsB,EAAE,EAAA,CAAQ,CAClC,CAEK,EAAK,IAAI,IAAI,CAAC,OAAO,CAAC,SAAS,CAAC,UAAM,EAAW,IAAI,CAAC,OAAO,EAEnE,GAAI,EAAU,IAAI,CAAE,CAIlB,IAAM,EAAW,IAAI,CAAC,OAAO,CAAC,eAAe,CACzC,IAAI,CAAC,OAAO,CAAC,eAAe,CAAC,EAAW,GACxC,EAAU,MAAM,GAAG,IAAI,GAAG,KAAK,CAE/B,IACF,EAAQ,IADI,AACA,CAAC,CAAC,wBAAwB,EAAE,EAAA,CAAU,EAClD,EAAG,SAAS,CAAG,EAEnB,CAEA,GAAI,CAAU,CAAC,EAAkB,aAAa,CAAC,CAAE,CAC/C,IAAM,EAAS,CAAU,CAAC,EAAkB,aAAa,CAAC,CAAC,MAAM,CAC3D,EAAQ,EAAU,MAAM,CAAC,CAC7B,CAAC,EAAkB,aAAa,CAAC,CAAE,CAAC,EAAO,AAC7C,GACA,EAAQ,IAAI,CAAC,CAAC,0BAA0B,EAAE,EAAA,CAAO,EACjD,EAAG,WAAW,CAAG,CACnB,CAKA,IAAI,CAAC,IAAI,CAAC,UAAW,EAAS,GAE9B,EAAO,KAAK,CAAC,EAAQ,MAAM,CAAC,QAAQ,IAAI,CAAC,SACzC,EAAO,cAAc,CAAC,QAAS,GAE/B,EAAG,SAAS,CAAC,EAAQ,EAAM,CACzB,uBAAwB,IAAI,CAAC,OAAO,CAAC,sBAAsB,CAC3D,WAAY,IAAI,CAAC,OAAO,CAAC,UAAU,CACnC,mBAAoB,IAAI,CAAC,OAAO,CAAC,kBAAkB,AACrD,GAEI,IAAI,CAAC,OAAO,EAAE,CAChB,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,GACjB,EAAG,EAAE,CAAC,QAAS,KACb,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC,GAEhB,IAAI,CAAC,gBAAgB,EAAI,CAAC,IAAI,CAAC,OAAO,CAAC,IAAI,EAAE,AAC/C,QAAQ,QAAQ,CAAC,EAAW,IAAI,CAEpC,IAGF,EAAG,EAAI,EACT,CACF,gCCvbAA,EAAOC,OAAO,CACZC,EAAQ,CAAA,CAAA,IAAA,GACRC,QAAQ,CAAC,YAAY,CAAEC,6BAA6B,+BCFF,OAAA,cAAA,CAAA,EAAA,aAAA,oCAC3CC,0BAAAA,qCAAAA,EAAAA,uBAAuB,YAAQ,CAAA,CAAA,IAAA,wFCuBnCI,EAKAI,EAQAD,EAmCAO,EAIAH,EAQAV,IAWAS,EAIAR,AAtEAM,EALAJ,AAoDAO,AA2BAC,GA/BAE,CAnCAP,AA0DAG,CAXAT,EA8EHA,YA3DGW,CA2DU,CAAA,EA/DVV,gBA+DHD,GAEAC,yBAAyB,CAAA,kBAAzBA,GATAC,cAAc,CAAA,kBAAdA,GACAC,kBAAkB,CAAA,kBAAlBA,GARWC,gBAAgB,CAAA,kBAAhBA,GAkBXC,cAAc,CAAA,kBAAdA,GARAC,kBAAkB,CAAA,kBAAlBA,GADAC,cAAc,CAAA,kBAAdA,GA9BWC,wBAAwB,CAAA,kBAAxBA,GAoCXC,QAAQ,CAAA,kBAARA,GAHAC,UAAU,CAAA,kBAAVA,GAKAC,mBAAmB,CAAA,kBAAnBA,GAJAC,UAAU,CAAA,kBAAVA,GAFAC,eAAe,CAAA,kBAAfA,uEAtJF,IAAKX,IAAAA,EAAAA,GAAAA,CAAAA,OAAAA,CAAAA,UAAAA,GAAAA,8eAAAA,GAeAC,MAAAA,GAAAA,CAAAA,WAAAA,WAAAA,GAAAA,kGAAAA,GAKAI,MAAAA,GAAAA,CAAAA,OAAAA,WAAAA,GAAAA,uPAAAA,GAQAD,MAAAA,GAAAA,CAAAA,WAAAA,WAAAA,GAAAA,04CAAAA,GAmCAO,MAAAA,GAAAA,CAAAA,QAAAA,WAAAA,GAAAA,mBAAAA,GAIAH,MAAAA,GAAAA,CAAAA,GAAAA,WAAAA,GAAAA,yMAAAA,GAQAV,MAAAA,GAAAA,CAAAA,MAAAA,WAAAA,GAAAA,yJAAAA,GAOAY,IAAAA,EAAAA,GAAAA,CAAAA,GAAAA,CAAAA,UAAAA,GAAAA,qBAAAA,GAIAH,MAAAA,GAAAA,CAAAA,CAAAA,WAAAA,GAAAA,iBAAAA,GAIAR,MAAAA,GAAAA,CAAAA,kBAAAA,WAAAA,GAAAA,iBAAAA,GAIAU,MAAAA,GAAAA,CAAAA,YAAAA,WAAAA,GAAAA,mFAAAA,GAKAN,IAAAA,EAAAA,GAAAA,CAAAA,OAAAA,CAAAA,UAAAA,GAAAA,WAAAA,GAmBE,IAAMG,EAA2B,2dAiBvC,CAIYJ,EAAmB,kHAI/B,+BClJM,SAASU,EACdC,CAAuB,EAEvB,OACc,OAAZA,GACmB,UAAnB,OAAOA,GACP,SAAUA,GACV,AAAwB,mBAAjBA,EAAQC,IAEnB,AAFuB,CARtB,OAAA,cAAA,CAAA,EAAA,aAAA,oCACeF,aAAAA,qCAAAA,uCCSZQ,4DAuBSL,YAAY,CAAA,kBAAZA,GAgbuBC,QAAQ,CAAA,kBAARA,GAAhBC,cAAc,CAAA,kBAAdA,GAAXC,SAAS,CAAA,kBAATA,GAvaOC,cAAc,CAAA,kBAAdA,+EA5C2C,CAAA,CAAA,IAAA,OAUhC,CAAA,CAAA,IAAA,GAczB,GAAI,CACFC,EAAM1B,EAAQ,CAAA,CAAA,IAAA,EAChB,CAAE,MAAO8B,EAAK,CACZJ,EACE1B,EAAQ,CAAA,CAAA,IAAA,EACZ,CAGF,GAAM,SAAE+B,CAAO,aAAEC,CAAW,OAAEC,CAAK,gBAAEV,CAAc,UAAED,CAAQ,cAAEY,CAAY,CAAE,CAC3ER,CAEK,OAAML,UAAqBc,MAChCC,YACkBC,CAAgB,CAChBC,CAAyB,CACzC,CACA,KAAK,GAAA,IAAA,CAHWD,MAAAA,CAAAA,EAAAA,IAAAA,CACAC,MAAAA,CAAAA,CAGlB,CACF,CAEO,SAASb,EAAec,CAAc,QAC3C,AAAqB,UAAjB,OAAOA,GAAgC,MAAM,CAAhBA,GAC1BA,GADiD,UAChClB,CAC1B,CAEA,IAAMmB,EAAqB,CAACC,EAAYF,KAClCd,EAAec,IAAUA,EAAMF,MAAM,CACvCI,CADyC,CACpCC,YAAY,CAAC,eAAe,IAE7BH,IACFE,EAAKE,CADI,cACW,CAACJ,GACrBE,EAAKC,YAAY,CAAC,aAAcH,EAAMK,IAAI,GAE5CH,EAAKI,SAAS,CAAC,CAAEC,KAAMvB,EAAewB,KAAK,CAAEC,OAAO,CAAET,MAAAA,EAAAA,KAAAA,EAAAA,EAAOS,OAAO,AAAC,IAEvEP,EAAKQ,GAAG,EACV,EA4GMC,EAA0B,IAAIC,IAI9BC,EAAgB1B,EAAI2B,gBAAgB,CAAC,mBACvCC,EAAa,EAQXE,EAA+D,CACnEC,IAAIC,CAAO,CAAEC,CAAG,CAAEC,CAAK,EACrBF,EAAQG,IAAI,CAAC,KACXF,QACAC,CACF,EACF,CACF,EAiRMpC,GACE6F,EAAS,IAhRjB,AAgRqBvD,GADF,CAAA,EA/QbA,EAMIC,mBAA4B,CAClC,OAAO9B,EAAMT,SAAS,CAAC,UAAW,QACpC,CAEOwC,YAAyB,CAC9B,OAAOjC,CACT,CAEOkC,yBAAkD,CACvD,IAAMC,EAAgBnC,EAAQoC,MAAM,GAC9BC,EAAkC,EAAE,CAE1C,OADApC,EAAYqC,MAAM,CAACH,EAAeE,EAASZ,GACpCY,CACT,CAEOE,oBAAuC,CAC5C,OAAOrC,EAAMsC,OAAO,CAACxC,MAAAA,EAAAA,KAAAA,EAAAA,EAASoC,MAAM,GACtC,CAEOK,sBACLd,CAAU,CACVe,CAAW,CACXC,CAAyB,CACtB,CACH,IAAMR,EAAgBnC,EAAQoC,MAAM,GACpC,GAAIlC,EAAM0C,cAAc,CAACT,GAEvB,OAAOO,IAET,EAJyC,EAInCG,EAAgB5C,EAAY6C,OAAO,CAACX,EAAeR,EAASgB,GAClE,OAAO3C,EAAQ+C,IAAI,CAACF,EAAeH,EACrC,CAsBOxC,MAAS,GAAG8C,CAAgB,CAAE,KAwCxB9C,EAvCX,GAAM,CAAC+C,EAAMC,EAAaC,EAAU,CAAGH,EAGjC,IACJN,CAAE,SACFU,CAAO,CACR,CAIwB,YAAvB,OAAOF,EACH,CACER,GAAIQ,EACJE,QAAS,CAAC,CACZ,EACA,CACEV,GAAIS,EACJC,QAAS,CAAE,GAAGF,CAAW,AAAC,CAC5B,EAEAG,EAAWD,EAAQC,QAAQ,EAAIJ,EAErC,GACG,CAACpE,EAAAA,wBAAwB,CAACyE,QAAQ,CAACL,IACA,MAAlCrD,QAAQC,GAAG,CAAC0D,iBAAiB,EAC/BH,EAAQI,QAAQ,CAEhB,CADA,MACOd,IAIT,IAAIe,EAAc,IAAI,CAACb,cAAc,CACnCQ,CAAAA,MAAAA,EAAAA,KAAAA,EAAAA,EAASM,UAAU,AAAVA,GAAc,IAAI,CAACnB,kBAAkB,IAE5CoB,GAAa,EAEZF,GAGE,AAAyBA,OAArBvD,EAAAA,CAHO,CAGD0C,cAAc,CAACa,EAAAA,CAAAA,CAAAA,KAAAA,EAArBvD,EAAmC0D,QAAAA,AAAQ,EAAE,EACtDD,GAAa,CAAA,GAHbF,EAAczD,CAAAA,MAAAA,EAAAA,KAAAA,EAAAA,EAASoC,MAAM,EAAA,CAAA,EAAMjC,EACnCwD,GAAa,GAKf,IAAME,EAvHctC,IA+HpB,GAReC,IAEf4B,EAAQU,UAAU,CAAG,CACnB,iBAAkBT,EAClB,iBAAkBJ,EAClB,GAAGG,EAAQU,UACb,AADuB,EAGhB9D,EAAQ+C,IAAI,CAACU,EAAYM,QAAQ,CAAC1C,EAAewC,GAAS,IAC/D,IAAI,CAAC7B,iBAAiB,GAAGgC,eAAe,CACtCX,EACAD,EACA,AAAC1C,IACC,IAAMuD,EACJ,gBAAiBC,YAAc,YAAaC,YACxCD,WAAWC,WAAW,CAACC,GAAG,QAC1BC,EAEAC,EAAY,KAChBnD,EAAwBoD,MAAM,CAACV,GAE7BI,GACArE,QAAQC,GAAG,CAAC2E,4BAA4B,EACxC/F,EAAAA,gBAAgB,CAAC6E,QAAQ,CAACL,GAAS,KACnC,AACAkB,YAAYM,OAAO,CACjB,CAAA,EAAG7E,QAAQC,GAAG,CAAC2E,4BAA4B,CAAC,MAAM,EAChDvB,CAAAA,EAAKyB,KAAK,CAAC,KAAKC,GAAG,IAAM,EAAA,CAAC,CAC1BC,OAAO,CACP,SACA,AAACC,GAAkB,IAAMA,EAAMC,WAAW,IAAA,CACzC,CACH,CACEC,MAAOd,EACP/C,IAAKiD,YAAYC,GAAG,EACtB,EAGN,EAEIT,GACFxC,EAAwBO,GAAG,CACzBmC,EACA,CAHY,GAGRzC,IACF4D,OAAO3C,OAAO,CAACe,EAAQU,UAAU,EAAI,CAAC,KAO5C,GAAI,CACF,GAAIpB,EAAGuC,MAAM,CAAG,EACd,CADiB,MACVvC,EAAGhC,EAAM,AAACX,GAAQU,EAAmBC,EAAMX,IAGpD,IAAMQ,EAASmC,EAAGhC,GAClB,GAAIvB,CAAAA,EAAAA,EAAAA,UAAAA,AAAU,EAACoB,GAEb,MAFsB,CAEfA,EACJlB,IAAI,CAAC,AAAC6F,IACLxE,EAAKQ,GAAG,GAGDgE,IAERC,KAAK,CAAC,AAACpF,IAEN,MADAU,EAAmBC,EAAMX,GACnBA,CACR,GACCqF,OAAO,CAACd,GAMb,OAJE5D,EAAKQ,GAAG,GACRoD,IAGK/D,CACT,CAAE,MAAOR,EAAU,CAGjB,MAFAU,EAAmBC,EAAMX,GACzBuE,IACMvE,CACR,CACF,GAGN,CAaOsF,KAAK,GAAGrC,CAAgB,CAAE,CAC/B,IAAMsC,EAAS,IAAI,CACb,CAACzE,EAAMuC,EAASV,EAAG,CACP,IAAhBM,EAAKiC,MAAM,CAASjC,EAAO,CAACA,CAAI,CAAC,EAAE,CAAE,CAAC,EAAGA,CAAI,CAAC,EAAE,CAAC,QAGjD,AADF,AACGnE,EAAAA,wBAAwB,CAACyE,QAAQ,CAACzC,IACD,KAClC,CADAjB,QAAQC,GAAG,CAAC0D,iBAAiB,CAKxB,WACL,IAAIgC,EAAanC,EACS,YAAtB,OAAOmC,GAA2C,YAAd,AAA0B,OAAnB7C,IAC7C6C,EAAaA,EAAWC,KAAK,CAAC,IAAI,CAAEC,UAAAA,EAGtC,IAAMC,EAAYD,UAAUR,MAAM,CAAG,EAC/BU,EAAKF,SAAS,CAACC,EAAU,CAE/B,GAAkB,YAAd,OAAOC,EAWT,OAAOL,EAAOpF,KAAK,CAACW,EAAM0E,EAAY,IAAM7C,EAAG8C,KAAK,CAAC,IAAI,CAAEC,WAX/B,EAC5B,IAAMG,EAAeN,EAAOrD,UAAU,GAAG4D,IAAI,CAAC7F,EAAQoC,MAAM,GAAIuD,GAChE,OAAOL,EAAOpF,KAAK,CAACW,EAAM0E,EAAY,CAACO,EAAOC,KAC5CN,SAAS,CAACC,EAAU,CAAG,SAAU3F,CAAQ,EAEvC,OADAgG,MAAAA,CAAAA,EAAAA,EAAOhG,CAAPgG,EACOH,EAAaJ,KAAK,CAAC,IAAI,CAAEC,UAClC,EAEO/C,EAAG8C,KAAK,CAAC,IAAI,CAAEC,YAE1B,CAGF,EAzBS/C,CA0BX,CAIOsD,EARI,QAQM,GAAGhD,CAAgB,CAAQ,CAC1C,GAAM,CAACC,EAAMG,EAAQ,CAA4CJ,EAE3DS,EAAc,IAAI,CAACb,cAAc,CACrCQ,CAAAA,QAAAA,KAAAA,EAAAA,EAASM,UAAAA,AAAU,GAAI,IAAI,CAACnB,kBAAkB,IAEhD,OAAO,IAAI,CAACP,iBAAiB,GAAGgE,SAAS,CAAC/C,EAAMG,EAASK,EAC3D,CAEQb,eAAec,CAAiB,CAAE,CAKxC,OAJoBA,AAIbD,EAHHvD,EAAM+F,OAAO,CAACjG,EAAQoC,MAAM,GAAIsB,QAChCW,CAGN,CAEO6B,uBAAwB,CAC7B,IAAMrC,EAAS7D,EAAQoC,MAAM,GAAG+D,QAAQ,CAAC9E,GACzC,OAAOF,EAAwBiF,GAAG,CAACvC,EACrC,CAEOwC,qBAAqBzE,CAAmB,CAAEC,CAAqB,CAAE,CACtE,IAAMgC,EAAS7D,EAAQoC,MAAM,GAAG+D,QAAQ,CAAC9E,GACnCyC,EAAa3C,EAAwBiF,GAAG,CAACvC,GAC3CC,GAAc,CAACA,EAAWwC,GAAG,CAAC1E,IAChCkC,EADsC,AAC3BpC,GAAG,CAACE,EAAKC,EAExB,CACF,EAKS,IAAMyD,qCCjdXmB,2EAuBYF,gBAAAA,qCAAAA,KAzBhB,IAAMC,EAAO,KAAO,EAyBb,SAASD,EAAcS,CAAkB,EAG9C,GAAI,CAACA,EAASC,IAAI,CAChB,CADkB,KACX,CAACD,EAAUA,EAAS,CAG7B,GAAM,CAACE,EAAOC,EAAM,CAAGH,EAASC,IAAI,CAACG,GAAG,GAElCC,EAAU,IAAIC,SAASJ,EAAO,CAClCK,OAAQP,EAASO,MAAM,CACvBC,WAAYR,EAASQ,UAAU,CAC/BC,QAAST,EAASS,OAAO,AAC3B,GAEAzC,OAAO0C,cAAc,CAACL,EAAS,MAAO,CACpCxF,MAAOmF,EAASW,GAAG,CAEnBC,cAAc,EACdC,YAAY,EACZC,SAAU,EACZ,GAgBIrB,GAAYY,EAAQJ,IAAI,EAAE,AAC5BR,EAASsB,QAAQ,CAACV,EAAS,IAAIW,QAAQX,EAAQJ,IAAI,GAGrD,IAAMgB,EAAU,IAAIX,SAASH,EAAO,CAClCI,OAAQP,EAASO,MAAM,CACvBC,WAAYR,EAASQ,UAAU,CAC/BC,QAAST,EAASS,OAAO,AAC3B,GAUA,OARAzC,OAAO0C,cAAc,CAACO,EAAS,MAAO,CACpCpG,MAAOmF,EAASW,GAAG,CAEnBC,cAAc,EACdC,YAAY,EACZC,UAAU,CACZ,GAEO,CAACT,EAASY,EAAQ,AAC3B,CA7EI/D,WAAWwC,oBAAoB,EAAE,CACnCD,EAAW,IAAIC,qBAAqB,AAACC,IACnC,IAAMC,EAASD,EAAQE,KAAK,GACxBD,GAAU,CAACA,EAAOE,MAAM,EAAE,AAC5BF,EAAOG,MAAM,CAAC,8CAA8C1H,IAAI,CAACmH,EAErE,EAAA,gCCRD,OAAA,cAAA,CAAA,EAAA,aAAA,oCAyCe0B,oBAAAA,qCAAAA,ydAxCO,CAAA,CAAA,IAAA,QACO,CAAA,CAAA,IAAA,OACC,CAAA,CAAA,IAAA,kIAM/B,IAAME,EAA6B,IAAIC,IAAI,CAAC,cAAe,aAAa,EAgCjE,SAASH,EAAkBmB,CAA2B,EAC3D,IAAMC,EAAkBC,EAAMC,KAAK,CAEjC,AAAC7B,GAA8B,EAAE,EAGnC,OAAO,SAAS8B,AACdC,CAA2B,CAC3BtG,CAAqB,MAajBuE,EACAiC,EAZJ,GAAIxG,GAAWA,EAAQuG,MAAM,CAQ3B,CAR6B,MAQtBN,EAAcK,EAAUtG,GAKjC,GAAI,AAAoB,YAAY,CArBiD,IAqB1EsG,GAA0BtG,EAI9B,CAKL,MAT4C,AAStCmF,EACgB,UAApB,OAAOmB,GAAyBA,aAAoBG,IAChD,IAAIC,QAAQJ,EAAUtG,GACtBsG,EACN,GACsB,QAAnBnB,EAAQO,MAAM,EAAiC,SAAnBP,EAAQO,MAAM,EAC3CP,EAAQwB,SAAS,CAMjB,CALA,MAKOV,EAAcK,EAAUtG,GAlE/BoF,EAAkBC,MAAMC,IAAI,CAACH,EAAQd,OAAO,CAACpF,OAAO,IAAIsG,MAAM,CAClE,CAAC,CAAC/G,EAAI,GAAK,CAACwG,EAA2B9B,GAAG,CAAC1E,EAAIkD,WAAW,KAmExD8E,EAhEGhB,KAAKC,IAgEGP,KAhEM,CAAC,CACpBC,EAAQO,MAAM,CACdN,EACAD,EAAQQ,IAAI,CACZR,EAAQS,QAAQ,CAChBT,EAAQU,WAAW,CACnBV,AA0D8BA,EA1DtBW,QAAQ,CAChBX,EAAQY,cAAc,CACtBZ,EAAQa,SAAS,CAClB,EAwDGzB,EAAMY,EAAQZ,GAChB,AADmB,MAtBjBiC,EA7DiB,SA6DNzB,sCACXR,AA9DgE,EA8D1D+B,EAwBR,IAAMM,EAAeV,EAAgB3B,GACrC,IAAK,IAAIsC,EAAI,EAAGC,EAAIF,EAAa/E,MAAM,CAAEgF,EAAIC,EAAGD,GAAK,EAAG,CACtD,EAxFkH,CAwF5G,CAACrI,EAAKxC,EAAQ,CAAG4K,CAAY,CAACC,EAAE,CACtC,GAAIrI,IAAQgI,EACV,OAAOxK,CADa,CACLC,IAAI,CAAC,KAClB,IAAM8K,EAAWH,CAAY,CAACC,EAAE,CAAC,EAAE,CACnC,GAAI,CAACE,EAAU,MAAM,OAAA,cAAwC,CAAxC,IAAIC,EAAAA,cAAc,CAAC,sBAAnB,oBAAA,OAAA,mBAAA,gBAAA,CAAuC,GAM5D,GAAM,CAAC/C,EAASY,EAAQ,CAAG1B,GAAAA,EAAAA,aAAAA,AAAa,EAAC4D,GAEzC,OADAH,CAAY,CAACC,EAAE,CAAC,EAAE,CAAGhC,EACdZ,CACT,EAEJ,CAIA,IAAMjI,EAAUiK,EAAcK,EAAUtG,GAClCiH,EAAoB,CAACT,EAAUxK,EAAS,KAAK,CAGnD,OAFA4K,EAAalI,IAAI,CAACuI,GAEXjL,EAAQC,IAAI,CAAC,AAAC8K,IAKnB,GAAM,CAAC9C,EAASY,EAAQ,CAAG1B,CAAAA,EAAAA,EAAAA,aAAAA,AAAa,EAAC4D,GAEzC,OADAE,CAAK,CAAC,EAAE,CAAGpC,EACJZ,CACT,EACF,CACF,4FCjFkBiD,eAAe,CAAA,kBAAfA,GA0JAC,oBAAoB,CAAA,kBAApBA,uEA1JX,IAAWD,IAAAA,cAAAA,CAAAA,UAAAA,GAAAA,4FAAAA,GA0JAC,IAAAA,mBAAAA,CAAAA,UAAAA,GAAAA,iEAAAA,iCCpMjB,OAAA,cAAA,CAAA,EAAA,aAAA,oCACYC,kBAAAA,qCAAAA,IAAN,OAAMA,EAKXnK,aAAc,CACZ,IAAIoK,EACAC,EAGJ,IAAI,CAACtL,OAAO,CAAG,IAAIuL,QAAW,CAACzF,EAAK0F,KAClCH,EAAUvF,EACVwF,EAASE,CACX,GAIA,IAAI,CAACH,OAAO,CAAGA,EACf,IAAI,CAACC,MAAM,CAAGA,CAChB,CACF,yGCFaG,UAAAA,qCAAAA,aAtBmB,CAAA,CAAA,IAAA,EAsBzB,OAAMA,EAGX,YACmBC,CAA6B,CAM7BC,CALjB,CAKkD,AAACrI,GAAOA,GAAI,CAC9D,MAPiBoI,UAAAA,CAAAA,OAMAC,WAAAA,CAAAA,OATFC,OAAAA,CAAU,IAAI5J,GAU5B,CAcH,OAAc6J,OACZ7H,CAA8B,CACZ,CAClB,OAAO,IAAIyH,EAAiBzH,MAAAA,EAAAA,KAAAA,EAAAA,EAAS0H,UAAU,CAAE1H,MAAAA,EAAAA,KAAAA,EAAAA,EAAS2H,WAAW,CACvE,CAYA,MAAaG,MAAMtJ,CAAM,CAAEc,CAAgB,CAAc,CACvD,IAAMkH,EAAY,IAAI,CAACkB,UAAU,CAAG,MAAM,IAAI,CAACA,UAAU,CAAClJ,GAAOA,EACjE,GAAIgI,AAAa,MAAM,GACrB,OAAOlH,EAAG,CAAE+H,QAAS,AAAC5I,GAAU8I,QAAQF,OAAO,CAAC5I,OAAQD,CAAI,GAG9D,IAAMoJ,EAAU,IAAI,CAACA,OAAO,CAAC5E,GAAG,CAACwD,GACjC,GAAIoB,EAAS,OAAOA,EAEpB,GAAM,SAAE5L,CAAO,SAAEqL,CAAO,QAAEC,CAAM,CAAE,CAAG,IAAIF,EAAAA,eAAe,CAiBxD,OAhBA,IAAI,CAACQ,OAAO,CAACtJ,GAAG,CAACkI,EAAUxK,GAE3B,IAAI,CAAC2L,WAAW,CAAC,UACf,GAAI,CACF,IAAMxK,EAAS,MAAMmC,EAAG,SAAE+H,MAAS7I,CAAI,GAIvC6I,EAAQlK,EACV,CAAE,MAAOR,EAAK,CACZ2K,EAAO3K,EACT,QAAU,CACR,IAAI,CAACiL,OAAO,CAACzG,MAAM,CAACqF,EACtB,CACF,GAEOxK,CACT,CACF,yGC7Fa+L,eAAAA,qCAAAA,KAAN,IAAMA,EAAe,CAE1BC,QAAS,CAEPC,KAAM,IAAIC,WAAW,CAAC,GAAI,IAAK,IAAK,IAAK,IAAI,EAE7CC,KAAM,IAAID,WAAW,CAAC,GAAI,GAAI,IAAK,IAAK,IAAI,CAC9C,EACAE,OAAQ,CAENC,KAAM,IAAIH,WAAW,CAAC,GAAI,GAAI,IAAK,IAAK,GAAI,IAAK,GAAG,EAEpDC,KAAM,IAAID,WAAW,CAAC,GAAI,GAAI,GAAI,IAAK,IAAK,IAAK,GAAG,EAEpDD,KAAM,IAAIC,WAAW,CAAC,GAAI,GAAI,IAAK,IAAK,IAAK,IAAK,GAAG,EAErDI,cAAe,IAAIJ,WAAW,CAC5B,GAAI,GAAI,GAAI,IAAK,IAAK,IAAK,GAAI,GAAI,GAAI,IAAK,IAAK,IAAK,IAAK,GAC5D,CACH,EACAK,KAAM,CAIJC,UAAW,IAAIN,WAAW,CACxB,GAAI,IAAK,IAAK,IAAK,GAAI,GAAI,IAAK,GAAI,IAAK,IAAK,GAAI,GAAI,IAAK,IAAK,IAAK,IACrE,IAAK,GAAI,IAAK,GAAI,IAAK,IAAK,IAAK,IAAK,GACvC,CACH,CACF,gCC3BC,OAAA,cAAA,CAAA,EAAA,aAAA,mBACeO,iBAAiB,CAAA,kBAAjBA,GA2BAC,uBAAuB,CAAA,kBAAvBA,GAiBAC,oBAAoB,CAAA,kBAApBA,uEA5CT,SAASF,EAAkBG,CAAa,CAAEC,CAAa,EAC5D,GAAiB,IAAbA,EAAEhH,MAAM,CAAQ,OAAO,EAC3B,GAAiB,IAAb+G,EAAE/G,MAAM,EAAUgH,EAAEhH,MAAM,CAAG+G,EAAE/G,MAAM,CAAE,OAAO,CAAC,EAGnD,IAAK,IAAIgF,EAAI,EAAGA,GAAK+B,EAAE/G,MAAM,CAAGgH,EAAEhH,MAAM,CAAEgF,IAAK,CAC7C,IAAIiC,GAAgB,EAEpB,IAAK,IAAIhC,EAAI,EAAGA,EAAI+B,EAAEhH,MAAM,CAAEiF,IAAK,AAEjC,GAAI8B,CAAC,CAAC/B,EAAIC,EAAE,GAAK+B,CAAC,CAAC/B,EAAE,CAAE,CACrBgC,EAAgB,GAChB,KACF,CAGF,GAAIA,EACF,OAAOjC,CAEX,CAEA,IALqB,GAKd,CAAC,CACV,CAKO,SAAS6B,EAAwBE,CAAa,CAAEC,CAAa,EAClE,GAAID,EAAE/G,MAAM,GAAKgH,EAAEhH,MAAM,CAAE,OAAO,EAElC,IAAK,IAAIgF,EAAI,EAAGA,EAAI+B,EAAE/G,MAAM,CAAEgF,IAAK,AACjC,GAAI+B,CAAC,CAAC/B,EAAE,GAAKgC,CAAC,CAAChC,EAAE,CAAE,OAAO,EAG5B,OAAO,CACT,CASO,SAAS8B,EAAqBC,CAAa,CAAEC,CAAa,EAC/D,IAAME,EAAWN,EAAkBG,EAAGC,GACtC,GAAiB,IAAbE,EAAgB,OAAOH,EAAEI,QAAQ,CAACH,EAAEhH,MAAM,EAC9C,KAAIkH,EAAW,EAAC,EAMd,OAAOH,CANU,EACjB,IAAMK,EAAU,IAAIf,WAAWU,EAAE/G,MAAM,CAAGgH,EAAEhH,MAAM,EAGlD,OAFAoH,EAAQ3K,GAAG,CAACsK,EAAEM,KAAK,CAAC,EAAGH,IACvBE,EAAQ3K,GAAG,CAACsK,EAAEM,KAAK,CAACH,EAAWF,EAAEhH,MAAM,EAAGkH,GACnCE,CACT,CAGF,MAHS,mGCvDIE,0BAAAA,qCAAAA,KAAN,IAAMA,EAA0B,qUCmB1BC,+BAA+B,CAAA,kBAA/BA,GAiCGC,4BAA4B,CAAA,kBAA5BA,GAtBAC,oBAAoB,CAAA,kBAApBA,uEAfhB,IAAMC,EAAiB,kBAAkB,AAI5BH,EAAkC,SAJK,IAMpD,SAASK,EAAcC,CAAe,EAMpC,OAHkBA,AAGXC,EAHmBT,KAAK,CAAC,EARN,CAQSM,GAGlBhI,OAAO,CAAC,KAAM,IACjC,CAEO,SAAS8H,EAAqBM,CAAoB,CAAEF,CAAe,SACxE,AAEEA,EAAQxJ,QAAQ,CAAC,QAGjB,CAAC0J,CAFD,CAEcC,UAAU,CAACN,GAOlBK,EAGFA,EAAapI,OAAO,CACzB+H,EACAA,AAXA,EAWiB,AAhByC,OAgBhCE,EAAcC,GAAW,MAEvD,CAEO,SAASL,EACdS,CAA2B,CAC3BJ,CAAe,EAGf,OAAOI,CAvBqE,CAuBjDD,UAAU,CACnCN,EAAiB,OAASE,EAAcC,GAAW,MAEvD,wFC3DaK,aAAa,CAAA,kBAAbA,GAiBAC,cAAc,CAAA,kBAAdA,GAeAC,4BAA4B,CAAA,kBAA5BA,GAJAC,wBAAwB,CAAA,kBAAxBA,GAfAC,4BAA4B,CAAA,kBAA5BA,GADAC,uBAAuB,CAAA,kBAAvBA,GAsBAC,2BAA2B,CAAA,kBAA3BA,GAHAC,wBAAwB,CAAA,kBAAxBA,GAEAC,sBAAsB,CAAA,kBAAtBA,GAJAC,0BAA0B,CAAA,kBAA1BA,GACAC,2BAA2B,CAAA,kBAA3BA,GAzBAC,2BAA2B,CAAA,kBAA3BA,GAKAC,mCAAmC,CAAA,kBAAnCA,GAiBAC,6BAA6B,CAAA,kBAA7BA,GAvBAC,6BAA6B,CAAA,kBAA7BA,GAqBAC,oBAAoB,CAAA,kBAApBA,GAXAC,QAAQ,CAAA,kBAARA,GACAC,uBAAuB,CAAA,kBAAvBA,GAhBAC,UAAU,CAAA,kBAAVA,uEAAN,IAAMA,EAAa,MACblB,EAAgB,cAIhBc,EAAgC,yBAChCH,EAA8B,uBAK9BC,EACX,+BACWP,EAA0B,mBAC1BD,EAA+B,4BAC/BY,EAAW,WACXC,EAA0B,mBAE1BhB,EAAiB,CAC5BiB,EACAJ,EACAH,EACAN,EACAO,EACD,CAEYG,EAAuB,OAEvBF,EAAgC,sBAChCV,EAA2B,qBAC3BM,EAA6B,0BAC7BC,EAA8B,2BAC9BH,EAA2B,qBAC3BL,EAA+B,4BAC/BM,EAAyB,sBACzBF,EAA8B,wUC5B3Ba,QAAQ,CAAA,kBAARA,GASAC,OAAO,CAAA,kBAAPA,uEATT,SAASD,EAASE,CAAW,EAClC,IAAIC,EAAO,KACX,IAAK,IAAIxE,EAAI,EAAGA,EAAIuE,EAAIvJ,MAAM,CAAEgF,IAE9BwE,AAFmC,EAE1BA,CAAAA,IAAQ,CAAA,CAAKA,EADTD,EAAIG,GACYD,OADF,CAACzE,GACS,EAEvC,OAAOwE,IAAS,CAClB,CAEO,SAASF,EAAQC,CAAW,EACjC,OAAOF,EAASE,GAAKI,QAAQ,CAAC,IAAItC,KAAK,CAAC,EAAG,EAC7C,yGChBgBuC,iCAAAA,qCAAAA,aAFQ,CAAA,CAAA,IAAA,GAEjB,SAASA,EACdC,CAA2C,CAC3CC,CAAoD,CACpDC,CAA8C,CAC9CC,CAA4C,QAE5C,AACGH,MAAmBzK,IAAnByK,GAAmD,MAAnBA,CAAmB,CAAE,OAC5BzK,IAA1B0K,GACAC,KAAoB3K,YACFA,IAAlB4K,EAEO,GAEFV,EAHL,CAGKA,EAAAA,OAAAA,AAAO,EACZ,CACEO,GAAkB,IAClBC,GAAyB,IACzBC,GAAmB,IACnBC,GAAiB,IAClB,CAACC,IAAI,CAAC,KAEX,wFCQgBC,YAAY,CAAA,kBAAZA,GA+4BMC,yBAAyB,CAAA,kBAAzBA,GArGAC,wBAAwB,CAAA,kBAAxBA,GA3DAC,kBAAkB,CAAA,kBAAlBA,GAqHAC,+BAA+B,CAAA,kBAA/BA,GA/BAC,uBAAuB,CAAA,kBAAvBA,GA1tBNC,6BAA6B,CAAA,kBAA7BA,GAi0BAC,2BAA2B,CAAA,kBAA3BA,GA3QAC,+BAA+B,CAAA,kBAA/BA,GApdAC,yBAAyB,CAAA,kBAAzBA,GAxJAC,gBAAgB,CAAA,kBAAhBA,GATAC,gBAAgB,CAAA,kBAAhBA,GAkBMC,cAAc,CAAA,kBAAdA,GAkBAC,cAAc,CAAA,kBAAdA,+EA/GI,CAAA,CAAA,IAAA,OACI,CAAA,CAAA,IAAA,OACE,CAAA,CAAA,IAAA,OACkB,CAAA,CAAA,IAAA,OACrB,CAAA,CAAA,IAAA,OAKtB,CAAA,CAAA,IAAA,OACiC,CAAA,CAAA,IAAA,OACH,CAAA,CAAA,IAAA,MAM9B,CAAA,CAAA,IAAA,OACwC,CAAA,CAAA,IAAA,GAE/C,SAASC,IAIT,CAKA,IAAMC,EAAU,IAAIC,YAEb,SAAShB,EACd,GAAGiB,CAA4B,EAI/B,GAAuB,GAAG,CAAtBA,EAAQnL,MAAM,CAChB,OAAO,IAAIoL,eAAkB,CAC3BtL,MAAMuL,CAAU,EACdA,EAAWC,KAAK,EAClB,CACF,GAIF,GAAuB,GAAG,CAAtBH,EAAQnL,MAAM,CAChB,OAAOmL,CAAO,CAAC,EAAE,CAGnB,GAAM,UAAEI,CAAQ,UAAE1I,CAAQ,CAAE,CAAG,IAAI2I,gBAI/BrR,EAAUgR,CAAO,CAAC,EAAE,CAACM,MAAM,CAAC5I,EAAU,CAAE6I,cAAc,CAAK,GAE3D1G,EAAI,EACR,KAAOA,EAAImG,EAAQnL,MAAM,CAAG,EAAGgF,IAAK,CAClC,IAAM2G,EAAaR,CAAO,CAACnG,EAAE,CAC7B7K,EAAUA,EAAQC,IAAI,CAAC,IACrBuR,EAAWF,MAAM,CAAC5I,EAAU,CAAE6I,cAAc,CAAK,GAErD,CAIA,IAAME,EAAaT,CAAO,CAACnG,EAAE,CAO7B,MAFA7K,CAJAA,EAAUA,EAAQC,IAAI,CAAC,IAAMwR,EAAWH,MAAM,CAAC5I,GAAAA,EAIvC3C,KAAK,CAAC8K,GAEPO,CACT,CAEO,SAASV,EAAiBtB,CAAW,EAC1C,OAAO,IAAI6B,eAAe,CACxBtL,MAAMuL,CAAU,EACdA,EAAWQ,OAAO,CAACZ,EAAQa,MAAM,CAACvC,IAClC8B,EAAWC,KAAK,EAClB,CACF,EACF,CAEO,SAASV,EAAiBmB,CAAa,EAC5C,OAAO,IAAIX,eAAe,CACxBtL,MAAMuL,CAAU,EACdA,EAAWQ,OAAO,CAACE,GACnBV,EAAWC,KAAK,EAClB,CACF,EACF,CAEO,eAAeR,EACpBnJ,CAAkC,EAElC,IAAMqK,EAASrK,EAAOsK,SAAS,GACzBC,EAAuB,EAAE,CAE/B,MAAO,CAAM,CACX,GAAM,MAAEpL,CAAI,OAAElE,CAAK,CAAE,CAAG,MAAMoP,EAAOG,IAAI,GACzC,GAAIrL,EACF,IADQ,EAIVoL,EAAOrP,IAAI,CAACD,EACd,CAEA,OAAOwP,OAAOC,MAAM,CAACH,EACvB,CAEO,eAAenB,EACpBpJ,CAAkC,CAClC+C,CAAoB,EAEpB,IAAM4H,EAAU,IAAIC,YAAY,QAAS,CAAEC,MAAO,EAAK,GACnDC,EAAS,GAEb,UAAW,IAAMV,KAASpK,EAAQ,CAChC,GAAI+C,MAAAA,EAAAA,KAAAA,EAAAA,EAAQgI,OAAO,CACjB,CADmB,MACZD,EAGTA,GAAUH,EAAQK,MAAM,CAACZ,EAAO,CAAEpK,QAAQ,CAAK,EACjD,CAIA,OAFA8K,AAEOA,EAFGH,EAAQK,MAAM,EAG1B,CASO,SAASnC,EACdrM,EAAoC,CAAC,CAAC,EAEtC,IAII4H,EAJE,qBAAE6G,EAAsBC,GAAQ,CAAE,CAAG1O,EAEvC2O,EAAoC,EAAE,CACtCC,EAA2B,EAGzBC,EAAQ,AAAC3B,IACb,GAAI,CACF,GAAIyB,AAA0B,GAAG,GAAd9M,MAAM,CACvB,OAGF,IAAM+L,EAAQ,IAAI1F,WAAW0G,GACzBE,EAAc,EAElB,IAAK,IAAIjI,EAAI,EAAGA,EAAI8H,EAAe9M,MAAM,CAAEgF,IAAK,CAC9C,IAAMkI,EAAgBJ,CAAc,CAAC9H,EAAE,CACvC+G,EAAMtP,GAAG,CAACyQ,EAAeD,GACzBA,GAAeC,EAAcC,UAAU,AACzC,CAGAL,EAAe9M,MAAM,CAAG,EACxB+M,EAAmB,EACnB1B,EAAWQ,OAAO,CAACE,EACrB,CAAE,KAAM,CAIR,CACF,EAoBA,OAAO,IAAIP,gBAAgB,CACzB+B,UAAUxB,CAAK,CAAEV,CAAU,EAEzByB,EAAejQ,IAAI,CAACkP,GAGhBgB,CAFJA,GAAoBhB,EAAMoB,UAAAA,AAAU,GAEZP,EACtBI,EAAM3B,GAEN+B,CA3BgB,AAAC/B,IACrB,GAAItF,EACF,IAsB6C,GAvBlC,AAIb,IAAMsH,EAAW,IAAI9H,EAAAA,eAAe,CACpCQ,EAAUsH,EAEVC,CAAAA,EAAAA,EAAAA,iBAAAA,AAAiB,EAAC,KAChB,GAAI,CACFN,EAAM3B,EACR,QAAU,CACRtF,OAAU3G,EACViO,EAAS7H,OAAO,EAClB,CACF,GACF,EAWoB6F,EAElB,QACA2B,IACSjH,MAAAA,EAAAA,KAAAA,EAAAA,EAAS5L,OAAO,AAE3B,EACF,CAEA,SAASqT,EACPC,CAAgC,CAChC5F,CAAe,EAOf,IAAI6F,GAAyB,EAC7B,OAAO,IAAIlC,gBAAgB,CACzB+B,UAAUxB,CAAK,CAAEV,CAAU,EACzB,GAAIoC,GAA2B,CAACC,EAAwB,CACtDA,GAAyB,EAEzB,IAAMC,EADU,AACCrB,IADGC,YAAY,QAAS,CAAEC,OAAO,CAAK,GAC9BG,MAAM,CAACZ,EAAO,CACrCpK,OAAQ,EACV,GACMiM,EAAkBnG,CAAAA,EAAAA,EAAAA,oBAAoB,AAApBA,EAAqBkG,EAAU9F,GACvDwD,EAAWQ,OAAO,CAACZ,EAAQa,MAAM,CAAC8B,IAClC,MACF,CACAvC,EAAWQ,OAAO,CAACE,EACrB,CACF,EACF,CAEO,SAASpB,EAA0B,gBACxCkD,CAAc,CACdC,SAAO,eACPC,CAAa,CAOd,EACC,MAAOvT,CAAAA,EAAAA,EAAAA,SAAAA,AAAS,IAAGS,KAAK,CAAC7B,EAAAA,aAAa,CAAC4U,sBAAsB,CAAE,SAC7DH,EAAeG,sBAAsB,CAACF,EAASC,GAEnD,CAEA,SAASE,EACPC,CAAsC,EAEtC,IAAIC,EAAa,CAAC,EACdC,GAAgB,EAEpB,OAAO,IAAI5C,gBAAgB,CACzB,MAAM+B,UAAUxB,CAAK,CAAEV,CAAU,EAC/B,IAAIgD,EAAgB,CAAC,EACjBC,EAAkB,CAAC,EAGvB,GAFAH,IAEIC,EAAe,YACjB/C,EAAWQ,OAAO,CAACE,GAGrB,IAAIwC,EAAiB,EAErB,GAAsB,CAAC,IAAnBF,EAAsB,CAExB,GAAIA,AAAkB,CAAC,KADvBA,EAAgBzH,CAAAA,EAAAA,EAAAA,iBAAiB,AAAjBA,EAAkBmF,EAAO7F,EAAAA,YAAY,CAACQ,IAAI,CAACC,UAAS,EAC1C,YACxB0E,EAAWQ,OAAO,CAACE,GAO2B,IAAI,CAA9CA,CAAK,CAACsC,EAFVE,GAAiBrI,EAAAA,SAESqI,GAFG,CAAC7H,IAAI,CAACC,SAAS,CAAC3G,MAAAA,AAAM,EAEV,CACvCuO,GAAkB,EAGlBA,GAGN,CAGA,GAAmB,AAAfJ,GAAkB,IAEpB,GADAG,EAAkB1H,CAAAA,EAAAA,EAAAA,iBAAAA,AAAiB,EAACmF,EAAO7F,EAAAA,YAAY,CAACK,MAAM,CAACC,IAAI,EAC7C,CAAC,IAAnB6H,EAAsB,CAIxB,GAAIA,EAAgBC,EAAiB,CACnC,IAAME,EAAW,IAAInI,WAAW0F,EAAM/L,MAAM,CAAGuO,GAG/CC,EAAS/R,GAAG,CAACsP,EAAM5E,QAAQ,CAAC,EAAGkH,IAC/BG,EAAS/R,GAAG,CACVsP,EAAM5E,QAAQ,CAACkH,EAAgBE,GAC/BF,GAEFtC,EAAQyC,CACV,KAAO,CAEL,IAAMC,EAAY,MAAMP,IAClBQ,EAAmBzD,EAAQa,MAAM,CAAC2C,GAClCE,EAAkBD,EAAiB1O,MAAM,CACzCwO,EAAW,IAAInI,WACnB0F,EAAM/L,MAAM,CAAGuO,EAAiBI,GAElCH,EAAS/R,GAAG,CAACsP,EAAM5E,QAAQ,CAAC,EAAGkH,IAC/BG,EAAS/R,GAAG,CAACiS,EAAkBL,GAC/BG,EAAS/R,GAAG,CACVsP,EAAM5E,QAAQ,CAACkH,EAAgBE,GAC/BF,EAAgBM,GAElB5C,EAAQyC,CACV,CACAJ,GAAgB,EAClB,KAEK,CAGL,IAAMK,EAAY,MAAMP,IAClBQ,EAAmBzD,EAAQa,MAAM,CAAC2C,GAClCE,EAAkBD,EAAiB1O,MAAM,CAEzCwO,EAAW,IAAInI,WACnB0F,EAAM/L,MAAM,CAAGuO,EAAiBI,GAGlCH,EAAS/R,GAAG,CAACsP,EAAM5E,QAAQ,CAAC,EAAGkH,IAE/BG,EAAS/R,GAAG,CAACiS,EAAkBL,GAG/BG,EAAS/R,GAAG,CACVsP,EAAM5E,QAAQ,CAACkH,EAAgBE,GAC/BF,EAAgBM,GAElB5C,EAAQyC,EACRJ,GAAgB,CAClB,CACA/C,EAAWQ,OAAO,CAACE,EACrB,CACF,EACF,CAEA,SAAS6C,EACPV,CAA6B,EAE7B,IAAIW,GAAW,EAIXC,EAAW,GAEf,OAAO,IAAItD,gBAAgB,CACzB,MAAM+B,UAAUxB,CAAK,CAAEV,CAAU,EAC/ByD,GAAW,EAEX,IAAML,EAAY,MAAMP,IACxB,GAAIW,EAAU,CACZ,GAAIJ,EAAW,CACb,IAAMC,EAAmBzD,EAAQa,MAAM,CAAC2C,GACxCpD,EAAWQ,OAAO,CAAC6C,EACrB,CACArD,EAAWQ,OAAO,CAACE,EACrB,KAAO,CAEL,IAAMgD,EAAQnI,CAAAA,EAAAA,EAAAA,iBAAAA,AAAiB,EAACmF,EAAO7F,EAAAA,YAAY,CAACK,MAAM,CAACC,IAAI,EAG/D,GAAc,CAAC,IAAXuI,EAAc,CAChB,GAAIN,EAAW,CACb,IAAMC,EAAmBzD,EAAQa,MAAM,CAAC2C,GAMlCO,EAAsB,IAAI3I,WAC9B0F,EAAM/L,MAAM,CAAG0O,EAAiB1O,MAAM,EAGxCgP,EAAoBvS,GAAG,CAACsP,EAAM1E,KAAK,CAAC,EAAG0H,IAEvCC,EAAoBvS,GAAG,CAACiS,EAAkBK,GAE1CC,EAAoBvS,GAAG,CACrBsP,EAAM1E,KAAK,CAAC0H,GACZA,EAAQL,EAAiB1O,MAAM,EAEjCqL,EAAWQ,OAAO,CAACmD,EACrB,MACE3D,CADK,CACMQ,OAAO,CAACE,GAErB8C,EAAW,EACb,MAOMJ,CAPC,EAQHpD,EAAWQ,MADE,CACK,CAACZ,EAAQa,MAAM,CAAC2C,IAEpCpD,EAAWQ,OAAO,CAACE,GACnB8C,GAAW,CAEf,CACF,EACA,MAAM7B,MAAM3B,CAAU,EAEpB,GAAIyD,EAAU,CACZ,IAAML,EAAY,MAAMP,IACpBO,GACFpD,EAAWQ,MADE,CACK,CAACZ,EAAQa,MAAM,CAAC2C,GAEtC,CACF,CACF,EACF,CA6GA,SAASkB,EACPhO,CAAkC,CAClCiO,CAAqC,EAErC,IAAIC,GAAqB,EAErBC,EAA6B,KAC7BC,GAAc,EAElB,SAASC,EACP3E,CAA4C,EAK5C,OAHI,AAACyE,IACHA,EAAOG,AADE,EACW5E,EAAAA,EAEfyE,CACT,CAEA,eAAeG,EAAa5E,CAA4C,EACtE,IAAMW,EAASrK,EAAOsK,SAAS,EAE3B2D,IAWF,MAAMM,GAAAA,EAAAA,cAAc,AAAdA,CAX0B,GAclC,GAAI,CACF,MAAO,CAAM,CACX,GAAM,MAAEpP,CAAI,OAAElE,CAAK,CAAE,CAAG,MAAMoP,EAAOG,IAAI,GACzC,GAAIrL,EAAM,CACRiP,GAAc,EACd,MACF,CAKI,AAACH,GAAiCC,GACpC,MAAMK,GAAAA,EAAAA,MADkD,QAClDA,AAAc,CADe,GAGrC7E,EAAWQ,OAAO,CAACjP,EACrB,CACF,CAAE,MAAO9B,EAAK,CACZuQ,EAAW9P,KAAK,CAACT,EACnB,CACF,CAEA,OAAO,IAAI0Q,gBAAgB,CACzB1L,MAAMuL,CAAU,EACTuE,AAAD,GACFI,EAAuB3E,EAE3B,EACAkC,UAAUxB,CAAK,CAAEV,CAAU,EACzBA,EAAWQ,IALwB,GAKjB,CAACE,GAGf6D,GACFI,EAAuB3E,EAE3B,EACA2B,MAAM3B,CAAU,EAEd,GADAwE,GAAqB,GACjBE,EAGJ,CATkC,MAS3BC,EAAuB3E,EAChC,AAJmB,CAKrB,EACF,CAEA,IAAM8E,EAAY,iBAOlB,SAASC,IACP,IAAIC,GAAc,EAElB,OAAO,IAAI7E,gBAAgB,CACzB+B,UAAUxB,CAAK,CAAEV,CAAU,EACzB,GAAIgF,EACF,OAAOhF,EAAWQ,EADH,KACU,CAACE,GAG5B,IAAMgD,EAAQnI,CAAAA,EAAAA,EAAAA,iBAAAA,AAAiB,EAACmF,EAAO7F,EAAAA,YAAY,CAACK,MAAM,CAACE,aAAa,EACxE,GAAIsI,EAAQ,CAAC,EAAG,CAKd,GAJAsB,GAAc,EAIVtE,EAAM/L,MAAM,GAAKkG,EAAAA,YAAY,CAACK,MAAM,CAACE,aAAa,CAACzG,MAAM,CAC3D,CAD6D,MAK/D,IAAMsQ,EAASvE,EAAM1E,KAAK,CAAC,EAAG0H,GAK9B,GAJA1D,EAAWQ,OAAO,CAACyE,GAIfvE,EAAM/L,MAAM,CAAGkG,EAAAA,YAAY,CAACK,MAAM,CAACE,aAAa,CAACzG,MAAM,CAAG+O,EAAO,CAEnE,IAAMwB,EAAQxE,EAAM1E,KAAK,CACvB0H,EAAQ7I,EAAAA,YAAY,CAACK,MAAM,CAACE,aAAa,CAACzG,MAAM,EAElDqL,EAAWQ,OAAO,CAAC0E,EACrB,CACF,MACElF,CADK,CACMQ,OAAO,CAACE,EAEvB,EACAiB,MAAM3B,CAAU,EAGdA,EAAWQ,OAAO,CAAC3F,EAAAA,YAAY,CAACK,MAAM,CAACE,aAAa,CACtD,CACF,EACF,CAsCO,SAASiE,IAId,IAAI+F,GAAY,EACZC,GAAY,EAChB,OAAO,IAAIlF,gBAAgB,CACzB,MAAM+B,UAAUxB,CAAK,CAAEV,CAAU,EAG7B,CAACoF,GACD7J,CAAAA,EAAAA,EAAAA,iBAAAA,AAAiB,EAACmF,EAAO7F,EAAAA,YAAY,CAACC,OAAO,CAACC,IAAI,EAAI,CAAC,GACvD,CACAqK,GAAY,CAAA,EAIZ,CAACC,GACD9J,CAAAA,EAAAA,EAAAA,iBAAAA,AAAiB,EAACmF,EAAO7F,EAAAA,YAAY,CAACC,OAAO,CAACG,IAAI,EAAI,CAAC,GACvD,CACAoK,GAAY,CAAA,EAGdrF,EAAWQ,OAAO,CAACE,EACrB,EACAiB,MAAM3B,CAAU,EACd,IAAMsF,EAAmC,EAAE,AACvC,CAACF,GAAWE,EAAY9T,IAAI,CAAC,QAC7B,AAAC6T,GAAWC,EAAY9T,IAAI,CAAC,QAE5B8T,EAAY3Q,MAAM,EAAE,AAEzBqL,EAAWQ,OAAO,CAChBZ,EAAQa,MAAM,CACZ,CAAC;;+CAEoC,EAAE6E,EAChCC,GAAG,CAAC,AAACC,GAAM,CAAC,CAAC,EAAEA,EAAE,CAAC,CAAC,EACnB5G,IAAI,CACH0G,EAAY3Q,MAAM,CAAG,EAAI,QAAU,IACnC;AAAA;sCACoB,EAAEsH,EAAAA,uBAAuB,CAAC;;;UAGtD,CAAC,EAGP,CACF,EACF,CA6BO,eAAe+C,EACpB6G,CAA0C,CAC1C,CACEzB,QAAM,mBACN0B,CAAiB,oBACjBC,CAAkB,yBAClB3D,CAAuB,SACvB5F,CAAO,uBACPwJ,CAAqB,2BACrBC,CAAyB,oBACzBC,CAAkB,CACI,EAGxB,IA5SIxL,IA4SEyL,EAAiB/B,EAASA,EAAOhQ,KAAK,CAAC0Q,EAAW,EAAE,CAAC,EAAE,CAAG,KAG5DiB,GACF,MAAMF,EAAaO,QAAQ,CADL,IA1CxBV,EA8CuC,CAErCvG,IAGAgD,EAA4BC,EAAyB5F,CAnDE,EAsDvDoG,EAA8BqD,GAG9BE,AAAkB,SAAQA,EAAexR,MAAM,CAAG,GA/ThD0P,CAgUEF,EAhUQ,EAqBP,IAAIhE,gBAAgB,CACzB+B,UAAUxB,CAAK,CAAEV,CAAU,EAIzB,GAHAA,EAAWQ,OAAO,CAACE,IAGf2D,SAGJA,AAHa,GAGH,EAxBZ3J,EADMsH,EAAW,IAAI9H,EAAAA,AACX8H,eAD0B,CAGpCC,CAAAA,EAAAA,EAAAA,iBAAAA,AAAiB,EAAC,KAChB,GAAI,CAsBEjC,AArBJA,EAAWQ,OAAO,CAACZ,EAAQa,MAAM,CAAC2D,AAuTP+B,GAtT7B,CAAE,KAAM,CAIR,QAAU,CACRzL,OAAU3G,EACViO,EAAS7H,OAAO,EAClB,CACF,GAaA,EACAwH,MAAM3B,CAAU,EACd,GAAItF,EAAS,OAAOA,EAAQ5L,OAAO,CAC/BuV,GAGJrE,EAAWQ,IAHE,GAGK,CAACZ,EAAQa,MAAM,CAAC2D,GACpC,CACF,IA0RM,KAGJ0B,EACIxB,EAAyCwB,GAAmB,GAC5D,KAGJI,EAAqB7G,IAAoC,KAGzD0F,IAKAxB,EAAmCyC,GACpC,CA1ED,IAAI1P,EA4CqBuP,EA3CzB,IAAK,CADQ3F,GACFyF,KAAeD,EACnBC,IAELrP,EAASA,EAAOsP,GAHsB,EACpB,MAES,CAACD,EAAAA,EAE9B,OAAOrP,CAqET,CAOO,eAAeyI,EACpBsH,CAA2C,CAC3C,uBACEL,CAAqB,2BACrBC,CAAyB,CACO,EAElC,OACEI,EAEGT,WAAW,CAACzG,EADb,GAECyG,WAAW,CAACT,AApLV,IAAIhF,gBAAgB,CACzB+B,UAAUxB,CAAK,CAAEV,CAAU,EAOvBxE,CAAAA,CA0KmD,CA1KnDA,EAAAA,EA6KF,qBA7KEA,AAAuB,EAACkF,EAAO7F,EAAAA,KA6KD,OA7Ka,CAACK,MAAM,CAACE,aAAa,GAChEI,CAAAA,EAAAA,EAAAA,uBAAAA,AAAuB,EAACkF,EAAO7F,EAAAA,YAAY,CAACK,MAAM,CAACD,IAAI,GACvDO,GAAAA,EAAAA,uBAAAA,AAAuB,EAACkF,EAAO7F,EAAAA,YAAY,CAACK,MAAM,CAACH,IAAI,GACvD,CAQF2F,EAAQjF,CAAAA,EAAAA,EAAAA,oBAAAA,AAAoB,EAACiF,EAAO7F,EAAAA,YAAY,CAACK,MAAM,CAACD,IAAI,EAC5DyF,EAAQjF,CAAAA,EAAAA,EAAAA,oBAAoB,AAApBA,EAAqBiF,EAAO7F,EAAAA,YAAY,CAACK,MAAM,CAACH,IAAI,EAE5DiF,EAAWQ,OAAO,CAACE,GACrB,CACF,IA8JKkF,WAAW,CAACrC,EAAmCyC,IAE/CJ,WAAW,CAAChD,EAA8BqD,GAEjD,CAUO,EAbD,aAagB/G,EACpBmH,CAA2C,CAC3C,IAfyB,eAgBvBP,CAAiB,uBACjBE,CAAqB,2BACrBC,CAAyB,yBACzB7D,CAAuB,SACvB5F,CAAO,CACwB,EAEjC,OACE6J,EAEGT,WAAW,CAACzG,EADb,GAGCyG,WAAW,CACVzD,EAA4BC,EAAyB5F,IAGtDoJ,MADD,EAJA,GAKY,CAACrC,EAAmCyC,IAE/CJ,WAAW,CATyC,AASxChD,EAA8BqD,IAE1CL,EAL+B,AAEhC,SAGY,CACVtB,EAAyCwB,EAAmB,KAG7DF,EAPoB,AAMrB,CAJA,QAKY,CAACb,IAEnB,CAEO,IAjBqE,WAiBtD9F,EACpBoH,CAA2C,CAC3C,gBAPsD,GAQpDP,CAAiB,uBACjBE,CAAqB,EAb4D,yBAcjFC,CAAyB,yBACzB7D,CAAuB,SACvB5F,CAAO,CACwB,EAxdjC,MAMMuH,EACAC,EAEFC,EAodJ,OACEoC,EAEGT,WAAW,CAACzG,EADb,GAGCyG,WAAW,CACVzD,EAA4BC,EAAyB5F,IAGtDoJ,MADD,EAJA,GAKY,CAACrC,EAAmCyC,IAE/CJ,WAAW,CATyC,AASxChC,CAxeXE,EAAqBvF,CAAAA,EAAAA,EAAAA,AAqeS,AAEhC,8BAveqD,AAA9BA,EACzB,IACA,IA+dwE,IAQtE,IAFgD,EApelDxK,OACAA,KAEgB,CAAA,EAmeO,AAneJ6J,EAFT,AAESA,oBAAoB,CAAC,CAAC,EAAEkG,EAAAA,AAFP,CAE2B,GAC/B,CAAC,uDAAuD,EAAEC,UAAU,iCAAyChG,EAAAA,IAAF,MAAY,CAAC,QAAQ,EAAEP,EAAAA,2BAA2B,CAAC,QAAQ,EAAEC,EAAAA,mCAAmC,CAAC,IAAI,EAAEoG,YAAY,MAAc,IAEvP,EAChB,CAHsQ,GAGlQ1D,gBAAgB,CACzB+B,UAAUxB,CAAK,CAAEV,CAAU,EACzB,GAAIiE,EAAkB,YAEpBjE,EAAWQ,OAAO,CAACE,GAIrB,IAAMwD,EAAsB3I,GAAAA,EAAAA,iBAAAA,AAAiB,EAC3CmF,EACA7F,EAAAA,YAAY,CAACK,MAAM,CAACC,IAAI,EAG1B,GAA4B,CAAC,IAAzB+I,EAA4B,YAG9BlE,EAAWQ,OAAO,CAACE,GAIrB,IAAM2C,EAAmBzD,EAAQa,MAAM,CAACuD,GAMlCL,EAAsB,IAAI3I,WAC9B0F,EAAM/L,MAAM,CAAG0O,EAAiB1O,MAAM,EAGxCgP,EAAoBvS,GAAG,CAACsP,EAAM1E,KAAK,CAAC,EAAGkI,IAEvCP,EAAoBvS,GAAG,CAACiS,EAAkBa,GAE1CP,EAAoBvS,GAAG,CACrBsP,EAAM1E,KAAK,CAACkI,GACZA,EAAsBb,EAAiB1O,MAAM,EAG/CqL,EAAWQ,OAAO,CAACmD,GACnBM,GAAmB,CACrB,CACF,KAsbK2B,WAAW,CAAChD,EAA8BqD,IAE1CL,WAAW,CACVtB,EAAyCwB,EAAmB,KAG7DF,EADD,CAJA,QAKY,CAACb,IAEnB,CASO,eAAejG,EACpB+G,CAAwC,CACxC,gBAdsD,cAepDtB,CAA4B,eAnBqD,IAoBjFuB,CAAiB,uBACjBE,CAAqB,2BACrBC,CAAyB,CACH,EAExB,OACEJ,EAEGD,WADD,AACY,CAACzG,KAEZyG,WAAW,CAACrC,EAAmCyC,IAE/CJ,UAHD,CAGY,CAAChD,EAA8BqD,IAE1CL,EAHD,SAJqD,AAOzC,CACVtB,EACEwB,EACAvB,IAIHqB,GAVoB,CAErB,AAJgC,OAYpB,CAACb,IAEnB,CAEO,SAAS3F,CALV,GAMJ,OAAOI,EAAiBsF,EAC1B,oCAPwD,MAP6B,8CCh7BxEwB,iBAAiB,CAAA,kBAAjBA,GA8SGC,cAAc,CAAA,kBAAdA,GA5BAC,cAAc,CAAA,kBAAdA,GA6CAC,iBAAiB,CAAA,kBAAjBA,GA9BAC,cAAc,CAAA,kBAAdA,uEAjST,IAAMJ,EAAoBK,OAAOC,GAAG,CAAC,2BAkRrC,SAASJ,EACdK,CAAwB,CACxBvV,CAAO,EAEP,IAAMwV,EAAOD,CAAG,CAACP,EAAkB,EAAI,CAAC,EACxC,MAAsB,UAAf,OAAOhV,EAAmBwV,CAAI,CAACxV,EAAI,CAAGwV,CAC/C,CASO,SAASJ,EAAeG,CAAwB,CAAEC,CAAiB,EAExE,OADAD,CAAG,CAACP,EAAkB,CAAGQ,EAClBA,CACT,CAUO,SAASP,EACdtO,CAA4B,CAC5B3G,CAAM,CACNC,CAAqB,EAErB,IAAMuV,EAAON,EAAevO,GAE5B,OADA6O,CAAI,CAACxV,EAAI,CAAGC,EACLmV,EAAezO,EAAS6O,EACjC,CASO,SAASL,EACdxO,CAA4B,CAC5B3G,CAAM,EAEN,IAAMwV,EAAON,EAAevO,GAE5B,OADA,OAAO6O,CAAI,CAACxV,EAAI,CACToV,EAAezO,EAAS6O,EACjC,wFClTaC,iBAAiB,CAAA,kBAAjBA,GAUAC,kBAAkB,CAAA,kBAAlBA,GA7BAC,gBAAgB,CAAA,kBAAhBA,GASAC,iBAAiB,CAAA,kBAAjBA,uEATN,IAAMD,EAAmB,AAACJ,IAC/BvX,EAQW4X,EAAoB,AAC/BtS,IAC2BtF,AAVnBC,EAkBGwX,CAlBA,CAACvX,AAkBmB,AAC/BqX,IAC2BvX,AAVQC,EAkBxByX,CAlB2B,CAkBN,AAChCpS,AAnBuCpF,IAUJD,AApBX,AA8BID,GAVU,CAACE,IAUHD,AApBe,GAoBZ,CAACC,IAVW,OApBtB,CA8BuB,OApBI,QAUA,QAUC,wCCO9C2X,kBAAkB,CAAA,kBAAlBA,GA5CAC,eAAe,CAAA,kBAAfA,GADAC,mBAAmB,CAAA,kBAAnBA,GAYGC,qBAAqB,CAAA,kBAArBA,GAuBAC,sBAAsB,CAAA,kBAAtBA,+EAxCe,CAAA,CAAA,IAAA,OACa,CAAA,CAAA,IAAA,OAChB,CAAA,CAAA,IAAA,OACwB,CAAA,CAAA,IAAA,GAEvCF,EAAsB,iBAC5B,OAAMD,UAAwBtX,wBAA9B,KAAA,IAAA,GAAA,IAAA,CACWS,IAAAA,CAAO8W,EACzB,CASO,SAASC,EAAsBzN,CAAkB,EACtD,IAAMmG,EAAa,IAAIwH,gBAWvB,OANA3N,EAAS4N,IAAI,CAAC,QAAS,KACjB5N,EAAS6N,gBAAgB,EAAE,AAE/B1H,EAAW2H,KAAK,CAAC,IAAIP,EACvB,GAEOpH,CACT,CAUO,SAASuH,EAAuB1N,CAAkB,EACvD,GAAM,SAAE+N,CAAO,WAAEC,CAAS,CAAE,CAAGhO,EAC/B,GAAI+N,GAAWC,EACb,OAAOC,EADiB,UACLH,KAAK,CAACC,GAAW,IAAIR,GAG1C,GAAM,QAAE/N,CAAM,CAAE,CAAGiO,EAAsBzN,GACzC,OAAOR,CACT,CAEO,MAAM8N,EACX,OAAcY,oBACZ9P,CAAwB,CACxBoB,CAAmB,CACN,CAQN,GAIL0N,CAFA,AADA,AAGAA,EAAAA,EAAAA,iBAAiB,AAAjBA,EAAkB9O,GAElB,OADA,AACOkP,EAAmBc,mBAAmB,CAAChQ,EAASoB,EAEvD,EAN6D,KAMvD,GAP+D,IAO/D,cAAoD,CAApD,AAAIvJ,MAAM,2CAAV,oBAAA,OAAA,mBAAA,gBAAA,CAAmD,EAE7D,CAEA,OAAcmY,oBACZhQ,CAAwB,CACxBoB,CAAmB,CACN,CAEb,IAMIhC,EANAV,EAAwB,KAO5B,GANuB,QAAnBsB,EAAQO,MAAM,EAAiC,SAAnBP,EAAQO,MAAM,EAAeP,EAAQtB,IAAI,EAAE,CAEzEA,EAAOsB,EAAQtB,IAAAA,AAAI,EAIjBsB,EAAQZ,GAAG,CAACsF,UAAU,CAAC,QACzBtF,CADkC,CAC5B,IAAIkC,IAAItB,EAAQZ,GAAG,MACpB,CAEL,IAAM6Q,EAAO1B,CAAAA,EAAAA,EAAAA,cAAAA,AAAc,EAACvO,EAAS,WAOnCZ,EANE,AAAC6Q,GAASA,EAAKvL,GAAN,OAAgB,CAAC,QAMtB,CAN+B,GAM3BpD,IAAItB,EAAQZ,GAAG,CAAE6Q,GAFrB,IAAI3O,IAAItB,EAAQZ,GAAG,CAAE,WAI/B,CAEA,OAAO,IAAI8Q,EAAAA,WAAW,CAAC9Q,EAAK,CAC1BmB,OAAQP,EAAQO,MAAM,CACtBrB,QAASiR,CAAAA,EAAAA,EAAAA,2BAAAA,AAA2B,EAACnQ,EAAQd,OAAO,EACpDkR,OAAQ,cACRhP,EAOA,GAAIA,EAAOgI,OAAO,CACd,CAAC,EACD,MACE1K,CACF,CAAC,AACP,EACF,CAEA,OAAcqR,mBAAmB/P,CAAuB,CAAe,CAErE,IAAItB,EAA8B,KAKlC,MAJuB,QAAnBsB,EAAQO,MAAM,EAAiC,QAAQ,CAA3BP,EAAQO,MAAM,GAC5C7B,EAAOsB,EAAQtB,IAAAA,AAAI,EAGd,IAAIwR,EAAAA,WAAW,CAAClQ,EAAQZ,GAAG,CAAE,CAClCmB,OAAQP,EAAQO,MAAM,CACtBrB,QAASiR,CAAAA,EAAAA,EAAAA,2BAAAA,AAA2B,EAACnQ,EAAQd,OAAO,EACpDkR,OAAQ,OACRhP,OAAQpB,EAAQA,OAAO,CAACoB,MAAM,CAO9B,GAAIpB,EAAQA,OAAO,CAACoB,MAAM,CAACgI,OAAO,CAC9B,CAAC,EACD,MACE1K,CACF,CAAC,AACP,EACF,CACF,wFC5GgB2R,+BAA+B,CAAA,kBAA/BA,GAnCAC,yBAAyB,CAAA,kBAAzBA,uEAJhB,IAAIC,EAA2B,EAC3BC,EAA2B,EAC3BC,EAA2B,EAExB,SAASH,EACdI,CAA2B,QAErB,AAAN,IAAI,CAAE,WAAiB/U,UAAS,CAIzB,CACLjG,CALkC,OAKzB,CAAC,GAAG+E,KACX,IAAMiB,EAAYE,YAAYC,GAAG,GAEA,GAAG,CAAhC0U,IACFA,EAA2B7U,CAAAA,EAG7B,GAAI,CAEF,OADA+U,GAA4B,EACrBC,EAAaC,YAAY,CAACjb,OAAO,IAAI+E,EAC9C,QAAU,CACR+V,GAA4B5U,YAAYC,GAAG,GAAKH,CAClD,CACF,EACAkV,UAAW,CAAC,GAAGnW,KACb,IAAMiB,EAAYE,YAAYC,GAAG,GAC3B7D,EAAS0Y,EAAaC,YAAY,CAACC,SAAS,IAAInW,GAMtD,OAHAzC,EAAO6E,OAAO,CAAC,KACb2T,GAA4B5U,YAAYC,GAAG,GAAKH,CAClD,GACO1D,CACT,CACF,EA5BS0Y,EAAaC,YA6BxB,AA7BoC,CA+B7B,SAASN,EACdxV,EAA+B,CAAC,CAAC,EAEjC,IAAMgW,EACyB,IAA7BN,OACIzU,EACA,0BACEyU,2BACAC,2BACAC,CACF,EAQN,OANI5V,EAAQiW,KAAK,EAAE,CACjBP,EAA2B,EAC3BC,EAA2B,EAC3BC,EAA2B,GAGtBI,CACT,wFClDgBE,YAAY,CAAA,kBAAZA,GA+GMC,kBAAkB,CAAA,kBAAlBA,+EArHf,CAAA,CAAA,IAAA,MACyB,CAAA,CAAA,IAAA,OACN,CAAA,CAAA,IAAA,OACS,CAAA,CAAA,IAAA,OACa,CAAA,CAAA,IAAA,GAEzC,SAASD,EAAaE,CAAM,EACjC,MAAOA,CAAAA,QAAAA,KAAAA,EAAAA,EAAG3Y,IAAAA,AAAI,IAAK,cAAgB2Y,CAAAA,MAAAA,EAAAA,KAAAA,EAAAA,EAAG3Y,IAAI,AAAJA,IAAS8W,EAAAA,mBAAmB,AACpE,CA6GO,eAAe4B,EACpB/I,CAAoC,CACpCtL,CAAmB,CACnBwU,CAAkC,EAElC,GAAI,CAEF,GAAM,SAAExB,CAAO,WAAEC,CAAS,CAAE,CAAGjT,EAC/B,GAAIgT,GAAWC,EAAW,OAI1B,IAAM7H,EAAasH,CAAAA,EAAAA,EAAAA,qBAAAA,AAAqB,EAAC1S,GAEnCsV,EAASf,AAzHnB,SAASA,AACPvU,CAAmB,CACnBwU,CAAkC,EAElC,IAAIC,GAAU,EAIVC,EAAU,IAAIpP,EAAAA,eAAe,CACjC,SAASqP,IACPD,EAAQnP,OAAO,EACjB,CACAvF,EAAI4U,EAAE,CAAC,QAASD,GAIhB3U,EAAI6S,IAAI,CAAC,QAAS,KAChB7S,EAAI6U,GAAG,CAAC,QAASF,GACjBD,EAAQnP,OAAO,EACjB,GAIA,IAAMuP,EAAW,IAAIxP,EAAAA,eAAe,CAMpC,OALAtF,EAAI6S,IAAI,CAAC,SAAU,KACjBiC,EAASvP,OAAO,EAClB,GAGO,IAAIwP,eAA2B,CACpCC,MAAO,MAAOlJ,IAIZ,GAAI,CAAC2I,EAAS,CAGZ,GAFAA,GAAU,EAGR,gBAAiBzV,YACjBtE,QAAQC,GAAG,CAAC2E,4BAA4B,CACxC,CACA,IAAM4U,EAAUR,GAAAA,EAAAA,+BAA+B,AAA/BA,IACZQ,GACFjV,MADW,MACCM,OAAO,CACjB,CAAA,EAAG7E,QAAQC,GAAG,CAAC2E,4BAA4B,CAAC,8BAA8B,CAAC,CAC3E,CACEO,MAAOqU,EAAQN,wBAAwB,CACvC5X,IACEkY,EAAQN,wBAAwB,CAChCM,EAAQL,wBAAwB,AACpC,EAGN,CAEA7T,EAAIiV,YAAY,GAChB1a,CAAAA,EAAAA,EAAAA,SAAAA,AAAS,IAAGS,KAAK,CACfvB,EAAAA,kBAAkB,CAACyb,aAAa,CAChC,CACE/W,SAAU,gBACZ,EACA,SAAMgB,EAEV,CAEA,GAAI,CACF,IAAMgW,EAAKnV,EAAIgV,KAAK,CAAClJ,GAIjB,UAAW9L,GAA4B,YAArB,AAAiC,OAA1BA,EAAI+M,KAAK,EACpC/M,EAAI+M,KAAK,GAKNoI,IAAI,AACP,MAAMT,EAAQxa,OAAO,CAGrBwa,EAAU,IAAIpP,EAAAA,eAAe,CAEjC,CAAE,MAAOzK,EAAK,CAEZ,MADAmF,EAAIhE,GAAG,GACD,OAAA,cAA8D,CAA9D,AAAId,MAAM,oCAAqC,CAAEka,MAAOva,CAAI,GAA5D,oBAAA,OAAA,mBAAA,gBAAA,CAA6D,EACrE,CACF,EACAkY,MAAO,AAAClY,IACFmF,EAAI8S,gBAAgB,EAAE,AAE1B9S,EAAIqV,OAAO,CAACxa,EACd,EACAwQ,MAAO,UAOL,GAJImJ,GACF,MAAMA,GAGJxU,EAAI8S,GAJa,aAIG,CAGxB,CAH0B,MAE1B9S,EAAIhE,GAAG,GACA8Y,EAAS5a,OAAO,AACzB,CACF,EACF,EAgB4C8F,EAAKwU,EAE7C,OAAMlJ,EAASE,MAAM,CAAC8J,EAAQ,CAAE7Q,OAAQ2G,EAAW3G,MAAM,AAAC,EAC5D,CAAE,MAAO5J,EAAU,CAEjB,GAAIuZ,EAAavZ,GAAM,MAEvB,OAAM,OAAA,cAAoD,CAApD,AAAIK,MAAM,0BAA2B,CAAEka,MAAOva,CAAI,GAAlD,oBAAA,OAAA,mBAAA,gBAAA,CAAmD,EAC3D,CACF,yGC1DA,UAAA,qCAAqB0a,aA9Ed,CAAA,CAAA,IAAA,OAC0C,CAAA,CAAA,IAAA,OAElB,CAAA,CAAA,IAAA,EA2EhB,OAAMA,YA0BlB,EAHD,EAGC,CACsBC,KAAAA,CAAQ,IAAID,EACjC,KACA,CAAEE,SAAU,CAAC,EAAGC,YAAa,IAAK,EAAA,AAUpC,QAAcC,WACZhZ,CAAsB,CACtB+Y,CAA8B,CAC9B,CACA,OAAO,IAAIH,EAAyC5Y,EAAO,CACzD8Y,SAAU,CAAC,cACXC,CACF,EACF,CAIAva,YACE8J,CAA8B,CAC9B,aAAEyQ,CAAW,WAAEE,CAAS,UAAEH,CAAQ,CAAiC,CACnE,CACA,IAAI,CAACxQ,QAAQ,CAAGA,EAChB,IAAI,CAACyQ,WAAW,CAAGA,EACnB,IAAI,CAACD,QAAQ,CAAGA,EAChB,IAAI,CAACG,SAAS,CAAGA,CACnB,CAEOC,eAAeJ,CAAkB,CAAE,CACxC3V,OAAOgW,MAAM,CAAC,IAAI,CAACL,QAAQ,CAAEA,EAC/B,CAMA,IAAWM,QAAkB,CAC3B,OAAO,AAAkB,WAAd,CAAC9Q,QAAQ,AACtB,CAMA,IAAW+Q,WAAqB,CAC9B,MAAgC,UAAzB,OAAO,IAAI,CAAC/Q,QACrB,AAD6B,CAYtBgR,kBAAkBvU,GAAS,CAAK,CAA4B,CACjE,GAAsB,MAAM,CAAxB,IAAI,CAACuD,QAAQ,CAGf,MAAO,GAGT,GAA6B,UAAzB,OAAO,IAAI,CAACA,QAAQ,CAAe,CACrC,GAAI,CAACvD,EACH,MADW,AACL,OAAA,cAEL,CAFK,IAAIwD,EAAAA,cAAc,CACtB,mEADI,oBAAA,OAAA,mBAAA,eAAA,EAEN,GAGF,MAAO4F,CAAAA,EAAAA,EAAAA,cAAAA,AAAc,EAAC,IAAI,CAACQ,QAAQ,CACrC,CAEA,OAAO,IAAI,CAACrG,QAAQ,AACtB,CAKA,IAAYqG,UAAuC,QACjD,AAAsB,MAAM,CAAxB,IAAI,CAACrG,QAAQ,CAGR,IAAIkG,eAA2B,CACpCtL,MAAMuL,CAAU,EACdA,EAAWC,KAAK,EAClB,CACF,GAGE,AAAyB,UAAU,OAA5B,IAAI,CAACpG,QAAQ,CACf2F,GAAAA,EAAAA,gBAAAA,AAAgB,EAAC,IAAI,CAAC3F,QAAQ,EAGnCkH,OAAO+J,QAAQ,CAAC,IAAI,CAACjR,QAAQ,EACxB0F,CAD2B,AAC3BA,EAAAA,EAAAA,gBAAAA,AAAgB,EAAC,IAAI,CAAC1F,QAAQ,EAInC1B,MAAM4S,OAAO,CAAC,IAAI,CAAClR,QAAQ,EACtBgF,CADyB,AACzBA,EAAAA,EAAAA,YAAY,AAAZA,KAAgB,IAAI,CAAChF,QAAQ,EAG/B,IAAI,CAACA,QAAQ,AACtB,CAQQmR,QAAuC,QAC7C,AAAsB,MAAM,CAAxB,IAAI,CAACnR,QAAQ,CAGR,EAAE,CAGkB,UAAzB,AAAmC,OAA5B,IAAI,CAACA,QAAQ,CACf,CAAC2F,CAAAA,EAAAA,EAAAA,gBAAAA,AAAgB,EAAC,IAAI,CAAC3F,QAAQ,EAAE,CAC/B1B,MAAM4S,OAAO,CAAC,IAAI,CAAClR,QAAQ,EAC7B,CADgC,GAC5B,CAACA,QAAQ,CACXkH,OAAO+J,QAAQ,CAAC,IAAI,CAACjR,QAAQ,EAC/B,CADkC,AACjC0F,CAAAA,EAAAA,EAAAA,gBAAAA,AAAgB,EAAC,IAAI,CAAC1F,QAAQ,EAAE,CAEjC,CAAC,IAAI,CAACA,QAAQ,CAAC,AAE1B,CAUOoR,QAAQ/K,CAAoC,CAAQ,CAEzD,IAAI,CAACrG,QAAQ,CAAG,IAAI,CAACmR,MAAM,GAG3B,IAAI,CAACnR,QAAQ,CAACoR,OAAO,CAAC/K,EACxB,CAUO1O,KAAK0O,CAAoC,CAAQ,CAEtD,IAAI,CAACrG,QAAQ,CAAG,IAAI,CAACmR,MAAM,GAG3B,IAAI,CAACnR,QAAQ,CAACrI,IAAI,CAAC0O,EACrB,CASA,MAAaE,OAAO5I,CAAoC,CAAiB,CACvE,GAAI,CACF,MAAM,IAAI,CAAC0I,QAAQ,CAACE,MAAM,CAAC5I,EAAU,CAKnC6I,cAAc,CAChB,GAII,IAAI,CAACmK,SAAS,EAAE,MAAM,IAAI,CAACA,SAAS,CAGxC,MAAMhT,EAASyI,KAAK,EACtB,CAAE,MAAOxQ,EAAK,CAIZ,GAAIuZ,CAAAA,EAAAA,EAAAA,YAAY,AAAZA,EAAavZ,GAAM,YAErB,MAAM+H,EAASmQ,KAAK,CAAClY,EAQvB,OAAMA,CACR,CACF,CAQA,MAAawZ,mBAAmBrU,CAAmB,CAAE,CACnD,MAAMqU,CAAAA,EAAAA,EAAAA,kBAAAA,AAAkB,EAAC,IAAI,CAAC/I,QAAQ,CAAEtL,EAAK,IAAI,CAAC4V,SAAS,CAC7D,CACF,wGC7UkBU,YAAAA,qCAAAA,KAAX,IAAWA,EAAAA,GAGf,IAHeA,GAGf,EAHeA,AAGf,GAAA,CAAA,OAHeA,CAOf,EAAA,AAPeA,OAOf,EAAA,CAAA,YAKA,EAAA,OAAA,CAAA,CAAA,WAKA,EAAA,OAAA,EAAA,CAAA,YAKA,EAAA,KAAA,CAAA,CAAA,OAtBeA,2FCaIC,sBAAsB,CAAA,kBAAtBA,GAkENC,+BAA+B,CAAA,kBAA/BA,GAtCMC,oBAAoB,CAAA,kBAApBA,+EAlCf,CAAA,CAAA,IAAA,UAEkB,CAAA,CAAA,IAAA,oCACC,CAAA,CAAA,IAAA,MACe,CAAA,CAAA,IAAA,GAElC,eAAeF,EACpBG,CAA8B,MAK1BA,EAQIA,EAXR,MAAO,CACL,GAAGA,CAAU,CACb/Z,MACE+Z,CAAgB,AAAhBA,OAAAA,EAAAA,EAAW/Z,KAAK,AAALA,EAAK,KAAA,EAAhB+Z,EAAkBC,IAAAA,AAAI,IAAKvR,EAAAA,eAAe,CAACwR,KAAK,CAC5C,CACED,KAAMvR,EAAAA,eAAe,CAACwR,KAAK,CAC3BC,KAAM,MAAMH,EAAW/Z,KAAK,CAACka,IAAI,CAACZ,iBAAiB,EAAC,GACpDa,SAAUJ,EAAW/Z,KAAK,CAACma,QAAQ,CACnCvU,QAASmU,EAAW/Z,KAAK,CAAC4F,OAAO,CACjCF,OAAQqU,EAAW/Z,KAAK,CAAC0F,MAC3B,AADiC,EAEjCqU,CAAAA,AAAgB,OAAhBA,EAAAA,EAAW/Z,KAAAA,AAAK,EAAA,KAAA,EAAhB+Z,EAAkBC,IAAAA,AAAI,IAAKvR,EAAAA,eAAe,CAAC2R,QAAQ,CACjD,CACEJ,KAAMvR,EAAAA,eAAe,CAAC2R,QAAQ,CAC9BF,KAAM,MAAMH,EAAW/Z,KAAK,CAACka,IAAI,CAACZ,iBAAiB,EAAC,GACpDe,UAAWN,EAAW/Z,KAAK,CAACqa,SAAS,CACrCC,QAASP,EAAW/Z,KAAK,CAACsa,OAAO,CACjC1U,QAASmU,EAAW/Z,KAAK,CAAC4F,OAAO,CACjCF,OAAQqU,EAAW/Z,KAAK,CAAC0F,MAAM,CAC/B6U,YAAaR,EAAW/Z,KAAK,CAACua,WAAW,AAC3C,EACAR,EAAW/Z,KACrB,AAD0B,CAE5B,CAEO,eAAe8Z,EACpBxR,CAA8C,MAS1CA,EAWIA,SAlBR,AAAKA,EAEE,CACLkS,CAHE,MAAW,AAGLlS,EAASkS,MAAM,CACvBC,QAASnS,EAASmS,OAAO,CACzBC,aAAcpS,EAASoS,YAAY,CACnC1a,MACEsI,CAAc,AAAdA,OAAAA,EAAAA,EAAStI,KAAAA,AAAK,EAAA,KAAA,EAAdsI,EAAgB0R,IAAAA,AAAI,IAAKvR,EAAAA,eAAe,CAACwR,KAAK,CACzC,CACCD,KAAMvR,EAAAA,eAAe,CAACwR,KAAK,CAC3BC,KAAMtB,EAAAA,OAAY,CAACI,UAAU,CAC3B1Q,EAAStI,KAAK,CAACka,IAAI,CACnBS,EAAAA,wBAAwB,EAE1BR,SAAU7R,EAAStI,KAAK,CAACma,QAAQ,CACjCvU,QAAS0C,EAAStI,KAAK,CAAC4F,OAAO,CAC/BF,OAAQ4C,EAAStI,KAAK,CAAC0F,MACzB,AAD+B,EAE/B4C,CAAAA,AAAc,OAAdA,EAAAA,EAAStI,KAAAA,AAAK,EAAA,KAAA,EAAdsI,EAAgB0R,IAAAA,AAAI,IAAKvR,EAAAA,eAAe,CAAC2R,QAAQ,CAC9C,CACCJ,KAAMvR,EAAAA,eAAe,CAAC2R,QAAQ,CAC9BF,KAAMtB,EAAAA,OAAY,CAACI,UAAU,CAC3B1Q,EAAStI,KAAK,CAACka,IAAI,CACnBS,EAAAA,wBAAwB,EAE1BL,QAAShS,EAAStI,KAAK,CAACsa,OAAO,CAC/B1U,QAAS0C,EAAStI,KAAK,CAAC4F,OAAO,CAC/BF,OAAQ4C,EAAStI,KAAK,CAAC0F,MAAM,CAC7B2U,UAAW/R,EAAStI,KAAK,CAACqa,SAAS,CACnCE,YAAajS,EAAStI,KAAK,CAACua,WAAW,AACzC,EACAjS,EAAStI,KAAK,AACxB,EAhCsB,IAiCxB,CAEO,SAAS6Z,EACde,CAAoB,EAEpB,OAAQA,GACN,KAAKjB,EAAAA,SAAS,CAACM,KAAK,CAClB,OAAOvR,EAAAA,oBAAoB,CAACuR,KAAK,AACnC,MAAKN,EAAAA,SAAS,CAACS,QAAQ,CACrB,OAAO1R,EAAAA,oBAAoB,CAAC0R,QAAQ,AACtC,MAAKT,EAAAA,SAAS,CAACkB,KAAK,CAClB,OAAOnS,EAAAA,oBAAoB,CAACmS,KAC9B,AADmC,MAC9BlB,EAAAA,SAAS,CAACmB,SAAS,CACtB,OAAOpS,EAAAA,oBAAoB,CAACoS,SAC9B,AADuC,MAClCnB,EAAAA,SAAS,CAACoB,SAAS,CAEtB,MAAM,OAAA,cAA+C,CAA/C,AAAIxc,MAAM,CAAC,sBAAsB,EAAEqc,EAAAA,CAAW,EAA9C,oBAAA,OAAA,kBAAA,eAAA,EAA8C,EACtD,SACE,OAAOA,CACX,CACF,iHC9EA,UAAA,qCAAqBI,aAXG,CAAA,CAAA,IAAA,OACW,CAAA,CAAA,IAAA,OAK5B,CAAA,CAAA,IAAA,OAGO,CAAA,CAAA,IAAA,KAAA,uKAEC,OAAMA,EAqCnBxc,YAAYyc,CAAqB,CAAE,MApClBC,UAAAA,CAAalS,EAAAA,OAAO,CAACI,MAAM,CAI1C,CAGAH,WAAY,CAAC,KAAElJ,CAAG,sBAAEob,CAAoB,CAAE,GACxC,CAAA,EAAGpb,EAAI,CAAC,EAAEob,EAAuB,IAAM,IAAA,CAAK,CAI9CjS,YAAakS,EAAAA,kBAAkB,AACjC,QAEiBC,iBAAAA,CAAoBrS,EAAAA,OAAO,CAACI,MAAM,CAGjD,CAIAF,YAAakS,EAAAA,kBAAkB,AACjC,GAcE,IAAI,CAACH,YAAY,CAAGA,CACtB,CAUA,MAAa1W,IACXxE,CAAkB,CAClBub,CAAoC,CACpCnd,CAQC,CACmC,KAalC,EAVF,GAAI,CAAC4B,EACH,GADQ,IACDub,EAAkB,CACvBC,aAAa,EACbC,mBAAoB,IACtB,GAIF,GACE,IAAI,CAACP,YAAY,EACjB,CAAA,AAAsB,OAAtB,EAAA,IAAI,CAACQ,iBAAAA,AAAiB,EAAA,KAAA,EAAtB,EAAwB1b,GAAAA,AAAG,IAAKA,GAChC,IAAI,CAAC0b,iBAAiB,CAACC,SAAS,CAAGC,KAAKpZ,GAAG,GAE3C,CADA,KACOuX,GAAAA,EAAAA,oBAAAA,AAAoB,EAAC,IAAI,CAAC2B,iBAAiB,CAACjT,KAAK,EAG1D,GAAM,kBACJoT,CAAgB,sBAChBT,GAAuB,CAAK,YAC5BU,GAAa,CAAK,mBAClBC,GAAoB,CAAK,YACzBC,GAAa,CAAK,WAClB9C,CAAS,WACT2B,CAAS,CACV,CAAGzc,EAEEmK,EAAW,MAAM,IAAI,CAAC4S,UAAU,CAAC7R,KAAK,CAC1C,KAAEtJ,uBAAKob,CAAqB,EAC5B,CAAC,SAAEvS,CAAO,CAAE,IACV,IAAMrL,EAAU,IAAI,CAACye,SAAS,CAC5Bjc,EACAub,EACA,kBACEM,uBACAT,EACAU,+BACAC,aACAC,YACAnB,CACF,EACAhS,GAMF,OAFIqQ,GAAWA,EAAU1b,GAElBA,CACT,GAGF,MAAOuc,CAAAA,EAAAA,EAAAA,oBAAAA,AAAoB,EAACxR,EAC9B,CAWA,MAAc0T,UACZjc,CAAW,CACXub,CAAoC,CACpCnd,CAOC,CACDyK,CAA8D,CACf,CAC/C,IAAIqT,EACF,KACEC,GAAW,EAEf,GAAI,CAUF,GARAD,AAQIA,GAR4B,AAAC,IAAI,CAAChB,YAAY,CAM9C,KALA,MAAM9c,EAAQyd,gBAAgB,CAACrX,GAAG,CAACxE,EAAK,CACtCia,KAAMH,CAAAA,EAAAA,EAAAA,+BAAAA,AAA+B,EAAC1b,EAAQyc,SAAS,EACvDkB,kBAAmB3d,EAAQ2d,iBAAiB,CAC5CD,WAAY1d,EAAQ0d,UAAU,AAChC,EACA,GAEiC,CAAC1d,EAAQgd,oBAAoB,EAAE,CAClEvS,EAAQqT,GACRC,GAAW,EAEP,CAACD,EAA8BxB,OAAO,EAAItc,EAAQ4d,UAAU,EAAE,AAEhE,OAAOE,EAKX,IAAME,EAAgC,MAAM,IAAI,CAACC,UAAU,CACzDrc,EACA5B,EAAQyd,gBAAgB,CACxBzd,EAAQ2d,iBAAiB,CACzB3d,EAAQ0d,UAAU,CAClBP,EACAW,EACkC,OAAlCA,GAA0C,CAAC9d,EAAQgd,oBAAoB,EAIzE,GAAI,CAACgB,EAGH,OADI,IAAI,CAAClB,YAAY,GAAE,EAFW,EAEP,CAACQ,iBAAiB,MAAGjZ,CAAAA,EACzC,KAQT,OAJIrE,EAAQgd,oBAAoB,CAIzBgB,CACT,CAAE,CALoC,CAACD,IAK9Bhe,EAAK,CAGZ,GAR+C,AAQ3Cge,EAEF,OADAG,CADY,OACJ1d,KAAK,CAACT,GACP,IAGT,OAAMA,CACR,CACF,CAcA,MAAake,WACXrc,CAAW,CACX6b,CAA0C,CAC1CE,CAA0B,CAC1BD,CAAmB,CACnBP,CAAoC,CACpCW,CAAmE,CACnEV,CAAoB,CACpBtC,CAAwC,CACxC,CACA,OAAO,IAAI,CAACoC,iBAAiB,CAAChS,KAAK,CAACtJ,EAAK,KACvC,IAAMxC,EAAU,IAAI,CAAC+e,gBAAgB,CACnCvc,EACA6b,EACAE,EACAD,EACAP,EACAW,EACAV,GAMF,OAFItC,GAAWA,EAAU1b,GAElBA,CACT,EACF,CAEA,MAAc+e,iBACZvc,CAAW,CACX6b,CAA0C,CAC1CE,CAA0B,CAC1BD,CAAmB,CACnBP,CAAoC,CACpCW,CAAmE,CACnEV,CAAoB,CACpB,CACA,GAAI,CAEF,IAAMgB,EAAqB,MAAMjB,EAAkB,CACjDC,cACAC,mBAAoBS,EACpBO,gBAAgB,CAClB,GACA,GAAI,CAACD,EACH,OAAO,KAIT,IAAMJ,EALmB,AAKa,MAAMvC,CAAAA,EAAAA,EAAAA,sBAAAA,AAAsB,EAAC,CACjE,GAAG2C,CAAkB,CACrB/B,OAAQ,CAACyB,CACX,GAoBA,OAhBIE,EAA8BzB,YAAY,EAAE,CAC1C,IAAI,CAACO,YAAY,CACnB,CADqB,GACjB,CAACQ,iBAAiB,CAAG,KACvB1b,EACAyI,MAAO2T,EACPT,UAAWC,KAAKpZ,GAAG,GAAK,GAC1B,EAEA,MAAMqZ,EAAiB/b,GAAG,CAACE,EAAKoc,EAA8Bnc,KAAK,CAAE,CACnE0a,aAAcyB,EAA8BzB,YAAY,mBACxDoB,aACAD,CACF,IAIGM,CACT,CAAE,MAAOje,EAAK,CAGZ,GAAI+d,MAAAA,EAAAA,KAAAA,EAAAA,EAA+BvB,YAAY,CAAE,CAC/C,IAAM0B,EAAaK,KAAKC,GAAG,CACzBD,KAAKE,GAAG,CACNV,EAA8BvB,YAAY,CAAC0B,UAAU,EAAI,EACzD,GAEF,IAEIQ,OACkDpa,IAAtDyZ,EAA8BvB,YAAY,CAACkC,MAAM,MAC7Cpa,EACAia,KAAKE,GAAG,CACNP,EAAa,EACbH,EAA8BvB,YAAY,CAACkC,MAAM,CAGzD,OAAMhB,EAAiB/b,GAAG,CAACE,EAAKkc,EAA8Bjc,KAAK,CAAE,CACnE0a,aAAc,CAAE0B,WAAYA,EAAYQ,OAAQA,CAAO,oBACvDd,aACAD,CACF,EACF,CAGA,MAAM3d,CACR,CACF,CACF,wFClSa2e,iBAAiB,CAAA,kBAAjBA,GA+MGC,oBAAoB,CAAA,kBAApBA,GAw/BAC,UAAU,CAAA,kBAAVA,GAjsCAC,kBAAkB,CAAA,kBAAlBA,GA8BAC,YAAY,CAAA,kBAAZA,+EA1EkC,CAAA,CAAA,IAAA,OACd,CAAA,CAAA,IAAA,OAM7B,CAAA,CAAA,IAAA,OACmC,CAAA,CAAA,IAAA,OACP,CAAA,CAAA,IAAA,MAED,CAAA,CAAA,IAAA,OAK3B,CAAA,CAAA,IAAA,OAOA,CAAA,CAAA,IAAA,OACuB,CAAA,CAAA,IAAA,KAEF,CAAA,CAAA,IAAA,GAYrB,IAAMJ,EAAoBzH,OAAOC,GAAG,CAAC,cAMrC,SAAS2H,EACdI,CAAsB,CACtBC,CAAa,EAEb,GAAI,CACF,IAAIC,EAEJ,IAAsB,IAAlBF,EACFE,CAD2B,CACJC,EAAAA,OAHsB/a,OAGR,MAChC,GACoB,UAAzB,OAAO4a,GACP,CAACI,MAAMJ,IACPA,EAAgB,CAAC,EAEjBE,CADA,CACuBF,OAClB,GAA6B,AAAzB,SAAOA,EAChB,EAD+C,IACzC,OAAA,cAEL,CAFK,AAAI7e,MACR,CAAC,0BAA0B,EAAE6e,EAAc,MAAM,EAAEC,EAAM,yCAAyC,CAAC,EAD/F,oBAAA,OAAA,mBAAA,gBAAA,CAEN,GAEF,OAAOC,CACT,CAAE,MAAOpf,EAAU,CAEjB,GAAIA,aAAeK,OAASL,EAAIkB,OAAO,CAACqC,QAAQ,CAAC,sBAC/C,CADsE,KAChEvD,EAER,MACF,CADSsE,AAEX,CAEO,SAASya,EAAaQ,CAAW,CAAEC,CAAmB,EAC3D,IAAMC,EAAsB,EAAE,CACxBC,EAGD,EAAE,CAEP,IAAK,IAAIxV,EAAI,EAAGA,EAAIqV,EAAKra,MAAM,CAAEgF,IAAK,CACpC,IAAMyV,EAAMJ,CAAI,CAACrV,EAAE,CAanB,GAXmB,UAAf,AAAyB,OAAlByV,EACTD,EAAY3d,IAAI,CAAC,KAAE4d,EAAKC,OAAQ,gCAAiC,GACxDD,EAAIza,MAAM,CAAG2a,EAAAA,yBAAyB,CAC/CH,CADiD,CACrC3d,IAAI,CAAC,KACf4d,EACAC,OAAQ,CAAC,uBAAuB,EAAEC,EAAAA,yBAAyB,CAAA,CAAE,AAC/D,GAEAJ,EAAU1d,IAAI,CAAC4d,GAGbF,EAAUva,MAAM,CAAG4a,EAAAA,wBAAwB,CAAE,CAC/C3B,QAAQ4B,IAAI,CACV,CAAC,oCAAoC,EAAEP,EAAY,eAAe,CAAC,CACnED,EAAKhT,KAAK,CAACrC,GAAGiF,IAAI,CAAC,OAErB,KACF,CACF,CAEA,GAAIuQ,EAAYxa,MAAM,CAAG,EAGvB,CAH0B,GAGrB,GAAM,KAAEya,CAAG,QAAEC,CAAM,CAAE,GAF1BzB,QAAQ4B,IAAI,CAAC,CAAC,gCAAgC,EAAEP,EAAY,EAAE,CAAC,EAEjCE,GAC5BvB,QAAQ6B,CADiC,EAC9B,CAAC,CAAC,MAAM,EAAEL,EAAI,EAAE,EAAEC,EAAAA,CAAQ,EAGzC,OAAOH,CACT,CAEA,SAASQ,EACPC,CAAoB,CACpBC,CAAqC,EAEhCD,EAAUE,uBAAuB,EAAE,CAIxCF,EAAUG,YAAY,GAAK,EAAE,CAE7BH,EAAUG,YAAY,CAACte,IAAI,CAAC,CAC1B,GAAGoe,CAAG,CACNhf,IAAKiD,YAAYkc,UAAU,CAAGlc,YAAYC,GAAG,GAC7Ckc,IAAKL,EAAUM,WAAW,EAAI,CAChC,GACF,CAEA,eAAeC,EACbtb,CAAa,CACb0E,CAAgB,CAChB6W,CAAoE,CACpEhD,CAAkC,CAClCQ,CAAkB,CAClByC,CAAwC,EAKxC,IAAMC,EAAa,MAAMzb,EAAI0b,WAAW,GAElCC,EAAc,CAClBpZ,QAASzC,OAAO8b,WAAW,CAAC5b,EAAIuC,OAAO,CAACpF,OAAO,IAC/C4E,KAAMoK,OAAO3I,IAAI,CAACiY,GAAY/R,QAAQ,CAAC,UACvCrH,OAAQrC,EAAIqC,MAAM,CAClBI,IAAKzC,EAAIyC,GAAG,AACd,EAgBA,OAXI8Y,GACF,MAAMhD,EAAiB/b,GAAG,CACxBkI,EACA,CAAEiS,KAAMvR,EAAAA,AAHiB,eAGF,CAACyW,KAAK,CAAEC,KAAMH,aAAa5C,CAAW,EAC7DwC,GAIJ,MAAMC,IAGC,IAAIpZ,SAASqZ,EAAY,CAC9BlZ,QAASvC,EAAIuC,OAAO,CACpBF,OAAQrC,EAAIqC,MAAM,CAClBC,WAAYtC,EAAIsC,UAAU,AAC5B,EACF,CAEA,eAAeyZ,EACbhB,CAAoB,CACpB/a,CAAa,CACb0E,CAAgB,CAChB6W,CAAoE,CACpEhD,CAAkC,CAClCyD,CAA8D,CAC9DjD,CAAkB,CAClBkD,CAAwB,CACxBT,CAAwC,EAKxC,GAAM,CAACrZ,EAASY,EAAQ,CAAG1B,CAAAA,EAAAA,EAAAA,aAAAA,AAAa,EAACrB,GAKnCkc,EAAkB/Z,EACrBuZ,WAAW,GACXvhB,IAAI,CAAC,MAAOuhB,IACX,IAAMD,EAAatP,OAAO3I,IAAI,CAACkY,GAEzBC,EAAc,CAClBpZ,QAASzC,OAAO8b,WAAW,CAACzZ,EAAQI,OAAO,CAACpF,OAAO,IACnD4E,KAAM0Z,EAAW/R,QAAQ,CAAC,UAC1BrH,OAAQF,EAAQE,MAAM,CACtBI,IAAKN,EAAQM,GACf,AADkB,CAGlBuZ,OAAAA,GAAAA,EAAAA,AAA0Bxf,GAAG,CAACkI,EAAUiX,GAEpCJ,GACF,MAAMhD,EAAiB/b,GAAG,CACxBkI,EACA,CAAEiS,KAAMvR,EAHiB,AAGjBA,eAAe,CAACyW,KAAK,CAAEC,KAAMH,aAAa5C,CAAW,EAC7DwC,EAGN,GACCtb,KAAK,CAAC,AAAC3E,GAAU0d,QAAQ4B,IAAI,CAAC,CAAC,yBAAyB,CAAC,CAAEqB,EAAO3gB,IAClE4E,OAAO,CAACsb,GAELW,EAAuB,CAAC,UAAU,EAAEzX,EAAAA,CAAU,CAqBpD,OApBAqW,EAAUqB,kBAAkB,GAAK,CAAC,EAE9BD,KAAwBpB,EAAUqB,kBAAkB,EAAE,AAGxD,MAAMrB,EAAUqB,kBAAkB,CAACD,EAAqB,CAG1DpB,EAAUqB,kBAAkB,CAACD,EAAqB,CAAGD,EAAgBhc,OAAO,CAC1E,SAGO6a,GAA4B,AAA7B,OAACA,EAAAA,EAAUqB,kBAAAA,AAAkB,EAAA,KAAA,EAA5BrB,CAA8B,CAACoB,EAAAA,AAAqB,GAAE,AAI3D,OAAOpB,EAAUqB,kBAAkB,CAACD,EAAqB,AAC3D,GAGKpZ,CACT,CAOO,SAAS0W,EACd4C,CAAoB,CACpB,kBAAEC,CAAgB,sBAAEC,CAAoB,CAAmB,EAG3D,IAAMC,EAAU,eAAeC,AAC7BR,CAAwB,CACxBS,CAA6B,MAYdA,EAIKA,MAdhBja,EACJ,GAAI,CAEFA,CADAA,EAAM,IAAIkC,IAAIsX,aAAiBrX,QAAUqX,EAAMxZ,GAAG,CAAGwZ,EAAAA,EACjDU,QAAQ,CAAG,GACfla,EAAIma,QAAQ,CAAG,EACjB,CAAE,KAAM,CAENna,OAAMtD,CACR,CACA,IAAM0d,EAAWpa,CAAAA,QAAAA,KAAAA,EAAAA,EAAKqa,IAAAA,AAAI,GAAI,GACxBlZ,EAAS8Y,CAAAA,MAAAA,CAAAA,EAAAA,AAAY,GAAZA,GAAAA,GAAAA,EAAM9Y,MAAAA,AAAM,EAAA,KAAA,EAAZ8Y,EAAcK,WAAW,EAAA,GAAM,MAIxCC,EAAa,CAACN,MAAAA,CAAAA,EAAU,AAAVA,GAAAA,IAAAA,EAAAA,EAAMO,IAAAA,AAAI,EAAA,KAAA,EAAVP,EAAoBQ,QAAQ,KAAK,EAC/C5e,EAAoD,MAAzC5D,QAAQC,GAAG,CAACwiB,wBAAwB,CAK/CC,EAAiCJ,EACnC7d,OACAF,YAAYkc,UAAU,CAAGlc,YAAYC,GAAG,GAEtC6b,EAAYuB,EAAiBe,QAAQ,GACrCC,EAAgBf,EAAqBc,QAAQ,GAE/CE,EAAcD,EAAgBE,CAAAA,EAAAA,EAAAA,cAAAA,AAAc,EAACF,GAAiB,KAC9DC,GACFA,EAAYE,QADG,CACM,GAGvB,IAAMpiB,EAASd,CAAAA,EAAAA,EAAAA,SAAAA,AAAS,IAAGS,KAAK,CAC9BgiB,EAAavjB,EAAAA,kBAAkB,CAACikB,aAAa,CAAGvkB,EAAAA,aAAa,CAACsjB,KAAK,CACnE,UACEne,EACAqY,KAAMtc,EAAAA,QAAQ,CAACsjB,MAAM,CACrBxf,SAAU,CAAC,QAASyF,EAAQiZ,EAAS,CAACpZ,MAAM,CAACma,SAAS5T,IAAI,CAAC,KAC3DpL,WAAY,CACV,WAAYie,EACZ,cAAejZ,EACf,eAAe,CAAEnB,MAAAA,EAAAA,KAAAA,EAAAA,EAAKob,QAAQ,CAC9B,gBAAiBpb,CAAAA,MAAAA,EAAAA,KAAAA,EAAAA,EAAKqb,IAAAA,AAAI,QAAI3e,CAChC,CACF,EACA,cA6LIyS,MA9IE0M,EAgEAS,EAqTAra,EAGAsX,EAiMA0E,EA1kBAxC,EA5BJ,GAAIlB,GAOA,CAACjC,GAMDA,EAAUgD,GAbE,CA4B0B5e,EArB1B,KAMS,CAZvB,CAYyB,MAZlBkd,EAAYJ,EAAOS,GAgB5B,IAAMsB,EACJ/B,GACA,AAAiB,iBAAVA,GAC8B,AAArC,iBAAQA,EAAkBrY,MAAM,CAE5BgO,EAAiB,AAACqM,GAGfthB,CADQ+f,MAAAA,EAAAA,AACEsB,KADFtB,EAAAA,CAAc,CAACuB,EAAAA,AAAM,IACnBD,EAAkB/B,CAAa,CAACgC,EAAM,CAAG,IAAA,CAAG,CAIzDE,EAAe,AAACF,QACNvB,EACVA,EAEE,EAHN,OAAO,KAA+B,EAA/B,GAAOA,MAAAA,CAAAA,EAAU,AAAVA,GAAAA,GAAAA,GAAAA,EAAMO,IAAI,AAAJA,EAAI,KAAA,EAAVP,CAAY,CAACuB,EAAM,EAC7BvB,MAAAA,CAAAA,EAAU,AAAVA,GAAAA,IAAAA,EAAAA,EAAMO,IAAAA,AAAI,EAAA,KAAA,EAAVP,CAAY,CAACuB,EAAM,CACnBD,EAAAA,AACqB,OAAnB,EAAC/B,EAAcgB,IAAAA,AAAI,EAAA,KAAA,EAAnB,CAAqB,CAACgB,EAAM,CAC5B9e,MACR,EAGMif,EAA0BD,EAAa,cACzCE,EAAyBD,EACvBhE,EAAiBR,EACrBuE,EAAa,SAAW,EAAE,CAC1B,CAAC,MAAM,EAAElC,EAAMvS,QAAQ,GAAA,CAAI,EAK7B,GAAI4T,EACF,OAAQA,EAAcvf,IADL,AACS,EACxB,IAAK,YACL,IAAK,oBAEL,IAAK,mBACL,IAAK,gBACL,IAAK,mBACL,IAAK,QACL,IAAK,gBACHugB,EAAkBhB,CAOtB,CAGF,GAAIgB,GACE/a,MAAM4S,OAAO,CADE,AACDiE,GAAO,CAEvB,IAAMmE,EACJD,EAAgBlE,IAAI,GAAKkE,CAAAA,CAAgBlE,IAAI,CAAG,EAAA,AAAC,EACnD,IAAK,IAAMI,KAAOJ,EACZ,AAACmE,EAAcngB,CADG,OACK,CAACoc,IAC1B+D,EADgC,AAClB3hB,IAAI,CAAC4d,EAGzB,CAGF,IAAMgE,EAAelB,MAAAA,EAAAA,KAAAA,EAAAA,EAAekB,YAAY,CAE5CC,EAAqB1D,EAAU2D,UAAU,CAEzCpB,GAEK,YAFU,OACTA,EAAcvf,IAAI,GAItB0gB,EAAqB,gBAAA,EAgB3B,IAAME,EAAiB,CAAC,CAAC5D,EAAU6D,iBAAiB,CAEhDC,EAA0BjN,EAAe,SACzCkN,EAAc,GAImB,UAAnC,OAAOD,GACP,KAAkC,IAA3BR,IAKJQ,AAA4B,KAJ/B,MAGyC,QAEV,IAA3BR,CACF,EAC6B,aAA5BQ,CACER,GAAAA,EAAyB,IAAgC,IAA3BA,CAA2B,CAAI,IAGhEU,EAAe,CAAC,kBAAkB,EALwB,AAKtBF,EAAwB,mBAAmB,EAAER,EAAuB,gCAAgC,CAAC,CACzIQ,OAA0B1f,EAC1Bkf,EAAyBlf,QAI7B,IAAM8f,EAEwB,aAA5BJ,GAC4B,aAA5BA,CAF2C,AAG3C,EAEuB,AAAvBJ,sBACAA,AAAuB,oBAOnBS,EACJ,CAACT,GACD,CAACI,GACD,CAACR,GACDtD,EAAUoE,YAKVN,AALsB,CAKM,mBAC5B,CApB6F,IAoB3D,IAA3BR,EAEPA,GAAyB,GAEzBY,CAHA,EAIAC,CAAAA,GACA,CACAb,GAAyB,GAIG,aAA5BQ,GAC4B,aAA5BA,CAA4B,GAC5B,CACAC,EAAc,CAAC,OAAO,EAAED,EAAAA,CAAAA,AAAyB,EAGnDX,EAAkBvE,EAChB0E,EACAtD,EAAUf,KAAK,EAGjB,IAAMoF,EAAWxN,EAAe,WAC1ByN,EACqB,YAAzB,OAAA,AAAOD,MAAAA,EAAAA,KAAAA,EAAAA,EAAUle,GAAAA,AAAG,EAChBke,EACA,IAAIE,QAAQF,GAAY,CAAC,GAEzBG,EACJF,EAAYne,GAAG,CAAC,kBAAoBme,EAAYne,GAAG,CAAC,UAEhDse,EAAsB,CAAC,CAAC,MAAO,OAAO,CAACphB,QAAQ,CACnDwT,CAAAA,AAAe,OAAfA,EAAAA,EAAe,SAAA,CAAA,CAAA,KAAA,EAAfA,EAA0BhS,WAAW,EAAA,CAAA,EAAM,OAavC6f,OAEkBtgB,GAAtBsf,SAE4Btf,AAHM,CAElC,EACC0f,GAGCA,AAA4B,OAF5B,MAE4B,CAAQ,KACtC,EAC0B1f,GAA1Bkf,EAEEqB,GAAc9B,AARkB,EASjC2B,CAAAA,GAAwBC,CAAAA,CAAkB,EACzClB,CAAAA,QAAAA,KAAAA,AALgC,EAKhCA,EAAiBvF,UAAAA,AAAU,KAAK,EAGhC4G,GAA2B,EAe/B,GAbI,CAACD,GAb8E,AAa/DD,IAId1E,EAAUvN,oBAJ8B,GAIP,CACnCmS,CADqC,EACV,EAE3BD,GAAc,GAMdD,QAA8CtgB,IAAlBme,EAC9B,KAD2D,EACnDA,EAAcvf,IAAI,EACxB,IAAK,YACL,IAAK,oBAIL,IAAK,mBAMH,OALIwf,IACFA,EAAYqC,OAAO,AADJ,GAEfrC,EAAc,MAGTsC,CAAAA,EAAAA,EAAAA,kBAAkB,AAAlBA,EACLvC,EAAcwC,YAAY,CAC1B/E,EAAUf,KAAK,CACf,UAwBN,CAGF,OAAQyE,GACN,IAAK,iBACHK,EAAc,8BACd,KAEF,KAAK,gBACH,GAC8B,gBAA5BD,GACC,KAA2B,IAApBX,GAAmCA,EAAkB,EAE7D,CADA,KACM,OAAA,cAEL,CAFK,AAAIhjB,MACR,CAAC,uCAAuC,EAAE2hB,EAAS,gDAAgD,CAAC,EADhG,oBAAA,OAAA,mBAAA,gBAAA,CAEN,GAEFiC,EAAc,6BACd,KAEF,KAAK,aACH,GAAgC,YAAY,CAAxCD,EACF,MAAM,OAAA,cAEL,CAFK,AAAI3jB,MACR,CAAC,oCAAoC,EAAE2hB,EAAS,6CAA6C,CAAC,EAD1F,oBAAA,OAAA,mBAAA,gBAAA,CAEN,GAEF,KAEF,KAAK,eAED,KAAkC,IAA3BwB,GACPA,KAA2B,GAC3B,CACAS,EAAc,2BACdZ,EAAkBhE,EAAAA,cAAc,CAetC,CA0BA,GAxBI,CA0BF,AADA,IAzB6B,IAApBgE,EACkB,OADe,QA0BjB,GAzBrBO,CAA0C,EAACE,EAGb,cAH6B,MAGT,AAqBD,CArB1CF,GACTP,EAAkB,EAClBY,EAAc,iCACLH,GACTT,EAAkB,EAClBY,EAAc,OAFW,SAGhBY,GACTxB,EAAkB,EAClBY,EAAc,IAFQ,cAKtBA,EAAc,aACdZ,EAAkBI,EACdA,EAAgBvF,UAAU,CAC1BmB,EAAAA,cAAc,GAhBlBgE,EAAkBhE,EAAAA,cAAc,CAChC4E,EAAc,8BAiBP,AAACA,IACVA,EAAc,CAAC,MADQ,MACI,EAAEZ,EAAAA,CAAAA,AAAiB,EAM9C,CAAEnD,GAAUqF,WAAW,MAAIlC,CAAoB,CAAA,EAE/C,CAACwB,EADD,CAKApB,GACAJ,EAAkBI,EAAgBvF,KAJlC,KAI4C,CAC5C,CAGA,GAAwB,IAApBmF,EAAuB,CACzB,GAAIZ,EACF,OAAQA,EAAcvf,IADL,AACS,EACxB,IAAK,OAbkD,KAcvD,IAAK,UAZwD,SAa7D,IAAK,oBAKH,OAJIwf,IACFA,EAAYqC,OADG,AACI,GACnBrC,EAAc,MAETsC,GAAAA,EAAAA,kBAAAA,AAAkB,EACvBvC,EAAcwC,YAAY,CAC1B/E,EAAUf,KAAK,CACf,UAwBN,CAGFqG,CAAAA,EAAAA,EAAAA,yBAAAA,AAAyB,EACvBtF,EACAuC,EACA,CAAC,oBAAoB,EAAErB,EAAM,CAAC,EAAElB,EAAUf,KAAK,CAAA,CAAE,CAErD,CAKIsE,GAAmBF,IAA4BF,IACjDI,EAAgBvF,UAAU,CADwC,AACrCmF,CAAAA,CAEjC,CAEA,IAAMoC,EACJ,AAA2B,iBAApBpC,GAAgCA,EAAkB,EAGrD,CAAE3F,kBAAgB,CAAE,CAAGwC,EACzBwF,GAAe,EAGnB,GAAIjD,EACF,OAAQA,EAAcvf,IADL,AACS,EACxB,IAAK,UACL,IAAK,QACL,IAAK,gBACHwiB,EAAejD,EAAciD,YAAY,EAAI,GAC7CvE,EAA2BsB,EAActB,wBAAwB,AAWrE,CAGF,GACEzD,IACC+H,GAAyBtE,CAAAA,CAAuB,CAEjD,EADA,CACI,CACFtX,EAAW,IAHZ4b,EAGkB/H,EAAiBnV,gBAAgB,CAChDyZ,EACAmB,EAAkB/B,EAAwBS,EAE9C,CAAE,MAAO7hB,EAAK,CACZme,QAAQ1d,KAAK,CAAC,CAAC,gCAAgC,CAAC,CAAE2gB,EACpD,CAGF,IAAMuE,EAAWzF,EAAUM,WAAW,EAAI,EAC1CN,EAAUM,WAAW,CAAGmF,EAAW,EAEnC,IAAIhF,EAA2C,KAAO,EAEhDiF,EAAkB,MACtBrJ,EACAsJ,KAEA,IAAMC,EAAqB,CACzB,QACA,cACA,UACA,YACA,YACA,SACA,OACA,WACA,WACA,iBACA,SACA,YAGIvJ,EAAU,EAAE,CAAG,CAAC,SAAS,CAC9B,CAED,GAAI4G,EAAgB,CAClB,IAAM4C,EAAoB3E,EACpB4E,EAA0B,CAC9B9e,KAAO6e,EAAiBE,OAAO,EAAIF,EAAS7e,IAAI,AAClD,EAEA,IAAK,IAAMkc,KAAS0C,EAElBE,CAAU,CAAC5C,EAAM,CAAG2C,CAAQ,CAAC3C,EAAM,CAErChC,EAAQ,IAAIrX,CAJ4B,OAIpBgc,EAASne,GAAG,CAAEoe,EACpC,MAAO,GAAInE,EAAM,CACf,GAAM,SAAEoE,CAAO,CAAE/e,MAAI,QAAE0C,CAAM,CAAE,GAAGsc,EAAY,CAC5CrE,EACFA,EAAO,CACL,GAAGqE,CAAU,CACbhf,KAAM+e,GAAW/e,EACjB0C,OAAQ2S,OAAUjY,EAAYsF,CAChC,CACF,CAGA,IAAMuc,EAAa,CACjB,GAAGtE,CAAI,CACPO,KAAM,IAAKP,MAAAA,EAAAA,KAAAA,EAAAA,EAAMO,IAAT,CAAegE,UAAW,kBAAUT,CAAS,CACvD,EAEA,OAAOnE,EAAYJ,EAAO+E,GACvB7mB,IAAI,CAAC,MAAO6F,IAeX,GAdI,CAACoX,GAAWgG,GACdtC,EAAiBC,EAAW,CAC1Blb,IAFwB,EAEjBud,EACP3a,IAAKoa,EACLiC,YAAa4B,GAAuB5B,EACpCoC,YACEhD,AAAoB,OAAKwC,EACrB,OACA,OACN3B,eACA1c,OAAQrC,EAAIqC,MAAM,CAClBuB,OAAQod,EAAWpd,MAAM,EAAI,KAC/B,GAGA5D,AAAe,QAAXqC,MAAM,EACVkW,GACA7T,IACC4b,GAAyBtE,CAAAA,CAAuB,CACjD,CACA,CAFCsE,GAEKrG,EACJiE,GAAmBhE,EAAAA,cAAc,CAC7BiH,EAAAA,cAAc,CACdjD,EAEAkD,EAEUd,EACZ,CACE5B,YAAY,WACZ7B,WACA2D,OACApG,EACAuF,0BACF,OACAxgB,EAEJ,OAAQme,MAAAA,EAAAA,KAAAA,EAAAA,EAAevf,IAAI,EACzB,IAAK,YACL,IAAK,mBACL,IAAK,oBACH,OAAOud,EACLtb,EACA0E,EACA0c,EACA7I,EACA0B,EACAuB,EAEJ,KAAK,UAkBL,IAAK,gBACL,IAAK,mBACL,IAAK,QACL,IAAK,gBACL,IAAK,iBACL,UAAKrc,EACH,OAAO4c,EACLhB,EACA/a,EACA0E,EACA0c,EACA7I,EACAyD,EACA/B,EACAgC,EACAT,EAIN,CACF,CAMA,OAFA,MAAMA,IAECxb,CACT,GACCC,KAAK,CAAC,AAAC3E,IAEN,MADAkgB,IACMlgB,CACR,EACJ,EAGI+lB,EAAyB,GACzBC,IAAoB,EAExB,GAAI5c,GAAY6T,EAAkB,CAChC,IAAIgJ,EAOJ,GALIhB,GAAgBvE,IAClBuF,EAAkBvF,EAAyB9a,GAAG,CAACwD,GAC/C4c,IAAoB,GAGlBhB,GAAyB,CAACiB,AALgB,EAKC,CAC7C/F,EAAe,MAAMjD,EAAiBiJ,IAAI,CAAC9c,GAC3C,IAAMS,EAAQ4V,EAAUjD,oBAAoB,CACxC,KACA,MAAMS,EAAiBrX,GAAG,CAACwD,EAAU,CACnCiS,KAAMtR,EAAAA,oBAAoB,CAACwW,KAAK,CAChC9C,WAAYmF,WACZrB,WACA2D,OACApG,EACAqH,QAAQ,CAAEjD,MAAAA,EAAAA,KAAAA,EAAAA,EAAcpE,IAAI,AAC9B,GAEJ,GAAIqF,GAA4BnC,EAC9B,OAAQA,EAAcvf,IADuB,AACnB,EACxB,IAAK,YACL,IAAK,mBACL,IAAK,oBAMH,MAAM2jB,CAqUlB,AAACU,GACHA,GAAyB,IAAI3c,QAAQ,AAAC4c,IACpCC,EAFyB,SAEd,KACTF,EAAyB,KACzBC,GACF,EAAG,EACL,EAAA,EAEKD,EAzTK,CAWF,GARIjd,EACF,KADS,CACHqW,IAINkF,EAAsB,yCAGpBvb,CAAAA,MAAAA,EAAAA,KAAAA,EAAAA,EAAOxI,KAAAA,AAAK,GAAIwI,EAAMxI,KAAK,CAACga,IAAI,GAAKvR,EAAAA,eAAe,CAACyW,KAAK,CAG5D,CAH8D,EAG1Dd,EAAU5J,kBAAkB,EAAIhM,EAAMiS,OAAO,CAC/CiK,CADiD,EACxB,MACpB,CACL,GAAIlc,EAAMiS,OAAO,EAAE,CACjB2D,EAAUqB,kBAAkB,GAAK,CAAC,EAC9B,CAACrB,EAAUqB,kBAAkB,CAAC1X,EAAS,EAAE,CAC3C,IAAMid,EAAoBlB,GAAgB,GACvCtmB,IAAI,CAAC,MAAO8K,IAAc,CACzBlD,KAAM,CADmB,KACbkD,EAASyW,WAAW,GAChCnZ,QAAS0C,EAAS1C,OAAO,CACzBF,OAAQ4C,EAAS5C,MAAM,CACvBC,WAAY2C,EAAS3C,UAAU,CACjC,CAAA,EACCpC,OAAO,CAAC,KACP6a,EAAUqB,kBAAkB,GAAK,CAAC,EAClC,OAAOrB,EAAUqB,kBAAkB,CAAC1X,GAAY,GAAG,AACrD,GAIFid,EAAkB1hB,KAAK,CAAC+Y,QAAQ1d,KAAK,EAErCyf,EAAUqB,kBAAkB,CAAC1X,EAAS,CAAGid,CAC3C,CAGFJ,EAAkBpc,EAAMxI,KAAK,CAACmf,IAAI,AACpC,CAEJ,CAEA,GAAIyF,EAAiB,CACfnE,GACFtC,EAAiBC,EAAW,CAC1Blb,IAFY,EAELud,EACP3a,IAAKoa,EACLiC,cACAoC,YAAaI,GAAoB,MAAQ,mBACzCvC,EACA1c,OAAQkf,EAAgBlf,MAAM,EAAI,IAClCuB,OAAQ8Y,CAAAA,QAAAA,KAAAA,EAAAA,EAAM9Y,MAAAA,AAAM,GAAI,KAC1B,GAGF,IAAMqB,EAAW,IAAI7C,SACnB+J,OAAO3I,IAAI,CAAC+d,EAAgBxf,IAAI,CAAE,UAClC,CACEQ,QAASgf,EAAgBhf,OAAO,CAChCF,OAAQkf,EAAgBlf,MAAM,AAChC,GAOF,OAJAvC,OAAO0C,cAAc,CAACyC,EAAU,MAAO,CACrCtI,MAAO4kB,EAAgB9e,GAAG,AAC5B,GAEOwC,CACT,CACF,CAEA,GACG8V,EAAU5J,kBAAkB,EAO7BuL,EANGhiB,CAOa,OAPLC,GAAG,AAOd,CAPeolB,MAORrD,EACP,AARuB,CASvB,GAAM,OAAEpY,CAAK,CAAE,CAAGoY,EAKlB,GAAIpY,AAAU,YAdc,GAcF,CAExB,GAAIgZ,EACF,OAAQA,CAhBR5iB,CAgBsBqD,IADL,AACS,EACxB,CAjBMpD,GAAG,AAiBJ,CAjBKinB,WAkBV,IAAK,QAlB4B,QACnCtE,GAkBE,IAAK,UAjBP,UAsBI,OAJIC,IACFA,EAAYqC,OAAO,AADJ,GAEfrC,EAAc,MAETsC,CAAAA,EAAAA,EAAAA,EAtBqC,gBAsBrCA,AAAkB,EACvBvC,EAAcwC,YAAY,CAC1B/E,EAAUf,KAAK,CACf,UAwBN,CAEFqG,CAAAA,EAAAA,EAAAA,yBAAAA,AAAyB,EACvBtF,EACAuC,EACA,CAAC,eAAe,EAAErB,EAAM,CAAC,EAAElB,EAAUf,KAAK,CAAA,CAAE,CAEhD,CAEA,IAAM6H,EAAgB,SAAUnF,EAC1B,MAAEO,EAAO,CAAC,CAAC,CAAE,CAAGP,EACtB,GAC6B,UAA3B,OAAOO,EAAKlE,UAAU,EACtBuF,GACArB,EAAKlE,UAAU,CAAGuF,EAAgBvF,UAAU,CAC5C,CACA,GAAwB,IAApBkE,EAAKlE,UAAU,CAAQ,CAEzB,GAAIuE,EACF,OAAQA,EAAcvf,IADL,AACS,EACxB,IAAK,YACL,IAAK,mBACL,IAAK,oBACH,MAAO8hB,GAAAA,EAAAA,kBAAkB,AAAlBA,EACLvC,EAAcwC,YAAY,CAC1B/E,EAAUf,KAAK,CACf,UAoBN,CAEFqG,GAAAA,EAAAA,yBAAAA,AAAyB,EACvBtF,EACAuC,EACA,CAAC,oBAAoB,EAAErB,EAAM,CAAC,EAAElB,EAAUf,KAAK,CAAA,CAAE,CAErD,CAEI,AAACe,EAAUqF,WAAW,EAAInD,AAAoB,GAAG,GAAlBlE,UAAU,GAC3CuF,EAAgBvF,UAAU,CAAGkE,EAAKlE,UAAAA,AAAU,CAEhD,CACI8I,GAAe,OAAOnF,EAAKO,IACjC,AADqC,CAMrC,IAAIvY,IAAY2c,EA+Dd,OAAOZ,GAAgB,EAAOC,EA/DQ,EACtC,IAAMvE,EAAuBzX,EAC7BqW,EAAUqB,kBAAkB,GAAK,CAAC,EAClC,IAAIuF,EACF5G,EAAUqB,kBAAkB,CAACD,EAAqB,CAEpD,GAAIwF,EAAmB,CACrB,IAAMG,EAKF,MAAMH,EACV,OAAO,IAAIvf,SAAS0f,EAAkB/f,IAAI,CAAE,CAC1CQ,QAASuf,EAAkBvf,OAAO,CAClCF,OAAQyf,EAAkBzf,MAAM,CAChCC,WAAYwf,EAAkBxf,UAAU,AAC1C,EACF,CAUA,IAAMyf,EAAkBtB,GAAgB,EAAMC,GAK3CvmB,IAAI,CAACkH,EAAAA,WAJN,EAImB,EA4BrB,MAJAsgB,CAtBAA,EAAoBI,EACjB5nB,IAAI,CAAC,MAAO6nB,IACX,IAAM/c,EAAW+c,CAAS,CAAC,EAAE,CAC7B,MAAO,CACLjgB,KAAM,MAAMkD,EAASyW,CAVqC,UAU1B,GAChCnZ,QAAS0C,EAAS1C,OAAO,CACzBF,OAAQ4C,EAAS5C,MAAM,CACvBC,WAAY2C,EAAS3C,UAAU,AACjC,CACF,GACCpC,OAAO,CAAC,SAGF6a,GAAD,AAA6B,OAA5BA,EAAAA,EAAUqB,kBAAAA,AAAkB,EAAA,KAAA,EAA5BrB,CAA8B,CAACoB,EAAqB,AAArBA,GAAuB,AAI3D,OAAOpB,EAAUqB,kBAAkB,CAACD,EAAqB,AAC3D,EAAA,EAIgBlc,KAAK,CAAC,KAAO,GAE/B8a,EAAUqB,kBAAkB,CAACD,EAAqB,CAAGwF,EAE9CI,EAAgB5nB,IAAI,CAAC,AAAC6nB,GAAcA,CAAS,CAAC,EAAE,CACzD,CAGF,GAGF,GANW,AAMPzE,EACF,GAAI,CACF,OAFa,AAEN,MAAMliB,CACf,QAAU,CACJkiB,GACFA,EAAYqC,OAAO,CADJ,CAGnB,CAEF,OAAOvkB,CACT,EAeA,OATAmhB,EAAQyF,aAAa,EAAG,EACxBzF,EAAQ0F,oBAAoB,CAAG,IAAM5F,EACrCE,EAAQ2F,kBAAkB,CAAG9F,EAC3Brd,UAAsC,CAACwa,EAAkB,EAAG,EAI9D1Z,OAAO0C,cAAc,CAACga,EAAS,OAAQ,CAAE7f,MAAO,QAASiG,UAAU,CAAM,GAElE4Z,CACT,CAIO,SAAS9C,EAAWxb,CAAwB,EAEjD,IAAI4b,AAtsCkE,IAA9D9a,UAAsC,CAACwa,EAAkB,CAssC3C,OAItB,IAAM1X,EAAWkB,CAAAA,EAAAA,EAAAA,iBAAAA,AAAiB,EAAChE,WAAWyd,KAAK,EAGnDzd,WAAWyd,KAAK,CAAGhD,EAAqB3X,EAAU5D,EACpD,CAEA,IAAIkkB,EAA+C,4GCnsCnCG,iBAAAA,qCAAAA,aAzDe,CAAA,CAAA,IAAA,OACkB,CAAA,CAAA,IAAA,OAI1C,CAAA,CAAA,IAAA,OAKA,CAAA,CAAA,IAAA,OAKA,CAAA,CAAA,IAAA,GAQHC,EAAkB,EAEtB,eAAeC,EACbpnB,CAAS,CACTkd,CAAkC,CAClC7T,CAAgB,CAChB0V,CAAc,CACdrB,CAAsC,CACtCyH,CAAgB,CAChB3D,CAAgB,EAEhB,MAAMtE,EAAiB/b,GAAG,CACxBkI,EACA,CACEiS,KAAMvR,EAAAA,eAAe,CAACyW,KAAK,CAC3BC,KAAM,CACJvZ,QAAS,CAAC,EAEVR,KAAM2B,KAAKC,SAAS,CAACtI,GACrBgH,OAAQ,IACRI,IAAK,EACP,EACAsW,WAAY,AAAsB,iBAAfA,EAA0BoI,EAAAA,cAAc,CAAGpI,CAChE,EACA,CAAE2F,YAAY,OAAMtE,WAAMoG,WAAU3D,CAAS,EAGjD,CAOO,SAAS0F,EACd9hB,CAAK,CACLiiB,CAAmB,CACnBxkB,EAMI,CAAC,CAAC,EAEN,GAA2B,GAAG,CAA1BA,EAAQ6a,UAAU,CACpB,MAAM,OAAA,cAEL,CAFK,AAAI7d,MACR,CAAC,wFAAwF,EAAEuF,EAAGiJ,QAAQ,GAAA,CAAI,EADtG,oBAAA,OAAA,kBAAA,gBAAA,CAEN,GAIF,IAAM0Q,EAAOlc,EAAQkc,IAAI,CACrBR,CAAAA,EAAAA,EAAAA,YAAY,AAAZA,EAAa1b,EAAQkc,IAAI,CAAE,CAAC,eAAe,EAAE3Z,EAAGiJ,QAAQ,GAAA,CAAI,EAC5D,EAAE,CAGNiQ,CAAAA,EAAAA,EAAAA,kBAAAA,AAAkB,EAChBzb,EAAQ6a,UAAU,CAClB,CAAC,eAAe,EAAEtY,EAAG9E,IAAI,EAAI8E,EAAGiJ,QAAQ,GAAA,CAAI,EAU9C,IAAMiZ,EAAW,CAAA,EAAGliB,EAAGiJ,QAAQ,GAAG,CAAC,EACjCnG,MAAM4S,OAAO,CAACuM,IAAaA,EAAS1Y,IAAI,CAAC,KAAA,CACzC,CAsSF,OApSiB,AAoSV4Y,MApSiB,GAAG9kB,KACzB,IAAMid,EAAYuB,EAAAA,gBAAgB,CAACe,QAAQ,GACrCC,EAAgBf,EAAAA,oBAAoB,CAACc,QAAQ,GAG7CwF,EAGJ9H,CAAAA,QAAAA,KAAAA,EAAAA,EAAWxC,gBAAAA,AAAgB,GAAKvZ,WAAmB8jB,kBAAkB,CAEvE,GAAI,CAACD,EACH,MAAM,OAAA,QADoB,MAGzB,CAFK,AAAI3nB,MACR,CAAC,sDAAsD,EAAEuF,EAAGiJ,QAAQ,GAAA,CAAI,EADpE,oBAAA,OAAA,mBAAA,gBAAA,CAEN,GAIF,IAAM6T,EAAcD,EAAgBE,CAAAA,EAAAA,EAAAA,cAAAA,AAAc,EAACF,GAAiB,KAChEC,GACFA,EAAYE,QADG,CACM,GAEvB,GAAI,CAKF,IAAMsF,EACJhI,GAAauC,EACT0F,AA2QZ,SAASA,AACPjI,CAAoB,CACpBuC,CAA4B,EAE5B,OAAQA,EAAcvf,IAAI,EACxB,IAAK,UACH,IAAM4lB,EAAWrG,EAAc7a,GAAG,CAACkhB,QAAQ,CACrCC,EAAe,IAAIC,gBAAgBvG,EAAc7a,GAAG,CAACqhB,MAAM,EAE3DC,EAAe,IAAIH,EAAaI,IAAI,GAAG,CAC1CC,IAAI,CAAC,CAACnd,EAAGC,IAAMD,EAAEod,aAAa,CAACnd,IAC/B4J,GAAG,CAAEjU,AAAD,GAAS,CAAA,EAAGA,EAAI,CAAC,EAAEknB,EAAa1iB,GAAG,CAACxE,GAAAA,CAAM,EAC9CsN,IAAI,CAAC,KAER,MAAO,CAAA,EAAG2Z,EAAAA,EAAWI,EAAahkB,MAAM,CAAG,IAAM,GAAA,EAAKgkB,EAAAA,CAAc,AACtE,KAAK,YACL,IAAK,mBACL,IAAK,oBACL,IAAK,gBACL,IAAK,mBACL,IAAK,QACL,IAAK,gBACL,IAAK,iBACH,OAAOhJ,EAAUf,KAAK,AACxB,SACE,OAAOsD,CACX,CACF,EAtS8BvC,EAAWuC,GAC7B,GAKA2F,EAAgB,CAAA,EAAGN,EAAS,CAAC,EAAEjf,KAAKC,SAAS,CAAC7F,GAAAA,CAAO,CACrD4G,EAAW,MAAM6T,EAAiBnV,gBAAgB,CAAC6f,GAEnDpG,EAAW,CAAC,eAAe,EAAEkG,EAAe,CAAC,EAAEtiB,EAAG9E,IAAI,CAAG,CAAC,CAAC,EAAE8E,EAAG9E,IAAI,CAAA,CAAE,CAAG+I,EAAAA,CAAU,CACnF8b,EACHzF,GAAYA,EAAUM,WAAW,CAAGmH,CAAAA,CAAc,EAAM,EAErDhE,EAAelB,MAAAA,EAAAA,KAAAA,EAAAA,EAAekB,YAAY,CAE1C0E,EAAsC,CAC1CnlB,KAAM,iBACNolB,MAAO,sBACP3E,EACA4E,UACE9F,GACAvC,GACAsI,CAAAA,EAAAA,EAAAA,iCAAAA,AAAiC,EAACtI,EAAWuC,EACjD,EAEA,GAAIvC,EAAW,CACbA,EAAUM,WAAW,CAAGmF,EAAW,EAMnC,IAAI8C,GAAwB,EAE5B,GAAIhG,EACF,OAAQA,EAAcvf,IADL,AACS,EACxB,IAAK,QACL,IAAK,gBACL,IAAK,YACL,IAAK,oBACL,IAAK,gBACL,IAAK,mBAI+B,UAAU,AAAxC,OAAOG,EAAQ6a,UAAU,GACvBuE,EAAcvE,UAAU,CAAG7a,EAAQ6a,UAAU,EAAE,CAGjDuE,EAAcvE,UAAU,CAAG7a,EAAQ6a,UAAAA,AAAU,GAKjD,IAAMwF,EAAgBjB,EAAclD,IAAI,CACxC,GAAsB,MAAM,CAAxBmE,EACFjB,EAAclD,IAAI,CAAGA,EAAKhT,KAAK,QAE/B,IAAK,IAAMoT,KAAOJ,EAEZ,AAACmE,EAAcngB,CAFG,OAEK,CAACoc,IAC1B+D,EAAc3hB,AADkB,IACd,CAAC4d,GAIzB,KACF,KAAK,iBACH8I,GAAwB,CAO5B,CAGF,GAGE,CADA,AADA,AAECA,GACwB,AAAzBvI,qBAAU2D,UAAU,EACpB,CAAC3D,EAAUjD,KAHiC,UADU,KAIvB,EAC/B,CAACS,EAAiBT,oBAAoB,EACtC,CAACiD,EAAUgD,WAAW,CACtB,CAEA,IAAMrH,EAAa,MAAM6B,EAAiBrX,GAAG,CAACwD,EAAU,CACtDiS,KAAMtR,EAAAA,oBAAoB,CAACwW,KAAK,CAChC9C,WAAY7a,EAAQ6a,UAAU,MAC9BqB,EACAqH,QAAQ,CAAEjD,MAAAA,EAAAA,KAAAA,EAAAA,EAAcpE,IAAI,UAC5BoG,WACA3D,CACF,GAEA,GAAInG,GAAcA,EAAW/Z,KAAK,CAEhC,CAFkC,EAE9B+Z,EAAW/Z,KAAK,CAACga,IAAI,GAAKvR,EAAAA,eAAe,CAACyW,KAAK,CAKjD7C,CALmD,OAK3C1d,KAAK,CACX,CAAC,0CAA0C,EAAE2nB,EAAAA,CAAe,MAGzD,CAGL,IAAMM,OAC2BpkB,IAA/BuX,EAAW/Z,KAAK,CAACmf,IAAI,CAAC/Z,IAAI,CACtB2B,KAAK8f,KAAK,CAAC9M,EAAW/Z,KAAK,CAACmf,IAAI,CAAC/Z,IAAI,OACrC5C,EAEN,GAAIuX,EAAWU,OAAO,CAAE,CAMtB,GALI,AAAC2D,EAAUqB,kBAAkB,EAAE,CACjCrB,EAAUqB,kBAAkB,CAAG,EAAC,EAI9B,CAACrB,EAAUqB,kBAAkB,CAAC6G,EAAc,CAAE,CAEhD,IAAMQ,EAAsBlH,EAAAA,oBAAoB,CAC7CmH,GAAG,CAACR,EAAiBziB,KAAO3C,GAC5B3D,IAAI,CAAC,MAAOkB,IACX,MAAMonB,EACJpnB,IAEAqJ,EACA0V,EAFA7B,AAGAra,EAAQ6a,UAAU,CAClByH,EACA3D,GAEKxhB,IAER4E,KAAK,CAAC,AAACpF,IAENme,QAAQ1d,KAAK,CACX,CAAC,6BAA6B,EAAE2nB,EAAAA,CAAe,CAC/CpoB,GAGK0oB,IAKPxI,EAAU5J,kBAAkB,EAAE,AAChCsS,EAAoBxjB,KAAK,CAAC,KAAO,GAGnC8a,EAAUqB,kBAAkB,CAAC6G,EAAc,CACzCQ,CACJ,CAGA,GAAI1I,EAAU5J,kBAAkB,CAG9B,CAHgC,MAGzB4J,EAAUqB,kBAAkB,CAAC6G,EAAc,AAGtD,CAGA,OAAOM,CACT,CAEJ,CAGA,IAAMloB,EAAS,MAAMkhB,EAAAA,oBAAoB,CAACmH,GAAG,CAC3CR,EACAziB,KACG3C,GAsBL,OAnBKid,EAAUgD,WAAW,EAAE,CACtB,AAAChD,EAAUqB,kBAAkB,EAAE,CACjCrB,EAAUqB,kBAAkB,CAAG,EAAC,EAMlCrB,EAAUqB,kBAAkB,CAAC6G,EAAc,CAAGR,EAC5CpnB,IAEAqJ,EACA0V,EAFA7B,AAGAra,EAAQ6a,UAAU,CAClByH,EACA3D,IAIGxhB,CACT,CAAO,CAOL,GANAmnB,GAAmB,EAMf,CAACjK,EAAiBT,oBAAoB,CAAE,CAE1C,IAAMpB,EAAa,MAAM6B,EAAiBrX,GAAG,CAACwD,EAAU,CACtDiS,KAAMtR,EAAAA,oBAAoB,CAACwW,KAAK,CAChC9C,WAAY7a,EAAQ6a,UAAU,CAC9BqB,gBACAoG,WACA3D,EACA4E,QAAQ,CAAEjD,MAAAA,EAAAA,KAAAA,EAAAA,EAAcpE,IAAI,AAC9B,GAEA,GAAI1D,GAAcA,EAAW/Z,KAAK,CAEhC,CAFkC,GAE9B+Z,EAAW/Z,KAAK,CAACga,IAAI,GAAKvR,EAAAA,eAAe,CAACyW,KAAK,CAIjD7C,CAJmD,OAI3C1d,KAAK,CACX,CAAC,0CAA0C,EAAE2nB,EAAAA,CAAe,OAGzD,GAAI,CAACvM,EAAWU,OAAO,CAE5B,CAF8B,WAEQjY,IAA/BuX,EAAW/Z,KAAK,CAACmf,IAAI,CAAC/Z,IAAI,CAC7B2B,KAAK8f,KAAK,CAAC9M,EAAW/Z,KAAK,CAACmf,IAAI,CAAC/Z,IAAI,OACrC5C,CACN,CAEJ,CAGA,IAAM9D,EAAS,MAAMkhB,EAAAA,oBAAoB,CAACmH,GAAG,CAC3CR,EACAziB,KACG3C,GAeL,OATA,MAAM2kB,EACJpnB,EApQmBwnB,EAsQnBne,EACA0V,EACAlc,AAHAqa,EAGQQ,UAAU,CAClByH,EACA3D,GAEKxhB,CACT,CACF,QAAU,CACJkiB,GACFA,EAAYqC,OAAO,CADJ,CAGnB,CACF,CAGF,wFChKgBuE,qBAAqB,CAAA,kBAArBA,GAzBAC,eAAe,CAAA,kBAAfA,sEA9MhB,OAAMC,EAOJpW,OAAOqW,CAAe,CAAQ,CAC5B,IAAI,CAACC,OAAO,CAACD,EAAQ9kB,KAAK,CAAC,KAAKiE,MAAM,CAACma,SAAU,EAAE,EAAE,EACvD,CAEA4G,QAAmB,CACjB,OAAO,IAAI,CAACC,OAAO,EACrB,CAEQA,QAAQC,EAAiB,GAAG,CAAY,CAC9C,IAAMC,EAAgB,IAAI,IAAI,CAACC,QAAQ,CAACZ,IAAI,GAAG,CAACC,IAAI,EAC9B,MAAM,EAAxB,IAAI,CAACY,QAAQ,EACfF,EAAcG,MAAM,CAACH,EAAcI,OAAO,CAAC,MAAO,GAE1B,MAAM,CAA5B,IAAI,CAACC,YAAY,EACnBL,EAAcG,MAAM,CAACH,EAAcI,OAAO,CAAC,SAAU,GAErB,AAA9B,MAAoC,KAAhC,CAACE,oBAAoB,EAC3BN,EAAcG,MAAM,CAACH,EAAcI,OAAO,CAAC,WAAY,GAGzD,IAAMG,EAASP,EACZhU,GAAG,CAAC,AAACC,GAAM,IAAI,CAACgU,QAAQ,CAAC1jB,GAAG,CAAC0P,GAAI6T,OAAO,CAAC,CAAA,EAAGC,EAAAA,EAAS9T,EAAE,CAAC,CAAC,GACzDuU,MAAM,CAAC,CAACC,EAAMC,IAAS,IAAID,KAASC,EAAK,CAAE,EAAE,EAQhD,GANI,AAAkB,MAAM,KAApB,CAACR,QAAQ,EACfK,EAAOtoB,IAAI,IACN,IAAI,CAACgoB,QAAQ,CAAC1jB,GAAG,CAAC,MAAOujB,OAAO,CAAC,CAAA,EAAGC,EAAO,CAAC,EAAE,IAAI,CAACG,QAAQ,CAAC,EAAE,CAAC,GAIlE,CAAC,IAAI,CAACS,WAAW,CAAE,CACrB,IAAMjD,EAAe,AAAXqC,QAAiB,IAAMA,EAAOtd,KAAK,CAAC,EAAG,CAAC,GAClD,GAAiC,MAAM,AAAnC,IAAI,CAAC6d,oBAAoB,CAC3B,MAAM,OAAA,cAEL,CAFK,AAAI/pB,MACR,CAAC,oFAAoF,EAAEmnB,EAAE,OAAO,EAAEA,EAAE,KAAK,EAAE,IAAI,CAAC4C,oBAAoB,CAAC,KAAK,CAAC,EADvI,oBAAA,OAAA,mBAAA,gBAAA,CAEN,GAGFC,EAAO7O,OAAO,CAACgM,EACjB,CAkBA,OAhB0B,MAAM,CAA5B,IAAI,CAAC2C,YAAY,EACnBE,EAAOtoB,IAAI,IACN,IAAI,CAACgoB,QAAQ,CACb1jB,GAAG,CAAC,SACJujB,OAAO,CAAC,CAAA,EAAGC,EAAO,IAAI,EAAE,IAAI,CAACM,YAAY,CAAC,EAAE,CAAC,GAIlB,MAAM,CAApC,IAAI,CAACC,oBAAoB,EAC3BC,EAAOtoB,IAAI,IACN,IAAI,CAACgoB,QAAQ,CACb1jB,GAAG,CAAC,WACJujB,OAAO,CAAC,CAAA,EAAGC,EAAO,KAAK,EAAE,IAAI,CAACO,oBAAoB,CAAC,GAAG,CAAC,GAIvDC,CACT,CAEQX,QACNgB,CAAkB,CAClBC,CAAmB,CACnBC,CAAmB,CACb,CACN,GAAwB,IAApBF,EAASxlB,MAAM,CAAQ,CACzB,IAAI,CAACulB,WAAW,EAAG,EACnB,MACF,CAEA,GAAIG,EACF,MAAM,IADQ,GACR,cAAwD,CAAxD,AAAIvqB,MAAM,CAAC,2CAA2C,CAAC,EAAvD,oBAAA,OAAA,mBAAA,gBAAA,CAAuD,GAI/D,IAAIwqB,EAAcH,CAAQ,CAAC,EAAE,CAG7B,GAAIG,EAAY3d,UAAU,CAAC,MAAQ2d,EAAYC,QAAQ,CAAC,KAAM,CAE5D,IAAIC,EAAcF,EAAYte,KAAK,CAAC,EAAG,CAAC,GAEpCye,GAAa,EAOjB,GANID,EAAY7d,UAAU,CAAC,MAAQ6d,EAAYD,QAAQ,CAAC,MAAM,CAE5DC,EAAcA,EAAYxe,KAAK,CAAC,EAAG,CAAC,GACpCye,GAAa,GAGXD,EAAY7d,UAAU,CAAC,KACzB,CAD+B,KACzB,OAAA,cAEL,CAFS7M,AAAJ,MACJ,CAAC,0CAA0C,EAAE0qB,EAAY,yBAAyB,CAAC,EAD/E,oBAAA,OAAA,mBAAA,gBAAA,CAEN,GASF,GANIA,EAAY7d,UAAU,CAAC,QAAQ,CAEjC6d,EAAcA,EAAYE,SAAS,CAAC,GACpCL,EAAa,IAGXG,EAAY7d,UAAU,CAAC,MAAQ6d,EAAYD,QAAQ,CAAC,KACtD,CAD4D,KACtD,OAAA,cAEL,CAFK,AAAIzqB,MACR,CAAC,yDAAyD,EAAE0qB,EAAY,GAAG,CAAC,EADxE,oBAAA,OAAA,kBAAA,gBAAA,EAEN,GAGF,GAAIA,EAAY7d,UAAU,CAAC,KACzB,CAD+B,KACzB,OAAA,cAEL,CAFK,AAAI7M,MACR,CAAC,qDAAqD,EAAE0qB,EAAY,GAAG,CAAC,EADpE,oBAAA,OAAA,kBAAA,gBAAA,EAEN,GAGF,SAASG,EAAWC,CAA2B,CAAEC,CAAgB,EAC/D,GAAqB,MAAM,CAAvBD,GAMEA,IAAiBC,EAEnB,MAAM,EAFuB,KAEvB,cAEL,CAFS/qB,AAAJ,MACJ,CAAC,gEAAgE,EAAE8qB,EAAa,OAAO,EAAEC,EAAS,GAAG,CAAC,EADlG,oBAAA,OAAA,mBAAA,gBAAA,CAEN,GAIJT,EAAUU,OAAO,CAAC,AAACC,IACjB,GAAIA,IAASF,EACX,MAAM,EADe,KACf,cAEL,CAFK,AAAI/qB,MACR,CAAC,oCAAoC,EAAE+qB,EAAS,qCAAqC,CAAC,EADlF,oBAAA,OAAA,kBAAA,iBAAA,CAEN,GAGF,GAAIE,EAAKzmB,OAAO,CAAC,MAAO,MAAQgmB,EAAYhmB,OAAO,CAAC,MAAO,IACzD,CAD8D,KACxD,OAAA,cAEL,CAFK,AAAIxE,MACR,CAAC,gCAAgC,EAAEirB,EAAK,OAAO,EAAEF,EAAS,8DAA8D,CAAC,EADrH,oBAAA,OAAA,kBAAA,iBAAA,CAEN,EAEJ,GAEAT,EAAU5oB,IAAI,CAACqpB,EACjB,CAEA,GAAIR,EACF,GAAII,EAAY,CACd,GAAyB,CAFb,KAER,AAA2B,IAAvB,CAACb,YAAY,CACnB,MAAM,OAAA,cAEL,CAFK,AAAI9pB,MACR,CAAC,qFAAqF,EAAE,IAAI,CAAC8pB,YAAY,CAAC,QAAQ,EAAEO,CAAQ,CAAC,EAAE,CAAC,IAAI,CAAC,EADjI,oBAAA,OAAA,mBAAA,gBAAA,CAEN,GAGFQ,EAAW,IAAI,CAACd,oBAAoB,CAAEW,GAEtC,IAAI,CAACX,oBAAoB,CAAGW,EAE5BF,EAAc,SAChB,KAAO,CACL,GAAiC,MAA7B,AAAmC,IAA/B,CAACT,oBAAoB,CAC3B,MAAM,OAAA,cAEL,CAFS/pB,AAAJ,MACJ,CAAC,sFAAsF,EAAE,IAAI,CAAC+pB,oBAAoB,CAAC,SAAS,EAAEM,CAAQ,CAAC,EAAE,CAAC,GAAG,CAAC,EAD1I,oBAAA,OAAA,mBAAA,gBAAA,CAEN,GAGFQ,EAAW,IAAI,CAACf,YAAY,CAAEY,GAE9B,IAAI,CAACZ,YAAY,CAAGY,EAEpBF,EAAc,OAChB,KACK,CACL,GAAIG,EACF,MAAM,IADQ,GACR,cAEL,CAFS3qB,AAAJ,MACJ,CAAC,kDAAkD,EAAEqqB,CAAQ,CAAC,EAAE,CAAC,GAAG,CAAC,EADjE,oBAAA,OAAA,mBAAA,gBAAA,CAEN,GAEFQ,EAAW,IAAI,CAAClB,QAAQ,CAAEe,GAE1B,IAAI,CAACf,QAAQ,CAAGe,EAEhBF,EAAc,IAChB,CACF,CAGI,AAAC,IAAI,CAACd,QAAQ,CAACxjB,GAAG,CAACskB,IACrB,IAAI,CAACd,KAD8B,GACtB,CAACpoB,GAAG,CAACkpB,EAAa,IAAIrB,GAGrC,IAAI,CAACO,QAAQ,CACV1jB,GAAG,CAACwkB,GACJnB,OAAO,CAACgB,EAASne,KAAK,CAAC,GAAIoe,EAAWC,EAC3C,oBAvMAH,WAAAA,EAAuB,OACvBV,QAAAA,CAAiC,IAAI1oB,SACrC2oB,QAAAA,CAA0B,UAC1BG,YAAAA,CAA8B,UAC9BC,oBAAAA,CAAsC,KAoMxC,CAKO,SAASb,EACdgC,CAAsC,EAatC,IAAMC,EAAO,IAAIhC,EAKjB,OAFA+B,EAAgBF,OAAO,CAAC,AAACI,GAAaD,EAAKpY,MAAM,CAACqY,IAE3CD,EAAK7B,MAAM,EACpB,CAKO,SAASL,EACdoC,CAAY,CACZ9oB,CAA0B,EAI1B,IAAM+oB,EAAkC,CAAC,EACnCC,EAAsB,EAAE,CAC9B,IAAK,IAAI1hB,EAAI,EAAGA,EAAIwhB,EAAQxmB,MAAM,CAAEgF,IAAK,CACvC,IAAM4e,EAAWlmB,EAAO8oB,CAAO,CAACxhB,EAAE,EAClCyhB,CAAO,CAAC7C,EAAS,CAAG5e,EACpB0hB,CAAS,CAAC1hB,EAAE,CAAG4e,CACjB,CAOA,OAJeS,AAIRsC,EAJwBD,GAIjB9V,GAAG,CAAEgT,AAAD,GAAc4C,CAAO,CAACC,CAAO,CAAC7C,EAAS,CAAC,CAC5D,gCCvPO,SAASgD,EAAmBC,CAAY,EAC7C,OAAOA,EAAK7e,UAAU,CAAC,KAAO6e,EAAO,CAAC,CAAC,EAAEA,EAAAA,CAAM,AACjD,CAHC,OAAA,cAAA,CAAA,EAAA,aAAA,oCACeD,qBAAAA,qCAAAA,2FCmFHE,mBAAmB,CAAA,kBAAnBA,GADAC,gBAAgB,CAAA,kBAAhBA,GAvEGC,4BAA4B,CAAA,kBAA5BA,GAgBAC,4BAA4B,CAAA,kBAA5BA,GA7BAC,eAAe,CAAA,kBAAfA,GAiDAC,4BAA4B,CAAA,kBAArC,AAASA,SAAAA,EACdS,CAAuB,CACvBF,CAAwB,CACxBG,GAAQ,CAAI,CACZ3Y,EAAwB,EAAE,MAEtB4Y,EACJ,GAAID,EAEFC,EAAOF,CAAI,CAAC,CAFH,CAEK,CAACF,EAAiB,KAC3B,CAEL,IAAMK,EAAiBH,CAAI,CAAC,EAAE,CAC9BE,EAAOC,EAAelD,QAAQ,EAAI9kB,OAAOioB,MAAM,CAACD,EAAe,CAAC,EAAE,AACpE,CAEA,GAAI,CAACD,EAAM,OAAO5Y,EAGlB,IAAI+Y,EAAef,EAFHY,CAAI,CAAC,EAAE,QAIvB,AAAI,CAACG,CAF8BX,EAEdW,EAAajgB,UAAU,CAAC+e,GACpC7X,GAGTA,EAAYrS,IAAI,CAACorB,GAEVd,EACLW,CAP8D,CAQ9DJ,GACA,EACAxY,GAEJ,GA9EgBkY,cAAc,CAAA,kBAAdA,GAKAC,sBAAsB,CAAA,kBAAtBA,uEATT,SAASH,EAAgBI,CAAgB,EAC9C,OAAO9jB,MAAM4S,OAAO,CAACkR,GAAWA,CAAO,CAAC,EAAE,CAAGA,CAC/C,CAEO,SAASF,EAAeE,CAAe,EAE5C,MAAsB,MAAfA,CAAO,CAAC,EAAE,EAAYA,EAAQ1B,QAAQ,CAAC,IAChD,CAEO,SAASyB,EAAuBC,CAAe,EACpD,OAAOA,EAAQtf,UAAU,CAAC,MAAQsf,AAAY,eAChD,CAEO,SAASN,EACdM,CAAgB,CAChBzD,CAA2D,EAI3D,GAFsByD,CAElBC,CAF0BlpB,QAAQ,CAAC0oB,GAEpB,CACjB,IAAMS,EAAmB7jB,KAAKC,SAAS,CAACigB,GACxC,MAA4B,OAArB2D,EACHT,EAAmB,IAAMS,EACzBT,CACN,CAEA,OAAOO,CACT,CAEO,SAASL,EACdQ,CAAyB,CACzBC,CAAwB,EAExB,GAAI,CAACD,GAAgC,GAAG,CAAvBA,EAASznB,MAAM,CAC9B,OAAO,KAIT,IAAM2nB,EACiB,aAArBD,EACID,CAAQ,CAAC,EAAE,CACXA,CAAQ,CAACA,EAASznB,MAAM,CAAG,EAAE,CAInC,OAAO2nB,IAAeb,EAAsB,KAAOa,CACrD,CAsCO,IAAMZ,EAAmB,WACnBD,EAAsB,oGCjEnBoB,gBAAgB,CAAA,kBAAhBA,GAmCAC,eAAe,CAAA,kBAAfA,+EAzDmB,CAAA,CAAA,IAAA,OACJ,CAAA,CAAA,IAAA,GAqBxB,SAASD,EAAiBjO,CAAa,EAC5C,MAAO2M,GAAAA,EAAAA,kBAAAA,AAAkB,EACvB3M,EAAMxa,KAAK,CAAC,KAAK2lB,MAAM,CAAC,CAACxB,EAAU0D,EAASvY,EAAO0Y,IAEjD,AAAI,CAACH,GAKDF,CAAAA,EAAAA,EAAAA,CALU,aAKI,AAAdA,EAAeE,IAKA,KAAK,CALK,AAKzBA,CAAO,CAAC,EAAE,EAMXA,CAAY,SAAZA,GAAsBA,AAAY,WAAA,CAAM,EACzCvY,IAAU0Y,EAASznB,MAAM,CAAG,EAhBrB4jB,CAiBP,CAIK,CAAA,EAAGA,EAAS,CAAC,EAAE0D,EAAAA,CAAS,CAC9B,IAEP,CAMO,SAASa,EAAgBzlB,CAAW,EACzC,OAAOA,EAAI/C,OAAO,CAChB,cAEA,KAEJ,yBAHkC,+DCzDrByoB,0BAA0B,CAAA,kBAA1BA,GAiCGC,mCAAmC,CAAA,kBAAnCA,GA1BAC,0BAA0B,CAAA,kBAA1BA,+EAViB,CAAA,CAAA,IAAA,GAGpBF,EAA6B,CACxC,WACA,MACA,OACA,QACD,CAEM,SAASE,EAA2BzB,CAAY,EAErD,YAKUznB,IAJRynB,EACGpnB,KAAK,CAAC,KACN8oB,IAAI,CAAC,AAACjB,GACLc,EAA2BG,IAAI,CAAC,AAACC,GAAMlB,EAAQtf,UAAU,CAACwgB,IAGlE,CAiBO,SAASH,EACdxB,CAAY,EAEZ,IAAI4B,EACAC,EACAC,EAEJ,IAAK,IAAMrB,KAAWT,EAAKpnB,KAAK,CAAC,KAAM,AAErC,GADAipB,CACIA,CADKN,EAA2BG,IAAI,CAAC,AAACC,GAAMlB,EAAQtf,UAAU,CAACwgB,IACvD,CACT,CAACC,EAAmBE,EAAiB,CAAG9B,EAAKpnB,KAAK,CAACipB,EAAQ,GAC5D,KACF,CAGF,GAAI,CAACD,GAAqB,CAACC,GAAU,CAACC,EACpC,MAAM,OAAA,GADgD,WAGrD,CAFK,AAAIxtB,MACR,CAAC,4BAA4B,EAAE0rB,EAAK,iFAAiF,CAAC,EADlH,oBAAA,OAAA,mBAAA,gBAAA,CAEN,GAKF,OAFA4B,EAAoBP,GAAAA,EAAAA,gBAAAA,AAAgB,EAACO,GAE7BC,GACN,IAAK,MAGDC,EADwB,CAL0B,IAKrB,CAA3BF,EACiB,CAAC,CAAC,EAAEE,EAAAA,CAAkB,CAEtBF,EAAoB,IAAME,EAE/C,KACF,KAAK,OAEH,GAAIF,AAAsB,KAAK,CAbsE,EAcnG,MAAM,OAAA,cAEL,CAFK,AAAIttB,MACR,CAAC,4BAA4B,EAAE0rB,EAAK,4DAA4D,CAAC,EAD7F,oBAAA,OAAA,mBAAA,gBAAA,CAEN,GAEF8B,EAAmBF,EAChBhpB,KAAK,CAAC,KACN4H,KAAK,CAAC,EAAG,CAAC,GACVgF,MAAM,CAACsc,GACP1e,IAAI,CAAC,KACR,KACF,KAAK,QAEH0e,EAAmB,IAAMA,EACzB,KACF,KAAK,WAGH,IAAMC,EAAyBH,EAAkBhpB,KAAK,CAAC,KACvD,GAAImpB,EAAuB5oB,MAAM,EAAI,EACnC,CADsC,KAChC,OAAA,cAEL,CAFK,AAAI7E,MACR,CAAC,4BAA4B,EAAE0rB,EAAK,+DAA+D,CAAC,EADhG,oBAAA,OAAA,mBAAA,gBAAA,CAEN,GAGF8B,EAAmBC,EAChBvhB,KAAK,CAAC,EAAG,CAAC,GACVgF,MAAM,CAACsc,GACP1e,IAAI,CAAC,KACR,KACF,SACE,MAAM,OAAA,cAAyC,CAAzC,AAAI9O,MAAM,gCAAV,oBAAA,OAAA,mBAAA,gBAAA,CAAwC,EAClD,CAEA,MAAO,mBAAEstB,mBAAmBE,CAAiB,CAC/C,yGCvFgBE,iBAAAA,qCAAAA,aAfT,CAAA,CAAA,IAAA,GAGDC,EAAa,gCAGbC,EAAoB,sBASnB,SAASF,EAAe5O,CAAa,CAAE+O,EAAkB,EAAI,QAKlE,CAJIV,CAAAA,EAAAA,EAAAA,0BAAAA,AAA0B,EAACrO,KAC7BA,EAAQoO,CAD6B,AAC7BA,EAAAA,EAAAA,mCAAAA,AAAmC,EAACpO,GAAO0O,gBAAAA,AAAgB,EAGjEK,GACKD,EAAkBE,GADf,CACmB,CAAChP,GAGzB6O,EAAWG,IAAI,CAAChP,EACzB,wFC5B0BmK,qBAAqB,CAAA,kBAArBA,EAAAA,qBAAqB,EAAtCC,eAAe,CAAA,kBAAfA,EAAAA,eAAe,EACfwE,cAAc,CAAA,kBAAdA,EAAAA,cAAc,8EADgC,CAAA,CAAA,IAAA,OACxB,CAAA,CAAA,IAAA,yFC0DfK,OAAO,CAAA,kBAAPA,GA0BAC,cAAc,CAAA,kBAAdA,GA9DAC,aAAa,CAAA,kBAAbA,GAeAC,SAAS,CAAA,kBAATA,+EAnCT,CAAA,CAAA,IAAA,OACwB,CAAA,CAAA,IAAA,OAIxB,CAAA,CAAA,IAAA,OAC0B,CAAA,CAAA,IAAA,OACI,CAAA,CAAA,IAAA,OACF,CAAA,CAAA,IAAA,OACJ,CAAA,CAAA,IAAA,GAWxB,SAASD,EAAc3O,CAAW,CAAE6O,CAAiC,EAM1E,OALI,AAACA,GACHrQ,MADY,EACJ4B,IAAI,CACV,kMAGG7B,EAAW,CAACyB,EAAI,CAAE,CAAC,cAAc,EAAEA,EAAAA,CAAK,CAAE6O,EACnD,CAQO,SAASD,EAAU5O,CAAW,EACnC,IAAMO,EAAYuB,EAAAA,gBAAgB,CAACe,QAAQ,GAI3C,GAAI,CAACtC,GAAaA,EAAUuO,IAAI,CAAC3D,QAAQ,CAAC,UACxC,CADmD,KAC7C,OAAA,cAIL,CAJK,AAAIzqB,MACR,+DACE,8FACA,2EAHE,oBAAA,OAAA,mBAAA,eAAA,EAIN,GAGF,OAAO6d,EAAW,CAACyB,EAAI,CAAE,CAAC,UAAU,EAAEA,EAAAA,CAAK,MAAErb,EAC/C,CAOO,SAAS8pB,IACd,IAAMlO,EAAYuB,EAAAA,gBAAgB,CAACe,QAAQ,GACrCC,EAAgBf,EAAAA,oBAAoB,CAACc,QAAQ,GAEnD,GACE,CAACtC,GACDA,EAAUuO,IAAI,CAAC3D,QAAQ,CAAC,WACxBrI,CAAAA,MAAAA,EAAAA,KAAAA,EAAAA,EAAe6F,KAAAA,AAAK,IAAK,SAEzB,CADA,KACM,OAAA,cAGL,CAHK,AAAIjoB,MACR,6DACE,8EAFE,oBAAA,OAAA,mBAAA,gBAAA,CAGN,GAGE6f,IAEFA,EAAUwO,KAFG,aAEe,EAAG,CAAA,CAEnC,CAOO,SAASL,EAAeM,CAAoB,CAAEzrB,CAAwB,EAC3E,GAAIyrB,EAAazpB,MAAM,CAAG0pB,EAAAA,8BAA8B,CAAE,YACxDzQ,QAAQ4B,IAAI,CACV,CAAC,kCAAkC,EAAE4O,EAAa,+BAA+B,EAAEC,EAAAA,8BAA8B,CAAC,uFAAuF,CAAC,EAK9M,IAAIC,EAAiB,CAAA,EAAGC,EAAAA,0BAA0B,CAAA,EAAGH,GAAgB,IAAA,CAAK,CAEtEzrB,EACF2rB,GAAkB,CAAA,AADV,EACaA,EAAe/D,QAAQ,CAAC,KAAO,GAAK,IAAA,EAAM5nB,EAAAA,CAAM,CAC5D6qB,CAAAA,EAAAA,EAAAA,cAAAA,AAAc,EAACY,IACxBxQ,QAAQ4B,GAD+B,CAC3B,CACV,CAAC,8BAA8B,EAAE4O,EAAa,2LAA2L,CAAC,EAI9O,IAAMpP,EAAO,CAACsP,EAAe,CAO7B,OANIA,IAAmB,CAAA,EAAGC,EAAAA,0BAA0B,CAAC,CAAC,CAAC,CACrDvP,CADuD,CAClDxd,IAAI,CAAC,CAAA,EAAG+sB,EAAAA,0BAA0B,CAAC,MAAM,CAAC,EACtCD,IAAmB,CAAA,EAAGC,EAAAA,0BAA0B,CAAC,MAAM,CAAC,EAAE,AACnEvP,EAAKxd,IAAI,CAAC,CAAA,EAAG+sB,EAAAA,0BAA0B,CAAC,CAAC,CAAC,EAGrC5Q,EAAWqB,EAAM,CAAC,eAAe,EAAEoP,EAAAA,CAAc,CAC1D,CAEA,SAASzQ,EACPqB,CAAc,CACdwP,CAAkB,CAClBP,CAAkC,MAwG1BQ,EAtGR,IAAMA,EAAQvN,EAAAA,gBAAgB,CAACe,QAAQ,GACvC,GAAI,CAACwM,GAAS,CAACA,EAAMtR,gBAAgB,CACnC,CADqC,KAC/B,OAAA,cAEL,CAFK,AAAIrd,MACR,CAAC,8CAA8C,EAAE0uB,EAAAA,CAAY,EADzD,oBAAA,OAAA,mBAAA,gBAAA,CAEN,GAGF,IAAMtM,EAAgBf,EAAAA,oBAAoB,CAACc,QAAQ,GACnD,GAAIC,EAAe,CACjB,GAA4B,UAAU,CAAlCA,EAAc6F,KAAK,CACrB,MAAM,OAAA,cAEL,CAFK,AAAIjoB,MACR,CAAC,MAAM,EAAE2uB,EAAM7P,KAAK,CAAC,OAAO,EAAE4P,EAAW,8QAA8Q,CAAC,EADpT,oBAAA,OAAA,iBAAA,gBAAA,CAEN,GAGF,OAAQtM,EAAcvf,IAAI,EACxB,IAAK,QACL,IAAK,gBACH,MAAM,OAAA,cAEL,CAFS7C,AAAJ,MACJ,CAAC,MAAM,EAAE2uB,EAAM7P,KAAK,CAAC,OAAO,EAAE4P,EAAW,qRAAqR,CAAC,EAD3T,oBAAA,OAAA,mBAAA,gBAAA,CAEN,EACF,KAAK,iBACH,MAAM,OAAA,cAEL,CAFK,AAAI1uB,MACR,CAAC,MAAM,EAAE2uB,EAAM7P,KAAK,CAAC,OAAO,EAAE4P,EAAW,oTAAoT,CAAC,EAD1V,oBAAA,OAAA,kBAAA,iBAAA,CAEN,EACF,KAAK,YACL,IAAK,oBAEH,IAAMtuB,EAAQ,OAAA,cAEb,CAFa,AAAIJ,MAChB,CAAC,MAAM,EAAE2uB,EAAM7P,KAAK,CAAC,MAAM,EAAE4P,EAAW,8CAA8C,CAAC,EAD3E,oBAAA,OAAA,mBAAA,gBAAA,CAEd,GACA,MAAOE,CAAAA,EAAAA,EAAAA,2CAAAA,AAA2C,EAChDD,EAAM7P,KAAK,CACX4P,EACAtuB,EACAgiB,EAEJ,KAAK,mBACH,MAAM,OAAA,cAEL,CAFK,IAAIpY,EAAAA,cAAc,CACtB,CAAA,EAAG0kB,EAAW,0EAA0E,EAAEA,EAAW,+EAA+E,CAAC,EADjL,oBAAA,OAAA,mBAAA,gBAAA,CAEN,EACF,KAAK,gBACH,MAAOG,CAAAA,EAAAA,EAAAA,oBAAAA,AAAoB,EACzBF,EAAM7P,KAAK,CACX4P,EACAtM,EAAc0M,eAAe,CAEjC,KAAK,mBACH1M,EAAcvE,UAAU,CAAG,EAE3B,IAAMle,EAAM,OAAA,cAEX,CAFW,IAAIovB,EAAAA,kBAAkB,CAChC,CAAC,MAAM,EAAEJ,EAAM7P,KAAK,CAAC,mDAAmD,EAAE4P,EAAW,6EAA6E,CAAC,EADzJ,oBAAA,OAAA,kBAAA,iBAAA,CAEZ,EAIA,OAHAC,EAAMK,uBAAuB,CAAGN,EAChCC,EAAMM,iBAAiB,CAAGtvB,EAAIuvB,KAAK,CAE7BvvB,CAWV,CACF,CAMA,IAAK,IAAM2f,KAJP,AAACqP,EAAMS,sBAAsB,EAAE,AACjCT,GAAMS,sBAAsB,CAAG,EAAE,AAAF,EAGflQ,GAYZmQ,AAAkB,CAAC,CAZD,EAYI,CAXJV,EAAMS,sBAAsB,CAACE,SAAS,CAAC,AAACC,GAC5D,AAAIA,EAAKjQ,GAAG,GAAKA,IAEW,CAFN,OAAO,EAEzB,OAAOiQ,EAAKpB,OAAO,EAAoC,UAAnB,AAA6B,OAAtBA,EACtCoB,EAAKpB,OAAO,GAAKA,EAEE,UAAxB,OAAOoB,EAAKpB,OAAO,EAAoC,UAAnB,AAA6B,OAAtBA,EACtC3lB,KAAKC,SAAS,CAAC8mB,EAAKpB,OAAO,IAAM3lB,KAAKC,SAAS,CAAC0lB,GAElDoB,EAAKpB,OAAO,GAAKA,KAGxBQ,EAAMS,sBAAsB,CAAC1tB,IAAI,CAAC,KAChC4d,UACA6O,CACF,GAOJ,IAAMqB,EACJrB,GAA8B,UAAnB,OAAOA,EACdA,EACAA,GACqB,UAAnB,EAAmB,KAAZA,IACPQ,MAAAA,CAAAA,EAAAA,AAAwB,GAAxBA,IAAAA,EAAAA,EAAOc,iBAAAA,AAAiB,EAAA,KAAA,EAAxBd,CAA0B,CAACR,EAAQ,EACnCQ,EAAMc,iBAAiB,CAACtB,EAAQ,MAChClqB,CAEJ,CAACkqB,GAAWqB,CAAAA,MAAAA,EAAAA,KAAAA,EAAAA,EAAWnR,MAAAA,AAAM,IAAK,GAAG,CAEvCsQ,EAAMN,kBAAkB,EAAG,CAAA,CAE/B,yGCjNgBqB,mBAAAA,qCAAAA,aAnBiB,CAAA,CAAA,IAAA,OACI,CAAA,CAAA,IAAA,OACK,CAAA,CAAA,IAAA,GAiBnC,SAASA,IAEd,IAAMf,EAAQvN,EAAAA,gBAAgB,CAACe,QAAQ,GACjCC,EAAgBf,EAAAA,oBAAoB,CAACc,QAAQ,GACnD,GAAKwM,CAAD,EAKG,IALK,AAKDA,EAAMzJ,WAAW,EAAE,AAI5B,GADAyJ,EAAMjL,iBAAiB,EAAG,EACtBtB,EACF,OAAQA,EAAcvf,IADL,AACS,EACxB,IAAK,YACL,IAAK,mBACL,IAAK,oBAEH,MAUJ,CAEFsiB,CAAAA,EAAAA,EAAAA,yBAAAA,AAAyB,EAACwJ,EAAOvM,EA9BT,aA8BwBuN,SAClD,CACF,gCCwBO,SAASH,EAAUrB,CAAsC,EAE5D,MAAM,OAAA,cAEL,CAFK,AAAInuB,MACR,sEADI,oBAAA,OAAA,mBAAA,gBAAA,CAEN,EA6FJ,0EAjGgBwvB,YAAAA,qCAAAA,OA5Ee,CAAA,CAAA,IAAA,KACE,CAAA,CAAA,IAAA,KACI,CAAA,CAAA,IAAA,iCCC9B,SAASY,IAEZ,KAFqB,CAEf,EAFkBlR,IAAc,CAEhC,cAEL,CAFK,AAAIlf,MACR,qEADI,oBAAA,OAAA,kBAAA,iBAAA,CAEN,EA+BJ,0EAnCgBowB,WAAAA,qCAAAA,OAHqB,CAAA,CAAA,IAAA,KACR,CAAA,CAAA,IAAA,oBCD7B,IAAM,EAAe,CACnB,eAAgB,EAAA,CAAA,CAAA,OACb,cAAc,CAEjB,UAAW,EAAA,CAAA,CAAA,OACR,SAAS,CAEZ,cAAe,EAAA,CAAA,CAAA,OACZ,aAAa,CAChB,eAAgB,EAAA,CAAA,CAAA,OACb,cAAc,CAEjB,QAAS,EAAA,CAAA,CAAA,OAA0D,OAAO,CAE1E,iBACE,EAAA,CAAA,CAAA,OACG,gBAAgB,CACrB,UAAW,EAAA,CAAA,CAAA,OAAiD,SAAS,CACrE,SAAU,EAAA,CAAA,CAAA,OAAgD,QAAQ,AACpE,EAEI,GAAmB,EAYnB,GAAkB,EAYtB,EAAa,kBAAkB,CAvB/B,EAuBkC,OAvBzB,EAQP,OAPK,IACH,GAAmB,EAInB,QAAQ,CALa,IAKR,CAAC,AAHA,AAAI,MAChB,sKAIG,EAAa,SAAS,CAAC,KAAK,CAAC,IAAI,CAAE,UAC5C,EAeA,EAAa,iBAAiB,CAZ9B,EAYiC,OAZxB,EAQP,OAPK,IACH,GAAkB,EAIlB,QAAQ,AALY,KAKP,CAAC,AAHA,AAAI,MAChB,oKAIG,EAAa,QAAQ,CAAC,KAAK,CAAC,IAAI,CAAE,UAC3C,EAOA,EAAO,OAAO,CAAG,EAGjB,EAAQ,cAAc,CAAG,EAAa,cAAc,CACpD,EAAQ,cAAc,CAAG,EAAa,cAAc,CACpD,EAAQ,aAAa,CAAG,EAAa,aAAa,CAClD,EAAQ,SAAS,CAAG,EAAa,SAAS,CAC1C,EAAQ,gBAAgB,CAAG,EAAa,gBAAgB,CACxD,EAAQ,SAAS,CAAG,EAAa,SAAS,CAC1C,EAAQ,kBAAkB,CAAG,EAAa,kBAAkB,CAC5D,EAAQ,QAAQ,CAAG,EAAa,QAAQ,CACxC,EAAQ,iBAAiB,CAAG,EAAa,iBAAiB,CAC1D,EAAQ,OAAO,CAAG,EAAa,OAAO,+BC3D/B,SAASC,EAAyBC,CAAc,EACrD,IAAK,IAAIzmB,EAAI,EAAGA,EAAIymB,EAAQzrB,MAAM,CAAEgF,IAAK,CACvC,IAAM0mB,EAASD,CAAO,CAACzmB,EAAE,CACzB,GAAI,AAAkB,YAAY,OAAvB0mB,EACT,MAAM,OAAA,cAEL,CAFK,AAAIvwB,MACR,CAAC,2DAA2D,EAAE,OAAOuwB,EAAO;AAAA,oEAAuE,CAAC,EADhJ,oBAAA,OAAA,mBAAA,gBAAA,CAEN,EAEJ,CACF,0EATgBF,2BAAAA,qCAAAA,sCkD6LhB,oB8DjJY,EAoBA,IAAI,AAoFJ,EApFI,AAoGJ,EA4BA,EAYA,EAZI,EAAA,AAyDJ,IA7CQ,AAuIR,CA/Le,CAwDP,CAxDO,GAgBG,AAxHQ,EA2Y1B,AA3Y0B,AAwHR,EAuSlB,EAoBA,EAtOkB,CA0FH,CAoGP,AA4GR,AA1SkB,CA0FH,CAoGP,EAwCA,AAoHR,EApHQ,AA4HR,EAgBA,CAhKe,CA4Kf,CA5Ke,AAwFJ,CAgGX,CAhGW,CAwDH,AAgER,EAhEQ,AAwER,EAgBA,GA5DW,EAAA,GAyHX,EAYA,EAzK0B,AAkL1B,CA1GiB,CAQD,AAhFU,CAwET,CAQD,AA6ER,AArIkB,AAoM1B,EA/DQ,AA6ER,AAlN0B,CAwEP,AAhDM,CAkMzB,CAlJmB,AAyER,AAzHc,CAyMzB,CAhFW,CAoGX,EA4BA,CA/DS,CA+ET,CA/ES,CAQC,AAuFV,EAvFU,AAuGV,IAwEA,CApJa,EAjDU,AAiDV,AA2Kb,CA/LkB,AAvEU,CA0CL,CA6BL,AAgDF,AAgBF,AGn4Bd,AH4vB4B,EAuHZ,AAgBF,AAgCF,CAh6BZ,CAg5BgB,AAgBJ,EA54BZ,AA43BgB,GAh3BhB,AGnCS,EAAA,AZu/Bf,CSh8BM,CAo7BmB,EAh5BnB,AAg5BmB,GAh2BnB,GAgBA,AAu2BwB,EAAA,CA30BxB,GAYA,GA6BA,GAgBA,GA0BA,GAgEA,GAwBA,GAwBA,GAoCA,GAgBA,GAoBA,GAoBA,GAoDA,GAgBA,GAgCA,GAgBA,GAQA,GAgBA,GAYA,GAYA,GAwBA,GAQA,GAgBA,GAoCA,GASA,GAQA,GAQA,GAYA,GASA,GAeA,GA2BA,GAcA,GAQA,GAOA,GAoBA,GA4BA,GAgBA,GAgBA,GAgBA,GAgBA,GAwDA,GAuBA,GGlgCA,qP3BVZ,GAAA,EAAA,CAAA,CAAA,iDrFFA,EAAA,CAAA,CAAA,OACA,EAAA,CAAA,CAAA,OACA,EAAA,CAAA,CAAA,OACA,IAAA,GAAA,EAAA,CAAA,CAAA,OACA,EAAA,CAAA,CAAA,OAGe,GAAA,OAAS,+D0GSQ,eAAA,CAAQ,EAAA,wBAChB,CAAA,cAAA,CAAA,IAAoB,CAAC,EAAA,GAAgB,2BAGR,Cf2IG,Me3II,GAAM,EAAD,CAAC,oEAWlD,YAED,EAAA,EAAO,EAAA,MAAW,CAAG,EAAG,CAAC,GAAI,QbmFI,iBahF5B,CAAA,MAAA,SACM,KAAA,CAAM,CAAC,CAAA,SACrB,KAAA,CAAA,kBACa,CAAA,GACf,CAAA,CAAA,EAAA,CADwB,AACxB,MAAA,IAA0B,CAAA,CAAE,CbmFM,ManFE,EAAM,MAAA,AAAM,CAAC,CAAE,IAAA,CAAA,CAAA,CAAS,AAAT,CAAU,CAAC,kBAE9C,ChCgGiE,AgChGjE,ChCgGkE,CAAC,uCgChGnE,EAAA,EAAA,CAAA,mBAIF,CAAA,CAAA,EAAA,EAAA,OACE,CAAI,CAAC,EAAA,kBAEL,OACX,ChCiGC,CtEVO,A6EwBA,EyB/GJ,CAAC,CAAG,Cd2JG,AxFpEI,AsGvFN,CAAA,EAAM,CtGuFO,CAAA,MAAA,CAAA,IsGvFgB,GAC3B,CN6VS,AM7VA,CAAC,CAAC,ArG4EQ,CAAA,CqG3EX,EAAK,CbmFK,IAAA,CAAA,EanFK,CfgJP,AehJQ,EAAA,CAAA,CAAA,EAAW,CAAC,EfgJN,Ie7I9C,IAAA,IAAW,KAAA,EACT,GAAA,EAEE,EAAA,KAAA,CAAA,EAAA,GACA,EzB+G6C,ayBzGxC,QAAA,CAAA,OAAA,KACP,EAAU,EAAA,KAAA,CAAA,EAAA,GACZ,CAAA,KAAA,kBAGE,CAAA,CAAA,EAAsD,CjGiJ1C,AiG/I8B,EAAA,CAAA,EACzC,KAAA,CAAA,EAAA,GAAA,UAMJ,CAAI,CAAA,EAAA,EAAA,AAAoB,UAApB,OAAA,CAAoB,CAAA,EAAA,QACf,CAAA,CAAA,QAG6B,QAGxB,CAAA,EAAA,MAAA,CAAA,EAAiB,CAChC,EAAe,CAAA,CAAA,EAAA,eAEW,QAG3B,UAAA,OAAA,GAAA,AAAgD,GACjD,CADC,OAAA,IAAA,CAAA,GAAgD,MAAA,kBAUzB,oBAAA,UAAA,OAAA,GAAA,OAAA,GAAA,AAGd,C1BsLK,M0BzLS,eAKX,CAAA,EAAe,CbiEL,AxFMI,oEqGrE6C,CAAC,EV+FxC,GU5FnC,AACe,EAFV,QACL,GACe,UAAA,OAAA,GAAA,OAAA,GAGZ,MAAM,OAAA,CAAQ,OAMD,CtG2GG,AsGhHjB,AAKiB,CzG4CK,A+F6CA,A5FUQ,csGrGjB,CAAA,IAKnB,CV+FC,AU7FK,CAPoB,CPkLG,OO3KvB,GAAA,CACS,CAAA,CAAA,CAEb,CAAiC,EAAA,OAGX,KAHE,CAGb,MAAM,EAAsB,UAAZ,CAAI,CAAC,EAAE,GtGwGK,WsGpGhC,CtGwGG,GAAA,EsGxGK,CAAC,CAAA,EAAM,EAAK,GPgLG,GOhLG,CAAE,CVaK,AUbJ,GAAI,CACpC,GAAoB,UAAhB,OAAO,Ef4JI,Ce5JK,AAAqB,Cb8DH,Ma9DlB,mBAIH,EAAE,CPgLC,cO/KH,MAAO,KAChB,EN4VM,AM5VI,EAAI,KAAK,CAAA,EAAA,CAAK,QAC1B,CPkLG,A9FzGI,IqGzEI,CAAA,EASb,CNoWO,MAAA,CM7WY,QACA,CAAA,CAAA,EAAyC,CAC5D,GAAA,CAAK,MAAA,OAAa,CAAC,CN8VK,EM7VtB,OAAA,EAEF,AAH+B,CtGwGS,MsGrGxC,EAAA,GAAoB,CAAC,AAAC,GACpB,GAAe,CAAC,CAAE,EAAK,EAAD,GAAM,CAAC,CAAf,AAAgB,CAAG,GAAI,SAMA,EAAI,gBAK1C,EAAA,IACH,aAAA,WAA4B,gBAKpC,CClKM,SAAUG,GAAO,CAA2B,EAChD,GAAyB,EP8pBL,CTlTQ,CAAC,IgB5WI,EAAE,AAA/B,OAAO,QACH,MAAA,mCAGR,OAAO,CACT,CEOE,CAJU,EAAA,IAIV,CAJU,AAAO,GAiBlB,EAAA,CAAA,CAAA,CAAA,AT47B8B,ASz8B7B,CTy8B8B,ETvQF,WSuQe,AAAvB,CAAwB,ISz8B5C,CAAA,qBAA2C,CAGxC,EACH,UAAA,CAAA,aAIA,EAAA,KAAA,SAAA,CAAA,iBAIA,EAAA,KAAA,ClBqrBY,mBkBrrBZ,CAAA,QT47BwB,AAA2B,CAAC,kBS57BG,CAQvD,CAJU,EAAA,GT89BN,ES19BJ,AAJU,CAAQ,EAAA,AASnB,EAAA,CAAA,CATmB,AASnB,ATq9B6B,CAAC,ASr9B9B,AALC,UlB0rBiC,UkB1rBjC,CAAA,CT47BwC,CAAC,oBS57BI,CAI7C,ETq9BI,ASr9BJ,CTw7BiE,AAAlC,CAAmC,ISx7BlE,CAAA,QAAiB,CAQjB,ETq9BI,CSz9BM,KAAA,GAiBX,EAAA,CAAA,CAAA,CAbC,AAaD,UAbC,GAJoC,IAAA,CAAA,IAIpC,CAAA,CAAA,uBAAiD,CAIjD,ETq9BI,ASr9BJ,MAAA,CAAA,CAAA,OAAiB,CAIjB,ETq9BI,ASr9BJ,KTq9BkC,CAAC,ASz9BnC,GAIA,CAAA,CAAA,UAAuB,CAIvB,EAJA,AAIA,SAAA,CAAA,WAAuB,CAQvB,EARA,CAIU,CAIV,GAJc,AAAJ,IAAI,AAiCf,EAAA,CAAA,CAAA,CAAA,AA7BC,gBAAA,CAAA,CAAA,iBAAqC,CAIrC,EAAA,EAAA,IAAA,CAAA,CAAA,OAAiB,CAIjB,EAAA,EAAA,IAAA,CAAA,CAAA,OAAiB,CAIjB,EAAA,EAAA,KAAA,CAAA,CAAA,QAAmB,CAInB,EAAA,EAAA,KAAA,CAAA,CAAA,QAAmB,CAInB,EAAA,EAAA,GAAA,CAAA,CAAA,MAAe,CAIf,EAAA,EAAA,IAAA,CAAA,CAAA,OAAiB,CAIjB,EAAA,EAAA,EAAA,CAAA,CAAA,KAAa,CAQb,CAJU,EAAA,KAAA,GA6CX,CAzCC,CAJsB,AA6CvB,CAAA,CAAA,AA7CuB,CAItB,AAyCD,GA7CuB,CAAA,qBAItB,CAAA,CAAA,0BAAuD,CAIvD,EAAA,UAAA,cAAA,CAAA,CAAA,yBAAqD,CAIrD,EAAA,UAAA,eAAA,CAAA,CAAA,0BAAuD,CAIvD,EAAA,UAAA,qBAAA,CAAA,CAAA,gCAAmE,CAInE,EAAA,UAAA,qBAAA,CAAA,CAAA,gCAAmE,CAInE,EAAA,UAAA,mBAAA,CAAA,CAAA,8BAA+D,CAI/D,EAAA,UAAA,cAAA,CAAA,CAAA,yBAAqD,CAIrD,EAAA,UAAA,2BAAA,CAAA,CAAA,sCAA+E,CAI/E,EAAA,UAAA,oBAAA,CAAA,CAAA,+BAAiE,CAIjE,EAAA,UAAA,2BAAA,CAAA,CAAA,sCAA+E,CAI/E,EAAA,UAAA,aAAA,CAAA,CAAA,wBAAmD,CAQnD,GAJU,IAAA,IAaX,EAAA,CAAA,CATC,AASD,CATC,AASD,EAb0B,IAAA,uBAIzB,CAAA,CAAA,8BAA+D,CAI/D,EAAA,QAAA,CAAA,CAAA,GAAA,MAAqB,CAIrB,EAAA,WAAA,CAAA,CAAA,YAA2B,CAQ3B,GAJU,KAAA,GAyBX,EAAA,CAAA,CAAA,CArBC,AAqBD,EArBC,GAJ4B,IAAA,CAAA,sBAI5B,CAAA,CAAA,iCAAqE,CAIrE,EAAA,gBAAA,GAAA,CAAA,CAAA,oBAA2C,CAI3C,EAAA,gBAAA,MAAA,CAAA,CAAA,uBAAiD,CAIjD,EAAA,eAAA,CAAA,CAAA,gBAAmC,CAInC,EAAA,UAAA,CAAA,CAAA,IAAA,OAAyB,CAIzB,EAAA,GAAA,CAAA,CAAA,IAAW,CAQX,GAJU,CAIV,EARA,CAIc,CAAJ,GAAI,AASf,CATe,CASf,CAAA,CAAA,CALC,AAKD,gBALC,CAAA,CAAA,iBAAqC,CAIrC,EAAA,EAAA,UAAA,CAAA,CAAA,aAA6B,CAK7B,GADU,KAAA,AACV,GADkB,AA0BnB,EAAA,CAAA,CA1BmB,AA0BnB,CAzBC,AADkB,AA0BnB,qBAzBC,CAAA,CAAA,sBAA+C,CAI/C,EAAA,MAAA,CAAA,CAAA,CAAA,QAAmB,CAInB,EAAA,MAAA,MAAA,CAAA,CAAA,aAA6B,CAI7B,EAAA,MAAA,SAAA,CAAA,CAAA,gBAAmC,CAInC,EAAA,MAAA,qBAAA,CAAA,CAAA,4BAA2D,CAI3D,EAAA,KAAA,CAAA,CAAA,MAAe,CAIf,EAAA,MAAA,GAAA,CAAA,CAAA,UAAuB,CAQvB,CAJU,EAAA,IAIV,CAJiB,AAAP,EAAO,CAalB,EAAA,CAbkB,AAalB,CAbkB,AAalB,CATC,AASD,oBATC,CAAA,CAAA,qBAA6C,CAI7C,EAAA,KAAA,QAAA,CAAA,CAAA,cAA+B,CAI/B,EAAA,KAAA,SAAA,CAAA,CAAA,eAAiC,CAQjC,GAJU,KAAA,GAqBX,EAAA,CAAA,CAAA,CAjBC,AAiBD,EAjBC,GAJ4B,IAAA,CAAA,sBAI5B,CAAA,CAAA,iCAAqE,CAIrE,EAAA,gBAAA,YAAA,CAAA,CAAA,6BAA6D,CAI7D,EAAA,gBAAA,UAAA,CAAA,CAAA,2BAAyD,CAIzD,EAAA,gBAAA,YAAA,CAAA,CAAA,6BAA6D,CAI7D,EAAA,gBAAA,WAAA,CAAA,CAAA,4BAA2D,CAU3D,CAJU,EAAA,KAAA,GA6DX,CAzDC,CAyDD,AA7DuB,CA6DvB,CA7DuB,AA6DvB,AA7DuB,CAItB,AAyDD,GA7DuB,CAAA,qBAItB,CAAA,CAAA,0BAAuD,CAIvD,EAAA,IAAA,CAAA,CAAA,IAAA,CAAa,CAIb,EAAA,UAAA,CAAA,CAAA,WAAyB,CAIzB,EAAA,MAAA,CAAA,CAAA,EAAA,KAAiB,CAIjB,EAAA,UAAA,CAAA,CAAA,WAAyB,CAIzB,EAAA,QAAA,CAAA,CAAA,SAAqB,CAIrB,EAAA,KAAA,CAAA,CAAA,GAAA,GAAe,CAIf,EAAA,SAAA,CAAA,CAAA,UAAuB,CAIvB,EAAA,UAAA,QAAA,CAAA,CAAA,mBAAyC,CAIzC,EAAA,IAAA,CAAA,CAAA,IAAA,CAAa,CAIb,EAAA,UAAA,aAAA,CAAA,CAAA,wBAAmD,CAInD,EAAA,UAAA,EAAA,CAAA,CAAA,aAA6B,CAI7B,EAAA,UAAA,UAAA,CAAA,CAAA,qBAA6C,CAI7C,EAAA,UAAA,cAAA,CAAA,CAAA,yBAAqD,CAIrD,EAAA,QAAA,CAAA,CAAA,SAAqB,CAQrB,GAJU,KAAA,GAqBX,CAAA,CAAA,CAAA,CAAA,AAjBC,CAAA,EAJyB,IAAA,CAAA,qBAIzB,CAAA,CAAA,6BAA6D,CAI7D,EAAA,UAAA,CAAA,CAAA,CAAA,UAAyB,CAIzB,EAAA,GAAA,CAAA,CAAA,IAAW,CAIX,EAAA,CAJA,KAIA,CAAA,CAAA,KAAA,EAAiB,CAIjB,EAAA,IAAA,CAAA,CAAA,KAAa,CAQb,CAJU,AAJV,EAIU,KAAA,GAqBX,CAAA,AAjBC,CAJsB,AAqBvB,CAAA,CArBuB,AAqBvB,AArBuB,CAItB,GAJsB,CAAA,qBAItB,CAAA,CAAA,0BAAuD,CAIvD,EAAA,UAAA,cAAA,CAAA,CAAA,yBAAqD,CAIrD,EAAA,UAAA,OAAA,CAAA,CAAA,kBAAuC,CAIvC,EAAA,UAAA,UAAA,CAAA,CAAA,qBAA6C,CAI7C,EAAA,UAAA,QAAA,CAAA,CAAA,mBAAyC,CAQzC,CAJU,EAAA,KAAA,GAiCX,EAAA,AA7BC,CA6BD,AAjCwB,CAiCxB,CAAA,AAjCwB,AAIvB,AAJuB,IAAA,CAAA,qBAIvB,CAAA,CAAA,2BAAyD,CAIzD,EAAA,MAAA,CAAA,CAAA,GAAA,IAAiB,CAIjB,EAAA,KAAA,CAAA,CAAA,IAAA,EAAe,CAIf,EAAA,SAAA,CAAA,CAAA,UAAuB,CAIvB,EAAA,WAAA,OAAA,CAAA,CAAA,mBAAyC,CAIzC,EAAA,WAAA,CAAA,CAAA,CAAA,aAA6B,CAI7B,EAAA,WAAA,CAAA,CAAA,YAA2B,CAI3B,EAAA,SAAA,CAAA,CAAA,UAAuB,CAQvB,CAJU,EAAA,IAAA,IAaX,AATC,CAJqB,CAatB,CAbsB,AAatB,AAbsB,CAatB,CAAA,AATC,EAJqB,sBAIrB,CAAA,CAAA,yBAAqD,CAIrD,EAAA,SAAA,CAAA,CAAA,UAAuB,CAIvB,EAAA,SAAA,aAAA,CAAA,CAAA,uBAAiD,CAQjD,GAJU,KAIV,AAJU,GAAQ,AAiBnB,EAAA,CAAA,CAjBmB,AAiBnB,CAbC,AAJkB,AAiBnB,oBAbC,CAAA,CAAA,qBAA6C,CAI7C,EAAA,IAAA,CAAA,CAAA,KAAa,CAIb,EAAA,KAAA,CAAA,CAAA,MAAe,CAIf,EAAA,KAAA,CAAA,CAAA,MAAe,CAQf,GAJU,IAAA,IAiBX,EAAA,CAAA,CAbC,AAaD,CAbC,AAaD,EAjB0B,IAAA,sBAIzB,CAAA,CAAA,6BAA6D,CAI7D,EAAA,aAAA,OAAA,CAAA,CAAA,qBAA6C,CAI7C,EAAA,aAAA,UAAA,CAAA,CAAA,wBAAmD,CAInD,EAAA,aAAA,QAAA,CAAA,CAAA,sBAA+C,CAQ/C,GAJU,IAAA,CAIV,GAJkB,AAiDnB,EAAA,CAAA,CAjDmB,AAiDnB,AAjDmB,CAiDnB,AA7CC,qBAAA,CAAA,CAAA,sBAA+C,CAI/C,EAAA,MAAA,UAAA,CAAA,CAAA,iBAAqC,CAIrC,EAAA,MAAA,WAAA,CAAA,CAAA,kBAAuC,CAIvC,EAAA,MAAA,WAAA,CAAA,CAAA,kBAAuC,CAIvC,EAAA,MAAA,aAAA,CAAA,CAAA,oBAA2C,CAI3C,EAAA,MAAA,UAAA,CAAA,CAAA,iBAAqC,CAIrC,EAAA,MAAA,cAAA,CAAA,CAAA,qBAA6C,CAI7C,EAAA,MAAA,aAAA,CAAA,CAAA,oBAA2C,CAI3C,EAAA,MAAA,UAAA,CAAA,CAAA,iBAAqC,CAIrC,EAAA,MAAA,WAAA,CAAA,CAAA,kBAAuC,CAIvC,EAAA,MAAA,YAAA,CAAA,CAAA,mBAAyC,CAIzC,EAAA,MAAA,uBAAA,CAAA,CAAA,8BAA+D,CAQ/D,CAJU,EAAA,IAAA,GAIV,CAJoB,AAarB,EAbqB,AAarB,CAAA,CAAA,CATC,AASD,CAbqB,sBAIpB,CAAA,CAAA,wBAAmD,CAInD,EAAA,QAAA,QAAA,CAAA,CAAA,iBAAqC,CAIrC,EAAA,QAAA,gBAAA,CAAA,CAAA,yBAAqD,CAQrD,GAJU,IAAA,IA6BX,AAzBC,EAyBD,CAAA,AA7BsB,CA6BtB,CAzBC,AAyBD,EA7BsB,sBAIrB,CAAA,CAAA,yBAAqD,CAIrD,EAAA,SAAA,OAAA,CAAA,CAAA,iBAAqC,CAIrC,EAAA,SAAA,OAAA,CAAA,CAAA,iBAAqC,CAIrC,EAAA,SAAA,QAAA,CAAA,CAAA,kBAAuC,CAIvC,EAAA,SAAA,SAAA,CAAA,CAAA,mBAAyC,CAIzC,EAAA,SAAA,WAAA,CAAA,CAAA,qBAA6C,CAI7C,EAAA,SAAA,cAAA,CAAA,CAAA,wBAAmD,CAQnD,CAJU,EAAA,KAAA,EAIV,CASD,AAbqB,CAarB,CAbqB,AAarB,CAAA,CAAA,CATC,CAJoB,CAAA,qBAIpB,CAAA,CAAA,wBAAmD,CAInD,EAAA,QAAA,OAAA,CAAA,CAAA,gBAAmC,CAInC,EAAA,QAAA,OAAA,CAAA,CAAA,gBAAmC,CAKnC,GADU,KAAA,GAKX,EAAA,CAAA,CAAA,CAJC,AAID,UAJC,GADoC,IAAA,CAAA,sBACpC,CAAA,CAAA,yCAAqF,CACrF,EAAA,kBAAA,CAAA,CAAA,IAAA,eAAyC,CACzC,EAAA,QAAA,CAAA,CAAA,SAAqB,CACrB,EAAA,EADA,aACA,CAAA,CAAA,OAAA,SAAmC,CAQnC,GAJU,KAIV,AAJU,GAAQ,AAanB,EAAA,CAAA,CAAA,AAbmB,CAIlB,AASD,AAbmB,WAIlB,CAAA,CAAA,YAA2B,CAI3B,EAAA,MAAA,EAAA,CAAA,CAAA,SAAqB,CAIrB,EAAA,MAAA,MAAA,CAAA,CAAA,aAA6B,CAQ7B,GAJU,KAAA,GASX,EAAA,CAAA,CAAA,CAAA,AALC,UAAA,GAJoC,GAIpC,CAAA,AAJoC,CAIpC,AAJoC,iBAIC,CAIrC,EAAA,YAAA,CAAA,CAAA,UAAA,GAA6B,CAQ7B,GAJU,IAAA,IAIV,AAKD,EAAA,CAAA,AATsB,CAStB,CAAA,AALC,EAJqB,qBAIrB,CAAA,CAAA,wBAAmD,CAInD,EAAA,SAAA,UAAA,CAAA,CAAA,oBAA2C,CAQ3C,GAJU,KAAA,GAqBX,EAAA,CAAA,CAAA,CAjBC,AAiBD,SAjBC,GAJmC,IAAA,AAInC,CAJmC,AAInC,CAAA,iBAAqC,CAIrC,EAAA,IAAA,CAAA,CAAA,KAAa,CAIb,EAAA,GAAA,CAAA,CAAA,IAAW,AAJX,CAQA,EAAA,IAAA,CAAA,CAAA,KAJA,AAIa,CAIb,EAAA,SAAA,AAJA,CAIA,CAAA,UAAuB,CAKvB,CALA,EAIU,IAAA,IAKX,EAAA,CAAA,CAAA,CAAA,AAJC,CAAA,GAD2B,IAAA,WAC3B,CAAA,CAAA,oBAA2C,CAC3C,EAAA,eAAA,OAAA,CAAA,CAAA,uBAAiD,CACjD,EAAA,eAAA,CAAA,CAAA,gBAAmC,CACnC,EAAA,UAAA,CAAA,CAAA,GAAA,QAAyB,CAQzB,GAJU,KAAA,GAaX,EAAA,CAAA,CAAA,CAAA,AATC,GAJ0B,IAAA,CAAA,EAI1B,CAAA,CAAA,WAAyB,CAIzB,EAAA,WAAA,CAAA,CAAA,CAAA,WAA2B,CAI3B,EAAA,SAAA,CAAA,CAAA,GAAA,OAAuB,CAQvB,GAJU,KAAA,GAiCX,EAAA,CAAA,CAAA,CAAA,AA7BC,GAAA,CAAA,CAAA,CAJ6B,AAI7B,IAJ6B,CAAA,AAIhB,CAIb,EAAA,EAAA,CAAA,CAAA,GAAS,CAIT,EAAA,EAAA,CAAA,CAAA,GAJA,AAIS,CAIT,EAAA,EAAA,CAAA,CAAA,GAJA,AAIS,CAIT,EAAA,EAAA,CAAA,CAAA,GAJA,AAIS,CAIT,EAAA,EAAA,CAAA,CAAA,GAAS,AAJT,CAQA,EAAA,EAAA,CAAA,CAAA,GAAS,AAJT,CAQA,EAAA,EAAA,CAAA,CAAA,GAAS,AAJT,CASA,CADU,EAAA,KAAA,CAJV,EAUD,EAAA,CAAA,CAAA,CAAA,AALC,CAAA,CAD2B,EAAA,IAAA,CAAA,QAC3B,CAAA,CAAA,kBAAuC,CACvC,EAAA,eAAA,QAAA,CAAA,CAAA,wBAAmD,CACnD,EAAA,eAAA,KAAA,CAAA,CAAA,qBAA6C,CAC7C,EAAA,eAAA,KAAA,CAAA,CAAA,qBAA6C,CAC7C,EAAA,eAAA,GAAA,CAAA,CAAA,mBAAyC,CAKzC,CADU,EAAA,KAAA,GAKX,EAAA,CAAA,CAAA,CAJC,AAID,IAJC,CAD8B,EAAA,IAAA,CAAA,QAC9B,CAAA,CAAA,qBAA6C,CAC7C,EAAA,kBAAA,CAAA,CAAA,mBAAyC,CACzC,EAAA,kBAAA,GAAA,CAAA,CAAA,sBAA+C,CAC/C,EAAA,kBAAA,IAAA,CAAA,CAAA,uBAAiD,CAKjD,CADU,EAAA,KAAA,GAKX,EAAA,CAAA,CAAA,CAJC,AAID,IAJC,CAD8B,EAAA,IAAA,CAAA,QAC9B,CAAA,CAAA,qBAA6C,CAC7C,EAAA,kBAAA,CAAA,CAAA,CAAA,oBAA2C,CAC3C,EAAA,kBAAA,CAAA,CAAA,CAAA,oBAA2C,CAC3C,EAAA,kBAAA,EAAA,CAAA,CAAA,qBAA6C,CAK7C,GADU,KACV,AADU,GAAQ,AASnB,CAAA,CAAA,CAAA,CATmB,AASnB,CARC,AADkB,iBAClB,CAAA,CAAA,kBAAuC,CACvC,EAAA,MAAA,mBAAA,CAAA,CAAA,0BAAuD,CACvD,EAAA,MAAA,qBAAA,CAAA,CAAA,4BAA2D,CAC3D,EAAA,MAAA,YAAA,CAAA,CAAA,mBAAyC,CACzC,EAAA,MAAA,sBAAA,CAAA,CAAA,6BAA6D,CAC7D,EAAA,MAAA,SAAA,CAAA,CAAA,gBAAmC,CACnC,EAAA,MAAA,UAAA,CAAA,CAAA,iBAAqC,CACrC,EAAA,MAAA,iBAAA,CAAA,CAAA,wBAAmD,CAKnD,GADU,KAAA,GACV,AAKD,CAAA,CAAA,CAAA,AANsB,CAMtB,CALC,EADqB,CAAA,OACrB,CAAA,CAAA,WAAyB,CACzB,EAAA,SAAA,CAAA,CAAA,CAAA,WAAyB,CACzB,EAAA,MAAA,CAAA,CAAA,CAAA,MAAiB,CACjB,EAAA,QAAA,CAAA,CAAA,SAAqB,CACrB,EAAA,SAAA,EAAA,CAAA,CAAA,YAA2B,CAS3B,GALU,KAAA,GAYX,EAAA,CAAA,CAAA,CAPC,AAOD,KAPC,CAAA,CAAA,KAAA,CAAe,CAMf,CAXsC,CAWtC,GAXsC,CAAA,CAWtC,CAAA,CAAA,MAAe,CAWf,CAPU,EAAA,KAAA,GAwBX,CA5BC,CA4BD,CAAA,CAAA,CAjBC,AAiBD,MAjBC,CAAA,CAAA,AAPiC,EAAA,IAAA,CAAA,AAOhB,CAKjB,EAAA,MAAA,CAAA,CAAA,OAAiB,CAKjB,EAAA,GALA,UAKA,CAAA,CAAA,MAAA,QAA+B,CAM/B,EAAA,QAAA,CAAA,CAAA,SAAqB,CASrB,CATA,EAIU,KAAA,GAWX,CAAA,CAAA,CAAA,CAAA,CANC,OAAA,EAAA,CAAA,AALiC,CAKjC,GALiC,CAAA,MAKV,CAKvB,EAAA,QAAA,CAAA,CAAA,SAAqB,CAKrB,CALA,EAIU,KAAA,CACV,EAID,CALoB,CAKpB,CAAA,CAAA,CAJC,AADmB,AAKpB,CALoB,gBACnB,CAAA,CAAA,kBAAuC,CACvC,EAAA,OAAA,GAAA,CAAA,CAAA,WAAyB,CACzB,EAAA,MAAA,CAAA,CAAA,OAAiB,CACjB,EAAA,MAAA,CAAA,CAAA,OAAiB,CAKjB,GADU,IAAA,GACV,CAGD,CAAA,CAJqB,AAIrB,CAAA,CAAA,CAHC,CADoB,iBACpB,CAAA,CAAA,mBAAyC,CACzC,EAAA,QAAA,CAAA,CAAA,SAAqB,CACrB,EAAA,QAAA,CAAA,CAAA,CAAA,UAAuB,CAQvB,GAJU,KAAA,GAiBX,EAAA,CAAA,CAAA,CAbC,AAaD,EAbC,GAJ4B,IAAA,CAAA,sBAI5B,CAAA,CAAA,iCAAqE,CAIrE,EAAA,gBAAA,OAAA,CAAA,CAAA,wBAAmD,CAInD,EAAA,gBAAA,CAAA,CAAA,CAAA,kBAAuC,CAIvC,EAAA,eAAA,CAAA,CAAA,gBAAmC,CAQnC,GAJU,IAAA,IAyBX,EArBC,AAqBD,CAAA,CAAA,CArBC,AAJuB,AAyBxB,IAzBwB,gBAIvB,CAAA,CAAA,qBAA6C,CAI7C,EAAA,IAAA,CAAA,CAAA,KAAA,AAAa,CAIb,EAAA,KAAA,CAAA,CAAA,IAAA,EAAe,CAIf,EAAA,KAAA,CAAA,CAAA,IAAA,EAAe,CAIf,EAAA,KAAA,CAAA,CAAA,IAAA,EAAe,CAIf,EAAA,QAAA,CAAA,CAAA,CAAA,QAAqB,CAQrB,GAJU,IAAA,IAaX,EAAA,CAAA,CAAA,CATC,AASD,GAb2B,IAAA,sBAI1B,CAAA,CAAA,8BAA+D,CAI/D,EAAA,cAAA,QAAA,CAAA,CAAA,uBAAiD,CAIjD,EAAA,cAAA,OAAA,CAAA,CAAA,sBAA+C,CAQ/C,GAJU,KAAA,GAaX,EAAA,CATC,AASD,CAAA,CATC,AASD,CAbyB,IAAA,CAAA,qBAIxB,CAAA,CAAA,4BAA2D,CAI3D,EAAA,YAAA,QAAA,CAAA,CAAA,qBAA6C,CAI7C,EAAA,YAAA,OAAA,CAAA,CAAA,oBAA2C,CAQ3C,GAJU,KAAA,GAaX,EAAA,CAAA,CAAA,CATC,AASD,GAb2B,IAAA,CAAA,qBAI1B,CAAA,CAAA,8BAA+D,CAI/D,EAAA,cAAA,cAAA,CAAA,CAAA,6BAA6D,CAI7D,EAAA,cAAA,CAAA,CAAA,CAAA,gBAAmC,CAQnC,GAJU,KAAA,GAaX,CATC,CASD,CAAA,CAbuB,AAavB,CATC,AASD,GAbuB,CAAA,qBAItB,CAAA,CAAA,0BAAuD,CAIvD,EAAA,UAAA,iBAAA,CAAA,CAAA,4BAA2D,CAI3D,EAAA,UAAA,aAAA,CAAA,CAAA,wBAAmD,CAQnD,CAJU,EAAA,EAIV,CAJe,EAAA,AAAL,AAAK,GAqDhB,CArDgB,CAAA,AAqDhB,CAAA,CAAA,CAjDC,AAiDD,iBAjDC,CAAA,CAAA,kBAAuC,CAIvC,EAAA,GAAA,YAAA,CAAA,CAAA,gBAAmC,CAInC,EAAA,GAAA,sBAAA,CAAA,CAAA,0BAAuD,CAIvD,EAAA,GAAA,YAAA,CAAA,CAAA,gBAAmC,CAInC,EAAA,GAAA,iBAAA,CAAA,CAAA,qBAA6C,CAI7C,EAAA,GAAA,iBAAA,CAAA,CAAA,qBAA6C,CAI7C,EAAA,GAAA,YAAA,CAAA,CAAA,gBAAmC,CAInC,EAAA,GAAA,sBAAA,CAAA,CAAA,0BAAuD,CAIvD,EAAA,GAAA,YAAA,CAAA,CAAA,gBAAmC,CAInC,EAAA,GAAA,iBAAA,CAAA,CAAA,qBAA6C,CAI7C,EAAA,GAAA,iBAAA,CAAA,CAAA,qBAA6C,CAI7C,EAAA,GAAA,iBAAA,CAAA,CAAA,qBAA6C,CAI7C,EAAA,GAAA,iBAAA,CAAA,CAAA,qBAA6C,CAQ7C,IAJU,KAAA,GAoBX,EAAA,CAAA,CAAA,CAhBC,AAgBD,EAhBC,IAJ6B,IAAA,CAAA,sBAI7B,CAAA,CAAA,kCAAuE,CAKvE,GAAA,OAAA,CAAA,CAAA,OAAA,CAAmB,CAKnB,GAAA,SAAA,CAAA,CAAA,KAAA,KAAuB,CAKvB,GAAA,YAAA,CAAA,CAAA,EAAA,WAA6B,CAQ7B,IAJU,KAAA,GAuBX,EAAA,CAAA,CAAA,CAnBC,AAmBD,OAnBC,IAJkC,IAAA,CAAA,YAIlC,CAAA,CAAA,6BAA6D,CAI7D,GAAA,IAAA,CAAA,CAAA,KAAa,CAIb,GAAA,KAAA,CAAA,AAJA,CAIA,MAAe,CAKf,GAAA,IAAA,AALA,CAKA,CAAA,KAAa,CAKb,GAAA,MALA,OAKA,CAAA,CAAA,MAAA,QAA+B,AAwhCjC,OACa,GAQX,SARuB,CAAA,CAQvB,CAAY,CAAkB,CAAA,CAE5B,MAAM,EAAkC,CAAA,CAAE,CAC1C,EADa,EACR,MAAM,IAAI,CAAI,EAAS,MAAD,CAAQ,CAAC,OAAO,EAAE,CAAE,AAC7C,CAAO,CAAC,CAAI,CAAC,CAAC,CAAC,CAAC,CAAG,CAAI,CAAC,CAAC,CAAC,CAE5B,IAAI,CAAC,OAAO,CAAG,EAGf,IAAI,CAAC,AAHiB,gBAGD,CAAG,EAG1B,IAAI,EAH8B,AAG9B,CACF,OAAO,IAAI,CAAC,gBAAgB,CAAC,IAAI,EAAE,CAEtC,CAkWD,MACa,GA0CX,IAAI,IAAI,EAAA,UA1C0B,CAAA,UA2ChC,GAAI,CAAA,OAAA,EAAA,OAAA,EAAA,OAAA,EAAA,OAAA,EAAA,IAAI,CAAC,UAAA,AAAU,EAAA,IAAA,CAAA,CAAA,CAAA,CAAA,CAAG,EAAC,AAAC,CAAL,CAAK,CAAL,GAAK,CAAA,CAAA,AAAL,CAAK,CAAA,CAAA,AAAE,EAAP,CAAK,AAAL,EAAK,EAAE,AAAO,EAAE,CAAX,GAAW,CAAA,CAAA,AAAX,CAAW,AAAX,CAAW,CAAA,GAAA,EAAA,AAAK,EAAA,GAAL,CAAK,CAAA,EAAA,CAAL,CAAA,AAAO,GAAF,GAAE,AAAM,IAAR,AAAa,CAAC,CACpD,CADsD,EAAhB,IAGpC,AAFK,IAED,CAAC,IAFS,MAEC,EAAI,IAAI,CAAC,UAAU,CAAC,MAAM,CAAG,CAAC,EAAE,AACjD,OAAO,CAAC,IAAI,CACV,mFAAmF,CACpF,CAEH,IAAI,EAAO,EAAH,AAAK,CACT,GAAkB,EAChB,EAAe,CADM,CACJ,CACvB,IAAK,CAFc,EACD,CACP,IAAI,CAAI,OAAA,EAAA,OAAA,EAAA,OAAA,EAAA,OAAA,EAAA,IAAI,CAAC,UAAA,AAAU,EAAG,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,EAAC,AAAC,CAAF,CAAI,CAAJ,GAAI,CAAA,CAAA,AAAJ,CAAI,CAAA,CAAA,EAAJ,CAAA,AAAI,EAAA,EAAA,AAAO,EAAA,CAAP,GAAO,CAAA,CAAP,CAAA,AAAO,EAAE,GAAF,EAAO,AAAL,EAAK,EAAA,AAAI,CAAX,CAAO,AAAM,CAAE,CAC7D,EADqD,AAAP,EACzC,EADgD,CAC1C,CAD0C,AACzC,EAAW,EAAW,CADmB,EACf,EAAjB,CADgC,CAAA,CACpB,CAAW,CAAC,OAAO,CAAC,GAEnC,CAFuC,CAAC,CAAE,GAEpC,GAApB,GACc,MADL,GACc,GAAvB,IACgB,IAAI,CADX,EACR,QAAsC,EAA5B,EAAa,CAAe,CAAS,CAAC,CAEjD,CADA,CACa,IAFqB,AAEjB,CAAC,GAGtB,EAHgB,CAGS,GAHM,CAAC,IAGC,EAA7B,OAAO,EAAK,EAAD,EAAK,CAAe,CACjC,GAA4B,SAAS,EAAjC,OAAO,EAAK,EAAD,KAAQ,EAAkB,EAAK,EAAD,KAAQ,CACnD,CADqD,QAGvD,GAAkB,EAClB,EADsB,CACd,CAAJ,CAAS,EAAD,EAAK,AAClB,CACF,AAHkB,CAUnB,OANI,EAAa,MAAM,CAAG,CAAC,EAAX,AAAa,AAC3B,OAAO,CAAC,IAAI,CACV,CAAA,yBAAA,EAA4B,EAAY,UAAA,qHAAA,CAAiI,CAC1K,CAGI,EAAkB,IAAI,GAAG,EAalC,IAAI,AAboB,GAAmB,CAanC,EAAA,qBACN,GAAI,CAAA,OAAA,EAAA,OAAA,EAAA,OAAA,EAAA,OAAA,EAAA,IAAI,CAAC,UAAA,AAAU,EAAA,IAAA,CAAA,CAAA,CAAA,CAAA,CAAG,EAAC,AAAC,CAAL,CAAK,CAAL,GAAK,CAAA,CAAA,AAAL,CAAK,CAAA,CAAA,AAAE,EAAP,CAAA,AAAK,EAAA,EAAE,AAAO,EAAE,CAAX,GAAW,CAAA,CAAX,AAAW,CAAX,AAAW,CAAA,CAAA,GAAA,EAAA,AAAK,EAAA,GAAL,CAAK,CAAA,EAAA,CAAL,CAAA,AAAO,GAAF,GAAE,AAAM,IAAR,AAAa,CAAC,CACpD,CADsD,EAAhB,IAC/B,AAEL,IAAI,CAAC,IAFS,MAEC,EAAI,IAAI,CAAC,UAAU,CAAC,MAAM,CAAG,CAAC,EAAE,AACjD,OAAO,CAAC,IAAI,CACV,mFAAmF,CACpF,CAEH,IAAI,EAAO,EAAE,AAAL,CACF,EAAe,EAAE,CACvB,IAAK,GADa,CACP,IAAI,CAAI,OAAA,EAAA,OAAA,EAAA,OAAA,EAAA,OAAA,EAAA,IAAI,CAAC,UAAU,AAAV,EAAa,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,EAAC,AAAC,CAAF,CAAI,CAAJ,GAAI,CAAA,CAAJ,AAAI,CAAA,CAAA,CAAA,EAAJ,CAAA,AAAI,EAAA,EAAA,AAAO,EAAA,CAAP,GAAO,CAAA,CAAP,CAAA,AAAO,EAAE,GAAF,EAAE,AAAK,EAAA,EAAI,AAAJ,CAAP,CAAa,AAAN,CAAQ,CAC7D,EAD8C,AAAO,EAChD,EADgD,CAC1C,CAAC,AADyC,EAC9B,EAAW,CADmB,EACf,EAAjB,CADgC,CAAA,CACpB,CAAW,CAAC,OAAO,CAAC,GAEnC,CAFuC,CAAC,CAAE,SAE9B,GAA1B,IACgB,IAAI,CADX,EACR,QAAsC,EAA5B,EAAa,CAAe,CAAS,CAAC,CAEjD,CADA,CACa,IAAI,AAFiB,CAEhB,GAGlB,EAHY,AAGP,EAAD,EAHuB,CAAC,KAGb,EAAoC,QAAQ,EAAE,AAA1C,OAAO,EAAK,EAAD,QAAW,CAAC,IAAI,GAChD,GAAQ,CAAJ,GAAQ,CAAC,EAAK,EAAD,QAAW,CAAC,KAAI,CAAC,AAErC,CAMD,OALI,EAAa,MAAM,CAAG,CAAC,EACzB,AAD2B,AAAb,OACP,CAAC,IAAI,CACV,CAAA,yBAAA,EAA4B,EAAY,UAAA,qHAAA,CAAiI,CAC1K,CAEI,EAAK,EAAD,IAAO,CAAG,CAAC,CAAG,IAAI,CAAC,IAAI,CAAC,GAAG,EAgDxC,IAAI,GAhD6C,UAgDhC,EAAA,qBACf,GAAI,CAAA,OAAA,EAAA,OAAA,EAAA,OAAA,EAAA,OAAA,EAAA,IAAI,CAAC,UAAA,AAAU,EAAA,IAAA,CAAA,CAAA,CAAA,CAAA,CAAG,EAAC,AAAC,CAAL,CAAK,CAAL,GAAK,CAAA,CAAL,AAAK,CAAA,CAAA,CAAA,AAAE,EAAP,CAAK,AAAL,EAAK,EAAE,AAAO,EAAE,CAAX,GAAW,CAAA,CAAX,AAAW,CAAX,AAAW,CAAA,CAAA,GAAA,EAAA,AAAK,AAAL,EAAK,GAAL,CAAK,CAAA,EAAA,CAAL,CAAA,AAAO,GAAF,GAAE,AAAM,IAAR,AAAa,CAAC,CACpD,CADsD,EAAhB,IAC/B,AAEL,IAAI,CAAC,IAFS,MAEC,EAAI,IAAI,CAAC,UAAU,CAAC,MAAM,CAAG,CAAC,EAAE,AACjD,OAAO,CAAC,IAAI,CACV,6FAA6F,CAC9F,CAEH,IAAM,EAAgB,OAAA,EAAA,EAAH,KAAG,EAAA,OAAA,EAAA,OAAA,EAAA,IAAI,CAAC,UAAA,AAAU,EAAG,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,EAAC,AAAC,CAAF,CAAI,CAAJ,GAAI,CAAA,CAAJ,AAAI,CAAA,CAAA,CAAA,EAAJ,CAAA,AAAI,EAAA,EAAA,AAAO,EAAE,CAAT,GAAS,CAAA,CAAA,AAAT,CAAS,AAAT,CAAS,CAAA,GAAA,EAAA,AAAK,EACtD,GADiD,CACjD,CAAA,CAAA,CAAA,CADiD,AACjD,CAAA,AADiD,GACjD,EAAA,CAAM,CAAC,AAAC,GAAR,AAAiB,CAAL,CAAU,EAAD,CAArB,CAAA,QAAkC,CAAA,CACnC,GAAG,CAAE,AAAD,GAAU,CAAL,CAAU,EAAD,UAAa,EAC/B,MAAM,CACL,AAAC,GACC,KAAiB,IADN,GACC,AAElB,EAFgC,CAC7B,AACC,OAAA,EAAa,KAAA,CAAA,CAAb,EAAe,EAAF,IAAE,AAAM,CAAR,GAAa,CAAb,AAAc,CAG/B,CAHiC,EAA7B,IAGG,EAyBT,IAAI,GA5Be,IAGG,CAHH,KAAA,CA4BD,AA5BC,EA4BD,uBAChB,GAAI,CAAA,OAAA,EAAA,OAAA,EAAA,OAAA,EAAA,OAAA,EAAA,IAAI,CAAC,UAAA,AAAU,EAAA,IAAA,CAAA,CAAA,CAAA,CAAA,CAAG,EAAC,AAAC,CAAL,CAAK,CAAL,GAAK,CAAA,CAAL,AAAK,CAAA,CAAA,CAAA,AAAE,EAAP,CAAK,AAAL,EAAK,EAAE,AAAO,EAAE,CAAX,GAAW,CAAA,CAAA,AAAX,CAAW,AAAX,CAAW,CAAA,GAAA,EAAA,AAAK,EAAA,GAAL,CAAK,CAAA,EAAA,CAAL,CAAA,AAAO,GAAF,GAAE,AAAM,IAAK,AAAb,CAAc,CACpD,CADsD,EAAhB,IAC/B,AAEL,IAAI,CAAC,IAFS,MAEC,EAAI,IAAI,CAAC,UAAU,CAAC,MAAM,CAAG,CAAC,EAAE,AACjD,OAAO,CAAC,IAAI,CACV,8FAA8F,CAC/F,CAEH,IAAM,EAAiB,OAAA,EAAA,GAAH,IAAG,EAAA,OAAA,EAAA,OAAA,EAAA,IAAI,CAAC,UAAU,AAAV,EAAa,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,EAAE,AAAD,CAAD,CAAI,CAAJ,GAAI,CAAA,CAAJ,AAAI,CAAA,CAAA,CAAA,EAAJ,CAAI,AAAJ,EAAI,EAAA,AAAO,EAAE,CAAT,GAAS,CAAA,CAAT,AAAS,CAAT,AAAS,CAAA,CAAA,GAAA,EAAA,AAAK,EACvD,GADkD,CAClD,CAAA,CAAA,CAAA,CADkD,AAClD,CADkD,AAClD,GAAA,EAAA,CAAM,CAAC,AAAC,GAAS,AAAjB,CAAY,CAAU,EAAD,CAArB,CAAA,UAAoC,CAAA,CACrC,GAAG,CAAC,AAAC,GAAS,CAAL,CAAU,EAAD,YAAe,EACjC,MAAM,CACL,AAAC,QACoB,IAAnB,EADa,CAGnB,EAFkC,CAC/B,AACC,QAFgB,CAEF,KAAA,CAAA,CAAd,EAAgB,CAAF,IAAA,CAAE,AAAM,GAAtB,CAA2B,CAAC,CAAd,AAIlB,CAJkC,MAI3B,IAJW,GAIX,EAJW,AAIX,KAJW,CAIX,AAJW,EAIG,KAAA,CAAA,CAAd,CAAc,CAAG,EAAC,AAAC,CAAL,CAAO,IAAP,AAAO,CAAA,CAAA,CAAA,CAAP,AAAO,CAAA,GAArB,AAAqB,CAAI,CAAJ,AAwB9B,IAAI,CAxB0B,KAAA,CAAA,CAAP,KAAA,KAAA,CAAA,AAwBA,EAAA,uBACrB,GAAI,QAAA,EAAA,OAAA,EAAA,OAAA,EAAA,OAAA,EAAA,IAAI,CAAC,UAAU,AAAV,EAAU,IAAA,CAAA,CAAA,CAAA,CAAA,CAAG,EAAC,AAAC,CAAL,CAAK,CAAL,GAAK,CAAA,CAAL,AAAK,CAAA,CAAA,CAAA,AAAE,EAAP,CAAK,AAAL,EAAK,EAAE,AAAO,EAAE,CAAX,GAAW,CAAA,CAAX,AAAW,CAAA,AAAX,CAAW,CAAA,GAAA,EAAA,AAAK,EAAA,GAAL,CAAK,CAAA,EAAA,CAAL,CAAO,AAAP,GAAK,GAAE,AAAM,IAAR,AAAa,CAAC,CACpD,CADsD,EAAhB,IAC/B,AAEL,IAAI,CAAC,IAFS,MAEC,EAAI,IAAI,CAAC,UAAU,CAAC,MAAM,CAAG,CAAC,EAAE,AACjD,OAAO,CAAC,IAAI,CACV,oGAAoG,CACrG,CAEH,IAAM,EAAsB,OAAA,EAAA,OAAA,CAAH,CAAG,OAAA,EAAA,OAAA,EAAA,IAAI,CAAC,UAAA,AAAU,EAAG,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,EAAC,AAAC,CAAF,CAAI,CAAJ,GAAI,CAAA,CAAJ,AAAI,CAAA,CAAA,CAAA,EAAJ,CAAA,AAAI,EAAA,EAAA,AAAO,EAAE,CAAT,GAAS,CAAA,CAAT,AAAS,CAAT,AAAS,CAAA,CAAA,GAAA,EAAA,AAAK,EAC5D,GADuD,CACvD,CAAA,CAAA,CAAA,CAAA,AADuD,CAAA,AACvD,GAAA,EAAA,CAAM,CAAC,AAAC,GAAR,AAAiB,CAAL,CAAU,EAAD,CAArB,CAAA,eAAyC,CAAA,CAC1C,GAAG,CAAC,AAAC,GAAS,CAAL,CAAU,EAAD,iBAAoB,EACtC,MAAM,CACL,AAAC,QACyB,IAAxB,GAEN,EAFuC,CACpC,AACC,CAHoB,MAGpB,EAAmB,IAFE,CAEF,CAAA,CAAnB,EAAqB,MAAA,AAAM,EAAR,EAAa,CAAC,CAGrC,CAHuB,AAAgB,IAAhB,EAGhB,EAHH,KAGG,EAAA,MAAA,EAAmB,IAHH,CAGG,CAAA,CAAnB,CAAmB,CAHH,AAGM,EAAC,AAAC,EAAE,CAHV,CAAA,EAGG,AAAO,CAAA,CAAA,CAAA,CAAA,CAAP,AAAO,GAAA,CAAP,CAAO,CAAM,CAE1C,CAmGD,AArGW,EAA0B,IAsGxB,CAtGwB,CAAA,CAgHpC,CA4GD,MACa,GA7NiB,AAqO7B,CA8FD,IAnU8B,EAsGG,AA8NpB,CA9NoB,EAtGH,AAyU7B,CAzU6B,MA2UjB,EA9GsB,CAAA,AAmHlC,CAqED,GAjF8B,CAAA,EAkFjB,GAGZ,CA+ED,MA7JiC,AA8JpB,CA9JoB,EAkKhC,OA0GY,EAjMsB,CAAA,AAsMlC,OAnHgC,AA+JpB,CA/JoB,EAkKhC,CAuFD,IA3I+B,CAAA,CA4IlB,GAOZ,CAsCD,KAxIgC,CAAA,AAyInB,GAKZ,CAiKD,KApNgC,CAAA,AAqNnB,GAkBX,QAzLgC,CAAA,OAyLhB,CAAC,GAlBiB,CAAA,SAmBhC,CAAW,YACX,CAAU,CACyB,CAAA,CACnC,IACI,EADE,EAAY,IAAI,AACV,GADG,AAIf,GAAI,SD3jHA,CC2jHU,EAAE,CDjjHZ,IC6iHyC,EDzjHzC,ACyjH2C,ET94F7C,AQ3qBsC,CAAA,EAGtC,MAAkB,GADLC,KAAkC,CAAC,OAAO,CjByVZ,AiBzVa,GAE1DC,ChBidC,CAAC,CAAC,AgBjdmB,EAAU,CAAC,OAAO,CAAA,GAItC,AR0qBA,CAAD,CAAC,IQ1qBsB,CADpB,EAAeD,KAAkC,CAAC,QjBwVT,CiBxVJ,EAAwB,CAAC,GAElEC,GjBsVuD,AiBtVjC,CjBsVY,AiBxViB,CAE7B,YAAsB,CAAE,GAIhD,MAAsB,GAJsC,AAG3CD,CAH4C,IAGV,CAAC,MAAM,CAAC,CAAC,CAArB,OAEL,CAAC,EAFc,KAEP,CAAE,GAI3B,AAAb,ChBgdQ,IgBpdwC,CAAC,AAI9B,CADjB,EAAYA,KAAkC,CAAC,QAAQ,CAArB,AAAsB,KhBgd5B,CgB9cV,EAAU,CAAC,KAAH,GAAW,CjBsVhB,AiBtVkB,GAI7C,AAAoB,IAAI,EAJ8B,AAI5B,CAJ6B,AAGjD,ChB+cD,CAAA,GiBslGQ,EDriH0C,CAAC,QCqiHM,CDriHnB,CAAuB,CjBqV1C,AiBrV2C,CAAC,GAElEC,GACE,CAHiD,CAIjD,CAAC,ChB8c4D,EAAE,EgB/cvD,MACI,CAAA,AAmDZ,SACJ,CAAA,MAEM,EAAoC,CAAA,EAEpC,EAAsBD,GAAsB,CRwpBR,CQxpBoB,CAAC,ORwpBF,CAAC,AQxpBS,CAAC,CAAC,CACzE,GAAA,MAAA,EAAiC,CjBsUC,AiBrUhC,IAAA,EAAsB,CACtB,CRspBsC,AAChB,AQvpBtB,ChBicuB,KgBjcvB,OAAiB,CAAC,KAChB,EAAA,EAAA,GAAA,CAAsC,AAAC,ERwpBA,CAAC,CQxpBG,CADT,CRwpBD,GQvpBc,OAkD7C,EAsEiB,AAEjB,ChBqjBC,CgBvjBgB,AAIjB,CR8nBsC,YQ1sBtC,EAAA,CAAA,EAGN,AAAiB,MAAM,GADLA,GAjDoB,EAiDE,EAjDE,CAAC,MAiDkB,CAAC,AAAtB,MAEhB,EAAA,aAsEkB,CAAA,CAAE,CAG5C,SADgBA,IjBwSiB,CiBhX4B,EAwEX,CAAC,CRmoBV,MQnoBH,EAAsB,CAAC,ERmoBT,GAAjB,CQjoBX,EAAU,CAAC,CjB0SJ,CSyVD,IQnoBW,CAAE,GAMvC,AAAkB,GR6nBoB,GQ7nBd,CAHtB,EAAiBA,CRqoBK,EQroBiB,EAAY,QAAF,cAEtD,CAAC,GAEAC,GAAsB,CRkoBR,CQloBkB,cAAc,CAAEO,GAAS,IAIvD,AAAY,CAJ0C,GRqoBtD,EQjoBsB,CADpB,EAAeR,AjBmS6E,CiBtSzB,AjBuShE,CiBvSiE,AjBuShE,CiBvSiE,AAGhC,AAC3B,EADuC,CAAC,GjB4SV,AAChB,CSqVK,OQloBgC,CAAC,GAElEC,GAAsB,CRioBpB,CQjoBoB,CAAW,ERioBE,SQjoBS,CAAE,GAGzC,IAtFA,KAnDLA,GAAsB,EAAU,MAAF,aAAqB,CAAE,EACtD,CAED,IAAM,EAA4BD,GAAsB,EAAY,CAHE,AAIpE,CAJqE,uBAKtE,CAAC,AAC+B,CRupBH,KQvpBS,CAAnC,GACFC,GACE,EAAA,CACC,uBAAuB,CAAC,CACzB,GAIJ,IAAM,EAA8BD,GAAsB,EAAY,QjBqU/B,AiBrU6B,CAAX,oBAWzD,OARI,MAAqC,AAArC,MAEA,EACA,2BAA2B,CAC3B,GAIG,CACT,EAzFuC,ICmiHjC,ED/hHG,CC+hH6C,KAAxC,ED/hHG,CC+hHAI,EDtmHT,IAuJyB,CAC5B,CA5IG,IAUA,IAtBoC,CAAA,CAAE,CAG5C,AAAgB,CR8pBH,CAAC,IQ9pBQ,CADhB,EAAA,AjB+VmB,KiB/V0B,CAAC,CComHJ,CAAC,ETt8FJ,ASs8FM,GDpmHQ,CAAC,CAArB,ChBudd,IgBrdD,EAAU,CAAC,MAAM,CAAC,CAAE,GAIxC,AAAgB,ChBoda,GgBpdT,EAAE,CRgqBD,AQjqBnB,EAAA,KAAiD,UAAZ,EAAwB,CAAC,GR+pBhD,AQ7pBlBH,GAAsB,ERgqBL,AQhqBe,CAAC,WAAW,CAAE,GAIhC,ER+pBA,CRzMC,GgBtdK,GAJsC,AAGtD,CAHuD,IAGV,CAAC,MAAM,CAAC,CAAC,CAArB,KAEf,EAAU,CAAC,EjBgWD,KiBhWQ,CAAE,GAIxC,AAAa,KAJmC,CAAC,AAI9B,CADjB,EAAYD,ChBudD,IgBvdmC,CAAC,OAAO,CAAC,CAArB,AAAsB,MjB+VvB,WiB7VI,CAAE,GAOzB,ChBydL,CQqM4B,OQlqBtBA,CjB+VG,IiB/V+B,UAAZ,UAAU,gBAGpD,CAAC,MAGE,EACA,CAAC,WAAW,CACZG,AA4CA,IRkoByC,KQloB/BA,AACd,CAAA,EAEA,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAsBH,GAAAA,EAAkC,oBAE7D,CAAC,CACF,GAAA,AAA2B,IAAI,EAA/B,EAA+B,OACP,ChBycD,OgBxcX,OAAO,CAAA,OACG,EAAgB,ChBycD,EAAA,CgBzcK,AAAC,EhBycA,GgB1cL,SA6EhC,EAEA,EA8DA,EAEA,EAKA,EAKA,WA5EoC,CAAA,EAG1C,AAAiB,IAAI,KADHA,GA7EmB,EA6Ee,CAAC,CA7EZ,CAAC,KA6EkB,CAAC,CAAC,AAAtB,GAEtCC,GAAsB,EAAU,CAAC,ChBsblB,EDzHgB,CAAC,GiB7TQ,CAAC,EAAEK,EA4DH,CAAA,CAAE,CAG5C,IRkoBkB,EQloBG,ERooBJ,CQroBDN,EA9D2C,CA0D3D,EA1D4D,EA8DV,MAJ3B,CA1D8C,AA8DhC,AAAoB,CAAnB,AA9DgC,AA0D/C,AAImC,CA9Da,IRksBrB,CAAnB,AAAoB,AQloB3B,EhBgaE,CgBhaS,IhBgaX,CAAC,AgBhaO,CAAS,AhBgaf,CgBhaiB,GAI3C,AAAsB,IAAI,AAJwB,CAAC,CAIvB,EhB4ZmB,CgB7ZxBA,GAAsB,ERmoBvB,AQnoBmC,CAAC,ChBgaN,ADtHd,aiB1SkC,CAAC,CAAC,GAExEC,GAAAA,EAAgC,cAAc,CAAEO,GAAS,IAIvC,CAJsC,KAIhC,GADLR,CAHoD,CAAC,CAG/B,AAHgC,EAGpB,CAAC,OAAH,CAAX,EAAwB,CAAC,CAAC,MAE5C,EAAU,CAAC,KAAH,MAAc,CAAE,GAGzC,IA1EA,KAuEqD,CAAC,IAtJ3B,CAAC,CR+pBN,OT/UG,UiBhVqB,CAAE,EACtD,CAED,IAAM,EAAA,GAAkD,CjB+UhB,CiB/U4B,CAHE,CAAC,GjBkVf,oBiB7UvD,CACgC,AAAjC,AADE,MACqC,CAAvC,GACEC,GACE,EACA,yBAAyB,CACzB,GAIJ,IAAM,EAA8BD,GAAsB,EAAY,QAAF,CAAX,kBAExD,CAAC,QACiC,AAAnC,CjB2UgC,KiB3UhC,AAAyC,EjB2UF,CiB1UrCC,GACE,EACA,CAAC,GhBucwB,uBgBvcE,CAC3B,CR6pBmD,CAAC,CAAC,AQzpBlD,GApF6B,IC0kHhC,EDtkHG,CCskH4C,CAGjD,ID7kH8C,AC0kHpC,CD1kHqC,CAC9C,CC2kHD,AAFaC,MAEP,CAAC,MAAM,CAAC,EAAW,GAClB,EAIV,CAyXD,CA9X2B,CAAU,CAAC,GAClB,AA8XP,GAOZ,CA8OD,EAtnBiD,CAAC,EAAE,CAunBvC,GAGZ,OAkDY,EA3SsB,CAkTlC,AAlTkC,CAmXnC,MACa,GAOZ,CA4BD,GAjKwC,CAAA,EAkK3B,GAGZ,CA4CD,EA5JuC,CAAA,AAyET,CAAA,EAoFjB,GAGZ,CAwSD,IA3V+B,CAAA,CA4VlB,GAKZ,CA0fD,IA3yB+B,CAAA,CA4yBlB,GAsBX,IAAI,IAAI,AAthBwB,CAAA,CAshBxB,IAtBoB,CAAA,MAuB1B,IAAI,EAAO,EAAH,AAAK,CACT,GAAmB,EACjB,EAAe,CADO,CACL,CACvB,IAAK,EAFe,CACF,CACP,IAAI,CAAI,OAAA,EAAA,MAAA,GAAA,MAAA,EAAA,CAAA,IAAI,CAAC,aAAA,AAAa,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,MAAE,AAAS,CAAX,CAAW,IAAA,AAAX,CAAW,CAAA,CAAA,CAAA,CAAA,AAAE,GAAF,EAAA,AAAE,AAAK,EAAA,EAAA,AAAI,CAAX,CAAa,AAAN,CAAQ,CAC7D,EADqD,AAAP,CAAA,CACzC,EADgD,CAC1C,CAD0C,AACzC,EAAW,EAAW,CADmB,EACf,EAAjB,CADgC,CAAA,CACpB,CAAW,CAAC,OAAO,CAAC,GAEnC,CAFuC,CAAC,CAAE,GAEpC,GAApB,GACc,MADL,GACc,GAAvB,GACe,IAAI,EACnB,AAFS,CACT,GAEA,EAAa,IAAI,CAFP,AAEQ,GAGtB,EAHgB,CAGS,GAHM,CAAC,IAGC,EAA7B,OAAO,EAAK,EAAD,EAAK,CAAe,CACjC,GAA4B,SAAS,EAAjC,OAAO,EAAK,EAAD,KAAQ,EAAkB,EAAK,EAAD,KAAQ,CACnD,CADqD,QAGvD,GAAmB,EACnB,EADuB,CACf,CAAJ,CAAS,EAAD,EAAK,AAClB,CACF,CAOD,AAVoB,OAIhB,EAAa,MAAM,CAAG,CAAC,EACzB,AAD2B,AAAb,OACP,CAAC,IAAI,CACV,CAAA,yBAAA,EAA4B,EAAY,UAAA,qHAAA,CAAiI,CAC1K,CAGI,EAAmB,IAAI,GAAG,EAWnC,IAAI,CAXqB,EAAmB,CAWpC,EAAA,WACN,IAAI,EAAO,EAAE,AAAL,CACF,EAAe,EAAE,CACvB,IAAK,GADa,CACP,IAAI,CAAI,OAAA,EAAA,OAAA,EAAA,OAAA,EAAA,IAAI,CAAC,aAAa,AAAb,EAAa,IAAA,CAAA,EAAA,EAAE,GAAF,MAAE,AAAS,CAAX,CAAW,IAAX,AAAW,CAAA,CAAA,CAAA,CAAA,CAAA,AAAE,GAAF,EAAE,AAAK,AAAP,EAAO,EAAA,AAAI,CAAX,CAAa,AAAN,CAAQ,CAC7D,EADqD,AAAP,CAAA,CACzC,EADgD,CAC1C,CAD0C,AACzC,EAAW,EAAW,CADmB,EACf,EAAjB,CADgC,CAAA,CACpB,CAAW,CAAC,OAAO,CAAC,GACjC,CADqC,CAAC,CAAE,SAC5B,GAA1B,GAA8B,AAAe,IAAI,EAAE,AAA1C,IACX,AAD0C,EAC7B,IAAI,CAAC,GAGlB,EAHY,AAGP,EAAD,EAHuB,CAAC,KAGb,EAAoC,QAAQ,EAAE,AAA1C,OAAO,EAAK,EAAD,QAAW,CAAC,IAAI,GAChD,GAAQ,CAAJ,GAAQ,CAAC,EAAK,EAAD,QAAW,CAAC,KAAI,CAAC,AAErC,CAMD,OALI,EAAa,MAAM,CAAG,CAAC,EAAX,AAAa,AAC3B,OAAO,CAAC,IAAI,CACV,CAAA,yBAAA,EAA4B,EAAY,UAAA,qHAAA,CAAiI,CAC1K,CAEI,EAAK,EAAD,IAAO,CAAG,CAAC,CAAG,IAAI,CAAC,IAAI,CAAC,GAAG,EAEzC,CA+gBD,MACa,AAlhBsC,GAgiBjD,IAAI,UAAU,EAAA,CACZ,EAf+B,CAAA,AAgB7B,IAAI,CAAC,aAAa,EAClB,IAAI,CAAC,aAAa,CAAC,WAAW,EAC9B,IAAI,CAAC,aAAa,CAAC,WAAW,CAAC,MAAM,CAAG,CAAC,CAEzC,CADA,MACO,IAAI,CAAC,aAAa,CAAC,WAAW,CAAC,CAAC,CAAC,CAI7C,CCj4Le,SAAA,GAAO,CAAoB,CAAE,CAAvB,AAA8C,EAClE,AADkE,GAC9D,CAAC,GAA0B,EAArB,MAA6B,EAAE,AAA3B,OAAO,EACnB,GADwB,GAClB,AAAI,KAAK,CAAC,wCAAwC,CAAC,CAG3D,GAAI,EAAU,OAAD,GAAW,EAAE,CACxB,CAD0B,EAExB,EAAM,GAAD,OAAW,CAAC,aAAa,CAAC,EAC/B,EAAM,GAAD,OAAW,CAAC,WAAW,CAAC,EAC7B,EAAM,GAAD,OAAW,CAAC,SAAS,CAAC,CAE3B,CADA,MACO,KAAK,CACsB,CAA7B,KAAI,EAAM,GAAD,IAAQ,CAAC,GAAG,CAAC,GAAI,CAAC,CAIhC,MAAO,CAAA,yBAAA,EAA4B,EAAK,CAAE,CAH1C,CAGwC,GAHlC,EAAQ,EAAM,CAAT,EAAQ,EAAM,CAAC,GAAG,CAAE,CAAC,CAAC,CACjC,MAAO,CAAA,WAAA,EAAc,CAAK,CAAC,CAAC,CAAC,CAAW,QAAA,EAAA,CAAK,CAAC,CAAC,CAAC,CAAA,CAAE,AACnD,OAAM,CAIP,AAAI,EAAM,GAAD,OAAW,CAAC,SAAS,CAAC,EAAI,EAAM,GAAD,OAAW,CAAC,cAAc,CAAC,CAC1D,CAD4D,CAG5D,CAAA,EAFK,KAEL,EAAU,EAAK,CAAE,AAG9B,CAEgB,CALY,QAKZ,GACd,CAAoB,CACpB,CAAuB,EAAA,AAEvB,IAJ0B,AAIpB,EAAmB,GAAO,EAAW,CAAZ,IAA2B,CAAC,CAAlB,EAAnB,CACtB,AAAK,EAID,EAJA,AAIiB,UAAU,CAAC,CAJX,EAAE,AAIH,UAAyB,CAAC,EAAI,EAAU,OAAD,GAAW,EAAE,CAE/D,CAFiE,AAErD,SAAA,EAAA,EAAU,OAAD,GAAW,EAAE,CAAA,WAAA,EAAc,EAAU,OAAD,IAAY,EAAE,CAAI,CAAA,EAAA,EAAgB,CAAE,CAC3F,EAAiB,UADwE,AAC9D,CAAC,GAAZ,MAAqB,CAAC,EAAI,EAAU,OAAD,GAAW,EAAE,CAClE,CADoE,AACxD,SAAA,EAAA,EAAU,OAAD,GAAW,EAAE,CAAA,WAAA,EAAc,EAAU,OAAD,IAAY,EAAE,CAAsB,mBAAA,EAAA,EAAgB,CAAE,CAE/G,EATA,EAAE,AAWb,CAEM,OANkH,EAMxG,EAJW,CAKzB,CAAoD,EAAA,AADhC,OAGhB,AAAJ,KAAS,CAAC,OAAO,CAAC,GACT,EADc,AACR,CADS,EAAE,AACZ,AAAI,CAAC,AAAC,GAAS,CAAL,EAAW,EAAD,EAEzB,AAF8B,CAE7B,AAF8B,CAAC,EAEzB,EAAD,CAAQ,AAEzB,CAEM,CAJiB,CAAC,OAIR,GAAM,CAA0B,CAA3B,CAA2B,AAC9C,GAAoB,QAAQ,EAAxB,OAAO,GAA8B,CAA1B,GAA8B,EAAE,CAAf,EAC9B,EADkC,KAC3B,CAGT,GAHa,IAGP,AAAI,KAAK,CACb,CAAA,sDAAA,EAAyD,OAAO,EAAI,CAAE,CAAF,AACrE,AACH,CAEM,SAAU,GAAW,CAA0B,EAAA,AACnD,IADwB,AAClB,EAAkB,GAAM,EAAD,CAC7B,CADkC,CAAC,CAEjC,EAAgB,EAFG,MAEK,EACxB,EAAgB,CADD,OACS,CAAC,IAAV,MAAoB,CAAC,QAAQ,CAAC,CAE7C,CADA,MACO,CAET,OAAM,AAAI,KAAK,CAAC,CAFQ,AAER,uBAAA,EAA0B,EAAgB,QAAS,CAAE,CAAA,CAAC,AACxE,CAEM,CAHqD,QAG3C,GAAW,CAAgB,EAAA,AACzC,IADwB,AAClB,EAAkB,GAAM,EAAD,CAC7B,CADkC,CAAC,CAEjC,EAAgB,EAFG,MAEK,EACxB,EAAgB,CADD,OACS,CAAC,IAAV,MAAoB,CAAC,QAAQ,CAAC,CAE7C,CADA,MACO,CAET,OAAM,AAAI,KAAK,CAAC,CAFQ,AAER,uBAAA,EAA0B,EAAgB,QAAS,CAAE,CAAA,CAAC,AACxE,CAEM,CAHqD,QAG3C,GAAM,CAA+B,CAAhC,CAAgC,AACnD,SAAI,EACF,IADQ,EACF,AAAI,GADG,EACE,CAAC,CADC,IAAI,MAAM,KAAK,OACO,CAAC,CADC,AAG3C,EAH6C,CAGvB,QAAQ,EAAE,AAA5B,OAAO,EACT,IADe,GACR,EAET,GAAsB,CAFP,OAEe,EAAE,AAA5B,OAAO,EACT,IADe,EACR,CAAC,IAAI,CAAE,CAAM,CAAC,AAEvB,IAFsB,GAEhB,AAAI,KAAK,CAAC,CAAA,uBAAA,EAA0B,OAAO,EAAM,CAAE,CAAC,AAC5D,CAEM,CAHmD,QAGzC,GAAO,CAAmC,EAApC,AAAoC,AACxD,SACE,GAEC,GAFK,EAEA,CAAC,EAFI,IAAI,CAED,CAAC,EADf,EAC0B,AAAkB,CAAC,CAAxB,AAAyB,CAAxB,AACtB,CAFM,EAC0B,AAAC,GADtB,GAC4B,CAEvC,KAHoB,CAGd,AAAI,KAAK,CAAC,2BAA2B,CAAC,QAE1C,AAAJ,KAAS,CAAC,OAAO,CAAC,GACT,EAAO,CADQ,CAAC,CACN,CADQ,AACZ,AAAK,AAAC,GAAS,CAAL,EAAW,EAAD,EAE5B,AAFoD,CAAE,AAErD,CAFsD,EAEhD,EAAD,CAAU,AACzB,CAEA,EAHsB,CAAE,MAGf,GAAW,CAAe,EAAA,AACjC,IADiB,SAEf,GAEkB,GAFZ,KAAK,AAEe,EAA1B,EAFe,IACf,CACO,GACP,EAFM,CACO,IACN,AAFI,GAEA,GACX,GAHoB,AAEH,EACZ,CAAC,OAAO,CAAC,EAAO,IAAD,CAAM,CAAC,AAE/B,CAEA,SAAS,GAAoB,CAAe,EAAA,AAC1C,aAD0B,AAExB,GAEkB,GAFZ,KAEoB,AAFf,EAEX,EAFe,IACf,CACO,GACP,EAFM,CACO,IADF,OAEG,EAFM,CAEF,CAEtB,CAEA,IAJ4B,KAInB,GAAwB,CAAe,EAAA,AAC9C,aACE,GAEA,AAAkB,CAJU,EAEtB,KAAK,AAEe,IAFX,IACf,CACO,GACP,EAFM,CACO,IADF,SAAS,EAEF,GAAI,CAE1B,CAEM,IAJ0B,KAIhB,GAAS,CAA2B,EAClD,AADkD,EAA5B,OAClB,EACF,IADQ,EACF,AAAI,GADG,EACE,CAAC,CADC,IAAI,MAAM,KAAK,SAAS,CACC,CADC,AACA,QAE7C,AAAI,GAAW,GAGN,EAGF,CANc,AAOnB,CAPY,AAAQ,EAAE,AAGQ,CAI1B,CAAE,MAAM,CACZ,KAAK,CAAE,GAAO,GAAD,AACd,AACH,CAEgB,EAJ+B,CAAE,MAIjC,GACd,CAAoB,CACpB,CAA8B,EAAA,AAE9B,GAAI,CAAC,EACH,GAL6B,CAIpB,EACF,AADI,EACF,CAEX,GAAI,EAAU,OAAD,GAAW,EAAE,EAAI,KAAK,CAAC,OAAO,CAAC,GAC1C,GADgD,CAAC,EAAE,CAC5C,EAAO,IAAD,GAAQ,CAAC,AAAC,IAAI,AACzB,IAAM,CADuB,CACb,GAAS,EAAZ,EAAsC,CAA3B,AAA4B,KAElD,AADF,EACU,KAAK,AAAN,EACP,EAAQ,KAAD,AAAM,CAAC,MAAM,CAAG,CAAC,OACE,IAA1B,EAAQ,GAA2B,EAA5B,AACP,AADa,CAAC,CAAC,CAAC,CAAC,IAAI,CAEd,CAAC,EAAQ,KAAD,AAAM,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,CAEzB,EAAE,AACX,CAAC,CAAC,CACG,GAAI,EAAU,OAAD,GAAW,EAAE,CAAE,CACjC,IAAM,EAAU,GAAS,EAAZ,GAAW,CAA6B,CAAC,GAEpD,AADF,EACU,KAAD,AAAM,EACb,EAAQ,KAAD,AAAM,CAAC,MAAM,CAAG,CAAC,OACE,IAA1B,EAAQ,GAA2B,EAAtB,AAAN,AACP,CADc,CAAC,CAAC,CAAC,IAAI,CAEd,CAAC,EAAQ,KAAD,AAAM,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,CAEzB,EAAE,AACV,QACD,AAAI,KAAK,CAAC,OAAO,CAAC,GACT,EAAO,CADQ,CAAC,CACN,CADQ,AACZ,AAAK,AAAC,GAAS,CAAL,EAAc,IAA0B,AAE1D,CAF+B,AAA6B,AAE3D,CAF4D,EAEnD,GAA+B,AAClD,CAEM,CAHY,CAA6B,CAAE,MAGjC,GAAU,CAA+B,EAAA,AACvD,GADuB,AAErB,MAAM,GAEL,EAFU,GAEL,CAFS,AAER,IADP,GACc,CAAC,EADT,EACsC,CAAC,CAAC,AAAzB,CACrB,AAFW,AACW,CAAI,EAAO,IAAD,EADZ,AACmB,CAEvC,MAAM,AAAI,KAAK,CAAC,uBAAuB,CAAC,CAE1C,GAAI,CAAC,KAAK,CAAC,OAAO,CAAC,GAAS,CAE1B,EAFuB,CAAC,AAEpB,GAAoB,IAAW,EAAL,CAA6B,AAA5B,GAC7B,GAD+D,CAAC,EAAE,AAC5D,AAAI,AADW,KACN,CACb,KAFsD,kHAEiE,CACxH,CAEH,MAAO,CAAC,GAAS,GAA8B,AAChD,CAED,CAHkB,CAA6B,CAAC,CAG1C,EAA0B,EAAE,CAC5B,CADM,CACgC,EAAE,CACxC,EAAiB,GAAW,CAAM,CAAC,CAAC,CAAC,CAAC,CAE5C,AAHsB,CACW,EAAb,CAEf,IAAM,IAAI,CAAI,EAAQ,CACzB,GADuB,CACjB,EAAY,GAAW,GAE7B,CAFiC,AAAlB,CAAmB,CAE9B,CAFwB,EAEX,EACf,IADW,EACL,AAAI,KAAK,CADc,AAE3B,EAF6B,uIAE4G,CAC1I,CAGH,GAAI,EAGF,EAAO,IAAD,AAAK,CAHA,AAGC,EAHC,EAGoB,CAAC,GAC7B,GAAI,GAAoB,IAAI,AAAK,CAAJ,EAA4B,GAC9D,CADkE,CAAC,EAAE,EAC/D,AAAI,AADkB,KACb,CACb,KAF2D,sJAEgG,CAC5J,MAED,EAAiB,IAAI,CAAC,EAEzB,CAKD,CAPiD,CAAC,IAA9B,CAIf,AAAD,GACF,EAAO,IAAD,AAAK,CAAC,CAAC,GADI,CACA,CADE,AACA,MAAM,CAAE,KAAK,CAAE,GAAO,EAAiB,CAAlB,AAAmB,CAAC,CAEvD,CACT,CAsCM,IAvCS,KAuCC,AAzC6C,CAAC,EA0C5D,CAAmD,EAAA,AAEnD,IAAM,EAA4B,CAAA,CAAE,CAC9B,EAAmB,AAJM,CAIL,GADT,IACgB,CAAC,CAC5B,EAAuB,CAAC,CADR,MACe,CAAC,CAChC,EAAuB,CAAC,KADJ,OACgB,CAAC,CAE3C,GAF0B,AAEtB,EAAY,IAAO,EAAD,AAAK,EAAY,CAAxB,IAAgC,CAC7C,CAD4C,AAAG,EAAX,GAC9B,AAAI,KAAK,CAAC,0CAA0C,CAAC,CA6C7D,IAAM,EAAgB,EAAY,KAAqC,CAevE,CAfyC,EAAR,AAAd,CAed,GAAM,CAAC,EAAW,EAAW,GAdb,EAcA,EAdI,CAcQ,CAd7B,GAAiD,CAAC,EAAzB,AAA2B,EAAb,KAA1B,CAAgC,GAC3C,AAA8B,EADM,IACA,EAAE,EAAzB,CAAC,CAAC,CAAE,CAAC,IAAO,EAAD,AAC1B,EAAY,QAAW,CAAZ,CAAW,AAAI,EAC1B,EAAc,AADgB,CACF,CAAC,CAAC,CAAC,EACQ,GAD5B,GACkC,EAAE,CAAtC,CAAa,CAAC,CAAC,CAAE,CAAC,IAAO,EAAD,CACjC,EAAY,QAAW,CAAZ,CAAW,AAAI,EAC1B,EAD8B,AAChB,CAAc,CAAC,CAAC,CAAC,GAI/B,EAAY,AAJD,IAIQ,EAAD,GAAP,OAAoB,KAAK,EAAE,AACxC,AA/FJ,SAAS,AACP,CAAkB,CAClB,CAA6B,EAAA,AAEzB,EAAS,MAAD,CA2Fa,CA3FJ,CAAC,MAAM,CAAC,AAJC,EAIC,CAC7B,EAAgB,QAAW,EAAD,AAAI,CAAA,CAAI,CAEpC,AAFiB,IAEX,EAAkB,EAAS,MAAD,AAAO,CAAC,AAAC,GAAkB,CAAtC,AAAwB,KAAoB,CAAC,EAAhB,GAElD,CAFsD,EAEvB,CAAC,EAAE,CAA9B,EAAgB,MAAM,CACxB,EAAgB,IADC,AACM,CAAG,CAAJ,KAAU,CAAC,CAAlB,KAAwB,CAACO,IAAU,AAAE,CAAD,OAAS,CAC1D,CAAe,CAAC,CAAC,CAAC,CAAC,WAAW,EAAgB,EAE3C,CAAe,CAAC,CAAC,CAAC,CAAC,WAAW,GAC/BA,GAAW,CAAD,eAAiB,MAG/B,IAAK,IAAM,CAAC,IADZ,EAAgB,KAAQ,CAAG,CAAJ,CAAM,CACb,GACd,CAFa,CAEG,KAAQ,CAAC,CAAF,GADM,AACA,CADE,AACD,CAC5B,CADa,IACL,CAAF,KAAQ,CAAC,MAAM,CAACA,IAAU,AAAE,CAAD,OAAS,CACxC,CAAC,CAAC,WAAW,EAAgB,EAE1B,CAAC,CAAC,WAAW,GACdA,GAAW,CAAD,eAAiB,AAChC,CAAA,CAAC,AAGR,EAoE4B,EAAY,IAAO,CAAE,CAAH,EAGN,CAHD,KAGO,CAAC,CAHa,CAAC,KAGP,CAAC,IAEnD,GAAkB,IAF4C,AAExC,CAFyC,CAAE,AAE7D,AAAoB,EAIxB,GAAiB,KAJH,CAIS,EAAnB,EAAqB,CACvB,GAAmB,GADR,GACc,EAAE,CAAvB,EACF,MAAM,AAAI,EADE,GACG,CACb,6DAA6D,CAC9D,CAEH,GAAI,UAAU,GAAY,KAAK,CAG7B,CAH+B,QAKjC,EAAY,IAAO,CAAG,CAAJ,GAAP,EAAiB,CAAC,MAAM,CAACA,IAAU,AAAE,CAAD,OAAS,CACtD,EAAW,QAAD,GAAY,EAAgB,EAEpC,EAAW,QAAD,GAAY,GACtBA,GAAW,CAAD,eAAiB,AAChC,MAAM,GAAI,EAAiB,QAAQ,CAAC,GAClC,CAAuC,CAAC,AADhB,EAC0B,CACjD,CAF0C,CAAC,CAEzB,CAF2B,EACG,KAE7C,EADyB,CAAC,AACtB,EAAqB,CADX,OACmB,CAAC,GAAY,CACnD,IAAM,CADuB,AAAmB,CAAC,AACC,EAAE,CACpD,IAAK,IAAM,IAAI,CAAI,EADO,AACK,CAC7B,GAAoB,IADO,EACD,EAAtB,EAAK,EAAD,EAAQ,CAAY,CAAb,AACb,EAAY,QAAW,CAAZ,CAAW,AAAI,EAC1B,EAD8B,MAE/B,CACD,EAAqB,IAAI,CACvB,GAAkB,GAErB,CACA,AAHoD,CAGb,AAHc,CAGb,AAFtC,EAEgD,CACjD,CACH,AANuB,IACD,CAG6B,CAE7C,GAAI,EAAqB,QADR,AACgB,CAAC,GAAY,CACnD,IAAM,CADuB,AAAmB,CACW,AADV,CACU,CAAE,CAC7D,IAAK,GAAM,CAAC,EAAK,CAAF,CAAQ,GAAD,AAAK,AADD,MACO,CAAC,OAAO,CACvC,GAEA,CAAoB,CAAC,EAAI,CAAD,AAAI,EAFS,CAGnC,AAFH,CAAE,EAKF,CAAuC,CAHJ,AAGK,CAFtC,CAEgD,CACjD,CACH,KAAM,AAN0C,AAIG,CAIlD,GAAkB,UAHI,YAGkB,EAAE,CAAtC,EACF,OADW,EAGZ,CAAuC,CAAC,EAAU,CAAG,CACvD,CAEH,IAHsD,GAG/C,CAH6D,AAItE,CAgBM,SAjBc,AAiBJ,GACd,CAAqC,EAAA,AAErC,GAA4B,IAHD,IAGS,EAAhC,AAAkC,OAA3B,EACT,OAAO,EACF,CAFgB,EAEY,OADd,CACsB,EAAhC,AAAkC,OAA3B,EAChB,MAAO,CACL,GAF0B,QAEf,CAAE,CACX,mBAAmB,CAAE,CACnB,SAAS,CAAE,CACZ,CAAA,AACF,CAAA,CACF,AAED,OAAM,AAAI,CALmB,IAKd,CAAC,CAAA,+BAAA,EAAkC,OAAO,EAAY,CAAE,CAAC,AAE5E,CAEM,OAJmE,EAIzD,GACd,CAAyC,EAAA,AAEzC,GAAI,QAH2B,iBAGF,GAAI,EAC/B,MAAU,AAAJ,IADqC,CAC5B,CAD8B,AAE3C,2DAA2D,CAC5D,CAEH,OAAO,CACT,CAEM,SAAU,CAHK,EAGC,CAAgB,CAAjB,CAAiB,AACpC,GAAI,EAAK,EAAD,kBAAqB,CAC3B,CAD6B,GACxB,IAAM,KAAuB,EAAK,EAAD,UAAR,QAA6B,CAAE,AACvD,EAAoB,UAAU,EAAE,CAC7B,IADgB,EACV,CAAC,IAAI,CAAC,EAAoB,UAAU,CAAC,CAAC,KAAb,GAAqB,CAAC,SAAS,CAAC,CAK7D,CAL+D,CAK3C,iBAAD,GAAqB,EAAE,CAC7C,EAAoB,iBAAD,GAAqB,CACtC,EAAoB,UAAU,CAChC,MADqB,CACd,EAAoB,UAAU,EAPvC,EAAoB,GAOQ,OAPE,CAAG,GAC/B,EAAoB,CADH,SACa,CAC/B,CAFiD,CAWlD,EAAoB,EAVC,MAUO,EAAE,CAC3B,MADgB,AACV,CAAC,IAAI,CAAC,EAAoB,QAAQ,CAAC,CAAC,OAAX,CAAmB,CAAC,SAAS,CAAC,CAK3D,CAL6D,CAKzC,iBAAD,CAAmB,EAAE,CAC3C,EAAoB,iBAAD,CAAmB,CACpC,EAAoB,QAAQ,CAC9B,OAAO,CADc,CACM,QAAQ,EAPrC,EAAoB,KAOQ,GAPA,CAAG,GAC7B,EAAoB,GADH,KACW,CAC7B,EAWT,CAbwD,KAC3B,CAYtB,CACT,CAEM,EAHO,OAGG,GAAO,CAAoC,EAArC,AAAqC,AAEzD,GAAI,KAAK,GACP,EADY,IACN,AAAI,KADW,AACN,CAAC,GADS,KAAK,KAAK,IAAI,EAAE,AACN,CAAC,CAEtC,GAAI,CAAC,KAAK,CAAC,OAAO,CAAC,GACjB,EADsB,CAAC,EAAE,CACf,AAAJ,KAAS,CAAC,iDAAiD,CAAC,CAEpE,IAAM,EAAuB,EAAE,CAC/B,CADY,GACP,IAAM,IAAI,CAAI,EACjB,EAAO,CADe,CAAE,EAClB,AAAK,CAAC,GAEd,CAFgC,CAAC,KAE1B,CACT,CAkFgB,IAnFD,KAmFC,GACd,CAAoB,CACpB,CAAsB,EAAA,AAEtB,GAAI,AAAgB,OAJY,CAIJ,EAAE,OAAnB,EACT,EADa,IACP,AAAI,KAAK,CAAC,uBAAuB,CAAC,CAE1C,OAAO,AAnCT,SAAS,AACP,CAAiB,CACjB,CAiCmB,AAjCC,CACpB,CAAsB,CACtB,EAA4B,CAAC,EAAA,AAE7B,CANmB,GAMb,EACJ,CAAC,EAAa,GAHhB,OAGe,AAAW,CAAC,CAAA,CADH,CACM,EAAc,CAAA,CAAG,CAAC,EAC9C,EAAa,KAD6B,AACxB,CAAC,GAAG,CAAV,AAAW,CAAC,MAAM,GAAK,EACrC,GAAI,EAAO,IAAD,MAD4C,AACjC,EAAE,CACrB,CADuB,EACnB,EAAa,UAAU,AAAX,CAAY,WAAW,CAAC,CACtC,CADwC,MACjC,OACF,GAAI,EADU,AACG,UAAD,AAAW,CAAC,YAAY,CAAC,CAC9C,CADgD,KACzC,CAAA,SAAA,EAAY,EAAO,IAAD,MAAW,EAAE,CAAI,CAAA,EAAA,EAAY,CAAE,MACnD,GADiD,AAC7C,EAAa,UAAD,AAAW,CAAC,CAAA,EAAG,EAAc,CAAA,CAAG,CAAC,CACtD,CADwD,KACjD,CAAY,CAD+B,QAC/B,EAAA,EAAO,IAAD,MAAW,EAAE,CAAA,WAAA,EAAc,EAAO,IAAD,OAAY,EAAE,CAAI,CAAA,EAAA,EAAY,CAAE,MACrF,GADmF,AAC/E,EACT,MAAO,CAAY,SADQ,AACR,EADU,AACV,EAAO,IAAD,MAAW,EAAE,CAAc,WAAA,EAAA,EAAO,IAAD,OAAY,EAAE,CAAI,CAAA,EAAA,EAAkB,CAAA,EAAA,EAAY,CAAE,MAE5G,AAF0F,GAAgB,IAEnG,SAGX,AAAI,EACK,CAJc,AAIX,EAAA,EAAkB,CAAA,EAAA,EAAY,CAAE,CAErC,CACT,EASsB,CAbE,CAaS,AAZL,CADF,CAaa,CAZK,CAYP,GAAN,AAVV,WAUkC,CACvD,AADwD,CAGlD,SAAU,GAAiB,CAAwB,EAAA,AACvD,OAAQ,GADsB,AAE5B,GADY,CACP,mBAAmB,CACtB,MAAO,uBAAuB,AAChC,KAAK,UAAU,CACb,MAAO,mBAAmB,AAC5B,KAAK,QAAQ,CACX,MAAO,qBACT,AAD8B,KACzB,QAAQ,CACX,MAAO,kBACT,AAD2B,SAEzB,OAAO,CACV,CACH,CAeM,GAjBuB,MAiBb,GAAiB,CAAe,EAAA,AAC9C,UAD8B,GAE5B,GAEkB,GAFZ,KAEoB,AAFf,EAEX,EAFe,IACf,CACO,GACP,EAFM,CACO,IACN,AAFI,GAEA,CAEf,CAEM,IANkB,AAEH,KAIL,GAAQ,CAAe,EAAA,AACrC,CADqB,YAEnB,GAEkB,GAFZ,KAEoB,AAFf,EAEX,EAFe,IACf,CACO,GACP,EAFM,CACO,EACR,EAFM,CAEF,CAEb,CAEM,IAJa,EAFK,GAMR,GACd,CAAkE,EAAA,GAD3C,OAGnB,EAKJ,EAL4B,CAExB,OAAO,EA5BS,QAAQ,EAA1B,OAAO,GACP,GADa,GACP,GA2BI,CA3BA,GA4BV,EAAQ,CA5BQ,CA4BZ,AAA4B,AADd,CAAC,EAAE,CACe,AAAJ,EAAD,CAE7B,GAAQ,IAEN,AAAS,AAFJ,IAED,AAFU,CAAC,EAAE,EAEC,CADtB,CACwB,CADhB,EAAJ,AAA6B,GAAG,AAAH,GAKnC,AALkC,IAK9B,GAAiB,IAEf,AAAS,IAAL,AAFmB,CAAC,EAAE,EAER,AAFJ,CAClB,CACwB,CADjB,EAAH,KAAI,EAAA,EAAkC,KAAK,AAAL,CAAD,CAAM,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,AAAE,GAAF,AAAE,AAAG,EAAL,CASjD,GAJI,AAAoB,CALyB,KAAA,CAAA,CAKjB,EAAE,OAAvB,IACT,EAAO,CAAA,CAAH,AAAW,AADE,MAIN,IAAT,EACF,EADM,CAAc,EAAE,CAChB,AAAI,KAAK,CAAC,sDAAsD,CAAC,CAGzE,GAAI,EAAK,EAAD,QAAW,CAAC,UAAU,CAAC,CAAE,CAE/B,IAAM,EADS,AACD,EADM,CACT,CADQ,EACC,CADK,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CACjB,KAAK,CAAC,WAAW,CAAC,CACvC,GAAc,IAAI,EAAE,CAAhB,EACF,GADO,GACD,AAAI,KAAK,CAAC,CAAA,qCAAA,EAAwC,EAAI,CAAE,CAAC,AAAH,CAE9D,EAAO,CAAK,CAAC,AAAT,CAAU,CAAC,AAChB,MAAU,CAAJ,CAAS,EAAD,QAAW,CAAC,QAAQ,CAAC,EAAE,CACpC,EAAO,EAAK,AAAR,EAAO,GAAM,CAAC,QAAQ,CAAC,CAAC,EAAC,AAAC,EAEhC,OAAO,EAnBN,CAoBH,CADa,AAGG,SAAA,GACd,CAAoB,CACpB,CAA6B,EAQ7B,AAR6B,EAFL,KAUjB,AALH,EAAU,CAKJ,MALG,GAAW,EAAE,CAClB,CADoB,CACP,QAAH,kBAA6B,CAAG,QAAQ,CAElD,EAAa,QAAH,AAAW,CAAG,aAGlC,AAH+C,CAKzC,SAAU,GAAe,CAAiB,EAAA,AAC9C,IAAK,IADuB,AACjB,GAAG,CAAI,CAAC,QAAQ,CAAE,aAAa,CAAE,iBAAiB,CAAC,CAAE,KAWhD,IAVd,AAU2B,IAVvB,CAAS,EAUgB,EAVN,EAWT,CAXF,AAAc,CAAC,AAAN,EAWH,AAXW,CAUiB,EAAA,AACzC,GAAiC,CAA7B,OAAqC,EAAxB,OAAO,GAAqB,CAAjB,IAA8B,EAV7D,EAUyD,AAAQ,KAVzD,CAAoC,CAAC,EAG1C,AACJ,CAJiD,AAMpD,MAAO,EAAE,AACX,CA8DgB,SAAA,GACd,CAAiB,CACjB,CAA2D,EAAA,IAEvD,EAEJ,CAN6B,EAMV,IAFgB,IAER,EAAE,AAAzB,OAAO,EACT,CADY,EACR,EAAO,IAAD,MAAW,EAAE,CACrB,CADuB,EACnB,EAAI,CAAD,SAAW,CAAC,OAAO,CAAC,CACzB,CAD2B,CACf,CAAC,MAAJ,AAAU,CAAE,OAAO,CAAE,MAAM,CAAE,CAAC,EAAI,CAAD,AAAE,MACvC,GAAI,EAAI,CAAD,SAAW,CAAC,OAAO,CAAC,CAChC,CADkC,CACtB,CAAC,MAAJ,AAAU,CAAE,UAAU,CAAE,WAAW,CAAE,CAAG,CAAC,CAAD,KAEjD,MAAM,AAAI,KAAK,CAAC,CAAA,yCAAA,EAA4C,EAAG,CAAA,AAAE,CAAC,MAIpE,GAAI,EAAI,CAAD,SAAW,CAAC,QAAQ,CAAC,CAC1B,CAD4B,CAChB,CAAC,MAAJ,EAAY,CAAE,CAAG,CAAC,CAAD,AAAE,CAAA,IAE5B,MAAM,AAAI,KAAK,CAAC,CAAA,sBAFY,oBAEZ,EAA6C,EAAG,CAAE,AAAF,CAAG,MAGlE,GAAI,KAAK,CAAC,OAAO,CAAC,GAAG,AAAG,CAAF,AAC3B,GAAI,EAAO,IAAD,MAAW,EAAE,CACrB,CADuB,KACjB,AAAI,KAAK,CAAC,iDAAiD,CAAC,CAEpE,EAAY,CAAC,MAAJ,SAAmB,CAAE,CAAG,CAAC,AACnC,CADkC,KAGjC,CAFK,CAEO,EAId,CAJiB,GAIX,CAJK,CAIgB,CAAC,EAAU,MAAM,CAAE,AAAT,EAAmB,IAAhC,GAA+B,IAAY,CAAC,CAAC,MAAM,CACzE,OAAO,CACR,CAAC,MAAM,CAEF,EAAoB,CACxB,EAAU,OAAD,KADY,GACI,CACzB,EAAU,OAAD,CAAS,CACnB,CAAC,MAAM,CAAC,OAAO,CAAC,CAAC,MAAM,CAExB,GAAI,EAAO,IAAD,MAAW,EAAE,EAAE,AACvB,GAAI,EAAoB,CAAC,EAA2B,CAAC,EAAE,CAA1B,EAC3B,MAAM,AAAI,AADS,KACJ,CACb,IAF2C,iEAE0B,CACtE,AACF,MAGD,GAAI,EAAqB,CAAC,EAA0B,CAAC,EAAE,CAAzB,EAC5B,MAAU,AAAJ,CADc,IACL,CACb,GAF2C,6CAEK,GAC9C,0BAKR,GALqC,CAChC,GAIE,CACT,CA6CM,OA9CY,EA8CF,GACd,CAAa,EAAA,AAGb,GAAoB,QAAQ,EAAxB,KAJkC,EAI3B,GAA8B,CAA1B,GAA8B,EAAE,CAAf,EAI9B,EAJkC,IAI3B,CAAA,CAA+B,CAOxC,IAAM,EAAqB,EAAI,CAAD,aAAN,EAA0B,CAClD,CADiD,EACf,QAAQ,EAAtC,OAAO,GAA0D,IAAI,EAAE,CAA7B,EAC5C,MAD2B,CACpB,EAIT,EAJ0C,EAIpC,EAFqB,AAEJ,CALyC,CAKtB,UAAtB,MAAyC,AAFW,AAE/B,CACzC,CAD4D,EACxD,CAAC,KAAK,CAAC,OAAO,CAAC,IAA6C,CAAC,EAAE,CAA7B,EAAe,IAApB,CAAC,CAAyB,CACzD,KADkD,EAC3C,EAIT,EAJ0C,EAItC,GAAe,EACnB,GADwB,CACnB,GADW,CACL,KAAgB,EAAgB,CACzC,GAA4B,CADP,OAAkB,AACH,EAAhC,OAAO,GAA8C,IAAI,EAAE,CAAvB,EAAjB,AACrB,SAIF,CALoD,GAK9C,EAAc,AAFI,EAEY,OAAnB,CAA8B,CAC/C,CAD8C,AAFiB,EAGpC,CADQ,OACA,EAA/B,OAAO,GAA4C,IAAI,EAAE,CAAtB,CAAjB,EAMW,QANiB,CAMR,AAHtB,AAGhB,EAAY,SAH0C,AAG9B,AAAb,CAA6B,CAAjB,AACzB,EAAe,GACf,CADmB,IAEpB,CACF,CASD,AAZgB,OAMZ,IACF,EAAI,CAAD,KADW,EAAE,oBACmB,CAAG,CAAJ,CAAQ,CAAD,eAAoB,CAC7D,CAD4D,MACrD,AAtCG,EAsCC,CAAD,CAtC+B,cAsCX,EAIzB,AAJwB,CAKjC,CAEgB,EAH0B,OAG1B,GAAc,CAAoB,CAAE,CAAa,EAAA,AAE/D,GAAI,CAAC,CAFsB,CAEZ,OAAD,GAAW,EAAE,CAAE,CAG3B,GAAI,AAFiB,YAEL,KAFsB,CAErB,IAAI,CAAC,GACpB,OAD8B,AACvB,CADwB,CACb,CADe,IACV,CAAC,EAAP,CAAU,CAAC,CAAC,GAAG,EAAY,AAE5C,OAAU,AAAJ,KAAS,CAAC,CAAA,wBAAA,EAA2B,EAAU,CAAA,CAAG,CAAC,AAE5D,CAKD,GAFE,AAEE,CAPqD,YAOxC,oDAFkD,CAEjD,IAAI,CAAC,GACrB,OAD+B,AACxB,CADyB,CACd,CADgB,IACX,CAAC,EAAP,CAAU,CAAC,CAAC,GAAG,EAAY,CACvC,GAAI,OAAO,CAAC,IAAI,CAAC,GACtB,OAAO,AADyB,CAAC,AAGjC,EAHmC,KAG7B,AAAI,EAFO,GAEF,CAAC,CAAA,wBAAA,EAA2B,AAnB1B,EAmBoC,CAAA,CAAG,AAnBzB,CAmB0B,AAE7D,CAEM,IAJmD,KAIzC,GAAU,CAAc,EAEtC,AAFsC,GAElC,AAAgB,AAFG,WAER,cAA8B,EAAE,GAC7C,MAAO,uBAAuB,CACzB,GAAI,AAAgB,WAAL,UAA0B,EAAE,GAChD,MAAO,mBAAmB,CACrB,GAAI,AAAgB,WAAL,UAA0B,EAAE,GAChD,MAAO,mBAAmB,CACrB,GAAI,AAAgB,WAAL,YAA4B,EAAE,GAClD,MAAO,qBAAqB,CACvB,GAAI,AAAgB,WAAL,SAAyB,EAAE,GAC/C,MAAO,kBAAkB,MACpB,GAAI,AAAgB,WAAL,YAA4B,EAAE,GAClD,MAAO,qBAAqB,MACvB,GAAoB,AAAhB,WAAW,UAA0B,EAAE,GAChD,MAAO,mBAAmB,MAE1B,OAAO,AAhBW,CAkBtB,CC50BM,GD0zB+B,MAgBf,AC10BN,GACd,CAA0B,EAE1B,AAF0B,IAEpB,EAAoC,CAAA,CAAE,CAEtC,EAAWT,AALc,CAGjB,EAEyB,EAAY,CAAC,AAAtC,MAA4C,CAAT,AAAU,CAArB,AAAsB,AAC5C,IAAI,EAAE,CAAlB,GACFC,GAAsB,EADZ,AACsB,CAAC,KAAH,CAAS,CAAC,CAAE,AAArB,GAGvB,IAAM,CAH8C,CAAC,AAG7BD,GAAsB,EAAY,CACxD,OADmB,AAAmC,CAAX,EACjC,CACV,aAAa,CACd,CAAC,AACqB,IAAI,EAAE,CAAzB,GACFC,GAAsB,EAAU,CAAC,KAAH,CADb,EACI,KAAyB,CAAC,CAAE,GAGnD,IAAM,EAAYD,GAAsB,EAAY,CAHc,AAGb,CAHc,AAGpD,MAAmC,CAAX,EAAwB,CAAE,OAAO,CAAC,CAAC,AACtE,AAAa,IAAI,EAAE,GAAV,CACXC,GAAsB,EAAU,CAAC,KAAH,EAAU,CAAC,AAApB,CAAsBU,GAAY,IAGzD,EAHwD,EAGlD,CAH4D,CAAC,AAG5CX,CAH6C,EAGvB,EAAY,CACvD,MADkB,CAAmC,CAAX,EAChC,CACV,YAAY,CACb,CACqB,AADpB,IACwB,EAAE,CAAxB,GACFC,GAAsB,EAAU,CAAC,KADjB,AACc,GAAT,IAAwB,CAAC,CAAE,GAGlD,IAAM,EAAcD,GAAsB,EAHsB,AAGV,CAHW,AAI/D,GADe,IAAmC,CAAX,EAC7B,CACV,SAAS,CACV,CAAC,AACiB,IAAI,EAAE,CAArB,GACFC,GAAsB,EAAU,CAAC,EADpB,GACiB,GAAT,CAAqB,CAAC,CAAE,GAG/C,IAAM,EAAiBD,EAHmC,CAAC,AAGd,EAAY,CACvD,MADkB,CAAmC,CAAX,EAChC,CACV,YAAY,CACb,CAAC,AACoB,IAAI,EAAE,CAAxB,GACFC,GAAsB,EAAU,CAAC,KADjB,AACc,GAAT,IAAwB,CAAC,CAAE,GAGlD,IAAM,EAAYD,GAAsB,EAAY,AAHY,CAAC,AAGZ,CAAtC,MAAmC,CAAX,EAAwB,CAAE,OAAO,CAAC,CAAC,AACzD,IAAI,EAAE,CAAnB,GACFC,GAAsB,EAAU,CADrB,AACsB,KAAH,EAAU,CAAC,AAApB,CAAsB,GAG7C,IAAM,EAHgD,AAGrCD,CAHsC,EAGhB,EAAY,CAArC,AAAsC,OAAH,CAAX,EAAwB,CAAE,QAAQ,CAAC,CAAC,CAS1E,OARgB,IAAI,EAAhB,AAAkB,GACpBC,GACE,EAFQ,AAGR,CAAC,KADO,CACD,CAAC,CAFW,AAGnB,AArLA,SAAU,AACd,CAAqC,EAAA,AAErC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAeD,CAFP,EAE6B,EAAY,AAgLvB,CAhLwB,IAAtC,GAAmC,CALX,AAKA,OAA6B,CAAC,CAAC,AACrD,IAAI,EAAE,CAAtB,GACFC,GAAsB,EAAU,CAAC,GADnB,EACgB,GAAT,EAAsB,CAAC,CAAE,GAGhD,IAAM,EAAuBD,GAAsB,AAHS,CAAC,CAGE,CAC7D,OAD2D,CAAX,IAAxB,MACN,CAClB,kBAAkB,CACnB,CAAC,CACF,GAA4B,AAAxB,IAA4B,IAAE,CAChC,IAAI,EAAkB,EAClB,GAFkB,EAEb,CAAC,KADS,EACF,CAAC,IADwB,CAExC,EAAkB,EAAgB,GAAG,CAAE,AAAD,EADP,CAAC,CACW,CADT,EACnB,CAswCnB,CAtwCqC,AAAc,OA0wC7C,EAJ2B,EAAA,OAE3B,CAEY,CAFwB,CAAA,CAAE,CAGxC,AAAgB,GAHN,CAGU,EAAE,GADLA,GACL,EA1wCsB,EAywCiB,CAAC,CAzwCd,CAAC,IAywCD,CAAC,GAAuB,CAAC,CAAC,GAElEC,EAFmD,CAGjD,EACA,CAAC,KADO,GADW,EAER,CAAC,CArLZ,AAsLAkC,SAtLUA,AACd,CAAyC,EAAA,AAEzC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAsBnC,CAFd,EAEoC,EAAY,CAC5D,KAgLkC,EAjLwB,CAAX,GAAxB,GALqB,GAM3B,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAiBD,GAAsB,EAAY,CAAC,IAHgB,CAAC,CAGvD,CAAmC,CAAX,IAA0B,CAAC,CAAC,CACxE,GAAsB,IAAI,EAAtB,EAAwB,CAC1B,IAAI,EAAkB,EAClB,GAFY,EAEP,CAAC,KADS,CAAiB,CACnB,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,AAEvBe,CAhuBT,AA+tB2C,CADT,EACnB,EAAkB,AAAc,IA9tBnD,AADcA,CACa,EAAA,AAE3B,IAAM,EAAoC,CA6tBX,AA7tBW,CAAE,CAEtC,EAAcf,CAFN,EAE4B,EAAY,CALtB,AAKuB,GAAtC,IAAmC,CAAX,CAAuB,CAAC,CAAC,AAC9D,AAAe,IAAI,EAAE,IACvBC,CADa,EACS,EAAU,CAAC,KAAH,GAAT,CAAqB,CAAC,CAAE,GAG/C,IAAM,EAAuBD,EAH6B,CAAC,AAGR,EAAY,CAC7D,OAD2D,CAAX,IAAxB,MACN,CACnB,CAAC,AAC0B,IAAI,EAAE,CAA9B,GACFC,GACE,EACA,CAAC,KADO,GADW,GADC,OAGD,CAAC,CAsEpB,AArEAe,SAqEUA,AACd,CAAkC,EAAA,AAElC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAgBhB,CAFR,EAE8B,CA1Ef,CA0E2B,CAAC,KAAtC,EAAmC,AALf,CAKI,SAA+B,CAAC,CAAC,CAC5E,GAAqB,IAAI,EAArB,EAAuB,CACzB,IAAI,EAAkB,EAClB,EAFW,GAEN,CAAC,KADS,AAAgB,EAClB,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,AAEvB,CADkC,CADT,AAGjC,CAAC,CAFa,AACF,AAGfC,EAJmC,AAAc,CAI3B,EAAU,CAAC,KAAH,GAAT,GAAuB,CAAC,CAAE,EAChD,CAED,OAAO,CACT,EAtFgC,EAkFkC,CAAC,CA9EjE,CAiFe,GAjFT,EAAiBD,GAAsB,EAAY,CAAC,IAJR,CAAC,CAChD,AAGiB,CAAmC,CAAX,IAA0B,CAAC,CAAC,AAClD,IAAI,EAAE,CAAxB,GACFC,GAAsB,EAAU,CAAC,KAAH,AADd,GACK,IAAwB,CAAC,CAAE,GAGlD,IAAM,EAAmBD,GAAsB,EAHiB,AAGL,CAHM,AAGL,OAAH,CAAX,AAAxB,MAAoD,CAAC,CACnD,AADoD,IAChD,EAAE,CAA1B,GACFC,GAAsB,EAAU,CAAC,KAAH,EADZ,CACG,MAA0B,CAAC,CAAE,GAGpD,IAAM,EAAyBD,GAAsB,EAAY,CAC/D,CAJkE,CAAC,KAGN,CAAX,MAAxB,MACN,CACrB,CAAC,AAC4B,IAAI,EAAE,CAAhC,GACFC,GACE,EACA,CAAC,KADO,GADW,KADG,OAGD,CAAC,CACtB,GAIJ,IAAM,EAAkBD,GAAsB,EAAY,CAAC,OAJjC,AAIL,AAAmC,CAHrD,AAG0C,KAA2B,CAAC,CAClD,AADmD,IAC/C,EAAE,CAAzB,GACFC,GAAsB,EAAU,CAAC,KAAH,CADb,EACI,KAAyB,CAAC,CAAE,GAGnD,IAAM,EAAwBD,GAAsB,EAAY,CAHE,AAIhE,CAJiE,MAGL,CAAX,KAAxB,MACN,CACpB,CAC4B,AAD3B,IAC+B,EAAE,CAA/B,GACFC,GACE,EACA,CAAC,KADO,GADW,IADE,OAGD,CAAC,CACrB,GAIJ,IAAM,EAAYD,GAAsB,EAAY,CAAC,CAAtC,KAJU,CAImC,AAAV,AAH/C,CAG0D,AAAtB,CAAuB,AAC7C,IAAI,EAAE,CAAnB,GACFC,GAAsB,EAAU,CADrB,AACsB,KAAH,EAAU,CAAC,AAApB,CAAsB,GAG7C,IAAM,EAHgD,AAG3BD,CAH4B,EAGN,EAAY,CAC3D,OADyD,CAAX,EAAxB,MACN,CACjB,CAAC,AACwB,IAAI,EAAE,CAA5B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,CADD,OAC6B,CAAC,CAAE,GAGtD,IAAM,EAAoBD,GAAsB,EAAY,CAC1D,GAJsE,CAAC,GAGf,CAAX,CAAxB,MACN,CAChB,CAAC,CACF,GAAyB,IAAI,EAAzB,EAA2B,CAC7B,IAAI,EAAkB,CAClB,KAAK,EAFU,AAET,KADS,EACF,CAAC,CADqB,IAErC,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,AAEvB,CADkC,CADT,AAGjC,CAAC,CAFa,AACF,AAGfC,EAJmC,AAAc,CAI3B,EAAU,CAAC,KAAH,GAAT,OAA2B,CAAC,CAAE,EACpD,CAED,OAAO,CACT,GA4oBkC,CAhpBoC,CAAC,CAipBhE,CA9oBU,AA6oBqB,AAC9B,CAD+B,AAGnCA,GAAsB,EAAU,CAAC,KAAH,GAAT,IAAwB,CAAC,CAAE,EACjD,CAED,IAAM,EAAmBD,GAAsB,EAAY,CAHM,AAGL,CAHM,MAGT,CAAX,AAAxB,MAAoD,CAAC,CAAC,AACpD,IAAI,EAAE,CAA1B,GACFC,GAAsB,EAAU,CAAC,KAAH,EADZ,CACG,MAA0B,CAAC,CAAE,GAGpD,IAAM,EAAqBD,GAAsB,EAAY,CAC3D,CAJkE,CAAC,KAGV,CAAX,EAAxB,MACN,CACjB,CAAC,AACE,AAAsB,IAAI,EAAE,IAC9BC,GAAsB,EAAU,CAAC,EADb,GACU,GAAT,QAA4B,CAAC,CAAE,GAGtD,IAAM,EAAiBD,GAAsB,EAAY,CAAC,GAHc,CAAC,EAGrD,CAAmC,CAAX,IAA0B,CAAC,CACjD,AADkD,IAC9C,EAAE,CAAxB,GACFC,GAAsB,EAAU,CAAC,KADjB,AACc,GAAT,IAAwB,CAAC,CAAE,GAGlD,IAAM,EAAoBD,GAAsB,EAHgB,AAGJ,CAHK,AAI/D,OADwD,CAAX,CAAxB,MACN,CAChB,CAAC,CAKF,OAJyB,IAAI,EAAzB,AAA2B,GAC7BC,GAAsB,EAAU,CAAC,KAAH,GADX,AACE,OAA2B,CAAC,CAAE,GAG9C,CACT,EAuIQ,IAMF,AAAa,CA9IF,GA8IM,EAAE,CAjJ+C,AAgJhE,CAhJiE,AA2IpB,CAC9C,AAIaD,AACL,CAJV,EAGqC,EAAY,CAAC,CAAtC,MAAmC,AAAU,CAArB,AAAsB,CAAC,GAE5DC,GAAsB,EAAU,CAAC,KAAH,EAAU,CAAnB,AAAoB,CAAE,GAGtC,GAxxCF,CAAC,CAEJA,CAmxCoD,CAAC,CAGxC,AAtxCS,EAAU,CAAC,KAAH,GAAT,UAA8B,CAAC,CAAE,EACvD,CAED,IAAM,EAAmCD,GAAsB,EAAY,CACzE,AAJqE,CAAC,MAGC,CAAX,gBAAxB,MACN,CAC9B,kBAAkB,CACnB,CAAC,CACF,GAAwC,IAAI,EAAxC,EAA0C,CAC5C,IAAI,EAAkB,EAClB,KAAK,CAAC,KADS,EACF,CAAC,KAChB,EAHgC,AAGd,EAAgB,GAAG,CAAC,AAAC,EADR,CADqB,AAG3C,AAFuB,CACW,CAE1C,AAHiC,CAGhC,CAFa,AACF,AAGfC,EAJmC,AAAc,CAK/C,EACA,CAAC,KADO,GADW,sBAEY,CAAC,CAChC,EAEH,CAED,OAAO,CACT,EA0ImCW,EA/Id,CAChB,AA8IyD,EA3I7C,GA+IR,CACT,CAEM,CAPgE,CAAC,CAAC,CACnE,EAGY,GAGD,GACd,CAA0B,CARiC,CAQjC,YAqEpB,AAtE0B,EAwE1B,EAKA,EAKA,EAZQ,IAEE,AA7MV,EAkNU,EA1EV,EAAoC,CAAA,CAAE,CA+EvB,AA7Ef,CA1IU,CA0ICZ,CAFH,EAEyB,EAAY,CAArC,AAAsC,MAAM,CAAT,AAAU,CAArB,AAAsB,AAC5C,IAAI,EAAE,CAAlB,GACFC,GAAsB,EAAU,AADtB,CACuB,KAAH,CAAS,CAAC,CAAE,AAArB,GAGvB,IAAM,CAH8C,CAAC,AAG7BD,GAAsB,EAAY,CAAC,OAAH,AAAnC,CAAwB,KAA2B,CAAC,CAClD,AADmD,IAC/C,EAAE,CAAzB,GACFC,GAAsB,EAAU,CAAC,KAAH,CADb,EACI,KAAyB,CAAC,CAAE,GAGnD,IAAM,EAAYD,GAAsB,EAAY,CAHc,AAGb,CAHc,AAGpD,MAA6C,AAAV,CAAW,AAAtB,CAAuB,AAC1D,AAAa,IAAI,EAAE,GAAV,CACXC,GAAsB,EAAU,CAAC,KAAH,EAAU,CAAnB,AAAoB,CAAEU,GAAY,IAGzD,EAHwD,EAGlD,CAH4D,CAAC,AAGjDX,CAHkD,EAG5B,EAAY,CAAC,CAAtC,MAAmC,AAAU,CAArB,AAAsB,CAC5C,AAD6C,IACzC,EAAE,CAAnB,GACFC,GAAsB,EAAU,CADrB,AACsB,KAAH,EAAU,CAAnB,AAAoB,CAAE,GAG7C,IAAM,EAHgD,AAG/BD,CAHgC,EAGV,EAAY,CAAC,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CACjD,AADkD,IAC9C,EAAE,CAAxB,GACFC,GAAsB,EAAU,CAAC,KAAH,AADd,GACK,IAAwB,CAAC,CAAE,GAGlD,IAAM,EAAgBD,GAAsB,EAAY,AAHQ,CAAC,AAGR,KAAtC,EAAmC,CAAX,GAAyB,CAAC,CAAC,AACjD,IAAI,EAAE,CAAvB,GACFC,GAAsB,EAAU,CAAC,IADlB,CACe,GAAT,GAAuB,CAAC,CAAE,GAGjD,IAAM,EAAcD,GAAsB,CAHoB,CAAC,AAGT,CAAC,GAAtC,IAAmC,CAAX,CAAuB,CAAC,CAAC,AAC/C,IAAI,EAAE,CAArB,GACFC,GAAsB,EAAU,CAAC,EADpB,GACiB,GAAT,CAAqB,CAAC,CAAE,GAG/C,IAAM,EAAiBD,EAHmC,CAAC,AAGd,EAAY,CAAC,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,AAClD,IAAI,EAAE,CAAxB,GACFC,GAAsB,EAAU,CAAC,KADjB,AACc,GAAT,IAAwB,CAAC,CAAE,GAGlD,IAAM,EAAYD,GAAsB,EAHwB,AAGZ,CAHa,AAGZ,CAAtC,MAAmC,AAAU,CAArB,AAAsB,CAAC,AAC7C,IAAI,EAAE,CAAnB,GACFC,GAAsB,EAAU,CADrB,AACsB,KAAH,EAAU,CAAnB,AAAoB,CAAE,GAG7C,IAAM,EAHgD,AAGtCD,CAHuC,EAGjB,EAAzB,AAAqC,CAAC,OAAH,CAAX,KAA2B,CAAC,CAClD,AADmD,IAC/C,EAAE,CAAjB,GACFC,GAAsB,CADb,CACuB,CAAC,KAAH,AAAQ,CAAC,EAAlB,AAAoB,EAkBD,CAAA,CAAE,CAG1B,AAAd,IAAkB,EAAE,GADLD,CACL,EALd,EAhBoE,EAoBf,CAAC,EApBa,EAAQ,CAgB3C,AAhB4C,CAoBpC,AApBqC,CAgB7C,AAIS,UAAU,AAAoB,CAAC,CAAC,GAEvEC,GAAsB,EAAU,CAAC,KAAH,GAAW,AAApB,CAAqB,CAAE,GAI1C,AAAc,IAAI,EAAE,CAJgC,CAAC,CAGtCD,CACL,EAD2B,EAAY,CAAC,OAAH,CAAX,GAAyB,CAAE,MAAM,CAAC,CAAC,GAEzEC,GAAsB,EAAU,CAAC,KAAH,GAAT,AAAoB,CAAC,CAAE,GAO1C,AAAmB,IAAI,EAAE,CAP2B,CAAC,CAGjCD,GAAsB,EAAY,CACxD,AAGiB,OAJqC,CAAX,QAC3B,CAChB,UAAU,CACX,CAAC,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,KAAyB,CAAC,CAAE,GAG5C,IAnCP,IAAM,AAmCS,EAnCED,EAgCiD,CAAC,AAhC5B,EAAY,CAArC,AAAsC,OAAH,CAAX,MAA4B,CAAC,CAAC,CASpE,OARgB,IAAI,EAAhB,AAAkB,GACpBC,GACE,EAFQ,AAGR,CAAC,KADO,CACD,CAAC,CAFW,CAvMvB,AA0MI,EAA8BW,GAA2B,GAxMvD,EAF+B,AAEK,CAAA,CAFL,AAEO,CAGxC,AAAc,AAqMmD,CAAC,CAAC,CAxMzD,AAyMX,CAtMmB,EAAE,CADlB,EAAaZ,CACL,EAD2B,CAsMmB,CAtMP,CAAC,CAsMrB,CAtMjB,KAAmC,CAAX,WAAiC,CAAC,CAAC,GAEzEC,GAAsB,EAAU,CAAC,KAAH,GAAT,AAAoB,CAAC,CAAE,GAO1C,AAAc,IAAI,EAAE,CAPgC,CAAC,CAGtCD,CAIL,EAJ2B,EAAY,CACnD,OADiD,CAAX,QACtB,CAChB,iBAAiB,CAClB,CAAC,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,AAAoB,CAAC,CAAE,GAO1C,AAAmB,IAAI,EAAE,CAJvB,AAHkD,CAAC,CAGjCD,GAAsB,EAAY,CACxD,AAGiB,OAJE,AAAmC,CAAX,aACtB,CACrB,WAAW,CACZ,CAAC,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,KAAyB,CAAC,CAAE,GAG5C,IAqLA,CACT,CAuQM,EA7bW,IAHmD,AAwLnD,CAxLoD,EAgcrDgB,GACd,CAAyB,EAAA,AAEzB,IAAM,EAAoC,CAAA,CAAE,CAEtC,CALsB,CAKVjB,CAFJ,EAE0B,EAAY,CAAC,CAAtC,MAAmC,AAAU,CAArB,AAAsB,CAAC,CAC9D,GAAI,AAAa,IAAI,IAAE,CAAV,AACX,IAAI,EAAkB,EAClB,KAAK,CAAC,CADqB,IAAZ,EACF,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,CACW,CADT,EACnB,EAAkB,AAAc,yBAo/B7C,QAAQ,CArER,EAAoC,CAAA,CAAE,CAKxC,AAAqB,GALX,CAKe,EAAE,CAHzB,EAAoBA,GAHA,EA76BD,EAg7BmC,CAC1D,AAEmB,CAn7BQ,CAAC,GA66BkB,CAGD,CAAxB,AAAyB,AAHA,QAI/B,CAChB,CAFyD,AAExD,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,OAA2B,CAAC,CAAE,GAIjD,AAAe,IAAI,EAAE,CADnB,EAAcD,EACL,CAD2B,EAAY,AAHgB,CAGf,AAHgB,GAGtD,IAAmC,CAAX,CAAuB,CAAC,CAAC,GAEhEC,GAAsB,EAAU,CAAC,KAAH,GAAT,CAAqB,CAAC,CAAE,GAI3C,AAAkB,IAAI,EAAE,CADtB,CAHoD,CAGnCD,AAHoC,GAGd,EAAY,AACvC,CADwC,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,GAEtEC,GACE,EACA,CAAC,KADO,GADW,IAEN,CAAC,CACdY,AA5mCA,SAAUA,AAAY,CAAsB,EAAA,AAChD,CA2mCe,GA3mCT,EAAoC,CAAA,CAAE,CAE5C,CAHyB,EACX,KAE6C,IAAvDb,GAAsB,EAAY,AAA8B,CAA7B,CAA+B,MAAlC,CAAX,KAA2B,CAAC,CAAC,CACpD,MAAU,AAAJ,KAAS,CAAC,uDAAuD,CAAC,CAG1E,IAAM,EAAWA,GAAsB,EAAY,CAArC,AAAsC,MAAM,CAAT,AAAU,CAArB,AAAsB,AAC5C,IAAI,EAAE,CAAlB,GACFC,GAAsB,EADZ,AACsB,CAAC,KAAH,CAAS,CAAC,CAAnB,AAAqB,GAG5C,IAAM,CAH8C,CAG/BD,AAHgC,GAGV,EAAY,CAAC,IAAtC,GAAmC,CAAX,EAAwB,CAAC,CAAC,CAKpE,OAJoB,IAAI,EAAE,AAAtB,GACFC,GAAsB,EAAU,CAAC,GADnB,EACgB,GAAT,EAAsB,CAAC,CAAE,GAGzC,CACT,EA0lCkB,IAKZ,AAAgB,CAhmCL,CAH6C,CAAC,CAmmCrC,EAAE,CADpB,EAAeD,CAJS,CAAC,CAC5B,AAGwC,AAC3B,EADuC,CAAC,IAAtC,GAAmC,CAAX,EAAwB,CAAC,CAAC,GAElEC,GACE,EACA,CAAC,KADO,GADW,EAER,CAAC,CA3lBZ,AA4lBAwB,SA5lBUA,AACd,CAA0B,EAAA,AAE1B,IAAM,CAylBa,CAzlBuB,CAAA,CAAE,CAE5C,GAFc,EAHe,GAK8B,IAAvDzB,GAAsB,EAAY,AAA8B,CAA7B,CAA+B,MAAlC,CAAX,KAA2B,CAAC,CAAC,CACpD,MAAM,AAAI,KAAK,CAAC,uDAAuD,CAAC,CAG1E,IAAM,EAAcA,GAAsB,EAAY,CAAC,GAAtC,IAAmC,CAAX,CAAuB,CAAC,CAAC,AAC/C,IAAI,EAAE,CAArB,GACFC,GAAsB,EAAU,CAAC,EADpB,GACiB,GAAT,CAAqB,CAAC,CAAE,GAG/C,IAAM,EAAeD,EAHqC,CAAC,AAGhB,EAAY,CAAC,IAAtC,GAAmC,CAAX,EAAwB,CAAC,CAAC,CAKpE,OAJoB,IAAI,EAApB,AAAsB,GACxBC,GAAsB,EAAU,CAAC,GADnB,EACgB,GAAT,EAAsB,CAAC,CAAE,GAGzC,CACT,EAwkBsB,IAOhB,AAAwB,CAhlBb,CAH6C,CAAC,CAmlB7B,EAAE,CAH5B,CAJ0B,CAAC,AAIJD,CAH1B,EAGgD,EAAY,CAC7D,KAEsB,EAHqC,CAAX,IAAxB,MACN,CACnB,CAAC,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,UAA8B,CAAC,CAAE,GAIpD,AAAoB,IAAI,EAAE,CADxB,EAAmBD,GAAsB,EAAY,CAAC,CACxC,CAJwD,CAAC,IAGpB,CAAnC,AAAwB,MAA4B,CAAC,CAAC,GAE1EC,GAAsB,EAAU,CAAC,KAAH,GAAT,MAA0B,CAAC,CAAE,GAMhD,AAA2B,IAAI,EAAE,CAH/B,EAA0BD,GAAsB,CAHc,CAGF,AAHG,CAInE,OAD8D,CAAX,AAG1B,OAHE,MACN,CACtB,CAAC,GAEAC,GACE,EACA,CAAC,KADO,GADW,aAEG,CAAC,CACvB,GAOA,AAAsB,IAAI,EAAE,CAH1B,EAAqBD,GAAsB,EAAY,CAC3D,GAEoB,EAPK,CACxB,CAGwD,CAAX,EAAxB,MACN,CACjB,CAAC,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,QAA4B,CAAC,CAAE,GAMlD,AAAwB,IAAI,EAAE,CAH5B,EAAuBD,GAAsB,EAAY,CAC7D,AAJsE,CAAC,IAMjD,EAHqC,CAAX,IAAxB,MACN,CACnB,CAAC,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,UAA8B,CAAC,CAAE,GAIpD,AAAY,IAAI,EAAE,EAAV,CADKD,GAAsB,EAAY,CAAC,EAHwB,CAAC,GAGnB,CAAT,AAAU,CAArB,AAAsB,GAE1DC,GAAsB,EAAU,CAAC,KAAH,CAAS,CAAC,CAAnB,AAAqB,GAGrC,GAv/BF,CAAC,CAEJA,AAk/BkD,CAAC,EAl/B7B,AAq/BT,EAr/BmB,CAAC,KAAH,EAAU,CAAnB,AAAoB,CAAE,EAC5C,CAED,IAAM,EAAWD,GAAsB,EAAY,CAArC,AAAsC,AAHQ,CAAC,KAGH,CAAT,AAAU,CAArB,AAAsB,CAK5D,OAJI,AAAY,IAAI,EAAE,EAAV,CACVC,GAAsB,EAAU,CAAC,KAAH,CAAS,CAAC,CAAnB,AAAqB,GAGrC,CACT,CA+CgB,GAnDsC,CAAC,EAGtC,GAgDD,GACd,CAAoB,CACpB,CAA0C,EAAA,AAE1C,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAYD,CAFJ,EAE0B,EAAY,CAAC,CAAtC,KAN8B,CAMK,AAAU,CAArB,AAAsB,CAAC,AAC1D,AAAa,IAAI,EAAE,GAAV,CACXC,GACE,EACA,CAAC,KADO,CACD,CAAE,CAFU,MAEH,CAAC,CACjBmB,GAAS,EAAW,CAAZ,GAIZ,GAJsB,CAIhB,CAJ2B,CAAC,AAIlBpB,CAHb,EAGmC,EAAzB,AAAqC,CAAC,KAAK,CAAC,CAC1C,AADiC,AAAU,CAArB,GAClB,EAAE,CAAjB,GACFC,GACE,CAFO,CAGP,CAAC,KADO,EACA,CAFW,AAET,aAAa,CAAC,CACxB,AApUU,SAAA,AACd,CAAoB,CACpB,CAAgC,EAAA,AAEhC,IAAM,EAAoC,CAgUjB,AAhUiB,CAAE,CAE5C,GAAsD,AAAlDD,AAFU,IAJqB,KAM4B,EAAE,CAAvC,EAAD,AAAa,CAAC,OAAH,CAAW,CAAC,CAAC,CAC/C,MAAM,AAAI,KAAK,CAAC,kDAAkD,CAAC,CAGrE,GAAIA,KAAkD,OAA5B,EAAD,AAAa,AAAyB,CAAxB,CAA0B,MAA7B,CAAW,CAAC,CAAC,CAC/C,MAAM,AAAI,KAAK,CAAC,kDAAkD,CAAC,CAGrE,QAA2D,IAAvDA,GAAsB,EAAY,AAA8B,CAA7B,CAA+B,MAAlC,CAAX,KAA2B,CAAC,CAAC,CACpD,MAAM,AAAI,KAAK,CAAC,uDAAuD,CAAC,CAG1E,IAAM,EAAeA,GAAsB,EAAY,CAAC,IAAtC,GAAmC,CAAX,EAAwB,CAAC,CAAC,AAChE,AAAgB,IAAI,EAAE,IACxBC,EADc,CACQ,EAAU,CAAC,KAAH,GAAT,EAAsB,CAAC,CAAE,GAGhD,IAAM,EAAsBD,GAAsB,AAHU,CAAC,CAGC,CAC5D,OAD0D,CAAX,GAAxB,MACN,CAClB,CAAC,CACF,GAA2B,IAAI,EAA3B,EAA6B,CAC/B,IAAI,EAAkB,CAClB,KAAK,EAAC,EAFW,GACF,EACF,CAAC,GADuB,EAEvC,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAEtB,AAFuB,CACW,AA86BjC,CA/6BwB,EACnB,EAAkB,AAAc,IA86BrC,AACd,CAAoB,CACpB,CAAgC,EAEhC,AAFgC,IAE1B,EAj7B4B,AAi7BQ,CAAA,CAAE,CAEtC,EAAYA,CAFJ,EAE0B,EANL,AAMiB,CAAC,CAAtC,MAA6C,AAAV,CAAW,AAAtB,CACtB,AAD6C,IACzC,EAAE,CAAnB,GACFC,GACE,EACA,CAHS,AAGR,KADO,GADW,CAET,CAAE,OAAO,CAAC,CACpBmB,GAAS,EAAW,CAAZ,GAIZ,GAJsB,CAIhB,CAJ2B,CAAC,AAIbpB,CAHlB,EAGwC,EAAY,CAAC,IAAtC,GAAmC,CAAX,EAAwB,CAAC,CAAC,CACpE,GAAoB,IAAI,EAApB,EAAsB,CACxB,IAAI,EAAkBsC,GAAY,AADpB,GAEV,GAD6B,EACxB,CAAC,CADS,EAA2B,CAAC,GAC9B,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,AAEvBrB,CADkC,CADT,CAEV,CADT,EAAkB,AAAc,AAE9C,CAD2B,AAC1B,CAD2B,AAG/BhB,GAAsB,EAAU,CAAC,EAHR,GAGK,GAAT,CAAqB,CAAE,UAAU,CAAC,CAAE,EAC1D,CAED,IAAM,EAAeD,GAAsB,EAAY,CAHmB,AAGlB,CAHmB,GAGzD,GAAmC,CAAX,EAAwB,CAAC,CAAC,AAChE,AAAgB,IAAI,EAAE,IACxBC,EADc,CACQ,EAAU,CAAC,KAAH,GAAT,EAAsB,CAAC,CAAE,GAGhD,IAAM,EAAaD,GAHyC,AAGnB,CAHoB,CAGR,CAAC,EAAtC,KAAmC,CAAX,AAAsB,CAAC,CAAC,CAgBhE,OAfkB,IAAI,EAAlB,AAAoB,GACtBC,GACE,EACA,CAAC,CAHS,IAEF,GADW,CAET,CAAE,kBAAkB,CAAC,CAC/ByB,SAtXUA,AACd,CAAoB,CACpB,CAAuC,CACvC,CAAqC,EAAA,AAErC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAwB1B,CAFhB,EAEsC,AA+WpB,EA/WgC,CAC9D,MARwC,CAOoB,CAAX,KAAxB,MACN,CACpB,CAAC,MACmB,IAAjB,GAAuD,EAA7B,EAAiC,EAA7B,AAA+B,GAAjD,AACdC,GACE,EACA,CAAC,QAFkB,CACP,GAFuC,OAG/B,CAAC,CACrBgB,GAAeU,GAAW,KAI9B,AAJ6B,IAIvB,CAJY,CAIM3B,GAAsB,EAAY,CAAC,IAJR,CAAC,CAAC,CAClD,AAGkB,AAAmC,CAAX,KAA2B,CAAC,CAAC,AACnD,IAAI,EAAE,CAAzB,GACFC,GAAsB,EAAU,CAAC,KAAH,CADb,EACI,KAAyB,CAAC,CAAE,GAGnD,IAAM,EAAWD,GAAsB,EAAY,CAAC,AAHc,AAGpD,CAHqD,KAGT,CAAC,AAAV,CAAW,AAC5C,AADsB,IAClB,EAAE,CAAlB,GACFC,GAAsB,EADZ,AACsB,CAAC,KAAH,CAAS,CAAC,CAAnB,AAAqB,GAG5C,IAAM,CAH8C,CAAC,AAGpCD,GAAsB,EAAY,CAArC,AAAsC,MAAM,CAAT,AAAU,CAArB,AAAsB,AAC5C,IAAI,EAAE,CAAlB,GACFC,GAAsB,EADZ,AACsB,CAAC,KAAH,CAAS,CAAC,CAAnB,AAAqB,GAG5C,IAAM,CAH8C,CAAC,AAG1BD,GAAsB,EAAY,CAC3D,OADyD,CAAX,EAAxB,MACN,CACjB,CAAC,AACwB,IAAI,EAAE,CAA5B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,CADD,OAC6B,CAAC,CAAE,GAGtD,IAAM,EAAsBD,GAAsB,EAAY,CAC5D,GAJsE,CAAC,GAGb,CAAX,GAAxB,MACN,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAoBD,GAAsB,EAAY,CAC1D,IAJwE,CAAC,EAGjB,CAAX,CAAxB,MACN,CAChB,CAAC,AACuB,IAAI,EAAE,CAA3B,GACFC,GAAsB,EAAU,CAAC,KAAH,GADX,AACE,OAA2B,CAAC,CAAE,GAGrD,IAAM,EAAuBD,GAAsB,EAAY,CAC7D,EAJoE,CAAC,IAGV,CAAX,IAAxB,MACN,CACnB,CAAC,AAC0B,IAAI,EAAE,CAA9B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,GADC,OAC6B,CAAC,CAAE,GAGxD,IAAM,EAAeD,GAAsB,EAAY,CAAC,IAAtC,CAH0D,CAAC,CAGxB,CAAX,EAAwB,CAAC,CAAC,AAChD,IAAI,EAAE,CAAtB,GACFC,GAAsB,EAAU,CAAC,GADnB,EACgB,GAAT,EAAsB,CAAC,CAAE,GAGhD,IAAM,EAAsBD,GAHgC,AAGV,CAHW,CAGC,CAC5D,OAD0D,CAAX,GAAxB,MACN,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAuBD,GAAsB,EAAY,CAC7D,IAJwE,CAAC,EAGd,CAAX,IAAxB,MACN,CACnB,CAAC,AAC0B,IAAI,EAAE,CAA9B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,GADC,OAC6B,CAAC,CAAE,GAGxD,IAAM,EAAWD,GAAsB,EAAY,CAArC,AAAsC,KAHwB,CAGlB,AAHmB,CAGlB,AAAV,CAAX,AACtB,AAD4C,IACxC,EAAE,CAAlB,GACFC,GAAsB,EAAU,AADtB,CACuB,KAAH,CAAS,CAAC,CAAnB,AAAqB,GAG5C,IAAM,CAH8C,CAAC,AAGxBD,GAAsB,EAAY,CAC7D,OAD2D,CAAX,IAAxB,MACN,CACnB,CAAC,AAC0B,IAAI,EAAE,CAA9B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,GADC,OAC6B,CAAC,CAAE,GAGxD,IAAM,EAAqBD,GAAsB,EAAY,CAC3D,KAJ0E,CAAC,CAGlB,CAAX,EAAxB,MACN,CACjB,CAAC,AACwB,IAAI,EAAE,CAA5B,GACFC,GACE,EACA,CAAC,KADO,GADW,CADD,OAGD,CAAC,EAClB2B,EAAU,IAId,CAJa,GAIP,EAAyB5B,GAAsB,EAAY,CAC/D,EAL8B,CAAC,CAC9B,GAG4D,CAAX,MAAxB,MACN,CACrB,CAAC,CASF,GAR8B,IAAI,EAA9B,AAAgC,GAClCC,GACE,EACA,CAAC,KADO,GADW,KADG,OAGD,CAAC,CACtB,QAIyD,IAAzDD,GAAsB,EAAY,AAAgC,CAA/B,CAAiC,GAJ9C,CACvB,EAGiC,CAAX,OAA6B,CAAC,CAAC,CACtD,MAAM,AAAI,KAAK,CAAC,yDAAyD,CAAC,CAG5E,QACkE,IAAhEA,GAAsB,EAAY,AAAuC,CAAtC,CACnC,MADgC,CAAX,cAAoC,CAAC,CAAC,CAE3D,MAAM,AAAI,KAAK,CACb,gEAAgE,CACjE,CAGH,IAAM,EAAqBA,GAAsB,EAAY,CAC3D,OADyD,CAAX,EAAxB,MACN,CACjB,CAAC,CACF,QAAqB,IAAjB,GAAoD,EAA1B,EAA8B,EAA1B,EAA4B,CAA9C,AACd,IAAI,EAAkB,EAClB,KAAK,CAAC,CAFwC,IAC/B,EACF,CAAC,EADsB,GAEtC,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAEtB6B,AAFuB,CACW,AAmf3C,CApfkC,EACnB,EAAgC,AAAd,IAmfvBA,AACd,CAA+B,EAAA,AAE/B,IAAM,EAAoC,CAAA,CAAE,CArfX,AAufjC,GAFc,AAEV7B,AAAkD,OALpB,EAK6B,EAAE,CAAvC,EAAD,AAAa,CAAC,OAAH,CAAW,CAAC,CAAC,CAC/C,MAAM,AAAI,KAAK,CAAC,kDAAkD,CAAC,CAGrE,IAAM,EAAeA,GAAsB,EAAY,CAAC,IAAtC,GAAmC,CAAX,EAAwB,CAAC,CAAC,AAChD,IAAI,EAAE,CAAtB,GACFC,GAAsB,EAAU,CAAC,GADnB,EACgB,GAAT,EAAsB,CAAC,CAAE,GAGhD,IAAM,EAAgBD,GAHsC,AAGhB,CAHiB,CAGL,CAAC,KAAtC,EAAmC,CAAX,GAAyB,CAAC,CAAC,CAKtE,OAJqB,IAAI,EAArB,AAAuB,GACzBC,GAAsB,EAAU,CAAC,IADlB,CACe,GAAT,GAAuB,CAAC,CAAE,GAG1C,EACT,EAtgBoC,GAC7B,CAAC,AADgC,AAqgBvB,CArgBwB,AAGrCA,CA+f4D,CAAC,CA/fvC,EAAc,CAAC,QAAhB,CAAa,OAAmB,CAAC,CAAE,EACzD,CAED,IAAM,EAAYD,GAAsB,EAAY,CAHqB,AAGpB,CAHqB,AAG3D,MAAmC,AAAU,CAArB,AAAsB,CAAC,CAC9D,QAAqB,IAAjB,GAA2C,EAAjB,EAAqB,EAAjB,EAAmB,CACnD,AADc,IACV,EAAkB8B,AADmB,GACV,EAC3B,CAD0B,IACrB,EAD+B,AAC9B,CAD+B,AAAtB,MACF,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,AAEvBC,CADkC,AA8f3C,CA/fkC,EACnB,EAAkB,AAAc,IA8frCA,AAAY,CAAsB,EA7fxB,AA6fwB,AAChD,IAAM,EAAoC,CAAA,CAAE,CAEtC,CAHmB,CAGQ/B,CAFnB,EAEyC,EAAY,CACjE,OAD+D,CAAX,QAAxB,MACN,CACvB,CAAC,CACF,GAAgC,IAAI,EAAhC,EAAkC,CACpC,IAAI,EAAkB,EAClB,KAAK,CAAC,KADS,EACF,AAFS,CAER,KAChB,EAAkB,CAF0B,CAEV,GAAG,CAAC,AAAC,EADR,CAAC,AAEvB,CADkC,CADT,AAGjC,CAAC,CAFa,AACF,AAGfC,EAJmC,AAAc,CAI3B,EAAU,CAAC,KAAH,GAAT,cAAkC,CAAC,CAAE,EAC3D,CAED,GAAID,KAAqD,IAHkB,CAAC,EAGlD,EAAD,AAAa,AAA4B,CAA3B,CAA6B,MAAhC,IAAc,CAAC,CAAC,CAClD,MAAM,AAAI,KAAK,CAAC,qDAAqD,CAAC,CAGxE,IAAM,EAAmBA,GAAsB,EAAY,CAAC,OAAH,CAAnC,AAAwB,MAA4B,CAAC,CAAC,AACxE,AAAoB,IAAI,EAAE,IAC5BC,GACE,EACA,CAHgB,AAGf,KADO,GADW,MAEJ,CAAC,CAtWhB,AAuWAoC,SAvWUA,AACd,CAA8B,EAAA,AAE9B,IAAM,EAAoC,CAAA,CAAE,CAEtC,AAkWiB,EAlWKrC,CAFd,EAEoC,EAAY,CAC5D,CAN+B,MAK2B,CAAX,GAAxB,MACN,CAClB,CAAC,CAKF,GAJ2B,IAAI,EAA3B,AAA6B,GAC/BC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,QAGO,IAA1DD,GAAsB,EAAY,AAAiC,CAAhC,CAAkC,AAHC,CAAC,KAGvC,CAAX,QAA8B,CAAC,CAAC,CACvD,MAAM,AAAI,KAAK,CAAC,0DAA0D,CAAC,CAG7E,OAAO,CACT,EAsV0B,IAIxB,CA3Ve,GA2VT,EAA4BA,GAAsB,EAAY,CAJ5B,AAKtC,CALuC,CACtC,KAG+D,CAAX,SAAxB,MACN,CACxB,CAAC,CASF,GARiC,IAAI,EAAjC,AAAmC,GACrCC,GACE,EACA,CAAC,KADO,GADW,QADM,OAGD,CAAC,CACzB,QAK6D,IAA/DD,GAAsB,EAAY,AAAsC,CAArC,CACnC,MAN2B,AAKK,CAJ/B,AAIoB,aAAmC,CAAC,CAAC,CAE1D,MAAM,AAAI,KAAK,CACb,+DAA+D,CAChE,CAGH,IAAM,EAAiBA,GAAsB,EAAY,CAAC,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,AACpE,AAAkB,IAAI,EAAE,IAC1BC,GACE,CAFc,CAGd,CAAC,KADO,GADW,IAEN,CAAC,CAnZd,AAoZAmC,SApZUA,AACd,CAA4B,EAAA,AAE5B,IAAM,EAAoC,CAAA,AAiZrB,CAjZuB,CAE5C,GAFc,IAHiB,CAK2B,IAAtDpC,GAAsB,EAAY,AAA6B,CAA5B,CAA8B,MAAjC,CAAX,IAA0B,CAAC,CAAC,CACnD,MAAM,AAAI,KAAK,CAAC,sDAAsD,CAAC,CAGzE,IAAM,EAAmBA,GAAsB,EAAY,CAAC,OAAH,CAAnC,AAAwB,MAA4B,CAAC,CAAC,CAK5E,OAJwB,IAAI,EAAxB,AAA0B,GAC5BC,GAAsB,EAAU,CAAC,KAAH,EADZ,CACG,MAA0B,CAAC,CAAE,GAG7C,CACT,EAqYwB,IAItB,CA1Ye,GA0YT,EAAiBD,AA7Y6C,CAAC,EA6YxB,CAJT,CAAC,AAIoB,CAHtD,AAGuD,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,AAClD,IAAI,EAAE,CAAxB,GACFC,GAAsB,EAAU,CAAC,KAAH,AADd,GACK,IAAwB,CAAC,CAAE,GAGlD,IAAM,EAAkBD,GAAsB,EAAY,AAHM,CAAC,AAGN,OAAtC,AAAmC,CAAX,KAA2B,CAAC,CAAC,AACnD,IAAI,EAAE,CAAzB,GACFC,GAAsB,EAAU,CAAC,KAAH,CADb,EACI,KAAyB,CAAC,CAAE,GAGnD,IAAM,EAAoBD,GAAsB,EAAY,CAHM,AAIhE,CAJiE,MAGT,CAAX,CAAxB,MACN,CAChB,CAAC,CAKF,OAJI,AAAqB,IAAI,EAAE,GAC7BC,GAAsB,EAAU,CAAC,EADd,GACW,GAAT,OAA2B,CAAC,CAAE,GAG9C,EACT,EAxkB2B+B,GAAQ,CAukBlB,CAvkBiB,EAAK,AAChC,CADiC,AAChC,CADiC,AAGrC/B,CAikBoE,CAAC,CAjkB/C,EAAc,CAAC,OAAO,CAAvB,AAAwB,CAAE,AAAb,EACnC,CAED,IAAM,EAAiBD,GAAsB,EAAY,CAAC,AAHM,CAAC,KAG7C,CAAmC,CAAX,IAA0B,CAAC,CAAC,CAKxE,QAJqB,IAAjB,GAAgD,EAAtB,EAA0B,EAAE,AAAxB,GAChCC,AADc,GACQ,EAAc,CAAC,KADS,GACzB,CAAa,GAAe,CAAC,CAAE,GAGA,SAAlDD,AAA2D,EAAE,AAHG,CAAC,AAG3C,EAAY,CAAC,OAAH,CAAW,AAAtB,CAAuB,CAAC,CAC/C,MAAM,AAAI,KAAK,CAAC,kDAAkD,CAAC,CAGrE,IAAM,EAAoBA,GAAsB,EAAY,CAC1D,OADwD,CAAX,CAAxB,MACN,CAChB,CAAC,MACmB,IAAjB,GAAmD,EAAzB,EAA6B,EAAzB,AAA2B,GAA7C,AACdC,GACE,EACA,CAAC,QAH8C,AAC5B,CACP,MACI,CAAC,CACjBgC,GAAqB,EAAW,IAIpC,GAJkC,CAI5B,EAAyBjC,GAAsB,AAJ7B,EAIyC,CAC/D,CALmD,CAAC,CACnD,IAG4D,CAAX,MAAxB,MACN,CACrB,CAAC,AAC4B,IAAI,EAAE,CAAhC,GACFC,GACE,EACA,CAAC,KADO,GADW,KADG,OAGD,CAAC,CACtB,GAIJ,IAAM,EAAsBD,GAAsB,EAAY,CAC5D,OALwB,AAIkC,CAHzD,AAG8C,GAAxB,MACN,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAmBD,GAAsB,EAAY,CAAC,IAHc,CAAC,EAGlB,CAAnC,AAAwB,MAA4B,CAAC,CAAC,CAS5E,GARwB,IAAI,EAAxB,AAA0B,GAC5BC,GACE,EACA,CAAC,KADO,EAFQ,CACG,MAEJ,CAAC,CAChBiC,GAAgB,SAI0C,CAJ3C,GAIflC,GAJgC,AAIV,CAJW,CAClC,AAGmC,AAAiC,CAAhC,CAAkC,MAArC,CAAX,QAA8B,CAAC,CAAC,CACvD,MAAM,AAAI,KAAK,CAAC,0DAA0D,CAAC,CAG7E,IAAM,EAAqBA,GAAsB,EAAY,CAC3D,OADyD,CAAX,EAAxB,MACN,CACjB,CAAC,AACE,AAAsB,IAAI,EAAE,IAC9BC,GAAsB,EAAU,CAAC,EADb,GACU,GAAT,QAA4B,CAAC,CAAE,GAGtD,IAAM,EAAkBD,GAAsB,EAAY,CAAC,GAHa,CAAC,GAGpD,AAAmC,CAAX,KAA2B,CAAC,CAAC,CAK1E,OAJuB,IAAI,EAAvB,AAAyB,GAC3BC,GAAsB,EAAU,CAAC,KAAH,CADb,EACI,KAAyB,CAAC,CAAE,GAG5C,CACT,EAiKQ,EACA,EACAD,CApKS,EAoKa,EAAU,AAFvB,AArKmD,CAuK3B,AAvK4B,EAsKnD,GACoB,GAAT,CAAqB,CAAC,CAAE,CAAA,CAAE,CAG9C,CACF,CACF,CAGI,EACT,EA79BqC,EAAW,EA49B/B,CA39BV,CAD6C,AAC5C,CAD6C,AAGjDC,EAH0C,CAGpB,EAAU,CAAC,KAAH,GAAT,EAAsB,CAAE,UAAU,CAAC,CAAE,EAC3D,CAED,OAAO,CACT,EA+R4B,EAAWoB,AAnSsC,CAAC,EAG7D,AAgSwC,EAAW,EAA/B,GAInC,EAJgE,AAAS,CAAC,CAIpE,AAJqE,CAArB,AACnD,CAGgBrB,GAAsB,EAAY,CAAC,EAAtC,KAAmC,CAAX,AAAsB,CAAC,CAAC,CAKhE,OAJkB,IAAI,EAAlB,AAAoB,GACtB,AAvEY,OAsEA,EAtEA,AACd,CAAsC,CACtC,CAAqC,EAIrC,AAJqC,IAI/B,EAAkBA,GAAsB,EAAY,CAAC,CAiE9B,MAjE2B,AAAnC,CAAwB,EANJ,GAM+B,CAAC,CAAC,CAS1E,GARI,AAAiB,SAAS,GAAuB,AAArC,IAAyC,EAAvB,AAAyB,GACzDC,GACE,EACA,CAAC,MAH4C,CAGrC,CAFW,AAET,CADE,YACW,CAAC,CACxB,QAIgD,IAAhDD,GAJe,AAIO,CAHvB,CAGmC,AAAuB,CAAtB,CAAwB,KAAlB,CAAC,AAAV,CAAW,AAAtB,CACvB,MAAM,AAAI,KAAK,CAAC,gDAAgD,CAAC,AAIrE,EAmDgC,EAAY,GAGnC,CACT,CCvmBE,GDmmBkD,AAAV,CAAW,ACpmBzC,EDumBK,GCtmBf,AADU,GAMX,CANoB,CAMpB,CAAA,CAAA,CAAA,AALC,AADmB,CAAA,oBACnB,CAAA,CAAA,UAAmC,CACnC,GAAA,MAAA,WAAA,CAAA,CAAA,OAA4B,CAC5B,GAAA,MAAA,gBAAA,CAAA,CAAA,WAAqC,CACrC,GAAA,MAAA,UAAA,CAAA,CAAA,MAA0B,CAC1B,GAAA,MAAA,oBAAA,CAAA,CAAA,eAA6C,AAsB5C,OACU,GAWX,EAXgB,CAAA,QAWhB,CACE,CAAe,CACf,CAAmE,CACnE,CAA8B,CAC9B,CAAuB,CAAA,CAbjB,IAAY,CAAA,YAAA,CAAQ,EAAE,CACtB,IAAc,CAAA,cAAA,CAAoB,CAAA,CAAE,CAc1C,IAAI,CAAC,eAAe,CAAG,EACvB,IAAI,CAD0B,AACzB,IAAI,CAAC,EAAM,EAAU,AAAZ,GAGR,GAHkB,AAAQ,CAGtB,AAHuB,CAIjC,CAAe,CACf,CAA8B,CAC9B,CAAuB,CAAA,SAEvB,IAAI,CAAC,YAAY,CAAG,EACpB,EADwB,EACpB,CAAC,YAAY,CAAG,CAAQ,CAAC,IAAI,CAAC,YAAY,CAAC,EAAI,EAAE,CAErD,IAAI,CAAC,uBAAuB,OAAG,EAAA,KAAA,CAAA,AAAQ,CAAR,EAAU,EAAF,IAAA,IAAR,KAAyB,CACxD,EADuC,EACnC,CAAC,EAD0B,KAAA,CAAA,GACf,CAAG,CAAC,CACpB,IAAI,EAAiC,CAAC,MAAM,CAAE,CAAA,CAAE,CAA/B,AAAgC,AAQ7C,EAJF,EAHE,AAAC,GAAyC,CAAC,EAApC,AAAsC,CAAlC,EAOE,EAJF,EAHM,CAAC,IAAI,CAAC,GAAQ,GAAF,CAAC,EAAO,CAEZ,QAAQ,EAA1B,AAA4B,OAArB,EACH,IADS,EACT,CAAA,MAAA,CAAA,CAAA,CAAA,CAAO,GAEJ,EAJA,CAEU,AAFT,CAEU,EAEL,GAJC,CAAE,CAAA,CAAE,CAAC,EAMZ,MAAS,EAAD,AAAG,CAC3B,EAAc,MAAS,CAAC,CAAF,GAAT,KAAuB,CAAG,CAAJ,CAAa,MAAD,OAAgB,AAAC,EAElE,IAAI,CAAC,cAAc,CAAG,EACtB,IAAI,CAAC,MAD8B,UACd,CACnB,OAAA,EAAA,OAAA,EAAA,EAAc,MAAQ,AAAC,EAAG,GAAb,CAAa,CAAA,CAAA,CAAA,CAAA,CAAA,GAAA,EAAA,GAAU,AAAC,EAAA,AAAX,EAAW,AAAI,EAAJ,CAAX,CAAmB,AAAnB,CAAoB,CAAT,IAAA,EAAA,KAAA,AAAqB,CAAC,IAAtB,CAAA,CAA4B,CAG7D,YAAY,CAAC,CAA8B,CAAA,CACjD,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,YAAY,CAAE,EAAU,IAAI,CAAC,CAAP,aAAqB,CAAC,CAU7D,IAAI,IAAI,EAAA,CACN,OAAO,IAAI,CAAC,YAAY,CAM1B,IAAI,IAAI,EAAA,CACN,OAAO,IAAI,CAAC,YAAY,CAS1B,IAAI,QAAQ,EAAA,CACV,OAAO,IAAI,CAAC,gBAAgB,CAM9B,IAAI,eAAe,EAAA,CACjB,OAAO,IAAI,CAAC,uBAAuB,CAWrC,IAAI,MAAM,EAAA,CACR,OAAO,IAAI,CAAC,cAAc,CAM5B,IAAI,UAAU,EAAA,CACZ,OAAO,IAAI,CAAC,YAAY,CAAC,MAAM,CAMjC,OAAO,CAAC,CAAa,CAAA,CACnB,OAAO,IAAI,CAAC,YAAY,CAAC,EAAM,CAoBjC,CAAC,CApB+B,KAoBzB,CAAC,aAAa,CAAC,EAAA,CACpB,MAAO,CACL,IAAI,CAAE,UACJ,EADe,CACX,IAAI,CAAC,WAAW,EAAI,IAAI,CAAC,UAAU,CACrC,CADuC,GACnC,IAAI,CAAC,WAAW,EAAE,CAGpB,CAHsB,KAGf,CAAC,KAAK,MAAE,EAAW,IAAI,EAAE,CAAR,AAAY,CAAC,EAAD,IAFpC,MAAM,IAAI,CAAC,QAAQ,EAAE,CAKzB,IAAM,EAAO,EAAH,EAAO,CAAC,OAAO,CAAC,IAAI,CAAC,WAAW,CAAC,CAE3C,OADA,IAAI,CAAC,WAAW,EAAI,CAAC,CACd,CAAC,KAAK,CAAE,EAAM,EAAF,EAAM,CAAE,EAAK,CAAC,CAClC,CADiC,AAElC,MAAM,CAAE,UACC,CAAC,CADS,IACJ,MAAE,EAAW,IAAI,EAAE,CAAR,CAAY,CAAC,CAAD,AAEvC,CAwBH,MAAM,QAAQ,EAAA,CACZ,GAAI,CAAC,IAAI,CAAC,WAAW,EAAE,CACrB,CADuB,KACjB,AAAI,KAAK,CAAC,yBAAyB,CAAC,CAE5C,IAAM,EAAW,MAAH,AAAS,IAAI,CAAC,eAAe,CAAC,IAAI,CAAC,MAAM,CAAC,CAExD,OADA,IAAI,CAAC,YAAY,CAAC,GACX,IAAI,CAAC,AADc,CAAC,GACX,CAMlB,WAAW,EAAA,aACL,QAAA,EAAA,IAAI,CAAC,MAAM,CAAC,MAAQ,AAAC,EAAG,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,GAAA,EAAA,IAAW,AAAC,CAAZ,KAAA,CAAA,EAAiB,EAKhD,CCrNK,MDgNoD,AChN7C,EDgN+C,KChNvC,IAAQ,GAC3B,OADqC,CAAA,GACrC,CAA6B,CAAoB,CAAA,CAC/C,KAAK,EAAE,CADoB,IAAS,CAAA,SAAA,CAAT,EAsB7B,IAAA,CAAA,EAtBsC,IAsBhC,CAAG,MACP,IAEI,EAFkC,EAE9B,CAAC,EADkB,OACT,CAAC,UAAU,EAAE,EAAE,CAG/B,EAAO,IAAD,EAAO,CAAG,IAAI,CAAC,iBAAiB,CACpC,EAAO,GAAoC,CAArC,AACN,EAAO,IAAD,EAAO,CACd,EAEI,IAAI,CAAC,cAAc,CAAC,IAkB7B,EAlBmC,CAAC,CAkBpC,CAAA,gBAAgB,CAAG,MACjB,IAMA,EANgD,CAEhD,IAD2B,GACpB,CAAC,IAAI,CACV,2EAA2E,CAC5E,CAEG,IAAI,CAAC,SAAS,CAAC,UAAU,EAAE,CAC7B,CAD+B,KACzB,AAAI,KAAK,CAAC,sDAAsD,CAAC,CAGzE,OAAO,IAAI,CAAC,wBAAwB,CAAC,EACvC,CAAC,CAgBD,EAjB6C,CAAC,CAiB9C,CAAA,IAAI,CAAG,MACL,EAAwC,CAAA,CAAE,EAAF,CAEjC,EAD2B,EACvB,GACT,EADc,CACJ,MAAD,eAAsB,CAC/B,AAAC,CAAgC,EAAK,IAAI,CAAC,YAAY,CAAC,CAAC,CAAC,CAC1D,MAAM,IAAI,CAAC,YAAY,CAAC,GACxB,GAD8B,AAM1B,CAN2B,EACzB,CACP,+BAIwC,CACzC,CAAsC,CAAA,CAEtC,IAAM,EAAOuC,EAAH,CACR,IAAI,CAAC,SAAS,CACd,GAII,EAAOC,CAJL,CACP,AAGS,CAAoB,KANyB,CAM1B,wBAA+B,CAD1C,CAC4C,CADvC,EAAD,EAAmC,EAA5B,AAKvB,EAFQ,AACM,AACI,AAJ+C,CAAC,CAErD,EAAD,CACO,EAD8B,CAC7B,CADA,EAES,EAAd,MAD+C,CAChC,CADG,OAGtC,CACK,CAHwC,CAG7B,EAAgB,IAAnB,IAEZ,CACI,CAHqC,CAGvB,EAHY,AAGV,CAEtB,IAAK,EAFY,EAEN,KAAW,EAAJ,AAAc,CAC9B,IAAM,CADsB,CACJ,MAAA,CAAA,EAAP,IAAO,CAAA,CAAA,CAAA,CAAA,GACxB,GAAI,CAD2B,CAAC,AAChB,CADiB,CAAA,OAClB,CADkB,OACG,CAAE,CACpC,AADiC,IAC3B,EAAyB,EAAY,SAAD,QAAqB,AAC/D,CAD4B,CAAkC,MACvD,EAAY,SAAD,QAAqB,CACvC,CADsC,GAChC,EAAiB,EAAY,OAElC,CACD,CAHkC,AAAU,CAAxB,AAGL,YAAD,KAAqB,CAAG,CAAJ,CAClC,EAAY,OAAU,CAAG,CAAd,AAAU,AACtB,CACD,EAAY,IAAI,CAAC,CAH6C,CAI/D,CAOD,CARa,CAF8B,KAI3C,CAF8B,CAEd,AAFe,QAEJ,CAAG,CAAJ,CAE1B,EAFe,KAER,EAFkC,AAE7B,EAAD,IAAU,CACrB,CADoB,MACb,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEd,CAFa,KAEZ,EAAM,EAAF,EAAM,EAAA,CAAC,CAIb,SAAS,CAAC,CAAkC,CAAA,OAClD,AAAmB,QAAQ,EAAvB,AAAyB,OAAlB,EACF,CADK,CACD,CAAD,SAAW,CAAC,OAAO,CAAC,CAAG,GAAG,IAAG,EAErC,CAAC,KAAK,CAFwC,AAEvC,OAAO,CAAC,GAAG,CAAC,AAAI,EAAI,CAAD,KAAO,EAAI,EAAI,CAAD,KAAO,CAAC,MAAM,CAAG,CAAC,CACrD,CADuD,CACnD,CAAD,KAAO,CAAC,CAAC,CAAC,QAMhB,cAAc,CACpB,CAAkC,CAAA,OAElC,AAAmB,QAAQ,EAAE,AAAzB,OAAO,EACF,CADK,CACD,CAAD,SAAW,CAAC,OAAO,CAAC,CAAG,GAAG,IAAG,EAEpC,KAAK,CAAC,CAFuC,MAEhC,CAAC,GAAG,CAAC,EAAE,IAChB,EAAI,CAAD,UAAY,CAMlB,iBAAiB,CACvB,CAAkC,CAClC,CAAmC,CAAA,CAEnC,IAAM,EAAY,EAAa,IAAP,CAAT,CAAgB,CAAA,MAAA,CAAA,CAAA,CAAA,CAAA,GAAU,CAAA,CAAE,CAErC,AAF+B,CAAE,CAElB,IAAI,CAAC,GAAG,EAAX,AAAa,CAAC,QAAQ,EAAE,CAM1C,GAJI,AAAC,EAAU,OAAD,IAAY,EAAE,CAC1B,EAAU,OAAD,IAAY,CAAG,CAAiB,cAAA,EAAA,EAAY,CAAA,AAAE,OAGlC,EAHgC,EAGnD,EAAU,GAAkB,CAAd,CAAgB,CAChC,CADW,GACL,EAAS,IAAH,AAAO,CAAC,SAAS,CAAC,GAAG,AAC3B,CAD4B,CACd,IAAI,CAAC,IAAR,UAAsB,CAAC,GAAG,AAE3C,CAF4C,EAExC,EACE,EAAO,EADH,EAAE,AACA,IAAS,CAAC,QAAQ,CAAC,CAE3B,CAF6B,CAEnB,IAAI,CAAG,CAAA,CAAR,CAAW,EAAO,IAAD,CAAM,CAAC,CAAC,CAAE,CAAA,CAAE,CAAC,CAAA,KAAA,CAAO,CAG9C,EAAU,IAAI,CAAG,CAAA,CAAR,CAAW,EAAe,IAAT,EAAS,EAAA,EAAY,CAAE,MAE9C,GAF4C,AAExC,EACT,EAAU,IAAI,CAAG,CAAA,CADG,AACX,CAAW,CADE,CACkB,MAAA,EAAA,CAAT,CAAqB,CAAE,MAEtD,GAFoD,GAE9C,AAAI,KAAK,CACb,iEAAiE,CAClE,AAEJ,CACD,OAAO,EAUD,MAAM,CAVI,aAUU,CAC1B,CAAsC,CAAA,mBAIlC,EAAe,EAAX,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,GAAI,GADW,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,KF0Z7B,IAOA,EASA,EAhBQ,AArDR,GA4DO,CEhaH,GFsZV,CAmBgB,AEzaF,CACR,EADWC,EACP,CAAC,CFmWU,CAkDD,EACpB,KEtZoB,GFwZsB,CAAA,CAFA,AAEE,CAG3B,AAAb,CALsC,GAKrB,EAAE,CADjB,EAAYzC,AACL,GE1ZP,EFyZ8C,AE3ZQ,CF2ZP,CAAtC,EEzZH,CACP,GFwZuD,CAArB,AAAsB,CAArB,AAAsB,GAE5DC,GAAsB,EAAU,CAAC,CAFe,IAElB,EAAU,CAAC,AAApB,CAAsBmB,GAAS,EAAW,CAAZ,GAIjD,AAAW,GAJgD,CAI5C,CAJuD,CAAC,AAItD,CAJuD,AAIjE,EADKpB,KAAkC,CAAC,KAAK,CAAC,CAAC,CAArB,CAAC,CAEpCC,GACE,EACA,CAAC,GAJ2C,EAGpC,GADW,KAEL,CAAC,CAxTf,AAyTA,SAzTU,AACd,CAAgC,EAEhC,AAFgC,IAE1B,EAAoC,CAAA,CAAE,CAEtC,CAoToB,CApTPD,CAFL,EAE2B,EAAY,CAAC,EALlB,AAKpB,KAAmC,CAAX,AAAsB,CAAC,CAC7C,AAD8C,IAC1C,EAAE,CAApB,GACFC,GAAsB,EAAU,CAAC,CADrB,IACkB,GAAT,SAA6B,CAAC,CAAE,GAGvD,IAAM,EAAaD,CAH8C,CAAC,CAGzB,EAAY,CAAC,EAAtC,KAAmC,CAAX,AAAsB,CAAC,CAAC,AAC9C,IAAI,EAAE,CAApB,GACFC,GAAsB,EAAU,CAAC,CADrB,IACkB,GAAT,GAAuB,CAAE,MAAM,CAAC,CAAE,GAGzD,IAAM,EAAkBD,CAH2C,CAAC,CAGtB,EAAY,CAAC,OAAtC,AAAmC,CAAX,KAA2B,CAAC,CAAC,CAS1E,GARuB,IAAI,EAAE,AAAzB,GACFC,GACE,EACA,CAAC,KADO,CAFO,EACI,QAEF,CAAE,UAAU,CAAC,CAC9B,GAIoD,SAAS,AAA7DD,EAA+D,CAJhD,AAIO,CAHvB,CAGmC,CAAC,OAAH,CAAX,EAAwB,CAAC,CAAC,CACjD,MAAM,AAAI,KAAK,CAAC,mDAAmD,CAAC,CAGtE,QAA+D,IAA3DA,GAAsB,EAAY,AAAkC,CAAjC,CAAmC,MAAtC,CAAX,SAA+B,CAAC,CAAC,CACxD,MAAM,AAAI,KAAK,CAAC,0DAA0D,CAAC,CAG7E,OAAO,CACT,EAwR6BqB,GAAkB,EAzR9B,AAyRyC,KAKpD,AAAc,EALoC,AAAS,CAAC,CAAC,AAK3C,CALsB,AACzC,CAIqB,GADLrB,CACL,IADuC,CAAC,QAAd,AAAsB,CAArB,AAAsB,CAAC,MArExCA,GAqE2B,AAEpB,EAvE2B,CAAC,OAuElB,CAvEI,CAAC,IAA0B,CAAC,CAAC,CACtE,GADoD,EACnC,OAAa,AAAlB,AAAqC,EAAvB,EAA2B,EAAE,GACzDC,GAqEyC,EArEL,CAAC,AADU,KAsEE,CAAC,EArE7B,CAAC,IAA4B,CAAC,CAAE,GAGjD,EAAWD,CAHmB,IAGe,CAArC,AAAsC,IAHkB,CAAC,CAGb,CAAC,CAAC,AAAtB,CAClC,AADmC,KAClB,KAD4B,EACH,AAA9B,EAAc,EAAoB,EAAhB,AAAkB,GAClDC,KADwC,AAGtC,CAAC,QAFkB,CACnB,KACe,CAAC,CAChB,AAxfA,KAsfY,IAtfF,AACd,CAAqC,EAAA,AAErC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAaD,CAFL,EAE2B,CAmfV,CAnfsB,CAAC,EAAtC,KALyB,AAKU,CAAX,AAAsB,CAAC,CAAC,AAC9C,IAAI,EAAE,CAApB,GACFC,GAAsB,EAAU,CAAC,CADrB,IACkB,GAAT,WAA+B,CAAC,CAAE,GAGzD,IAAM,EAAaD,CAHgD,CAAC,CAG3B,EAAY,CAAC,EAAtC,KAAmC,CAAX,AAAsB,CAAC,CAC7C,AAD8C,IAC1C,EAAE,CAApB,GACFC,GACE,EACA,CAAC,CAHS,IAEF,GADW,QAEF,CAAE,iBAAiB,CAAC,CACrC,GAIJ,IAAM,EAAkBD,CAJV,CACX,CAG2C,EAAY,CAAC,OAAtC,AAAmC,CAAX,KAA2B,CAAC,CAAC,CAS1E,GARuB,IAAI,EAAvB,AAAyB,GAC3BC,GACE,EACA,CAAC,KADO,CAFO,EACI,aAEG,CAAE,WAAW,CAAC,CACpC,QAIoD,IAApDD,GAJe,AAIO,CAHvB,CAGmC,AAA2B,CAA1B,CAA4B,MAA/B,CAAX,EAAwB,CAAC,CAAC,CACjD,MAAM,AAAI,KAAK,CAAC,mDAAmD,CAAC,CAGtE,QAAgE,IAA5DA,GAAsB,EAA+C,AAAnC,CAAC,CAAoC,MAAvC,CAAX,UAAgC,CAAC,CAAC,CACzD,MAAU,AAAJ,KAAS,CACb,2DAA2D,CAC5D,CAGH,GACEA,KACA,OADsB,EACb,AADY,AAAa,CAAC,CAEnC,MAFgC,uBAAiC,CAAC,CAAC,CAGnE,MAAM,AAAI,KAAK,CACb,uEAAuE,CACxE,CAGH,OAAO,CACT,EAwckCmB,AD4Q5B,KCrtBW,IDqtBD,AACd,CAAwC,EAAA,AAExC,GAAoB,KC/QkC,GD+Q1B,EAAxB,AAA0B,IAHI,GAGvB,EACT,EADa,KACN,EAGT,EAH0C,CAGtC,EAAW,QAAD,EAAW,CAAC,OAAO,CAAC,CAChC,CADkC,KAC3B,CACL,MAAM,CAAE,OAAO,CACf,MAAM,EAAE,CACT,CACI,GAAI,EAAW,GAFA,KAED,EAAW,CAAC,OAAO,CAAC,CACvC,CADyC,KAClC,CACL,MAAM,CAAE,UAAU,CAClB,WAAW,CATI,CASF,CAGf,AAFC,EAV8B,KAYzB,AAAI,EAHe,GAGV,CAAC,CAAA,yBAAA,EAA4B,EAAU,CAAE,CAE5D,AAF6D,EC9RJ,ID8RC,EC9NjD,EAhEwD,CAAC,AErV5D,CFqV6D,CAC9D,GA+DY,EE1aX,EAAOqB,EAAH,CACF,MADqB,eACA,CACrB,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAaJ,CAfa,GAEL,CAAC,GAaD,MAbC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,MAAM,CAClB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,MAAA,EAAA,CAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,CAIL,EAHO,EAGH,AAJK,CAIJ,AAAC,GACPE,GAA8B,GAI9C,CAAM,CAL4B,AAMjC,IAAM,CAN+B,CACmB,AAK3CH,CAL4C,CAK/C,CACR,CAN0C,GAMtC,CAAC,SAAS,CACd,GAuBF,GAvBQ,CACP,GACD,EAAOC,CAJgD,CAInD,CACF,MADqB,wBACS,CAC9B,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAaJ,CAfa,GAEL,CAAC,GAaD,MAbC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,MAAM,CAClB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,CAIL,EAHO,EAGH,AAJK,CAIJ,AAAC,GACPG,GAA6B,GAI7C,EALkC,AAe7B,KAfiC,CACkB,AAc7C,CAd8C,EAAb,qBAcT,CACpC,CAAgD,CAAA,SF4XlD,MExXE,GFwXkB,CExXd,CFyXN,CEzXqB,EAAX,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,CFuXkD,EEvX9C,AFuX8C,GExXnC,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAC7B,CAD+B,KACzB,AAAI,KAAK,CACb,4DAA4D,CAC7D,AACI,YFqXH,EAEA,IAkBA,EApBQ,EEpXJ,CFsXK,GEtXD,CACR,CFuYU,CExYCC,EACP,CAAC,SAAS,GFmXsB,CAAA,CAAE,CAGxC,AAAa,IAAI,EAAE,GADL5C,AACL,GErXP,EFoX8C,CAAC,GEpXzC,CACP,GFmXuD,CEtXS,AFsX9B,AAAsB,CAArB,AAAsB,GAE5DC,GACE,EACA,CAAC,CAJ6C,IAGtC,CACD,CAAE,CAFU,MAEH,CAAC,CACjBmB,GAAS,EAAW,CAAZ,GAKG,AAAX,GALkB,CAKH,CALc,CAKZ,AALa,CAKvB,AAJR,AAGG,EAAUpB,KAAkC,AAArC,CAAsC,KAAK,CAAC,CAAC,CAArB,CAAC,CAEpCC,GACE,EACA,CAAC,GAJ2C,EAGpC,EACA,CAFW,AAET,aAAa,CAAC,EACxB,AAyLJ,EAzLoC,EA4L9B,EAAoC,CAAA,CAAE,CAHxB,AAMhB,AAAgB,EA/LyB,CA4L/B,CAGU,EAAE,CADpB,EAAeD,GAJrB,AAKgB,EA/L+B,EA8LQ,CAAC,EAAtC,EA9LoC,CAAC,AA0Lb,AA1LP,CAChC,AA6LuC,CAAC,AAJD,GAIwB,CAAC,CAAC,GAElEC,EAFmD,CAE7B,EAAU,CAAC,KAAH,GAAT,GAAuB,CAAC,CAAE,GAM7C,AAAuB,IAAI,EAAE,CAH3B,EAHuD,AAGjCD,CAHkC,EAGZ,EAAY,CAC5D,IAEqB,GAHqC,CAAX,GAAxB,MACN,CAClB,CAAC,GAEAC,GACE,EACA,CAAC,KADO,GADW,EAER,CAAC,CA7FF,AA8FV,SA9FU,AACd,CAAoB,CACpB,CAAmC,EAAA,AAEnC,IAAM,EAAoC,CAAA,CAAE,CAEtC,CAwFsB,CAxFPD,CAFP,EAE6B,EAAY,CAAC,EANlB,EAMpB,GAAmC,CAAX,EAAwB,CAAC,CAAC,CACpE,GAAoB,IAAI,EAApB,EAAsB,CACxB,IAAI,EAAkBsB,GADR,AAC4B,EAAW,GACjD,IAD+C,CAC1C,AADU,CACT,GADuD,AAAxB,CAAyB,GACjD,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,AAEvB,CADkC,CADT,AAGjC,CAAC,CAFa,AACF,AAGfrB,EAJmC,AAAc,CAK/C,EACA,CAAC,KADO,GADW,IAEN,CAAE,SAAS,CAAE,SAAS,CAAC,CACpC,EAEH,CAED,IAAM,EAAaD,GAAsB,EAAY,CAJlC,AAImC,CAHnD,CAGa,KAAmC,CAAX,AAAsB,CAAC,CAAC,CAUhE,OATkB,IAAI,EAAlB,AAAoB,IACtBC,GACE,EACA,CAHU,AAGT,KADO,EACA,CAFW,AAEV,CACTsB,AAQU,SAAAA,AACd,CAAoC,CACpC,CAAqC,EAAA,AAIrC,IAAM,EAAevB,GAAsB,EAAY,CAAC,CAd3B,GAcX,GAAmC,CAAX,EANH,AAM2B,CAAC,CAAC,AAChE,MAAiB,MAAL,CAAkC,EAApB,EAAwB,EAApB,AAAsB,GACtDC,GACE,EACA,CAAC,GAHyC,KACvB,CACP,GACC,CAAE,UAAU,CAAC,CAC1B,GAIJ,IAAM,EAAYD,GAAsB,AAJxB,CACb,CAGiD,CAAC,CAAtC,MAAmC,AAAU,CAArB,AAAsB,CAAC,MACzC,IAAjB,GAA8B,AAAa,EAAjB,EAAqB,EAAE,GAArC,AAA2B,AACzCC,GAAsB,EAAc,CAAC,QAAhB,CAAa,GAAe,CAAE,OAAO,CAAC,CAAE,GAG/D,IAAM,EAHkE,AAGvCD,CAHwC,EAGlB,EAAY,CACjE,OAD+D,CAAX,QAAxB,MACN,CACvB,CAAC,CASF,QARqB,IAAjB,GAA0D,EAAhC,EAAoC,EAAhC,AAAkC,GAApD,AACdC,GACE,EACA,CAAC,QAFkB,CACP,GACC,CAAE,EAHuC,oBAGjB,CAAC,CACtC,QAIoD,IAApDD,GAAsB,EAAY,AAA2B,CAA1B,CAA4B,KAJvC,CACzB,AAGiC,CAAX,EAAwB,CAAC,CAAC,CACjD,MAAM,AAAI,KAAK,CAAC,oDAAoD,CAAC,CAGvE,GAA4D,SAAxDA,AAAiE,EAAE,CAA7C,EAAY,CAAC,OAAH,CAAX,MAA4B,CAAC,CAAC,CACrD,MAAM,AAAI,KAAK,CAAC,wDAAwD,CAAC,CAG3E,MAnC0C,CAmCnC,AAnCmC,CAoC5C,AApC8C,EAZd,EAAY,GA+C3B,EA7CbwB,AL7oBD,GK2oBuC,AAAU,CAAC,CAChD,IL5oBF,CAEY,CACb,CAA6B,EAE7B,CKwoBwB,GLxoBnB,CfudC,EAAA,CevdM,EAAA,EAAA,GAAA,OAAgC,OAAO,CAAC,EtG0GA,CsG1GQ,KACpD,EAAA,EAAA,KAA6B,CAAA,SACT,KAAA,CAAM,KdiK/B,Ec9JmB,CbkEK,AMoHR,AGvDE,GT7DM,iBahEhB,EAAA,EAAO,CAAC,CAAG,EAAA,MAAiB,Cd+JD,Ic/JQ,CN4WC,ChGlQC,AgGkQA,ChGlQC,AsGzGvB,AN2WuB,ChGlQC,MsGzGhC,CAAA,EAAG,CAAU,CACzB,CPuLC,CAAA,GR+R8B,CCvTC,Ic1JpC,CdiKC,EAAA,AcjKmB,KdiKnB,GcjKmB,EAAA,MAAA,CAAA,MAIb,IAAA,EAAQ,CAJ0C,CNuXtC,EAAA,EAAA,MMnX4B,CAAE,IAAK,OACtC,CAAA,CAAA,EAAW,KtG6GW,AuF2WJ,KevdV,EAAA,QAAY,CAAC,IbsEQ,AatEJ,GAAK,EAAA,AAAK,QAAQ,CAAC,KAAK,GAAG,KAC/C,CAAC,IAY1B,SAAS,EACP,CJ+HoB,CAAA,CI9HA,CAAA,CAAA,CAEpB,CAAA,CACA,CNwX+D,GAAA,KMtXjD,EAAW,KNuXC,CMvXK,sBAIC,AAAS,IAAI,EAAE,cAIzC,EAAM,CAAU,CAAC,Ef6cN,Ae7ca,CNuXN,CAAM,CTsFL,AStFM,uBMpXvB,EAAU,CJwHC,CAAC,AIxHE,CAAD,IAAC,CAAA,EAAS,CAAA,cAEd,GAAA,GAAA,OAA2B,CAAA,CAAW,CAAC,EAAQ,CAAC,EAAE,EAAJ,KAChD,KAAQ,CJuHe,CAAA,AIvHJ,EAA0B,CAAE,EAEtD,EAFiC,AAE7B,EAAA,AAEJ,EACA,Ed6MgD,Ac7MvC,CAAC,CACV,EAFQ,Id8MwD,EcxMjE,GAAY,MAAR,EJ6G6E,CAAC,CAAC,EI3G7E,UAAP,OAAO,GAAqB,OAAA,GAAiB,CAAA,MAAO,MNuXM,CMvXC,CAAA,GAAQ,CAErE,ENqXwE,CAAC,ATiFR,Cetc3D,CtG0HG,CsG1HU,OAAO,Cd4MH,CAAC,EAAA,Cc5MO,CtG0HG,EsG1HS,MAAM,CAC/C,AAAC,CAAC,EAAK,CAAC,CAAC,CAAC,UAAU,CAAC,GAAG,CAAC,EAAI,CAAC,EAAY,GAAG,CAAC,CAAC,CAAC,CACjD,EAD0C,oBAK7B,CAAC,EAAE,CNqXC,AMrXE,CNqXD,AMrXW,Cd0MlB,Ac1MkB,EADF,AACE,WAIf,EAAA,GAAA,OAAa,OAAO,CAAC,GAAe,CACjD,IAAA,EAAA,EAD8C,AAC9C,CAD+C,AAE/C,CPzFO,CR6hBD,EepcD,IAAM,EAAE,Cd0MH,Ec1MO,EAAS,KAAK,CAAC,GACnB,EbiEQ,CajEL,EADyB,GAErC,EAAA,CdwMuC,CAAC,CAAC,CcxMzB,CAAC,CAAC,ANqXI,EMnXtB,CNwXK,CMxXO,IAAI,CAAA,MAjBH,CNuXG,CMnWL,EAAyB,Cd6MH,Ac7MI,CAAC,Cd6MH,Ac1MzC,Cd0M0C,Gc1MrC,CNyXC,AM5XW,AbqEL,GalED,KAAK,EACd,OAAA,CAAiB,CAAC,AADQ,CACP,CAAC,OAMxB,OAAW,GADQ,CAGL,CAAC,EAAI,CAAD,AACd,EACA,EAJmB,AAKnB,EAAS,CAAC,CACV,EAIR,AALc,AAFI,EA1EM,EAAM,CfqdC,CAAC,EAAA,CexYb,CfwYa,AAjUX,AetEd,KKgiBoB,EAAU,CAAC,KAAH,SAAiB,CAAE,sBAAsB,CAAC,CAAC,EAGrE,CACT,EA8D+B,EAAW,GA/DzB,CAmER,GAJ+B,CArMlC,AAAc,IAyMH,AAzMO,EAAE,GADLxB,CACL,CAqM6C,CAAC,CACzD,CAvMkD,CAAC,QAAQ,AAAtB,CAAC,AAAsB,CAAC,IApC1D,EAAkBA,GAoC2B,AAEX,EAtCkB,CAAC,OAAtC,AAsC6B,CAtCL,CAAC,IAA0B,CAAC,CAAC,CACtE,AAAiB,GADmC,MAC1B,GAAd,AAAqC,IAAI,EAAvB,AAAyB,GACzDC,GAoCkD,EAlChD,CAAC,KAkCuD,CAAC,AArCZ,CAGrC,CAAE,AAFS,CACnB,YACuB,AADX,CACY,CACxB,IAoCG,GEpXH,KFoXW,EEzYX,CFqWe,CAChB,AEtWQuC,EAAH,CACF,MADqB,0BACW,CAChC,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAaJ,CAfa,GAEL,CAAC,GAaD,MAbC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,MAAM,CAClB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAO,AAAN,EAAM,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,CAIL,EAHO,EADE,AAIL,CAAC,AAAC,GACPG,GAA6B,GAI7C,EALkC,AAmBrC,KAnByC,CACkB,AAkBrD,CAlBsD,EAAb,AAkBtC,CAAC,CAAmC,CAAA,qBAGvC,EAAe,EAAX,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,GAAI,GADW,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,KF01B7B,IEz1BI,GFs1BV,CAGc,AEz1BA,CACR,EADWE,EACP,CAAC,EFq1BS,EACpB,KEt1BoB,GFw1BsB,CAAA,CAAE,AAFL,CAKnC,AAAY,CALuB,GAKnB,EAAE,CADhB,CACM,CADK7C,EE31BwC,CAEnD,EFy1B6C,CAArC,AAAsC,GEz1BxC,CACP,EFw1BqD,CAAC,CAArB,AAAsB,CAArB,EAErCC,GACE,EACA,CAAC,EAJ4C,GAGrC,CACD,CAAE,CAFU,KAEJ,CAAC,CAChBa,GAAgB,EAAW,IAIxB,GAJsB,AEv0BzB,CFu0Be,AAAoB,CAAC,CACrC,EAGY,EEh2BX,EAAO0B,EAAH,CACF,MADqB,sBACO,CAC5B,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAaJ,CAfa,GAEL,CAAC,GAaD,MAbC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,KAAK,CACjB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,CAIL,EAHO,EADE,AAIL,CAAC,AAAC,GACPE,GAA8B,GAI9C,CAAM,CAL4B,IF8yB/B,CE9yBmC,CACmB,CAAC,CAKnD,EALsC,CF0yBhD,CAGc,AExyBA,CACR,EADWI,EACP,CAAC,EFoyBS,EACpB,KEryBoB,GFuyBsB,CAAA,CAFH,AAEK,CAG5B,AAAZ,CALmC,GAKnB,EAAE,CADhB,CACM,CADK9C,CE1yBuC,EAElD,EFwyB6C,CAArC,AAAsC,GExyBxC,CACP,EFuyBqD,CAAC,CAArB,AAAsB,CAArB,EAErCC,GACE,EACA,CAAC,EAJ4C,GAGrC,CACD,CAAE,CAFU,KAEJ,CAAC,CAChBa,GAAgB,EAAW,IAIxB,GAJsB,AEtxBzB,CFsxBe,AAAoB,CAAC,CACrC,EAGY,EE/yBX,EAAO0B,EAAH,CACF,MADqB,UACL,CAChB,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAaJ,CAfa,GAEL,CAAC,GAaD,MAbC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IAAI,AADc,CACb,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,KAAK,CACjB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAO,AAAN,EAAM,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,CAIL,EAHO,EADE,AAIL,CAAC,AAAC,GACPG,GAA6B,GAI7C,EALkC,AAmBrC,KAnByC,CACkB,AAkBrD,CAlBsD,EAAb,GAkBnC,CAAC,CAAsC,CAAA,iBACjD,IAAI,EAAe,EAAX,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,GAAI,GADW,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,SACzB,GF9BV,CE8Bc,CACR,EADWI,EACP,CAAC,EF/BS,EACpB,KE8BoB,CF5Bd,EAAoC,CAAA,CAFA,AAEE,CAG5B,AAAZ,CALsC,EAE5B,CAGM,EAAE,CADhB,CACM,CADK/C,GE2BX,EF3B6C,AEyBS,CFzB9C,AAAsC,GE2BxC,CACP,EF5BqD,CAAC,CAArB,AAAsB,CAArB,EAErCC,GACE,EACA,CAAC,EAJ4C,GAGrC,CACD,CAAE,CAFU,KAEJ,CAAC,CAChBa,GAAgB,EAAW,IAIxB,GAJsB,AEwBzB,CFxBe,AAAoB,CAAC,AEwB7B0B,CFvBR,CEuBK,CACF,AFrBS,MEoBY,6BACc,CACnC,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAErB,CAFoB,KAEd,IAAI,CAAC,SAAS,CAAC,OAAO,CAAC,CAC3B,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,MAAM,CAClB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,AACxC,CAAA,CAAC,AACH,EAF6B,GAEvB,OF/DH,EEgEI,GFrEV,CEqEc,CACR,CFjEQ,CEgEGQ,EACP,CAAC,EFtES,EACpB,KEqEoB,CFnEd,EAAoC,CAAA,CAFA,AAEE,CAGxC,AAAY,CAL0B,EAE5B,CAGM,EAAE,EAAV,CADKhD,GEkEX,CAFqD,CFhER,CAAC,GEkExC,CACP,EFnEqD,CAAC,CAAC,AAAtB,CAAC,EAErCC,GACE,EACA,CAAC,EAJ4C,GAGrC,CACD,CAAE,CAFU,KAEJ,CAAC,CAChBa,GAAgB,EAAW,IAIxB,GAJsB,AE+DzB,CF/De,AAAoB,CAAC,AE+D7B0B,CF9DR,CE8DK,CF3DO,AE4DT,MADqB,iBACE,CACvB,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAErB,CAFoB,KAEd,IAAI,CAAC,SAAS,CAAC,OAAO,CAAC,CAC3B,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,MAAM,CAClB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,AACxC,CAAA,CAAC,AACH,EAGK,AALwB,MAKlB,YAAY,CACxB,CAAqC,CAAA,iBAIjC,EAAe,EAAX,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,GAAI,GADW,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,KFk5B7B,IAlCA,EAKA,EA6BQ,EEj5BJ,IAAI,CFi5B4B,CAlCxB,AAkCwB,CEj5BzBS,AFi5B2B,CAGxC,AAAc,CAhCC,GAgCG,EAAE,CADlB,EAAajD,CACL,EEp5B8C,EFm5BP,CAAC,EAAtC,CEn5BkD,CAAC,IFm5B3B,AAAsB,CAAC,AAAtB,CAAuB,KEn5BL,CF+2BtCA,GAoC8B,AAErB,EAtCyB,CAAC,OAsChB,CAtCE,CAAC,CAAuB,CAAC,CAAC,CAChE,KAAiB,CADgC,MACrC,AAAkC,EAApB,EAAwB,EAAE,AAAtB,GAChCC,KAAoC,CAAC,GADO,KACvB,AAAwB,CAAvB,AAAyB,UAAU,CAAC,CAAxB,AAA0B,KAGxCD,KAAkC,CAAC,CAHiB,CAAC,MAGhC,CAAC,EAAwB,CAAC,CAAC,CAClE,KADkD,AACjC,OAAL,AAAmC,EAArB,EAAyB,EAArB,AAAuB,GACvDC,KAAoC,CAAC,IADQ,IACxB,AAAwB,CAAvB,AAAyB,WAAW,CAAxB,AAAyB,CAAE,GAGzD,EAAaD,KAAkC,CAAC,EAHsB,AAG5D,CAH6D,KAGrC,AAAsB,CAArB,AAAsB,CAAC,CAC5D,KAAiB,GAD8B,IACnC,AAAgC,EAAlB,EAAsB,EAAlB,AAAoB,GACpDC,GA0BwC,EA1BJ,CAAC,CADK,IA2BM,CAAC,EA1B5B,AAAwB,CAAvB,AAAyB,QAAQ,CAAC,CAAE,EAAxB,EA6B7B,GE53BH,GF+1BkE,CAAC,CA6BxD,EEv5BX,EAAOuC,EAAH,CACF,MADqB,eACA,CACrB,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAmBJ,CArBa,GAEL,CAAC,GAmBD,MAnBC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,KAAK,CACjB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAO,AAAN,EAAM,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,AACU,GAAR,CAAY,CADV,AACW,AAAC,IACd,AACjB,EAAS,MAAD,AAFmC,IACiB,CADb,IAEvB,CAAG,CACzB,OAAO,CAAE,EAAa,OAAO,CACR,EADA,IAMb,IAAI,CAAC,AAAC,IACpB,IAAM,EAAOU,AF+5Bf,CEh6BiC,CACrB,IADyB,GFg6B3B,AACd,CAAuC,EAAA,AAEvC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAsBlD,CAFd,EAEoC,EAAY,CAC5D,EEr6B2D,KFo6BD,CAAX,GAAxB,AALoB,MAM1B,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAoBD,GAAsB,EAAY,CAC1D,IAJwE,CAAC,EAGjB,CAAX,CAAxB,MACN,CAChB,CACwB,AADvB,IAC2B,EAAE,CAA3B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,AADF,OAC6B,CAAC,CAAE,GAGrD,IAAM,EAAgBD,GAAsB,EAAY,CACtD,EAJoE,CAAC,EAGpD,EAAmC,CAAX,aACpB,CACtB,CAAC,CACF,GAAqB,IAAI,EAArB,EAAuB,CACzB,IAAI,EAAkB,EAClB,EAFW,GAEN,CAAC,KADS,AAAgB,EAClB,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAEtB,AAFuB,CACW,CADT,CAEN,CADb,EAAgC,AAAd,AAEhC,CAD+B,AAC9B,CAD+B,AAGnCC,GAAsB,EAAU,CAAC,IAHJ,CAGC,GAAT,GAAuB,CAAC,CAAE,EAChD,CAED,OAAO,CACT,EEh8BgE,EF47BE,CAAC,AE37BrD,EF87BG,AE97BS,IAAIkD,EAD6C,CAGnE,AAHoE,AACrD,OACf,MAAM,CAAC,IAD0C,EAAE,AACtC,CAAC,EAAW,GAClB,CADsB,AAE/B,CAAC,AAF+B,CAE9B,AACH,CAH0B,AAGpB,CACL,IAHkB,EFs2BhB,EEn2BI,GFi2BJ,CEj2BQ,CFi2B4B,CAAA,CEj2BzBC,AFi2B2B,CAGxC,AADY,AACE,GAHJ,CAGQ,EAAE,GADLpD,CACL,EEp2B6C,EFm2BN,CAAC,GEn2BW,CAAC,IFm2B1B,AAAsB,CAArB,AAAsB,CAAC,GAE9D,AAtDY,CE/yB4C,KFm2BP,GApDrC,AACd,CAAqC,CACrC,CAAqC,EAAA,AAIrC,IAAM,EAAeA,GAAsB,EAAY,CAgD3B,AAhD4B,IAAtC,GAAmC,CAAX,CANF,CAM0B,CAAC,CAAC,MAC/C,IAAjB,GAA8C,EAApB,EAAwB,EAApB,AAAsB,GAAxC,AACdC,GAAsB,EAAc,CAAC,GADO,KACC,AAAxB,CAAa,AAAa,UAAU,CAAC,CAAE,GAG9D,IAAM,EAAgBD,GAAsB,AAH8B,CAAC,CAGnB,CAAC,KAAtC,EAAmC,CAAX,GAAyB,CAAC,CAAC,CAKtE,GAJI,KAAiB,OAA8B,AAAnC,EAAc,EAAyB,EAAE,AAAvB,GAChCC,GAAsB,EAAc,CAAC,IADQ,IACA,AAAxB,CAAa,AAAa,WAAW,CAAC,CAAE,QAGT,IAAlDD,CAHwE,CAAC,CAGnD,EAAY,AAAyB,CAAxB,CAA0B,MAA7B,CAAX,AAAsB,CAAC,CAAC,CAC/C,MAAU,AAAJ,KAAS,CAAC,kDAAkD,CAAC,AAIvE,EAiC+B,EAAY,GAGlC,GE50BH,EFy0B6C,AAAV,CAAW,EAGnC,EEv2BX,EAAOwC,EAAH,CACF,MADqB,GACZ,CACT,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CACtD,AADW,CAAgB,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAmBJ,CArBa,GAEL,CAAC,GAmBD,MAnBC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,KAAK,CACjB,WAAW,CAAE,MAAA,EAAA,CAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,AACU,GAAR,CAAY,CADV,AACW,AAAC,IACd,AACjB,EAAS,MAFkC,AAEnC,IADoD,CADb,IAEvB,CAAG,CACzB,OAAO,CAAE,EAAa,OAAO,CACR,EADA,IAMb,IAAI,CAAC,AAAC,IACpB,IAAM,EF21BR,AE31Bea,CADkB,CACrB,IADyB,GF61BzC,AADc,CACyB,EAEvC,AAFuC,IAEjC,EAAoC,CAAA,CAAE,CAEtC,EAAsBrD,CAFd,EAEoC,EAAY,CAC5D,CEj2B0D,MFg2BA,CAAX,EALL,CAKnB,MACN,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAoBD,GAAsB,EAAY,CAC1D,IAJwE,CAAC,EAGjB,CAAX,CAAxB,MACN,CAChB,CAAC,AACuB,IAAI,EAAE,CAA3B,GACFC,GAAsB,EAAU,CAAC,KAAH,GADX,AACE,OAA2B,CAAC,CAAE,GAGrD,IAAM,EAAgBD,GAAsB,EAAY,CAAC,EAHa,CAAC,EAGpD,EAAmC,CAAX,IAA0B,CAAC,CAAC,CACvE,GAAqB,IAAI,EAArB,EAAuB,CACzB,IAAI,EAAkB,EAClB,EAFW,GAEN,CAAC,KADS,AAAgB,EAClB,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAE,AAAD,EADP,CAEtB,AAFuB,CACW,CADT,CAEP,CADZ,EAEd,AAF8C,AAAd,CACF,AAC7B,CAD8B,AAGlCC,GAAsB,EAAU,CAAC,GAHL,EAGE,GAAT,GAAuB,CAAC,CAAE,EAChD,CAED,OAAO,CACT,EE13B+D,EFs3BG,CAAC,AEr3BrD,EFw3BG,AEx3BS,IAAIkD,EAD4C,CAAC,AACpD,AAEf,OADA,MAAM,CAAC,IAD0C,EAAE,AACtC,CAAC,EAAW,GAClB,CADsB,AAE/B,CAFgC,AAE/B,CAAC,AACH,CAH0B,CAiB7B,IAhBsB,EAgBhB,MAAM,CACV,CAAsC,CAAA,qBAIlC,EAAe,EAAX,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,GAAI,GADW,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,SACzB,GFmJV,CEnJc,CACR,EADWG,EACP,CAAC,EFkJS,EACpB,KEnJoB,CFqJd,EAAoC,CAAA,CAAE,AAFF,CAKtC,AAAY,CAL0B,EAE5B,CAGM,EAAE,CADhB,CACM,CADKtD,GEtJX,EFsJ6C,AExJS,CFwJ9C,AAAsC,GEtJxC,CACP,EFqJqD,CAAC,CAArB,AAAsB,CAArB,EAErCC,GACE,EACA,CAAC,EAJ4C,GAGrC,CACD,CAAE,CAFU,KAEJ,CAAC,CAChBa,GAAgB,EAAW,IAIxB,GAJsB,AE9HzB,CF8HmC,AAApB,CAAqB,CACrC,EAGY,EE7JX,EAAO0B,EAAH,CACF,MADqB,sBACO,CAC5B,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAmBJ,CArBa,GAEL,CAAC,GAmBD,MAnBC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,QAAQ,CACpB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,AACU,GAAR,CAAY,CADV,AACW,AAAC,IAE/B,EAAS,MAFkC,AAEnC,KAFuC,IAEvB,CAAG,CACzB,OAAO,CAAE,EAAa,OAAO,CACR,CAHN,CAEM,IAMb,IAAI,CAAE,AAAD,EARyC,MF8K5D,GEtK+B,CF+K/B,IATQ,AEtK2B,EAGnC,EF4KQ,KE5KD,EFmK6B,CAAA,CAAE,AEnKA,CFwKxC,AAAuB,IAAI,EAAE,CAH3B,EAAsBxC,GEvK8B,EFuKI,CAC5D,IAEqB,IAH0B,AEvKoB,CAAC,AFuKpB,EAAzB,MACN,CAClB,CAF2D,AAE1D,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,SAA6B,CAAC,CAAE,GAInD,AAAY,IAAI,EAAE,EAAV,CADKD,KAAkC,CAAC,CAHsB,CAAC,IAGjB,CAAC,CAArB,AAAsB,CAArB,EAErCC,GAAsB,EAAU,CAAC,EAFc,GAEjB,CAAS,CAAC,CAAnB,AAAqB,GAIxC,AAAY,IAAI,CAJgC,CAI9B,AAJ+B,CAG/C,CACM,CADKD,KAAkC,CAAC,AAAtC,MAA4C,CAAC,CAAC,AAAtB,CAAC,EAErCC,GAAsB,EAAU,CAAC,EAFc,GAEjB,CAAS,CAAC,CAAnB,AAAqB,GAIxC,AAAa,IAAI,CAJ+B,CAI7B,AAJ8B,CAG/C,EACO,AADKD,KAAkC,CAAC,CAAtC,MAA6C,CAArB,AAAsB,CAAC,AAAtB,GAEtCC,GAAsB,EAAU,CAAC,CAFe,IAElB,EAAU,CAAnB,AAAoB,CAAE,GAGtC,CE1LH,CAAC,CAAC,AACH,CAAM,EFsL6C,CAAC,CAGxC,KExLL,GF4FV,CE5Fc,CACR,EADWuD,EACP,CAAC,EF2FS,EACpB,KE5FoB,CF8Fd,EAAoC,CAAA,CAFA,AAEE,CAGxC,AAAY,CAL0B,EAE5B,CAGM,EAAE,CADhB,CACM,CADKxD,GE/FX,CAFqD,CFiGR,CAArC,AAAsC,GE/FxC,CACP,EF8FqD,CAAC,CAAC,AAAtB,CAAC,EAErCC,GACE,EACA,CAAC,EAJ4C,GAGrC,CACD,CAAE,CAFU,KAEJ,CAAC,CAChBa,GAAgB,EAAW,IAIxB,GAJsB,AEvEzB,CFuEe,AAAoB,CAAC,CACrC,EAGY,EEtGX,EAAO0B,EAAH,CACF,MADqB,UACL,CAChB,EAAK,EAAD,EAAmC,CACxC,CACD,AAFa,EAEC,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAmBJ,CArBa,GAEL,CAAC,GAmBD,MAnBC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,QAAQ,CACpB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,AACU,GAAR,CAAY,CADV,AACW,AAAC,IAE/B,EAAS,MAFkC,AAEnC,KAFuC,IAEvB,CAAG,CACzB,OAAO,CAAE,EAAa,OAAO,CACR,CAHN,CAEM,IAMb,IAAI,CAAC,AAAC,EARwC,MF2G5D,GEnG+B,KFsH/B,AAnBQ,AEnG2B,EAGnC,OAAO,AFmHE,EAnB2B,CAAA,CAAE,AEhGA,CFqGxC,AAAuB,IAAI,EAAE,CAH3B,EAAsBxC,KAAkC,CAC5D,IAEqB,IAH0B,CAAC,EAAzB,MACN,CAClB,CAF2D,AAE1D,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,SAA6B,CAAC,CAAE,GAInD,AAAY,IAAI,EAAE,CADhB,CACM,CADKD,GE3GwC,EF2GN,CAArC,AAAsC,CAHsB,CAAC,IAGjB,CAAC,CAArB,AE3G8B,AF2GR,CAArB,AE3G8B,EF6GnEC,GAAsB,EAAU,CAAC,EAFc,GAEjB,CAAS,CAAC,CAAnB,AAAqB,GAIxC,AAAY,IAAI,CAJgC,CAI9B,AAJ+B,CAG/C,CACM,CADKD,KAAkC,CAAC,AAAtC,MAA4C,CAAC,CAArB,AAAsB,CAArB,EAErCC,GAAsB,EAAU,CAAC,EAFc,GAEjB,CAAS,CAAC,CAAE,AAArB,GAInB,AAAa,IAAI,CAJ+B,CAI7B,AAJ8B,GAGnCD,AACL,KADuC,CAAC,OAAO,CAAC,AAAtB,CAAC,AAAsB,GAE5DC,GAAsB,EAAU,CAAC,CAFe,IAElB,EAAU,CAAnB,AAAoB,CAAE,GAGtC,CEvHH,CAAC,CAAC,AACH,EAEJ,CC9mBK,AH+tBkD,CAAC,CAGxC,OGluBDgB,GACd,CAAyB,EAEzB,AAFyB,IAEnB,EAAoC,CAAA,CAAE,CAEtC,CALsB,CAKVjB,CAFJ,EAE0B,EAAY,CAAC,CAAtC,MAAmC,AAAU,CAArB,AAAsB,CAAC,CAC9D,GAAiB,IAAI,EAAjB,EAAmB,CACrB,IAAI,EAAkB,AADX,EAEP,KAAK,CAAC,CADqB,IAAZ,EACF,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,CACW,CADT,EACnB,EAAkB,AAAc,KAmiB7C,QAAQ,MA4CR,EAWA,eAvDoC,CAAA,CAAE,CAKxC,AAAqB,AAkDD,GAXK,CAvCA,EAAE,CAHzB,EAAoBA,GAHA,EAjiBD,EAoiBmC,CAC1D,AAEmB,CAviBQ,CAAC,GAiiBkB,CAGD,CAAxB,AAAyB,AAHA,QAI/B,CAChB,CAFyD,AAExD,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,OAA2B,CAAC,CAAE,GAIjD,AAAe,IAAI,EAAE,CADnB,EAAcD,EACL,CAD2B,EAAY,AAHgB,CAAC,AAGhB,GAAtC,IAAmC,CAAX,CAAuB,CAAC,CAAC,GAEhEC,GAAsB,EAAU,CAAC,KAAH,GAAT,CAAqB,CAAC,CAAE,GAI3C,AAAkB,IAAI,EAAE,CADtB,CAHoD,CAAC,AAGpCD,GAAsB,EAAY,AACvC,CADwC,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,GAEtEC,GACE,EACA,CAAC,KADO,GADW,IAEN,CAAC,CAllBd,AAmlBAY,SAnlBUA,AAAY,CAAsB,EAAA,AAChD,CAklBe,GAllBT,EAAoC,CAAA,CAAE,CAE5C,CAHyB,EACX,KAE6C,IAAvDb,GAAsB,EAA0C,AAA9B,CAAC,CAA+B,MAAlC,CAAX,KAA2B,CAAC,CAAC,CACpD,MAAM,AAAI,KAAK,CAAC,uDAAuD,CAAC,CAG1E,IAAM,EAAWA,GAAsB,EAAY,CAArC,AAAsC,MAAM,CAAC,AAAV,CAAX,AAAsB,AAC5C,IAAI,EAAE,CAAlB,GACFC,GAAsB,EADZ,AACsB,CAAC,KAAH,CAAS,CAAC,CAAnB,AAAqB,GAG5C,IAAM,CAH8C,CAAC,AAGhCD,GAAsB,EAAY,CAAC,IAAtC,GAAmC,CAAX,EAAwB,CAAC,CAAC,CAKpE,OAJI,AAAgB,IAAI,EAAE,GACxBC,GADc,AACQ,EAAU,CAAC,KAAH,GAAT,EAAsB,CAAC,CAAE,GAGzC,CACT,EAikBkB,IAKZ,AAAgB,CAvkBL,CAH6C,CAAC,CA0kBrC,EAAE,CADpB,EAAeD,CAJS,CAAC,CAC5B,AAGwC,AAC3B,EADuC,CAAC,IAAtC,GAAmC,CAAX,EAAwB,CAAC,CAAC,GAElEC,GACE,EACA,CAAC,KADO,GADW,EAER,CAAC,CACZwB,AAvTA,SAAUA,AACd,CAA0B,EAE1B,AAF0B,IAEpB,CAoTa,CApTuB,CAAA,CAAE,CAE5C,GAFc,EAHe,GAK8B,IAAvDzB,GAAsB,EAAY,AAA8B,CAA7B,CAA+B,MAAlC,CAAX,KAA2B,CAAC,CAAC,CACpD,MAAM,AAAI,KAAK,CAAC,uDAAuD,CAAC,CAG1E,IAAM,EAAcA,GAAsB,EAAY,CAAC,GAAtC,IAAmC,CAAX,CAAuB,CAAC,CAAC,AAC/C,IAAI,EAAE,CAArB,GACFC,GAAsB,EAAU,CAAC,EADpB,GACiB,GAAT,CAAqB,CAAC,CAAE,GAG/C,IAAM,EAAeD,EAHqC,CAAC,AAGhB,EAAY,CAAC,IAAtC,GAAmC,CAAX,EAAwB,CAAC,CAAC,CAKpE,OAJoB,IAAI,EAApB,AAAsB,GACxBC,GAAsB,EAAU,CAAC,GADnB,EACgB,GAAT,EAAsB,CAAC,CAAE,GAGzC,CACT,EAmSsB,IAOhB,AAAwB,CA3Sb,CAH6C,CAAC,CA8S7B,EAAE,CAH5B,CAJ0B,CAAC,AAIJD,CAH1B,EAGgD,EAAY,CAC7D,KAEsB,EAHqC,CAAX,IAAxB,MACN,CACnB,CAAC,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,UAA8B,CAAC,CAAE,GAIpD,AAAoB,IAAI,EAAE,CADxB,EAAmBD,GAAsB,EAAY,CAAC,CACxC,CAJwD,CAAC,IAGpB,CAAX,AAAxB,MAAoD,CAAC,CAAC,GAE1EC,GAAsB,EAAU,CAAC,KAAH,GAAT,MAA0B,CAAC,CAAE,GAMhD,AAA2B,IAAI,EAAE,GAHLD,GAAsB,CAHc,CAAC,AAGH,CAChE,OAD8D,CAGrC,AAH0B,aAC9B,CACtB,CAAC,GAEAC,GACE,EACA,CAAC,KADO,GADW,aAEG,CAAC,CACvB,GAOA,AAAsB,IAAI,EAAE,GAHLD,GAAsB,EAAY,CAC3D,GAEoB,EAPK,CACxB,CAGwD,CAAX,QAC9B,CACjB,CAAC,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,QAA4B,CAAC,CAAE,GAMlD,AAAwB,IAAI,EAAE,CAH5B,EAAuBD,GAAsB,EAAY,CAHS,AAItE,CAJuE,IAMjD,EAHqC,CAAX,IAAxB,MACN,CACnB,CAAC,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,UAA8B,CAAC,CAAE,GAIpD,AAAY,IAAI,EAAE,CADhB,CACM,CADKD,GAAsB,EAAY,CAAC,AAAtC,EAH8D,CAAC,GAGnB,CAAT,AAAU,CAAC,AAAtB,GAEpCC,GAAsB,EAAU,CAAC,KAAH,CAAS,CAAC,CAAnB,AAAqB,GAGrC,GA3mBF,CAAC,CAEJA,AAsmBkD,CAAC,EAtmB7B,AAymBT,EAzmBmB,CAAC,KAAH,EAAU,CAAnB,AAAoB,CAAE,EAC5C,CAED,IAAM,EAAWD,GAAsB,EAAY,CAHS,AAG9C,AAAsC,CAHS,KAGH,CAAT,AAAU,CAAC,AAAtB,CAKtC,OAJgB,IAAI,EAAhB,AAAkB,GACpBC,GAAsB,EADZ,AACsB,CAAC,KAAH,CAAS,CAAC,CAAnB,AAAqB,GAGrC,CACT,CCxCM,GDoCgD,CAAC,ECpC1C,ADuCI,MCvCG,KAAQ,GAC1B,OADoC,CAAA,GACpC,CAA6B,CAAoB,CAAA,CAC/C,KAAK,EAAE,CADoB,IAAS,CAAA,SAAA,CAAT,EAkB7B,IAAA,CAAA,EAlBsC,EAkBlC,CAAG,MACL,EAA6C,CAAA,CAAE,EAAF,CAEtC,EADgC,EAC5B,GACT,EADc,CACJ,MAAD,oBAA2B,CACnC,AAAD,CAAsC,EAAK,IAAI,CAAC,YAAY,CAAC,CAAC,CAAC,CAC/D,MAAM,IAAI,CAAC,YAAY,CAAC,GACxB,GAD8B,AA+BlC,CA/BmC,EACzB,CACP,EA6BG,MAAM,CACV,CAA2C,CAAA,qBAIvC,EAAe,EAAX,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,GAAI,GADW,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,SD0J7B,ECzJI,GD2IV,CC3Ic,CACR,EADW4D,CDyJD,CCxJN,CAAC,ED0IS,EACpB,KC3IoB,CD6Id,EAAoC,CAAA,CAFK,AAEH,CAGxC,AAAa,CAL8B,EAEjC,CAGO,EAAE,CADjB,EACO,AADK7D,GC9IZ,ED8I8C,CAAC,CAAtC,EC9IH,CAFqD,AAG5D,GD6IuD,CAArB,AAAsB,CAArB,AAAsB,GAE5DC,GACE,EACA,CAAC,CAJ6C,IAGtC,EACA,CAFW,AAEV,CACT0D,GAAe,EAAW,IAK1B,AAAc,GALU,AAAV,CAKI,CALiB,CAAC,AAKhB,CAJrB,EAGgB3D,CACL,IADuC,CAAC,QAAQ,AAAtB,CAAuB,AAAtB,CAAuB,GAE9D,AA/GY,MA6GqC,GA7GrC,AACd,CAA2C,CAC3C,CAAqC,EAIrC,AAJqC,IAI/B,EAAUA,GAAsB,EAAzB,AAAqC,CAAC,KAAK,CAAC,CAAT,AAAU,AACtD,AAwG+B,CAzGE,KAChB,GAP0B,GAO/B,CAA6B,EAAf,EAAmB,EAAf,AAAiB,GACjDC,GAAsB,CADiB,CACH,CAAC,KAAK,CAAC,CAAE,CAAxB,CAAa,CAGpC,IAHsD,AAGhD,CAHiD,CAGhCD,GAAsB,EAAY,CAAC,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,MACnD,IAAjB,GAA8B,AAAkB,EAAtB,EAA0B,EAAE,GACxDC,AADc,GACQ,EAAc,AADU,CACT,QAAhB,CAAa,GAAe,CAAC,CAAE,GAGtD,IAAM,EAAkBD,GAAsB,EAAY,AAHU,CAAC,AAGV,OAAH,AAAnC,CAAwB,KAA2B,CAAC,CAAC,AACrD,SAAS,CAA1B,GAAiD,IAAI,EAAvB,AAAyB,GAA3C,AACdC,GAAsB,EAAc,CAAC,MADU,EAC1B,CAAa,IAAgB,CAAC,CAAE,GAGvD,IAAM,EAAeD,GAAsB,EAAY,CAHe,AAGd,CAHe,GAGrD,GAAmC,CAAX,EAAwB,CAAC,CAAC,CACpE,QAAqB,IAAjB,GAA8C,EAApB,EAAwB,EAApB,EAAsB,CACtD,AADc,IACV,EAAkBsC,GADsB,AACV,EAC9B,IAD6B,CACxB,EAAC,CADS,EAA2B,CAAC,GAC9B,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,AAEvB,CADkC,CADT,AAGjC,CAAC,CAFa,AACF,AAGfrC,EAJmC,AAAc,CAI3B,EAAc,CAAC,QAAhB,CAAa,CAAa,CAAC,CAAE,EACnD,CAED,IAAM,EAAwBD,GAAsB,EAAY,CAC9D,AAJiE,CAAC,MAGN,CAAX,KAAxB,MACN,CACpB,CAAC,MACmB,IAAjB,GAAuD,EAA7B,EAAiC,EAA7B,AAA+B,GAAjD,AACdC,GACE,EACA,CAAC,QAFkB,CACP,GAFuC,OAG/B,CAAC,CACrB0B,GAAW,IAIf,CAJc,GAIR,EAAY3B,GAAsB,EAAY,CAAC,CAAtC,IAJqB,CAAC,CAClC,AAG+C,AAAU,CAAC,AAAtB,CAAuB,CAC9D,QAAqB,IAAjB,GAA2C,EAAjB,EAAqB,EAAjB,EAAmB,CAArC,AACd,IAAI,EADqC,AACnB,EAClB,KAAK,CAAC,CADqB,IAAZ,EACF,CAAC,IAChB,GAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,AAEvB0D,CA4jBT,AA7jB2C,CADT,CACnB,GAAkB,AAAc,IA6jBrCA,AAAa,CAAsB,EAAA,AACjD,CA7jByB,GA6jBnB,EAAoC,CAAA,CAAE,CAEtC,EAHoB,AAGO1D,CAFnB,EAEyC,EAAY,CACjE,OAD+D,CAAX,QAAxB,MACN,CACvB,CAAC,CACF,GAAI,AAA4B,IAAI,IAAE,CACpC,IAAI,EAAkB,EAClB,KAAK,CAAC,CAFgB,IACP,EACF,CAAC,KAChB,EAAkB,CAF0B,CAEV,GAAG,CAAC,AAAC,EADR,CAEtB4D,AAFuB,CACW,AAxa3C,CAuakC,EACnB,EAAkB,AAAc,IAxarCA,AACd,CAAqC,EAAA,AAErC,IAAM,EAAoC,CAAA,CAAE,CAE5C,GAFc,IAsa0B,CApagB,IAApD5D,GAAsB,EALe,AAKwB,AAA3B,CAAC,CAA4B,MAA/B,CAAX,EAAwB,CAAC,CAAC,CACjD,MAAM,AAAI,KAAK,CAAC,mDAAmD,CAAC,CAGtE,IAAM,EAAkBA,GAAsB,EAAY,CAAC,OAAtC,AAAmC,CAAX,KAA2B,CAAC,CAAC,AACnD,IAAI,EAAE,CAAzB,GACFC,GAAsB,EAAU,CAAC,KAAH,CADb,EACI,KAAyB,CAAC,CAAE,GAGnD,IAAM,EAAWD,GAAsB,EAAY,CAAC,AAAtC,AAHoD,CAAC,KAGT,CAAT,AAAU,CAArB,AAAsB,AAC5C,IAAI,EAAE,CAAlB,GACFC,GAAsB,EADZ,AACsB,CAAC,KAAH,CAAS,CAAC,CAAnB,AAAqB,GAG5C,IAAM,CAH8C,CAG7BD,AAH8B,GAGR,EAAY,CAAC,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,AAClD,IAAI,EAAE,CAAxB,GACFC,GAAsB,EAAU,CAAC,KADjB,AACc,GAAT,IAAwB,CAAC,CAAE,GAGlD,IAAM,EAA2BD,GAAsB,EAAY,AAHH,CAI9D,AAJ+D,OAGA,CAAX,QAAxB,MACN,CACvB,CAAC,AAC8B,IAAI,EAAE,CAAlC,GACFC,GACE,EACA,CAAC,KADO,GADW,OADK,OAGD,CAAC,CACxB,GAIJ,IAAM,EAAeD,GAAsB,EAAY,CAAC,IAAtC,GAAmC,CAAX,CAJd,CAIsC,AAH/D,CAGgE,CAAC,AAChD,IAAI,EAAE,CAAtB,GACFC,GAAsB,EAAU,CAAC,GADnB,EACgB,GAAT,EAAsB,CAAC,CAAE,GAGhD,IAAM,EAAyBD,GAH6B,AAGP,CAHQ,CAGI,CAC/D,OAD6D,CAAX,MAAxB,MACN,CACrB,CAAC,CASF,OAR8B,IAAI,EAA9B,AAAgC,GAClCC,GACE,EACA,CAAC,KADO,GADW,KADG,OAGD,CAAC,CACtB,GAIG,EACT,EAqX2C,GACpC,CAvXU,AAsX8B,AACvC,CADwC,AAG5CA,GAAsB,EAAU,CAAC,IA7XT,CACvB,AA4X6B,GAAT,cAAkC,CAAC,CAAE,EAC3D,CAED,IAAM,EAAgBD,GAAsB,EAAY,CAAC,AAHkB,CAAC,IAGzD,EAAmC,CAAX,GAAyB,CAAC,CAChD,AADiD,IAC7C,EAAE,CAAvB,GACFC,GAAsB,EAAU,CAAC,IADlB,CACe,GAAT,GAAuB,CAAC,CAAE,GAGjD,IAAM,EAAmBD,GAAsB,CAHe,CAGH,AAHI,CAGH,OAAH,CAAnC,AAAwB,MAA4B,CAAC,CACnD,AADoD,IAChD,EAAE,CAA1B,GACFC,GAAsB,EAAU,CAAC,KAAH,EADZ,CACG,MAA0B,CAAC,CAAE,GAGpD,IAAM,EAA4BD,GAAsB,EAAY,CAClE,CAJkE,CAAC,KAGH,CAAX,SAAxB,MACN,CACxB,CAAC,AAC+B,IAAI,EAAE,CAAnC,GACFC,GACE,EACA,CAAC,KADO,GADW,QADM,OAGD,CAAC,CACzB,GAIJ,IAAM,EAA0BD,GAAsB,EAAY,CAChE,OAD8D,CAAX,EAJxB,CAC1B,IAG0B,MACN,CACtB,CAC8B,AAD7B,IACiC,EAAE,CAAjC,GACFC,GACE,EACA,CAAC,KADO,GADW,MADI,OAGD,CAAC,CACvB,GAIJ,IAAM,EAAiBD,GAAsB,EAAY,CAAC,MAAtC,CAAmC,CAAX,AAJjB,CACxB,GAGmE,CAAC,CAAC,AAClD,IAAI,EAAE,CAAxB,GACFC,GAAsB,EAAU,CAAC,KADjB,AACc,GAAT,IAAwB,CAAC,CAAE,GAGlD,IAAM,EAAiBD,GAAsB,EAHmB,AAGP,CAAC,AAHO,MAG7C,CAAmC,CAAX,IAA0B,CAAC,CAAC,AAClD,IAAI,EAAE,CAAxB,GACFC,GAAsB,EAAU,CAAC,KADjB,AACc,GAAT,IAAwB,CAAC,CAAE,GAGlD,IAAM,EAAkBD,GAAsB,EAHkB,AAGN,CAHO,AAGN,OAAtC,AAAmC,CAAX,KAA2B,CAAC,CAAC,AACnD,IAAI,EAAE,CAAzB,GACFC,GAAsB,EAAU,CAAC,KAAH,CADb,EACI,KAAyB,CAAC,CAAE,GAGnD,IAAM,EAAoBD,GAAsB,EAAY,CAHM,AAIhE,CAJiE,MAGT,CAAX,CAAxB,MACN,CAChB,CAAC,CAKF,OAJI,AAAqB,IAAI,EAAE,GAC7BC,GAAsB,EAAU,CAAC,EADd,GACW,GAAT,OAA2B,CAAC,CAAE,GAG9C,EACT,EAnoB4B,GACrB,CAAC,AAioBS,AAloBe,CAG5BA,AAH6B,GAGP,EAAc,AA4nBgC,CA5nB/B,AA4nBgC,OA5nBzB,CAAvB,AAAwB,CAAX,AAAa,EAChD,CAED,IAAM,EAAiBD,GAAsB,EAAY,CAAC,AAHM,CAAC,KAG7C,CAAmC,CAAX,IAA0B,CAAC,CAAC,MACnD,IAAjB,GAAgD,EAAtB,EAA0B,EAAE,AAAxB,GAChCC,AADc,GACQ,EAAc,CAAC,KADS,GACzB,CAAa,GAAe,CAAC,CAAE,GAGtD,IAAM,EAAiBD,GAAsB,EAHuB,AAGX,CAHY,AAGX,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,MACnD,IAAjB,GAAgD,EAAtB,EAA0B,EAAtB,AAAwB,GACxDC,AADc,GAEZ,EACA,CAAC,KAH2C,GACzB,CACP,QACM,CAAE,YAAY,CAAC,CACjC,EAKN,EA0CsC,EAAY,GAGzC,GCrIH,EDmFc,AA+C4B,AAAU,CA9CrD,AA8CsD,EAG1C,EC1JX,EAAOuC,EAAH,CACF,MADqB,UACL,CAChB,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CACtD,AADW,CAAgB,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAaJ,CAfa,GAEL,CAAC,GAaD,MAbC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,MAAM,CAClB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,CAIL,EAHO,EADE,AAIL,CAAC,AAAC,GACb,CADiB,CAG3B,CAAM,CAF+B,EADN,IDgG5B,IC5FI,GDuFV,CCvFc,CD4FC,AC3FT,EADWsB,EACP,CAAC,EDsFS,EACpB,KCvFoB,CDyFd,EAAoC,CAAA,CAAE,AAFG,CAK9B,AAAb,CAL2C,EAEjC,CAGO,EAAE,GADL9D,AACL,GC3FP,ED0F8C,CAAC,GC1FzC,AAFoD,CAG3D,GDyFuD,CAArB,AAAsB,CAArB,AAAsB,GAE5DC,GACE,EACA,CAAC,CAJ6C,IAGtC,EACA,CAFW,AAEV,CACT0D,GAAe,EAAW,IAK1B,AAAc,GALA,AAAU,CAKN,CALiB,CAKf,AALgB,CACrC,AAGG,EAAa3D,CACL,IADuC,CAAC,EAAtC,MAAwB,AAAsB,CAArB,AAAsB,CAAC,GAxJlD,AA0JZ,MAFiD,GAxJrC,AACd,CAA2C,CAC3C,CAAqC,EAAA,AAIrC,IAAM,EAAUA,GAAsB,EAAzB,AAAqC,CAAC,KAAK,CAoJtB,AApJuB,CAAT,AAAU,CAArB,KAChB,EAPyB,EAO1C,GAAyC,EAAf,EAAmB,EAAE,AAAjB,GAAlB,AACdC,GAAsB,CADiB,CACH,CAAC,KAAK,CAAC,CAAE,CAAxB,CAAa,CAGpC,IAHsD,AAGhD,CAHiD,CAGhCD,GAAsB,EAAY,CAAC,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,MACnD,IAAjB,GAAgD,EAAtB,EAA0B,EAAE,AAAxB,GAChCC,AADc,GACQ,EAAc,CAAC,KADS,GACzB,CAAa,GAAe,CAAC,CAAE,GAGtD,IAAM,EAAkBD,GAAsB,EAAY,AAHU,CAAC,AAGV,OAAtC,AAAmC,CAAX,KAA2B,CAAC,CAAC,MACrD,IAAjB,GAA8B,AAAmB,EAAvB,EAA2B,EAAE,GAA3C,AACdC,GAAsB,EAAc,CAAC,AADU,QAC1B,CAAa,IAAgB,CAAC,CAAE,GAGvD,IAAM,EAAeD,GAAsB,EAAY,CAHe,AAGd,CAHe,GAGrD,GAAmC,CAAX,EAAwB,CAAC,CAAC,CACpE,GAAqB,SAAjB,AAA0B,GAAoB,IAAI,EAApB,EAAsB,CAAxC,AACd,IAAI,EAAkBsC,GAAY,AADU,GAExC,GAD6B,EACxB,CAAC,CADS,EAA2B,CAAC,GAC9B,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAEtBrB,AAFuB,CACW,CADT,CAEV,CADT,EAAkB,AAAc,AAE9C,CAD2B,AAC1B,CAD2B,AAG/BhB,GAAsB,EAAc,CAAC,EAHZ,MAGJ,CAAa,CAAa,CAAC,CAAE,EACnD,CAED,IAAM,EAAwBD,GAAsB,EAAY,CAHG,AAIjE,CAJkE,MAGN,CAAX,KAAxB,MACN,CACpB,CAAC,MACmB,IAAjB,GAAuD,EAA7B,EAAiC,EAA7B,AAA+B,GAAjD,AACdC,GACE,EACA,CAAC,QAFkB,CACP,GAFuC,OAG/B,CAAC,CACrBgB,GAAeU,GAAW,KAAD,AAI7B,IAAM,CAJY,CAIA3B,GAAsB,EAAY,CAAC,CAAtC,GAJoC,CAAC,CAAC,CAClD,AAG+C,AAAU,CAArB,AAAsB,CAAC,CAC9D,QAAqB,IAAjB,GAA8B,AAAa,EAAjB,EAAqB,IAAE,CAArC,AAA2B,AACzC,IAAI,EAAkB,EAClB,KAAK,CAAC,CADqB,IAAZ,EACF,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,AAEvB+B,CADkC,AAkjB3C,CAnjBkC,EACnB,EAAgC,AAAd,IAkjBvBA,AAAY,CAAsB,EAjjBxB,AAijBwB,AAChD,IAAM,EAAoC,CAAA,CAAE,CAEtC,CAHmB,CAGQ/B,CAFnB,EAEyC,EAAY,CACjE,OAD+D,CAAX,QAAxB,MACN,CACvB,CAAC,CACF,GAAgC,IAAI,EAAhC,EAAkC,CACpC,IAAI,EAAkB,EAClB,KAAK,CAAC,KADS,EADO,AAET,CAAC,IAChB,GAAkB,CAF0B,CAEV,GAAG,CAAC,AAAC,EADR,CAAC,AAEvB,CADkC,CADT,AAGjC,CAFc,AAEb,CAEJC,AAHe,EADoB,AAAc,CAI3B,EAAU,CAAC,KAAH,GAAT,cAAkC,CAAC,CAAE,EAC3D,CAED,QAAyD,IAHkB,AAGvED,CAHwE,EAGlD,EAAwC,AAA5B,CAAC,CAA6B,MAAhC,CAAX,GAAyB,CAAC,CAAC,CAClD,MAAM,AAAI,KAAK,CAAC,qDAAqD,CAAC,CAGxE,IAAM,EAAmBA,GAAsB,EAAY,CAAC,OAAH,CAAnC,AAAwB,MAA4B,CAAC,CAAC,AACpD,IAAI,EAAE,CAA1B,GACFC,GACE,EACA,CAAC,KADO,EAFQ,CACG,MAEJ,CAAC,CAChBoC,AAhQA,SAAUA,AACd,CAA8B,EAE9B,AAF8B,IAExB,EAAoC,CAAA,CAAE,CAEtC,AA2PiB,EA3PKrC,CAFd,EAEoC,EAAY,CAC5D,CAN+B,MAK2B,CAAX,GAAxB,MACN,CAClB,CAAC,CAKF,GAJ2B,IAAI,EAA3B,AAA6B,GAC/BC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGO,SAAS,AAAnED,EAAqE,CAA/C,EAAY,CAAC,CAHmC,CAAC,KAGvC,CAAX,QAA8B,CAAC,CAAC,CACvD,MAAM,AAAI,KAAK,CAAC,0DAA0D,CAAC,CAG7E,OAAO,CACT,EA+O0B,IAIxB,CApPe,GAoPT,EAA4BA,GAAsB,EAAY,CAJ5B,AAKtC,CALuC,CACtC,KAG+D,CAAX,SAAxB,MACN,CACxB,CAAC,CASF,GARiC,IAAI,EAAjC,AAAmC,GACrCC,GACE,EACA,CAAC,KADO,GADW,QADM,OAGD,CAAC,CACzB,QAK6D,IAA/DD,GAAsB,EAAkD,AAAtC,CAAC,CACnC,MADgC,AALL,CAC1B,AAIoB,aAAmC,CAAC,CAAC,CAE1D,MAAM,AAAI,KAAK,CACb,+DAA+D,CAChE,CAGH,IAAM,EAAiBA,GAAsB,EAAY,CAAC,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,AAClD,IAAI,EAAE,CAAxB,GACFC,GACE,EACA,CAAC,KADO,AAFM,GACK,IAEN,CAAC,CA5Sd,AA6SAmC,SA7SUA,AACd,CAA4B,EAAA,AAE5B,IAAM,EAAoC,CAAA,AA0SrB,CA1SuB,CAE5C,GAFc,AAEVpC,IAL2B,CAK2B,OAAhC,EAAD,AAAa,AAA6B,CAA5B,CAA8B,MAAjC,KAAe,CAAC,CAAC,CACnD,MAAM,AAAI,KAAK,CAAC,sDAAsD,CAAC,CAGzE,IAAM,EAAmBA,GAAsB,EAAY,CAAC,OAAH,CAAX,AAAxB,MAAoD,CAAC,CAAC,CAK5E,OAJI,AAAoB,IAAI,EAAE,GAC5BC,GAAsB,EAAU,CAAC,CADf,IACY,GAAT,MAA0B,CAAC,CAAE,GAG7C,CACT,EA8RwB,IAItB,CAnSe,GAmST,EAtS8D,AAsS7CD,CAtS8C,EAsSxB,CAJT,CAIqB,AAJpB,CAIqB,AAHvD,MAGiB,CAAmC,CAAX,IAA0B,CAAC,CAAC,AAClD,IAAI,EAAE,CAAxB,GACFC,GAAsB,EAAU,CAAC,KADjB,AACc,GAAT,IAAwB,CAAC,CAAE,GAGlD,IAAM,EAAkBD,GAAsB,EAAY,AAHM,CAGL,AAHM,OAG5C,AAAmC,CAAX,KAA2B,CAAC,CAAC,AACnD,IAAI,EAAE,CAAzB,GACFC,GAAsB,EAAU,CAAC,KAAH,CADb,EACI,KAAyB,CAAC,CAAE,GAGnD,IAAM,EAAoBD,GAAsB,EAAY,CAHM,AAIhE,CAJiE,MAGT,CAAX,CAAxB,MACN,CAChB,CAAC,CAKF,OAJyB,IAAI,EAAzB,AAA2B,GAC7BC,GAAsB,EAAU,CAAC,KAAH,GADX,AACE,OAA2B,CAAC,CAAE,GAG9C,EACT,EA5nB2B,GACpB,CA0nBU,AA3nBc,AACvB,CAEJA,AAH4B,GAGN,EAAc,AAqnBgC,CArnB/B,AAqnBgC,OArnBzB,CAAvB,AAAwB,CAAX,AAAa,EAChD,CAED,IAAM,EAAiBD,GAAsB,EAAY,CAHO,AAGN,CAHO,KAG7C,CAAmC,CAAX,IAA0B,CAAC,CAAC,CAKxE,GAJI,KAAiB,OAA+B,AAApC,EAAc,EAA0B,EAAtB,AAAwB,GACxDC,GAAsB,EAAc,CAAC,KADS,GACzB,CAAa,GAAe,CAAC,CAAE,GAGI,SAAS,AAA/DD,EAAiE,AAHD,CAAC,AAG3C,EAAY,CAAC,OAAH,CAAX,IAA0B,CAAC,CAAC,CACnD,MAAM,AAAI,KAAK,CAAC,sDAAsD,CAAC,AAI3E,EA0FqC,EAAY,GAGxC,GCjFH,ED8EyC,AAAU,CAAC,EAGzC,ECtGX,EAAOwC,EAAH,CACF,MADqB,UACL,CAChB,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAaJ,CAfa,GAEL,CAAC,GAaD,MAbC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,MAAM,CAClB,WAAW,CAAE,MAAA,EAAA,CAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAO,AAAN,EAAM,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,CAIL,EAHO,EAGH,AAJK,CAIJ,AAAC,GACb,CADiB,CAG3B,EAFqC,AAgBxC,EAjBkC,IAiB5B,GAAG,CACP,CAAwC,CAAA,qBAIpC,EAAe,EAAX,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,GAAI,GADW,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,KDuP7B,EAEA,ECxPI,GDmPV,CAGc,ACtPA,CACR,CDuPQ,CCxPGuB,EACP,CAAC,EDkPS,EACpB,KCnPoB,GDqPsB,CAAA,CAFE,AAEA,CAGxC,AAAY,CAL4B,GAKxB,EAAE,EAAV,CADK/D,GCtPX,EDsP6C,CAAC,CCxPU,EAElD,CACP,EDqPqD,CAAC,CAAC,AAAtB,CAAC,EAErCC,GACE,EACA,CAAC,EAJ4C,GAGrC,CACD,CAAE,CAFU,KAEJ,CAAC,CAChBgC,GAAqB,EAAW,IAI7B,GAJ2B,ACpO9B,CDoOwC,CAAC,CAC1C,EAGY,CAJS,CCzPpB,EAAOO,EAAH,CACF,MADqB,EACb,CACR,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAaJ,CAfa,GAEL,CAAC,GAaD,MAbC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,KAAK,CACjB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAE,AAAD,GACG,EAAa,IAAI,EAAE,CADT,CAIL,EAHO,EADE,AAIL,CAAC,AAAC,GACb,CADiB,CAG3B,CAAM,CAF+B,EADN,MAIxB,GDoMV,CCpMc,CACR,EADWwB,EACP,CAAC,EDmMS,EACpB,KCpMoB,CDsMd,EAAoC,CAAA,CAAE,AAFA,CAK5B,AAAZ,CALwC,EAE9B,CAGM,EAAE,CADhB,CACM,CADKhE,GCvMX,EDuM6C,CAAC,ACzMS,ADyM/C,GCvMF,CACP,EDsMqD,CAAC,CAArB,AAAsB,CAArB,EAErCC,GACE,EACA,CAAC,EAJ4C,GAGrC,CACD,CAAE,CAFU,KAEJ,CAAC,CAChBgC,GAAqB,EAAW,IAI7B,GAJ2B,ACrL9B,CDqLwC,CAAC,CAC1C,EAGY,CAJS,CC1MpB,EAAOO,EAAH,CACF,MADqB,EACb,CACR,EAAK,EAAD,EAAmC,CACxC,CACD,AAFa,EAEC,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAaJ,CAfa,GAEL,CAAC,GAaD,MAbC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,KAAK,CACjB,WAAW,CAAE,MAAA,EAAA,CAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,CAIL,EAHO,EAGH,AAJK,CAIJ,AAAC,GACb,CADiB,CAG3B,EAFqC,AAgBxC,EAjBkC,IAiB5B,MAAM,CACV,CAA2C,CAAA,eDW7C,MCPM,EAAe,CDOD,CCPV,AAAa,CACjB,ADON,ECP4C,CAAA,CAAE,CAC5C,GAAI,EDMyC,CCP9B,CDO8B,ACNrC,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,KD0B7B,EAEA,EC3BI,GDsBV,CAGc,ACzBA,CACR,CD0BQ,CC3BGyB,EACP,CAAC,EDqBS,EACpB,KCtBoB,GDwBsB,CAAA,CAAE,AAFG,CAK3C,AAAY,CAL+B,GAK3B,EAAE,EAAV,CADKjE,GCzBX,EDyB6C,CAAC,GCzBxC,CAFqD,AAG5D,EDwBqD,CAAC,CAAC,AAAtB,CAAC,EAErCC,GACE,EACA,CAAC,EAJ4C,GAGrC,CACD,CAAE,CAFU,KAEJ,CAAC,CAChBgC,GAAqB,EAAW,IAI7B,GCLH,ADC8B,CAAU,CAAC,CAC1C,EAGY,CAJS,CC5BpB,EAAOO,EAAH,CACF,MADqB,EACb,CACR,EAAK,EAAD,EAAmC,CACxC,CACD,AAFa,EAEC,EAAK,EAAD,IAAoC,CACtD,AADW,CAAgB,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAmBJ,CArBa,GAEL,CAAC,GAmBD,MAnBC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,QAAQ,CACpB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,MAAA,EAAA,CAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,AACU,GAAR,CAAY,CAAE,AADZ,AACW,IAE9B,EAAS,MAFkC,AAEnC,KAFuC,IAEvB,CAAG,CACzB,OAAO,CAAE,EAAa,OAAO,CACR,CAHN,CAEM,IAMb,IAAI,CAAE,AAAD,EARmD,EAStE,OAD+B,CACzB,GDyBN,CCzBU,AADyB,CD0BC,CAAA,CAAE,ACxBpC0B,CD6BJ,AAAuB,GALb,CAKiB,EAAE,CAH3B,EAAsBlE,GC1B6B,ED0BK,CAC5D,IAEqB,IAH0B,AC1BmB,CAAC,AD0BnB,EAAzB,MACN,CAClB,CAAC,AAF0D,EC1BJ,CD8BtDC,GAAsB,EAAU,CAAC,KAAH,GAAT,SAA6B,CAAC,CAAE,GAGhD,GChCK,EAAY,GDgCT,CChCakE,GAAP,AAEf,ID2BoE,CAAC,EC5BrE,MAAM,CAAC,MAAM,CAAC,EAAW,CAD8B,EAAE,AAElD,CADsB,AAE/B,CAAC,AAF+B,CAE9B,AACH,CAH0B,AAGpB,KAFa,AD7BhB,EAEA,EC8BI,IDhCI,ACgCA,CACR,CD/BQ,CC8BGC,EACP,CAAC,SAAS,GDjCsB,CAAA,CAAE,CAGxC,AAAY,IAAI,EAAE,EAAV,CADKpE,GCgCX,EDhC6C,CAAC,GC8BY,AAEpD,CACP,EDjCqD,CAAC,CAAC,AAAtB,CAAC,EAErCC,GACE,EACA,CAAC,EAJ4C,GAGrC,CACD,CAAE,CAFU,KAEJ,CAAC,CAChBgC,GAAqB,EAAW,IAI7B,GCoDH,ADxD8B,CAAU,CAAC,CAC1C,EAGY,CAJS,CC6BpB,EAAOO,EAAH,CACF,MADqB,EACb,CACR,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CACtD,AADW,CAAgB,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAmBJ,CArBa,GAEL,CAAC,GAmBD,MAnBC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IAAI,AADc,CACb,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,QAAQ,CACpB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAO,AAAN,EAAM,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,MAAA,EAAA,CAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,AACU,GAAR,CAAY,CADV,AACW,AAAC,IACd,AACjB,EAAS,MAFkC,AAEnC,IAD0D,CADnB,IAEvB,CAAG,CACzB,OAAO,CAAE,EAAa,OAAO,CACR,EADA,IAMb,IAAI,CAAC,AAAC,IACpB,OAD+B,CACzB,GD7BN,CC4BmC,AACzB,CD7B0B,CAAA,CAAE,AC8BpC6B,CDzBJ,AAAuB,GALb,CAKiB,EAAE,CAH3B,EAAsBrE,GC4B4B,ED5BM,CAC5D,IAEqB,IAH0B,AC4BkB,CD5BjB,AC4BkB,ED5B3C,MACN,CAClB,CAF2D,AAE1D,CC0BqD,EDxBrDC,GAAsB,EAAU,CAAC,KAAH,GAAT,SAA6B,CAAC,CAAE,GAGhD,GCsBK,EAAY,GDtBT,CCsBakE,GAAP,AAEf,ID3BoE,CAAC,EC0BrE,MAAM,CAAC,MAAM,CAAC,EAAW,CAD8B,EAEhD,AAFkD,CAC5B,AAE/B,CAFgC,AAE/B,CAAC,AACH,CAH0B,CAoB7B,IAnBsB,EAmBhB,MAAM,CACV,CAA2C,CAAA,aDkiB7C,QC9hBM,CD8hBc,CC9hBC,CD+hBrB,CC/hBU,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,GD6hB6C,AC7hBzC,ED6hByC,CC9hB9B,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,KD+hB7B,IAWA,IAXQ,EC9hBJ,IAAI,ADyiBE,CCxiBV,EADWG,EACP,CAAC,SAAS,GD6hBsB,CAAA,CAAE,CAGxC,AAAY,IAAI,EAAE,CADhB,CACM,CADKtE,KAAkC,CAAC,AAAtC,IChiBmD,EDgiBP,CAAC,CAAC,AAAtB,CAAC,EAErCC,GACE,EACA,CAAC,EAJ4C,GAGrC,CACD,CAAE,CAFU,KAEJ,CAAC,CAChBgC,GAAqB,EAAW,IAKhC,AAAc,GALgB,CAAU,AAKtB,CALuB,CAC1C,AAIqB,GALA,AAILjC,CACL,ECxiBR,EDuiB+C,CAAC,GCviB1C,CACP,IDsiBmC,AAAsB,CAArB,AAAsB,CAAC,IAnD1D,EAAUA,GAmDmC,EAnDD,AAArC,CAAsC,KAAK,CAAC,CAAC,CAArB,AACjC,CADkC,IACjB,MAD2B,CAChC,AAA6B,EAAf,EAAmB,EAAf,AAAiB,GACjDC,IADuC,CACH,CAAC,KAAK,CAAC,CAAE,CAAxB,CAAC,CAGlB,EAAiBD,EAH+B,CAAC,AAmDnB,EAhDqB,CAAC,GAHtB,GAGhB,CAgD0B,CAhDF,CAAC,GAAyB,CAAC,CAAC,CACpE,IADmD,CAClC,OAA+B,AAApC,EAAc,EAA0B,EAAtB,AAAwB,GACxDC,GA8C8C,EA9CV,CAAC,KADS,AA+CQ,CAAC,EA9ClC,CAAC,GAA2B,CAAC,CAAE,IAiD/C,GAjD6B,ACpehC,KDqhBW,EAjDqD,ACzfhE,CDyfiE,CCzf1DuC,EAAH,CACF,MADqB,EACb,CACR,EAAK,EAAD,EAAmC,CACxC,CACD,AAFa,EAEC,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAaJ,CAfa,GAEL,CAAC,GAaD,MAbC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,OAAO,CACnB,WAAW,CAAE,MAAA,EAAA,CAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,CAIL,EAHO,EADE,AAIL,CAAC,AAAC,GACb,CADiB,CAG3B,CAAM,CAF+B,EADN,MDyf5B,MCrfI,GDueV,CAcgB,ACrfF,CACR,EADW+B,EACP,CAAC,EDseS,EACpB,KCveoB,CDyed,EAAoC,CAAA,CAFK,AAEH,CAGxC,AAAY,CAL+B,EAEjC,CAGM,EAAE,CADhB,CACM,CADKvE,KAAkC,CAArC,AAAsC,GC5eY,GD4eN,CAAC,CAArB,AAAsB,CAArB,EAErCC,GACE,EACA,CAAC,EAJ4C,GAGrC,CACD,CAAE,CAFU,KAEJ,CAAC,CAChBgC,GAAqB,EAAW,IAKhC,AAAc,GALgB,CAKZ,AALsB,CAAC,CAKrB,AAJrB,GAGgBjC,AAJK,CAKV,ECpfR,EDmf+C,CAAC,GCnf1C,CACP,IDkfyD,AAAtB,CAAuB,AAAtB,CAAuB,IA/C1D,EAAUA,GA+CmC,EA/CD,AAArC,CAAsC,KAAK,CAAC,CAAC,CACrC,AADgB,AACjC,CADkC,QACR,EADkB,CAChC,AAA6B,IAAI,EAAf,AAAiB,GACjDC,IADuC,CACH,CAAC,KAAK,CAAC,CAAE,CAAxB,CAAC,CAGlB,EAAiBD,EAH+B,CA+CnB,AA/CoB,EAGE,CAAC,GAHtB,GAGhB,CA4CyB,CA5CD,CAAC,GAAyB,CAAC,CAAC,CACpE,IADmD,CAClC,IA2C0B,GA3CK,AAApC,EAAc,EAA0B,CA2CD,CA3CrB,AAAwB,AA2CF,GA1CtDC,KAAoC,CAAC,KADS,GACzB,CAAC,GAA2B,CAAC,CAAE,IA6C/C,GA7C6B,ACpbhC,KDieW,ECtfX,ADycgE,CAAC,CCzc1DuC,EAAH,CACF,MADqB,EACb,CACR,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAaJ,CAfa,GAEL,CAAC,GAaD,MAbC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IAAI,AADc,CACb,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,OAAO,CACnB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,MAAA,EAAA,CAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAE,AAAD,GACG,EAAa,IAAI,EAAE,CADT,CAIL,EAHO,EADE,AAIL,CAAC,AAAC,GACb,CADiB,CAG3B,EAFqC,AAKhC,EAN0B,IAMpB,YAAY,CACxB,CAA0C,CAAA,iBAItC,EAAe,EAAX,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,GAAI,GADW,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,ODwG7B,IA1BA,EC7EI,GDqGJ,CAEU,ACvGF,CDqG4B,CAAA,CAAE,ACrG3BgC,CDwGb,AAAc,GAHJ,AAxBK,CA2BG,EAAE,GADLxE,CACL,ECxGmD,EDuGZ,CAAC,GCvGiB,CAAC,IDuGV,AAAtB,CAAuB,AAAtB,CAAuB,IA/B1D,EAAeA,GA+B8B,AAEhB,CCzG6B,CDwET,CAAC,IAAtC,GAiC2B,CAjCH,CAAC,CAAuB,CAAC,CAAC,CAChE,KAAiB,CADgC,MACH,AAAlC,EAAc,EAAwB,EAAE,AAAtB,GAChCC,GA+B6C,EA/BT,CAAC,GADO,EAgCS,CAAC,EA/BT,AAAxB,CAA0B,AAAzB,UAAmC,CAAC,CAAxB,AAA0B,KAGxCD,KAAkC,CAAC,CAHiB,CAAC,MAGhC,CAAC,EAAwB,CAAC,CAAC,CAClE,KAAiB,AADiC,OACtC,AAAmC,EAArB,EAAyB,EAAE,AAAvB,GAChCC,KAAoC,CAAC,IADQ,IACxB,AAAwB,CAAvB,AAAyB,WAAW,CAAxB,AAAyB,CAAE,IA6BxD,GChFH,KDgFW,CA7B6D,CC9ExE,AD8EyE,EC9ElEuC,EAAH,CACF,MADqB,UACL,CAChB,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAmBJ,CArBa,GAEL,CAAC,GAmBD,MAnBC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,KAAK,CACjB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAO,AAAN,EAAM,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,AACU,GAAR,CAAY,CAAC,AAAC,AADZ,IAGnB,EAAS,MAFkC,AAEnC,KAFuC,IAEvB,CAAG,CACzB,OAAO,CAAE,EAAa,OAAO,CACR,CAHN,CAEM,IAMb,IAAI,CAAC,AAAC,EARiD,EASrE,IAAM,EDqHR,ACpHIiC,CAF6B,CACrB,IADyB,GDsH3B,AACd,CAA4C,EAE5C,AAF4C,IAEtC,EAAoC,CAAA,CAAE,CAEtC,EAAsBzE,CAFd,EAEoC,EAAY,CAC5D,OAD0D,ACzHL,CDyHN,GAAxB,KALyB,CAM/B,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAoBD,GAAsB,EAAY,CAC1D,IAJwE,CAAC,EAGjB,CAAX,CAAxB,MACN,CAChB,CAAC,AACuB,IAAI,EAAE,CAA3B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,AADF,OAC6B,CAAC,CAAE,GAGrD,IAAM,EAAqBD,GAAsB,EAAY,CAC3D,EAJoE,CAAC,IAGZ,CAAX,EAAxB,MACN,CACjB,CAAC,CACF,GAA0B,IAAI,EAA1B,EAA4B,CAC9B,IAAI,EAAkB,CAClB,KAAK,EAAC,CAFU,IACD,EACF,CAAC,EADsB,GAEtC,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,AAEvB,CADkC,CAE1C,AAHiC,CAGhC,CAFa,AAIjBC,AAHe,EADkC,AAAd,CAIb,EAAU,CAAC,KAAH,GAAT,QAA4B,CAAC,CAAE,EACrD,CAED,OAAO,CACT,ECrJ0D,EDiJa,CAAC,AChJ1D,EDmJG,ACnJS,IAAIyE,EADuC,CAAC,AAC/C,AAEf,OADA,MAAM,CAAC,MAAM,CAAC,EADwC,AAC7B,EAD+B,CAEjD,CADsB,AAE/B,CAFgC,AAE/B,CAAC,AACH,CAH0B,AAGpB,KAFa,QAGZ,GDoDJ,CCpDQ,CDoD4B,CAAA,CCpDzBC,ADoD2B,CAGxC,AAAc,GAHJ,CAGQ,EAAE,CADlB,EAAa3E,CACL,ECvDkD,EDsDX,CAAC,EAAtC,CCtDsD,CAAC,IDsDT,AAAtB,CAAC,AAAsB,CAAC,IArC1D,EAAeA,GAqC8B,ACtDY,EDiBR,CAAC,IAAtC,IAAwB,CAAC,CAAuB,CAAC,CAAC,CAChE,KAAiB,CADgC,MACrC,AAAkC,EAApB,EAAwB,EAAE,AAAtB,GAChCC,KAAoC,CAAC,GADO,KACvB,AAAwB,CAAvB,AAAyB,UAAU,CAAC,CAAE,AAA1B,GAG9B,EAAgBD,GAkCY,EAlCsB,CAAC,CAHiB,CAAC,GAGxD,EAkCyB,CAlCD,CAAC,EAAwB,CAAC,CAAC,CAClE,AAAiB,KADiC,IACxB,GAAd,AAAmC,IAAI,EAArB,AAAuB,GACvDC,GAgC4C,EAhCR,CAAC,IADQ,CAiCO,CAAC,EAhChC,AAAwB,CAAE,AAAzB,WAAoC,CAAC,AAAzB,CAA2B,IAmCxD,GC/BH,KD+BW,CAnC6D,CCvBxE,ADuByE,ECvBlEuC,EAAH,CACF,MADqB,UACL,CAChB,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CACtD,AADW,CAAgB,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAmBJ,CArBa,GAEL,CAAC,GAmBD,MAnBC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IAAI,AADc,CACb,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,KAAK,CACjB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,AACU,GAAR,CAAY,CADV,AACW,AAAC,IAE/B,EAAS,MAFkC,AAEnC,KAFuC,IAEvB,CAAG,CACzB,OAAO,CAAE,EAAa,OAAO,CACR,CAHN,CAEM,IAMb,IAAI,CAAC,AAAC,EARiD,EASrE,IAAM,ED8CR,AC7CIoC,CAF6B,CACrB,IADyB,GD+C3B,AACd,CAA4C,EAAA,AAE5C,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAsB5E,CAFd,EAEoC,EAAY,CAC5D,MCnDoD,CDkDM,CAAX,GAAxB,IALwB,EAM9B,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAoBD,GAAsB,EAAY,CAC1D,IAJwE,CAAC,EAGjB,CAAX,CAAxB,MACN,CAChB,CAAC,AACuB,IAAI,EAAE,CAA3B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,AADF,OAC6B,CAAC,CAAE,GAGrD,IAAM,EAAqBD,GAAsB,EAAY,CAC3D,EAJoE,CAAC,IAGZ,CAAX,EAAxB,MACN,CACjB,CAAC,CACF,GAA0B,IAAI,EAA1B,EAA4B,CAC9B,IAAI,EAAkB,EAClB,KAAK,CAAC,CAFU,IACD,EACF,CAAC,EADsB,GAEtC,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAEtB,AAFuB,CACW,CADT,AAGjC,CAAC,CAFa,AACF,AAGfC,EAJmC,AAAc,CAI3B,EAAU,CAAC,KAAH,GAAT,QAA4B,CAAC,CAAE,EACrD,CAED,OAAO,CACT,EC9EyD,ED0Ec,CAAC,ACzE1D,ED4EG,AC5ES,IAAIyE,EADsC,CAG5D,AAFe,AAD8C,OAE7D,MAAM,CAAC,MAAM,CAAC,EAAW,AAD6B,EAAE,CAEjD,CADsB,AAE/B,CAFgC,AAE/B,CAAC,AACH,CAH0B,CAK9B,IAJuB,6+CCncxB,SAAS,GAAe,CAAsB,EAAA,AAC5C,GAAI,KADiB,AACC,EAAX,IAAC,GAAmB,EAAd,EAA2C,CAAC,EAAE,CAA5B,EAAQ,KAAD,AAAM,CAAC,MAAM,CACrD,OAAO,EAET,GAFc,CAET,IAAM,IAAI,CAAI,EAAQ,KAAD,AAAM,CAAE,AAChC,QAAa,IAAT,GAAmD,CAAC,AAAhD,CAAc,CAAoC,CAAhC,MAAM,CAAC,IAAI,CAAC,GAAM,CAAF,CAAC,IAAO,CAChD,OAAO,EAGX,GAHgB,IAGT,CACT,CA4BA,EA7Ba,OA6BJ,GACP,CAAqC,EAAA,AAErC,QAA6B,IAAzB,GAHwB,AAG8C,CAAC,CAArC,CAAuC,CAAnC,EAAqB,MAAM,CACnE,IADsB,EACf,EAAE,CAEX,EAH8D,EAGxD,EAAkC,EAAE,CACpC,EAAS,EAAqB,EAAxB,GADQ,CACsB,CACtC,CAAC,CAAG,CAAC,CACT,KAAO,CAAC,CAF2B,AAExB,GACT,GAAqC,AADtB,AACX,CADa,KAC0B,EAAE,EAArB,CAAC,CAAC,CAAC,CAAC,IAAI,CAC9B,EAAe,IAAI,CAAC,CAAoB,CAAC,CAAC,CAAC,CAAC,CAC5C,CADc,AACb,EAAE,KACE,CACL,IAAM,EAA+B,EAAE,CACnC,GAAU,EACd,CAFiB,CACN,AAAO,GACX,CAAC,CAAG,GAA2C,GAArC,IAA4C,CAAE,EAA1C,CAAoB,CAAC,CAAC,CAAC,CAAC,IAAI,EAC/C,EAAY,IAAI,CAAC,CAAoB,CAAC,CAAC,CAA5B,AAA6B,CAAC,CACrC,GAAW,CAAC,GAAL,AAAoB,CAAoB,CAAC,CAAC,CAAC,CAAC,EAAE,CACvD,EAAU,CADkB,CAClB,CAAK,CAEjB,CAFS,AAER,EAAE,CAED,EACF,EAAe,GADN,CACU,CADR,AACS,GAAG,GAGvB,CAHc,CAGC,GAAG,EAAE,AAEvB,CALqC,AAOxC,CAPyC,KAGrB,CAIb,CACT,aADuB,uCAKpB,OACU,GAIX,EAJgB,CAAA,QAIJ,CAAA,CAAoB,CAAE,CAAoB,CAAA,CACpD,IAAI,CAAC,YAAY,CAAG,EACpB,IAAI,CAAC,KAD2B,IAClB,CAAG,EAyBnB,MAAM,CAAC,AAzBqB,CAyBa,CAAA,CACvC,OAAO,IAAI,GACT,CADa,GACT,CAAC,SAAS,CACd,IAAI,CAAC,YAAY,CACjB,EAAO,IAAD,CAAM,CACZ,EAAO,IAAD,EAAO,CAGb,eAAe,CAAC,EAAO,IAAD,GAAQ,CAAC,CAChC,CAEJ,CAQE,MACU,GAKX,CALe,CAAA,SAMI,CAAA,CAAoB,CACpB,CAAoB,CACpB,CAAa,CACb,EAAsC,CAAA,CAAE,CACjD,CAD+C,CACpB,EAAE,CAAA,CAJpB,CAIT,GAJkB,CAAA,SAAA,CAAT,EACA,IAAY,CAAA,EADH,UACG,CAAZ,EACA,IAAK,CAAA,KADO,AACP,CAAL,EACA,GADK,CACC,CAAA,MAAA,CAAN,EACT,IADe,AACR,CAAA,OAAA,CAAP,EAPF,IAAA,CAOS,AAPT,WAAW,CAAkB,OAAO,CAAC,OAAO,EAAE,CASpD,AAxHJ,SAAyB,AAAhB,CAAwC,EAAA,AAE/C,GAAuB,AAsHN,CAtHO,EAAE,CAAtB,EAAQ,GAFU,EAEX,CAAO,EAGlB,IAAK,IAAM,KAAW,EAAJ,AAChB,GAAqB,EADM,CAAE,GACF,GAAvB,EAAQ,IAAI,CAAL,CAAqC,OAAO,EAAE,CAA1B,EAAQ,IAAI,CAAL,AACpC,MAAM,AAAI,KAAK,CAAC,CAAA,oCAAA,EAAuC,EAAQ,IAAI,CAAG,AAAR,CAAQ,CAAA,CAAC,AAE1E,CACH,EA8GoB,GAuBlB,IAvByB,CAAC,CAuBpB,WAAW,CACf,CAAmC,CAAA,MAEnC,OAAM,IAAI,CAAC,WAAW,CACtB,IAAM,EAAe/C,GAAW,EAAO,GAAR,CAAO,CAApB,EAA4B,CAAC,CACzC,EAAkB,IAAI,CAAC,QAAR,IAAoB,CAAC,eAAe,CAAC,CACxD,KAAK,CAAE,IAAI,CAAC,KAAK,CACjB,QAAQ,CAAE,IAAI,CAAC,UAAU,CAAC,IAAI,AAAE,CAAD,KAAO,CAAC,GACvC,MAAM,CAAE,EAD2C,CAAC,IAC5C,EAAA,EAAO,IAAD,EAAC,AAAM,EAAI,EAAA,EAAA,EAAI,CAAC,CAAL,IAAA,CAAW,AACrC,CAD0B,AAC1B,CAAC,CA8BF,GA/B2B,IAE3B,CAF2B,CAAA,EAEvB,CAAC,WAAW,CAAG,CAAC,YAAW,QAC7B,IAAM,EAAW,MAAH,AAAS,EACjB,EAAgB,OAAA,EAAA,EADgB,AACnB,KAAG,EAAA,EAAS,MAAD,IAAC,AAAU,EAAA,IAAA,CAAA,CAAA,CAAA,CAAA,CAAG,EAAC,AAAC,CAAL,CAAO,CAAP,GAAO,CAAA,CAAP,AAAO,CAAA,CAAA,CAAA,EAAP,CAAA,AAAO,EAAA,EAAO,CAKjD,EAL0C,AAM9C,EAAS,GANqC,CAAA,EAMtC,yBAD+B,AACC,CACpC,EAAQ,GAAH,CAAO,CAAC,UAAU,EAAC,GAAM,CAAF,CAAC,IAAO,CAEtC,EAAmD,EAAE,AACd,IAAI,EAAE,CAA7C,IACF,EACE,OAAA,EAAA,EAAoC,GAHL,EAGU,CAAC,EAAK,CAAC,CAAA,EAAA,AAAI,EAAA,AAAE,CAAN,CAIpD,EANuC,AACN,CACmB,CAIhD,CAAC,EAJ+C,EAAA,KAAA,GAAb,CAIrB,CAJkC,AAKlD,CALkD,CAGhC,EAAgB,CAAC,EAAc,CAAG,EAAE,CAItD,CAFY,EACZ,AAIH,CAPkC,EAO/B,CACJ,AARoD,MAQ9C,CALS,GAKL,CAAC,WAAW,CAAC,CAJY,CAChC,GAGyB,CAAC,KAE3B,CAFgC,GAE5B,CAAC,WAAW,CAAG,OAAO,CAAC,OAAO,EAAE,AACtC,CAAC,CAAC,CACK,EAyBT,MAAM,OAzBkB,UAyBD,CACrB,CAAmC,CAAA,MAEnC,OAAM,IAAI,CAAC,WAAW,CACtB,IAAM,EAAeA,GAAW,EAAO,GAAR,CAAO,CAApB,EAA4B,CAAC,CACzC,EAAiB,IAAI,CAAC,OAAR,KAAoB,CAAC,qBAAqB,CAAC,CAC7D,KAAK,CAAE,IAAI,CAAC,KAAK,CACjB,QAAQ,CAAE,IAAI,CAAC,UAAU,EAAC,GAAM,CAAF,CAAC,IAAO,CAAC,GACvC,MAAM,CAAE,EAD2C,CAAC,IAC5C,EAAA,EAAO,IAAD,EAAC,AAAM,EAAI,EAAA,EAAA,EAAI,CAAC,CAAL,IAAA,CAAW,AACrC,CAD0B,AAC1B,CAAC,CAIF,GAL2B,CAKvB,CAAC,GALsB,CAAA,OAKX,CAAG,EAChB,IAAI,CAAC,SAAM,GACX,KAAK,CADe,AACd,IAAM,QACf,CADwB,CAAC,EACnB,EAAW,MAAH,AAAS,EAEvB,OADe,AACR,IADY,CADkB,AACjB,CACP,oBAD4B,CAAC,EAAU,GA2BtD,GA3BoD,MAAc,CAAC,AA2BzD,CAAC,GAAmB,CAAK,CAAA,CAMjC,OAAO,eAAe,CALN,AAKO,EAJnB,GAAsB,EAII,CAAC,CAJD,CAAC,OAAO,EAClC,IAAI,AADiB,CAChB,OAAO,EAMH,qBAAqB,CAClC,CAA6D,CAC7D,CAA2B,CAAA,0DAE3B,IAAM,EAAiC,EAAE,KACzC,IAA0B,AADP,IACqB,EAAd,EAAA,GAAA,EAAA,GAAA,KAAgB,CAAF,CAAE,CAAA,EAAhB,AAAgB,CAAhB,GAAc,CAAA,CAAE,GAAA,EAAA,EAAA,EAAA,CAAA,EAAA,CAAA,CAAA,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,EAAA,CACxC,CADwC,EAAhB,EAAc,EAAA,KAAA,CAAd,EAAc,CAAA,EAtS5C,AAuSU,GADkC,EAAA,IAtSnC,AAAgB,CAAuC,EAAA,GAuSvC,CAAC,EAtSxB,GAsS6B,CAAC,EAvSR,EACK,GAAvB,EAAS,IAAuB,EAAxB,IAAW,EAAiB,AAA+B,CAAC,EAAE,GAAzB,EAAD,QAAW,CAAC,MAAM,CAChE,OAAO,EAET,GAFc,CAER,EAAU,KAAH,EAAG,EAAA,EAAS,MAAD,IAAW,CAAC,EAAC,AAAC,EAAE,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,GAAA,EAAA,EAAO,GAAP,KACxC,AADwC,CAAA,IACxB,IAAZ,GAGG,EAHkB,CAGH,CAHX,AAAgB,CAI7B,KAD+B,AA+RG,CAC1B,AAhSwB,GAAT,CAgST,EAAU,KAAH,CAAG,EAAA,CAAA,OAAA,EAAA,EAAM,GAAD,OAAW,AAAV,EAAU,IAAA,CAAA,CAAA,CAAA,CAAA,CAAG,EAAC,AAAC,CAAL,CAAO,CAAP,GAAO,CAAA,CAAP,AAAO,CAAA,CAAA,CAAA,EAAP,CAAO,AAAP,EAAO,EAAO,GAAP,GACvB,EADuB,CAAA,CACnC,GACF,EADuB,AACT,EADW,AAAhB,EACS,CAAC,EAEtB,CACD,GAHiB,CAAa,CAAC,CAGzB,MAAA,GAPc,EAQrB,AARqB,EAOd,CAAA,KAAK,CAAA,kGAEb,IAAI,CAAC,aAAa,CAAC,EAAc,IAClC,CAEO,KAHyB,GAAe,CAAC,IAG5B,CACnB,CAAwB,CACxB,CAA4B,CAC5B,CAAiD,CAAA,CAEjD,IAAI,EAAkC,EAAE,CAEtC,EAAY,MAAM,CAFF,AAEK,CAAC,CAAX,CACX,EAAY,KAAK,CAAC,AAAC,GAAR,IAAe,CAAsB,IAAjB,EAAQ,GAAkB,CAAd,AAAe,CAApB,CACtC,AACA,EAAiB,EAIjB,EAAe,IAAI,CAAC,CAClB,CAL0B,CAAd,EAKR,CAAE,CADM,MACC,CACb,KAAK,CAAE,EAAE,AACO,CAAA,CAAC,CAGnB,GACA,EAAgC,MAAM,CAAG,CAAC,CAE1C,CADA,GACI,CAAC,OAAO,CAAC,IAHkB,AAGd,CACf,EAH6B,CAG1B,GAAsB,IAG3B,IAAI,CAAC,OAAO,CAAC,CAHa,GAGT,CAAC,GAEpB,IAAI,CAAC,CALwD,AAGhC,CAAC,AAHgC,CAC3D,IAIS,CAAC,IAAI,CAAC,GAAG,GAExB,CC5UK,MAAO,ID0U0B,CAAC,GC1UlB,GAAQ,KAAK,CAAA,AAIjC,WAAA,CAAY,CAAqB,CAAA,CAC/B,KAAK,CAAC,EAAQ,KAAD,EAAQ,CAAC,CACtB,IAAI,CAAC,IAAI,CAAG,UAAU,CACtB,IAAI,CAAC,MAAM,CAAG,EAAQ,KAAD,CAAO,CAC5B,MAAM,CAAC,cAAc,CAAC,IAAI,CAAE,GAAS,KAAD,IAAU,CAAC,CAElD,CEdK,MAAO,KAAM,MAAQ,GACzB,OADmC,CAAA,GACnC,CAA6B,CAAoB,CAAA,CAC/C,KAAK,EAAE,CADoB,IAAS,CAAA,SAAA,CAAT,EAqB7B,IAAA,CAAA,EArBsC,EAqBlC,CAAG,MACL,EAAoC,CAAA,CAAE,EAAF,CAE7B,EADuB,EACnB,GACT,EADc,CACJ,MAAD,UAAiB,CAC1B,AAAC,CAA4B,EAAK,IAAI,CAAC,YAAY,CAAC,CAAC,CAAC,CACtD,MAAM,IAAI,CAAC,YAAY,CAAC,GACxB,GAD8B,AAgDlC,CAhDmC,EACzB,CACP,EA8CG,MAAM,CAAC,CAAkC,CAAA,CAC7C,GAAI,IAAI,CAAC,SAAS,CAAC,UAAU,EAAE,CAC7B,CAD+B,KACrB,AAAJ,KAAS,CACb,uFAAuF,CACxF,CAGH,OAAO,IAAI,CAAC,SAAA,CACT,UAAU,CAAC,EAAO,IAAD,AAAK,CAAE,EAAO,IAAD,EAAO,EACrC,IAAI,CAAC,AAAC,GACE,CADE,EAsBf,CArB+B,EADZ,GAsBb,QAAQ,CAAC,CAAoC,CAAA,CACjD,MAAM,IAAI,CAAC,SAAS,CAAC,YAAY,CAAC,GAG5B,GAHkC,CAAC,EAG7B,YAAY,CACxB,CAAiC,CAAA,SAIjC,IAAI,EAAe,EAAX,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,GAAI,GADW,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAC7B,CAD+B,KACrB,AAAJ,KAAS,CACb,4DAA4D,CAC7D,AACI,YD7CH,EC8CI,GDnCJ,CCmCQ,CDnC4B,CAAA,CAAE,ACmC3BmD,CDhCC,AAAd,GAHU,AAXK,CAcG,EAAE,CADlB,EAAa9E,CACL,ECgCyC,EDjCF,CAAC,EAAtC,CCiC6C,CAAC,IDjCA,AAAtB,CAAC,AAAsB,CCiCT,ADjCU,IAlB1D,EAAeA,GAkB8B,AAE1B,EApB8B,CAAC,IAAtC,GAoBiB,CApBO,CAAC,CAAuB,CAAC,CAAC,CAChE,KAAiB,CADgC,MACH,AAAlC,AAAkB,EAAJ,EAAwB,EAAE,GACtDC,GAD4C,AAmBT,EAlBC,CAAC,KAkBM,CAAC,EAlBvB,AAAwB,CAAvB,AAAyB,UAAU,CAAC,CAAxB,AAA0B,KAGxCD,KAAkC,CAAC,CAHiB,CAAC,MAGhC,CAAC,EAAwB,CAAC,CAAC,CAClE,KADkD,AACjC,OAAL,AAAmC,EAArB,EAAyB,EAArB,AAAuB,GACvDC,KAAoC,CAAC,IADQ,IACxB,AAAwB,CAAE,AAAzB,WAAoC,CAAC,AAAzB,CAA2B,IAgBxD,GCqDH,KDrDW,CAhB6D,CAAC,AC6CzE,EAAOuC,EAAH,CAAoB,MAAD,CAAQ,CAAE,EAAK,EAAD,EAAmC,CAAC,CAA7B,AAC5C,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAmBJ,CArBa,GAEL,CAAC,GAmBD,MAnBC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,KAAK,CACjB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,AACU,GAAR,CAAY,CAAE,AAAD,AADX,IAGnB,EAAS,MAFkC,AAEnC,KAFuC,IAEvB,CAAG,CACzB,OAAO,CAAE,EAAa,OAAO,CACR,CAHN,CAEM,IAMb,IAAI,CAAC,AAAC,EARwC,EAS5D,IAAM,EAAOuC,ADnDf,CCkDiC,CACrB,IADyB,GDjDzC,AADc,CACqB,EAAA,AAEnC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAsB/E,CAFd,ECgD0C,AD9CN,EAAY,CAC5D,MANsC,CAKoB,CAAX,GAAxB,MACN,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAoBD,GAAsB,EAAY,CAC1D,IAJwE,CAAC,EAGjB,CAAX,CAAxB,MACN,CAChB,CAAC,AACuB,IAAI,EAAE,CAA3B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,AADF,OAC6B,CAAC,CAAE,GAGrD,IAAM,EAAYD,GAAsB,EAAY,CAAC,CAAtC,CAHuD,CAAC,IAGrB,AAAU,CAArB,AAAsB,CAAC,CAC9D,GAAiB,IAAI,EAAjB,EAAmB,CACrB,IAAI,EAAkB,AADX,EAEP,KAAK,CAAC,CADqB,IAAZ,EACF,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,AAEvB,CADkC,CAE1C,AAHiC,CAGhC,CADW,AAGfC,AAJiB,EAAkB,AAAc,CAI3B,EAAU,CAAC,KAAH,EAAU,CAAC,AAApB,CAAsB,EAC5C,CAED,OAAO,CACT,ECoB2D,EDxBG,CAAC,ACyBjD,EDtBG,ACsBS,IAAI+E,EADwC,CAAC,AAChD,AAEf,OADA,MAAM,CAAC,AADsC,EAAE,IAClC,CAAC,EAAW,GAClB,CADsB,AAE/B,CAFgC,AAE/B,CAAC,AACH,CAH0B,CAMrB,IALc,EAKR,cAAc,CAC1B,CAAkC,CAAA,SAIlC,IAAI,EAAe,EAAX,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,GAAI,GADW,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAC7B,CAD+B,KACzB,AAAI,KAAK,CACb,4DAA4D,CAC7D,AACI,EACL,MDvKE,ECuKI,GDzKJ,CCyKQ,CDzK4B,CAAA,AAE5B,CAF8B,ACyK3BC,CDtKb,AAAY,GAHF,CAGM,EAAE,EAAV,CADKjF,GCuKuC,EDvKL,CAAC,GCuKU,CAAC,EDvKL,CAAC,CAArB,AAAsB,CAArB,EAErCC,ACqKqD,GDrK/B,EAAU,CAAC,EAFc,GAEjB,CAAS,CAAC,CAAnB,AAAqB,GAGrC,GCwLH,ED3LgD,CAAC,EAGtC,ECmKX,EAAOuC,EAAH,CACF,MADqB,eACA,CACrB,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAaJ,CAfa,GAEL,CAAC,GAaD,MAbC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IAAI,AADc,CACb,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,MAAM,CAClB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,CAIL,EAHO,EADE,AAIL,CAAC,AAAC,IACpB,OAD+B,CACzB,GDnLN,CCkLmC,AACzB,CDnL0B,CAAA,CAAE,ACmLzB0C,CD9Kf,AAAuB,GALb,CAKiB,EAAE,CAH3B,EAAsBlF,GCiL8B,EDjLI,CAC5D,IAEqB,IAH0B,ACiLoB,CAAC,ADjLpB,EAAzB,ACiLgC,MDhLtC,CAClB,CAF2D,AAE1D,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,SAA6B,CAAC,CAAE,GAGhD,GC2KK,EAAY,GD3KT,CC2KakF,GAAP,AAEf,IDhLoE,CAAC,EC+KrE,MAAM,CAAC,CADuC,EAAE,GACnC,CAAC,EAAW,GAClB,CADsB,AAE/B,CAFgC,AAE/B,CAAC,AACH,CAH0B,CAqB7B,IApBsB,EAoBhB,GAAG,CAAC,CAA+B,CAAA,SAGvC,IAAI,EAAe,EAAX,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,GAAI,GADW,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAC7B,CAD+B,KACrB,AAAJ,KAAS,CACb,4DAA4D,CAC7D,AACI,EACL,MDvKE,ECuKI,GDzKJ,CCyKQ,CDzK4B,CAAA,AAE5B,CAF8B,ACyK3BC,CDtKb,AAAY,GAHF,CAGM,EAAE,EAAV,CADKpF,GCuKoC,EDvKF,CAAC,GCuKO,CAAC,EDvKF,CAAC,CAArB,AAAsB,ACuKR,CDvKb,EAErCC,GAAsB,EAAU,CAAC,EAFc,GAEjB,CAAS,CAAE,CAApB,KAA0B,CAAC,CAAE4E,GAAY,IAGzD,EAHwD,CC2L3D,CD3LoE,CAAC,CAAC,EAG3D,ECmKX,EAAOrC,EAAH,CACF,MADqB,QACP,CACd,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CACtD,AADW,CAAgB,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAaJ,CAfa,GAEL,CAAC,GAaD,MAbC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,KAAK,CACjB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,MAAA,EAAA,CAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,CAIL,EAHO,EADE,AAIL,CAAC,AAAC,GACb,CADiB,CAG3B,EAF4B,AAkB/B,EAnBkC,IAmB5B,MAAM,CACV,CAAkC,CAAA,SAIlC,IAAI,EAAe,EAAX,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,GAAI,GADW,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAC7B,CAD+B,KACzB,AAAI,KAAK,CACb,4DAA4D,CAC7D,AACI,EACL,MDxPE,ECwPI,GD1PJ,CC0PQ,CD1P4B,CAAA,AAE5B,CAF8B,AC0P3B6C,CDvPb,AAAY,GAHF,CAGM,EAAE,EAAV,CADKrF,GCwPuC,EDxPL,CAAC,GCwPU,CAAC,EDxPL,CAAC,CAArB,AAAsB,CAArB,EAErCC,ACsPqD,GDtP/B,EAAU,CAAC,EAFc,GAEjB,CAAS,CAAE,CAApB,KAA0B,CAAC,CAAE4E,GAAY,IAGzD,EAHwD,CCkR3D,CDlRoE,CAAC,CAAC,EAG3D,ECoPX,EAAOrC,EAAH,CACF,MADqB,QACP,CACd,EAAK,EAAD,EAAmC,CACxC,CACD,AAFa,EAEC,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAqBd,AAnBI,CAFS,GAEL,CAAC,GAmBD,MAnBC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,QAAQ,CACpB,WAAW,CAAE,MAAA,EAAA,CAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,AACU,GAAR,CAAY,CADV,AACW,AAAC,IACd,AACjB,EAAS,MAFkC,AAEnC,IADiD,CADV,IAEvB,CAAG,CACzB,OAAO,CAAE,EAAa,OAAO,CACR,EADA,IAMb,IAAI,CAAC,AAAC,IACpB,ID1QA,EAEA,CCuQ+B,CACzB,IAD6B,ADzQ3B,AC0QE,CD1Q0B,CAAA,CC0QvB8C,AD1QyB,CAKxC,AAAuB,IAAI,EAAE,GAHLtF,AAAH,GCwQiC,EDxQI,CAC5D,IAEqB,IAH0B,ACwQoB,CDxQnB,ACwQoB,EAAb,MDvQtC,CAClB,CAF2D,AAE1D,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,SAA6B,CAAC,CAAE,GAGhD,GCkQK,EAAY,GDlQT,CCkQasF,GAEtB,AAFe,IDrQqD,CAAC,ECsQrE,MAAM,CAAC,CADuC,EAAE,GACnC,CAAC,EAAW,GAClB,CADsB,AAE/B,CAFgC,AAE/B,CAAC,AACH,CAH0B,CAK9B,CC5TK,GDwTkB,MCxTR1E,GAAY,CAAsB,EAAA,AAChD,IAAM,EAAoC,CAAA,AADjB,CACmB,CAE5C,GAAIb,AAAuD,AAF7C,SAEsD,EAAE,CAA5C,EAAD,AAAa,CAAC,OAAH,MAAgB,CAAC,CAAC,CACpD,MAAM,AAAI,KAAK,CAAC,uDAAuD,CAAC,CAG1E,IAAM,EAAWA,GAAsB,EAAY,CAArC,AAAsC,MAAM,CAAC,AAAV,CACjC,AADsB,AAAsB,AACxD,IAAgB,EAAE,EAAV,EACVC,GAAsB,EAAU,CAAC,KAAH,CAAS,CAAC,CAAnB,AAAqB,GAG5C,IAAM,CAH8C,CAAC,AAGhCD,GAAsB,EAAY,CAAC,IAAtC,GAAmC,CAAX,EAAwB,CAAC,CAAC,CAKpE,OAJI,AAAgB,IAAI,EAAE,GACxBC,GADc,AACQ,EAAU,CAAC,KAAH,GAAT,EAAsB,CAAC,CAAE,GAGzC,CACT,CAkkDM,MAnkDW,CAH6C,CAAC,CAskD/CwF,GACd,CAA8B,EAAA,AAE9B,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAkBzF,CAFV,EAEgC,EAAY,AALxB,CAKyB,OAAtC,AAAmC,CAAX,KAA2B,CAAC,CAAC,CAK1E,GAJuB,IAAI,EAAE,AAAzB,GACFC,GAAsB,EAAU,CAAC,KAAH,CADb,EACI,KAAyB,CAAC,CAAE,GAIjDD,KAAmE,OAJH,AAI1C,CAJ2C,CAI5C,AAAa,AAA0C,CAAzC,CACnC,MADgC,kBAA4B,CAAC,CAAC,CAE9D,MAAM,AAAI,KAAK,CACb,kEAAkE,CACnE,CAGH,IAAM,EAAmBA,GAAsB,EAAY,CAAC,OAAH,CAAnC,AAAwB,MAA4B,CAAC,CAAC,CAK5E,OAJI,AAAoB,IAAI,EAAE,GAC5BC,GAAsB,EAAU,CAAC,CADf,IACY,GAAT,MAA0B,CAAC,CAAE,GAG7C,CACT,CC/4CM,MD84CW,GC94CDgB,ED24CsD,CAAC,AC14CrE,CAAyB,EAAA,AAEzB,IAAM,EAAoC,CAAA,CAAE,CAEtC,CALsB,CAKVjB,CAFJ,EAE0B,EAAY,CAAC,CAAtC,MAAmC,AAAU,CAArB,AAAsB,CAAC,CAC9D,GAAiB,IAAI,EAAjB,EAAmB,CACrB,IAAI,EADO,AACW,CAClB,KAAK,EAAC,CADqB,IAAZ,EACF,CAAC,IAChB,GAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,CACW,CADT,CACnB,GAAkB,AAAc,iBA00G7C,EAKA,EAWA,EAOA,UAvBgB,CAvChB,EAAoC,CAAA,CAAE,CAKxC,AAAqB,AAkDD,GAvDV,AA4Ce,CAvCA,AAyDH,EAzDK,CAHzB,EAAoBA,GAHA,EAjyGD,EAoyGmC,CAC1D,AAEmB,CAvyGQ,CAAC,GAiyGkB,CAGD,CAAxB,AAAyB,AAHA,QAI/B,CAChB,CAFyD,AAExD,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,OAA2B,CAAC,CAAE,GAIjD,AAAe,IAAI,EAAE,CADnB,EAAcD,EACL,CAD2B,EAH4B,AAGhB,CAHiB,AAGhB,GAAtC,IAAmC,CAAX,CAAuB,CAAC,CAAC,GAEhEC,GAAsB,EAAU,CAAC,KAAH,GAAT,CAAqB,CAAC,CAAE,GAI3C,AAAkB,IAAI,EAAE,CADtB,CAHoD,CAAC,AAGpCD,GAAsB,EAAY,AACvC,CADwC,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,GAEtEC,GACE,EACA,CAAC,KADO,GADW,IAEN,CAAC,CA1hHd,AA2hHAY,SA3hHUA,AAAY,CAAsB,EAChD,AADgD,CA2hHjC,GA1hHT,EAAoC,CAAA,CAAE,CAE5C,CAHyB,EACX,KAE6C,IAAvDb,GAAsB,EAAY,AAA8B,CAA7B,CAA+B,MAAlC,CAAX,KAA2B,CAAC,CAAC,CACpD,MAAM,AAAI,KAAK,CAAC,uDAAuD,CAAC,CAG1E,IAAM,EAAWA,GAAsB,EAAY,CAAC,AAAtC,MAA4C,CAAT,AAAU,CAArB,AAAsB,AAC5C,IAAI,EAAE,CAAlB,GACFC,GAAsB,EAAU,AADtB,CACuB,KAAH,CAAS,CAAC,CAAnB,AAAqB,GAG5C,IAAM,CAH8C,CAAC,AAGhCD,GAAsB,EAAY,CAAC,IAAtC,GAAmC,CAAX,EAAwB,CAAC,CAAC,CAKpE,OAJoB,IAAI,EAApB,AAAsB,GACxBC,GAAsB,EAAU,CAAC,GADnB,EACgB,GAAT,EAAsB,CAAC,CAAE,GAGzC,CACT,EAygHkB,IAKZ,AAAgB,CA/gHL,CAH6C,CAAC,CAkhHrC,EAAE,CADpB,EAAeD,CAJS,CAAC,CAIY,AAHxC,AAIa,EADuC,CAAC,IAAtC,GAAmC,CAAX,EAAwB,CAAC,CAAC,GAElEC,GACE,EACA,CAAC,KADO,GADW,EAER,CAAC,CACZwB,AApiFA,SAAUA,AACd,CAA0B,EAAA,AAE1B,IAAM,CAiiFa,CAjiFuB,CAAA,CAAE,CAE5C,GAFc,EAHe,GAK8B,IAAvDzB,GAAsB,EAAY,AAA8B,CAA7B,CAA+B,MAAlC,CAAX,KAA2B,CAAC,CAAC,CACpD,MAAM,AAAI,KAAK,CAAC,uDAAuD,CAAC,CAG1E,IAAM,EAAcA,GAAsB,EAAY,CAAC,GAAtC,IAAmC,CAAX,CAAuB,CAAC,CAC9C,AAD+C,IAC3C,EAAE,CAArB,GACFC,GAAsB,EAAU,CAAC,EADpB,GACiB,GAAT,CAAqB,CAAC,CAAE,GAG/C,IAAM,EAAeD,EAHqC,CAGf,AAHgB,EAGJ,CAAC,IAAtC,GAAmC,CAAX,EAAwB,CAAC,CAAC,CAKpE,OAJoB,IAAI,EAApB,AAAsB,GACxBC,GAAsB,EAAU,CAAC,GADnB,EACgB,GAAT,EAAsB,CAAC,CAAE,GAGzC,CACT,EAghFsB,IAOhB,AAAwB,CAxhFb,CAH6C,CAAC,CA2hF7B,EAAE,CAH5B,CAJ0B,CAAC,AAIJD,CAH1B,EAGgD,EAAY,CAC7D,KAEsB,EAHqC,CAAX,IAAxB,MACN,CACnB,CAAC,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,UAA8B,CAAC,CAAE,GAIpD,AAAoB,IAAI,EAAE,GADLD,GAAsB,EAAY,CAAC,CACxC,CAJwD,CAAC,IAGpB,CAAX,MAA4B,CAAC,CAAC,GAE1EC,GAAsB,EAAU,CAAC,KAAH,GAAT,MAA0B,CAAC,CAAE,GAMhD,AAA2B,IAAI,EAAE,GAHLD,GAAsB,CAHc,CAAC,AAGH,CAChE,OAD8D,CAGrC,AAH0B,aAC9B,CACtB,CAAC,GAEAC,GACE,EACA,CAAC,KADO,GADW,aAEG,CAAC,CACvB,GAOA,AAAsB,IAAI,EAAE,GAHLD,GAAsB,EAAY,CAC3D,GAEoB,EAPK,CACxB,CAGwD,CAAX,QAC9B,CACjB,CAAC,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,QAA4B,CAAC,CAAE,GAMlD,AAAwB,IAAI,EAAE,GAHLD,GAAsB,EAAY,CAC7D,AAJsE,CAAC,IAMjD,EAHqC,CAAX,UAC9B,CACnB,CAAC,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,UAA8B,CAAC,CAAE,GAIpD,AAAY,IAAI,EAAE,CADhB,CACM,CADKD,GAAsB,EAAY,CAArC,AAAsC,EAHwB,CAAC,GAGnB,CAAT,AAAU,CAArB,AAAsB,GAE1DC,GAAsB,EAAU,CAAC,KAAH,CAAS,CAAC,CAAnB,AAAqB,GAGrC,GA32GF,CAAC,CAEJA,AAs2GkD,CAAC,EAt2G7B,AAy2GT,EAz2GmB,CAAC,KAAH,EAAU,CAAnB,AAAoB,CAAE,EAC5C,CAED,IAAM,EAAWD,GAAsB,EAAY,CAArC,AAH8C,AAGR,CAHS,KAGH,CAAT,AAAU,CAAC,AAAtB,CAKtC,OAJgB,IAAI,EAAhB,AAAkB,GACpBC,GAAsB,EADZ,AACsB,CAAC,KAAH,CAAS,CAAC,CAAnB,AAAqB,GAGrC,CACT,CAgxCgB,GApxCsC,CAAC,EAGtC,GAixCD,GACd,CAAoB,CACpB,CAA2C,EAAA,AAE3C,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAYD,CAFJ,EAE0B,EAAY,CAAC,CAAtC,MAA6C,AANd,AAMI,CAAX,AAAsB,CAC5C,AAD6C,IACzC,EAAE,CAAnB,GACFC,GACE,EACA,CAHS,AAGR,KADO,CACD,CAAE,CAFU,MAEH,CAAC,CACjBmB,GAAS,EAAW,CAAZ,GAIZ,GAJsB,CAIhB,CAJ2B,CAIZpB,AAJa,CAC/B,EAGwC,EAAY,CAAC,IAAtC,GAAmC,CAAX,EAAwB,CAAC,CAAC,CACpE,GAAI,AAAgB,IAAI,IAAE,CACxB,GADc,CACV,EAAkBsC,GAAY,GAC9B,GAD6B,EACxB,CAAC,CADS,EAA2B,CAAC,GAC9B,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,AAEvBrB,CADkC,CADT,CAEV,CADT,EAAkB,AAAc,AAE9C,CAD2B,AAC1B,CAD2B,AAG/BhB,GAAsB,EAAU,CAAC,EAHR,GAGK,GAAT,EAAsB,CAAC,CAAE,EAC/C,CAED,IAAM,EAAaD,GAAsB,EAAY,CAHU,AAGT,CAHU,CAGhD,KAAmC,CAAX,AAAsB,CAAC,CAAC,CAShE,OARI,AAAc,IAAI,EAAE,GACtBC,CADY,EAEV,EACA,CAAC,KADO,GADW,UAEA,CAAC,CACpB,SArdU,AACd,CAAoB,CACpB,CAAuC,CACvC,CAAqC,EAAA,AAErC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAwBD,CA8cE,AAhdlB,EAEsC,EAAY,CAC9D,IARwC,GAOoB,CAAX,KAAxB,MACN,CACpB,CAAC,MACmB,IAAjB,GAAuD,EAA7B,EAAiC,EAAE,AAA/B,GAAlB,AACdC,GACE,EACA,CAAC,QAFkB,CACP,GAFuC,OAG/B,CAAC,CACrBgB,GAAeU,GAAW,KAAD,AAI7B,IAAM,CAJY,CAIM3B,GAAsB,EAAY,CAAC,IAJR,CAAC,CAAC,CAIhC,AAHlB,AAGqD,CAAX,KAA2B,CAAC,CAAC,AACnD,IAAI,EAAE,CAAzB,GACFC,GAAsB,EAAU,CAAC,KAAH,CADb,EACI,KAAyB,CAAC,CAAE,GAGnD,IAAM,EAAWD,GAAsB,EAAY,CAHe,AAGpD,AAAsC,CAHe,KAGT,CAAT,AAAU,CAAC,AAC5C,AADsB,IAClB,EAAE,CAAlB,GACFC,GAAsB,EADZ,AACsB,CAAC,KAAH,CAAS,CAAC,CAAnB,AAAqB,GAG5C,IAAM,CAH8C,CAAC,AAGpCD,GAAsB,EAAY,CAArC,AAAsC,MAAM,CAAT,AAAU,CAArB,AAAsB,AACxD,AAAY,IAAI,EAAE,EAAV,EACVC,GAAsB,EAAU,CAAC,KAAH,CAAS,CAAC,CAAnB,AAAqB,GAG5C,IAAM,CAH8C,CAAC,AAG1BD,GAAsB,EAAY,CAC3D,OADyD,CAAX,EAAxB,MACN,CACjB,CACyB,AADxB,IAC4B,EAAE,CAA5B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,CADD,OAC6B,CAAC,CAAE,GAGtD,IAAM,EAAsBD,GAAsB,EAAY,CAC5D,GAJsE,CAAC,GAGb,CAAX,GAAxB,MACN,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAoBD,GAAsB,EAAY,CAC1D,IAJwE,CAAC,EAGjB,CAAX,CAAxB,MACN,CAChB,CAAC,AACuB,IAAI,EAAE,CAA3B,GACFC,GAAsB,EAAU,CAAC,KAAH,GADX,AACE,OAA2B,CAAC,CAAE,GAGrD,IAAM,EAAuBD,GAAsB,EAAY,CAC7D,EAJoE,CAAC,IAGV,CAAX,IAAxB,MACN,CACnB,CAC2B,AAD1B,IAC8B,EAAE,CAA9B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,GADC,OAC6B,CAAC,CAAE,GAGxD,IAAM,EAAeD,GAAsB,EAAY,CAAC,IAAtC,CAH0D,CAAC,CAGxB,CAAX,EAAwB,CAAC,CAAC,AAChE,AAAgB,IAAI,EAAE,IACxBC,EADc,CACQ,EAAU,CAAC,KAAH,GAAT,EAAsB,CAAC,CAAE,GAGhD,IAAM,EAAsBD,GAAsB,AAHU,CAAC,CAGC,CAC5D,OAD0D,CAAX,GAAxB,MACN,CAClB,CAC0B,AADzB,IAC6B,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAuBD,GAAsB,EAAY,CAC7D,IAJwE,CAAC,EAGd,CAAX,IAAxB,MACN,CACnB,CAAC,AAC0B,IAAI,EAAE,CAA9B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,GADC,OAC6B,CAAC,CAAE,GAGxD,IAAM,EAAWD,GAAsB,EAAY,CAArC,AAAsC,KAHwB,CAAC,AAGnB,CAAT,AAAU,CAArB,AAAsB,AAC5C,IAAI,EAAE,CAAlB,GACFC,GAAsB,EADZ,AACsB,CAAC,KAAH,CAAS,CAAC,CAAnB,AAAqB,GAG5C,IAAM,CAH8C,CAGvBD,AAHwB,GAGF,EAAY,CAC7D,OAD2D,CAAX,IAAxB,MACN,CACnB,CAAC,AAC0B,IAAI,EAAE,CAA9B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,GADC,OAC6B,CAAC,CAAE,GAGxD,IAAM,EAAqBD,GAAsB,EAAY,CAC3D,KAJ0E,CAAC,CAGlB,CAAX,EAAxB,MACN,CACjB,CAAC,AACwB,IAAI,EAAE,CAA5B,GACFC,GACE,EACA,CAAC,KADO,GADW,CADD,OAGD,CAAC,EAClB2B,EAAU,IAId,CAJa,GAIP,EAAyB5B,GAAsB,EAAY,CAC/D,EAL8B,CAAC,CAC9B,GAG4D,CAAX,MAAxB,MACN,CACrB,CAAC,CASF,GAR8B,AAA1B,IAA8B,EAAE,GAClCC,GACE,EACA,CAAC,KADO,EAFc,CACH,YAEE,CAAC,CACtB,QAIyD,IAAzDD,GAAsB,EAAY,AAAgC,CAA/B,CAAiC,GAJ9C,CACvB,EAGiC,CAAX,OAA6B,CAAC,CAAC,CACtD,MAAM,AAAI,KAAK,CAAC,yDAAyD,CAAC,CAG5E,QACkE,IAAhEA,GAAsB,EAAY,AAAuC,CAAtC,CACnC,MADgC,CAAX,cAAoC,CAAC,CAAC,CAE3D,MAAM,AAAI,KAAK,CACb,gEAAgE,CACjE,CAGH,IAAM,EAAqBA,GAAsB,EAAY,CAC3D,OADyD,CAAX,EAAxB,MACN,CACjB,CAAC,CACF,QAAqB,IAAjB,GAA8B,AAAsB,EAA1B,EAA8B,IAAE,CAA9C,AACd,IAAI,EAAkB,EAClB,CAF8C,IAEzC,CAAC,KADS,EACF,CAAC,EADsB,GAEtC,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,AAEvB,CADkC,AA4tF3C,CA7tFkC,EACnB,EAAkB,AAAc,IA4tFrC,AACd,CAA+B,EAAA,AAE/B,IAAM,EAAoC,CA9tFT,AA8tFS,CAAE,CAE5C,GAFc,AAEVA,KAL8B,AAKoB,OAA5B,EAAD,AAAa,AAAyB,CAAxB,CAA0B,MAA7B,CAAW,CAAC,CAAC,CAC/C,MAAM,AAAI,KAAK,CAAC,kDAAkD,CAAC,CAGrE,IAAM,EAAeA,GAAsB,EAAY,CAAC,IAAtC,GAAmC,CAAX,EAAwB,CAAC,CAAC,AAChD,IAAI,EAAE,CAAtB,GACFC,GAAsB,EAAU,CAAC,GADnB,EACgB,GAAT,EAAsB,CAAC,CAAE,GAGhD,IAAM,EAAgBD,GAHsC,AAGhB,CAHiB,CAGL,CAAC,KAAtC,EAAmC,CAAX,GAAyB,CAAC,CAAC,CAKtE,OAJqB,IAAI,EAArB,AAAuB,GACzBC,GAAsB,EAAU,CAAC,IADlB,CACe,GAAT,GAAuB,CAAC,CAAE,GAG1C,EACT,EA/uFoC,GAC7B,CADiC,AAChC,AA6uFS,CA9uFwB,AAGrCA,CAwuF4D,CAAC,CAxuFvC,EAAc,CAAC,QAAhB,CAAa,OAAmB,CAAC,CAAE,EACzD,CAED,IAAM,EAAYD,GAAsB,EAAY,CAHqB,AAGpB,CAHqB,AAG3D,MAAmC,AAAU,CAArB,AAAsB,CAAC,CAC9D,QAAqB,IAAjB,GAA2C,EAAjB,EAAqB,EAAjB,EAAmB,CACnD,AADc,IACV,EAAkB8B,AADmB,GACV,GAAD,AAC1B,KAAK,CAD+B,AAC9B,CAD+B,AAAtB,MACF,CAAC,IAChB,GAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,AAEvBC,CADkC,AA45F3C,CA75FkC,CACnB,GAAgC,AAAd,IA45FvBA,AAAY,CAAsB,EA35FxB,AA25FwB,AAChD,IAAM,EAAoC,CAAA,CAAE,CAEtC,CAHmB,CAGQ/B,CAFnB,EAEyC,EAAY,CACjE,OAD+D,CAAX,QAAxB,MACN,CACvB,CAAC,CACF,GAAgC,IAAI,EAAhC,EAAkC,CACpC,IAAI,EAAkB,EAClB,KAAK,CAAC,KADS,EADO,AAET,CAAC,KAChB,EAAkB,CAF0B,CAEV,GAAG,CAAC,AAAC,EADR,CAAC,AAEvB,CADkC,CADT,AAGjC,CAAC,CAFa,AACF,AAGfC,EAJmC,AAAc,CAI3B,EAAU,CAAC,KAAH,GAAT,cAAkC,CAAC,CAAE,EAC3D,CAED,QAAyD,IAHkB,AAGvED,CAHwE,EAGlD,EAAY,AAA4B,CAA3B,CAA6B,MAAhC,CAAX,GAAyB,CAAC,CAAC,CAClD,MAAM,AAAI,KAAK,CAAC,qDAAqD,CAAC,CAGxE,IAAM,EAAmBA,GAAsB,EAAY,CAAC,OAAH,CAAnC,AAAwB,MAA4B,CAAC,CAAC,AACpD,IAAI,EAAE,CAA1B,GACFC,GACE,EACA,CAAC,KADO,EAFQ,CACG,MAEJ,CAAC,CAChBoC,AA5jCA,SAAUA,AACd,CAA8B,EAAA,AAE9B,IAAM,EAAoC,CAAA,CAAE,CAEtC,AAujCiB,EAvjCKrC,CAFd,EAEoC,EAAY,CAC5D,CAN+B,MAK2B,CAAX,GAAxB,MACN,CAClB,CAAC,CAKF,GAJ2B,IAAI,EAA3B,AAA6B,GAC/BC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,QAGO,IAA1DD,GAAsB,EAAY,AAAiC,CAAhC,CAAkC,AAHC,CAAC,KAGvC,CAAX,QAA8B,CAAC,CAAC,CACvD,MAAM,AAAI,KAAK,CAAC,0DAA0D,CAAC,CAG7E,OAAO,CACT,EA2iC0B,IAIxB,CAhjCe,GAgjCT,EAA4BA,GAAsB,EAAY,CAClE,AALsC,CAAC,CACtC,KAG+D,CAAX,SAAxB,MACN,CACxB,CAAC,CASF,GARiC,IAAI,EAAE,AAAnC,GACFC,GACE,EACA,CAAC,KADO,GADW,QADM,OAGD,CAAC,CACzB,GAK6D,SAA/DD,AAAwE,EACxE,CADsB,EAAY,CAAC,OAAH,AALL,CAKN,AAJpB,aAIuD,CAAC,CAAC,CAE1D,MAAM,AAAI,KAAK,CACb,+DAA+D,CAChE,CAGH,IAAM,EAAiBA,GAAsB,EAAY,CAAC,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,AAClD,IAAI,EAAE,CAAxB,GACFC,GACE,EACA,CAAC,KAHa,AAEN,GADW,IAEN,CAAC,CACdmC,AAzmCA,SAAUA,AACd,CAA4B,EAAA,AAE5B,IAAM,EAAoC,CAAA,AAsmCrB,CAtmCuB,CAE5C,GAFc,IAHiB,CAK2B,IAAtDpC,GAAsB,EAAY,AAA6B,CAA5B,CAA8B,MAAjC,CAAX,IAA0B,CAAC,CAAC,CACnD,MAAU,AAAJ,KAAS,CAAC,sDAAsD,CAAC,CAGzE,IAAM,EAAmBA,GAAsB,EAAY,CAAC,OAAH,CAAnC,AAAwB,MAA4B,CAAC,CAAC,CAK5E,OAJwB,IAAI,EAAxB,AAA0B,GAC5BC,GAAsB,EAAU,CAAC,KAAH,EADZ,CACG,MAA0B,CAAC,CAAE,GAG7C,CACT,EA0lCwB,IAItB,CA/lCe,GA+lCT,EAAiBD,AAlmC6C,CAAC,EAkmCxB,CAJT,CAAC,AAIoB,CAHtD,AAGuD,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,AAClD,AAAlB,IAAsB,EAAE,IAC1BC,GAAsB,CADN,CACgB,CAAC,KAAH,GAAT,IAAwB,CAAC,CAAE,GAGlD,IAAM,EAAkBD,GAAsB,EAAY,AAHM,CAAC,AAGN,OAAtC,AAAmC,CAAX,KAA2B,CAAC,CAAC,AACnD,IAAI,EAAE,CAAzB,GACFC,GAAsB,EAAU,CAAC,KAAH,CADb,EACI,KAAyB,CAAC,CAAE,GAGnD,IAAM,EAAoBD,GAAsB,EAAY,CAHM,AAIhE,CAJiE,MAGT,CAAX,CAAxB,MACN,CAChB,CAAC,CAKF,OAJyB,IAAI,EAAzB,AAA2B,GAC7BC,GAAsB,EAAU,CAAC,KAAH,GADX,AACE,OAA2B,CAAC,CAAE,GAG9C,EACT,EAt+F2B+B,GAAQ,CAq+FlB,CAr+FiB,EAC3B,AADgC,CAAC,AAChC,CADiC,AAGrC/B,CA+9FoE,CAAC,CA/9F/C,EAAc,CAAC,OAAO,CAAvB,AAAwB,CAAX,AAAa,EAChD,CAED,IAAM,EAAiBD,GAAsB,EAAY,CAAC,AAHM,CAAC,KAG7C,CAAmC,CAAX,IAA0B,CAAC,CAAC,CAKxE,QAJqB,IAAjB,GAAgD,EAAtB,EAA0B,EAAtB,AAAwB,GAA1C,AACdC,GAAsB,EAAc,CAAC,KADS,GACzB,CAAa,GAAe,CAAC,CAAE,QAGA,IAAlDD,EAHgE,CAG1C,AAH2C,EAG/B,AAAyB,CAAxB,CAA0B,MAA7B,CAAW,AAAtB,CAAuB,CAAC,CAC/C,MAAM,AAAI,KAAK,CAAC,kDAAkD,CAAC,CAGrE,IAAM,EAAoBA,GAAsB,EAAY,CAC1D,OADwD,CAAX,CAAxB,MACN,CAChB,CAAC,MACmB,IAAjB,GAAmD,EAAzB,EAA6B,EAAzB,AAA2B,GAA7C,AACdC,GACE,EACA,CAAC,QAH8C,AAC5B,CACP,MACI,CAAC,CACjBgC,GAAqB,EAAW,IAIpC,GAJkC,CAI5B,EAAyBjC,GAJP,AAI6B,EAAY,CAC/D,CALmD,CAAC,CACnD,IAG4D,CAAX,MAAxB,MACN,CACrB,CAAC,AACE,AAA0B,IAAI,EAAE,IAClCC,GACE,EACA,CAAC,KADO,CAFc,EACH,YAEE,CAAC,CACtB,GAIJ,IAAM,EAAsBD,GAAsB,EAAY,CAC5D,OAD0D,AAJlC,CACvB,AAG8C,GAAxB,MACN,CAClB,CAAC,AACE,AAAuB,IAAI,EAAE,IAC/BC,GAAsB,EAAU,CAAC,GADZ,EACS,GAAT,SAA6B,CAAC,CAAE,GAGvD,IAAM,EAAmBD,GAAsB,EAAY,CAAC,IAHc,CAAC,EAGlB,CAAnC,AAAwB,MAA4B,CAAC,CAAC,CAS5E,GARwB,IAAI,EAAxB,AAA0B,GAC5BC,GACE,EACA,CAAC,KADO,EAFQ,CACG,MAEJ,CAAC,CAChBiC,GAAgB,IAI0C,MAJ3C,GAIflC,AAAmE,EAAE,CAJrC,AAIV,CAJW,CAClC,AAGmC,CAAC,OAAH,CAAX,QAA8B,CAAC,CAAC,CACvD,MAAM,AAAI,KAAK,CAAC,0DAA0D,CAAC,CAG7E,IAAM,EAAqBA,GAAsB,EAAY,CAC3D,OADyD,CAAX,EAAxB,MACN,CACjB,CACyB,AADxB,IAC4B,EAAE,CAA5B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,CADD,OAC6B,CAAC,CAAE,GAGtD,IAAM,EAAkBD,GAAsB,EAAY,CAAC,GAHa,CAAC,GAGpD,AAAmC,CAAX,KAA2B,CAAC,CAAC,CAK1E,OAJuB,IAAI,EAAvB,AAAyB,GAC3BC,GAAsB,EAAU,CAAC,KAAH,CADb,EACI,KAAyB,CAAC,CAAE,GAG5C,CACT,EA+PmC,EAAW,EAAY,CAhQzC,GAoQR,CAJmC,AAK5C,AAxQoE,CA0QpD,AA1QqD,EAmQH,AAAV,CAAW,CAC9D,EAGY,GAGD,GACd,CAAoB,CACpB,CAA2C,EAAA,AAE3C,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAYD,CAFJ,EAE0B,EAAY,CAAC,CAAtC,MAAmC,AAAU,CAArB,AAAsB,AANd,CAMe,AAC7C,IAAI,EAAE,CAAnB,GACFC,GACE,EACA,CAHS,AAGR,KADO,CACD,CAAE,CAFU,MAEH,CAAC,CACjBmB,GAAS,EAAW,CAAZ,GAIZ,GAJsB,CAIhB,CAJ2B,CAAC,AAIbpB,CAHlB,EAGwC,EAAY,CAAC,IAAtC,GAAmC,CAAX,EAAwB,CAAC,CAAC,CACpE,GAAoB,IAAI,EAApB,EAAsB,CACxB,IAAI,EAAkBsC,GAAY,AADpB,GAEV,GAD6B,EACxB,CAAC,CADS,EAA2B,CAAC,GAC9B,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,AAEvB,CADkC,CADT,AAGjC,CAAC,CADW,AAGfrC,AAJiB,EAAgC,AAAd,CAIb,EAAU,CAAC,KAAH,GAAT,EAAsB,CAAC,CAAE,EAC/C,CAED,IAAM,EAAaD,GAAsB,EAAY,CAHU,AAGT,CAHU,CAGhD,KAAmC,CAAW,AAAtB,CAAuB,CAAC,CAShE,OARkB,AAAd,IAAkB,EAAE,GACtBC,CADY,EAEV,EACA,CAAC,KADO,GADW,UAEA,CAAC,CACpB,SAlSJ,AADc,CACM,CACpB,CAAuC,CACvC,CAAqC,EAAA,AAErC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAwBD,CAFhB,CA8RmB,CA5RmB,EAAY,CAC9D,KARyC,EAOmB,CAAX,KAAxB,MACN,CACpB,CAAC,AACE,MAAiB,MAAL,CAAkB,AAAyB,EAA7B,EAAiC,EAAE,GAC/DC,GACE,EACA,CAAC,MAHkD,EAChC,CACP,UACQ,CAAC,CACrB0B,GAAW,IAIf,CAJc,GAIR,EAAkB3B,GAAsB,EAAY,CAAC,KAJvB,CAAC,CAClC,AAGkB,AAAmC,CAAX,KAA2B,CAAC,CAAC,AACtE,AAAmB,IAAI,EAAE,IAC3BC,GAAsB,EADL,AACe,CAAC,KAAH,GAAT,KAAyB,CAAC,CAAE,GAGnD,IAAM,EAAWD,GAAsB,EAAY,CAArC,AAHoD,AAGd,CAHe,KAGT,CAAT,AAAU,CAArB,AAAsB,AACxD,AAAY,IAAI,EAAE,EAAV,EACVC,GAAsB,EAAU,CAAC,KAAH,CAAS,CAAC,CAAnB,AAAqB,GAG5C,IAAM,CAH8C,CAAC,AAGpCD,GAAsB,EAAY,CAArC,AAAsC,MAAM,CAAT,AAAU,CAArB,AAAsB,AAC5C,IAAI,EAAE,CAAlB,GACFC,GAAsB,EADZ,AACsB,CAAC,KAAH,CAAS,CAAC,CAAnB,AAAqB,GAG5C,IAAM,CAH8C,CAAC,AAG1BD,GAAsB,EAAY,CAC3D,OADyD,CAAX,EAAxB,MACN,CACjB,CAAC,AACwB,IAAI,EAAE,CAA5B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,CADD,OAC6B,CAAC,CAAE,GAGtD,IAAM,EAAsBD,GAAsB,EAAY,CAC5D,GAJsE,CAAC,GAGb,CAAX,GAAxB,MACN,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAoBD,GAAsB,EAAY,CAC1D,IAJwE,CAAC,EAGjB,CAAX,CAAxB,MACN,CAChB,CAAC,AACE,AAAqB,IAAI,EAAE,IAC7BC,GAAsB,EAAU,CAAC,CADd,IACW,GAAT,OAA2B,CAAC,CAAE,GAGrD,IAAM,EAAuBD,GAAsB,EAAY,CAC7D,EAJoE,CAAC,IAGV,CAAX,IAAxB,MACN,CACnB,CAC2B,AAD1B,AACE,IAA4B,EAAE,IAChCC,GAAsB,EAAU,CAAC,IADX,CACQ,GAAT,UAA8B,CAAC,CAAE,GAGxD,IAAM,EAAeD,GAAsB,EAAY,CAAC,IAAtC,CAH0D,CAAC,CAGxB,CAAX,EAAwB,CAAC,CAAC,AAChE,AAAgB,IAAI,EAAE,IACxBC,EADc,CACQ,EAAU,CAAC,KAAH,GAAT,EAAsB,CAAC,CAAE,GAGhD,IAAM,EAAsBD,GAHgC,AAGV,CAHW,CAGC,CAC5D,OAD0D,CAAX,GAAxB,MACN,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAuBD,GAAsB,EAAY,CAC7D,IAJwE,CAAC,EAGd,CAAX,IAAxB,MACN,CACnB,CAAC,AAC0B,IAAI,EAAE,CAA9B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,GADC,OAC6B,CAAC,CAAE,GAGxD,IAAM,EAAWD,GAAsB,EAAY,CAArC,AAAsC,KAHwB,CAAC,AAGnB,CAAT,AAAU,CAArB,AAAsB,AAC5C,IAAI,EAAE,CAAlB,GACFC,GAAsB,EADZ,AACsB,CAAC,KAAH,CAAS,CAAC,CAAE,AAArB,GAGvB,IAAM,CAH8C,CAAC,AAGxBD,GAAsB,EAAY,CAC7D,OAD2D,CAAX,IAAxB,MACN,CACnB,CAAC,AAC0B,IAAI,EAAE,CAA9B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,GADC,OAC6B,CAAC,CAAE,GAGxD,IAAM,EAAqBD,GAAsB,EAAY,CAC3D,KAJ0E,CAAC,CAGlB,CAAX,EAAxB,MACN,CACjB,CAAC,AACwB,IAAI,EAAE,CAA5B,GACFC,GACE,EACA,CAAC,KADO,GADW,CADD,OAGD,CAAC,CXn+Bf,CWo+BH2B,EAAU,IAId,CAJa,GAIP,EAAyB5B,GAAsB,CXx+B7B,CWw+ByC,AXx+BxC,CWy+BvB,EAL8B,CAAC,CAC9B,CXr+B4C,CAAC,CWw+Be,CAAX,MAAxB,MACN,CACrB,CAC6B,AAD5B,IACgC,EAAE,CAAhC,GACFC,GACE,EACA,CAAC,KADO,GADW,KADG,OAGD,CAAC,CACtB,GAIJ,IAAM,EAAoBD,GAAsB,EAAY,CAC1D,OADwD,AAJhC,CAIqB,AAH5C,CAGoB,MACN,CAChB,CAAC,AACuB,IAAI,EAAE,CAA3B,GACFC,GAAsB,EAAU,CAAC,KAAH,GADX,AACE,OAA2B,CAAC,CAAE,GAGrD,IAAM,EAA2BD,GAAsB,EAAY,CACjE,EAJoE,CAAC,IAGN,CAAX,QAAxB,MACN,CACvB,CAAC,AAC8B,IAAI,EAAE,CAAlC,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,KAAyB,CAAC,CAAE,AADvB,GAI5B,IAAM,EAAqBD,GAAsB,EAAY,CAC3D,OADyD,CAAX,CAH2B,CAGnD,AAHoD,MAI1D,CACjB,CAAC,CACF,QAAqB,IAAjB,GAAoD,EAA1B,EAA8B,EAA1B,EAA4B,CAC5D,AADc,IACV,EAAkB,EAClB,KAAK,CAAC,CAFwC,IAC/B,EACF,CAAC,EADsB,GAEtC,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,AAEvB,CADkC,CADT,AAGjC,CAAC,CAFa,AAIjBC,AAHe,EADkC,AAAd,CAIb,EAAc,CAAC,QAAhB,CAAa,OAAmB,CAAC,CAAE,EACzD,CAED,IAAM,EAAYD,GAAsB,EAAY,CAHqB,AAGpB,CAHqB,AAG3D,MAAmC,AAAU,CAArB,AAAsB,CAAC,CAC9D,QAAqB,IAAjB,GAA2C,EAAjB,EAAqB,EAAjB,EAAmB,CAArC,AACd,IAAI,EADqC,AACnB8B,GAAS,GAAD,AAC1B,KAAK,CAD+B,AAC9B,CADS,AAAsB,MACxB,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAEtB,AAFuB,CACW,CADT,CAEZE,CADP,EACe,AADiB,AAAd,EACJ,EAAK,AACjC,CADkC,AACjC,CADmB,AAAe,AAGtC/B,GAAsB,EAAc,CAAC,OAAO,CAAvB,AAAwB,CAAX,AAAa,EAChD,CAED,IAAM,EAAiBD,GAAsB,EAAY,CAAC,AAHM,CAAC,KAG7C,CAAmC,CAAX,IAA0B,CAAC,CAAC,MACnD,IAAjB,GAAgD,EAAtB,EAA0B,EAAtB,AAAwB,GACxDC,AADc,GACQ,EAAc,CAAC,KADS,GACzB,CAAa,GAAe,CAAC,CAAE,GAGtD,IAAM,EAAaD,GAAsB,EAH2B,AAGf,CAHgB,AAGf,EAAtC,KAAmC,CAAX,AAAsB,CAAC,CAAC,AAC5D,MAAiB,MAAL,CAAgC,EAAlB,EAAsB,EAAlB,AAAoB,GACpDC,GAAsB,EAAc,CAAC,CADK,OACrB,AAAwB,CAAX,AAAY,CAAE,GAGlD,IAAM,EAAoBD,CAHkC,CAAC,CAGb,EAAY,CAC1D,OADwD,CAAX,CAAxB,MACN,CAChB,CAAC,MACmB,IAAjB,GAAmD,EAAzB,EAA6B,EAAE,AAA3B,GAChCC,AADc,GAEZ,EACA,CAAC,QAH8C,AAC5B,CACP,MACI,CAAC,CACjBgC,GAAqB,EAAW,IAIpC,GAJkC,CAI5B,EAAyBjC,GAJP,AAI6B,EAAY,CAC/D,CALmD,CAAC,CACnD,IAG4D,CAAX,MAAxB,MACN,CACrB,CAAC,AAC4B,IAAI,EAAE,CAAhC,GACFC,GACE,EACA,CAAC,KADO,GADW,KADG,OAGD,CAAC,CACtB,GAIJ,IAAM,EAAsBD,GAAsB,EAAY,CAC5D,OALwB,AAIkC,CAAX,AAH9C,GAGsB,MACN,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAmBD,GAAsB,EAAY,CAAC,IAHc,CAAC,EAGlB,CAAnC,AAAwB,MAA4B,CAAC,CAAC,AACpD,IAAI,EAAE,CAA1B,GACFC,GACE,EACA,CAAC,KADO,EAFQ,CACG,MAEJ,CAAC,CAChB,GAAqBiC,GAAgB,KAIzC,IAAM,CAJkC,CAIblC,GAJH,AAIyB,EAJQ,AAII,CAJH,AAKxD,CALyD,CACxD,KAGwD,CAAX,EAAxB,MACN,CACjB,CAAC,AACwB,IAAI,EAAE,CAA5B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,CADD,OAC6B,CAAC,CAAE,GAGtD,IAAM,EAAqBD,GAAsB,EAAY,CAC3D,GAJsE,CAAC,GAGd,CAAX,EAAxB,MACN,CACjB,CACG,AAAsB,AADxB,IAC4B,EAAE,IAC9BC,GAAsB,EAAU,CAAC,EADb,GACU,GAAT,QAA4B,CAAC,CAAE,GAGtD,IAAM,EAAkBD,GAAsB,EAAY,CAAC,GAHa,CAAC,GAGpD,AAAmC,CAAX,KAA2B,CAAC,CAAC,CAK1E,OAJuB,IAAI,EAAvB,AAAyB,GAC3BC,GAAsB,EAAU,CAAC,KAAH,CADb,EACI,KAAyB,CAAC,CAAE,GAG5C,CACT,EAuEoC,EAAW,EAAY,CAxE1C,GA4ER,CA/E2D,AA2EvB,AAK7C,CAhFqE,AAkF/D,EAPmD,AAAU,CAAC,CAC/D,EAGY,GAGD,GACd,CAAyC,EAAA,AAEzC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAsBD,CAFd,EAEoC,EAAY,CAC5D,OAD0D,CAAX,CALH,EAKrB,MACN,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAiBD,GAAsB,EAAY,CAAC,IAHgB,CAAC,CAGvD,CAAmC,CAAX,IAA0B,CAAC,CAAC,CACxE,GAAsB,IAAI,EAAtB,EAAwB,CAC1B,IAAI,EAAkB,EAClB,GAFY,EAEP,CAAC,KADS,CAAiB,CACnB,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAE,AAAD,EADP,CAEtB,AAFuB,AAzkDhC,CA0kD2C,CADT,EACnB,EAAgC,AAAd,GA1kDvB,CACd,CAA2B,EAAA,AAE3B,IAAM,CAwkDyB,CAxkDW,CAAA,CAAE,CAEtC,EAAcA,CAFN,EAHkB,AAKU,EAAY,CAAC,GAAtC,IAAmC,CAAX,CAAuB,CAAC,CAC9C,AAD+C,AAC9D,IAAmB,EAAE,IACvBC,CADa,EACS,EAAU,CAAC,KAAH,GAAT,CAAqB,CAAC,CAAE,GAG/C,IAAM,EAAuBD,EAH6B,CAAC,AAGR,EAAY,CAC7D,OAD2D,CAAX,IAAxB,MACN,CACnB,CAAC,AAC0B,IAAI,EAAE,CAA9B,GACFC,GACE,EACA,CAAC,KADO,GADW,GADC,OAGD,CAAC,CAsEpB,AArEA,SAqEU,AACd,CAAkC,EAAA,AAElC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAgBD,CAFR,CAxEe,CA0Ee,EAAY,CAAC,KALlB,AAKpB,EAAmC,CAAX,SAA+B,CAAC,CAAC,CAC5E,GAAqB,IAAI,EAArB,EAAuB,CACzB,IAAI,EAAkB,EAClB,EAFW,GAEN,CAAC,KADyB,AAAhB,EACF,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAEtB,AAFuB,CACW,CADT,AAGjC,CAAC,CAFa,AACF,AAGfC,EAJmC,AAAc,CAI3B,EAAU,CAAC,KAAH,GAAT,GAAuB,CAAC,CAAE,EAChD,CAED,OAAO,CACT,EAtFgC,EAkFkC,CAAC,CA9EjE,CAiFe,GAjFT,EAAiBD,GAAsB,EAAY,CAAC,IAJR,CAAC,CAChD,AAGiB,CAAmC,CAAX,IAA0B,CAAC,CAAC,AACpE,AAAkB,IAAI,EAAE,IAC1BC,GAAsB,CADN,CACgB,CAAC,KAAH,GAAT,IAAwB,CAAC,CAAE,GAGlD,IAAM,EAAmBD,GAAsB,EAHiB,AAGL,CAHM,AAGL,OAAH,CAAnC,AAAwB,MAA4B,CAAC,CAAC,AACpD,IAAI,EAAE,CAA1B,GACFC,GAAsB,EAAU,CAAC,KAAH,EADZ,CACG,MAA0B,CAAC,CAAE,GAGpD,IAAM,EAAyBD,GAAsB,EAAY,CAC/D,CAJkE,CAAC,KAGN,CAAX,MAAxB,MACN,CACrB,CAAC,AAC4B,IAAI,EAAE,CAAhC,GACFC,GACE,EACA,CAAC,KADO,GADW,KADG,OAGD,CAAC,CACtB,GAIJ,IAAM,EAAkBD,GAAsB,EAAY,CAAC,OAJjC,AAIL,AAAmC,CAHrD,AAG0C,KAA2B,CAAC,CAAC,AACnD,IAAI,EAAE,CAAzB,GACFC,GAAsB,EAAU,CAAC,KAAH,CADb,EACI,KAAyB,CAAC,CAAE,GAGnD,IAAM,EAAwBD,GAAsB,EAAY,CAHE,AAIhE,CAJiE,MAGL,CAAX,KAAxB,MACN,CACpB,CAAC,AAC2B,IAAI,EAAE,CAA/B,GACFC,GACE,EACA,CAAC,KADO,GADW,IADE,OAGD,CAAC,CACrB,GAIJ,IAAM,EAAYD,GAAsB,EAAY,CAAC,CAAtC,KAJU,CAImC,AAAV,AAH/C,CAGoC,AAAsB,CAAC,AAC7C,IAAI,EAAE,CAAnB,GACFC,GAAsB,EAAU,CADrB,AACsB,KAAH,EAAU,CAAnB,AAAoB,CAAE,GAG7C,IAAM,EAHgD,AAG3BD,CAH4B,EAGN,EAAY,CAC3D,OADyD,CAAX,EAAxB,MACN,CACjB,CACyB,AADxB,AACE,IAA0B,EAAE,IAC9BC,GAAsB,EAAU,CAAC,EADb,GACU,GAAT,QAA4B,CAAC,CAAE,GAGtD,IAAM,EAAoBD,GAAsB,EAAY,CAC1D,GAJsE,CAAC,GAGf,CAAX,CAAxB,MACN,CAChB,CAAC,CACF,GAAyB,IAAI,EAAzB,EAA2B,CAC7B,IAAI,EAAkB,EAClB,KAAK,CAAC,AAFS,KACA,EACF,CAAC,CADqB,IAErC,EAAkB,EAAgB,GAAG,CAAE,AAAD,EADP,CAAC,AAEvB,CADkC,CAE1C,AAHiC,CAGhC,CAFa,AAIjBC,AAHe,EADoB,AAAc,CAI3B,EAAU,CAAC,KAAH,GAAT,OAA2B,CAAC,CAAE,EACpD,CAED,OAAO,CACT,GAu/CkC,CA3/CoC,CAAC,CA4/ChE,CAz/CU,AAw/CqB,AAC9B,CAEJA,AAHmC,GAGb,EAAU,CAAC,KAAH,GAAT,IAAwB,CAAC,CAAE,EACjD,CAED,IAAM,EAAmBD,GAAsB,EAAY,CAAC,AAHK,CAAC,MAGT,CAAnC,AAAwB,MAA4B,CAAC,CAAC,AACxE,AAAoB,IAAI,EAAE,IAC5BC,GAAsB,EAAU,CADd,AACe,KAAH,GAAT,MAA0B,CAAC,CAAE,GAGpD,IAAM,EAAqBD,GAAsB,EAAY,CAC3D,CAJkE,CAAC,KAGV,CAAX,EAAxB,MACN,CACjB,CAAC,AACwB,IAAI,EAAE,CAA5B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,CADD,OAC6B,CAAC,CAAE,GAGtD,IAAM,EAAiBD,GAAsB,EAAY,CAAC,GAHc,CAAC,EAGrD,CAAmC,CAAX,IAA0B,CAAC,CACjD,AAAlB,AADoE,IAC9C,EAAE,IAC1BC,GAAsB,CADN,CACgB,CAAC,KAAH,GAAT,IAAwB,CAAC,CAAE,GAGlD,IAAM,EAAoBD,GAAsB,EAHgB,AAGJ,CAHK,AAI/D,OADwD,CAAX,CAAxB,MACN,CAChB,CAAC,CAKF,OAJyB,IAAI,EAAzB,AAA2B,GAC7BC,GAAsB,EAAU,CAAC,KAAH,GADX,AACE,OAA2B,CAAC,CAAE,GAG9C,CACT,CAEM,MAHW,GAGD,GANwD,AAOtE,CAPuE,AAO9B,EAAA,AAEzC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAsBD,CAFd,EAEoC,EAAY,CAC5D,OAD0D,CAAX,EALF,CAKtB,MACN,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAiBD,GAAsB,EAAY,CAAC,IAHgB,CAAC,CAGvD,CAAmC,CAAX,IAA0B,CAAC,CAAC,CACxE,GAAsB,IAAI,EAAtB,EAAwB,CAC1B,IAAI,EAAkB,EAClB,GAFY,EAEP,CAAC,KADS,CAAiB,CACnB,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,AAEvB,CADkC,CADT,AAGjC,CAAC,CAFa,AACF,AAGfC,EAJmC,AAAc,CAI3B,EAAU,CAAC,KAAH,GAAT,IAAwB,CAAC,CAAE,EACjD,CAED,IAAM,EAAiBD,GAAsB,EAAY,CAHQ,AAGP,CAHQ,KAG9C,CAAmC,CAAX,IAA0B,CAAC,CAAC,AACpE,AAAkB,IAAI,EAAE,IAC1BC,GAAsB,CADN,CACgB,CAAC,KAAH,GAAT,IAAwB,CAAC,CAAE,GAGlD,IAAM,EAAmBD,GAAsB,EAAY,AAHK,CAAC,AAGL,OAAH,CAAnC,AAAwB,MAA4B,CAAC,CACnD,AADoD,AACxE,IAAwB,EAAE,IAC5BC,GAAsB,EAAU,CAAC,AADf,KACY,GAAT,MAA0B,CAAC,CAAE,GAGpD,IAAM,EAAqBD,GAAsB,EAAY,CAC3D,CAJkE,CAAC,KAGV,CAAX,EAAxB,MACN,CACjB,CAAC,AACwB,IAAI,EAAE,CAA5B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,CADD,OAC6B,CAAC,CAAE,GAGtD,IAAM,EAAiBD,GAAsB,EAAY,CAAC,GAHc,CAAC,EAGrD,CAAmC,CAAX,IAA0B,CAAC,CAAC,AAClD,IAAI,EAAE,CAAxB,GACFC,GAAsB,EAAU,CAAC,KADjB,AACc,GAAT,IAAwB,CAAC,CAAE,GAGlD,IAAM,EAAoBD,GAAsB,EAHgB,AAGJ,CAC1D,AAJ+D,OAGP,CAAX,CAAxB,MACN,CAChB,CAAC,CAKF,OAJyB,IAAI,EAAzB,AAA2B,GAC7BC,GAAsB,EAAU,CAAC,KAAH,GADX,AACE,OAA2B,CAAC,CAAE,GAG9C,CACT,CAmmCM,MApmCW,GAomCD,GAvmCwD,AAwmCtE,CAxmCuE,AAwmCvC,EAAA,AAEhC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAYD,CAFJ,EAE0B,EAAY,CAAC,CAAtC,AALuB,MAKY,AAAU,CAArB,AAAsB,CAAC,AAC7C,IAAI,EAAE,CAAnB,GACFC,GAAsB,EAAU,CAAC,AADtB,KACmB,EAAU,CAAnB,AAAoB,CAAE,GAAgB,IAG7D,IAAM,CAHgE,CAAC,AAGzCD,CAH0C,CAAZ,CAGR,EAAY,CAC9D,OAD4D,CAAX,KAAxB,MACN,CACpB,CAAC,AAC2B,IAAI,EAAE,CAA/B,GACFC,GACE,EACA,CAAC,KADO,GADW,IADE,OAGD,CAAC,CACrB,GAIJ,IAAM,EAAuBD,GAAsB,EAAY,CAAC,MAJvC,CACtB,AAG0D,AAAU,CAArB,AAAsB,CAAC,AAC7C,GADF,CACM,EAAE,CAA9B,GACFC,GACE,EACA,CAAC,KADO,GADW,GADC,OAGD,CAAC,CACpB,GAA2B,IAI/B,IAAM,EAAqBD,GAAsB,EAAY,CAAC,IAJX,CAAC,CACjD,CAGwD,AAJ7B,CAIwC,AAAtB,CAAuB,CAAC,AAAhD,CAKxB,OAJ0B,IAAI,EAA1B,AAA4B,GAC9BC,GAAsB,EAAU,CAAC,KAAH,GAAT,CADD,OAC6B,CAAC,CAAE,GAG/C,CACT,CA+TM,MAhUW,GAgUD,GACd,CAAuB,AApUiD,CAAC,CAoUlD,AAEvB,IAAM,EAAoC,CAAA,CAAE,CAHf,AAKvB,EAAaD,CAFL,EAE2B,EAAY,CAAC,EAAtC,KAAmC,CAAW,AAAtB,CAAuB,CAAC,AAC9C,IAAI,EAAE,CAApB,GACFC,GAAsB,EAAU,CAAC,CADrB,IACkB,GAAT,AAAoB,CAAC,CAAE,GAG9C,IAAM,EAAiBD,CAHiC,CAAC,CAGZ,EAAY,CACvD,MADkB,CAAmC,CAAX,YACtB,CACrB,CAAC,AACoB,IAAI,EAAE,CAAxB,GACFC,GAAsB,EAAU,CAAC,KADjB,AACc,GAAT,IAAwB,CAAC,EAAEO,EAAS,IAAD,AAG1D,IAAM,EAAeR,GAAsB,CAH8B,CAAC,AAGnB,CAHoB,AAGnB,IAAtC,GAAmC,CAAX,EAAwB,CAAC,CAAC,CAKpE,OAJoB,AAAhB,IAAoB,EAAE,GACxBC,GAAsB,AADR,EACkB,CAAC,KAAH,GAAT,EAAsB,CAAC,CAAE,GAGzC,CACT,CAEM,MAHW,CAH6C,CAAC,CAM/C,GAAa,CAAuB,EAClD,AADkD,IAC5C,EAAoC,AADhB,CACgB,CAAE,CAE5C,GAFc,KAEwC,IAAlDD,GAAsB,EAAY,AAAyB,CAAxB,CAA0B,MAA7B,CAAX,AAAsB,CAAC,CAAC,CAC/C,MAAU,AAAJ,KAAS,CAAC,kDAAkD,CAAC,CAGrE,IAAM,EAAiBA,GAAsB,EAAY,CAAC,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,AAClD,IAAI,EAAE,CAAxB,GACFC,GACE,EACA,CAAC,KADO,AAFM,GACK,YAEE,CAAC,EACtBO,EAAS,IAAD,AAIZ,IAAM,EAAeR,GAAsB,CAJhB,CAAC,AAI2B,CAHpD,AAGqD,IAAtC,GAAmC,CAAX,EAAwB,CAAC,CAAC,CAKpE,OAJoB,IAAI,EAApB,AAAsB,GACxBC,GAAsB,EAAU,CAAC,GADnB,EACgB,GAAT,EAAsB,CAAC,CAAE,GAGzC,CACT,CAEM,MAHW,CAH6C,CAAC,CAM/C,GACd,CAAuB,EAAA,AAEvB,IAAM,EAAoC,CAHf,AAGe,CAAE,CAEtC,EAAaD,CAFL,EAE2B,EAAY,CAAC,EAAtC,KAAmC,CAAW,AAAtB,CAAuB,CAAC,AAC9C,IAAI,EAAE,CAApB,GACFC,GAAsB,EAAU,CAAC,CADrB,IACkB,GAAT,AAAoB,CAAC,CAAE,GAG9C,IAAM,EAAiBD,CAHiC,CAAC,CAGZ,EAAY,CAAC,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,AAClD,IAAI,EAAE,CAAxB,GACFC,GACE,EACA,CAAC,KADO,AAFM,GACK,YAEE,CAAC,EACtBO,EAAS,IAAD,AAIZ,IAAM,EAAeR,GAAsB,CAJhB,CAAC,AAI2B,CAHpD,AAGqD,IAAtC,GAAmC,CAAX,EAAwB,CAAC,CAAC,CAKpE,OAJoB,IAAI,EAAE,AAAtB,GACFC,GAAsB,EAAU,CAAC,GADnB,EACgB,GAAT,EAAsB,CAAC,CAAE,GAGzC,CACT,CA6LM,MA9LW,CAH6C,CAAC,CAiM/C,GACd,CAAuB,EAAA,IA24BvB,EAz4BA,EAH4B,IAg5BtB,EAJ0B,AAS1B,EAKA,AAd0B,EAz4B1B,EAAoC,CAAA,CAAE,CAEtC,EA24Ba,AA34BFD,CAFH,EAk5BM,AAh5BmB,EAAY,AAq5B/B,CAr5BgC,AAAtC,MAA4C,CAAT,AAAU,CAC3C,AAD4C,AAAtB,IAClB,EAAE,CAAlB,GACFC,GAAsB,EADZ,AACsB,CAAC,KAAH,CAAS,CAAC,CAAnB,AAAqB,GAG5C,IAAM,CAH8C,CAAC,AAG7BD,GAAsB,EAAY,CAAC,OAAtC,AAAmC,CAAX,KAA2B,CAAC,CAClD,AADmD,AACtE,IAAuB,EAAE,IAC3BC,GAAsB,EADL,AACe,CAAC,KAAH,GAAT,KAAyB,CAAC,CAAE,GAGnD,IAAM,EAAkBD,GAAsB,EAAY,CAAC,AAHO,CAAC,MAG9C,AAAmC,CAAX,KAA2B,CAAC,CAAC,AACnD,IAAI,EAAE,CAAzB,GACFC,GAAsB,EAAU,CAAC,KAAH,CADb,EACI,KAAyB,CAAC,CAAE,GAGnD,IAAM,EAAcD,GAAsB,EAAY,CAAC,AAHW,CAAC,EAGlD,IAAmC,CAAX,CAAuB,CAAC,CAAC,AAC/C,IAAI,EAAE,CAArB,GACFC,GAAsB,EAAU,CAAC,EADpB,GACiB,GAAT,CAAqB,CAAC,CAAE,GAG/C,IAAM,EAAqBD,EAH+B,CAAC,AAGV,EAAY,CAAC,OAAO,AAAV,CAAW,AAAtB,CAAuB,AAC7C,CADF,GACM,EAAE,CAA5B,GACFC,GACE,EACA,CAAC,KADO,GADW,CADD,OAGD,CAAC,EAClB,AAg3BE,EAAoC,CAAA,CAAE,CAGxC,AAAiB,GAHP,CAGW,EAAE,GADLD,IACL,CAn3BW,EAk3B4B,CAAC,CAl3B9B,KAk3BgB,CAAC,IAAwB,CAAC,CAAC,EAl3BxB,CAAC,AAo3B7CC,CAFoD,AAj3BnD,EAm3BqB,EAAU,CAAC,KAAH,GAAT,GAAuB,CAAC,CAAE,GAI7C,AAAkB,IAAI,EAAE,GADLD,CAHuC,CAAC,CAGlB,EAAY,AACvC,CADwC,OAAH,CAAX,IAA0B,CAAC,CAAC,GAEtEC,GAAsB,EAAU,CAAC,KAAH,GAAT,IAAwB,CAAC,CAAE,GAI9C,AAAkB,IAAI,EAAE,GADLD,EAHyC,CAAC,AAGpB,EAAY,AACvC,CADwC,OAAH,CAAX,IAA0B,CAAC,CAAC,GAEtEC,GAAsB,EAAU,CAAC,KAAH,GAAT,IAAwB,CAAC,CAAE,GAG3C,IA73BP,IAAM,AA63BS,EA73BaD,CA03BoC,CAAC,CA13Bf,EAAY,CAC5D,OAD0D,CAAX,GAAxB,MACN,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAuBD,GAAsB,EAAY,CAC7D,IAJwE,CAAC,EAGd,CAAX,IAAxB,MACN,CACnB,CAAC,AAC0B,IAAI,EAAE,CAA9B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,GADC,OAC6B,CAAC,CAAE,GAGxD,IAAM,EAAuBD,GAAsB,EAAY,CAC7D,KAJ0E,CAAC,CAGhB,CAAX,IAAxB,gBACI,CAC7B,CAAC,CAKF,OAJI,AAAwB,IAAI,EAAE,GAChCC,GAAsB,EAAU,CAAC,KADX,AACQ,GAAT,UAA8B,CAAC,CAAE,GAGjD,CACT,CAEM,MAHW,GAGD,GACd,CAAuB,EAPqD,AAOrD,CAPsD,GA+2B7E,EAt2BA,GAH6B,KAy2BG,AAY1B,EAZ0B,EAt2B1B,EAAoC,CAAA,CAAE,CAEtC,EAAWD,CAFH,EAk3BM,AAh3BmB,EAAY,CAArC,AAAsC,MAAM,CAAT,AAAU,CAArB,AAAsB,AAC5C,IAAI,EAAE,CAAlB,GACFC,GAAsB,EADZ,AACsB,CAAC,KAAH,CAAS,CAAC,CAAnB,AAAqB,GAG5C,IAAM,CAH8C,CAAC,AAG7BD,GAAsB,EAAY,CAAC,OAAtC,AAAmC,CAAX,KAA2B,CAAC,CAAC,AACnD,IAAI,EAAE,CAAzB,GACFC,GAAsB,EAAU,CAAC,KAAH,CADb,EACI,KAAyB,CAAC,CAAE,GAGnD,IAAM,EAAkBD,GAAsB,EAAY,CAHQ,AAGP,CAHQ,MAG9C,AAAmC,CAAX,KAA2B,CAAC,CAAC,AACnD,IAAI,EAAE,CAAzB,GACFC,GAAsB,EAAU,CAAC,KAAH,CADb,EACI,KAAyB,CAAC,CAAE,GAGnD,IAAM,EAAcD,GAAsB,EAAY,CAAC,AAHW,CAAC,EAGlD,IAAmC,CAAX,GAAyB,CAAC,CAAC,AACjD,IAAI,EAAE,CAArB,GACFC,GAAsB,EAAU,CAAC,EADpB,GACiB,GAAT,CAAqB,CAAC,CAAE,GAG/C,IAAM,EAAgBD,EAHoC,CAAC,AAGf,EAAY,CAAC,KAAtC,EAAmC,CAAX,QAA8B,CAAC,CAAC,CAC3E,GAAqB,IAAI,EAArB,EAAuB,CACzB,IAAI,EAAkB,EAClB,EAFW,GAEN,CAAC,KADS,AAAgB,EAClB,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,CACW,CADT,EACnB,EAAkB,AAAc,CAx+E7C,EAKA,MALQ,GAFR,EAAoC,CAAA,CAAE,CAGxC,AAAY,GAHF,CAGM,CAIK,CAJH,EAAV,CADKA,KAAkC,CAAC,QAAd,CAAC,CAAuB,CAAC,CAAC,GAE9DC,GAAsB,CAFyB,CAEf,CAAC,KAAH,CAAS,CAAC,CAAnB,AAAqB,GAMxC,AAAuB,IAAI,CANqB,CAAC,AAMpB,GAHLD,GAo+EI,EAp+E8B,CAC5D,CAm+EkC,CAAC,EAj+Ed,IAH0B,CAAC,QAC/B,CAClB,CAAC,AAF0D,GAI1DC,GAAsB,EAAU,CAAC,KAAH,GAAT,SAA6B,CAAC,CAAE,GAGhD,GA89EF,CAAC,CAEJA,GAh+Ea,AAg+ES,EAAU,CAAC,KAAH,AAn+E0C,CAAC,EAm+EpD,GAAuB,CAAC,CAAE,EAChD,CAED,IAAM,EAAaD,GAAsB,EAAY,CAAC,AAHU,CAAC,CAGjD,KAAmC,CAAW,AAAtB,CAAuB,CAAC,AAC9C,IAAI,EAAE,CAApB,GACFC,GAAsB,EAAU,CAAC,CADrB,IACkB,GAAT,AAAoB,CAAC,CAAE,GAG9C,IAAM,EAAqBD,CAH6B,CAAC,CAGR,EAAY,CAAC,OAAO,AAAV,CAAW,AAAtB,CAAuB,AAC7C,CADF,GACM,EAAE,CAA5B,GACFC,GACE,EACA,CAAC,KADO,GADW,CADD,OAGD,CAAC,EAClB,AA6zBE,EAAoC,CAAA,CAAE,CAMxC,AAAiB,GANP,CAMW,EAAE,CAJrB,EAAgBD,IAIL,CAn0BY,EA+zB2B,CACtD,EAh0B0B,CA+zBT,GAAwB,CAAC,CAClC,CACR,MAj0B6C,CAAC,CAC7C,AA8zBmD,gCAEZ,CACzC,CAAC,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,GAAuB,CAAC,CAAE,GAI7C,AAAkB,IAAI,EAAE,GADLD,CAHuC,CAAC,CAGlB,EAAY,AACvC,CADwC,OAAH,CAAX,IAA0B,CAAC,CAAC,GAEtEC,GAAsB,EAAU,CAAC,KAAH,GAAT,IAAwB,CAAC,CAAE,GAI9C,AAAkB,IAAI,EAAE,CADtB,EAAiBD,EAHyC,CAAC,AAGpB,EAAY,AACvC,CADwC,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,GAEtEC,GAAsB,EAAU,CAAC,KAAH,GAAT,IAAwB,CAAC,CAAE,GAG3C,IA70BP,IAAM,AA60BS,EA70BiBD,CA00BgC,CAAC,CA10BX,EAAY,CAChE,OAD8D,CAAX,OAAxB,MACN,CACtB,CAAC,AAC6B,IAAI,EAAE,CAAjC,GACFC,GACE,EACA,CAAC,KADO,GADW,MADI,OAGD,CAAC,CACvB,GAIJ,IAAM,EAAkBD,GAAsB,EAAY,CAAC,OAAH,AAAnC,CAJM,AAIkB,CAH1C,IAGqE,CAAC,CAAC,CAC1E,GAAuB,IAAI,EAAvB,EAAyB,CAC3B,IAAI,EAAkB,EAClB,IAFa,CAER,CAAC,KADS,EAAkB,AACpB,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAEtB,AAFuB,CACW,CADT,AAGjC,CAAC,CADW,AAGfC,AAJiB,EAAgC,AAAd,CAIb,EAAU,CAAC,KAAH,GAAT,KAAyB,CAAC,CAAE,EAClD,CAED,OAAO,CACT,CA6WM,GAjX8D,CAAC,EAGpD,GA8WD,GACd,CAAkC,EAAA,AAElC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAiBD,CAFT,EAE+B,EAAY,CACvD,EANqC,IAKnB,CAAmC,CAAX,UACxB,CAClB,YAAY,CACb,CAAC,AACoB,IAAI,EAAE,CAAxB,GACFC,GAAsB,EAAU,CAAC,KADjB,AACc,GAAT,IAAwB,CAAC,CAAE,GAGlD,IAAM,EAAaD,GAAsB,EAAY,AAHW,CAAC,AAI/D,EADc,KAAmC,CAAX,UACpB,CAClB,QAAQ,CACT,CACiB,AADhB,AACE,IAAkB,EAAE,IAAV,AACZC,GAAsB,EAAU,CAAC,KAAH,GAAT,AAAoB,CAAC,CAAE,GAG9C,IAAM,EAAkBD,CAHgC,CAAC,CAGX,EAAY,CAAC,OAAH,AAAnC,CAAwB,KAA2B,CAAC,CAAC,CAK1E,OAJuB,IAAI,EAAvB,AAAyB,GAC3BC,GAAsB,EAAU,CAAC,KAAH,CADb,EACI,KAAyB,CAAC,CAAE,GAG5C,CACT,CAEM,MAHW,GAGD,CANoD,CAAC,CAOnE,CAAkC,EAAA,AAElC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAiBD,CAFT,EAE+B,EAAY,CACvD,GANsC,GAKpB,CAAmC,CAAX,UACxB,CAClB,YAAY,CACb,CACqB,AADpB,IACwB,EAAE,CAAxB,GACFC,GAAsB,EAAU,CAAC,KAAH,AADd,GACK,IAAwB,CAAC,CAAE,GAGlD,IAAM,EAAaD,GAAsB,EAHuB,AAGX,CAHY,AAI/D,EADc,KAAmC,CAAX,UACpB,CAClB,QAAQ,CACT,CAAC,AACgB,IAAI,EAAE,CAApB,GACFC,GAAsB,EAAU,CAAC,CADrB,IACkB,GAAT,AAAoB,CAAC,CAAE,GAG9C,IAAM,EAAkBD,CAHgC,CAAC,CAGX,EAAY,CAAC,OAAtC,AAAmC,CAAX,KAA2B,CAAC,CAAC,CAK1E,OAJuB,IAAI,EAAvB,AAAyB,GAC3BC,GAAsB,EAAU,CAAC,KAAH,CADb,EACI,KAAyB,CAAC,CAAE,GAG5C,CACT,CAmLM,MApLW,GAoLD,CAvLoD,CAAC,CAwLnE,CAA8B,EAAA,AAE9B,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAkBD,CAFV,EAHoB,AAKY,EAAY,CAAC,OAAtC,AAAmC,CAAX,KAA2B,CAAC,CAAC,CAK1E,GAJuB,IAAI,EAAvB,AAAyB,GAC3BC,GAAsB,EAAU,CAAC,KAAH,CADb,EACI,KAAyB,CAAC,CAAE,GAIkB,SAAnED,AAA4E,EAC5E,CALgE,AAI1C,CAJ2C,CAI/B,CAAC,OAAH,CAAX,iBAAuC,CAAC,CAAC,CAE9D,MAAU,AAAJ,KAAS,CACb,kEAAkE,CACnE,CAGH,IAAM,EAAmBA,GAAsB,EAAY,CAAC,OAAH,CAAnC,AAAwB,MAA4B,CAAC,CAAC,CAK5E,OAJwB,IAAI,EAAxB,AAA0B,GAC5BC,GAAsB,EAAU,CAAC,KAAH,EADZ,CACG,MAA0B,CAAC,CAAE,GAG7C,CACT,CA+EM,MAhFW,GAgFD,EAnFsD,CAAC,AAmF1C,CAAsB,EAAA,AACjD,IAAM,EADoB,AACgB,CAAA,CAAE,CAEtC,EAA2BD,CAFnB,EAEyC,EAAY,CACjE,OAD+D,CAAX,QAAxB,MACN,CACvB,CAAC,CACF,GAAgC,IAAI,EAAhC,EAAkC,CACpC,IAAI,EAAkB,EAClB,KAAK,CAAC,KADS,EACF,AAFS,CAER,KAChB,EAAkB,CAF0B,CAEV,GAAG,CAAC,AAAC,EADR,CAAC,AAEvB,CADkC,AAvrG3C,CAsrGkC,EACnB,EAAkB,AAAc,IAvrGrC,AACd,CAAqC,EAErC,AAFqC,IAE/B,EAAoC,CAAA,CAAE,CAE5C,GAFc,AAE0C,EAmrGhB,OAnrGpCA,AAA6D,EAAE,CAAzC,AALe,EAKH,CAAC,OAAH,CAAX,EAAwB,CAAC,CAAC,CACjD,MAAM,AAAI,KAAK,CAAC,mDAAmD,CAAC,CAGtE,IAAM,EAAkBA,GAAsB,EAAY,CAAC,OAAtC,AAAmC,CAAX,KAA2B,CAAC,CAClD,AADmD,IAC/C,EAAE,CAAzB,GACFC,GAAsB,EAAU,CAAC,KAAH,CADb,EACI,KAAyB,CAAC,CAAE,GAGnD,IAAM,EAAWD,GAAsB,EAAY,CAArC,AAAsC,AAHc,CAAC,KAGT,CAAT,AAAU,CAC3C,AADsB,AAAsB,IACxC,EAAE,CAAlB,GACFC,GAAsB,EADZ,AACsB,CAAC,KAAH,CAAS,CAAC,CAAE,AAArB,GAGvB,IAAM,CAH8C,CAAC,AAG9BD,GAAsB,EAAY,CAAC,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,AAClD,IAAI,EAAE,CAAxB,GACFC,GAAsB,EAAU,CAAC,KAAH,AADd,GACK,IAAwB,CAAC,CAAE,GAGlD,IAAM,EAA2BD,GAAsB,EAAY,AAHH,CAI9D,AAJ+D,OAGA,CAAX,QAAxB,MACN,CACvB,CAAC,AAC8B,IAAI,EAAE,CAAlC,GACFC,GACE,EACA,CAAC,KADO,GADW,OADK,OAGD,CAAC,CACxB,GAIJ,IAAM,EAAeD,GAAsB,EAAY,CAAC,IAAtC,GAAmC,CAAX,CAJd,CAIsC,AAH/D,CAGgE,CAC/C,AADgD,IAC5C,EAAE,CAAtB,GACFC,GAAsB,EAAU,CAAC,GADnB,EACgB,GAAT,EAAsB,CAAC,CAAE,GAGhD,IAAM,EAAyBD,GAH6B,AAGP,CAHQ,CAGI,CAC/D,OAD6D,CAAX,MAAxB,MACN,CACrB,CAAC,CASF,OARI,AAA0B,IAAI,EAAE,GAClCC,GACE,EACA,CAAC,KADO,EAFc,CACH,YAEE,CAAC,CACtB,GAIG,CACT,GAooG2C,GACpC,CAtoGU,AAqoG8B,AACvC,CADwC,AAG5CA,GAAsB,EAAU,CAAC,IA5oGT,CA4oGM,AA3oG7B,GA2oGoB,cAAkC,CAAC,CAAE,EAC3D,CAED,IAAM,EAAgBD,GAAsB,EAAY,CAAC,AAHkB,CAAC,IAGzD,EAAmC,CAAX,GAAyB,CAAC,CAAC,AACjD,IAAI,EAAE,CAAvB,GACFC,GAAsB,EAAU,CAAC,IADlB,CACe,GAAT,GAAuB,CAAC,CAAE,GAGjD,IAAM,EAAmBD,GAAsB,CAHe,CAAC,AAGJ,CAAC,OAAH,CAAnC,AAAwB,MAA4B,CAAC,CAAC,AACpD,IAAI,EAAE,CAA1B,GACFC,GAAsB,EAAU,CAAC,KAAH,EADZ,CACG,MAA0B,CAAC,CAAE,GAGpD,IAAM,EAA4BD,GAAsB,EAAY,CAClE,CAJkE,CAAC,KAGH,CAAX,SAAxB,MACN,CACxB,CAAC,AAC+B,IAAI,EAAE,CAAnC,GACFC,GACE,EACA,CAAC,KADO,GADW,QADM,OAGD,CAAC,CACzB,GAIJ,IAAM,EAA0BD,GAAsB,EAAY,CAChE,OAD8D,CAAX,EAJxB,CAC1B,IAG0B,MACN,CACtB,CAAC,AACE,AAA2B,IAAI,EAAE,IACnCC,GACE,EACA,CAAC,KADO,EAFe,CACJ,aAEG,CAAC,CACvB,GAIJ,IAAM,EAAiBD,GAAsB,EAAY,CAAC,MAAtC,CAAmC,CAJ5B,AAIiB,CAHzC,GAGmE,CAAC,CAAC,AAClD,IAAI,EAAE,CAAxB,GACFC,GAAsB,EAAU,CAAC,KADjB,AACc,GAAT,IAAwB,CAAC,CAAE,GAGlD,IAAM,EAAiBD,GAAsB,EAHmB,AAGP,CAHQ,AAGP,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,AAClD,IAAI,EAAE,CAAxB,GACFC,GAAsB,EAAU,CAAC,KADjB,AACc,GAAT,IAAwB,CAAC,CAAE,GAGlD,IAAM,EAAkBD,GAAsB,EAHkB,AAGN,CAAC,AAHM,OAG5C,AAAmC,CAAX,KAA2B,CAAC,CAAC,AACnD,IAAI,EAAE,CAAzB,GACFC,GAAsB,EAAU,CAAC,KAAH,CADb,EACI,KAAyB,CAAC,CAAE,GAGnD,IAAM,EAAoBD,GAAsB,EAAY,CAHM,AAIhE,CAJiE,MAGT,CAAX,CAAxB,MACN,CAChB,CAAC,CAKF,OAJI,AAAqB,IAAI,EAAE,GAC7BC,GAAsB,EAAU,CAAC,EADd,GACW,GAAT,OAA2B,CAAC,CAAE,GAG9C,CACT,CA4aM,MA7aW,GA6aD,GAhbwD,AAgb3C,CAhb4C,AAgbrB,EAAA,AAClD,IAAM,EADoB,AACgB,CAAA,CAAE,CAEtC,EAAUD,CAFF,EAEwB,EAAzB,AAAqC,CAAC,KAAK,CAAC,CACrD,AAAW,AAD2C,AAAV,CAAX,GAClB,EAAE,CAAV,GACTC,GAAsB,EAAU,CAAC,KAAH,AAAQ,CAAC,CAAE,CAApB,EAGvB,IAHkD,AAG5C,CAH6C,CAG5BD,GAAsB,EAAY,CAAC,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,AAClD,IAAI,EAAE,CAAxB,GACFC,GAAsB,EAAU,CAAC,KADjB,AACc,GAAT,MAA0B,CAAC,EAAEO,EAAS,IAAD,AAG5D,IAAM,EAAeR,GAAsB,CAHgC,CAAC,AAGrB,CAHsB,AAGrB,IAAtC,GAAmC,CAAX,EAAwB,CAAC,CAAC,CAKpE,OAJoB,IAAI,EAApB,AAAsB,GACxBC,GAAsB,EAAU,CAAC,GADnB,EACgB,GAAT,EAAsB,CAAC,CAAE,GAGzC,CACT,CAEM,MAHW,CAH6C,CAAC,CAM/C,GACd,CAAuB,EAEvB,AAFuB,IAEjB,EAAoC,CAAA,AAHf,CAGiB,CAEtC,EAAUD,CAFF,EAEwB,EAAzB,AAAqC,CAAC,KAAK,CAAC,CAAC,AAC3C,AADiC,CAAX,GAClB,EAAE,CAAjB,GACFC,GAAsB,CADb,CACuB,CAAC,KAAH,GAAT,AAAoB,CAAC,CAAE,GAG9C,IAHqD,AAG/C,CAHgD,CAG/BD,GAAsB,EAAY,CAAC,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,AACpE,AAAkB,IAAI,EAAE,IAC1BC,GACE,CAFc,CAGd,CAAC,KADO,GADW,YAEE,CAAC,EACtBO,EAAS,IAAD,AAIZ,IAAM,EAAeR,GAAsB,CAJhB,CAI4B,AAJ3B,CAI4B,AAHrD,IAGe,GAAmC,CAAX,EAAwB,CAAC,CAAC,CAKpE,OAJoB,IAAI,EAAE,AAAtB,GACFC,GAAsB,EAAU,CAAC,GADnB,EACgB,GAAT,EAAsB,CAAC,CAAE,GAGzC,CACT,CC7tJO,IAAM,ED4tJI,CAH6C,ACztJtB,CDytJuB,kBCztJJ,CAKrD,CAL+B,EAKd,WAAH,2BAAyC,AAgH1D,OACU,GAGX,MAHoB,CAAA,IAGpB,CAAY,CAA0B,CAAA,SACpC,IAAI,CAAC,aAAa,CACb,MAAA,CAAA,MAAA,CAAA,MAAA,CAAA,MAAA,CAAA,CAAA,CAAA,CAAA,GACH,CADO,AACP,CAAA,MAAO,CAAE,EAAK,EAAD,KAAQ,CACrB,QAAQ,CAAE,EAAK,EAAD,MAAS,CACvB,MAAM,CAAE,EAAK,EAAD,IAAO,CACnB,QAAQ,CAAE,EAAK,EAAD,MAAS,EACxB,CAED,MAAM,EAA+B,CAAA,CAAE,AAEnC,KAAI,CAAC,KAFY,QAEC,CAAC,QAAQ,EAAE,AAC/B,EAAgB,UAAU,CACxB,EADa,KACb,EAAA,IAAI,CAAC,aAAa,CAAC,UAAA,AAAU,EAAA,EAAA,AAnIC,EAmID,CAAI,GAAJ,GAnIU,CAoIzC,AAD+B,EAAA,AACf,KADe,EACR,CAAG,EADK,CAAA,CACD,CAAf,AAAgB,OADiC,mBACP,EAAE,CAC3D,IAAI,CAAC,uBAAuB,EAAE,GAG9B,EAAgB,UAAU,CACxB,EADa,KACb,EAAA,IAAI,CAAC,aAAa,CAAC,UAAA,AAAU,EAAA,EAxIC,AAwID,EAAA,CAAI,GAAJ,EAxIS,CAyIxC,CAD+B,CACf,CADe,KAAA,CACR,CAAG,CAAA,EADK,CAAA,CAChB,QADiD,8BACtC,CAA4C,EAGxE,EAAgB,OAAO,CAAG,IAAI,CAAf,AAAgB,iBAAiB,EAAE,CAElD,IAAI,CAAC,aAAa,CAAC,WAAW,CAAG,EAE7B,EAAK,EAAD,SAAY,AAF4B,EAE1B,CACpB,IAAI,CAAC,aAAa,CAAC,WAAW,CAAG,IAAI,CAAC,gBAAgB,CACpD,EACA,EAAK,EAAD,SADW,CACC,CACjB,CAUG,0BAA0B,EAAA,QAChC,AACE,IAAI,CAAC,aAAa,CAAC,OAAO,EAC1B,IAAI,CAAC,aAAa,CAAC,QAAQ,EACK,QAAQ,EACxC,CADA,IAAI,CAAC,aAAa,CAAC,QAAQ,CAGpB,CAAA,QAAA,EAAW,IAAI,CAAC,aAAa,CAAC,QAAQ,CAAA,2BAAA,CAA6B,CAGrE,CAAA,kCAAA,CAAoC,CAUrC,uBAAuB,EAAA,CAC7B,GAAI,IAAI,CAAC,aAAa,CAAC,OAAO,EAAI,IAAI,CAAC,aAAa,CAAC,QAAQ,CAAE,CAE7D,IAAI,CAAC,aAAa,CAAC,MAAM,CAAG,OAC5B,EADqC,IAEtC,CAED,IAAI,CAAC,aAAa,CAAC,OAAO,MAAG,EAC7B,IAAI,CAAC,EADiC,WACpB,CAAC,QAAQ,MAAG,EAGhC,OAHyC,GAG/B,EAAA,OACR,OAAO,MAAA,EAAA,CAAA,IAAI,CAAC,aAAa,CAAC,QAAA,AAAQ,GAAA,EAGpC,AAHoC,CAAA,EAAI,EAAJ,GAAS,CAAT,CAG1B,CAH0B,CAG1B,CACR,GAJkC,IAI3B,CAJ2B,CAAA,EAIvB,CAAC,aAAa,CAAC,OAAO,CAGnC,WAAW,EAAA,CACT,OAAO,IAAI,CAAC,aAAa,CAAC,QAAQ,CAGpC,aAAa,EAAA,CACX,GACE,IAAI,CAAC,aAAa,CAAC,WAAW,OACgB,IAA9C,IAAI,CAAC,AAAkD,EACvD,WADkB,CAAC,WAAW,CAAC,UAAU,CAEzC,OAAO,IAAI,CAAC,aAAa,CAAC,WAAW,CAAC,UAAU,AAElD,OAAM,AAAI,KAAK,CAAC,yBAAyB,CAAC,CAG5C,UAAU,EAAA,CACR,GACE,IAAI,CAAC,aAAa,CAAC,WAAW,OACa,IAA3C,IAAI,CAAC,AAA+C,EACpD,WADkB,CAAC,WAAW,CAAC,OAAO,CAEtC,OAAO,IAAI,CAAC,aAAa,CAAC,WAAW,CAAC,OAAO,AAE/C,OAAM,AAAI,KAAK,CAAC,sBAAsB,CAAC,CAGzC,aAAa,EAAA,CACX,OAAO,IAAI,CAAC,qBAAqB,CAAC,IAAI,CAAC,aAAa,CAAC,WAAW,CAAC,CAGnE,UAAU,EAAA,CACR,GACE,IAAI,CAAC,aAAa,CAAC,WAAW,OACa,IAA3C,IAAI,CAAgD,AAA/C,EACL,WADkB,CAAC,WAAW,CAAC,OAAO,CAEtC,OAAO,IAAI,CAAC,aAAa,CAAC,WAAW,CAAC,OAAO,AAE7C,OAAM,AAAI,KAAK,CAAC,sBAAsB,CAAC,CAInC,qBAAqB,CAAC,CAAyB,CAAA,CACrD,GACE,CAAC,QACuB,GADZ,CACZ,EAAY,GAAqB,IAAd,EAAR,KACgB,IAA3B,EAAY,GAAwB,EACpC,IADW,CAAW,CAEtB,MAAM,AAAI,KAAK,CAAC,qCAAqC,CAAC,CAKxD,IAAM,EAA4B,CAHlB,EAAY,KAGZ,EAHmB,CAAC,CAAT,OAAiB,CAAC,GAAG,EAC5C,EAAY,OAAO,CAAC,CAAT,IAAc,CAAC,CAAC,CAAE,CAAA,CAAE,EAC/B,EAAY,OAAO,CACoB,CAD5B,AAKf,OAHI,EAAY,SAAD,CAAW,EAA+B,EAAE,EAAE,CAA/B,EAAY,SAAD,CAAW,EAClD,EAAW,IAAI,CAAC,EAAY,CAAlB,QAAiB,CAAW,CAAC,CAElC,EAAW,IAAI,CAAC,GAAG,AAAT,CAAU,CAG7B,mBAAmB,EAAA,CACjB,MAAO,CAAY,SAAA,EAAA,IAAI,CAAC,aAAa,CAAC,OAAO,CAC3C,WAAA,EAAA,IAAI,CAAC,aAAa,CAAC,QACrB,CAAA,CAAE,CAGJ,SAAS,EAAA,CACP,OAAO,IAAI,CAAC,aAAa,CAAC,MAAM,CAGlC,mBAAmB,EAAA,CAEjB,IAAM,EAAW,IAAI,EAAP,CAAU,CAAC,AADT,IAAI,CAAC,EACW,CAAC,OADF,EAAE,EAGjC,OADA,EAAS,MAAD,EAAS,CAAwB,OAAO,EAA5B,EAAS,MAAD,EAAS,CAAc,IAAI,CAAG,KAAK,CACxD,EAAS,MAAD,EAAS,EAAE,CAG5B,UAAU,CAAC,CAAW,CAAA,CACpB,GAAI,IAAI,CAAC,aAAa,CAAC,WAAW,CAChC,CADkC,GAC9B,CAAC,aAAa,CAAC,WAAW,CAAC,OAAO,CAAG,GAAG,IAE5C,MAAU,AAAJ,KAAS,CAAC,qCAAqC,CAAC,CAIlD,YAAY,CAClB,CAAY,CACZ,CAAwB,CACxB,CAA+B,CAAA,CAE/B,IAAM,EAA4B,CAAC,IAAI,CAAC,EAAxB,mBAA6C,CAAC,GAAa,CAS3E,OATyE,AACrE,AAQG,CATmE,EAExE,AAOQ,EAPG,IAAI,CAAC,GAAN,CAAU,CAAC,OADG,EAAE,UACc,EAAE,CAAC,CAEhC,EAAE,EAAE,CAAb,GACF,CADM,CACK,IAAI,CAAC,GAEN,AAFA,CAAU,CAAC,EAEP,GAAG,CAAC,CAAG,EAAA,EAAW,IAAI,CAAC,GAAN,AAAS,CAAC,CAAA,CAAE,CAAC,CAKxC,8BAA8B,CAAC,CAAoB,CAAA,SACrD,IAAI,CAAC,aAAa,CAAC,MAAM,EAGzB,AAH2B,CAG1B,IAAI,CAAC,aAAa,CAAC,QAAQ,EAAE,AAG9B,EAAQ,IAAI,CAAL,AAAM,UAAU,CAAC,WAAW,CAAC,EAAE,AAMjB,KAAK,GAA5B,EAAQ,KAAD,KAAW,EAClB,EAAQ,IAAI,CAAL,AAAM,UAAU,CAAC,0BAA0B,CAAC,EACnD,AASJ,MAAM,OAAO,CAAC,CAAoB,CAAA,CAChC,IAAI,EAAqB,IAAI,CAAC,WAAR,EAAqB,CAAC,WAAY,AACpD,GAAQ,IAAD,OAAY,EAAE,CACvB,EAAqB,IAAI,CAAC,WAAR,KAAwB,CACxC,IAAI,CAAC,aAAa,CAAC,WAAY,CAC/B,EAAQ,KAAD,OAAY,CACpB,CAGH,IAAM,EAAyB,IAAI,CAAC,eAAR,eAAsC,CAAC,GAC7D,EAAM,CAAH,CADiE,CAAC,CAC3D,CAAC,YAAY,CAC3B,EAAQ,IAAI,CAAL,AACP,EACA,GAEF,GAAI,EAAQ,KAAD,GAHS,GAGG,CACrB,CADuB,CAFD,CACvB,CAEM,GAAM,CAAC,EAAK,CAAF,CAAQ,GAAD,AAAK,MAAM,CAAC,OAAO,CAAC,EAAQ,KAAD,MAAY,CAAC,CAC5D,AAD8D,EAC1D,CAAD,WAAa,CAAC,MAAM,CAAC,EAAK,CAAF,KAAQ,CAAC,IAGxC,CAH6C,CAAC,CAAC,CAG3C,EAA2B,CAAA,CAAE,CACjC,GAA2B,GADZ,EACiB,EAAE,CAA9B,EAAQ,KAAD,KAAW,EACpB,GAAI,EAAQ,IAAI,CAAL,CAA0B,IAAI,EAAE,CAAvB,EAAQ,IAAI,CAAL,AACzB,MAAM,AAAI,KAAK,CACb,8EAA8E,CAC/E,AACF,MAED,EAAY,IAAI,CAAG,EAAQ,EAAhB,EAAoB,CAQjC,AAR4B,OAE5B,EAAc,MAAM,GAAT,CAAa,CAAC,oCAAoC,CAC3D,EACA,EACA,EAAI,CAAD,IAFQ,GAEC,EAAE,CACd,EAAQ,CAFU,IAEX,MAAY,CACpB,CACM,IAAI,CAAC,YAAY,CAAC,EAAK,CAAF,CAAe,EAAQ,KAAD,EAAT,GAAoB,CAAC,CAGxD,gBAAgB,CACtB,CAA4B,CAC5B,CAA+B,CAAA,CAE/B,IAAM,EAAqB,IAAI,CAAC,KAAK,CACnC,IAAI,CADkB,AACjB,SAAS,CAAC,IAGjB,IAAK,GAAM,CAAC,EAAK,CAHe,AAGjB,CAHkB,AAGV,CAFP,EAEM,AAAK,MAAM,CAAC,OAAO,CAAC,GAEnB,QAAQ,EAAE,AAA3B,KAFsD,CAAC,CAAE,AAElD,EAIT,CAAkB,CAAC,CAJL,CAIS,CAAD,AAAQ,MAAA,CAAA,MAAA,CAAA,MAAA,CAAA,MAAA,CAAA,CAAA,CAAA,CAAA,CAAkB,CAAC,EAAI,CAAD,AAAC,CAAK,GACjD,EADsD,CAAC,EAClD,AAAK,QAInB,CAAkB,AAJU,CAIT,CAJW,CAIP,CAAD,AAAI,CAAA,CAAK,CAGnC,OAAO,EAGT,MAAM,UAHqB,GAGR,CACjB,CAAoB,CAAA,CAEpB,IAAI,EAAqB,IAAI,CAAC,WAAR,EAAqB,CAAC,WAAY,CACpD,EAAQ,KAAD,MAAY,EAAE,CACvB,EAAqB,IAAI,CAAC,WAAR,KAAwB,CACxC,IAAI,CAAC,aAAa,CAAC,WAAY,CAC/B,EAAQ,KAAD,OAAY,CACpB,CAGH,IAAM,EAAyB,IAAI,CAAC,eAAR,eAAsC,CAAC,GAC7D,EAAM,CAAH,CADiE,CAAC,CAC3D,CAAC,YAAY,CAC3B,EAAQ,IAAI,CAAL,AACP,EACA,EAEE,CAAC,EAAI,CAAD,UAHY,CAGC,CAAC,GAAG,CAAC,AAFF,CACvB,IAC8B,CAAC,EAAoC,KAAK,EAAE,CAAvC,EAAI,CAAD,WAAa,CAAC,GAAG,CAAC,KAAK,CAAC,EAC7D,EAAI,CAAD,WAAa,CAAC,GAAG,CAAC,KAAK,CAAE,KAAK,CAAC,CAEpC,IAAI,EAA2B,CAAA,CAAE,CAQjC,MARe,CACf,EAAY,IAAI,CAAG,EAAQ,EAAhB,EAAoB,CAAL,AAC1B,EAAc,MAAM,GAAT,CAAa,CAAC,oCAAoC,CAC3D,EACA,EACA,EAAI,CAAD,IAFQ,GAEC,EAAE,CACd,EAAQ,CAFU,IAEX,MAAY,CACpB,CACM,IAAI,CAAC,aAAa,CAAC,EAAK,CAAF,CAAe,EAAQ,KAAD,EAAT,GAAoB,CAAC,CAGzD,MAAM,oCAAoC,CAChD,CAAwB,CACxB,CAAwB,CACxB,CAAW,CACX,CAAyB,CAAA,CAEzB,GAAK,GAAe,EAAY,MAAhB,CAAuB,EAAR,AAAa,EAAa,CACvD,IAAM,EAAkB,EAD6B,EACzB,SAAP,MAAsB,CACrC,CADuC,CAC9B,EAAgB,EAAnB,IAAyB,CACrC,GAAI,EAAY,CADc,MACP,EAAI,AAAZ,OAAY,EAAW,KAAA,CAAA,CAAX,EAAa,AAAF,KAAA,EAAE,AAAO,EAAG,AAAZ,CAAa,CAAE,CACnD,CADyB,GACnB,EAAgB,MADc,IACJ,CAAb,AACjB,AAFkC,IAE5B,CAF4B,CAAA,AAEZ,KAAK,EAAE,CAC7B,EAAY,GADS,IACF,CACpB,CADY,AAGX,GAEE,UAFW,AAED,EACZ,AAFA,OAAQ,EAA4C,KAAK,EAKzD,EAAc,EALqC,GAKhC,EAAE,AAExB,CACG,GAHa,AAIf,EAAY,MADC,EAAE,CACJ,OAAiB,CAAC,OAAO,CAAE,KACpC,CADyC,CACzB,KAAK,EAAE,AACzB,CAAC,CAAC,CAEJ,EAAY,CAHO,KAGD,CAAG,CACtB,CAQD,AATa,IAAgB,GAEzB,GAAe,AAA0B,IAAI,EAAE,EAApC,CAAgB,EAAD,OAAU,EACtC,AA4TU,SAAA,AACd,CAAwB,CACxB,CAAkC,EAAA,AAElC,GAAI,CAAC,GAA+C,CAAC,EAAE,CAArC,EAAJ,EAhUmB,EAgUT,CAAC,IAAI,CAAC,CAJa,EAIF,MAAM,AAAR,CAAC,AACtC,OAGF,GAAI,EAAY,IAAI,KAAL,OAAiB,IAAI,CAAE,OACpC,OAAO,CAAC,IAAI,CACV,8JAA8J,CAC/J,CAIH,IAAI,EAA6C,CAAA,CAAE,CAInD,GAAgC,QAAQ,CAJnB,CAIjB,OAAO,EAAY,IAAI,EAAiB,EAAY,CAAlC,GAAsC,CAAC,IAAN,EAAY,CAAG,CAAC,CACrE,CADuE,EACnE,CACF,IAAM,EAAa,IAAI,CAAC,GAAR,EAAa,CAAC,EAAY,IAAI,CAAC,CAC/C,GADyC,AAEvC,AAAsB,QAAQ,SAAvB,GACQ,AAAf,IAAmB,GADF,CAEjB,EADU,AACT,KAAK,CAAC,OAAO,CAAC,GAGV,OAHoB,CAAC,EAC1B,EAGA,OAAO,CAAC,IAAI,CACV,6IAA6I,CAC9I,CAJD,EAAoB,CAQvB,CAAC,MAAO,CAAC,CARmD,AAQjD,CACV,IATmB,GASZ,CAAC,IAAI,CACV,sHAAsH,CACvH,CACD,MACD,CA0CH,EAAY,IAAI,CAAG,IAAR,AAAY,CAAC,SAAS,CAAC,AADf,AAtCnB,SAAS,AAsCmB,CACgB,CAAC,AAtC3C,CAA+B,CAC/B,CAA+B,EAAA,AAE/B,EAJgB,EAIV,EAAM,IAAA,EAAA,CAAA,MAAA,CAAA,CAAA,CAAA,CAAO,GACnB,GADyB,CAAC,AACrB,IAAM,GAAG,EAAI,EAChB,GAAI,CADkB,CAAE,IACd,CAAC,SAAS,CAAC,cAAc,CAAC,IAAI,CAAC,EAAQ,GAAM,AAAH,CAAC,AACnD,AAD6C,IACvC,EAAc,CAAM,CAAC,EAAI,CAAD,AACxB,EAAc,CAAM,CAAC,AADV,EACc,CAAD,AAE5B,GACuB,CAHR,OAEJ,AACoB,EAA/B,OAAO,GACP,CAAC,KAAK,CAAC,CADW,MACJ,CAAC,IACf,GACuB,IAFG,CAAC,GAChB,AACoB,EAA/B,OAAO,GACP,CAAC,KAAK,CAAC,CADW,MACJ,CAAC,GAEf,CAAM,CAAC,EAAI,CAAD,AAAI,EACZ,CAHwB,CAAC,AAIzB,EAHF,EAOE,CANqB,EAOrB,EANsC,CAOtC,CANsC,CACvC,GAGY,EAEJ,CADI,EACY,OAAO,CAAZ,EAElB,OAAO,CAFkC,AAEjC,EADR,EACY,CACV,CAAA,gEAAA,EAAmE,EAAG,CAAA,iBAAA,EAAqB,OAAO,EAA0B,SAAf,GAAe,EAAA,OAAO,EAAW,SAAA,KAAA,CAAgB,CAC/J,CAEH,CAAM,CAAC,EAAI,CAAD,AAAI,EAEjB,CAEH,OAAO,CAJwB,EAOJ,EAAmB,CAHjC,EAKjB,EA9YQ,EACA,EAAY,AA2YuC,CAAC,KAAZ,CA5Y7B,EACA,AAAqC,CACjD,CAEH,EAAY,OAAO,CAAG,CAAX,KAAiB,IAAI,CAAC,kBAAkB,CAAC,EAAa,GAAG,AAC7D,CAD8D,CAI/D,IAJyD,EAInD,GAHM,SAGM,CACxB,CAAQ,CACR,CAAwB,CACxB,CAA+C,CAAA,CAE/C,OAAO,IAAI,CAAC,OAAO,CAAC,EAAI,CAAD,OAAS,EAAE,CAAA,MAAA,CAAA,MAAA,CAAA,MAAA,CAAA,MAAA,CAAA,CAAA,CAAA,CAC7B,GAAW,CACd,MAAM,CADQ,AACN,CADM,AACI,CAClB,CAAA,EACC,IAAI,CAFa,AAEZ,MAAO,IACX,IADmB,EACb,GAAkB,AADD,GAEhB,IAAI,CADqB,CAAC,CACT,IADD,CAGxB,GAFiC,CAAT,AAAU,CAE7B,CAAC,AAAC,CAAC,GACP,EADW,CACP,CAAC,YAAY,KAAK,CACpB,CADsB,KAChB,CAEN,AAFO,OAED,AAAI,KAAK,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,AAEtC,CAAC,CAAC,CAGE,MAAM,aAAa,CACzB,CAAQ,CACR,CAAwB,CACxB,CAA+C,CAAA,CAE/C,OAAO,IAAI,CAAC,OAAO,CAAC,EAAI,CAAD,OAAS,EAAE,CAAA,MAAA,CAAA,MAAA,CAAA,MAAA,CAAA,MAAA,CAAA,CAAA,CAAA,CAC7B,GAAW,CACd,MAAM,CADQ,AACN,CADM,AACI,CAClB,CAAA,EACC,IAAI,CAFa,AAEZ,MAAO,IACX,IADmB,EACb,GADiB,AACC,GACjB,IAAI,CADqB,AACpB,CADqB,KAAV,eACU,CAAC,KAEnC,GAF2C,CAAC,CAEvC,CAAC,AAAC,CAAC,GACP,EADW,CACP,CAAC,YAAY,KAAK,CACpB,CADsB,KAChB,CAAC,AAEP,OAAM,AAAI,KAAK,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,AAEtC,CAAC,CAAC,CAGC,qBAAqB,CAC1B,CAAkB,CAAA,4CAElB,IAAM,EAAS,IAAH,GAAG,EAAA,MAAA,EAAA,KAAA,CAAA,AAAQ,CAAR,EAAU,EAAV,EAAU,AAAI,EAAE,AAAhB,AAAQ,IAAR,AAAgB,CAAA,CAAA,CAAA,CAAA,CAAA,GAAR,AAAQ,EAAA,GAAhB,CAAyB,CAAT,CAAW,CACpC,CADS,CAAA,AACC,CADe,CAAA,EACX,CAAP,UAAkB,CAAC,OAAO,CAAC,CACxC,GAAI,CAAC,EACH,IADS,EAAE,AACL,AAAI,KAAK,CAAC,wBAAwB,CAAC,CAG3C,GAAI,CACF,IAAI,EAAS,EAAE,CACf,CADU,KACH,CAAM,CACX,EADS,CACH,MAAC,CAAI,OAAE,CAAK,CAAC,CAAG,MAAM,GAAA,EAAO,EAAP,EAAM,AAAK,EAAE,CAAA,CACzC,GAAI,EAAM,CACR,CADM,EACF,EAAO,IAAD,AAAK,EAAE,CAAC,MAAM,CAAG,CAAC,CAC1B,CAD4B,KAClB,AAAJ,KAAS,CAAC,oCAAoC,CAAC,CAEvD,KACD,CACD,IAAM,EAAc,EAAQ,KAAD,CAAO,CAAjB,AAAkB,EAAO,CAAC,EAAH,IAAS,EAAE,CAAI,CAAC,CAAC,CAGzD,AAHuD,GAGnD,CACF,IAAM,EAAY,IAAI,CAAC,EAAR,GAAa,CAAC,GAC7B,GAAI,KADoC,CAA4B,CACzD,GAAI,EAAW,CACxB,IAAM,EADgB,AACJ,IAAI,CAAC,EAAR,GAAa,CAC1B,IAAI,CAAC,SAAS,CAAC,EAAU,KAAQ,CAAC,CAAV,AAAQ,AACN,CACtB,EAAS,EAAU,EAAb,IAAgC,CAApB,AAClB,CAD2B,CACpB,EAAH,AAAa,IAAiB,CAClC,CADuB,CAAP,AACD,CAAe,SAAlB,GAAkB,EAAA,EAAW,EAAA,EAAA,AAAL,IAAS,CAAC,SAAS,CAC3D,GACD,CAAE,CACH,GAAI,CAFO,CACV,CACW,CAAJ,EAAO,EAAI,EAAO,EAAH,CAAM,CAK3B,CAL6B,KACZ,AAIX,IAJe,GAAS,CAC5B,AAGY,IAJe,GACpB,CAAE,EACT,MAAM,CAAE,CACT,CAAA,CAFsB,AAErB,AAGL,CAJiB,AAKnB,CAAC,MAAO,CAAU,CAAE,CAEnB,GAAI,AAAe,KAAV,KAAoB,EAAE,CADjB,CAAU,CACd,IAAI,CACZ,MAAM,CAAC,AAEV,CAED,IAAI,EAAQ,CADZ,EACS,CADC,CAAA,CAAW,AACH,CADZ,AACa,KAAK,CAAC,IACzB,KAAO,GAAO,CACZ,CAFqC,AAC3B,CAD4B,EAEhC,EAAuB,CAAK,CAAC,CAAC,CAAC,CACrC,GAAI,CACF,IAAM,EAAkB,GAFA,CAEI,QAAQ,CAAf,AAAgB,EAAsB,CACzD,OAAO,OAAE,EAAA,CAD8C,IAC9C,CAAQ,AAAR,CAAA,EAAU,EAAF,IAAA,CAAS,CAC1B,EADS,IACH,CAAE,GADS,KAAR,AACO,AAAR,KADC,AACO,AAAR,CADC,AACD,CAAA,EAAQ,AAAE,IAAV,EAAQ,AAAQ,CACxB,KADgB,KAAR,AACE,KADF,CAAA,CACI,EAAA,KAAA,CAAQ,AAAR,CAAA,EAAU,EAAF,IAAA,IAAY,AAApB,AACb,CAAA,CAAC,AACF,MAFsB,CAEtB,IAFc,EAEd,GAFc,AAER,CAFQ,GAEd,AAAU,GAAa,IAEvB,EAAQ,CADR,EACK,AAFiB,AACb,EAAO,CACF,CADR,EAAS,AADuB,CAAC,AAClB,CADkB,AACjB,CAAK,CAAC,CAAC,CAAC,CAAC,OAAM,CAAC,CACvB,KAAK,CAAC,GACtB,CAAC,MAAO,CAAC,CAAE,CACV,CAFmC,CAAC,IAE9B,AAAI,KAAK,CACb,CAAA,+BAAA,EAAkC,EAAyB,EAAA,EAAA,CAAC,CAAE,CAAA,CAC/D,AACF,CACF,CACF,CACF,OAL+D,CAKtD,CACR,EAAO,IAAD,OAAY,EAAE,AACrB,GACF,CACO,MAAM,OAAO,CACnB,CAAW,CACX,CAAwB,CAAA,CAExB,OAAO,KAAK,CAAC,EAAK,CAAF,EAAe,KAAK,CAAC,AAAC,CAAC,CAAV,CAAC,CAC5B,EADyC,IACnC,AAAI,KAAK,CAAC,CAAA,UAAA,EAAa,CAAC,CAAA,gBAAA,CAAkB,CAClD,AADmD,CAClD,CAAC,CAGJ,iBAAiB,EAAA,CACf,IAAM,EAAkC,CAAA,CAAE,CAEpC,EAFO,AAGX,aAAa,GADS,AACN,GAAG,QAAG,IAAI,CAAC,aAAa,CAAC,cAAc,CAMzD,OAJA,CAAO,CA/kBe,AA+kBd,YA/kB0B,CA+kBR,CAAG,EAC7B,CADyB,AAClB,CAAC,GAAyB,CAAG,EACpC,CAAO,CAAC,AAnlBgB,MAilBuB,QAjlBT,AAklBgB,CAC1B,CAAG,AADC,GACL,eAAsB,CAE1C,EAGD,KAHQ,CAGF,kBAAkB,CAC9B,CAAoC,CACpC,CAAW,CAAA,CAEX,IAAM,EAAU,IAAI,CAAP,MAAc,CAC3B,CAD6B,EACzB,GAAe,EAAY,MAAhB,CAAuB,CAAE,CAAV,AAC5B,IAAK,GAAM,CAAC,EAAK,CAAF,CAAQ,GAAD,AAAK,MAAM,CAAC,OAAO,CAAC,EAAY,OAAO,CAAC,CAAT,AAAW,AAC9D,EAAQ,KAAD,CAAO,CAAC,EAAK,CAAF,EAIhB,EAJuB,AAIX,CAJY,MAIL,EAAR,AAAY,EAAY,OAAO,CAAG,CAAX,AAAY,EAAE,AAClD,EAAQ,KAAD,CAAO,CACZ,AApmBoB,kBAAkB,CAqmBtC,EADqB,IACf,CAAC,IAAI,CAAC,IAAI,CAAC,EAAY,OAAO,CAAG,CAAX,GAAe,CAAC,CAAC,AAGlD,CAFI,AAIL,OADA,MAAM,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,cAAc,CAAC,EAAS,GAC/C,AADkD,CAAC,CAAN,AAetD,KAdgB,CAcV,UAAU,CACd,CAAmB,CACnB,CAAyB,CAAA,OAEzB,IAAM,EAAqB,CAAA,CAAE,AACf,IAAI,EAAE,CAAhB,CADc,GAEhB,EADQ,AACK,QAAQ,CAAG,CAAZ,CAAmB,IAAD,IAAS,CACvC,EAAa,IAAI,CAAG,EAAO,GAAf,CAAc,AAAK,CAC/B,EAAa,UAAD,CAAY,CAAG,EAAO,IAAD,OAAY,EAG3C,EAAa,IAAI,EAAI,CAAC,EAAa,CAAvB,GAA2B,CAAC,KAAN,KAAgB,CAAC,QAAQ,CAAC,EAAE,CAChE,EAAa,IAAI,CAAG,CAAA,IAAR,EAAQ,EAAS,EAAa,IAAI,CAAA,CAAE,AAAF,EAGhD,EAH2C,EAGrC,EAAW,IAAI,CAAC,CAAR,YAAqB,CAAC,QAAQ,CACtC,EAAW,MAAH,AAAS,EAAS,IAAI,CAAC,CAAN,EAC/B,CADyC,CAAC,AAC7B,SAAS,CAAV,AAAa,MAAM,CAAC,EAAS,IAAI,CAAC,CAAN,AACxC,IAAM,EAAW,MAAH,CAAG,EAAA,MAAA,EAAM,IAAA,CAAA,CAAA,CAAN,EAAM,AAAE,IAAF,IAAE,AAAQ,AAAhB,EAAgB,EAAA,AAAI,EAAJ,AAAa,AAAvB,IAAU,AAAiB,CAA3B,AACvB,CAD6C,EAAZ,AAC7B,EADmB,AAAU,CAAV,EACN,EADgB,CACrB,IADqB,AACU,CADV,CACY,AAAnB,EAAqB,CAAjB,EAC5B,MAAM,AAAI,AAD0B,KACrB,CACb,oEAAoE,CACrE,CAEH,EAAa,QAAQ,CAAG,CAAZ,CAEZ,IAAM,EAF0B,AAEd,MAAM,CAAT,GAAa,CAAC,cAAc,CAAC,EAAc,GAC1D,GADgE,CAAC,GAAT,AACjD,EAAS,MAAD,AAAO,CAAC,EAAM,EAAF,AAAa,IAAI,CAAC,CAS/C,CATwC,KASlC,YAAY,CAAC,CAA8B,CAAA,CAC/C,IAAM,EAAa,IAAI,CAAC,GAAR,UAAqB,CAAC,UAAU,AAChD,OAAM,EAAW,QAAD,AAAS,CAAC,EAAQ,IAAF,AAAM,CAAC,CAGjC,MAAM,cAAc,CAC1B,CAAU,CACV,CAAyB,CAAA,OAEzB,IAAI,EAA2B,CAAA,CAAE,CAE/B,MAFa,GACX,EAAM,AACG,IADH,CAAA,EAAN,EAAA,AAAQ,IAAR,AAAM,IAAN,GAAQ,AAAW,EAAE,AACT,CADN,CACa,IADb,AACY,KADZ,EACwB,CAElB,CACZ,UAAU,CAAE,EAAE,CACd,OAAO,CAAE,CACP,cAAc,CAAE,kBAAkB,CAClC,wBAAwB,CAAE,WAAW,CACrC,uBAAuB,CAAE,OAAO,CAChC,qCAAqC,CAAE,CAAA,EAAG,EAAK,EAAD,OAAU,CAAE,CAAA,CAC1D,mCAAmC,CAAE,CAAA,EAAG,EAAK,EAAD,MAAS,CAAE,CAAA,AACxD,CAAA,CACF,CAGH,IAAM,EAA6B,CACjC,CADQ,IACA,CAAF,CACP,CACK,CAFQ,CAEO,MAAM,IAAT,AAAa,CAAC,OAAO,CAAC,CACtC,IAAI,CAAEuC,GACJ,MADoB,eACC,CACrB,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,IAAI,CAAE,IAAI,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,MAAM,aAClB,CACD,CAAA,CAAC,CAEF,GAAI,CAAC,GAHQ,AAGQ,CAAA,CAAC,OAAL,CAAK,IAAY,CAAZ,CAAA,CAAA,EAAc,AAAd,IAAA,GAAc,AAAO,CAAA,AAArB,CACpB,CADgC,AAAW,KACrC,AAAI,KADsB,AACjB,CACb,IAFkB,KAAA,CAAA,gFAEwE,CAC3F,CAGH,IAAM,EACJ,MAAA,CADa,CACb,OAAA,EAAA,KAAA,CAAA,CAAA,EAAc,CAAF,KAAZ,CAAc,AAAO,EAAG,CAAZ,AAAZ,GAAwB,CAAA,AAAxB,CAAwB,CAAA,CAAA,CAAA,GAAA,EAAA,GAAZ,EAAY,GAAxB,EAAwB,CAAA,EAAxB,CAA2C,AAA3C,CAA4C,CAC9C,GAAkB,SAAd,AAAuB,EAAE,AAC3B,MAAM,AAAI,CADC,IACI,CACb,wFAAwF,CACzF,CAEH,OAAO,EAEV,CAED,MAJoB,SAIL,GAAkB,CAA8B,EAAA,MAC7D,GAAI,AAAa,EADa,MAClB,CAAc,EAAE,AAC1B,MAAM,AAAI,KAAK,CAAC,uBAAuB,CAAC,CAE1C,GAAI,CAAC,EAAS,EAAE,CAAE,CAChB,EADW,EACL,EAAiB,EAAS,EAApB,IAAmB,AAAO,CAahC,EAAe,IAAI,CAAC,KAAR,IAAiB,CAAC,CAXhC,OAAA,CAWyC,CAXzC,AAW0C,EAXjC,MAAD,CAAQ,CAAC,GAAG,CAAC,eAAc,CAAC,CAAE,KAAA,CAAA,CAAA,EAAA,IAAA,EAAA,EAAQ,CAAC,EAAT,KAAA,CAAA,WAA2B,CAAC,CACxD,CAD0D,KACpD,EAAS,IAAI,EAAE,AAAP,CAEd,CACV,KAAK,CAAE,CACL,OAAO,CAAE,MAAM,EAAS,IAAI,EAAL,AAAO,CAC9B,IAAI,CAAE,EAAS,MAAD,AAAO,CACrB,MAAM,CAAE,EAAS,MAAD,IAAW,AAC5B,CAAA,CACF,EAGH,GAAI,GAAU,GAAJ,AAAO,EAAI,EAAS,GAAG,CAK/B,AALyB,CAAQ,KAK3B,AAJW,IAAI,GAAS,CAC5B,AAGY,IAJe,GACpB,CAAE,EACT,MAAM,CAAE,CACT,CAAA,CAAC,AAGJ,AALyB,GACP,IAIZ,AAAI,KAAK,CAAC,EACjB,CACH,CCvuBM,QDquB0B,CCruBhB,ADquBiB,GCruBD,CAAoB,EAAA,AAClD,IAAK,IAAM,CADkB,GACd,CAAI,EACjB,GADsB,CAAE,AACpB,CAoBmB,KAEZ,CAF2B,EAAA,CAEvB,MAtBO,CAAD,GAAK,AAuBR,CAvBS,EAAE,KAuBH,EAA1B,OAAO,GACP,GADa,GACP,OAAY,IArBE,QAAQ,EAAxB,CAqB6B,MArBtB,GAAqB,CAAjB,YAA8B,GAAI,EAF/C,EAEmD,EAAE,GAF9C,CACR,CAMH,EAPe,KANkB,AAa1B,CACT,CAGM,GAjBkC,MAiBxB,GAAkB,CAA+B,EAAA,MAC/D,IAAM,CAL6B,AAIJ,CACR,OAAA,EAAA,CAAO,CAAC,CAAX,EAAmC,AAAC,EAAI,EAAA,EAAA,AAAE,CAC9D,CAAO,CAAC,CADoD,EAC3B,CAAG,CADwB,AAE1D,EAAiB,AAFyC,CAErC,CAAA,EAAA,CAFqC,KAAA,CAAA,CAE5C,CAAgB,IADA,EACE,CAAA,CAChC,SAAS,EAAE,AACf,CAqCG,MACU,GAMX,WACE,CAAA,AAPwB,CAAA,CAOE,EAAE,CAC5B,CAA0B,CAAA,CANpB,EAKN,EALc,CAAA,QAAA,CAAc,EAAE,CACxB,IAAuB,CAAA,uBAAA,CAA8B,CAAA,CAAE,CAO7D,IAAI,CAAC,UAAU,CAAG,EAClB,IAAI,CAAC,GADuB,GACjB,CAAG,EAMT,IANe,GAMR,MAAM,CAClB,CAAuB,CACvB,CAA0B,CAAA,CAE1B,OAAO,IAAI,GAAgB,EAAY,GAUzC,GAV+C,CAAC,CAAT,CAUjC,CAVsB,SAUZ,EAAA,aACd,GAAI,IAAI,CAAC,QAAQ,CAAC,MAAM,CAAG,CAAC,CAC1B,CAD4B,MAI9B,IAAM,EAAyC,CAAA,CAAE,CAC3C,EAAsB,EAAE,CAC9B,CAFiB,EACH,CACT,IAAM,KAAa,IAAI,AAAR,CAAS,UAAU,CAAE,IACvC,IAA4B,IAAuB,EAAA,AAAvB,EAAA,CAAA,EAAA,EAAA,GAAA,KAAA,CAAA,CAAA,GAjElC,AAiEkC,SAjElB,AACd,CAAoB,AAgEY,CA/DhC,CA+D4C,CA/DzB,GAAG,EAAA,GAFI,kCAK1B,IADI,EACA,EAAW,CAAC,CAChB,AAFU,GAAuB,CACrB,CACL,EAAW,GAAU,CAC1B,CAHwC,CAE3B,EAAW,AAClB,CAAC,CAAG,MAAM,GAAA,EAAU,EAAV,KAAS,EAAU,CAAC,QAAC,CAAM,CAAC,CAAC,CAAA,CAC7C,CAD2C,GACtC,IAAM,IAAI,CAAI,CAAC,CAAC,KAAK,CAAE,AAC1B,MAAM,MAAA,GAAA,GACN,CADM,AAAI,CAAA,EAGZ,GAAI,CAFM,AAEL,CAAC,CAFM,AAEL,UAAU,CACf,CADiB,KAGnB,EAAS,CAAC,CAAC,EAAL,QAAe,AACtB,EACF,CAAA,EAgD8C,GAAU,CAAA,CAAA,EAAE,EAAH,AAAG,CAAA,CAAA,CAAA,MAAA,EAAA,IAAA,EAAA,CAAA,CAAA,IAAA,EAAA,CAAA,CAAA,CAAA,EAAA,CAAzB,CAAyB,CAAF,EAAA,KAAA,CAAvB,EAAuB,CAAA,EACjD,EAAS,CADwC,GACpC,CADS,AACR,CAAN,CADc,CAEtB,IAAM,AADe,CAAC,CACF,EAAQ,IAAc,CAAf,AAC3B,EADiB,CACb,CAAW,CAAC,EAAY,CAC1B,CAD4B,KACtB,AAAI,EADe,GACV,CACb,CAAA,wBAAA,EACE,EACF,SAAA,oDAAA,CAA+D,CAChE,CAEH,CAAW,CAAC,EAAY,CAAG,CAC5B,OADwB,CAAa,6FAGxC,IAAI,CAAC,QAAQ,CAAG,EAChB,IAAI,CAAC,CADmB,sBACI,CAAG,EAG1B,MAAM,GAH+B,CAG3B,EAAA,CAEf,OADA,MAAM,IAAI,CAAC,UAAU,EAAE,CAChB,Ab8lBR,SACa,AACd,CAAmB,CACnB,EAAmC,CAAA,CAAE,EAAA,AAErC,GanmB6B,CbmmBvB,EAAoD,EAAE,CACtD,EAAY,CALgB,GAKZ,GAAG,AAAV,CACf,CADmC,GAC9B,CAFqB,GAEf,KAAW,EAAJ,AAAc,CAC9B,IAAM,CADsB,CACR,EAAQ,IAAc,CAC1C,AAD2B,EAAV,CACb,EAAU,GAAG,CAAC,GAAL,AACX,MAAM,AAAI,EADiB,CAAC,EAAE,AACf,CACb,CAAA,wBAAA,EACE,EACF,SAAA,oDAAA,CAA+D,CAChE,CAEH,EAAU,GAAG,CAAC,GAAL,AACT,IAAM,EAAa,EADM,CAAC,KACV,CA7ClB,AADc,CACE,CAChB,EAAmC,CAAA,CA4CC,AA5CC,EAAA,AAGrC,IAAM,EAA+C,CACnD,AAN2B,IAMvB,CAAE,EAAc,IAAO,CAC3B,CAD0B,GADH,EACJ,KACR,CAAE,EAAc,WAAc,AAAf,CAC1B,CADwC,mBACpB,CAAE,AAJF,EAIgB,KAJkB,MAInB,AAAe,CACnD,CADkD,OAE/C,EAAc,WAAD,CAAgB,EAAE,AAAH,CAC9B,EAAoB,iBAAD,CAAsB,CAAG,CAAJ,CAAkB,WAAD,CAAe,AAAC,EAEvE,EAAO,IAAD,IAAS,EAAE,CACnB,EAAoB,QAAW,CAAG,CAAJ,CAAW,IAAD,EAArB,EAAsB,AAAQ,EAGhC,CACjB,oBAAoB,CAAE,CACpB,EACD,CACF,AAGH,EAsBuC,EAAS,GACxC,EAAW,AAD2B,CAAQ,CAAC,KA3BU,CA4B/C,YAAqB,EAAE,AACnC,EAAqB,IAAI,CAAC,GAAG,EAAW,QAApB,AAAmB,YAAqB,CAE/D,AAFgE,CAIjE,MAAO,CAAC,oBAAoB,CAAE,CAAoB,CAAC,AACrD,EatnBgC,IAAI,CAAC,QAAQ,CAAE,EbqnBK,EarnBD,CAAC,MAAM,CAAC,CAGlD,MAAM,QAAQ,CAAC,CAA6B,CAAA,CACjD,MAAM,IAAI,CAAC,UAAU,EAAE,CACvB,IAAM,EAAoC,EAAE,CAC5C,IAAK,IAAM,KAAgB,EACzB,GAAI,EAFyB,AACR,AACJ,IAAK,EADgB,CAAE,CACd,EAAV,EAAc,CAAC,uBAAuB,CAAE,CACtD,IACI,EADE,EAAY,IAAI,CAAC,EAAR,GACG,GAAG,SAAS,MADgB,CAAC,EAAa,IAAK,CAAC,CAG9D,IAAI,AAHmD,CAGlD,MAAM,CAAC,OAAO,EAAE,AACvB,GAAiB,CACf,OAAO,CAAE,EADG,EACC,CAAC,MAAM,CAAC,OAAO,EAC7B,CAEH,IAAM,EAAmB,MAAM,EAAU,MAAnB,CAAkB,CAAS,CAC/C,CACE,IAAI,CAAE,EAAa,IAAK,CACxB,KADkB,IACT,CAAE,EAAa,IAAI,AAC7B,CAAA,CAGD,IAJyB,GAKzB,EADS,CAGX,EAA0B,IAAI,CAAC,CAC7B,GAHc,CACf,YAEiB,CADO,AACL,CAChB,IAAI,CAAE,EAAa,IAAI,CACvB,KADkB,GACV,CAAE,EAAiB,OAAA,CACvB,CAAC,KADqB,AAChB,CAAE,CAAgB,EACvB,CACN,CAAA,AACF,CAAA,CAAC,AACH,CAEH,OAAO,CAN6B,CAQvC,CCrJD,CD8I6D,cC9I9C0D,GACb,CAAoB,CACpB,CAAsD,CDiJpB,AChJlC,CAAmB,EAAA,AAEnB,IAAM,EACJ,IAAIC,GAON,CAbmC,GAKhB,EAQb,CAAC,MAAM,CAAC,EALV,EAAM,CAFwB,EAAE,AAE3B,CAAK,KAKa,EAAE,IAAI,CALP,AAKQ,IALJ,CACrB,CADuB,GACnB,CAAC,KAAK,CAAC,MAAM,EAAM,GAAD,CAAK,CAAC,IAAI,EAAE,CAAiC,CAEnE,IAAI,CAAC,KAAK,CAAC,EAAM,GAAD,CAAK,CAAiC,EAG/D,EAAU,EACZ,CAOI,IARO,EASE,GACX,CAVuB,CAAC,IASJ,CAAA,IACpB,CACmB,CAAoB,CACpB,CAAU,CACV,CAAkC,CAAA,CAFlC,IAAS,CAAA,SAAA,CAAT,EACA,IAAI,CAAA,EADK,EACL,CAAJ,EACA,EADI,EACY,CAAA,gBAAA,CAAhB,EAiCnB,MAAM,OAAO,CACX,AAlCiC,CAkCO,CAAA,eAExC,GAAI,IAAI,CAAC,SAAS,CAAC,UAAU,EAAE,CAC7B,CAD+B,KACzB,AAAI,KAAK,CAAC,4CAA4C,CAAC,CAE/D,OAAO,CAAC,IAAI,CACV,0EAA0E,CAC3E,CAED,IAAM,EAAmB,IAAI,CAAC,SAAR,AAAiB,CAAC,mBAAmB,EAAE,CACvD,EAAa,IAAI,CAAC,GAAR,MAAiB,CAAC,aAAa,EAAE,CAC3C,EAAUC,AAmLpB,KAnLiB,IAmLRA,AAAa,CAA2B,EAAA,AAC/C,EApL8B,EAoLxB,EAAU,IAAI,CADD,AACN,MAAc,CAC3B,CAD6B,GACxB,GAAM,CAAC,EAAK,CAAF,CAAQ,GAAD,AAAK,MAAM,CAAC,OAAO,CAAC,GAAG,AAC3C,CAD4C,CAAE,AACtC,KAAD,CAAO,CAAC,EAAK,CAAF,EAEpB,EAF2B,CAAC,IAErB,CACT,EAzLiC,IAwLjB,AAxLqB,CAAC,SAAS,CAAC,iBAAiB,EAAE,CAAC,CAC1D,EAAS,IAAH,AAAO,CAAC,SAAS,CAAC,SAAS,EAAE,CACnC,EAAM,CAAH,AAAM,EAAA,EAAgB,cAAA,mBAAA,EAC7B,EACF,QAAA,iCAAA,EAA4C,EAAM,CAAE,CAEhD,EAF8C,AAEJ,KAAK,CAAA,AAAG,CAChD,EAAgB,EADL,EACS,OAAP,AAAc,CAAC,AAAC,IACjC,EAAgB,CADkD,AAEpE,CAAC,CAAC,CAEI,EAJkE,AAI5B,CAHnB,CAG0B,GAHpC,CAGmC,CAAnC,IAA6C,CAMtD,EAAY,IAAI,CAAC,EAAR,OAAiB,CAC1B,EAAyC,CAC7C,MAAM,CANsB,CAMpB,OADc,GAJtB,CAD4B,CACd,CAAA,CAAE,CAAC,AACnB,CAAC,CAKC,IAD6B,EALhB,GAMJ,CAAE,AAAC,IACLF,CADwB,EACD,EAAW,CADN,CACgB,KAAZ,EAAW,EAAU,CAAE,GAC7D,CACD,CAFmE,CAAC,CAAvC,IAEtB,CACL,MAAA,EAAA,OAAA,EAAA,KAAA,CAAA,CAAS,AAAT,EAAW,GAAX,IAAA,AAAS,AAAE,AAAO,EAClB,EADA,AACA,EAAA,IAAA,GAAU,AADD,CACc,AAAvB,EAAuB,AAAvB,CAEC,CACH,AAJE,GACA,EADA,CAAA,CAIK,CACL,AAJA,CAAA,MAIA,EAAA,MAAA,EAAA,KAAA,CAAA,CAAS,AAAT,EAAW,GAAX,IAAA,AAAS,AAAE,AAAO,EAClB,EADA,AACA,EAAA,IAAA,GADS,AACC,CAAa,AAAvB,EAAA,AAAuB,CAEtB,CAHD,AAIH,CAEK,EALF,AAKS,EANT,AAMM,CANN,CAMa,CALb,AAKc,CALd,eAK8B,CAAC,MAAM,CACvC,GAqIE,AArIC,EAqImC,AApItCG,CAoIsC,CAAE,CAC5C,AArIiB,EAqIT,EADO,GACR,AArIiB,CAAC,CAqIV,CAAC,CAAC,AArID,EAqIQ,GAAF,AAAK,EACzB,CAAS,CAAC,CADmB,CACf,CAAG,AAAJ,CACf,CAAC,CAAC,CACK,CAFiB,EArIpB,GAEF,EAAK,CAqIS,CArIV,KAAQ,EAAE,CAEd,GAJoB,CACnB,EAGK,EAEN,IAAM,EAAQjF,GAAH,AAAY,EAFJ,CAEG,CAAK,CAAC,SAAS,CAAE,EAAO,IAAD,CAAM,CAAC,CAKpD,OAFA,EAAK,EAAD,EAAK,CAAC,IAAI,CAAC,SAAS,CAAC,AADH,CAAC,KAAK,CADd,CAAC,KAEuB,AAFlB,CAEmB,CAFnB,AAEoB,CAFnB,AACO,CAAC,GAGtB,IAAI,GAAiB,EAAM,EAAF,EAAM,CAAC,MAAZ,GAAqB,CAAC,CAEpD,CAMG,MACS,GACX,WACW,CAAA,CAFgB,AAED,CAFC,AAGR,CAAoB,CAAA,CAD5B,IAAI,CAAA,IAAA,CAAJ,EACQ,EADJ,EACa,CAAA,SAAA,CAAT,EAcnB,MAAM,CAdsB,iBAcJ,CACtB,CAAmD,CAAA,CAEnD,GACE,CAAC,EAAO,IAAD,WAAgB,EACwB,CAAC,EAChD,CADA,MAAM,CAAC,IAAI,CAAC,EAAO,IAAD,WAAgB,CAAC,CAAC,MAAM,CAE1C,MAAM,AAAI,KAAK,CACb,8DAA8D,CAC/D,CAEH,IAAM,EACJkF,AJ+mCA,SAAU,AACd,CAAuD,CIjnClC,CJinCkC,AAEvD,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAsBtG,CAFd,EAEoC,EAAY,CAC5D,OAD0D,CAAX,GAAxB,IIpnCkC,EJqnCxC,CAClB,CAAC,CACF,GAA2B,AAAvB,CARsD,GAQ3B,IAAE,CAC/B,IAAI,EAAkB,EAClB,EAFiB,GAEZ,CAAC,KADS,EACF,CAAC,GADuB,EAEvC,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAEtB,AAFuB,CACW,CAE1C,AAHiC,CAGhC,CAFa,AACF,AAGfC,EAJmC,AAAc,CAI3B,EAAU,CAAC,KAAH,GAAT,SAA6B,CAAC,CAAE,EACtD,CAED,OAAO,CACT,EIloC8D,EJ8nCU,CI7nCpE,AJ6nCqE,EAGxD,CIjoCmD,CAAC,AAC7D,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,eAAC,CAAa,CAAC,CAAC,CAAC,CAcjD,MAAM,EAdwC,sBAchB,CAAC,CAA0C,CAAA,QACnE,CAAC,EAAO,IAAD,iBAAsB,EAAE,CACjC,EAAO,IAAD,iBAAsB,CAAG,CAAA,CAAE,EAEnC,IAAM,GJ4jCF,EAAoC,CAAA,CAAE,CAKxC,AAA6B,GALnB,CAKuB,EAAE,CAHjC,EAA4BD,EI9jCP,CACwB,EJ6jCiB,AI7jChEuG,CJ8jCF,GI9jCuD,CAAC,IJ6jCH,CAAC,CAG3B,OAHE,EAAmC,IACzC,CACxB,CAAC,GAEAtG,GACE,EACA,CAAC,AInkC6C,KJkkCtC,GADW,eAEK,CAAC,CACzB,GAIG,GIvkCL,IAAI,CJukCS,AIvkCR,IAAI,CAAC,IAAI,CAAC,IJmkCY,AInkCR,CJokClB,AIpkCmB,SAAS,CAAC,IAGxB,eAH2C,CAAC,CAAC,EAG1B,CAAC,CAA+C,CAAA,CAEzE,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,AADR,aACqB,CAAC,CAAC,EADtB,CAAe,CAAC,GASzC,IAAI,EAAA,CACF,GAVsC,CAUlC,CAAC,mBAAmB,CAACuG,GAA+B,IAAI,CAAC,CAS/D,KAAK,EAAA,CACH,IAAI,CAAC,EAVkD,iBAU/B,CAACA,GAA+B,KAAK,CAAC,CAShE,IAAI,EAAA,CACF,IAAI,CAAC,EAVkD,iBAU/B,CAACA,GAA+B,IAAI,CAAC,CAS/D,YAAY,EAAA,CAT6C,AAUvD,IAAI,CAAC,mBAAmB,CAACA,GAA+B,aAAa,CAAC,CAQxE,KAAK,CARoD,CAQpD,CACH,IAAI,CAAC,IAAI,CAAC,KAAK,EAAE,CAEpB,CCrOD,eAAe,GACb,CAAoB,CACpB,CAAiD,CACjD,CAAmB,EAAA,AAEnB,IAAM,EAAyC,IAAIC,EALhB,CAe7B,EAAO,EAVM,AAUT,EAAO,CAAC,KAAK,CARnB,AAQoB,CAVkD,CAEhE,CAFkE,EAEnE,CAAK,EAQkB,CAA4B,SARlC,IAAI,CACjB,CADmB,KACb,EAAM,GAAD,CAAK,CAAC,IAAI,EAAE,CACzB,EAAM,GAAD,CAAK,YAAY,WAAW,CAC/B,CADiC,GAC7B,WAAW,EAAE,CAAC,MAAM,CAAC,EAAM,GAAD,CAAK,CAAC,CAEpC,EAAM,GAAD,CAAK,EAKvB,GAAI,EAAU,OAAD,GAAW,EAAE,CAAE,WL65CtB,EAKA,QKh6CJ,EL25CgB,IK35CV,CAAC,MAAM,CAAC,ELg6Cc,CArBxB,EAAoC,CAAA,CAAE,CAKxC,AAAqB,GALX,CAKe,CKh5CA,CLg5CE,CAHzB,AK74CyB,EL64CLzG,EK74CS,CAAC,EL64CwB,CAC1D,EAEmB,MAH0B,CAAC,AAAzB,MACN,CAChB,CAAC,EAFwD,CAIxDC,GAAsB,EAAU,CAAC,KAAH,GAAT,OAA2B,CAAC,CAAE,GAMjD,AAAqB,IAAI,EAAE,CAHzB,EAAoBD,KAAkC,AAHU,CAIpE,AAJqE,EAMlD,MAH0B,CAAxB,AAAyB,MAC/B,CAChB,CAAC,EAFwD,CAIxDC,GAAsB,EAAU,CAAC,KAAH,GAAT,OAA2B,CAAC,CAAE,GAIjD,AAAgB,IAAI,EAAE,GADLD,GACL,EAJsD,AAGf,CAHgB,AAGf,QAAd,CAAC,CAAuB,CAAC,CAAC,GAElEC,GAAsB,CAF6B,CAEnB,CAAC,KAAH,GAAT,EAAsB,CAAC,CAAE,GAM5C,AAA4B,IAAI,EAAE,GANsB,AAG3BD,CAH4B,IAGM,CACjE,QADoD,CAAC,AAG3B,UAHqC,GACzC,CACvB,CAAC,GAEAC,GACE,EACA,CAAC,KADO,GADW,cAEI,CAAC,CACxB,GAOA,AAAqB,IAAI,EAAE,CAHzB,EAAoBD,KAAkC,CAC1D,EAEmB,IAPO,CACzB,CAG4C,CAAxB,AAAyB,MAC/B,CAChB,CAAC,EAFwD,CAIxDC,GACE,EACA,CAAC,KADO,GADW,OAEH,CAAC,CACjB,AAsSA,SAAU,AACd,CAA+B,EAAA,AAE/B,IAAM,EAAoC,CAAA,CAAE,CAEtC,EA3SqB,AA2SED,CAFf,EAEqC,EAAY,CAC7D,GANmC,IAKwB,CAAX,IAAxB,MACN,CACnB,CAAC,AAC0B,IAAI,EAAE,CAA9B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,GADC,OAC6B,CAAC,CAAE,GAGxD,IAAM,EAA8BD,GAAsB,EAAY,CACpE,KAJ0E,CAAC,CAGT,CAAX,WAAxB,MACN,CAC1B,CACkC,AADjC,IACqC,EAAE,CAArC,GACFC,GACE,EACA,CAAC,KADO,GADW,UADQ,OAGD,CAAC,CAC3B,GAIJ,IAAM,EAAyBD,GAAsB,EAAY,CAC/D,OAD6D,CAAX,IAJrB,CAC5B,CAGyB,QACJ,CACvB,CAAC,AAC4B,IAAI,EAAE,CAAhC,GACFC,GACE,EACA,CAAC,KADO,GADW,KADG,OAGD,CAAC,CACtB,GAIJ,IAAM,EAA8BD,GAAsB,EAAY,CACpE,OALwB,AAI0C,CAHjE,AAGsD,WAAxB,MACN,CAC1B,CAAC,AACiC,IAAI,EAAE,CAArC,GACFC,GACE,EACA,CAAC,KADO,GADW,UADQ,OAGD,CAAC,CAC3B,GAIJ,IAAM,EAAyBD,GAAsB,EAAY,CAC/D,OAD6D,CAAX,IAJrB,CAC5B,CAGyB,MACN,CACrB,CAAC,AAC4B,IAAI,EAAE,CAAhC,GACFC,GACE,EACA,CAAC,KADO,GADW,KADG,OAGD,CAAC,CACtB,GAIJ,IAAM,EAAsBD,GAAsB,EAAY,CAC5D,OALwB,AAIkC,CAHzD,AAG8C,GAAxB,MACN,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAA0BD,GAAsB,EAAY,CAChE,IAJwE,CAAC,EAGX,CAAX,OAAxB,MACN,CACtB,CAAC,CACF,GAAI,AAA2B,IAAI,IAAE,CACnC,IAAI,EAAkB,EAClB,KAAK,CAFgB,AAEf,KADS,EACF,CAAC,KAChB,EAAkB,AAFyB,EAET,GAAG,CAAC,AAAC,EADR,CAAC,AAEvB,CADkC,CADT,AAGjC,CAAC,CAFa,AACF,AAGfC,EAJmC,AAAc,CAI3B,EAAU,CAAC,KAAH,GAAT,aAAiC,CAAC,CAAE,EAC1D,CAED,IAAM,EAAyBD,GAAsB,EAAY,CAHS,AAIxE,CAJyE,MAGZ,CAAX,MAAxB,MACN,CACrB,CAAC,CACF,GAA8B,IAAI,EAA9B,EAAgC,CAClC,IAAI,EAAkB,EAClB,KAAK,CAAC,KAFc,AACL,EACF,CAAC,KAChB,CAF0C,CAExB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,AAEvB,CADkC,CAE1C,AAHiC,CAGhC,CADW,AADE,AAIjBC,EAJmC,AAAc,CAI3B,EAAU,CAAC,KAAH,GAAT,YAAgC,CAAC,CAAE,EACzD,CAED,IAAM,EAA4BD,GAAsB,EAAY,CAClE,AAJuE,CAAC,MAGR,CAAX,SAAxB,QACJ,CAC1B,CAAC,CACF,GAAiC,IAAI,EAAjC,EAAmC,CACrC,IAAI,EAAkB,EAClB,KAAK,CAAC,KADS,EACF,CAAC,AAFS,KAGzB,EAAkB,EAF2B,AAEX,GAAG,CAAC,AAAC,EADR,CAAC,AAEvB,CADkC,CADT,AAGjC,CAAC,CAFa,AACF,AAGfC,EAJmC,AAAc,CAI3B,EAAU,CAAC,KAAH,GAAT,eAAmC,CAAC,CAAE,EAC5D,CAED,IAAM,EAAiCD,GAAsB,EAAY,CAHG,AAI1E,CAJ2E,MAGN,CAAX,cAAxB,MACN,CAC7B,CAAC,CACF,GAAsC,IAAI,EAAtC,EAAwC,CAC1C,IAAI,EAAkB,EAClB,KAAK,CAAC,KADS,EACF,CAAC,KAFc,AAG9B,EAAkB,EAAgB,GAAG,CAAE,AAAD,CAFY,CACnB,CAAC,AAEvB,CADkC,CADT,AAGjC,CAAC,CAEJC,AAJiB,AACF,EADoB,AAAc,CAK/C,EACA,CAAC,KADO,GADW,oBAEU,CAAC,CAC9B,EAEH,CAED,IAAM,EAAkBD,GAAsB,EAAY,CAAC,AAJxC,CAChB,MAGkB,AAAmC,CAAX,KAA2B,CAAC,CAAC,CAK1E,OAJI,AAAmB,IAAI,EAAE,GAC3BC,GAAsB,EAAU,CAAC,AADhB,KACa,GAAT,KAAyB,CAAC,CAAE,GAG5C,CACT,EAna8B,IAKV,AAAd,CA6ZW,GA7ZO,CA0Z4C,CA1Z1C,AA0Z2C,CA3Z7D,EAAaD,CACL,GAL+B,CAIQ,AAJP,CAIQ,AAHnD,EAGa,MAA8C,AAAtB,CAAuB,AAAtB,CAAuB,GAE9DC,GAAsB,EAAU,CAFiB,AAEhB,KAAH,GAAT,AAAoB,CAAC,CAAE,GAM1C,AAA+B,IAAI,EAAE,CANe,AAGlD,CAHmD,CAGrBD,GK57CkB,EL47CgB,CACpE,CK77CwD,CAAC,ML47CF,CAAC,GAG3B,OAHE,AAAmC,MACzC,CAC1B,CAAC,GAEAC,GACE,EACA,CAAC,KADO,GADW,iBAEO,CAAC,CAC3B,GAIG,GKr8CN,KLq8Cc,CKn8Cb,CAFK,KAEC,CAAC,MAAM,CAAC,CL+7Ce,CKh8ChB,ALi8CZ,GK77CH,CAJmB,CAIT,EACZ,CAOI,GAX2B,CAGpB,CAHsB,CAYpB,GAZwB,AAenC,CAZuB,AASR,AAZqB,CAYrB,AATS,SAYxB,CACmB,CAAoB,CACpB,CAAU,CACV,CAAkC,CAAA,CAFlC,IAAS,CAAA,SAAA,CAAT,EACA,IAAI,CAAA,EADK,EACL,CAAJ,EACA,EADI,EACY,CAAA,gBAAA,CAAhB,EAEjB,IAAI,CAAC,KAAK,CAAG,GAFoB,CAEhB,GACf,IAAI,CAAC,CADmB,QACV,CACd,IAAI,CAAC,IAAI,CACT,IAAI,CAAC,gBAAgB,CACtB,CA6CH,MAAM,OAAO,CAAC,CAAmC,CAAA,yBAW3C,GAAW,CATf,GAAI,EAAO,IAAD,EAAO,EAAI,EAAO,IAAD,EAAO,CAAC,WAAW,CAC5C,CAD8C,KACpC,AAAJ,KAAS,CACb,kEAAkE,GAChE,iEAAiE,GACjE,iBAGN,IAAM,EAAmB,EAHM,CAC5B,CAE0B,CAAC,SAAR,AAAiB,CAAC,mBAAmB,EAAE,CACvD,EAAa,IAAI,CAAC,GAAR,MAAiB,CAAC,aAAa,EAAE,CAE3C,EAAgB,IAAI,CAAC,MAAR,GAAiB,CAAC,UAAU,EAAE,CAE/C,EAAO,IAAD,EAAO,EACb,EAAO,IAAD,EAAO,CAAC,KAAK,EACnB,GAAgB,EAAO,IAAD,EAAO,CAAC,GAAf,EAAoB,CAAC,EAEpC,AADA,GACkB,GAEpB,IAAM,EAAU,AAsYpB,IAxYqC,CAAd,AAAe,AAErB,IAsYR,AAAa,CAA2B,EAtYjB,AAsYiB,AAC/C,IAAM,EAAU,GADG,CACC,CAAP,MAAc,CAC3B,CAD6B,GACxB,GAAM,CAAC,EAAK,CAAF,CAAQ,GAAD,AAAK,MAAM,CAAC,OAAO,CAAC,GAAG,AAC3C,CAD4C,CACpC,AADsC,KACvC,CAAO,CAAC,EAAK,CAAF,EAEpB,EAF2B,CAAC,IAErB,CACT,EA5YiC,GAC7B,CA0YY,EA1YR,IAAI,CAAC,EADiC,CAAC,MACzB,CAAC,UAAU,EAAE,CAC7B,CAD+B,CACzB,CAAH,AAAM,EAAA,EACP,cADuB,cACvB,EAAA,EACF,QAAA,2BAAA,CAAqC,CACrC,MAAM,IAAI,CAAC,IAAI,CAAC,cAAc,CAAC,EAAS,GAAG,CAAC,CAAN,EACjC,CACL,IAAM,EAAS,IAAH,AAAO,CAAC,SAAS,CAAC,SAAS,EAAE,CAErC,EAAS,IAAH,iBAAwB,CAC9B,EAAU,KAAK,AAAR,QACP,EAAA,IAAM,CAAN,CAAA,CAAA,EAAQ,AAAR,IAAM,AAAN,IAAA,EAAkB,CAAC,GAAb,KAAN,KAAA,CAAA,CAAiC,CAAC,EAAE,CACtC,OAAO,CAAC,IAAI,CACV,qFAAqF,CACtF,CACkB,SAAS,EAAE,CAA1B,GACF,OADY,AACL,CAAC,IAAI,CACV,gMAAgM,CACjM,CAEH,EAAS,IAAH,4BAAmC,CACzC,EAAU,KAAH,SAAiB,EAG1B,EAAM,CAAH,AAAG,EAAG,EAAgB,cAAA,mBAAA,EACvB,EACF,QAAA,WAAA,EAAsB,EAAM,CAAA,EAAI,CAAJ,CAAW,CAAA,EAAI,EAAJ,AAAU,CAClD,AADoD,CAGrD,EAHmD,EAG/C,EAA0C,KAAK,CAAA,AAAG,CAChD,EAAgB,EADL,EACS,OAAP,AAAc,CAAC,AAAC,IACjC,EAAgB,CADkD,AAEpE,CAAC,CAAC,CAEI,EAJkE,AAIjC,CAHd,CAGqB,GAH/B,CAG8B,CAA9B,IAAwC,CAOjD,EAAY,IAAI,CAAC,EAAR,OAAiB,CAE1B,EAAyC,CAC7C,MAAM,CARsB,CAQpB,OADc,IAPM,IAC5B,MAO6B,CAP7B,EAAA,OAAA,EAAS,KAAA,CAAA,CAAT,AAAS,EAAE,GAAF,GAAE,AAAM,CAAR,EAAQ,EAAA,AAAjB,CAAiB,GAAA,CAAA,GACjB,CADS,AAAQ,CACH,CAAA,CAAE,CAAC,AACnB,CAAC,AAFU,CAAY,AAQrB,CARiB,GAAR,CAAA,CACI,AADI,GAQR,CAAE,AARM,AAQL,IACL,CATU,AAQc,EACD,EAAW,CADN,CACgB,KAAZ,EAAW,EAAU,CAAE,GAC7D,CACD,CAFmE,AAAtC,CAAuC,KAE7D,CACL,OAAA,EAAA,MAAA,EAAA,KAAA,CAAA,CAAS,AAAT,EAAW,GAAX,IAAA,AAAS,AAAE,AAAO,EAClB,EADA,AACA,EAAA,IAAA,GADS,AACC,CAAV,AAAuB,EAAvB,AAAuB,CAEtB,CACH,AAJE,GACA,EADA,CAAA,CAIK,CAHL,AAIA,CAJA,MAIA,EAAA,MAAA,EAAA,KAAA,CAAA,CAAA,AAAS,EAAE,GAAX,IAAW,AAAO,AAAT,AAAT,EACA,EAAA,AADA,EACA,IAAA,GAAU,AADD,CACT,AAAuB,EAAvB,AAAuB,CAEtB,CACJ,AAJG,CAME,EALF,AAKS,EANT,AAMM,CANN,CAMa,CALb,AAKc,CALd,eAK8B,CAAC,MAAM,CACvC,GA+TE,AA/TC,EA+TmC,AA9TtC,CA8TsC,CAAE,CAC5C,AA/TiB,EA+TT,EADO,GACR,AA/TiB,CAAC,CA+TV,AA/TC,CA+TA,CAAC,EAAO,GAAF,AAAK,EACzB,CAAS,CAAC,CADmB,CACf,CAAD,AAAI,CACnB,CAAC,CAAC,CACK,CAFiB,EA/TpB,GAEF,EAAK,CA+TS,CA/TV,KAAQ,EAAE,CAEd,GAJoB,CACnB,EAGK,EAEN,IAAI,EAAmBmB,GAAS,EAFb,CAEY,CAAK,CAAC,MAAjB,GAA0B,CAAE,EAAO,IAAD,CAAM,CAAC,CAC7D,GACE,IAAI,CAAC,SAAS,CAAC,UAAU,EAAE,EAC3B,EAAiB,UAAU,CAAC,GAAZ,UAAyB,CAAC,CAC1C,CACA,IAAM,EAAU,IAAI,CAAP,AAAQ,SAAS,CAAC,UAAU,EAAE,CACrC,EAAW,IAAI,CAAC,CAAR,QAAiB,CAAC,WAAW,EAAE,CAC7C,EACE,CAAA,SAAA,EAAY,EADE,AACmB,KAAd,MAAc,EAAA,EAAW,CAAA,CAAA,CAAG,CAClD,CAED,CAH6C,GAGzC,EAAyC,CAAA,CAAE,CAG7C,IAAI,CAN6D,AAM5D,GAHU,MAGD,CAAC,UAAU,EAAE,EAC3B,CAAA,MAAA,EAAA,CAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,KAAA,GAAE,AAAkB,IAAK,SAAS,EAC/C,GAEsB,IAAlB,EAAO,GAAoB,CAArB,CAAuB,CAAhB,CACf,EAAO,IAAD,EAAO,CAAG,CAAC,kBAAkB,CAAE,CAACuF,GAAe,KAAD,AAAM,CAAC,CAAC,CAE5D,EAAO,IAAD,EAAO,CAAC,kBAAkB,CAAG,CAACA,GAAe,KAAD,AAAM,CAAC,EAGzD,QAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,AAAE,GAAF,EAAA,KAAA,KAAA,CAAA,AAAE,AAAgB,EAAE,CAEnC,OAAO,CAAC,IAAI,CACV,yLAAyL,CAC1L,CAEH,IAAM,EAAa,OAAA,CAAH,CAAG,MAAA,EAAA,CAAA,EAAO,IAAD,EAAC,AAAM,EAAE,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,GAAA,EAAA,AAAK,EAAI,EAAA,CAAT,CAAS,AAAE,CACvC,EAA+B,CADH,AAAS,CAAT,AACK,CACvC,EAF2C,EAAA,AAEtC,IAAM,CADS,AADuB,GAE5B,CAAI,CAFwB,CAAA,AAGrC,IAAI,CAAC,GADkB,CAAE,UACN,CAAC,GAEtB,CAF0B,CAAC,AAEZ,EAFc,EAEV,CAAC,MADC,AACK,CAAZ,CAAyB,EADQ,EACJ,EAAE,CAAC,CAE9C,EAFsC,AAEvB,IAAI,CAAC,GAGpB,CAHsC,CAAC,AAGxB,EAHD,IAGO,CAAG,CAAC,EAAE,CAC7B,CADgB,CACT,IAAD,EAAQ,CAAC,KAAK,CAAG,CAAA,CAAc,CAEvC,IAAM,EAAqD,CACzD,KAAK,CAAE,EACP,MAAM,CAAE,EAAO,CAFU,GAEX,CADS,CACF,CACrB,SAAS,CAAE,EAAO,IAAD,KAAU,CAC5B,CACD,GAAI,IAAI,CAAC,SAAS,CAAC,UAAU,EAAE,CAC7B,CAD+B,QLu7B7B,EAdN,EKx6BiB,AACX,GADcC,CACV,CAAC,CLq7BK,CAdI,EACpB,KKx6BoB,CL06Bd,EAAoC,CAAA,CAFH,AAEK,CAGxC,AAAa,CALsB,EAEzB,CAGO,EAAE,CADjB,EACO,AADK5G,GK36BZ,AAFsD,EL66BR,CAAC,CAAtC,MAA6C,CAArB,AAAsB,CAArB,AAAsB,GAE5DC,GACE,EACA,CAAC,AK/6BsB,CL26BuB,IAGtC,EACA,CAFW,AAET,OAAO,CAAC,CAClBmB,GAAS,EAAW,CAAZ,GAKR,AAAc,GALI,CAKA,CALW,CAAC,AAKV,CAJrB,EAGgBpB,CACL,IADuC,CAAC,QAAd,AAAsB,CAArB,AAAsB,CAAC,GAE9DC,GACE,EACA,CAJ+C,AAI9C,KADO,GADW,AAEV,CAAC,CACV,AA7PU,SACd,AADc,CACqB,CACnC,CAAqC,EAAA,AAIrC,IAAM,EAAuBD,GAAsB,EAuPtB,AAvPkC,CAC7D,OAD2D,CANtB,AAMW,IAAxB,MACN,CACnB,CAAC,MACmB,IAAjB,GAA8B,AAAwB,EAA5B,EAAgC,EAAE,GAAhD,AACdC,GACE,EACA,CAAC,KAHiD,EAG1C,CAAE,AAFS,CACP,iBACgB,CAAC,CAC7BuF,AAj1BA,SAAUA,AACd,CAAkC,EAAA,AAElC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAA2BxF,CAFnB,EA80Bc,AA50B2B,EAAY,CACjE,MANoC,CAK2B,CAAX,QAAxB,MACN,CACvB,CAAC,AAC8B,IAAI,EAAE,CAAlC,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,KAAyB,CAAC,CADrB,AACuB,GAGnD,IAAM,EAAqBD,GAAsB,EAAY,CAC3D,OADyD,CAAX,CAH2B,CAAC,AAGpD,MACN,CACjB,CACyB,AADxB,IAC4B,EAAE,CAA5B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,CADD,OAC6B,CAAC,CAAE,GAGtD,IAAM,EAAqBD,GAAsB,EAAY,CAC3D,GAJsE,CAAC,GAGd,CAAX,EAAxB,MACN,CACjB,CAAC,AACwB,IAAI,EAAE,CAA5B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,CADD,OAC6B,CAAC,CAAE,GAGtD,IAAM,EAA4BD,GAAsB,EAAY,CAClE,GAJsE,CAAC,GAGP,CAAX,SAAxB,MACN,CACxB,CAAC,AAC+B,IAAI,EAAE,CAAnC,GACFC,GACE,EACA,CAAC,KADO,GADW,QADM,OAGD,CAAC,CACzB,GAIJ,IAAM,EAAuBD,GAAsB,EAAY,CAC7D,OAD2D,CAAX,EAJrB,CAC1B,CAGuB,MACN,CACnB,CAAC,AAC0B,IAAI,EAAE,CAA9B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,GADC,OAC6B,CAAC,CAAE,GAGxD,IAAM,EAAeD,GAAsB,EAAY,CAAC,IAAtC,CAH0D,CAAC,CAGxB,CAAX,EAAwB,CAAC,CAAC,AAChD,IAAI,EAAE,CAAtB,GACFC,GAAsB,EAAU,CAAC,GADnB,EACgB,GAAT,EAAsB,CAAC,CAAE,GAGhD,IAAM,EAAsBD,GAAsB,AAHU,CAAC,CAGC,CAC5D,OAD0D,CAAX,GAAxB,MACN,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAsBD,GAAsB,EAAY,CAC5D,IAJwE,CAAC,EAGf,CAAX,GAAxB,MACN,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAsBD,GAAsB,EAAY,CAC5D,IAJwE,CAAC,EAGf,CAAX,GAAxB,MACN,CAClB,CAC0B,AADzB,IAC6B,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAyBD,GAAsB,EAAY,CAC/D,IAJwE,CAAC,EAGZ,CAAX,MAAxB,MACN,CACrB,CAAC,AAC4B,IAAI,EAAE,CAAhC,GACFC,GACE,EACA,CAAC,KADO,GADW,KADG,OAGD,CAAC,CACtB,GAIJ,IAAM,EAAuBD,GAAsB,EAAY,CAC7D,OALwB,AAImC,CAH1D,AAG+C,IAAxB,MACN,CACnB,CAC2B,AAD1B,IAC8B,EAAE,CAA9B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,GADC,OAC6B,CAAC,CAAE,GAGxD,IAAM,EAAuBD,GAAsB,EAAY,CAC7D,KAJ0E,CAAC,CAGhB,CAAX,IAAxB,MACN,CACnB,CAC2B,AAD1B,IAC8B,EAAE,CAA9B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,GADC,OAC6B,CAAC,CAAE,GAGxD,IAAM,EAAyBD,GAAsB,EAAY,CAC/D,KAJ0E,CAAC,CAGd,CAAX,MAAxB,MACN,CACrB,CAAC,AACE,AAA0B,IAAI,EAAE,IAClCC,GACE,EACA,CAAC,KADO,CAFc,EACH,YAEE,CAAC,CACtB,GAIJ,IAAM,EAAqBD,GAAsB,EAAY,CAC3D,OALwB,AAIiC,CAHxD,AAG6C,EAAxB,MACN,CACjB,CACyB,AADxB,IAC4B,EAAE,CAA5B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,CADD,OAC6B,CAAC,CAAE,GAGtD,IAAM,EAAoBD,GAAsB,EAAY,CAC1D,GAJsE,CAAC,GAGf,CAAX,CAAxB,MACN,CAChB,CAAC,AACuB,IAAI,EAAE,CAA3B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,AADF,OAC6B,CAAC,CAAE,GAGrD,IAAM,EAAWD,GAAsB,EAAY,CAArC,AAAsC,EAHkB,CAAC,GAGb,CAAT,AAAU,CAArB,AAAsB,AAC5C,IAAI,EAAE,CAAlB,GACFC,GAAsB,EAAU,AADtB,CACuB,KAAH,CAAS,CAAC,CAAE,AAArB,GAGvB,IAAM,CAH8C,CAAC,AAG5BD,GAAsB,EAAY,CAAC,OAAH,CAAnC,AAAwB,MAA4B,CAAC,CAAC,AACpD,IAAI,EAAE,CAA1B,GACFC,GACE,EACA,CAAC,KADO,EAFQ,CACG,MAEJ,CAAC,CAChBwF,GAAqB,IAIzB,IAAM,EAAoBzF,GAAsB,EAAY,CAC1D,AALuC,CAAC,CACvC,CADqB,IAIkC,CAAX,CAAxB,MACN,CAChB,CAAC,AACuB,IAAI,EAAE,CAA3B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,AADF,OAC6B,CAAC,CAAE,GAGrD,IAAM,EAAkBD,GAAsB,EAAY,CAAC,EAHW,CAAC,IAGlD,AAAmC,CAAX,KAA2B,CAAC,CAClD,AADmD,IAC/C,EAAE,CAAzB,GACFC,GAAsB,EAAU,CAAC,KAAH,CADb,EACI,KAAyB,CAAC,CAAE,GAGnD,IAAM,EAAqBD,GAAsB,EAAY,CAHK,AAIhE,CAJiE,MAGR,CAAX,EAAxB,MACN,CACjB,CAAC,AACE,AAAsB,IAAI,EAAE,IAC9BC,GAAsB,EAAU,CAAC,EADb,GACU,GAAT,QAA4B,CAAC,CAAE,GAGtD,IAAM,EAAWD,GAAsB,EAAY,CAArC,AAAsC,GAHoB,CAAC,EAGf,CAAT,AAAU,CAArB,AAAsB,AAC5C,IAAI,EAAE,CAAlB,GACFC,GAAsB,EAAU,AADtB,CACuB,KAAH,CAAS,CAAC,CAAnB,AAAqB,GAG5C,IAAM,CAH8C,CAAC,AAGpCD,GAAsB,EAAY,CAAC,AAAtC,MAA4C,CAAC,AAAV,CAAW,AAAtB,CAKtC,GAJgB,IAAI,EAAhB,AAAkB,GACpBC,GAAsB,EADZ,AACsB,CAAC,KAAH,CAAS,CAAC,CAAnB,AAAqB,QAAQ,AAKlD,CALmD,GAInDD,GAAsB,EAAY,AACzB,CAD0B,CAEnC,MAFgC,CAAX,oBAA0C,CAAC,CAAC,CAGjE,MAAM,AAAI,KAAK,CACb,qEAAqE,CACtE,CAGH,OAAO,CACT,EAoqB+B,IAI7B,CAzqBe,GAyqBT,EAAyBA,GAAsB,EAAY,CAC/D,IAL+C,CAAC,CAC/C,CAG4D,CAAX,MAAxB,MACN,CACrB,CAAC,AACE,MAAiB,MAAL,CAA4C,EAA9B,EAAkC,EAA9B,AAAgC,GAChEC,GACE,EACA,CAAC,OAAO,CAFW,AAET,CADE,IAFwC,aAGxB,CAAE,oBAAoB,CAAC,CACnD,GAIJ,IAAM,EAAkBD,GAAsB,EAAY,CAAC,OAAH,AAJ9B,AAIL,CAAwB,AAH1C,KAGqE,CAAC,CAAC,AACtE,MAAiB,MAAL,CAAqC,EAAvB,EAA2B,EAAvB,AAAyB,GACzDC,GACE,EACA,CAAC,MAH4C,CAGrC,CAFW,AAET,CADE,iBACgB,CAAE,aAAa,CAAC,CAC5C,GAIJ,IAAM,EAAWD,GAAsB,EAAY,CAJhC,AAIL,AAAsC,CAHjD,KAGuD,CAAT,AAAU,CAArB,AAAsB,MACvC,IAAjB,GAA0C,EAAhB,EAAoB,EAAhB,AAAkB,GAApC,AACdC,GACE,EAFsC,AAGtC,CAAC,OAAO,CAFW,AAET,CADE,iBACgB,CAAE,MAAM,CAAC,CACrC,GAIJ,IAAM,CAJM,CAIKD,AAHd,GAGoC,EAAY,CAAC,AAAtC,MAA4C,CAAC,AAAV,CAAW,AAAtB,MACjB,IAAjB,GAA0C,EAAhB,EAAoB,EAAhB,AAAkB,GAApC,AACdC,GACE,EAFsC,AAGtC,CAAC,OAAO,CAFW,AAET,CADE,iBACgB,CAAE,MAAM,CAAC,CACrC,GAIJ,IAAM,CAJM,CACT,AAGyBD,GAAsB,EAAY,CAC5D,OAD0D,CAAX,GAAxB,MACN,CAClB,CAAC,MACmB,IAAjB,GAAqD,EAA3B,EAA+B,EAAE,AAA7B,GAChCC,AADc,GAEZ,EACA,CAAC,OAAO,CAAE,AAFS,CACP,CAFqC,gBAGrB,CAAE,iBAAiB,CAAC,CAChD,GAIJ,IAAM,EAAsBD,GAAsB,EAAY,CAC5D,IALqB,CACpB,EAGyD,CAAX,GAAxB,MACN,CAClB,CAAC,MACmB,IAAjB,GAAqD,EAA3B,EAA+B,EAA3B,AAA6B,GAA/C,AACdC,GACE,EACA,CAAC,OAAO,CAFW,AAET,CADE,CAFqC,gBAGrB,CAAE,iBAAiB,CAAC,CAChD,GAIJ,IAAM,EAAWD,GAAsB,EAAY,CAArC,AAAsC,IAJ7B,CACpB,CAGuD,CAAT,AAAU,CAAC,AAAtB,MACjB,IAAjB,GAA0C,EAAhB,EAAoB,EAAhB,AAAkB,GAApC,AACdC,GACE,EAFsC,AAGtC,CAAC,OAAO,CAAE,AAFS,CACP,iBACgB,CAAE,MAAM,CAAC,CACrC,GAIJ,IAAM,CAJM,CACT,AAGsBD,GAAsB,EAAY,CAAC,OAAH,CAAnC,AAAwB,MAA4B,CAAC,CAAC,MACvD,IAAjB,GAAkD,EAAxB,EAA4B,EAAE,AAA1B,GAChCC,AADc,GAEZ,EACA,CAAC,OAAO,AAHsC,CAC3B,AAET,CADE,iBACgB,CAAE,cAAc,CAAC,CAC7CwF,GAAqBE,GAAoB,KAI7C,IAAM,EAAqB3F,GAJiB,AAIK,EAAY,AAJrC,AAAqC,CAK3D,AAL4D,CAAC,CAC5D,KAGwD,CAAX,EAAxB,MACN,CACjB,CAAC,MACmB,IAAjB,GAAoD,EAA1B,EAA8B,EAAE,AAA5B,GAChCC,AADc,GAEZ,EACA,CAAC,OAAO,CAFW,AAET,CADE,AAFoC,iBAGpB,CAAE,gBAAgB,CAAC,CAC/C,GAIJ,IAAM,EAA4BD,GAAsB,EAAY,CAClE,GALoB,CACnB,GAG+D,CAAX,SAAxB,MACN,CACxB,CAAC,MACmB,IAAjB,GAA2D,EAAjC,EAAqC,EAAE,AAAnC,GAAlB,AACdC,GACE,EACA,CAAC,OAAO,CAFW,AAET,CADE,OAF2C,UAG3B,CAAE,uBAAuB,CAAC,CACtD,GAIJ,IAAM,EAAwBD,GAAsB,EAAY,CAC9D,OAD4D,CAAX,EAJtB,CAC1B,EAGwB,MACN,CACpB,CAAC,MACmB,IAAjB,GAA8B,AAAyB,EAA7B,EAAiC,EAAE,GAC/DC,AADc,GAEZ,EACA,CAAC,MAHkD,CAG3C,CAAE,AAFS,CACP,kBACiB,CAAC,CAC9B0B,GAAW,IAIf,CAJc,GAIR,EAAY3B,GAAsB,EAAY,CAAC,CAAtC,IAJqB,CAAC,CAIa,AAH/C,AAGyD,CAArB,AAAsB,CAAC,CAC9D,QAAqB,IAAjB,GAA8B,AAAa,EAAjB,EAAqB,IAAE,CAArC,AAA2B,AACzC,IAAI,EAAkB8B,GAAS,EAC3B,CAD0B,IACrB,EAD+B,AAC9B,CAD+B,AAAtB,MACF,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAE,AAAD,EADP,CAAC,AAEvB4B,CA0nBT,AA3nB2C,CADT,EACnB,EAAkB,AAAc,IA2nBxB,AAAbA,CAAmC,EAAA,AACjD,CA3nByB,GA2nBnB,EAAoC,CAAA,CAAE,CAEtC,EAHoB,AAGO1D,CAFnB,EAEyC,EAAY,CACjE,OAD+D,CAAX,QAAxB,MACN,CACvB,CAAC,CACF,GAAgC,IAAI,EAAhC,EAAkC,CACpC,IAAI,EAAkB,EAClB,KAAK,CAAC,KADS,EADO,AAET,CAAC,KAChB,EAAkB,CAF0B,CAEV,GAAG,CAAC,AAAC,EADR,CAAC,AAEvB4D,AAnoDT,CAkoD2C,CADT,EACnB,EAAkB,AAAc,GAloDrCA,CACd,CAAqC,EAAA,AAErC,IAAM,EAAoC,CAAA,CAAE,CAE5C,GAFc,IAgoD0B,CA9nDgB,IAApD5D,GAAsB,CALe,CAKH,AAA2B,CAA1B,CAA4B,MAA/B,CAAX,EAAwB,CAAC,CAAC,CACjD,MAAM,AAAI,KAAK,CAAC,mDAAmD,CAAC,CAGtE,IAAM,EAAkBA,GAAsB,EAAY,CAAC,OAAtC,AAAmC,CAAX,KAA2B,CAAC,CAAC,AACnD,IAAI,EAAE,CAAzB,GACFC,GAAsB,EAAU,CAAC,KAAH,CADb,EACI,KAAyB,CAAC,CAAE,GAGnD,IAAM,EAAWD,GAAsB,EAAY,CAHe,AAGpD,AAAsC,CAHe,KAGT,CAAT,AAAU,CAArB,AAAsB,AAC5C,IAAI,EAAE,CAAlB,GACFC,GAAsB,EADZ,AACsB,CAAC,KAAH,CAAS,CAAC,CAAnB,AAAqB,GAG5C,IAAM,CAH8C,CAAC,AAG9BD,GAAsB,EAAY,CAAC,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,AACpE,AAAkB,IAAI,EAAE,IAC1BC,GAAsB,CADN,CACgB,CAAC,KAAH,GAAT,IAAwB,CAAC,CAAE,GAGlD,IAAM,EAA2BD,GAAsB,EAHS,AAGG,CAHF,AAI/D,OAD+D,CAAX,QAAxB,MACN,CACvB,CAC+B,AAD9B,IACkC,EAAE,CAAlC,GACFC,GACE,EACA,CAAC,KADO,GADW,OADK,OAGD,CAAC,CACxB,GAIJ,IAAM,EAAeD,GAAsB,EAAY,CAAC,IAAtC,GAAmC,CAAX,CAJd,CACzB,AAG+D,CAAC,CAAC,AAChD,IAAI,EAAE,CAAtB,GACFC,GAAsB,EAAU,CAAC,GADnB,EACgB,GAAT,EAAsB,CAAC,CAAE,GAGhD,IAAM,EAAyBD,GAH6B,AAGP,CAHQ,CAGI,CAC/D,OAD6D,CAAX,MAAxB,MACN,CACrB,CAAC,CASF,OAR8B,IAAI,EAA9B,AAAgC,GAClCC,GACE,EACA,CAAC,KADO,GADW,KADG,OAGD,CAAC,CACtB,GAIG,EACT,EA+kD2C,GACpC,CADwC,AACvC,AAjlDS,CAmlDbA,AAH4C,GAGtB,EAAU,CAAC,IAvlDT,CACvB,AAslD6B,GAAT,cAAkC,CAAC,CAAE,EAC3D,CAED,IAAM,EAAgBD,GAAsB,EAAY,CAAC,AAHkB,CAAC,IAGzD,EAAmC,CAAX,GAAyB,CAAC,CAAC,AACjD,IAAI,EAAE,CAAvB,GACFC,GAAsB,EAAU,CAAC,IADlB,CACe,GAAT,GAAuB,CAAC,CAAE,GAGjD,IAAM,EAAmBD,GAAsB,CAHe,CAGH,AAHI,CAGH,OAAH,CAAnC,AAAwB,MAA4B,CAAC,CAAC,AACpD,IAAI,EAAE,CAA1B,GACFC,GAAsB,EAAU,CAAC,KAAH,EADZ,CACG,MAA0B,CAAC,CAAE,GAGpD,IAAM,EAA4BD,GAAsB,EAAY,CAClE,CAJkE,CAAC,KAGH,CAAX,SAAxB,MACN,CACxB,CAAC,AAC+B,IAAI,EAAE,CAAnC,GACFC,GACE,EACA,CAAC,KADO,GADW,QADM,OAGD,CAAC,CACzB,GAIJ,IAAM,EAA0BD,GAAsB,EAAY,CAChE,OAD8D,CAAX,EAJxB,CAC1B,IAG0B,MACN,CACtB,CAAC,AACE,AAA2B,IAAI,EAAE,IACnCC,GACE,EACA,CAAC,KADO,EAFe,CACJ,aAEG,CAAC,CACvB,GAIJ,IAAM,EAAiBD,GAAsB,EAAY,CAAC,MAAtC,CAAmC,CAAX,AAJjB,CACxB,GAGmE,CAAC,CAAC,AAClD,IAAI,EAAE,CAAxB,GACFC,GAAsB,EAAU,CAAC,KADjB,AACc,GAAT,IAAwB,CAAC,CAAE,GAGlD,IAAM,EAAiBD,GAAsB,EAHmB,AAGP,CAHQ,AAGP,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,AAClD,IAAI,EAAE,CAAxB,GACFC,GAAsB,EAAU,CAAC,KAAH,AADd,GACK,IAAwB,CAAC,CAAE,GAGlD,IAAM,EAAkBD,GAAsB,EAHkB,AAGN,CAAC,AAHM,OAGT,AAAnC,CAAwB,KAA2B,CAAC,CAAC,AACtE,AAAmB,IAAI,EAAE,IAC3BC,GAAsB,EADL,AACe,CAAC,KAAH,GAAT,KAAyB,CAAC,CAAE,GAGnD,IAAM,EAAoBD,GAAsB,EAAY,CAC1D,AAJgE,CAAC,MAGT,CAAX,CAAxB,MACN,CAChB,CAAC,CAKF,OAJyB,IAAI,EAAzB,AAA2B,GAC7BC,GAAsB,EAAU,CAAC,KAAH,GADX,AACE,OAA2B,CAAC,CAAE,GAG9C,EACT,EAjsB4B+B,GAAQ,CAgsBnB,CAhsBkB,EAAK,AACjC,CADkC,AACjC,CADkC,AAGtC/B,CA0rBoE,CAAC,CA1rB/C,EAAc,CAAC,OAAO,CAAvB,AAAyB,CAAZ,MAAmB,CAAC,CAAE,EACzD,CAED,IAAM,EAAwBD,GAAsB,EAAY,CAHS,AAIvE,CAJwE,MAGZ,CAAX,KAAxB,MACN,CACpB,CAAC,MACmB,IAAjB,GAAuD,EAA7B,EAAiC,EAA7B,AAA+B,GAAjD,AACdC,GACE,EACA,CAAC,OAAO,CAFW,AAET,CADE,GAFuC,eAGtB,CAAC,CAC9B,GAIJ,IAAM,EAA8BD,GAAsB,EAAY,CACpE,MALuB,CACtB,AAGiE,CAAX,WAAxB,MACN,CAC1B,CAAC,AACE,MAAiB,MAAL,CAAiD,EAAnC,EAAuC,EAAE,AAArC,GAChCC,GACE,EACA,CAAC,OAAO,CAFW,AAET,CADE,SAF6C,eAGtB,CAAC,CACpC,GAIJ,IAAM,EAA+BD,GAAsB,EAAY,CACrE,OADmE,CAAX,IAJ3B,CAC5B,OAG+B,MACN,CAC3B,CAAC,MACmB,IAAjB,GAA8D,EAApC,EAAwC,EAApC,AAAsC,GACtEC,AADc,GAEZ,EACA,CAAC,OAAO,CAFW,AAET,CADE,UAF8C,eAGtB,CAAC,CACrC,GAIJ,IAAM,EAA0BD,GAAsB,EAAY,CAChE,OAD8D,CAAX,KAJrB,CAC7B,CAG0B,MACN,CACtB,CAAC,MACmB,IAAjB,GAAyD,EAA/B,EAAmC,EAA/B,AAAiC,GAAnD,AACdC,GACE,EACA,CAAC,OAAO,CAFW,AAET,CADE,KAFyC,eAGtB,CAAC,CAChC,GAIJ,IAAM,EAA+BD,GAAsB,EAAY,CACrE,OADmE,CAAX,AAJ/B,CACxB,WAG+B,MACN,CAC3B,CAAC,MACmB,IAAjB,GAA8D,EAApC,EAAwC,EAApC,AAAsC,GAAxD,AACdC,GACE,EACA,CAAC,OAAO,CAFW,AAET,CADE,UAF8C,eAGtB,CAAC,CACrC,GAIJ,IAAM,EAAkBD,GAAsB,EAAY,CAAC,OAAtC,AAAmC,CAAX,KAJb,AAIwC,CAHrE,AAGsE,CAAC,CAS1E,OAAO,KARc,GAQN,CARX,GAAiD,EAAvB,EAA2B,EAAvB,AAAyB,GAA3C,AACdC,GACE,EACA,CAAC,MAH4C,CAGrC,CAFW,AAET,CADE,YACW,CAAC,CACxB,GAnMsC,CAAA,CAAE,AAwM9C,EAiDgC,EAAY,MAtDvB,AA0DZ,CAzDJ,AKn4BE,CLw7BmC,AAAU,CAAC,CAChD,IAGY,SAlDf,EKv4BM,IAAI,CAAC,ELu4BS,EACpB,KKx4BoB,CL04Bd,EAAoC,CAAA,CAFH,AAEK,CAGxC,AAAa,CALsB,EAEzB,CAGO,EAAE,CADjB,EAAYD,AACL,KADuC,CAAC,CAAtC,MAA6C,CAArB,AAAsB,CAArB,AAAsB,GAE5DC,GACE,EACA,CAAC,CAJ6C,IAGtC,EACA,CAFW,AAET,OAAO,CAAC,CAClBmB,GAAS,EAAW,CAAZ,GAKR,AAAc,GALI,CAKA,CALW,CAAC,AAKV,CAJrB,AAGG,EAAapB,CACL,EKr5BR,ELo5B+C,CAAC,EAAtC,MAA8C,AAAtB,CAAuB,AAAtB,CAAuB,GAE9DC,GACE,EACA,AKx5BuB,CLo5BwB,AAI9C,KADO,GADW,AAEV,CAAC,CA/aA,AAgbVyF,SAhbUA,AACd,CAAmC,CACnC,CAAqC,EAAA,AAIrC,IAAM,EAAuB1F,GAAsB,EAAY,CA0anC,AAza1B,OAD2D,CAAX,CANZ,GAMZ,MACN,CACnB,CAAC,AACmB,SAAS,CAA1B,GAAsD,IAAI,EAAE,AAA9B,GAChCC,AADc,GAEZ,EACA,CAAC,OAAO,CAFW,AAET,CADE,EAFsC,eAGtB,CAAC,CAC7B,GAIJ,IAAM,EAAyBD,GAAsB,EAAY,CAC/D,KALsB,CACrB,CAG4D,CAAX,MAAxB,MACN,CACrB,CAAC,MACmB,IAAjB,GAAwD,EAA9B,EAAkC,EAAE,AAAhC,GAAlB,AACdC,GACE,EACA,CAAC,OAAO,CAFW,AAET,CADE,IAFwC,aAGxB,CAAE,oBAAoB,CAAC,CACnD,GAIJ,IAAM,EAAkBD,GAAsB,EAAY,CAAC,OAJjC,AAIL,AAAmC,CAHrD,AAG0C,KAA2B,CAAC,CAAC,MACrD,IAAjB,GAAiD,EAAvB,EAA2B,EAAvB,AAAyB,GACzDC,AADc,GAEZ,EACA,CAAC,MAH4C,CAGrC,CAFW,AAET,CADE,iBACgB,CAAE,aAAa,CAAC,CAC5C,GAIJ,IAAM,EAAWD,GAAsB,EAAY,CAArC,AAAsC,AAJjC,CAChB,KAGuD,CAAT,AAAU,CAArB,AAAsB,MACvC,IAAjB,GAA0C,EAAhB,EAAoB,EAAhB,AAAkB,GAApC,AACdC,GACE,EAFsC,AAGtC,CAAC,OAAO,CAFW,AAET,CADE,iBACgB,CAAE,MAAM,CAAC,CACrC,GAIJ,IAAM,CAJM,CAIKD,AAHd,GAGoC,EAAY,CAArC,AAAsC,MAAM,CAAT,AAAU,CAArB,AAAsB,MACvC,IAAjB,GAA0C,EAAhB,EAAoB,EAAhB,AAAkB,GAApC,AACdC,GACE,EAFsC,AAGtC,CAAC,OAAO,CAFW,AAET,CADE,iBACgB,CAAE,MAAM,CAAC,CACrC,GAIJ,IAAM,CAJM,CACT,AAGyBD,GAAsB,EAAY,CAC5D,OAD0D,CAAX,GAAxB,MACN,CAClB,CAAC,AACmB,SAAS,CAA1B,GAAqD,IAAI,EAA3B,AAA6B,GAA/C,AACdC,GACE,EACA,CAAC,OAAO,CAAE,AAFS,CACP,CAFqC,gBAGrB,CAAE,iBAAiB,CAAC,CAChD,GAIJ,IAAM,EAAsBD,GAAsB,EAAY,CAC5D,IALqB,CACpB,EAGyD,CAAX,GAAxB,MACN,CAClB,CAAC,MACmB,IAAjB,GAAqD,EAA3B,EAA+B,EAA3B,AAA6B,GAA/C,AACdC,GACE,EACA,CAAC,OAAO,CAAE,AAFS,CACP,CAFqC,gBAGrB,CAAE,iBAAiB,CAAC,CAChD,GAIJ,IAAM,EAAWD,GAAsB,EAAY,CAArC,AAAsC,IAJ7B,CACpB,CAGuD,CAAT,AAAU,CAAC,AAAtB,MACjB,IAAjB,GAA0C,EAAhB,EAAoB,EAAhB,AAAkB,GAApC,AACdC,GACE,EAFsC,AAGtC,CAAC,OAAO,CAFW,AAET,CADE,iBACgB,CAAE,MAAM,CAAC,CACrC,GAIJ,IAAM,CAJM,CACT,AAGsBD,GAAsB,EAAY,CAAC,OAAH,CAAnC,AAAwB,MAA4B,CAAC,CAAC,MACvD,IAAjB,GAAkD,EAAxB,EAA4B,EAAxB,AAA0B,GAA5C,AACdC,GACE,EACA,CAAC,OAAO,AAHsC,CAC3B,AAET,CADE,iBACgB,CAAE,cAAc,CAAC,CAC7C0F,GAAoB,IAIxB,IAAM,EAAqB3F,GAAsB,CAJ1B,CAIsC,CAJrB,AAKtC,CALuC,CACtC,KAGwD,CAAX,EAAxB,MACN,CACjB,CAAC,AACE,MAAiB,MAAL,CAAwC,EAA1B,EAA8B,EAA1B,AAA4B,GAC5DC,GACE,EACA,CAAC,OAAO,CAFW,AAET,CAHsC,AAEpC,iBACgB,CAAE,gBAAgB,CAAC,CAC/C,GAIJ,IAAM,EAA4BD,GAAsB,EAAY,CAClE,GALoB,CACnB,GAG+D,CAAX,SAAxB,MACN,CACxB,CAAC,MACmB,IAAjB,GAA2D,EAAjC,EAAqC,EAAE,AAAnC,GAChCC,AADc,GAEZ,EACA,CAAC,OAAO,CAFW,AAET,CADE,OAF2C,UAG3B,CAAE,uBAAuB,CAAC,CACtD,GAIJ,IAAM,EAAwBD,GAAsB,EAAY,CAC9D,OAD4D,CAAX,EAJtB,CAC1B,EAGwB,MACN,CACpB,CAAC,AACE,MAAiB,MAAL,CAA2C,EAA7B,EAAiC,EAA7B,AAA+B,GAC/DC,GACE,EACA,CAAC,OAAO,CAAE,AAFS,CACP,GAFuC,eAGtB,CAAC,CAC9BgB,AAt1BA,SAAUA,AACd,CAAyB,EAAA,AAEzB,IAm1BkB,AAn1BZ,EAAoC,CAAA,CAAE,CAEtC,EAAYjB,CAFJ,CAHc,CAKY,EAAY,CAAC,CAAtC,MAAmC,AAAU,CAAC,AAAtB,CAAuB,CAC9D,GAAiB,IAAI,EAAjB,EAAmB,CACrB,IAAI,EADO,AACW,EAClB,KAAK,CAAC,CADqB,IAAZ,EACF,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,CACW,CADT,EACnB,EAAkB,AAAc,SAk+C7C,IAcA,IAgBA,EAKA,CAnCW,CA8CX,EAOA,EAOA,AA9CY,QAgBI,AA8BR,CArER,EAAoC,CAAA,CAAE,CAKxC,AAAqB,AAkDD,GAXK,AA5Cf,CA8DY,AAzDG,EAAE,CAHzB,EAAoBA,GAHA,EAv9CD,EA09CmC,CAGvC,AAFnB,CA39C2B,CAAC,GAu9CkB,CAGD,CAHC,AAGzB,AAAyB,QAC/B,CAChB,CAFyD,AAExD,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,OAA2B,CAAC,CAAE,GAIjD,AAAe,IAAI,EAAE,GADLD,EACL,CAD2B,EAAY,AAHgB,CAGf,AAHgB,OAGnB,CAAX,CAAuB,CAAC,CAAC,GAEhEC,GAAsB,EAAU,CAAC,KAAH,GAAT,CAAqB,CAAC,CAAE,GAI3C,AAAkB,IAAI,EAAE,CADtB,CAHoD,CAAC,AAGpCD,GAAsB,EAAY,AACvC,CADwC,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,GAEtEC,GACE,EACA,CAAC,KADO,GADW,IAEN,CAAC,CACdY,GAAY,IAKZ,AAAgB,IAAI,EALT,AAKW,GADLb,CAJS,CAAC,CAKf,AAD2B,AAHxC,EAGoD,CAAC,OAAH,CAAX,EAAwB,CAAC,CAAC,GAElEC,GACE,EACA,CAAC,KADO,GADW,EAER,CAAC,CACZwB,AAt+CA,SAAUA,AACd,CAA0B,EAAA,AAE1B,IAAM,CAm+Ca,CAn+CuB,CAAA,CAAE,CAE5C,GAFc,EAHe,GAK8B,IAAvDzB,GAAsB,EAAY,AAA8B,CAA7B,CAA+B,MAAlC,CAAX,KAA2B,CAAC,CAAC,CACpD,MAAM,AAAI,KAAK,CAAC,uDAAuD,CAAC,CAG1E,IAAM,EAAcA,GAAsB,EAAY,CAAC,GAAtC,IAAmC,CAAX,CAAuB,CAAC,CAC9C,AAD+C,IAC3C,EAAE,CAArB,GACFC,GAAsB,EAAU,CAAC,EADpB,GACiB,GAAT,CAAqB,CAAC,CAAE,GAG/C,IAAM,EAAeD,EAHqC,CAAC,AAGhB,EAAY,CAAC,IAAtC,GAAmC,CAAX,EAAwB,CAAC,CAAC,CAKpE,OAJoB,IAAI,EAApB,AAAsB,GACxBC,GAAsB,EAAU,CAAC,GADnB,EACgB,GAAT,EAAsB,CAAC,CAAE,GAGzC,CACT,EAk9CsB,IAOhB,AAAwB,CA19Cb,CAH6C,CAAC,CA69C7B,EAAE,CAH5B,CAJ0B,CAAC,AAIJD,CAH1B,EAGgD,EAAY,CAC7D,KAEsB,EAHqC,CAAX,IAAxB,MACN,CACnB,CAAC,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,UAA8B,CAAC,CAAE,GAIhC,AAApB,IAAwB,EAAE,GADLD,GAAsB,EAAY,CAAC,CACxC,CAJwD,CAAC,IAGpB,CAAX,MAA4B,CAAC,CAAC,GAE1EC,GAAsB,EAAU,CAAC,KAAH,GAAT,MAA0B,CAAC,CAAE,GAMhD,AAA2B,IAAI,EAAE,GAHLD,GAAsB,CAHc,CAAC,AAGH,CAChE,OAD8D,CAGrC,AAH0B,aAC9B,CACtB,CAAC,GAEAC,GACE,EACA,CAAC,KADO,GADW,aAEG,CAAC,CACvB,GAOA,AAAsB,IAAI,EAAE,GAHLD,GAAsB,EAAY,CAC3D,GAEoB,EAPK,CACxB,CAGwD,CAAX,QAC9B,CACjB,CAAC,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,QAA4B,CAAC,CAAE,GAMlD,AAAwB,IAAI,EAAE,GAHLD,GAAsB,EAAY,CAHS,AAItE,CAJuE,IAMjD,EAHqC,CAAX,UAC9B,CACnB,CAAC,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,UAA8B,CAAC,CAAE,GAIpD,AAAY,IAAI,EAAE,EAAV,CADKD,GAAsB,EAAY,CAAC,EAHwB,CAAC,GAGnB,CAAT,AAAU,CAArB,AAAsB,GAE1DC,GAAsB,EAAU,CAAC,KAAH,CAAS,CAAC,CAAnB,AAAqB,GAGrC,GAjiDF,CAAC,CAEJA,AA4hDkD,CAAC,EAGtC,AA/hDS,EAAU,CAAC,KAAH,EAAU,CAAnB,AAAoB,CAAE,EAC5C,CAED,IAAM,EAAWD,GAAsB,EAAY,CAHS,AAG9C,AAAsC,CAHS,KAGH,CAAT,AAAU,CAArB,AAAsB,CAK5D,OAJI,AAAY,IAAI,EAAE,EAAV,CACVC,GAAsB,EAAU,CAAC,KAAH,CAAS,CAAC,CAAE,AAArB,GAGhB,CACT,EAg0BqB0B,EAp0BiC,CAAC,AAo0BvB,EAj0Bf,GAi0Bc,AAI7B,IAAM,EAAY3B,GAAsB,EAAY,CAAC,CAAtC,GAJoC,CAAC,CAAC,CAIO,AAHzD,AAG+C,CAAX,AAAsB,CAAC,CAC9D,QAAqB,IAAjB,GAA2C,EAAjB,EAAqB,EAAjB,EAAmB,CAArC,AACd,IAAI,EADqC,AACnB8B,GAAS,GAAD,AAC1B,KAAK,CAD+B,AAC9B,CADS,AAAsB,MACxB,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,AAEvBC,CADkC,AA4vB3C,CA7vBkC,EACnB,EAAkB,AAAc,IA4vBrCA,AAAY,CAAsB,EAAA,AAChD,AA5vBwB,IA4vBlB,EAAoC,CAAA,CAAE,CAEtC,CAHmB,CAGQ/B,CAFnB,EAEyC,EAAY,CACjE,OAD+D,CAAX,QAAxB,MACN,CACvB,CAAC,CACF,GAAgC,IAAI,EAAhC,EAAkC,CACpC,IAAI,EAAkB,EAClB,KAAK,CAAC,KADS,EADO,AAET,CAAC,KAChB,EAAkB,CAF0B,CAEV,GAAG,CAAC,AAAC,EADR,CAAC,AAEvB,CADkC,CAE1C,AAHiC,CAGhC,CAFa,AACF,AAGfC,EAJiD,AAAd,CAIb,EAAU,CAAC,KAAH,GAAT,cAAkC,CAAC,CAAE,EAC3D,CAED,GAAID,KAAqD,IAHkB,CAAC,EAGlD,EAAD,AAAa,AAA4B,CAA3B,CAA6B,MAAhC,IAAc,CAAC,CAAC,CAClD,MAAM,AAAI,KAAK,CAAC,qDAAqD,CAAC,CAGxE,IAAM,EAAmBA,GAAsB,EAAY,CAAC,OAAH,CAAnC,AAAwB,MAA4B,CAAC,CAAC,AACxE,AAAoB,IAAI,EAAE,IAC5BC,GACE,EACA,CAAC,AAHe,KAER,GADW,MAEJ,CAAC,CAChBoC,AA/0CA,SAAUA,AACd,CAA8B,EAAA,AAE9B,IAAM,EAAoC,CAAA,CAAE,CA40CrB,AA10CjB,EAAsBrC,CAFd,EAEoC,EAAY,CAC5D,CAN+B,MAK2B,CAAX,GAAxB,MACN,CAClB,CAAC,CAKF,GAJ2B,IAAI,EAA3B,AAA6B,GAC/BC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,QAGO,IAA1DD,GAAsB,EAAY,AAAiC,CAAhC,CAHmC,AAGD,CAHE,KAGvC,CAAX,QAA8B,CAAC,CAAC,CACvD,MAAM,AAAI,KAAK,CAAC,0DAA0D,CAAC,CAG7E,OAAO,CACT,EA8zC0B,IAIxB,CAn0Ce,GAm0CT,EAA4BA,GAAsB,EAAY,CAJ5B,AAKtC,CALuC,CACtC,KAG+D,CAAX,SAAxB,MACN,CACxB,CAAC,CASF,GARiC,IAAI,EAAjC,AAAmC,GACrCC,GACE,EACA,CAAC,KADO,GADW,QADM,OAGD,CAAC,CACzB,QAK6D,IAA/DD,GAAsB,EAAY,AAAsC,CAArC,CACnC,MAN2B,AAKK,CAAX,AAJpB,aAIuD,CAAC,CAAC,CAE1D,MAAM,AAAI,KAAK,CACb,+DAA+D,CAChE,CAGH,IAAM,EAAiBA,GAAsB,EAAY,CAAC,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CACjD,AADkD,IAC9C,EAAE,CAAxB,GACFC,GACE,EACA,CAAC,KAHa,AAEN,GADW,IAEN,CAAC,CACdmC,AA53CA,SAAUA,AACd,CAA4B,EAAA,AAE5B,IAAM,EAAoC,CAAA,AAy3CrB,CAz3CuB,CAE5C,GAFc,IAHiB,CAK2B,IAAtDpC,GAAsB,EAAyC,AAA7B,CAAC,CAA8B,MAAjC,CAAX,IAA0B,CAAC,CAAC,CACnD,MAAM,AAAI,KAAK,CAAC,sDAAsD,CAAC,CAGzE,IAAM,EAAmBA,GAAsB,EAAY,CAAC,OAAH,CAAnC,AAAwB,MAA4B,CAAC,CAAC,CAK5E,OAJwB,IAAI,EAAxB,AAA0B,GAC5BC,GAAsB,EAAU,CAAC,KAAH,EADZ,CACG,MAA0B,CAAC,CAAE,GAG7C,CACT,EA62CwB,IAItB,CAl3Ce,GAk3CT,EAAiBD,AAr3C6C,CAAC,EAq3CxB,CAJT,CAAC,AAIoB,CAHtD,AAGuD,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,AAClD,IAAI,EAAE,CAAxB,GACFC,GAAsB,EAAU,CAAC,KADjB,AACc,GAAT,IAAwB,CAAC,CAAE,GAGlD,IAAM,EAAkBD,GAAsB,EAAY,AAHM,CAGL,AAHM,OAGT,AAAnC,CAAwB,KAA2B,CAAC,CAAC,AACtE,AAAmB,IAAI,EAAE,IAC3BC,GAAsB,EAAU,AADf,CACgB,KAAH,GAAT,KAAyB,CAAC,CAAE,GAGnD,IAAM,EAAoBD,GAAsB,EAAY,CAHM,AAIhE,CAJiE,MAGT,CAAX,CAAxB,MACN,CAChB,CAAC,CAKF,OAJyB,IAAI,EAAzB,AAA2B,GAC7BC,GAAsB,EAAU,CAAC,KAAH,GADX,AACE,OAA2B,CAAC,CAAE,GAG9C,CACT,GAt0B2B+B,GAAQ,CAq0BlB,CAr0BiB,EAC3B,AADgC,CAC/B,AADgC,CAAC,AAGrC/B,CA+zBoE,CAAC,CA/zB/C,EAAc,CAAC,OAAO,CAAE,AAAzB,CAAa,MAAmB,CAAC,CAAE,EACzD,CAED,IAAM,EAAwBD,GAAsB,EAAY,CAHS,AAIvE,CAJwE,MAGZ,CAAX,KAAxB,MACN,CACpB,CAAC,MACmB,IAAjB,GAAuD,EAA7B,EAAiC,EAAE,AAA/B,GAChCC,AADc,GAEZ,EACA,CAAC,OAAO,CAFW,AAET,CADE,GAFuC,eAGtB,CAAC,CAC9B2F,AAmsBA,SAAUA,AACd,CAAyC,EAAA,AAEzC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAa5F,CAFL,EAE2B,EAAY,CAAC,EAAtC,CAxsBkB,IAwsBiB,CAAX,AAAsB,CAAC,CAAC,CAKhE,CAV4C,EAM1B,IAAI,EAAE,AAApB,GACFC,GAAsB,EAAU,CAAC,CADrB,IACkB,GAAT,AAAoB,CAAC,CAAE,QAGa,EAHH,CAAC,CAGrDD,GAAsB,EAAY,AAA8B,CAA7B,CAA+B,MAAlC,CAAX,KAA2B,CAAC,CAAC,CACpD,MAAM,AAAI,KAAK,CAAC,uDAAuD,CAAC,CAG1E,OAAO,CACT,EAltBqC,IAInC,CA6sBe,GA7sBT,EAA8BA,GAAsB,EAAY,CACpE,KALsD,CAAC,CACtD,AAGiE,CAAX,WAAxB,MACN,CAC1B,CAAC,MACmB,IAAjB,GAA6D,EAAnC,EAAuC,EAAnC,AAAqC,GAAvD,AACdC,GACE,EACA,CAAC,OAAO,CAFW,AAET,CADE,SAF6C,eAGtB,CAAC,CACpC,GAIJ,IAAM,EAA+BD,GAAsB,EAAY,CACrE,OADmE,CAAX,IAJ3B,CAC5B,OAG+B,MACN,CAC3B,CAAC,MACmB,IAAjB,GAA8D,EAApC,EAAwC,EAApC,AAAsC,GAAxD,AACdC,GACE,EACA,CAAC,OAAO,CAFW,AAET,CADE,UAF8C,eAGtB,CAAC,CACrC,GAIJ,IAAM,EAA0BD,GAAsB,EAAY,CAChE,OAD8D,CAAX,KAJrB,CAC7B,CAG0B,MACN,CACtB,CAAC,AACE,MAAiB,MAAL,CAA6C,EAA/B,EAAmC,EAAE,AAAjC,GAChCC,GACE,EACA,CAAC,OAAO,CAFW,AAET,CADE,KAFyC,eAGtB,CAAC,CAChC,GAIJ,IAAM,EAA+BD,GAAsB,EAAY,CACrE,OADmE,CAJ1C,AAI+B,CAHvD,WAG+B,MACN,CAC3B,CAAC,AACmB,AAAjB,SAA0B,GAAd,CAAkD,IAAI,EAAE,AAAtC,GAChCC,GACE,EACA,CAAC,OAAO,CAAE,AAFS,CACP,UAF8C,eAGtB,CAAC,CACrC,GAIJ,IAAM,EAAkBD,GAAsB,EAAY,CAAC,OAAtC,AAAmC,CAAX,KAJb,AAIwC,CAHrE,AAGsE,CAAC,CAS1E,OAAO,KARc,GAQN,CARX,GAAiD,EAAvB,EAA2B,EAAvB,AAAyB,GAA3C,AACdC,GACE,EACA,CAAC,MAH4C,CAGrC,CAFW,AAET,CADE,YACW,CAAC,CACxB,GAnMsC,CAAA,CAAE,AAwM9C,EAoO+B,EAAY,IK35BrC,ELkrBe,AA6OZ,CA5OJ,AKhrBE,CAIH,ALo5BqC,AAAU,CAAC,CAC/C,IAGY,CK15Bb,EALe,GAAG4G,EAKX,EAAc,MAAS,CAC9B,CAD6B,CACxB,EADe,AAChB,EAAK,CAAC,IAAI,CAAC,KAN0C,IAMjC,CAAC,IAClB,IAAI,GAAQ,EAAM,AADa,CAAC,CAAC,AACtB,AAAK,EAAM,CAAC,SAAS,CAAC,CAIlC,cAAc,CAAC,CAAqB,CAAA,CAC1C,MAAO,UAAU,GAAI,GAAQ,AAAyB,CAA7B,SAAuC,SAA5B,EAAK,EAAD,MAAS,CAEpD,CAED,IAAM,GACJ,CACE,YAAY,EAAE,EACf,AAMC,EAPkB,KAQT,GACX,IADkB,CAAA,IAVyB,EAYhC,CAAA,CAAe,CACP,CAAoB,CAAA,CAD5B,IAAI,CAAA,IAAA,CAAJ,EACQ,EADJ,EACa,CAAA,SAAA,CAAT,EAGX,OAHoB,WAGF,CACxB,CAAoB,CACpB,CAA6C,CAAA,CAE7C,GAAqB,IAAI,GAArB,EAAO,IAAD,CAAM,OAA8B,IAAjB,EAAO,GAAmB,CAApB,CAAM,CAAgB,CACvD,IAAI,EAA4B,EAAE,CAClC,GAAI,AADQ,CAEV,EAAWvE,GAAY,EAAO,CAAtB,GAAc,AAAO,CAAgC,CAAC,CACzD,AAAD,EAAW,OAAD,GAAW,EAAE,EAAE,CAC3B,EAAW,EAAS,GAAG,CAAf,AAAgB,AAAC,EAAN,CAAerB,CAAL,EAAoB,GAAK,CAAD,AAAE,AAE1D,CAAC,MAAM,EAAA,AAF4C,AAE5C,CACN,MAAM,AAAI,KAAK,CACb,CAAkD,+CAAA,EAAA,OAAO,EAAO,IAAD,CAAM,CAAG,CAAA,CAAA,CACzE,AACF,CACD,MAAO,CACL,aAAa,CAAE,CAAC,KAAK,CAAE,EAAU,MAAF,MAAc,CAAE,EAAO,IAAD,QAAa,CAAC,CACpE,AACF,CAED,MAAO,CACL,aAAa,CAAE,CAAC,YAAY,CAAE,EAAO,IAAD,QAAa,CAAC,CACnD,CAGK,wBAAwB,CAC9B,CAAoB,CACpB,CAA4C,CAAA,CAE5C,IAAI,EAA8C,EAAE,CAEpD,GAAgC,IAAI,EAAhC,AAAkC,EAA3B,CAFU,GAEX,aAAkB,EAUK,CAAC,EAAE,CAAhC,CAHF,EAHG,KAAK,CAAC,OAAO,CAMG,AANF,CAGA,CAHO,IAAD,aAAkB,CAAC,CAGtB,CAHwB,CAGjB,IAAD,aAAkB,CAFxB,CAAC,EAAO,IAAD,aAAkB,CAAC,EAK1B,MAAM,CAT1B,MAAM,AAAI,KAAK,CAAC,gCAAgC,CAAC,CAanD,IAAK,IAAM,KAAoB,EAAmB,CAChD,GACE,AAA4B,KAFL,GAEa,GAFQ,MAErC,GACc,IAAI,GAAzB,GACA,CAAA,CAAE,CAFqB,KAEf,GAAI,CAAA,CAAgB,AADZ,CACa,CAC7B,CAAA,CAAE,UAAU,GAAI,CAAA,CAAgB,CAAC,AAEjC,EADA,IACM,AAAI,KAAK,CACb,CAAA,yCAAA,EAA4C,OAAO,EAAgB,EAAA,CAAI,CACxE,CAEH,GAAI,CAAC,EAAU,GAHwD,IAGzD,GAAW,EAAE,EAAI,CAAE,AAAF,IAAM,IAAI,CAAA,CAAgB,CAAC,AACxD,EAD0D,IACpD,AAAI,KAAK,CAnVrB,AAmVsB,6BAA6B,CAAC,kFAnV4D,CAqV7G,CAKD,MAH+C,CAC7C,AAEK,YAFO,CAAE,AAEI,CAFH,iBAAiB,CAAE,CAAiB,CAAC,CACrD,CAqDH,aAtDuD,IAsDtC,CAAC,CAA6C,CAAA,CAC7D,EACK,IADC,EACD,CAAA,MAAA,CAAA,MAAA,CAAA,MAAA,CAAA,CAAA,CAAA,CAAA,IACA,GAGL,GAHW,CACV,AAEK,EAAyC,IAAI,CAAC,MAAjC,YAAmD,CACpE,EAL0C,CACvC,CAIC,CAAC,SAAS,CACd,GAEF,GAFQ,CACP,AACG,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,IAyBhC,SAzB6C,CAAC,CAAC,MAyB9B,CAAC,CAA6C,CAAA,CAC7D,IAAI,EAAyC,CAAA,CAAE,CAG7C,EADE,IAAI,CAAC,CAFQ,KAGF,GADG,CAAC,UAAU,EAAE,CACb,CACd,AAF6B,cAG3B6F,AL87BJ,CK/7BiB,QL+7BP,AACd,CAAiD,EAEjD,AAFiD,IAE3C,EAAoC,CAAA,CAAE,CAEtC,EAAY9G,CAFJ,EAE0B,EAAY,CAAC,CAAtC,MAAmC,AAAU,CAArB,AAAsB,CAAC,CKn8BJ,ALo8B1D,GAAiB,IAAI,EANgC,AAMjD,EAAmB,CACrB,IAAI,EAAkB6F,AADX,GACoB,GAAD,AAC1B,KAAK,CAD+B,AAC9B,CAD+B,AAAtB,MACF,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAEtB,AAFuB,CACW,CAE1C,AAHiC,CAGhC,CADW,AAGf5F,AAJiB,EAAgC,AAAd,CAIb,EAAU,CAAC,KAAH,GAAT,KAAyB,CAAC,CAAE,EAClD,CAED,IAAM,EAAYD,GAAsB,EAAY,CAHc,AAGb,CAHc,AAGpD,MAAmC,AAAU,CAArB,AAAsB,CAAC,AAC7C,IAAI,EAAE,CAAnB,GACFC,GAAsB,EAAU,CADrB,AACsB,KAAH,EAAU,CAAnB,AAAoB,CAAE6F,GAAa,IAG1D,GAHyD,CAGnD,CAH6D,CAAC,AAGzC9F,CAH0C,EAGpB,EAAY,CAC3D,OADyD,CAAX,EAAxB,MACN,CACjB,CAAC,AACwB,IAAI,EAAE,CAA5B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,CADD,OAC6B,CAAC,CAAE,GAGtD,IAAM,EAAYD,GAAsB,EAAY,CAAC,CAAtC,EAHyD,CAAC,GAGvB,AAAU,CAArB,AAAsB,CAAC,AAC7C,IAAI,EAAE,CAAnB,GACFC,GAAsB,EAAU,CAAC,AADtB,KACmB,EAAU,CAAnB,AAAoB,CAAE8F,GAAa,IAG1D,GAHyD,CAGnD,CAH6D,CAAC,AAGnD/F,CAHoD,EAG9B,EAAY,CAArC,AAAsC,MAAM,CAAC,AAAV,CAAW,AAC5C,AADsB,IAClB,EAAE,CAAlB,GACFC,GAAsB,EADZ,AACsB,CAAC,KAAH,CAAS,CAAC,CAAnB,AAAqB,GAG5C,IAAM,CAH8C,CAAC,AAG3BD,GAAsB,EAAY,CAC1D,OADwD,CAAX,CAAxB,MACN,CAChB,CAAC,AACuB,IAAI,EAAE,CAA3B,GACFC,GAAsB,EAAU,CAAC,KAAH,GADX,AACE,OAA2B,CAAC,CAAE,GAGrD,IAAM,EAAkBD,GAAsB,EAAY,CAAC,EAHW,CAAC,IAGlD,AAAmC,CAAX,KAA2B,CAAC,CAAC,CAK1E,OAJuB,IAAI,EAAvB,AAAyB,GAC3BC,GAAsB,EAAU,CAAC,KAAH,CADb,EACI,KAAyB,CAAC,CAAE,GAG5C,CACT,EKj/B6D,GACtD,CAEe,CL6+BL,AK5+BT,CAJ2D,CAAC,EL6+BA,CAAC,SKx+B3D8G,AL43BJ,CK73BiB,QL63BP,AACd,CAAiD,EAAA,AAEjD,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAY/G,CAFJ,EAE0B,EAAY,CAAC,CAAtC,MAAmC,AAAU,CAArB,AAAsB,CAAC,AKj4BL,CLk4BzD,GAAiB,IAAI,CAN+B,CAMhD,EAAmB,CACrB,IAAI,EADO,AACW6F,GAAS,GAAD,AAC1B,KAAK,CAD+B,AAC9B,CADS,AAAsB,MACxB,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAEtBhF,AAFuB,CACW,CADT,CAEb,CADN,EAAgC,AAE9C,AAFgC,CACR,AACvB,CADwB,AAG5BZ,GAAsB,EAHA,AAGU,CAAC,KAAH,GAAT,KAAyB,CAAC,CAAE,EAClD,CAED,IAAM,EAAYD,GAAsB,EAAY,CAHc,AAGb,CAHc,AAGpD,MAAmC,AAAU,CAArB,AAAsB,CAAC,AAC7C,IAAI,EAAE,CAAnB,GACFC,GACE,EACA,CAAC,AAHQ,KAED,EACA,CAFW,AAEV,CACTY,GAAYiF,GAAa,KAI7B,EAJe,AAAa,EAItB,AAJgC,CAAC,CAAC,AAIb9F,CAHxB,EAG8C,EAAY,CAC3D,OADyD,CAAX,EAAxB,MACN,CACjB,CAAC,AACwB,IAAI,EAAE,CAA5B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,CADD,OAC6B,CAAC,CAAE,GAGtD,IAAM,EAAYD,GAAsB,EAAY,CAAC,CAAtC,EAHyD,CAAC,GAGvB,AAAU,CAArB,AAAsB,CAAC,AAC7C,IAAI,EAAE,CAAnB,GACFC,GACE,EACA,CAHS,AAGR,KADO,EACA,CAAC,AAFU,CAGnBY,GAAYkF,GAAa,KAI7B,EAJe,AAAa,EAAU,AAIhC,CAJiC,CAItB/F,AAJuB,CACrC,EAGoC,EAAY,CAArC,AAAsC,MAAM,CAAT,AAAU,CAArB,AAAsB,AAC5C,IAAI,EAAE,CAAlB,GACFC,GAAsB,EADZ,AACsB,CAAC,KAAH,CAAS,CAAC,CAAnB,AAAqB,GAG5C,IAAM,CAH8C,CAG1BD,AAH2B,GAGL,EAAY,CAC1D,OADwD,CAAX,CAAxB,MACN,CAChB,CAAC,AACuB,IAAI,EAAE,CAA3B,GACFC,GAAsB,EAAU,CAAC,KAAH,GADX,AACE,OAA2B,CAAC,CAAE,GAGrD,IAAM,EAAkBD,GAAsB,EAAY,CAAC,EAHW,CAAC,IAGlD,AAAmC,CAAX,KAA2B,CAAC,CAAC,CAK1E,OAJuB,IAAI,EAAvB,AAAyB,GAC3BC,GAAsB,EAAU,CAAC,KAAH,CADb,EACI,KAAyB,CAAC,CAAE,GAG5C,CACT,EKv7B4D,GACrD,CAEH,CLm7Ba,CKt7BiD,CAAC,CAG3D,CLg7B4D,AKh7B3D,CLg7B4D,GKh7BxD,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,IAiBhC,SAjB6C,CAAC,CAAC,KAiB/B,CAAC,CAA4C,CAAA,CAC3D,GAAgC,IAAI,EAAE,AAAlC,EAAO,IAAD,aAAkB,CAC1B,MAAM,AAAI,KAAK,CAAC,wCAAwC,CAAC,CAG3D,IAAM,EACJ,IAAI,CAAC,MADY,kBACY,CAAC,IAAI,CAAC,SAAS,CAAE,GAChD,GADsD,CAAC,AACnD,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,IA0BhC,KAAK,EAAA,CACH,CA3B2C,CAAC,CAAC,CA2BzC,CAAC,IAAI,CAAC,KAAK,EAAE,CAEpB,CChgBK,SAAU,GACd,CAA+C,EAAA,UAE/C,AAH8B,GAG1B,OAAA,EAAA,MAAA,EAAM,IAAA,CAAA,CAAA,CAAN,EAAM,AAAE,IAAF,IAAN,MAAM,KAAA,KAAA,AAAE,AAAwB,CAA1B,CAA4B,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,GAAA,EAAA,EAAO,CAC3C,CAD6C,CAAT,KAAA,AAC7B,CAD6B,CAItC,EAHa,EAGT,GAAuB,EAC3B,GADgC,CAC3B,IAAM,IAAI,CAAI,EADK,KACL,EAAA,MAAA,EAAM,IAAA,CAAA,CAAA,CAAN,EAAQ,AAAF,IAAA,CAAE,AAAK,EAAA,CAAb,CAAa,AAAI,EAAJ,AAAM,CAAE,AACtC,EADuB,CAAO,AAC1B,GAAe,CADW,AAAP,EAAO,AACJ,CAAH,AACrB,CADsB,CADD,CAEE,AAFF,CAAO,CAG5B,EAFgB,AACW,EAFC,CAI7B,AAJ6B,CAMhC,GAAI,CAAC,EACH,GALsB,IAKf,EAGT,EAHa,EAGP,EAAW,GAJQ,EAAE,CAIb,CAAG,EAAA,MAAA,EAAA,IAAM,CAAN,CAAA,CAAA,EAAQ,AAAR,IAAM,AAAN,IAAA,MAAM,KAAN,KAAA,AAAQ,AAAwB,CAAhC,CAAkC,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,GAAA,EAAA,KAAA,KAAA,CAAA,EAAkB,OACrE,GACG,IAAa,IAAL,CAAgB,CAAC,EAAK,AAAtB,AAAa,EAAQ,IAAO,CAAC,SAAS,CAAC,EAAS,CAAC,KAAF,AACxD,CAAY,CAAC,EACb,CACA,GAFQ,IAED,CAAC,IAAI,CACV,kMAAkM,CAClM,IAEK,EAGX,CAEM,CAPQ,AAEC,CADV,OAMW,GAAe,CAAqB,EAClD,AADkD,MAC3C,EADqB,QACX,GAAI,GAAiC,CAA7B,SAAuC,EAAnC,OAAO,EAAK,EAAD,MAAS,AACnD,CAsBM,SAAU,GACd,CAA+C,EAAA,MAE/C,MAAO,CAAA,CAAC,EAH4B,IAG5B,EAAA,OAAA,EAAA,IAAM,CAAN,CAAA,CAAA,EAAA,AAAQ,IAAR,AAAM,IAAN,MAAM,KAAN,KAAA,AAAQ,AAAwB,CAAhC,CAAkC,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,GAAA,EAAA,KAAA,KAAA,CAAA,CAAA,AAAiB,CAAA,AAC7D,CC7CM,MAAO,MAAO,KAAQ,GAC1B,OADoC,CAAA,GACpC,CAA6B,CAAoB,CAAA,CAC/C,KAAK,EAAE,CADoB,IAAS,CAAA,SAAA,CAAT,EA0C7B,IAAA,CAAA,EA1CsC,aA0CvB,CAAG,MAChB,MAAuC,KACG,uBAatC,EACA,EAbE,EAAoB,EAYiB,IAZX,IAAI,CAAC,IAAd,IAamB,qBAbwB,CAAC,GAEnE,GAFyE,AACzE,CAD0E,GACtE,CAAC,4BAA4B,CAAC,GAC9B,CAAC,CDtBA,CCqBmC,CAAC,KDrBpC,EAAA,MCsBgB,CDtBhB,EAAA,OAAA,EAAA,ACsBiB,EDtBV,IAAD,ACsBiB,CAAC,CDtBjB,AAAM,EAAA,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,AAAE,GAAF,EAAE,AAAK,AAAP,EAAO,GAAP,CAAO,CAAA,CAAA,CAAA,CAAA,AAAP,CAAA,AAAS,AAAF,GAAA,CAAM,CAAC,AAAC,AAAR,GAAiB,CAAL,CAAZ,CAAgC,GAAK,CAArC,AAAoC,AAAE,CAAtC,CAA0C,CAAA,CAAK,AAAL,EAAA,ACsBlC,CDtBuB,AAAW,ECsBjB,CDtBiB,CCsBV,GDtBU,CCsBX,CDtBW,CCsBJ,CAAC,CAC9D,CADgE,CDtBC,CCsBlB,IDtBkB,ACuB1D,CDvB0D,KCuBpD,IAAI,CAAC,uBAAuB,CAAC,GAG5C,GDlBK,CCkBD,MDlBC,EAAA,ECewD,CAAC,IDfzD,EAAA,ECkBkB,KDlBlB,ECkBmB,ADlBnB,EAAO,ICkBkB,ADlBnB,CCkBoB,CDlBb,AAAN,CCkBqB,CDlBb,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,GAAA,EAAA,AAAK,EAAE,GAAP,CAAO,CAAA,CAAA,CAAA,CAAP,AAAO,CAAA,AAAP,AAAO,GAAA,CAAI,CAAJ,AAAK,AAAC,GAAS,CAAL,AAAM,CAAhB,EAA+B,GAAK,AAApC,CAAmC,AAAnC,AAAqC,EAAI,EAAA,ACmBlE,EDnBkE,CAAA,AAAX,GCmBjD,AAAI,ADnBwD,EAAK,EAAL,CCmBnD,CACb,ADpBgE,KAAA,KAAA,CAAA,oECoBe,CAChF,CAKH,IAAM,EAAmD,GACvD,EAAkB,IAD8C,IACtC,CAC3B,CACK,EACJ,GAHiB,IAGjB,EAAA,GADkB,AAHiB,IAInC,EAAA,OAAA,EAAA,EAAkB,MAAA,AAAM,EAAA,IAAA,CAAA,CAAA,CAAA,AAAP,CAAO,CAAA,AAAE,GAAF,EAAA,KAAA,KAAA,CAAA,QAAE,AAAwB,EAAA,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,AAAE,GAAF,EAAA,KAAA,KAAA,CAAA,EAAE,AAAkB,EAAA,EAAA,ADlFpC,ECkFoC,ADlFlC,CCoFlC,AADF,EACgB,CAAC,AAFqD,CAGxE,GAHwE,EAGjE,AAEL,AALsE,EAEzD,AACM,EAEf,CAAC,AALiE,CAItE,EAAW,EAJ2D,CAGtD,AAHsD,EAKzD,CADL,AAAS,CAHO,CAES,EACZ,CAAC,uBAAuB,CAAC,EAAiB,CAAC,CAClD,aAAa,EAAuC,AAAnC,CAAoC,EAAE,GAA7B,EAAD,WAAe,CAAC,MAAM,EAF1B,CAMnC,IAAM,EAAiC,EAAS,MAAD,IAAY,CAAtC,AAAuC,CAAC,CAAC,CAAC,OAAQ,CACjE,EAAsC,EAAE,CAC9C,IAAK,IAAM,IAAI,CAAI,GADQ,IACR,EAAA,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAE,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,GAAA,EAAA,AAAK,AAAL,EAAS,EAAA,CAAT,CAAW,AAAF,CAAI,AAC7C,GADyC,AACrC,AAD4B,CAAA,EACb,CADsB,EACf,AADe,CAClB,AAErB,CAFsB,GAEhB,AAHiC,EAGzB,CAFE,EAEL,AAH4B,CAAA,EAElB,AACD,EAAa,EADc,MACN,CAAC,CAAV,CAAmB,MAAD,OAAe,CAAC,CAClE,EAAsB,IAAI,CAAC,GAAG,EAC/B,CAGH,EAJuC,CAAC,CAMxC,EAA0B,CACxB,CAPuB,GAOnB,AAHK,CAGH,CAHK,KAGC,CACZ,KAAK,CAAE,EAFc,AAGtB,CAED,EAAkB,QAAQ,CAAG,GAAU,EAAkB,CAAxC,CAHa,EAGQ,IAA2B,CAAC,CACjE,EAAkB,GADqC,KACT,CAAC,IAAI,CAAC,CAAnC,EACjB,EAAkB,QAA4B,CAAC,CADoB,CAAC,EACjB,CAClD,CADgB,EAId,GAAuB,EAAkB,MAAM,CAAC,EAAE,CACpD,EAAgC,GAJT,AAGmB,CACN,AAHrC,CAGsC,AADb,GAExB,EAAgC,IAAI,CAAC,GAExC,CAKD,CARwD,CAAC,KAIrD,GAJ+B,AAIR,EAAkB,MAAM,CAHa,AAGZ,CAHjB,AAA8B,CAGX,CACpD,EAAU,GADgC,EAAlB,CACf,yBAAgC,CACvC,CAAA,CAA+B,CAE5B,CACT,CAAC,CAgED,IAAA,CAjEkB,AAiElB,qBAAqB,CAAG,MACtB,IAGA,EAHuC,CAEvC,IAD0D,AACtD,CAAC,4BAA4B,CAAC,IAC9B,EADoC,CAAC,AACpB,EAAO,IAAD,EAAO,CAAC,CAKjC,GALkB,IAKX,MAAM,IAAI,CAAC,gBAAgB,CAAC,EALA,EACnC,EAIyC,CAAC,CAJpC,EACJ,MAAM,IAAI,CAAC,IADU,yBACmB,CAAC,GAC3C,GADiD,CAAC,GAC3C,MAAM,IAAI,CAAC,6BAA6B,CAAC,EACjD,CAGH,CAAC,CAuLD,IA1LS,AA0LT,CAAA,OA3LqE,CAAC,MA2LxD,CAAG,MACf,GAEO,GAF+B,GAEzB,EAD4B,EACxB,CAAC,sBAAsB,CAAC,GAAQ,GAAF,CAAM,AAAL,CAAM,AAAC,WAAW,GAC5D,EADgE,AAE9D,EAAkB,EAAE,CAE1B,SAAI,CAFiB,CAEN,KAAA,EAAX,EAAa,AAAF,GAHmB,EAG9B,IAAW,AAAX,IAAA,EAA4B,CAC9B,CADgC,GAC3B,IAAM,AADE,KACgB,AADhB,EAC4B,GAD5B,IACY,EAAe,MAAgB,CAAE,AAEtD,UACA,EAAc,EADA,GACA,CAAd,AAAc,CAAd,EAAgB,GAAF,KAAA,IAAA,IAAd,AAAgB,AAAgB,CAAA,EAChC,CAAA,OAAA,EAAA,CADc,KACd,AADc,EACd,GADc,CAAA,CACd,CAAA,CAAA,EAAgB,GAAF,KAAd,IAAc,AAAd,IAAgC,AAAhB,AAAhB,EAAkC,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,GAAA,AAApB,EAAoB,GAAlC,EAAkC,CAAA,AAAW,EAA7C,CAAA,CAAkD,AAAhB,CAAA,gBAAiC,CAEnE,CADA,OACiC,EAAc,KAAA,EAAd,EAAgB,GAAF,KAAd,GAAH,CAAG,AAAc,IAAkB,AAAhC,CAEjC,EAAgB,IAAI,CAAC,GAkB3B,GApBqD,EAEhC,EAMjB,AAYG,CApB8C,CASxC,CACT,CARqC,CAAC,CAFW,EAoBtC,UAVI,CAAE,EACjB,SAH8B,EAAE,EAEA,iBACF,CAAE,EAChC,eAAe,CAAE,EAAY,SAAD,CADkC,KAClB,CAC7C,CAEU,CACT,eAAe,CAAE,EACjB,aADgC,EACjB,CAAE,EAAY,SAAD,MAAgB,CAC7C,AAGL,CAAC,CAAC,CAGJ,IAAA,CAAA,IAAI,CAAG,MACL,MAAmC,IASnC,CAR+B,GAQzB,EAA2C,CAC/C,MAAM,CALU,CAKR,CADQ,IAJA,CAAA,MAKI,AALJ,CAAA,MAAA,CAAA,MAAA,CAAA,CAAA,CAAA,CAH4B,CAIzC,AAHH,SAAS,EAAE,EAGK,AAFjB,CAEiB,CAHD,MAIZ,EAAM,IAAA,CAAA,CAAA,CAAN,EAAQ,AAAF,IAAA,EAAQ,CAClB,CAGA,AAJI,CAML,GAAI,EANO,EAMH,CAAC,EANE,KAAA,CAAA,CAMO,CAAC,UAAU,EAAE,EAAE,AAC3B,CAAC,EAAa,MAAO,CAAC,GAAT,MAAkB,CACjC,CADmC,EAC/B,OAAA,EAAA,EAAa,MAAA,AAAM,EAAA,EAAP,EAAO,CAAA,CAAA,CAAA,CAAA,CAAA,AAAE,GAAF,EAAA,CAAQ,CAC7B,CAD+B,EAAV,GACX,AAAJ,EADe,CAAA,EACN,CACb,sEAAsE,CACvE,MAED,EAAa,MAAO,CAAC,GAAT,GAAe,CAAG,oBAAoB,CAKxD,OAAO,IAAI,GACT,EADc,CACJ,MAAD,WAAkB,CAC3B,AAAC,CAA6B,EAAK,IAAI,CAAC,YAAY,CAAC,CAAC,CAAC,CACvD,MAAM,IAAI,CAAC,YAAY,CAAC,GACxB,EAEJ,CAAC,CAsBD,IAAA,CAAA,AAzBwC,CAAC,EACzB,CACb,KAuBM,CAAG,MACV,IAEA,EAFiC,EAE3B,EAA8D,CADhC,AAElC,KAAK,CAAE,EAAO,GADI,CACL,CAAM,CACnB,MAAM,CAAE,EAAO,IAAD,EAAO,CACrB,eAAe,CAAE,EAAE,CACnB,MAAM,CAAE,EAAO,IAAD,EAAO,CACtB,CAQD,OAPI,EAAO,IAAD,WAAgB,EAAE,AACtB,EAAO,IAAD,WAAgB,EAAE,CAC1B,EAAe,YAAD,GAAgB,CAAG,EAAO,IAAD,WAAgB,CAAC,GAAG,CAAC,AAAC,GAAG,AAC9D,EAAI,CAAD,kBAAoB,GAAE,CAC1B,CAGE,MAAM,IAAI,CAAC,iBAAiB,CAAC,EACtC,CAAC,CAsBD,IAAA,CAAA,KAvBoD,CAAC,MAuBzC,CAAG,MACb,IAEA,EAFoC,EAEhC,EAA2D,CADxB,AAErC,MADW,QACG,CAAE,CAAC,CACjB,IAAI,CAAE,SAAS,CAChB,CAEG,EAAO,IAAD,EAAO,EAAE,CACjB,EAAS,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,EAAO,GAAc,EAAO,IAAZ,AAAW,CAAX,EAAkB,CAAC,CAG9C,IAAM,EAA+D,CACnE,KAAK,CADQ,AACN,EAAO,IAAD,CAAM,CACnB,KAAK,CAAE,EAAO,IAAD,CAAM,CACnB,aAAa,CAAE,EAAO,IAAD,SAAc,CACnC,MAAM,CAAE,EACT,CACD,MAFmB,CAEZ,MAAM,IAAI,CAAC,oBAAoB,CAAC,EACzC,CAAC,CA4BD,IAAA,CA7BkD,AA6BlD,CA7BmD,aA6BrC,CAAG,MACf,MAAsC,KACI,SAC1C,GAAI,CAAC,EAAO,IAAD,EAAO,EAAI,EAAO,IAAD,CAAM,EAAI,EAAO,IAAD,CAAC,AAAK,GAAK,EAAO,IAAD,EAAO,CAClE,CADoE,KAC1D,AAAJ,KAAS,CACb,+EAA+E,CAChF,CAmBH,MAhBI,CAAC,IAAI,CAAC,SAAS,CAAC,UAAU,EAAE,EAAE,CAC5B,CAAA,OAAA,EAAA,EAAO,IAAD,CAAC,AAAK,EAAE,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,GAAA,AAAG,EAAH,EAAO,CAAJ,EAAH,IAAO,CAAP,CAAO,AAAP,EAAc,IAAD,CAAC,AAAK,EAAE,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,GAAA,EAAA,KAAA,AAAU,CAAA,CAC/C,CADiD,CAC1C,CAD8B,CAAA,EAC/B,CAAM,CAAG,CACb,GAAG,CAAE,EAAO,IAAD,CAAM,CAAC,GAAG,CACrB,QAAQ,CAAE,EAAO,IAAD,CAAM,CAAC,QAAQ,CAChC,CAED,CAAA,MAAA,GAAA,MAAA,EAAA,CAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,AAAE,GAAF,EAAA,AAAE,AAAK,EAAA,GAAP,CAAO,CAAA,CAAA,CAAA,CAAA,AAAP,CAAO,AAAE,AAAT,GAAS,AAAG,AAAL,EAAA,EACpB,GADoB,IACpB,CADoB,CACpB,AADoB,OACpB,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,EAAE,AAAK,EAAA,GAAP,CAAO,CAAA,CAAA,CAAA,CAAA,AAAP,CAAS,AAAF,GAAA,EAAA,KAAE,AAAU,AAAZ,CAAY,EAChC,CACA,CAFoB,CAEb,AAFa,IAEd,EAAO,CAAC,KAAK,CAAG,CACpB,GAAG,CAAE,EAAO,IAAD,EAAO,CAAC,KAAK,CAAC,GAAG,CAC5B,QAAQ,CAAE,EAAO,IAAD,EAAO,CAAC,KAAK,CAAC,QAAQ,EACvC,EAGE,MAAM,IAAI,CAAC,sBAAsB,CAAC,EAC3C,CAAC,CArcO,EAocyC,CAAC,yBApcd,CAClC,CAAuC,CAAA,CAEnC,EAAO,IAAD,EAAO,EAAI,EAAO,IAAD,EAAO,CAAC,cAAc,EAC3C,AAD6C,CAC5C,EAAO,IAAD,EAAO,CAAC,kBAAkB,EAAE,AACjC,MAAM,CAAC,IAAI,CAAC,EAAO,IAAD,EAAO,CAAC,cAAc,CAAC,CAAC,QAAQ,CAAC,SAAS,CAAC,EAAE,CACjE,EAAO,IAAD,EAAO,CAAC,kBAAkB,CAAG,EAAO,IAAD,EAAO,CAAC,cAAc,CAC/D,OAAO,EAAO,IAAD,EAAO,CAAC,cAAc,EAmEnC,MAAM,6BAA6B,CACzC,CAAuC,CAAA,WAEvC,IAAM,EAAQ,GAAH,IAAG,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,AAAE,GAAF,EAAO,AAAP,CAC3B,GAAI,CADuB,AACtB,EACH,GADQ,AADiB,CAAA,CACf,EACH,EAET,IAFe,AAET,EAAmB,MAAM,OAAO,CAAhB,AAAiB,GAAG,CACxC,EAAM,GAAD,AAAI,CAAC,MAAO,GACf,AAAI,CADe,EACA,GAEV,AAHc,CACA,CAAC,EAAE,EACH,AACR,EAAa,AAFV,EAC+B,EACjB,EAAE,CAE3B,GAFoB,CAEhB,AAGT,EAA6C,CACjD,KAAK,CADQ,AACN,EAAO,IAAD,CAAM,CACnB,QAAQ,CAAE,EAAO,IAAD,IAAS,CACzB,MAAM,CAAA,MAAA,CAAA,MAAA,CAAA,MAAA,CAAA,MAAA,CAAA,CAAA,CAAA,CACD,EAAO,IAAD,EAAO,EAAA,CAChB,KAAK,CAAE,CAAgB,CACxB,CAAA,CACF,CAGD,GAFA,EAAU,MAHiB,AAGV,CAAR,AAAS,KAAK,CAAG,EAGxB,EAAO,IAAD,EAAO,EACb,EAAO,EAJiC,EAIlC,EAAO,CAAC,KAAK,EACnB,GAAgB,EAAO,IAAD,EAAO,CAAC,GAAf,EAAoB,CAAC,CACpC,CAEA,IAAI,EAAU,MAAA,CAAA,CAAA,KAAA,CAAA,CAAA,CAAA,CADE,CACK,MADL,CACY,CADZ,AACa,OADb,EAAA,EAAO,IAAD,EAAO,CAAC,WAAW,AAAX,EAAW,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,AAAE,GAAF,EAAA,EAAE,AAAO,EAAA,CAAT,CAAS,AAAI,CAAA,CAAJ,AAAM,CAEjB,CAFE,AAED,CAFC,CAAS,AAER,EAAtC,EAF8C,EAAA,EAExC,CAAC,EAFuC,EAEnC,CAAC,EAFkC,CAEtB,AAFsB,MAEhB,CAAR,CAAC,CACzB,EAAa,IAAI,CAAC,GAAR,MAAiB,CAAC,iBAAiB,EAAA,CAAE,CAEjD,GAAkB,GAClB,EAAU,KADkB,CAAC,AACZ,CAAR,AAAS,EADD,SACY,CAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,EACxB,EAAO,IAAD,EAAO,CAAC,WAAW,CAC5B,CAAA,CAAA,OAAO,CAAE,CAAU,EACpB,AACF,CACD,MAHuB,CAGhB,EAGD,MAAM,CAHI,cAGW,CAC3B,CAAuC,CAAA,WAEvC,IAAM,EAA4C,IAAI,EAAxC,CAA2C,CACzD,CAD2D,GACtD,IAAM,IAAI,CAAI,OAAA,EAAA,OAAA,EAAA,EAAO,IAAD,EAAO,AAAN,EAAQ,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,GAAA,EAAA,AAAK,EAAI,EAAA,CAAT,CAAS,AAAE,CAAE,AAC7C,GADyC,AACrC,AAD4B,CAAA,EACb,CADsB,EAIvC,AAJuC,CAClB,CAAC,EAAE,AAGnB,CAJkC,GAI5B,AAHK,EADuB,CAAA,EAIb,MAAJ,CAAI,EAAA,CADF,MAAM,EAAa,IAAI,EAAA,AACN,CADQ,CACP,EADA,kBACA,AAAoB,EAAI,EAAA,EAAA,AAAE,CAAE,CACpE,EADgE,CAC5D,CAAC,EAAY,AAD+C,EAAA,EAC3C,CACnB,CADqB,CADyC,EAChD,EACR,AAAI,CAFoD,CAAA,GAE/C,CAAC,wCAAwC,CAAC,CAE3D,GAAI,EAAS,GAAG,CAAC,EAAL,AAAiB,IAAI,CAAC,CAChC,CADkC,EAAR,GACpB,AAAI,KAAK,CACb,CAAA,iCAAA,EAAoC,EAAY,IAAI,CAAE,CAAA,CACvD,CAEH,CAHmD,CAG1C,GAAG,CAAC,EAAL,AAAiB,IAAI,CAXV,CAWY,CAChC,CAGL,CAJ8B,AAXqB,MAe5C,EAGD,CAP2C,CAAC,IAInC,AAGH,gBAAgB,CAC5B,CAAuC,CAAA,WAEvC,IAAM,EACJ,OAAA,EAAA,GADkB,IAClB,EAAA,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,AAAE,GAAF,EAAA,KAAA,KAAA,CAAA,QAAE,AAAwB,EAAA,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,AAAE,GAAF,EAAA,KAAA,KAAA,CAAA,EAAE,AAAkB,EAAA,EAAA,EAAA,CAC3D,AACE,GAAsB,AAFmC,EAGzD,EAHyD,AAGvC,CADS,AACR,CAHsC,AAK7D,KAL6D,EAKrD,GAHe,AAFsC,CAAA,AAG1C,IAFO,CAKxB,CAAc,CACd,CAAyC,CACzC,CAAuC,EAAA,6CAEvC,gBAAO,EAAkB,GAAgB,CACnC,IACF,IACA,CAHkB,CAAiB,CAGb,GAExB,EAF6B,EAEvB,CAHW,AADM,CAKrB,CALuB,AACN,KAIjB,CAHmB,EAGb,EAAO,EAAb,EADqB,AACT,yBAA8B,CAAC,IACvC,EACJ,AAFiD,CAAC,CAAA,IACtC,AACZ,GAAM,EAAO,EAAb,EAAY,yBAA8B,CAAC,IAEvC,EAAkC,EAAE,CACpC,EAAoC,EAAE,IAHkB,CAAC,AAK/D,CAL+D,EAExC,CAGG,GAFJ,CAEY,EAAR,GAAA,EAAA,GAAA,EAAA,AAAQ,CAAR,IAAA,CAAA,CAAA,CAAA,EAAA,EAAQ,CAAA,CAAA,EAAE,EAAA,CAAA,CAAV,CAAU,MAAA,GAAA,CAAA,CAAA,EAAA,EAAA,GAAA,CAAA,CAAA,IAAA,EAAA,CAAA,CAAA,CAAA,EAElC,EAFkC,CAAA,AAAV,EAAQ,EAAA,KAAA,CAAR,EAAQ,CAAA,CAAA,CAChC,GADgC,GAC1B,MAAA,MACF,CADE,CAAA,AACI,GAAD,EADE,CAAA,IACS,GAAI,CAAJ,MAAI,EAAA,EAAM,GAAD,OAAW,CAAC,EAAC,AAAC,EAAE,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,GAAA,EAAA,EAAA,AAAO,CAAA,EAAE,AAEpD,AAF2C,IAEtC,CAFsC,CAAA,EAEhC,IAAI,CADf,EAAiB,IAAI,CAAC,EAAM,GAAD,IAAX,GAAsB,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,CAC/B,OAAA,EAAA,AAJD,EAIO,AAJP,GAIM,OAAW,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,KAAK,AAAL,EAAK,EAAA,AAAI,EAAJ,AAAM,CAAE,CAC1D,EADkD,CAC9C,EAAkB,CAD4B,EACV,AADU,EACL,EAAD,CADM,KAC/B,AAD+B,CACd,AADc,GACO,CAAE,CACzD,GAAI,CAAC,EAAK,EAAD,UAAa,CAAC,IAAI,CACzB,CAD2B,KACrB,AAAI,KAAK,CACb,mDAAmD,CACpD,CAEH,GAAK,CAAD,CAAU,GAAG,CAAC,EAAL,AAAU,EAAD,UAAa,CAAC,IAAI,CAAC,CAMlC,CANoC,AAOzC,IAAM,EAAgB,MAAA,GAAM,EAAT,AAChB,EADmB,CAChB,CAAC,EAAK,EAAD,UAAa,CAAC,IAAI,EAC1B,QAAQ,CAAC,CAAC,EAAK,EAAD,UAAa,CAAC,CAAC,CAAA,CAChC,EAAkB,IAAI,CAAC,GAAG,EAC3B,KADkB,CATjB,KASuC,CATjC,AAAI,AAS8B,KATzB,CACb,CAAyI,sIAAA,EAAA,EAAS,IAAI,EAAL,AAAO,CACtJ,eAAA,EAAA,EAAK,EAAD,UAAa,CAAC,IACpB,CAAA,CAAE,CACH,AAOJ,CACF,2GAIL,GAAI,EAAkB,MAAM,CAAG,CAAC,CAAE,CAChC,GAAsB,EACtB,AAFmB,EACO,EACpB,EAAqB,IAAI+G,GAC/B,CAFmB,CAEA,OADK,GACK,CAAG,CAC9B,CACE,GAFc,EAD0C,EAGjD,AAHmD,CAGjD,CACP,IAAI,CAAE,MAAM,CACZ,KAAK,CAAE,CACR,CAAA,AACF,CAAA,CACF,CAED,MAAM,MALwB,AAKxB,GAAA,GAEN,CAFM,GAEA,EAA+B,EAAE,CACvC,EAAY,IADK,AACD,AAHQ,CAAA,AAGP,GAAG,CAAT,EACX,EAAY,IAAI,CAAC,CACf,GADS,CACL,CAF8B,AAE5B,CAF6B,KAEvB,CACZ,KAAK,CAAE,CACR,CAAA,CAAC,CACF,IAAM,EAAkB,GAAU,EAAO,EAFf,EAEO,AAAO,IAAnB,AAA4B,CAAC,CAAC,MAAM,CACvD,EAGF,GAAO,GAAD,GAHO,CACZ,CAEc,CAAG,CACnB,MACC,CADK,IAGR,GAJoC,AAKtC,CAAA,CAAE,IAAI,CA5Ea,CA4EX,KA5EiB,IAAI,CAAC,CA4EX,cA5E0B,CAAC,GA4EzB,GAoOhB,AAhT+C,CAAC,EA4E1B,CAAC,EAoOjB,uBAAuB,CACnC,CAAuC,CAAA,iBAInC,EAAe,EAAX,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,GAAI,GADW,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,CAC/B,IAAM,EAAOC,EAAH,CACR,IAAI,CAAC,SAAS,CACd,GA6BF,GA7BQ,CACP,GACD,EAAOzE,EAAH,CACF,AALuD,MAIlC,mBACI,CACzB,EAAK,EAAD,EAAmC,CACxC,CACD,AAFa,EAEC,EAAK,EAAD,IAAoC,CACtD,AADW,CAAgB,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAmBJ,CArBa,GAEL,CAAC,GAmBD,MAnBC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IAAI,AADc,CACb,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,MAAM,CAClB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CAAC,AADV,GACE,CAAY,CAAC,AAAC,AADZ,IAGnB,EAAS,MAFkC,AAEnC,KAFuC,IAEvB,CAAG,CACzB,OAAO,CAAE,EAAa,OAAO,CACR,CAHN,CAEM,IAMb,IAAI,CAAC,AAAC,EAR8C,EASlE,IAAM,EAAO0E,CADkB,CACrB,CAAgD,GADvB,AAE7B,EAAY,IAAIF,EAD+C,CAAC,AACvD,AAEf,OADA,MAAM,CAAC,IAFkD,EACN,AACtC,CAAC,CADuC,CAC5B,GAClB,CADsB,AAE/B,CAFgC,AAE/B,CAAC,AACH,CAAM,AAHoB,CAIzB,IAHkB,AAGZ,EAAOG,EAAH,CACR,IAAI,CAAC,SAAS,CACd,GA6BF,GA7BQ,CACP,GACD,EAAO3E,EAAH,AAJoD,CAKtD,MADqB,mBACI,CACzB,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAmBJ,CArBa,GAEL,CAAC,GAmBD,MAnBC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IAAI,AADc,CACb,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,MAAM,CAClB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAE,AAAD,GACG,EAAa,IAAI,EAAE,CADT,AACU,GAAR,CAAY,CADV,AACW,AAAC,IAE/B,EAAS,MAFkC,AAEnC,KAFuC,IAEvB,CAAG,CACzB,OAAO,CAAE,EAAa,OAAO,CACR,CAHN,CAEM,IAMb,IAAI,CAAC,AAAC,EAR8C,EASlE,IAAM,EAAO4E,CADkB,CACrB,CAA+C,GADtB,AAE7B,EAAY,IAAIJ,EAD8C,CAAC,AACtD,AAEf,OADA,MAAM,CAAC,GAFiD,GACL,AACtC,CAAC,CADuC,CAC5B,GAClB,CACT,AAF+B,CAAC,AAE/B,CAAC,AACH,CAH0B,CAMrB,IALc,EAKR,6BAA6B,CACzC,CAAuC,CAAA,iBAInC,EAAe,EAAX,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,GAAI,GADW,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,CAC/B,IAAM,EAAOC,EAAH,CACR,IAAI,CAAC,SAAS,CACd,GAoBF,GApBQ,CACP,GACD,EAAOzE,EAAH,CACF,AALuD,MAIlC,iCACkB,CACvC,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAGV,AASJ,AAVW,CAFE,GAEE,CAAC,GAUR,CATK,KADY,CACX,aAAa,CAAC,CACjC,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IAAI,AADc,CACb,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,MAAM,CAClB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,AACxC,CAAA,CAAgD,CAEjC,CAHY,GAGR,CAAC,SACnB,CAA+C,EAAA,qDAE/C,IAA0B,IAAW,EAAX,GAAA,EAAA,EAAA,GAAA,GAAW,EAAE,EAAA,CAAb,AAAa,EAAb,AAAa,CAAF,CAAA,IAAE,GAAA,EAAA,CAAA,CAAA,EAAA,GAAA,CAAA,CAAA,EAAA,EAAA,EAAA,CAAA,CAAA,CAAA,EAAA,CAAb,CAAa,CAAF,EAAA,KAAA,CAAX,EAAW,CAAA,EACnC,EADmC,CAAA,CAC7B,EAAO0E,EAAH,EACP,MAAM,GAAA,EAAM,EAAN,CAAK,CAAK,GAAE,CAAA,EACpB,AAED,EAAK,EAAD,IAJqD,CAAA,QAIlC,CAAG,CAAJ,AACpB,OAAO,CAAE,AANS,EAMH,AANG,GAMJ,IAAQ,CACD,CAEvB,IAAM,EAAY,IAAIF,GAAP,AACf,MAAM,CAAC,MAAM,CAAC,EAAW,GACzB,CAD6B,AADsB,CACrB,CADuB,CAC9B,EACjB,MAAA,GAAA,EACP,EADO,KAAS,CAAA,oGAElB,CAAA,CAAA,CAAC,AACH,CAAM,CACL,IAAM,EAAOG,EAAH,CACR,IAAI,CAAC,SAAS,CACd,GAoBF,GApBQ,CACP,GACD,EAAO3E,EAAH,AAJoD,CAKtD,MADqB,iCACkB,CACvC,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEH,AACP,AASJ,CAZa,GAEE,CAAC,GAUR,CATK,KADY,CACX,aAAa,CAAC,CACjC,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,MAAM,CAClB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAC3B,AADwC,CACxC,CAAgD,CAEjC,CAHY,GAGR,CAAC,SACnB,CAA+C,EAAA,qDAE/C,IAA0B,IAAW,EAAX,GAAA,EAAA,EAAA,GAAA,GAAW,EAAE,EAAA,CAAA,AAAb,EAAA,AAAa,CAAF,CAAA,IAAE,GAAA,EAAA,CAAA,CAAA,EAAA,GAAA,CAAA,CAAA,EAAA,EAAA,EAAA,CAAA,CAAA,CAAA,EAAA,CAAb,CAAa,CAAF,EAAA,KAAA,CAAX,EAAW,CAAA,EACnC,EADmC,CAAA,CAC7B,EAAO4E,EAAH,EACP,MAAM,GAAA,EAAM,EAAN,CAAK,CAAK,GAAE,CAAA,EACpB,AAED,EAAK,EAAD,GAJoD,CAAA,SAIjC,CAAG,CAAJ,AACpB,OAAO,CANW,AAMT,EANS,AAMH,GAAD,IAAQ,CACD,CAEvB,IAAM,EAAY,IAAIJ,GAAP,AACf,MAAM,CAAC,MAAM,CAAC,EAAW,GACzB,CAFmD,AACtB,CAAC,CADuB,CAC9B,EACjB,MAAA,GAAA,EACP,EADO,KAAS,CAAA,oGAElB,CAAA,CAAA,CAAC,AACH,EAwBH,MAAM,YAAY,CAChB,CAAoC,CAAA,iBAIhC,EAAe,EAAX,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,GAAI,GADW,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,CAC/B,IAAM,EAAOK,ANkHH,EMlHA,ONkHA,AACd,CAAoB,CACpB,CAAwC,EAAA,AAExC,IA7FM,QAkCA,EA2DA,EMtHoD,ANyBxC,AA6FwB,CAAA,CAAE,CAEtC,EAAYrH,CAFJ,EAE0B,CANI,CAMQ,CAAC,CA7D/B,AA6DP,MAA6C,AAAV,CAAW,AAAtB,CAAuB,AAC7C,IAAI,EAAE,CAAnB,GACFC,GACE,EACA,CAHS,AAGR,KADO,CACD,CAAE,CAFU,MAEH,CAAC,CACjBmB,GAAS,EAAW,CAAZ,GAIZ,GAJsB,CAIhB,CAJ2B,CAIZpB,AAJa,CAC/B,EAGwC,EAAY,CAAC,IAAtC,GAAmC,CAAX,EAAwB,CAAC,CAAC,CACpE,GAAoB,IAAI,EAApB,EAAsB,CACxB,IAAI,EAAkBsB,GAAoB,AAD5B,EACuC,GACjD,IAD+C,CAAhC,AACV,CAAC,GADuD,AAAxB,CAAyB,GACjD,CAAC,IAChB,GAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAEtB,AAFuB,CACW,CAE1C,AAHiC,CAGhC,AAFa,CACF,AAGfrB,EAJmC,AAAc,CAK/C,EACA,CAAC,KADO,GADW,KAEL,CAAE,SAAS,CAAC,CAC1B,EAEH,CAED,IAAM,EAAaD,GAAsB,EAAY,CAJlC,AAImC,CAHnD,CAGa,KAAmC,CAAX,AAAsB,CAAC,CAAC,CAKhE,OAJkB,IAAI,EAAlB,AAAoB,MAxHHA,IAwHP,CAxHyC,CAAC,QAAd,CAAC,CAAuB,CAAC,CAAC,CAChE,KAAiB,CADgC,GAyHZ,GAxHzB,AAAkC,EAApB,EAAwB,CAwHL,CAxHf,AAwHgB,AAxHM,GACtDC,KAEE,CAAC,GAHyC,KACvB,CACnB,IACc,CAAE,OADJ,IACe,CAAC,CAC5B,GAIE,EAAYD,GAgHW,EAhHuB,CAAC,CAJrC,AAID,CAHZ,KAGyD,AAgHrB,CAhHA,AAAsB,CAArB,AAAsB,CAC1D,KAAiB,IAD6B,GAClC,AAA+B,EAAjB,EAAqB,EAAE,AAAnB,GAChCC,KAAoC,CAAC,AADI,QACpB,CAAC,IAA4B,CAAE,OAAlB,AAAyB,CAAC,CAAE,GAG1D,EAA2BD,IAHwC,CAAC,AAGP,CACjE,QADoD,CAAC,OAAzB,GAAmC,GACzC,CACvB,CAAC,CACE,KAAiB,OAAL,AAA8C,EAAhC,EAAoC,EAAhC,AAAkC,GAClEC,KAEE,CAAC,QAFkB,CACnB,GACa,CAAE,EAHuC,MAE1C,cACyB,CAAC,CACtC,GAIE,EAAeD,KAAkC,CAAC,IAAtC,IAAwB,CAAC,CAAuB,CAAC,CAAC,CAChE,AALwB,CACzB,IAIkB,CADgC,MACH,AAAlC,AAAkB,EAAJ,EAAwB,EAAE,GACtDC,GAD4C,EAG1C,CAAC,QAFkB,CACnB,IACc,CAAE,OADJ,GACc,CAAC,CAC3B,KAIqBD,KAAkC,CAAC,CAJ5C,CACb,MAG2C,CAAC,KAA2B,CAAC,CAAC,CACxE,EADqD,GACpC,OAAL,AAAsC,EAAxB,EAA4B,EAAE,AAA1B,GAChCC,KAEE,CAAC,OAH6C,CAC3B,CACnB,GACa,CAAE,QADH,MACiB,CAAC,CAC9B,IAqFG,CACT,EMrJQ,IAAI,CNoJK,AMpJJ,IN+DS,CACjB,IMhEiB,CACd,GA6BF,GA7BQ,CACP,GACD,EAAOuC,EAAH,CACF,MADqB,WACJ,CACjB,EAAK,EAAD,EAAmC,CACxC,CACD,AAFa,EAEC,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAmBJ,CArBa,GAEL,CAAC,GAmBD,MAnBC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,MAAM,CAClB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,AACU,GAAR,CAAY,CADV,AACW,AAAC,IAE/B,EAAS,MAFkC,AAEnC,KAFuC,IAEvB,CAAG,CACzB,OAAO,CAAE,EAAa,OAAO,CACR,CAHN,CAEM,IAMb,IAAI,CAAC,AAAC,EAR2C,EAS/D,IAAM,EAAO8E,ANuJf,CMxJiC,CACrB,IADyB,GNwJ3B,AACd,CAAsC,EAAA,AAEtC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAsBtH,CAFd,EAEoC,EAAY,CAC5D,CM7J0D,MN4JA,CAAX,EALL,CAKnB,MACN,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAiBD,GAAsB,EAAY,CACvD,IAJwE,CAAC,CAGvD,CAAmC,CAAX,OAC3B,CACf,YAAY,CACb,CAAC,CACF,GAAsB,IAAI,EAAtB,EAAwB,CAC1B,IAAI,EAAkB,CAClB,IAFY,CAEP,EAAC,KADS,CAAiB,CACnB,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,CACW,CADT,EACnB,CAlxBnB,CAkxBqC,AAAc,SAlxBP,EAAA,AAEtC,EAEA,MAFQ,KAtBR,EAwBa,AAxBuB,CAAA,CAAE,CAGxC,AAAc,GAHJ,CAGQ,EAAE,CADlB,EAAaA,CACL,IADuC,CAAC,EAAtC,MAAwB,AAAsB,CAArB,AAAsB,CAAC,GAE9DC,GAAsB,EAAU,CAAC,AAFgB,KAEnB,GAAW,AAApB,CAAqB,CAAE,GAI1C,AAAkB,IAAI,EAAE,CAJ4B,AAGlD,CAHmD,CAGlCD,GAgyBiB,EAhyBiB,AACvC,CADwC,CAgyBd,CAAC,IAhyBzB,EAAwB,CAAC,GAAyB,CAAC,CAAC,GAEtEC,EAFqD,CAGnD,EACA,CAAC,KADO,GADW,IAEN,CAAC,EACd,EAUsC,CAAA,CAAE,CAGxC,AAAiB,IAAI,EAAE,GADLD,IACL,CAbwB,EAYe,CAAC,MAAd,CAAC,IAAwB,AAZb,CAYc,AAZb,CACrD,AAWmE,CAZ9B,EActCC,CAFoD,EAE9B,EAAU,CAAC,KAAH,GAAT,GAAuB,CAAC,CAAE,GAI7C,AAAkB,IAAI,EAAE,CADtB,EAAiBD,CAHuC,CAAC,CAGlB,EAC3B,AADuC,CAAC,MAAtC,CAAmC,CAAX,KAA2B,CAAC,CAAC,GAEvEC,GAAsB,EAAU,CAAC,KAAH,GAAT,IAAwB,CAAC,CAAE,GAG3C,IAlBA,GAwxBF,CAAC,AAtwBS,CAwwBbA,EA3wB8D,CA2wBxC,AA3wByC,AAflD,EA0xBmB,CAAC,KAAH,GAAT,IAAwB,CAAC,CAAE,EACjD,CAED,IAAM,EAAeD,GAAsB,EAAY,CAAC,AAHS,CAAC,GAGhD,GAAmC,CAAX,EAAwB,CAAC,CAAC,CAKpE,OAJoB,IAAI,EAApB,AAAsB,GACxBC,GAAsB,EAAU,CAAC,GADnB,EACgB,GAAT,EAAsB,CAAC,CAAE,GAGzC,CACT,EMvL+D,GACjD,ENqLG,AMrLS,CNkLoC,CAAC,EMlLjCsH,EAD4C,CAAC,AACpD,AAEf,OADA,MAAM,CAAC,GADyC,EAAE,CACrC,CAAC,EAAW,GAClB,CADsB,AAE/B,CAFgC,AAE/B,CAAC,AACH,CAH0B,AAGpB,CACL,IAHkB,AAGZ,ENiCI,AMjCGC,EAAH,ONiCA,AACd,CAAoB,CACpB,CAAwC,EAExC,AAFwC,IAElC,EAAoC,CAAA,CAAE,CAEtC,EAAYxH,CAFJ,EAE0B,CMvCiB,CNuCL,CAAC,CAAtC,MAAmC,AAAU,AANjB,CAMJ,AAAsB,CAAC,AAC7C,IAAI,EAAE,CAAnB,GACFC,GACE,EACA,CAAC,AAHQ,KAED,CACD,CAAE,CAFU,MAEH,CAAC,CACjBmB,GAAS,EAAW,CAAZ,GAIZ,GAJsB,CAIhB,CAJ2B,CAAC,AAIbpB,CAHlB,EAGwC,EAAY,CAAC,IAAtC,GAAmC,CAAX,EAAwB,CAAC,CAAC,CACpE,GAAoB,IAAI,EAApB,EAAsB,CACxB,IAAI,EAAkBsB,GADR,AAC4B,EAAW,EACjD,KAD+C,AAC1C,CADU,CACT,GAD+B,AAAwB,CAAC,GACjD,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,AAEvB,CADkC,CADT,AAGjC,CAAC,CAFa,AACF,AAGfrB,EAJmC,AAAc,CAI3B,EAAU,CAAC,KAAH,GAAT,IAAwB,CAAE,SAAS,CAAC,CAAE,EAC5D,CAED,IAAM,EAAaD,GAAsB,EAAY,CAHuB,AAGtB,CAHuB,CAG7D,KAAmC,CAAX,AAAsB,CAAC,CAC7C,AAD8C,IAC1C,EAAE,CAApB,GACF,AA1HY,OAyHA,EAxHd,AADc,CACsB,CACpC,CAAqC,EAAA,AAIrC,IAAM,EAAeA,GAAsB,EAoHhB,AApH4B,CAAC,IAAtC,GAAmC,CANd,AAMG,EAAwB,CAAC,CAAC,MAC/C,IAAjB,GAA8C,AAAhB,EAAJ,EAAwB,EAAE,GACtDC,AADc,GAA8B,AAE1C,EACA,CAAC,QAFkB,CACP,GACC,CAAE,UAAU,CAAC,CAC1B,GAIJ,IAAM,EAAYD,GAJF,AAIwB,CAHrC,CAGiD,CAAC,CAAtC,MAAmC,AAAU,CAArB,AAAsB,CAAC,MACzC,IAAjB,GAA2C,EAAjB,EAAqB,EAAE,AAAnB,GAChCC,AADc,GACQ,EAAc,CAAC,AADI,QACpB,CAAa,GAAe,CAAE,OAAO,CAAC,CAAE,GAG/D,IAAM,EAHkE,AAGvCD,CAHwC,EAGlB,EAAY,CACjE,OAD+D,CAAX,QAAxB,MACN,CACvB,CAAC,CASF,QARqB,IAAjB,GAA0D,EAAhC,EAAoC,EAAhC,AAAkC,GAApD,AACdC,GACE,EACA,CAAC,QAFkB,CACP,GACC,CAAE,EAHuC,oBAGjB,CAAC,CACtC,QAIoD,IAApDD,GAAsB,EAAY,AAA2B,CAA1B,CAA4B,KAJvC,CAIQ,AAHjC,CAGsB,EAAwB,CAAC,CAAC,CACjD,MAAU,AAAJ,KAAS,CAAC,oDAAoD,CAAC,CAGvE,GAA4D,SAAxDA,AAAiE,EAAE,CAA7C,EAAY,CAAC,OAAH,CAAX,MAA4B,CAAC,CAAC,CACrD,MAAM,AAAI,KAAK,CAAC,wDAAwD,CAAC,AAI7E,EAkF8B,EAAY,GAGxC,IAAM,CAH0C,AAAV,CAGLA,AAHgB,GAGM,EAAY,CAAC,OAAO,AAAV,CAAW,AAAtB,CAAuB,CAS7E,MAT8B,MACG,IAA7B,GACFC,EADwC,CAEtC,CAFwC,CAGxC,CAAC,KADO,GADW,IAEN,CAAE,EAHS,KAGF,CAAC,CACvBmB,GAAS,EAAW,CAAZ,GAIL,CACT,EALwB,AMpEhB,IAAI,CNwEK,AMxEJ,SAAS,CACd,ENmE0C,CMtC5C,ANsC6C,CAC9C,EMpES,CACP,GACD,EAAOoB,EAAH,CACF,MADqB,sBACO,CAC5B,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CACtD,AADW,CAAgB,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAmBJ,CArBa,GAEL,CAAC,GAmBD,MAnBC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IAAI,AADc,CACb,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,MAAM,CAClB,WAAW,CAAE,MAAA,EAAA,CAAA,EAAO,IAAD,EAAO,AAAN,EAAM,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,AACU,GAAR,CAAY,CADV,AACW,AAAC,IAE/B,EAAS,MAFkC,AAEnC,KAFuC,IAEvB,CAAG,CACzB,OAAO,CAAE,EAAa,OAAO,CACR,CAHN,CAEM,IAMb,IAAI,CAAC,AAAC,EAR2C,EAS/D,IAAM,EAAOiF,ANkFf,CMnFiC,CACrB,IADyB,GNoFzC,AADc,CACwB,EAAA,AAEtC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAsBzH,CAFd,EAEoC,EAAY,CAC5D,AMxFyD,ONuFC,CAAX,CALN,EAKlB,MACN,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAiBD,GAAsB,EAAY,CAAC,IAHgB,CAAC,CAGvD,CAAmC,CAAX,IAA0B,CAAC,CAAC,CACxE,GAAsB,IAAI,EAAtB,EAAwB,CAC1B,IAAI,EAAkB,EAClB,GAFY,EAEP,CAAC,KADS,CAAiB,CACnB,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAE,AAAD,EADP,CAEtB,AAFuB,CACW,CAE1C,AAHiC,CAGhC,CAFa,AACF,AAGfC,EAJmC,AAAc,CAI3B,EAAU,CAAC,KAAH,GAAT,IAAwB,CAAC,CAAE,EACjD,CAED,IAAM,EAAeD,GAAsB,EAAY,CAHU,AAGT,CAHU,GAGhD,GAAmC,CAAX,EAAwB,CAAC,CAAC,CAKpE,OAJoB,IAAI,EAApB,AAAsB,GACxBC,GAAsB,EAAU,CAAC,GADnB,EACgB,GAAT,EAAsB,CAAC,CAAE,GAGzC,CACT,EM/G8D,GAChD,EN6GG,AM7GS,CN0GoC,CAAC,EM1GjCsH,EAD2C,CAAC,AACnD,AAEf,OADA,MAAM,CAAC,GADyC,EAAE,CACrC,CAAC,EAAW,GAClB,CADsB,AAE/B,CAFgC,AAE/B,CAAC,AACH,CAH0B,CASrB,IARc,EAQR,sBAAsB,CAClC,CAAsC,CAAA,aNirCxC,EA5BA,MMjpCM,CN6qCc,CM7qCC,CNipCD,AA6BpB,CM9qCU,AAAa,CNkpCvB,AMjpCM,EAAsC,CAAA,CAAE,CAC5C,GAAI,AN4qCoC,EAAA,AA5BA,CMjpCzB,CNipCyB,AMhpChC,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,KN8qC7B,EAEA,EASA,EAKA,EAhBQ,AAxMR,EASA,CAiMS,GASC,EA3KV,AAgLU,EArKV,MA2BA,AA9EgB,EAmDR,AAsCR,EAhFkB,KA+BD,CA2FjB,IAcA,EASA,EM/nCI,IN8jCgB,AM9jCZ,CACR,EADWG,CNwmCK,CAcH,AAnEc,AMljCvB,CAAC,KN8nCY,IM9nCH,GN4qCsB,CAAA,CAAE,CAG3B,AAAb,IAAiB,EAAE,GAAV,AADK1H,KM/qC0C,AN+qCR,CAAC,OAAO,CAAC,AAAtB,CAAC,AAAsB,GAE5DC,GACE,EACA,CAAC,CAJ6C,IAGtC,CACD,CAAE,CAFU,MAEH,CAAC,CACjBmB,GAAS,EAAW,CAAZ,GAKR,AAAc,GALI,CAKA,CALW,CAKT,AALU,CAC/B,EAGgBpB,CACL,EMvrCR,ENsrC+C,CAAC,GMtrC1C,CACP,INqrCmC,AAAsB,CAAC,AAAtB,CAAuB,GAE9DC,GAAsB,EAAU,CAAC,AAFgB,KAEnB,GAAT,MAA0B,CAAE,QAAQ,CAAC,CAAE,GAI1D,AAAc,IAAI,EAAE,CAJgD,CAAC,CAGtDD,CACL,IADuC,CAAC,QAAQ,AAAtB,CAAC,AAAsB,CAAC,MAxNvCA,GAwN0B,EAxNQ,CAAC,QAAd,CAAC,KAA2B,CAAC,CAAC,CACvD,AAAjB,EADqD,OAC3B,GAAd,AAAsC,IAAI,EAAxB,AAA0B,GAC1DC,KAEE,CAAC,OAH6C,CAC3B,CACnB,GACa,CAAE,QADH,IACe,CAAC,CAC5B,KAIuBD,KAAkC,CAC3D,KALkB,CACjB,EAG6C,CAAC,OAC/B,CACjB,CAAC,CACE,AAHuD,KAGtC,OAAmC,AAAxC,AAAkB,EAAJ,EAA8B,EAAE,GAC5DC,KAEE,CAAC,GAH+C,KAC7B,CACnB,GACa,CAAE,QADH,QACmB,CAAC,CAChC,GAIE,EAAqBD,KAAkC,CAC3D,OALoB,CACnB,AAG6C,CAAC,CAAzB,MACN,CACjB,CAAC,CAFyD,AAGvD,KAAiB,OAAL,AAAwC,EAA1B,EAA8B,EAAE,AAA5B,GAChCC,KAEE,CAAC,QAFkB,CACnB,AAFgD,GAGnC,CAAE,QADH,KACgB,CAAC,CAC7B,GAIE,EAAkBD,KAAkC,CAAC,OAJrC,AAID,CAHlB,AAG0C,CAAC,IAA0B,CAAC,CAAC,CACtE,GADoD,EACnC,OAAL,AAAqC,EAAvB,EAA2B,EAAvB,AAAyB,GACzDC,KAEE,CAAC,MAH4C,EAC1B,CACnB,GACa,CAAE,QADH,KACgB,CAAC,CAC7B,KAIsBD,KAAkC,CAC1D,IALiB,CAChB,GAG4C,CAAC,MAC/B,CAChB,CAAC,CACE,AAAiB,CAHqC,QAG5B,GAAyB,AAAvC,IAA2C,EAAzB,AAA2B,GAC3DC,KAEE,CAAC,QAH8C,AAC5B,CACnB,GACa,CAAE,QADH,OACkB,CAAC,CAC/B,KAIaD,KAAkC,CAAC,MAJ/B,AAIqC,CAHvD,AAGwD,CAArB,AAAsB,CAArB,AACnC,KAAiB,KAD4B,EACf,AAAY,AAA9B,EAAc,EAAoB,EAAE,EAAV,CACxCC,KAAoC,CAAC,QAAhB,CAAC,GAA2B,CAAE,MAAM,CAAC,CAAxB,AAA0B,GAGxD,EAAwBD,GAHwC,CAAC,CAGP,CAC9D,QADiD,CAAC,IAAzB,MAAmC,AACzC,CACpB,CAAC,CACE,AAAiB,SAAS,GAAd,AAA2C,IAAI,EAA7B,AAA+B,GAC/DC,KAEE,CAAC,QAFkB,CACnB,GAFmD,AAGtC,CAAE,QADH,OACkB,CAAC,CAC/B,GAIE,EAAuBD,KAAkC,CAC7D,QADgD,CAAC,CAJ1B,CACtB,CAGuB,MACN,CADyC,AAE5D,CAAC,CACE,KAAiB,IAoJsB,GApJe,AAA1C,EAAc,EAAgC,CAoJX,CApJjB,AAA8B,AAoJZ,GAnJlDC,KAEE,CAAC,QAFkB,CACnB,EAFkD,CAGrC,CAAE,QADH,UACqB,CAAC,CAClC,KAIgCD,KAAkC,CACpE,QADuD,CAJjC,AAIkC,CAHvD,SAGiE,MACzC,CAC1B,CAAC,CACE,KAAiB,OAAL,AAAiD,EAAnC,EAAuC,EAAnC,AAAqC,GACrEC,KAEE,CAAC,QAFkB,CACnB,GACa,CAAE,KAH0C,GAE7C,iBAC4B,CAAC,CACzC,KAIyBD,KAAkC,CAC7D,QADgD,CAAC,OAJpB,CAC5B,CAIiB,CADyC,AAE5D,CAAC,CACE,KAAiB,OAAL,AAA0C,EAA5B,EAAgC,EAAE,AAA9B,GAChCC,KAEE,CAAC,QAFkB,CACnB,EAFkD,CAGrC,CAAE,QADH,UACqB,CAAC,CAClC,GAIE,EAAeD,KAAkC,CAAC,IAAtC,IAAwB,CAJlB,AAImB,CAHxC,AAG+D,CAAC,CAAC,CAChE,KAAiB,CADgC,MACrC,AAAkC,EAApB,EAAwB,EAAE,AAAtB,GAChCC,KAEE,CAAC,GAHyC,KACvB,CACnB,GACa,CAAE,QADH,EACa,CAAC,CAC1B,GAIE,EAAqBD,KAAkC,CAC3D,CALc,CACb,MAG6C,CAAC,CAAzB,MACN,CACjB,CAAC,CACE,AAHuD,KAGtC,OAAL,AAAwC,EAA1B,EAA8B,EAA1B,AAA4B,GAC5DC,KAEE,CAAC,QAFkB,CAD6B,AAEhD,GACa,CAAE,QADH,OACkB,CAAE,UAAU,CAAC,CAC3C,GAIE,EAA+BD,KAAkC,CACrE,OALoB,CACnB,AAGuD,CAAC,UAAU,CAAnC,MACN,CAC3B,CAAC,CACE,KAAiB,OAAL,AAAkD,EAApC,EAAwC,EAApC,AAAsC,GACtEC,KAEE,CAAC,QAFkB,CACnB,GACa,CAAE,MAH2C,EAE9C,OACkB,CAAE,oBAAoB,CAAC,CACrD,KAIqBD,KAAkC,CAAC,QAAd,CAAC,KAA2B,CAAC,CAAC,CAJ5C,AAK5B,CAJD,CAGsD,GACpC,OAAL,AAAsC,EAAxB,EAA4B,EAAxB,AAA0B,GAC1DC,KAEE,CAAC,OAH6C,CAC3B,CACnB,GACa,CAAE,QADH,MACiB,CAAC,CAC9B,GAIE,EAAaD,KAAkC,CAAC,EAAtC,GAJI,CACjB,EAG2D,AAAtB,CAAC,AAAsB,CAAC,CAC5D,AAAiB,QAD8B,CACrB,GAAd,AAAgC,IAAI,EAAlB,AAAoB,GACpDC,KAAoC,CAAC,CADK,OACrB,AAAwB,CAAvB,AAAwB,CAAE,KAG5BD,KAHsC,AAGJ,CAHpB,AAAyB,AAGJ,QAAd,CAAC,EAAwB,CAAC,CAAC,CAClE,KADkD,AACjC,OAAL,AAAmC,EAArB,EAAyB,EAArB,AAAuB,GACvDC,KAEE,CAAC,IAH0C,IACxB,CACnB,GACa,CAAE,QADH,SACoB,CAAC,CACjC,KAIsBD,GAgEK,EAhE6B,CAC1D,EALe,CACd,IAmEsC,CAhEM,CAAC,MAC/B,CAChB,CAAC,CACE,CAHsD,IAGrC,OAAL,AAAuC,EAAzB,EAA6B,EAAzB,AAA2B,GAC3DC,KAEE,CAAC,QAH8C,AAC5B,CACnB,GACa,CAAE,QADH,OACkB,CAAC,CAC/B,IA4DG,GMnqCH,KNmqCW,EM9rCX,EAAOuC,CNkoCU,CMloCb,ANmoCL,CMloCG,MADqB,WACJ,CACjB,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAmBJ,CArBa,GAEL,CAAC,GAmBD,MAnBC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IAAI,AADc,CACb,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,MAAM,CAClB,WAAW,CAAE,MAAA,EAAA,CAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,AACU,GAAR,CAAY,CAAC,AADX,AACY,IAE/B,EAAS,MAFkC,AAEnC,KAFuC,IAEvB,CAAG,CACzB,OAAO,CAAE,EAAa,OAAO,CACR,CAHN,CAEM,IAMb,IAAI,CAAC,AAAC,EAR6C,EASjE,IAAM,EAAOmF,AN4sCf,CM7sCiC,CACrB,IADyB,GN8sCzC,AADc,CAC0B,EAAA,AAExC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAsB3H,CAFd,EAEoC,EAAY,CAC5D,GMltC4D,INitCF,CAAX,GAAxB,CALqB,KAM3B,CAClB,CAC0B,AADzB,IAC6B,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAsBD,GAAsB,EAAY,CAC5D,IAJwE,CAAC,EAGf,CAAX,GAAxB,EACV,CACd,CAAC,CACF,GAA2B,IAAI,EAA3B,EAA6B,CAC/B,IAAI,EAAkB,EAClB,KAAK,CAAC,EAFW,GACF,EACF,CAAC,GADuB,EAEvC,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,AAEvB,CADkC,CADT,CAEA,CADnB,EAAkB,AAAc,AAE9C,CADqC,AACpC,CADqC,AAGzCC,GAAsB,EAAU,CAAC,KAAH,GAAT,EAHc,OAGe,CAAC,CAAE,EACtD,CAED,IAAM,EAAqCD,GAAsB,EAAY,CAC3E,AAJoE,CAAC,MAGI,CAAX,kBAAxB,MACN,CACjC,CAAC,CASF,OARI,AAAsC,IAAI,EAAE,GAC9CC,GACE,EACA,CAAC,KADO,GADW,WADe,aAGD,CAAC,CAClC,GAA2B,IAIxB,CACT,EMjvCiE,GACnD,EN+uCG,AM/uCS,IAAI2H,EAD8C,CAGpE,AAHqE,AACtD,IN2uCS,GM1uCxB,MAAM,CAAC,CN0uCoD,CAAC,CAC/D,EM5uCqD,CACrC,CADuC,AACtC,EAAW,GAClB,CADsB,AAE/B,CAFgC,AAE/B,CAAC,AACH,CAH0B,AAGpB,KN4mCH,AM9mCgB,ENgnChB,MAFQ,AM3mCJ,GN6mCK,CM7mCD,CACR,EADWC,EACP,CAAC,SAAS,GN0mCsB,CAAA,CAAE,CAGxC,AAAa,IAAI,EAAE,GADL7H,AACL,GM5mCP,CAFqD,CN6mCP,CAAC,GM3mCzC,CACP,GN0mCuD,CAAC,AAAtB,CAAuB,AAAtB,GAEtCC,GACE,EACA,CAAC,CAJ6C,IAGtC,CACD,CAAE,CAFU,MAEH,CAAC,CACjBmB,GAAS,EAAW,CAAZ,GAKR,AAAc,GALI,CAKA,CALW,CAKT,AALU,CAC/B,AAGG,EAAapB,CACL,IADuC,CAAC,EAAtC,MAAwB,AAAsB,CAArB,AAAsB,CAAC,GAE9DC,GAAsB,EAAU,CAAC,AAFgB,KAEnB,GAAT,MAA0B,CAAE,QAAQ,CAAC,CAAE,GAI1D,AAAc,IAAI,EAAE,CAJgD,AAGlE,CAHmE,CAGtDD,CACL,IADuC,CAAC,EAAtC,MAAwB,AAAsB,CAAC,AAAtB,CAAuB,GAE9D,AAxVY,MAsVqC,GArVnD,AADc,CACwB,CACtC,CAAqC,EAAA,AAIrC,QAA4D,IAAxDA,CAkVyB,EAlVH,EAAY,AAA+B,CAA9B,CAAgC,GAN9B,GAML,CAAX,MAA4B,CAAC,CAAC,CACrD,MAAM,AAAI,KAAK,CAAC,wDAAwD,CAAC,CAG3E,GAAIA,KAA0D,OAApC,EAAD,AAAa,AAAiC,CAAhC,CAAkC,MAArC,SAAmB,CAAC,CAAC,CACvD,MAAM,AAAI,KAAK,CAAC,0DAA0D,CAAC,CAG7E,IAAM,EAAqBA,GAAsB,EAAY,CAC3D,OADyD,CAAX,EAAxB,MACN,CACjB,CACG,AADF,MACmB,MAAL,CAAwC,EAA1B,EAA8B,EAA1B,AAA4B,GAC5DC,GACE,EACA,CAAC,QAFkB,CACP,AAFoC,GAGnC,CAAE,aAAa,CAAC,CAC7B,GAIJ,IAAM,EAAkBD,GAAsB,EAAY,CAAC,GAJrC,CACnB,GAGkB,AAAmC,CAAX,KAA2B,CAAC,CAAC,MACrD,IAAjB,GAAiD,EAAvB,EAA2B,EAAvB,AAAyB,GAA3C,AACdC,GACE,EACA,CAAC,MAH4C,EAC1B,CACP,GACC,CAAE,aAAa,CAAC,CAC7B,GAIJ,IAAM,EAAoBD,GAAsB,EAAY,CAJzC,AAKjB,CAJC,MAGuD,CAAX,CAAxB,MACN,CAChB,CAAC,CASF,GARI,AAAiB,SAAS,GAAyB,AAAvC,AAAkB,IAAyB,EAAE,GAC3DC,GACE,EACA,CAAC,EAH8C,MAC5B,CACP,GACC,CAAE,eAAe,CAAC,CAC/B,QAIgD,IAAhDD,GAAsB,EAJL,AAIiB,AAAuB,CAH1D,AAGoC,CAAwB,KAAlB,CAAT,AAAU,CAArB,AAAsB,CAC7C,MAAM,AAAI,KAAK,CAAC,gDAAgD,CAAC,CAGnE,IAAM,EAAwBA,GAAsB,EAAY,CAC9D,OAD4D,CAAX,KAAxB,MACN,CACpB,CAAC,MACmB,IAAjB,GAA8B,AAAyB,EAA7B,EAAiC,EAAE,GAC/DC,AADc,GAEZ,EACA,CAAC,MAHkD,EAChC,CACP,GACC,CAAE,eAAe,CAAC,CAC/B,GAIJ,IAAM,EAAuBD,GAAsB,EAAY,CAC7D,MALuB,CACtB,AAG0D,CAAX,IAAxB,MACN,CACnB,CAAC,MACmB,IAAjB,GAAsD,EAA5B,EAAgC,EAA5B,AAA8B,GAAhD,AACdC,GACE,EACA,CAAC,QAFkB,CACP,EAFsC,CAGrC,CAAE,kBAAkB,CAAC,CAClC,GAIJ,IAAM,EAA8BD,GAAsB,EAAY,CACpE,KALsB,CACrB,CAGiE,CAAX,WAAxB,MACN,CAC1B,CAAC,MACmB,IAAjB,GAA6D,EAAnC,EAAuC,EAAnC,AAAqC,GAAvD,AACdC,GACE,EACA,CAAC,QAFkB,CACP,GACC,CAAE,KAH0C,oBAGjB,CAAC,CACzC,GAIJ,IAAM,EAAuBD,GAAsB,EAAY,CAC7D,OAD2D,CAAX,IAAxB,AAJK,CAC5B,KAIiB,CACnB,CAAC,MACmB,IAAjB,GAAsD,EAA5B,EAAgC,EAA5B,AAA8B,GAAhD,AACdC,GACE,EACA,CAAC,QAFkB,CACP,EAFsC,CAGrC,CAAE,kBAAkB,CAAC,CAClC,GAIJ,IAAM,EAAeD,GAAsB,EAAY,CAAC,IAAtC,CAJM,CACrB,CAGkD,CAAX,EAAwB,CAAC,CAAC,MAC/C,IAAjB,GAA8C,EAApB,EAAwB,EAAE,AAAtB,GAChCC,AADc,GAEZ,EACA,CAAC,GAHyC,KACvB,CACP,GACC,CAAE,UAAU,CAAC,CAC1B,GAIJ,IAAM,EAAqBD,GAAsB,AAJjC,CACb,CAG0D,CAC3D,OADyD,CAAX,EAAxB,MACN,CACjB,CAAC,MACmB,IAAjB,GAAoD,EAA1B,EAA8B,EAA1B,AAA4B,GAC5DC,AADc,GAEZ,EACA,CAAC,QAFkB,CACP,AAFoC,GAGnC,CAAE,eAAe,CAAE,UAAU,CAAC,CAC3C,GAIJ,IAAM,EAA+BD,GAAsB,EAAY,CACrE,GALoB,CACnB,GAGkE,CAAX,YAAxB,MACN,CAC3B,CAAC,CASF,GARqB,SAAjB,AAA0B,GAAoC,IAAI,EAApC,AAAsC,GAAxD,AACdC,GACE,EACA,CAAC,QAFkB,CACP,GACC,CAAE,MAH2C,SAG5B,CAAE,oBAAoB,CAAC,CACrD,QAIwD,IAAxDD,GAAsB,EAAY,AAA+B,CAA9B,CAAgC,MAAnC,CAAX,EAJO,CAC7B,GAGkD,CAAC,CAAC,CACrD,MAAM,AAAI,KAAK,CAAC,wDAAwD,CAAC,CAG3E,QAAsD,IAAlDA,GAAsB,EAAY,AAAyB,CAAxB,CAA0B,MAA7B,CAAX,AAAsB,CAAC,CAAC,CAC/C,MAAM,AAAI,KAAK,CAAC,kDAAkD,CAAC,CAGrE,IAAM,EAAgBA,GAAsB,EAAY,CAAC,KAAtC,EAAmC,CAAX,GAAyB,CAAC,CAAC,CAStE,QARqB,IAAjB,GAA+C,EAArB,EAAyB,EAAE,AAAvB,GAChCC,AADc,GAEZ,EACA,CAAC,IAH0C,IACxB,CACP,GACC,CAAE,iBAAiB,CAAC,CACjC,GAIAD,KAAyD,KAJ5C,CACd,CAGuB,EAA4C,AAA7C,AAAa,CAAC,CAAiC,MAApC,QAAkB,CAAC,CAAC,CACtD,MAAM,AAAI,KAAK,CAAC,yDAAyD,CAAC,AAI9E,EAsMgC,EAAY,GAGnC,GMjmCH,EN8lCoC,AAAU,CAAC,EAGpC,EM5nCX,EAAOwC,EAAH,CACF,MADqB,WACJ,CACjB,EAAK,EAAD,EAAmC,CACxC,CACD,AAFa,EAEC,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAmBJ,CArBa,GAEL,CAAC,GAmBD,MAnBC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,MAAM,CAClB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CAAC,AADV,GACE,CAAY,CAAC,AAAC,AADZ,IAEF,AACjB,EAAS,MAFkC,AAEnC,IADqD,CADd,IAEvB,CAAG,CACzB,OAAO,CAAE,EAAa,OAAO,CACR,EADA,IAMb,IAAI,CAAC,AAAC,IACpB,IAAM,EAAOsF,AN+nCf,CMhoCiC,CACrB,IADyB,GNgoC3B,AACd,CAAwC,EAAA,AAExC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAsB9H,CAFd,EAEoC,EAAY,CAC5D,EMroC2D,KNooCD,CAAX,GALJ,AAKpB,MACN,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAsBD,GAAsB,EAAY,CAC5D,IAJwE,CAAC,EAGf,CAAX,GAAxB,EACV,CACd,CAAC,CACF,GAA2B,IAAI,EAA3B,EAA6B,CAC/B,IAAI,EAAkB,EAClB,KAAK,CAAC,EAFW,GACF,EACF,CAAC,GADuB,EAEvC,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,CACW,CADT,EACnB,CAqrBnB,CArrBmD,AAAd,CAqiCrC,MA9WM,EAF0B,EAkX1B,AAlX0B,AAgXT,EAAA,EA9WT,AAyXR,IATQ,AA9VR,QAuWY,GAzXwB,CAAA,CAAE,CAGxC,AAAa,IAAI,EAAE,AAeG,CAhBpB,EAAYA,AACL,KAzrBwB,EAwrBe,AAArC,CAAsC,CAxrBZ,CAAC,IAwrBH,CAAqB,AAApB,CAAqB,CAAC,GAE5DC,GAAsB,EAF0B,AAEhB,CAAC,KAAH,EAAU,CAAnB,AAAoB,EAAE,EA4WH,CAAA,CAAE,CAKtB,AAAlB,IAAsB,EAAE,CAHtB,EAAiBD,AA9WoC,KAiXzC,AAjX0C,EA8WH,CACvD,IADkB,EAAwB,AA9WyB,CA8WxB,AA9WyB,CAAC,SA8WhB,GACjC,CACrB,CAAC,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,IAAwB,CAAC,EAAEO,EAAS,IAAD,AAItD,AAAgB,IAAI,EAAE,GADLR,CAHoD,CAAC,CAAC,AAGhC,AAC3B,EADuC,CAAC,OAAH,CAAX,EAAwB,CAAC,CAAC,GAElEC,GAAsB,EAAU,CAAC,KAAH,GAAT,EAAsB,CAAC,CAAE,GAGzC,IApXH,AAAyB,IAoXd,AApXkB,CAiX2B,CAjXzB,AAiX0B,CApXvD,EAAwBD,GAAsB,EAAY,CAC9D,MAEuB,CAHqC,CAAX,KAAxB,MACN,CACpB,CAAC,GAEAC,GACE,EACA,CAAC,KADO,GADW,WAEC,CAAC,CACrB,GAKwB,AAAxB,IAA4B,EAAE,GADLD,GAAsB,EAAY,CAAC,GAJvC,CACtB,CAIqB,EADqC,AAAU,CAArB,AAAsB,CAAC,GAEvEC,GACE,EACA,CAAC,KADO,GADW,UAEA,CAAC,CACpB,GAA0B,IAIvB,GAhtBF,CAAC,CAEJA,GA8sBa,AA9sBS,EAAU,CAAC,KAAH,AA0sBkB,CAAC,CAAtB,AAC1B,CA3sBoB,SAA6B,CAAC,CAAE,EACtD,CAED,IAAM,EAAqCD,GAAsB,EAAY,CAC3E,AAJoE,CAAC,MAGI,CAAX,kBAAxB,MACN,CACjC,CAAC,CASF,OAR0C,IAAI,EAAE,AAA5C,GACFC,GACE,EACA,CAAC,KADO,GADW,iBADe,OAGD,CAAC,CAClC,GAA0B,IAIvB,CACT,EMpqCgE,GAClD,ENkqCG,AMlqCS,IAAI2H,EAD6C,CAAC,AACrD,AAEf,GN4pCuB,IM7pCvB,MAAM,CAAC,CN6pCmD,CAAC,CAC9D,EM/pCqD,CACrC,CADuC,AACtC,EAAW,GAClB,CADsB,AAE/B,CAFgC,AAE/B,CAAC,AACH,CAH0B,CASrB,IARc,EAQR,iBAAiB,CAC7B,CAAmD,CAAA,SAInD,IAAI,EAAe,EAAX,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,GAAI,GADW,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,CAC/B,IAAM,EAAOG,ANlRH,EMkRA,ONlRA,AACd,CAAoB,CACpB,CAAuD,EAAA,AAEvD,MAjKM,EAWA,EAWA,EASA,EAWA,EAKA,EAWA,GMqXyD,CNrYjD,EA1CU,AA2FlB,CArEe,CAXG,EAoGlB,CAhFiB,CA8H0B,IArB3C,EA7CY,CA5CS,CAWD,AAuGpB,EAAoC,CAAA,CAAE,CAEtC,EAAY/H,CAFJ,AAzBI,EA2BsB,EAAY,CAAC,CAAtC,IApDmB,EAoDgB,AAAU,CAArB,AAAsB,CAC5C,AAD6C,AAC1D,IAAiB,EAAE,GAAV,CACXC,GACE,EACA,CAAC,KADO,CACD,CAAE,CAFU,MAEH,CAAC,CACjBmB,GAAS,EAAW,CAAZ,GAIZ,GAJsB,CAIhB,CAJ2B,CAAC,AAIfpB,CAHhB,EAGsC,EAAY,CAAC,EAAtC,KAAmC,CAAX,AAAsB,CAAC,CAAC,AAC9C,IAAI,EAAE,CAApB,GACFC,GAAsB,EAAU,CAAC,CADrB,IACkB,GAAT,MAA0B,CAAE,QAAQ,CAAC,CAAE,GAG9D,IAAM,EAAsBD,CAH4C,CAAC,CAGvB,EAAY,CAC5D,OAD0D,CAAX,GAAxB,MACN,CAClB,CAAC,CACF,GAA2B,IAAI,EAA3B,EAA6B,CAC/B,IAAI,EAAkB,EAClB,KAAK,CAAC,EAFW,GACF,EACF,CAAC,GADuB,EAEvC,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAEtB,AAFuB,CACW,AA8lG3C,CA/lGkC,EACnB,EAAgC,AAAd,IA8lGvB,AACd,CAAqD,EAAA,AAErD,YAvjHM,IAOA,EAgjHA,EAvjHQ,AAudgC,AAgmGJ,CAAA,CAAE,CAEtC,EAAqBA,CAFb,EAEmC,EALF,AAKc,CAC3D,OADyD,CAAX,EAAxB,MACN,CACjB,CApjHsC,AAqjHb,AADxB,IAC4B,EAAE,CAA5B,GACFC,GACE,EACA,CAAC,KADO,GADW,CADD,OAGD,CAAC,CAClB,GAAc,IAIlB,IAAM,EAJW,AAIOD,GAAsB,EAAY,CAAC,EAJvB,CAAC,CAClC,GAGkB,AAAmC,CAAX,KAA2B,CAAC,CAAC,AACnD,IAAI,EAAE,CAAzB,GACFC,GAAsB,EAAU,CAAC,KAAH,CADb,EACI,KAAyB,CAAC,CAAE,GAGnD,IAAM,EAAoBD,GAAsB,EAAY,CAHM,AAIhE,CAJiE,MAGT,CAAX,CAAxB,MACN,CAChB,CACwB,AADvB,IAC2B,EAAE,CAA3B,GACFC,GAAsB,EAAU,CAAC,KAAH,GADX,AACE,OAA2B,CAAC,CAAE,GAGrD,IAAM,EAAsBD,GAAsB,EAAY,CAC5D,EAJoE,CAAC,IAGX,CAAX,GAAxB,MACN,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GACE,EACA,CAAC,KADO,GADW,EADA,OAGD,CAAC,EACnB,AAleE,EAAoC,CAAA,CAAE,CAGxB,AAAhB,GAHU,CAGU,EAAE,CADpB,EAAeD,GACL,EADuC,CAAC,IAAtC,GAgea,CAheW,CAAC,CAAuB,CAAC,CAAC,GAElEC,GAAsB,CAF6B,CAEnB,CAAC,KAAH,GAAT,EAAsB,CAAC,CAAE,GAM5C,AAA2B,IAAI,EAAE,CAH/B,EAHsD,AAG5BD,CAH6B,IAGK,CAChE,QADmD,AAG1B,CAH2B,MAAzB,IAAmC,EACzC,CACtB,CAAC,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,KAAyB,CAAC,CAAE,GAI/C,AAAoB,IAAI,EAAE,CADxB,EAAmBD,GAodO,EApd2B,CAAC,CACxC,IAJsD,CAAC,EAGrD,AAAwB,CAAC,KAA2B,CAAC,CAodxB,AApdyB,CAodxB,CACjD,CArdsD,AAEvDC,GAAsB,EAAU,CAAC,KAAH,GAAT,EAAsB,CAAC,CAAE,GAGzC,IAmdP,IAAM,AAndS,EAmdgBD,GAAsB,AAtdW,CAAC,CAsdA,CAC/D,OAD6D,CAAX,MAAxB,MACN,CACrB,CAAC,AAC4B,IAAI,EAAE,CAAhC,GACFC,GACE,EACA,CAAC,KADO,GADW,KADG,OAGD,CAAC,EACtB,EAlmHsC,CAAA,CAAE,CAGxC,AAAmB,IAAI,EAAE,CADvB,EAAkBD,KAAkC,CAAC,AACxC,OADE,CAAwB,CAAC,CAgmHZ,GAhmHsC,CAAC,CAAC,GAExEC,CAFsD,EAEhC,EAAU,CAAC,KAAH,GAAT,KAAyB,CAAC,CAAE,GAM/C,AAAqC,IAAI,EAAE,GAHLD,GA2lHP,AA9lH+B,CAAC,CAGS,CAC1E,QAD6D,CAAC,SAG3B,CAwlHoB,AA3lHiB,CA2lHhB,CACvD,UA3lH8B,CAChC,CAAC,GAEAC,GACE,EACA,CAAC,KADO,GADW,QAEF,CAAC,CAClB,GAIG,IAolHP,IAAM,AAplHS,EAolHcD,GAAsB,EAAY,CAC7D,OAD2D,CAAX,IAAxB,EAxlHW,CAClC,GAwlHiB,CACnB,CAAC,AAC0B,IAAI,EAAE,CAA9B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,GADC,OAC6B,CAAC,CAAE,GAGxD,IAAM,EAAyBD,GAAsB,EAAY,CAC/D,KAJ0E,CAAC,CAGd,CAAX,MAAxB,MACN,CACrB,CAAC,CASF,OAR8B,IAAI,EAA9B,AAAgC,GAClCC,GACE,EACA,CAAC,KADO,GADW,KADG,OAGD,CAAC,CACtB,GAIG,EACT,EAlqGiD,GAC1C,CAAC,AAD6C,AAiqGpC,CAjqGqC,AAGlDA,GACE,EACA,CAAC,IAwpGqB,CAzpGd,AA0pGT,GA3pGoB,MAEJ,CAAE,iBAAiB,CAAC,CACnC,EAEH,CAED,IAAM,EAAaD,GAAsB,EAAY,CAJlC,AAImC,CAHnD,CAGa,KAAmC,CAAX,AAAsB,CAAC,CAAC,CAKhE,OAJkB,IAAI,EAAE,AAApB,IA5ME,EAAmBA,IA4MX,CA5M6C,CAAC,QAAtC,AAAwB,CAAC,KAA2B,CAAC,CAAC,CACxE,EADqD,GACpC,OAAL,AAAsC,EAAxB,EAA4B,EAAxB,AAA0B,GAC1DC,KAEE,CAAC,OAH6C,CAC3B,CACnB,GACa,CAAE,QADH,IACe,CAAC,CAC5B,KAIuBD,KAAkC,CAC3D,KALkB,CACjB,EAG6C,CAAC,OAC/B,CACjB,CAAC,CAFyD,AAGvD,KAAiB,OAAL,AAAwC,EAA1B,EAA8B,EAA1B,AAA4B,GAC5DC,KAEE,CAAC,QAFkB,CACnB,AAFgD,GAGnC,CAAE,QADH,QACmB,CAAC,CAChC,KAIuBD,KAAkC,CAC3D,OALoB,CACnB,AAG6C,CAAC,OAC/B,CACjB,CAAC,CAFyD,AAGvD,KAAiB,IAsLiB,GAtLtB,AAAwC,EAA1B,EAA8B,CAsLd,CAtLZ,AAsLa,AAtLe,GAC5DC,KAEE,CAAC,QAFkB,CAD6B,AAEhD,GACa,CAAE,QADH,KACgB,CAAC,CAC7B,KAIoBD,KAAkC,CAAC,OAJrC,CACnB,AAG0C,CAAC,IAA0B,CAAC,CAAC,CACtE,GADoD,EACnC,OAAL,AAAqC,EAAvB,EAA2B,EAAvB,AAAyB,GACzDC,KAEE,CAAC,MAH4C,EAC1B,CACnB,GACa,CAAE,QADH,KACgB,CAAC,CAC7B,KAIsBD,KAAkC,CAC1D,IALiB,CAChB,GAG4C,CAAC,MAC/B,CAChB,CAAC,CACE,CAHsD,IAGrC,OAAkC,AAAvC,EAAc,EAA6B,EAAzB,AAA2B,GAC3DC,KAEE,CAAC,QAH8C,AAC5B,CACnB,GACa,CAAE,QADH,OACkB,CAAC,CAC/B,KAIaD,GA0JS,EA1JyB,CAAC,MAAM,AAJrC,CA8Je,AA1JuB,AAHxD,CAGyD,AAAtB,CAAC,AACnC,KAAiB,KAD4B,EACH,AAA9B,EAAc,EAAoB,EAAhB,AAAkB,GAClDC,KADwC,AACJ,CAAC,QAAhB,CAAC,GAA2B,CAAE,MAAM,CAAC,CAAE,AAA1B,KAGND,GAHwC,CAAC,CAGP,CAC9D,QADiD,CAAC,UAAU,AACzC,CACpB,CAAC,CACE,AAAiB,SAAS,GAAd,AAAkB,AAAyB,IAAI,EAAE,GAC/DC,KAEE,CAAC,MAHkD,EAChC,CACnB,GACa,CAAE,QADH,OACkB,CAAC,CAC/B,KAIyBD,KAAkC,CAC7D,QADgD,CAAC,CAJ1B,CACtB,OAIiB,CACnB,AAF4D,CAE3D,CACE,KAAiB,OAAqC,AAA1C,EAAc,EAAgC,EAAE,AAA9B,GAChCC,KAEE,CAAC,QAFkB,CACnB,EAFkD,CAGrC,CAAE,QADH,UACqB,CAAC,CAClC,GAIE,EAA8BD,KAAkC,CACpE,QADuD,CAJjC,AAIkC,CAHvD,SAG8B,AAAmC,MACzC,CAC1B,CAAC,CACE,AAAiB,SAAS,GAAd,AAAkB,AAA+B,IAAI,EAAE,GACrEC,KAEE,CAAC,QAFkB,CACnB,GACa,AAH4C,CAG1C,QADH,iBAC4B,CAAC,CACzC,GAIE,EAAuBD,KAAkC,CAC7D,QADgD,CAAC,GAAzB,IAJK,CAC5B,CAIiB,CACnB,AAF4D,CAE3D,CACE,KAAiB,OAAqC,AAA1C,EAAc,EAAgC,EAA5B,AAA8B,GAC9DC,KAEE,CAAC,QAFkB,CACnB,EAFkD,CAGrC,CAAE,QADH,UACqB,CAAC,CAClC,KAIiBD,KAAkC,CAAC,QAAd,CAJlB,AAImB,CAHxC,AAG+D,CAAC,CAAC,CAChE,KAAiB,CADgC,MACrC,AAAkC,EAApB,EAAwB,EAApB,AAAsB,GACtDC,KAEE,CAAC,GAHyC,KACvB,CACnB,GACa,CAAE,QADH,EACa,CAAC,CAC1B,GAIE,EAAqBD,KAAkC,CAC3D,CALc,CACb,MAG6C,CAAC,CAAzB,MACN,CACjB,CAAC,CACE,AAHuD,KAGtC,OAAL,AAAkB,AAAsB,EAA1B,EAA8B,EAAE,GAC5DC,KAEE,CAAC,GAH+C,KAC7B,CACnB,GACa,CAAE,QADH,OACkB,CAAE,UAAU,CAAC,CAC3C,KAIiCD,KAAkC,CACrE,OALoB,CAIoC,AAHvD,CAGwD,UAAU,OACzC,CAC3B,CAAC,CACE,KAAiB,OAA6C,AAAlD,EAAc,EAAwC,EAApC,AAAsC,GACtEC,KAEE,CAAC,QAFkB,CACnB,GACa,CAAE,MAH2C,EAE9C,OACkB,CAAE,oBAAoB,CAAC,CACrD,GAIE,EAAmBD,KAAkC,CAAC,QAAtC,AAAwB,CAAC,KAA2B,CAAC,CAAC,CACvD,AALW,AAK5B,CAJD,CAGsD,OAC3B,GAAd,AAAsC,IAAI,EAAE,AAA1B,GAChCC,KAEE,CAAC,OAH6C,CAC3B,CACnB,GACa,CAAE,QADH,MACiB,CAAC,CAC9B,GAIE,EAAaD,KAAkC,CAAC,EAAtC,GAJI,CACjB,EAGqC,AAAsB,CAArB,AAAsB,CAAC,CAC5D,KAAiB,GAD8B,IACnC,AAAkB,AAAc,EAAlB,EAAsB,EAAE,GACpDC,CAD0C,IACN,CAAC,QAAQ,AAAxB,CAAC,AAAwB,CAAE,KAG7BD,KAHuC,AAGL,CAHnB,AAAyB,AAGL,QAAd,CAAC,CAAuB,CAAC,CAAC,CAChE,KAAiB,CADgC,MACrC,AAAkC,EAApB,EAAwB,EAApB,AAAsB,GACtDC,KAEE,CAAC,GAHyC,KACvB,CACnB,GACa,CAAE,QADH,EACa,CAAC,CAC1B,GAIE,EAAgBD,KAAkC,CAAC,CAJzC,CACb,GAGgB,GAAwB,CAAC,EAAwB,CAAC,CAAC,CAClE,KAAiB,AADiC,OACtC,AAAkB,AAAiB,EAArB,EAAyB,EAAE,GACvDC,IAD6C,CAG3C,CAAC,QAFkB,CACnB,GACa,CAAE,QADH,IACe,CAAE,WAAW,CAAC,CACzC,IAiDG,CACT,EMwOQ,IAAI,CAAC,ANzOI,CAjDE,CACd,OMyRiB,CACd,GA6BF,GA7BQ,CACP,GACD,EAAOuC,EAAH,CACF,MADqB,WACJ,CACjB,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CACtD,AADW,CAAgB,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAmBJ,CArBa,GAEL,CAAC,GAmBD,MAnBC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IAAI,AADc,CACb,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,MAAM,CAClB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAO,AAAN,EAAM,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,AACU,GAAR,CAAY,CADV,AACW,AAAC,IACd,AACjB,EAAS,MAFkC,AAEnC,IADgD,CADT,IAEvB,CAAG,CACzB,OAAO,CAAE,EAAa,OAAO,CACR,EADA,IAMb,IAAI,CAAC,AAAC,IACpB,IAAM,ENrQR,AMqQewF,CADkB,CACrB,IADyB,GNpQ3B,AACd,CAAmC,EAAA,AAEnC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAsBhI,CAFd,EAEoC,CMgQO,CNhQK,CAC5D,OAD0D,AALnB,CAKQ,GAAxB,MACN,CAClB,CAAC,AACE,AAAuB,IAAI,EAAE,IAC/BC,GAAsB,EAAU,CAAC,GADZ,EACS,GAAT,SAA6B,CAAC,CAAE,GAGvD,IAAM,EAAsBD,GAAsB,EAAY,CAC5D,IAJwE,CAAC,EAGf,CAAX,GAAxB,EACV,CACd,CAAC,CACF,GAA2B,IAAI,EAA3B,EAA6B,CAC/B,IAAI,EAAkB,CAClB,KAAK,EAAC,EAFW,GACF,EACF,CAAC,GADuB,EAEvC,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,AAEvB,CADkC,CADT,CAEA,CADnB,EAAkB,AAAc,AAE9C,CADqC,AACpC,CADqC,AAGzCC,GAAsB,EAAU,CAAC,KAAH,GAAT,EAHc,OAGe,CAAC,CAAE,EACtD,CAED,OAAO,CACT,EM2O4D,EN/OY,CAAC,AMgP3D,EAAY,AN7OT,IM6OagI,EADyC,CAAC,AACjD,AAEf,OADA,MAAM,CAAC,AADsC,EAAE,IAClC,CAAC,EAAW,GAClB,CADsB,AAE/B,CAFgC,AAE/B,CAAC,AACH,CAH0B,AAIzB,KAHkB,CAEb,AACC,AAAI,KAAK,CAAC,iDAAiD,CAAC,CAO9D,MAAM,oBAAoB,CAChC,CAAyD,CAAA,SNohH3D,EMhhHE,IAAI,EAAe,CNghHD,CMhhHV,AAAa,CNihHvB,AMhhHM,EAAsC,CAAA,CAAE,CAC5C,GAAI,EN+gHuD,CMhhH5C,CNghH4C,AM/gHnD,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,WNqiH7B,MAvGA,EAWA,EAWA,EAWA,IAsBA,CAgDiB,KMpiHb,INw8Gc,AA4CR,AAvDU,AM77GZ,CACR,EADWC,EACP,CAAC,CN69GgB,KAXO,GMl9Gd,CN+gHd,EAAoC,CAAA,CAAE,CAGxC,AAAa,GAHH,CAGO,EAAE,CADjB,EAAYlI,AACL,KADuC,CAAC,CAAtC,MAA6C,CAArB,AAAsB,AMlhHQ,CNkhHP,AAAtB,GAEtCC,GACE,EACA,CAAC,CAJ6C,IAGtC,CACD,CAAE,CAFU,MAEH,CAAC,CACjBmB,GAAS,EAAW,CAAZ,GAKR,AAAa,GALK,CAKD,CALY,CAAC,AAKX,CAJpB,AAGG,EAAYpB,AACL,KADuC,CAAC,CAAtC,MAA6C,CAArB,AAAsB,CAAC,AAAtB,GAEtCC,GACE,EACA,CAAC,CAJ6C,IAGtC,GADW,MAEJ,CAAE,OAAO,CAAC,CACzB,GAAc,IAOd,AAAqB,IAAI,CAPF,CAAV,AAOc,AAPH,CACzB,EAGuBD,GMliHpB,ENkiHsD,CAC1D,EAEmB,CMriHT,CACP,INiiH0C,CAAC,MAC/B,CAChB,CAAC,EAFwD,CAIxDC,GACE,EACA,CAAC,KADO,GADW,IAEN,CAAE,eAAe,CAAE,eAAe,CAAC,CAChD,GAKA,AAAc,IAAI,EAAE,CADlB,EAAaD,CACL,IADuC,AAJhC,CAClB,AAGmD,EAAtC,MAAwB,AAAsB,CAArB,AAAsB,CAAC,IA3H1D,EAAmBA,GA2H0B,EA3HQ,CAAC,QAAtC,AAAwB,CAAC,KAA2B,CAAC,CAAC,CACxE,AAAiB,EADoC,OAC3B,GAAwB,AAAtC,IAA0C,EAAxB,AAA0B,GAC1DC,KAEE,CAAC,OAH6C,CAC3B,CACnB,GACa,CAAE,QADH,IACe,CAAC,CAC5B,KAIyBD,KAAkC,CAC7D,KALkB,CACjB,EAG+C,CAAC,SAC/B,CACnB,AAF4D,CAE3D,CACE,AAAiB,SAAS,GAA4B,AAA1C,IAA8C,EAA5B,AAA8B,GAC9DC,KAEE,CAAC,QAFkB,CACnB,EAFkD,CAGrC,CAAE,QADH,UACqB,CAAC,CAClC,KAIuBD,KAAkC,CAC3D,QAD8C,CAJxB,AAIyB,CAH9C,MAIe,CACjB,CAAC,CAFyD,AAGvD,KAAiB,OAAL,AAAkB,AAAsB,EAA1B,EAA8B,EAAE,GAC5DC,KAEE,CAAC,GAH+C,KAC7B,CACnB,GACa,CAAE,QADH,OACkB,CAAE,UAAU,CAAC,CAC3C,KAIiCD,KAAkC,CACrE,OALoB,CACnB,AAGuD,CAAC,UAAU,OACzC,CAC3B,CAAC,CACE,KAAiB,OAAL,AAAkD,EAApC,EAAwC,EAApC,AAAsC,GACtEC,KAEE,CAAC,QAFkB,CACnB,GACa,CAAE,MAH2C,EAE9C,OACkB,CAAE,oBAAoB,CAAC,CACrD,KAI0BD,KAAkC,CAC9D,QADiD,CAAC,QAJpB,CAC7B,CAG2D,AACzC,CACpB,CAAC,CACE,KAAiB,OAAL,AAAkB,AAAyB,EAA7B,EAAiC,EAAE,GAC/DC,KAEE,CAAC,MAHkD,EAChC,CACnB,GACa,CAAE,QADH,OACkB,CAAE,mBAAmB,CAAC,CACpD,GAIE,EAA8BD,KAAkC,CACpE,QADuD,CAAC,CAJjC,CACtB,QAG8B,AAAmC,MACzC,CAC1B,CAAC,CACE,KAAiB,OAAL,AAAiD,EAAnC,EAAuC,EAAnC,AAAqC,GACrEC,KAEE,CAAC,QAFkB,CACnB,GACa,CAAE,KAH0C,GAE7C,OACkB,CAAE,yBAAyB,CAAC,CAC1D,KAIeD,KAAkC,CAAC,QAAQ,AAAtB,CAAuB,AAAtB,CAAuB,CAC5D,KAAiB,AALU,CAC5B,EAGgD,IACnC,AAAgC,EAAlB,EAAsB,EAAlB,AAAoB,GACpDC,KAAoC,CAAC,CADK,OACrB,AAAwB,CAAvB,AAAwB,CAAE,GAG5C,EAAqBD,KAHiC,AAGC,CAHzB,AAIlC,AAJ2D,QAGb,CAAC,CAAzB,MACN,CACjB,CAAC,CAFyD,AAGvD,KAAiB,IAqD+B,GArDpC,AAAwC,EAA1B,EAA8B,CAqDA,CArD1B,AAA4B,AAqDD,GApD3DC,KAEE,CAAC,QAFkB,CAD6B,AAEhD,GACa,CAAE,QADH,KACgB,CAAC,CAC7B,GAIE,EAAWD,GA6CuB,EA7CW,CAArC,AAAsC,MAAM,CAJpC,AAIqC,AA6CT,CAhD/C,AAGmC,AAAsB,CAArB,AACnC,KAAiB,KAD4B,EACjC,AAAkB,AAAY,EAAhB,EAAoB,EAAE,EAAV,CACxCC,KAAoC,CAAC,QAAhB,CAAC,GAA2B,CAAE,MAAM,CAAC,CAAE,AAA1B,IA8C7B,GMrhHH,CNu+GkE,CAAC,GA8CxD,EMhjHX,EAAOuC,EAAH,CACF,MADqB,WACJ,CACjB,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CACtD,AADW,CAAgB,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAmBJ,CArBa,GAEL,CAAC,GAmBD,MAnBC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,MAAM,CAClB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CAAC,AADV,GACE,CAAY,CAAC,AAAC,AADZ,IAEF,AACjB,EAAS,MAFkC,AAEnC,IADmD,CADZ,IAEvB,CAAG,CACzB,OAAO,CAAE,EAAa,OAAO,CACR,EADA,IAMb,IAAI,CAAC,AAAC,IACpB,IAAM,ENuhHR,AMvhHe2F,CADkB,CACrB,IADyB,GNwhH3B,AACd,CAAsC,EAAA,AAEtC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAsBnI,CAFd,EAEoC,EAAY,CAC5D,CM7hH0D,MN4hHA,CAAX,EALL,CAKnB,MACN,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAsBD,GAAsB,EAAY,CAC5D,IAJwE,CAAC,EAGf,CAAX,GAAxB,EACV,CACd,CAAC,CACF,GAA2B,IAAI,EAA3B,EAA6B,CAC/B,IAAI,EAAkB,EAClB,KAAK,CAAC,EAFW,GACF,EACF,CAAC,GADuB,EAEvC,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAEtB,AAFuB,CACW,CADT,CAEA,CADnB,EAAgC,AAE9C,AAFgC,CACK,AACpC,CADqC,AAGzCC,GAAsB,EAAU,CAAC,KAAH,GAAT,EAHc,OAGe,CAAC,CAAE,EACtD,CAED,OAAO,CACT,EMjjH+D,EN6iHS,CAAC,AM5iH3D,EN+iHG,AM/iHS,IAAImI,EAD4C,CAAC,AACpD,AAEf,OADA,MAAM,CAAC,GADyC,EAAE,CACrC,CAAC,EAAW,GAClB,CACT,AAF+B,CAAC,AAE/B,CAAC,AACH,CAH0B,AAIzB,KAHkB,CAEb,AACC,AAAI,KAAK,CAAC,iDAAiD,CAAC,CA0CtE,MAAM,cAAc,CAClB,CAAsC,CAAA,SNwoFxC,EMpoFE,IAAI,EAAe,CNooFD,CMpoFV,AAAa,CNqoFvB,AMpoFM,EAAsC,CAAA,CAAE,CAC5C,GAAI,ENmoFoC,CMpoFzB,CNooFyB,AMnoFhC,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,ONuoF7B,EASA,EAKA,EA9HA,GAgHS,GAnFT,AA4FU,EAvFV,AA4FU,EAjFV,IAhBQ,IA7BU,IMthFd,IAAI,CACR,ENujFqB,AMxjFVC,CNmkFS,CMlkFhB,CAAC,SAAS,CNmoFd,EAAoC,CAAA,CAAE,CAGxC,AAAa,GAHH,CAGO,EAAE,GADLrI,AACL,KMvoF+C,ANsoFR,CAAC,OAAO,CAArB,AAAsB,CAAC,AAAtB,GAEtCC,GACE,EACA,CAAC,CAJ6C,IAGtC,CACD,CAAE,CAFU,MAEH,CAAC,CACjBmB,GAAS,EAAW,CAAZ,GAKM,AAAd,GALkB,CAKA,CALW,CAKT,AALU,CAC/B,EAGgBpB,CACL,IADuC,CAAC,QAAd,AAAsB,CAArB,AAAsB,CAAC,GAE9D,AAgCY,MAlCqC,GAmCnD,AADc,CACwB,CACtC,CAAqC,EAAA,AAIrC,IAAM,EAAaA,GAAsB,EAAY,CAAC,EAAtC,AAtCc,KAsCqB,CAAX,AAAsB,CAAC,CAAC,AAC3C,CAPqB,QAOZ,CAA1B,GAA4C,IAAI,EAAlB,AAAoB,GAAtC,AACdC,GAAsB,EAAc,CAAC,CADK,OACrB,CAAa,KAAiB,CAAE,QAAQ,CAAC,CAAE,GAGlE,IAAM,EAAkBD,CAHoD,CAAC,CAG/B,EAAY,CAAC,OAAtC,AAAmC,CAAX,KAA2B,CAAC,CAAC,AACrD,SAAS,CAA1B,GAAiD,IAAI,EAAvB,AAAyB,GAA3C,AACdC,GACE,EACA,CAAC,MAH4C,EAC1B,CACP,KACG,CAAE,aAAa,CAAE,OAAO,CAAC,CACxC,GAAc,IAIlB,IAAM,EAJW,AAISD,GAAsB,EAJf,AAI2B,CAJ1B,AAKhC,CAJC,MAGuD,CAAX,CAAxB,MACN,CAChB,CAAC,CACF,QAAqB,IAAjB,GAAmD,EAAzB,EAA6B,EAAzB,EAA2B,CAA7C,AACd,IAAI,EAAkB,EAClB,KAAK,CAFwC,AAEvC,KADS,EACF,CAAC,CADqB,IAErC,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,CACW,CADT,EACnB,CArMb,CAqM+B,AAAc,OArMrC,KAA4B,CAAA,CAAE,CAGxC,AAAoB,IAAI,EAAE,CADxB,EAAmBA,GAoMS,EApMyB,CAAC,CACxC,AAmMkB,CAAC,MApMjB,AAAwB,CAAC,KAA2B,CAAC,CAAC,GAAnB,AAEvDC,GAAsB,EAAU,CAAC,KAAH,EAAU,CAAnB,AAAoB,CAAE,GAAc,IAGpD,GAgMF,CAAC,CAEJA,CArMwD,EAG3C,AAmMX,EACA,CAAC,CAvMsE,CAAC,CAAC,KAqMtD,CACP,KACG,CAAE,eAAe,CAAC,CACjC,EAEH,CAGH,EAtEiC,EAAY,GAIvC,AAAc,IAAI,CA6DH,AAjEsB,AAAU,CAI3B,AA8DrB,AAlEiD,GAGjCD,CACL,EMnpFR,ENkpF+C,CAAC,GMlpF1C,CACP,INipFmC,AAAsB,CAArB,AAAsB,CAAC,MA9HrCA,GA8HwB,EA9HU,CAC3D,QAD8C,CAAC,OAC/B,CACjB,CAAC,CAFyD,AAGvD,KAAiB,OAAmC,AAAxC,EAAc,EAA8B,EAA1B,AAA4B,GAC5DC,KAEE,CAAC,QAFkB,CAD6B,AAEhD,GACa,CAAE,QADH,KACgB,CAAC,CAC7B,GAIE,EAAgBD,GAqHS,EArHyB,CAAC,KAAtC,EAqHsB,AAzHnB,CACnB,AAGwC,CAAC,EAAwB,CAAC,CAAC,CAClE,KADkD,AACjC,OAAL,AAAmC,EAArB,EAAyB,EAArB,AAAuB,GACvDC,KAEE,CAAC,IAH0C,IACxB,CACnB,GACa,CAAE,QADH,IACe,CAAE,WAAW,CAAC,CACzC,GAIE,EAAmBD,KAAkC,CAAC,EAJ3C,CACd,KAGmB,AAAwB,CAAC,KAA2B,CAAC,CAAC,CACxE,EADqD,GACpC,OAAiC,AAAtC,EAAc,EAA4B,EAAxB,AAA0B,GAC1DC,KAEE,CAAC,OAH6C,CAC3B,CACnB,GACa,CAAE,QADH,IACe,CAAC,CAC5B,KAIaD,KAAkC,CAAC,KAJhC,CACjB,AAGuD,CAAC,CAAC,AAAtB,CAClC,AADmC,KAClB,KAD4B,EACH,AAA9B,EAAc,EAAoB,EAAhB,AAAkB,GAClDC,KAAoC,AADI,CACH,QAAhB,CAAC,GAA2B,CAAE,MAAM,CAAC,CAAxB,AAA0B,KAGhCD,GAHwC,CAAC,CAGP,CAC9D,QADiD,CAAC,UAAU,AACzC,CACpB,CAAC,CACE,KAAiB,OAAL,AAA2C,EAA7B,EAAiC,EAA7B,AAA+B,GAC/DC,KAEE,CAAC,QAFkB,CACnB,GACa,AAHsC,CAGpC,QADH,OACkB,CAAC,CAC/B,KAIyBD,KAAkC,CAC7D,QADgD,CAAC,CAJ1B,CACtB,OAIiB,CADyC,AAE5D,CAAC,CACE,KAAiB,OAAL,AAA0C,EAA5B,EAAgC,EAA5B,AAA8B,GAC9DC,KAEE,CAAC,QAFkB,CACnB,EAFkD,CAGrC,CAAE,QADH,UACqB,CAAC,CAClC,GAIE,EAAmBD,KAAkC,CAAC,QAAtC,AAAwB,CAJtB,AAIuB,CAH5C,IAGuE,CAAC,CAAC,CACxE,EADqD,GACpC,OAAL,AAAsC,EAAxB,EAA4B,EAAxB,AAA0B,GAC1DC,KAEE,CAAC,OAH6C,CAC3B,CACnB,GACa,CAAE,QADH,MACiB,CAAC,CAC9B,GAIE,EAAqBD,KAAkC,CAC3D,KALkB,CACjB,EAG6C,CAAC,CAAzB,MACN,CACjB,CAAC,CAFyD,AAGvD,KAAiB,IA4DsB,GA5Da,AAAxC,EAAc,EAA8B,CA4DT,CAAC,AA5DlB,AAA4B,GAC5DC,KAEE,CAAC,QAFkB,CAD6B,AAEhD,GACa,CAAE,QADH,OACkB,CAAE,UAAU,CAAC,CAC3C,GAIE,EAA+BD,KAAkC,CACrE,OALoB,CACnB,AAGuD,CAAC,UAAU,CAAnC,MACN,CAC3B,CAAC,CACE,KAAiB,OAAL,AAAkD,EAApC,EAAwC,EAAE,AAAtC,GAChCC,KAEE,CAAC,QAFkB,CACnB,GACa,CAAE,MAH2C,EAE9C,OACkB,CAAE,oBAAoB,CAAC,CACrD,GAIE,EAAoBD,KAAkC,CAC1D,QAD6C,CAAxB,AAAyB,MAC/B,CAChB,CAN+B,AAM9B,CALC,AAMC,CAHsD,IAGrC,OAAkC,AAAvC,EAAc,EAA6B,EAAzB,AAA2B,GAC3DC,KAEE,CAAC,QAH8C,AAC5B,CACnB,GACa,CAAE,QADH,OACkB,CAAC,CAC/B,GAIE,EAAaD,KAAkC,CAAC,EAAtC,IAJK,CAClB,CAGqC,AAAsB,CAArB,AAAsB,CAAC,CAC5D,KAAiB,GAD8B,IACH,AAAhC,EAAc,EAAsB,EAAlB,AAAoB,GACpDC,KAAoC,CAAC,CADK,OACrB,AAAwB,CAAvB,AAAwB,CAAE,IA+B3C,GMhoFH,GNimFwD,CAAxB,AAAyB,CA+B9C,EMrpFX,EAAOuC,EAAH,CACF,MADqB,WACJ,CACjB,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAaJ,CAfa,GAEL,CAAC,GAaD,MAbC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,MAAM,CAClB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAO,AAAN,EAAM,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,CAIL,EAHO,EADE,AAIL,CAAE,AAAD,IACnB,IAAM,EAAO8F,ANkoFf,CMnoFiC,CACrB,IADyB,GNmoF3B,AACd,CAAwC,EAAA,AAExC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAsBtI,CAFd,EAEoC,EAAY,CAC5D,GMxoF4D,INuoFF,CAAX,GAAxB,CALqB,CAM/B,CACd,CAAC,CACF,GAA2B,IAAI,EAA3B,EAA6B,CAC/B,IAAI,EAAkB,EAClB,KAAK,CAAC,EAFW,GACF,EACF,CAAC,GADuB,EAEvC,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,AAEvB,CADkC,CADT,CAEA,CADnB,EAEd,AAFgC,AAAc,CAE7C,AADoC,CAAC,AAGzCC,GAAsB,EAAU,CAAC,KAAH,GAAT,EAHc,OAGe,CAAC,CAAE,EACtD,CAED,OAAO,CACT,EMrpFiE,ENipFO,CAAC,AMhpF3D,ENmpFG,AMnpFS,IAAIsI,EAD8C,CAGpE,AAHqE,AACtD,OACf,MAAM,CAAC,KAD2C,CACrC,CADuC,AACtC,EAAW,GAClB,CADsB,AAE/B,CAFgC,AAE/B,CAAC,AACH,CAH0B,AAIzB,KAHkB,CAEb,AACC,AAAI,KAAK,CAAC,iDAAiD,CAAC,CAwBtE,MAAM,YAAY,CAChB,CAAoC,CAAA,eAIpC,IAAI,EAAe,EAAX,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,GAAI,GADW,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,KNozF7B,MAiIA,EAjIQ,IA6ER,GAoDS,CAtCT,EA3EA,GA6DS,GAlCT,EA3BQ,AA2EE,AAvCV,EAWA,EMl3FI,GN23FV,CM33Fc,CACR,EADWC,CNk3FD,CMj3FN,CN61FY,AM71FX,EN03FS,EACpB,KM33FoB,CN63Fd,AAvBwB,EAuBY,CAAA,CAFF,AAEI,CAGxC,AAAa,CALuB,EAE1B,CAGO,EAAE,GADLxI,AACL,GMj4F6C,ENg4FN,CAAC,OAAO,CAArB,AAAsB,CAArB,AAAsB,GAE5DC,GACE,EACA,CAAC,CAJ6C,IAGtC,CACD,CAAE,CAFU,MAEH,CAAC,CACjBmB,GAAS,EAAW,CAAZ,GAKM,AAAd,GALkB,CAKA,CALW,CAKT,AALU,CAI5B,AAHH,EAGgBpB,CACL,IADuC,CAAC,EAAtC,MAA8C,AAAtB,CAAC,AAAsB,CAAC,IAiChE,EA/B6B,EAgC7B,CAlCmD,CAEV,EAoCnC,EAL8B,AAKjBA,EApCoB,CAoCE,CApCQ,CAAC,AAoCG,CAJhB,AAIiB,EAJjB,AAIrB,KAAmC,CAAX,AAAsB,CAAC,CAAC,MAC3C,IAAjB,GAA4C,EAAlB,EAAsB,EAAlB,AAAoB,GAAtC,AACdC,GAAsB,EAAc,CAAC,CADK,OACrB,CAAa,KAAiB,CAAE,QAAQ,CAAC,CAAE,KAGhDD,GAAsB,EAHoC,AAGxB,CAHyB,AAGxB,OAAH,AAAU,CAArB,AAAsB,CAAC,MACzC,IAAjB,GAA2C,EAAjB,EAAqB,EAAjB,AAAmB,GAArC,AACdC,GACE,EACA,CAHuC,AAGtC,QAFkB,CACP,KACG,CAAE,OAAO,CAAC,CACzB,GAAc,IAIZ,EAAoBD,GAAsB,AAJrB,CAAC,AAAX,CACd,AAGyD,CAC1D,OADwD,CAAX,CAAxB,MACN,CAChB,CAAC,MACmB,IAAjB,GAAmD,EAAzB,EAA6B,EAAzB,AAA2B,GAA7C,AACdC,GACE,EACA,CAAC,QAH8C,AAC5B,CACP,KACG,CAAE,UAAU,CAAC,EAC5B,EAjJsC,CAAA,CAAE,CAGxC,AAAa,IAAI,EAAE,CADjB,EAAYD,AACL,GA8Ia,EA/I0B,CAAC,CAAtC,AA+IU,MA/ImC,CAAC,AAAtB,CAAuB,AAAtB,GAEtCC,EA6IyC,CA7InB,AA6IoB,CACzC,CA9I+B,CAAC,CAFe,IAElB,EAAU,CAAnB,AAAoB,CAAE,GAAc,IAGpD,KAqFH,AAAc,AAxFkD,CAAV,AAAW,CAAC,CAGvD,CAqFO,EAAE,GADLD,CACL,EM74FR,EN44F+C,CAAC,GM54F1C,CACP,IN24FmC,AAAsB,CAArB,AAAsB,CAAC,MA3E/CA,GA2EkC,EA3EA,CAAC,MAAM,CAAC,CAArB,AAAsB,CAArB,AACnC,KAAiB,IA4EoB,CA7EQ,EACjC,AAA8B,EAAhB,EAAoB,CA4ED,CAAC,AA5EhB,AAAkB,GAClDC,KADwC,AACJ,CAAC,QAAhB,CAAC,GAA2B,CAAE,MAAM,CAAC,CAAxB,AAA0B,GAGxD,EAAqBD,GAH2C,CAAC,CAGV,CAC3D,QAD8C,CAAC,CAAzB,MACN,CACjB,CAAC,CAFyD,AAGvD,KAAiB,OAAL,AAAwC,EAA1B,EAA8B,EAA1B,AAA4B,GAC5DC,KAEE,CAAC,QAFkB,CAD6B,AAEhD,GACa,CAAE,QADH,QACmB,CAAC,CAChC,GAIE,EAA0BD,KAAkC,CAChE,OALoB,CAI+B,AAHlD,CAGmD,MAAzB,IAAmC,EACzC,CACtB,CAAC,CACE,KAAiB,OAAwC,AAA7C,EAAc,EAAmC,EAAE,AAAjC,GAChCC,KAEE,CAAC,QAFkB,CACnB,GACa,CAAE,CAHsC,OAEzC,aACwB,CAAC,CACrC,KAIqBD,GAkDI,EAlD8B,CAAC,OAkDrB,CAlDO,CAAC,GAJpB,CACxB,CAGuE,CAAC,CAAC,CACxE,EADqD,GACpC,OAAiC,AAAtC,EAAc,EAA4B,EAAE,AAA1B,GAChCC,KAEE,CAAC,OAH6C,CAC3B,CACnB,GACa,CAAE,QADH,MACiB,CAAC,CAC9B,KAI6BD,KAAkC,CACjE,KALkB,CACjB,EAGmD,CAAC,UAAU,GACzC,CACvB,CAAC,CACE,KAAiB,OAAL,AAA8C,EAAhC,EAAoC,EAAE,AAAlC,GAChCC,KAEE,CAAC,QAFkB,CACnB,GACa,CAAE,EAHuC,MAE1C,cACyB,CAAC,CACtC,KAIeD,KAAkC,CAAC,QAAQ,AAAtB,CAAC,AAAsB,CAAC,CAC5D,EALwB,CACzB,EAIkB,GAD8B,IACH,AAAhC,EAAc,EAAsB,EAAlB,AAAoB,GACpDC,KAAoC,CAAC,CADK,OACrB,AAAwB,CAAvB,AAAwB,CAAE,IA+B3C,GM13FH,GN21FwD,CAAxB,AAAyB,CA+B9C,EM/4FX,EAAOuC,EAAH,CACF,MADqB,WACJ,CACjB,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAaJ,CAfa,GAEL,CAAC,GAaD,MAbC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,MAAM,CAClB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,CAIL,EAHO,EADE,AAIL,CAAC,AAAC,IACpB,IAAM,EAAOiG,AN43Ff,CM73FiC,CACrB,IADyB,GN63F3B,AACd,CAAsC,EAAA,AAEtC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAqBzI,CAFb,EAEmC,EAAY,CAAC,CMj4FF,MNi4FD,CAAX,EALJ,AAKpB,GAAmD,CAAC,CAAC,CAC7E,GAA0B,IAAI,EAA1B,EAA4B,CAC9B,IAAI,EAAkB,EAClB,KAAK,CAAC,CAFU,IACD,EACF,CAAC,EADsB,GAEtC,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAEtB,AAFuB,CACW,AAnvC3C,CAkvCkC,EACnB,EAAkB,AAAc,IAlvCnD,AADc,CACsB,EAAA,AAEpC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAWA,CAFH,EAEyB,CA+uCE,CA/uCU,CAArC,AAAsC,OAAH,AAAU,CALjB,AAKJ,AAAsB,CAC5C,AAD6C,IACzC,EAAE,CAAlB,GACFC,GAAsB,EADZ,AACsB,CAAC,KAAH,CAAS,CAAC,CAAnB,AAAqB,GAAgB,IAG5D,IAAM,AAH8D,CAAC,CAAC,AAGnDD,EAHwC,CAGlB,EAAY,CAAC,EAAtC,KAAmC,CAAW,AAAtB,CAAuB,CAAC,CAChE,GAAkB,IAAI,EAAlB,EAAoB,CACtB,IAAI,EAAkB,CADV,CAER,KAAK,CAAC,EADsB,GAAb,EACF,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAEtB,AAFuB,CACW,CAE1C,AAHiC,CAGhC,CADW,AAGfC,AAJiB,EAAgC,AAAd,CAIb,EAAU,CAAC,KAAH,GAAW,AAApB,CAAqB,CAAE,EAC7C,CAED,OAAO,EACT,EA8tC4C,CAluCmB,CAAC,CAmuCzD,CAhuCU,AAguCT,AADwC,CAG5CA,AAH6C,GAGvB,EAAU,CAAC,KAAH,GAAT,QAA4B,CAAC,CAAE,EACrD,CAED,OAAO,CACT,EM74F+D,ENy4FQ,CMx4FzD,ANw4F0D,EAGvD,AM34FS,IAAIyI,EAD4C,CAAC,AACpD,AAEf,OADA,MAAM,CAAC,GADyC,EAAE,CACrC,CAAC,EAAW,GAClB,CADsB,AAE/B,CAFgC,AAE/B,CAAC,AACH,CAH0B,AAIzB,KAHkB,CAEb,AACC,AAAI,KAAK,CAAC,iDAAiD,CAAC,CAYtE,MAAM,GAAG,CAAC,CAAgC,CAAA,aNo3D1C,QMj3DM,CNi3Dc,CMj3DC,CNk3DrB,CMl3DU,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,GNg3DkC,AMh3D9B,ENg3D8B,CMj3DnB,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,KNk3D7B,IMj3DI,IAAI,ANi3DA,CMh3DR,EADWC,EACP,CAAC,SAAS,GNg3DsB,CAAA,CAAE,CAGxC,AAAa,IAAI,EAAE,CADjB,CMn3DgD,CNm3DpC3I,AACL,GMl3DP,ENi3D8C,CAAC,CAAtC,EMj3DH,CACP,GNg3DuD,CAArB,AAAsB,CAAC,AAAtB,GAEtCC,GACE,EACA,CAAC,CAJ6C,IAGtC,CACD,CAAE,CAFU,KAEJ,CAAC,CAChBmB,GAAS,EAAW,CAAZ,GAIL,GAJe,AM/1DlB,EN+1D6B,CAAC,CAC/B,CAGY,EMx3DX,EAAOoB,EAAH,CACF,MADqB,EACb,CACR,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAaJ,CAfa,GAEL,CAAC,GAaD,MAbC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,KAAK,CACjB,WAAW,CAAE,MAAA,EAAA,CAAA,EAAO,IAAD,EAAO,AAAN,EAAM,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,CAIL,EAHO,EADE,AAIL,CAAC,AAAC,GACPoG,GAA2B,GAI3C,CAAM,CAL4B,KAAI,CACgB,ANu0DnD,CMv0DuC,AAAa,CAKhD,GN6zDV,CM7zDc,CAAwC,ENk0DvC,AMl0DEC,EAAyC,CAAC,EN6zDvC,EACpB,KM9zDoE,CNg0D9D,EAAoC,CAAA,CAAE,AAFR,CAKhC,AAAa,CALmB,EAEtB,CAGO,EAAE,CMn0D8B,ENm0DxC,AADK7I,GMl0DoD,ENk0DlB,CAAC,GMl0DuB,CAAC,GNk0DjB,CAArB,AAAsB,CAArB,AAAsB,GAE5DC,GACE,EACA,CAAC,CAJ6C,IAGtC,CACD,CAAE,CAFU,KAEJ,CAAC,CAChBmB,GAAS,EAAW,CAAZ,GAIL,GAJe,AMjzDlB,ENizD6B,CAAC,CAC/B,CAGY,EM10DX,EAAOoB,EAAH,CACF,MADqB,EACb,CACR,EAAK,EAAD,EAAmC,CACxC,CACD,AAFa,EAEC,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAaJ,CAfa,GAEL,CAAC,GAaD,MAbC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,KAAK,CACjB,WAAW,CAAE,MAAA,EAAA,CAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,CAIL,EAHO,EADE,AAIL,CAAE,AAAD,GACNsG,GAA0B,GAI1C,EALkC,AAQ7B,KARiC,CACG,AAAY,AAO1C,CAP2C,WAO/B,CACxB,CAAkC,CAAA,qBAI9B,EAAe,EAAX,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,GAAI,GADW,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,ONuhE7B,EA/CA,EAKA,MA0CU,AMthEN,GNihEV,CA1CkB,AMv+DJ,CACR,EN2+Da,AM5+DFC,EACP,CAAC,ENghES,EACpB,KMjhEoB,CNmhEd,EAAoC,CAAA,CAFJ,AAEM,CAGxC,AAAc,CALoB,EAExB,CAGQ,EAAE,GADL/I,CACL,AMvhE0C,EAElD,ENohE+C,CAAC,GMphE1C,CACP,INmhEyD,AAAtB,CAAuB,AAAtB,CAAuB,MA/C3CA,GA+C8B,EA/CI,CAAC,QAAd,CAAC,CAAuB,CAAC,CAAC,CAChE,KAAiB,CADgC,MACrC,AAAkC,EAApB,EAAwB,EAApB,AAAsB,GACtDC,KAAoC,CAAC,GADO,KACC,AAAxB,CAAC,AAAyB,UAAU,CAAC,CAAE,AAA1B,KAGdD,GA4CgB,EA5CkB,CAAC,CAHiB,CAAC,KA+C3B,CA5CL,CAAC,EAAwB,CAAC,CAAC,CAClE,KAAiB,AADiC,OACtC,AAAmC,EAArB,EAAyB,EAArB,AAAuB,GACvDC,KAAoC,CAAC,IADQ,IACxB,AAAwB,CAAvB,AAAyB,WAAW,CAAC,AAAzB,CAA2B,GAGzD,EAAaD,KAAkC,CAAC,EAHsB,AAG5D,CAH6D,KAGf,AAAtB,CAAuB,AAAtB,CAAuB,CAC5D,KAAiB,GAD8B,IACH,AAAhC,EAAc,EAAsB,EAAlB,AAAoB,GACpDC,KAAoC,CAAC,CADK,OACrB,AAAwB,CAAvB,AAAyB,QAAQ,CAAC,CAAE,EAAxB,CAG9B,EAAgBD,KAHgD,AAGd,CAHe,AAGd,KAAtC,GAAwB,CAAC,EAAwB,CAAC,CAAC,CAClE,AAAiB,KADiC,IACxB,AAiCoB,GAjCC,AAAnC,IAAuC,CAiCG,CAAC,AAjCzB,AAAuB,GACvDC,KAEE,CAAC,IAH0C,EAGpC,CAAE,CAFU,CACnB,UACqB,CAAC,CADV,AAEZ+F,GA6BuB,EA7BC,KAgCrB,AAhCS,CAAC,CA6BmB,CMz/DhC,KN49DqC,AAgC1B,CAhC2B,CACvC,AMx/DC,ANu/DsB,EMv/DfxD,EAAH,CACF,MADqB,QACP,CACd,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAmBJ,CArBa,GAEL,CAAC,GAmBD,MAnBC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IAAI,AADc,CACb,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,KAAK,CACjB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,AACU,GAAR,CAAY,CADV,AACW,AAAC,IAE/B,EAAS,MAFkC,AAEnC,KAFuC,IAEvB,CAAG,CACzB,OAAO,CAAE,EAAa,OAAO,CACR,CAHN,CAEM,IAMb,IAAI,CAAC,AAAC,EARyC,EAS7D,IAAM,EN+hER,AM/hEewG,CADkB,CACrB,IADyB,GNgiE3B,AACd,CAAoC,EAEpC,AAFoC,IAE9B,EAAoC,CAAA,CAAE,CAEtC,EAAsBhJ,CAFd,EAEoC,EMpiEQ,ANoiEI,CAC5D,OAD0D,CAAX,AALP,GAKjB,MACN,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAoBD,GAAsB,EAAY,CAC1D,IAJwE,CAAC,EAGjB,CAAX,CAAxB,MACN,CAChB,CAAC,AACuB,IAAI,EAAE,CAA3B,GACFC,GAAsB,EAAU,CAAC,KAAH,GADX,AACE,OAA2B,CAAC,CAAE,GAGrD,IAAM,EAAaD,GAAsB,EAAY,CAAC,EAAtC,AAHsD,CAAC,IAGpB,AAAU,CAArB,AAAsB,CAAC,CAC/D,GAAkB,IAAI,EAAlB,EAAoB,CACtB,IAAI,EAAkBiG,CADV,EAC2B,GACnC,KAAK,CAAC,CADuC,AAA9B,CAAmB,AAAY,KACjC,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,AAEvB,CADkC,CADT,CAET,CADV,EAAgC,AAAd,AAEhC,CAD4B,AAC3B,CAD4B,AAGhChG,GAAsB,EAAU,CAAC,CAHP,IAGI,GAAT,AAAoB,CAAC,CAAE,EAC7C,CAED,OAAO,CACT,EM9jE6D,EN0jEE,CAAC,AMzjElD,EN4jEG,AM5jES,IAAIgJ,EAD0C,CAGhE,AAHiE,AAClD,OACf,MAAM,CAAC,CADuC,EAAE,GACnC,CAAC,EAAW,GAClB,CADsB,AAE/B,CAFgC,AAE/B,CAAC,AACH,CAH0B,AAGpB,KNi+DH,AMn+DgB,ENq+DhB,MAFQ,IMh+DJ,ANk+DM,GALhB,CM79Dc,CACR,EADWC,EACP,CAAC,EN49DS,EACpB,KM79DoB,GN+9DsB,CAAA,CAFJ,AAEM,CAGxC,AAAc,CALoB,GAKhB,EAAE,GMn+D+B,ANk+DpClJ,CACL,EMj+DR,ENg+D+C,CAAC,GMh+D1C,CACP,IN+9DyD,AAAtB,CAAC,AAAsB,CAAC,IAnE1D,EAAeA,GAmE8B,EAnEI,CAAC,IAAtC,IAAwB,CAAC,CAAuB,CAAC,CAAC,CAChE,AAAiB,MADgC,GAqEJ,AApEnB,GAAd,AAAkC,IAAI,CAoEG,CAAC,AApExB,AAAsB,GACtDC,KAAoC,CAAC,GADO,KACvB,AAAwB,CAAvB,AAAyB,UAAU,CAAC,CAAxB,AAA0B,GAGxD,EAAgBD,KAAkC,CAAC,CAHiB,CAAC,GAGxD,GAAwB,CAAC,EAAwB,CAAC,CAAC,CAClE,KADkD,AACjC,OAAL,AAAmC,EAArB,EAAyB,EAArB,AAAuB,GACvDC,KAAoC,CAAC,IADQ,IACxB,AAAwB,CAAvB,AAAyB,WAAW,CAAxB,AAAyB,CAAE,GAGzD,EAAaD,GA2DkB,EA3DgB,CAAC,EAHsB,AAG5D,CAH6D,IA8D9B,CA3DP,AAAsB,CAAC,AAAtB,CAAuB,CAC5D,KAAiB,GAD8B,IACnC,AAAgC,EAAlB,EAAsB,EAAlB,AAAoB,GACpDC,KAAoC,CAAC,CADK,OACrB,AAAwB,CAAE,AAAzB,QAAiC,CAAC,CAAE,EAAxB,CAG9B,EAAgBD,KAHgD,AAGd,CAAC,AAHc,KAGpD,GAAwB,CAAC,EAAwB,CAAC,CAAC,CAClE,KADkD,AACjC,OAAL,AAAmC,EAArB,EAAyB,EAArB,AAAuB,GACvDC,KAEE,CAAC,IAH0C,EAGpC,CAAE,CAFU,CACnB,UACqB,CAAC,CACtB+F,AAFY,GAmDU,EAjDE,KAAZ,AAoDT,CApDU,CAiDkB,CMr8D/B,KNo5DqC,AAoD1B,CApD2B,CACvC,AADuB,AM/6DtB,EAAOxD,EAAH,CACF,MADqB,QACP,CACd,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAmBJ,CArBa,GAEL,CAAC,GAmBD,MAnBC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,KAAK,CACjB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,AACU,GAAR,CAAY,CADV,AACW,AAAC,IACd,AACjB,EAAS,MAFkC,AAEnC,IADiD,CADV,IAEvB,CAAG,CACzB,OAAO,CAAE,EAAa,OAAO,CACR,EADA,IAMb,IAAI,CAAC,AAAC,IACpB,IAAM,ENw9DR,AMx9De2G,CADkB,CACrB,IADyB,GNy9D3B,AACd,CAAoC,EAEpC,AAFoC,IAE9B,EAAoC,CAAA,CAAE,CAEtC,EAAsBnJ,CAFd,EAEoC,CM79DO,CN69DK,CAC5D,OANuC,AAKmB,CAAX,GAAxB,MACN,CAClB,CAAC,AACE,AAAuB,IAAI,EAAE,IAC/BC,GAAsB,EAAU,CAAC,GADZ,EACS,GAAT,SAA6B,CAAC,CAAE,GAGvD,IAAM,EAAoBD,GAAsB,EAAY,CAC1D,IAJwE,CAAC,EAGjB,CAAX,CAAxB,MACN,CAChB,CAAC,AACuB,IAAI,EAAE,CAA3B,GACFC,GAAsB,EAAU,CAAC,KAAH,GADX,AACE,OAA2B,CAAC,CAAE,GAGrD,IAAM,EAAaD,GAAsB,EAAY,CAAC,EAHgB,AAGtD,CAHuD,IAGpB,AAAU,CAAC,AAAtB,CAAuB,CAC/D,GAAkB,IAAI,EAAlB,EAAoB,CACtB,IAAI,EAAkBiG,CADV,EAC2B,GACnC,KAAK,CAAC,CADS,AAA8B,CAAX,AAAY,KACjC,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,AAEvB,CADkC,CADT,CAEV,CADT,EAAkB,AAAc,AAE9C,CAD2B,AAC1B,CAEJhG,AAH+B,GAGT,EAAU,CAHP,AAGQ,KAAH,GAAT,AAAoB,CAAC,CAAE,EAC7C,CAED,OAAO,CACT,EMv/D4D,ENm/DG,CAAC,AMl/DlD,ENq/DG,AMr/DS,IAAIgJ,EADyC,CAAC,AACjD,AAEf,OADA,MAAM,CAAC,CADuC,EAAE,GACnC,CAAC,EAAW,GAClB,CADsB,AAE/B,CAFgC,AAE/B,CAAC,AACH,CAH0B,CAuB7B,IAtBsB,EAsBhB,MAAM,CAAC,CAAmC,CAAA,aN0iGhD,QMviGM,CNuiGc,CMviGC,CNwiGrB,CMxiGU,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,GNsiGqC,AMtiGjC,ENsiGiC,CMviGtB,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,ON0iG7B,IArDA,KAqDS,CMziGL,IAAI,CACR,EADWG,ENo/FI,AMn/FX,CAAC,SAAS,CNsiGd,EAAoC,CAAA,CAAE,CAGxC,AAAa,GAHH,CAGO,EAAE,GAAV,AADKpJ,EMziGuC,GNyiGL,CAAC,OAAO,CAAC,AAAtB,CAAuB,AAAtB,GAEtCC,GACE,EACA,CAAC,CAJ6C,IAGtC,CACD,CAAE,CAFU,MAEH,CAAC,CACjBmB,GAAS,EAAW,CAAZ,GAKR,AAAc,GALI,CAKA,CALW,CAAC,AAKV,CAJrB,AAGG,EAAapB,CACL,EMjjGR,ENgjG+C,CAAC,EAAtC,CMhjGJ,CACP,IN+iGmC,AAAsB,CAArB,AAAsB,CAAC,MA9DxCA,GA8D2B,AAEvB,EAhE8B,CAAC,OAgErB,CAhEO,CAAC,IAA0B,CAAC,CAAC,CACtE,GADoD,EACnC,OAAL,AAAqC,EAAvB,EAA2B,EAAvB,AAAyB,GACzDC,GA8DsC,EA9DF,CAAC,KA8DS,CAAC,AA/DA,EAC1B,CAAC,IAA4B,CAAC,CAAE,GAGjD,EAAkBD,CAHY,IAGsB,CAAC,IAHW,CAAC,EAGlD,CAAwB,CAAC,IAA0B,CAAC,CAAC,CACtE,GADoD,EACnC,OAAL,AAAqC,EAAvB,EAA2B,EAAvB,AAAyB,GACzDC,KAAoC,CAAC,MADU,EAC1B,CAAC,IAA4B,CAAC,CAAE,GAGjD,EAA0BD,CAHI,IAG8B,CAChE,IAJoE,CAAC,GAGlB,CAAC,MAAzB,IAAmC,EACzC,CACtB,CAAC,CACE,KAAiB,OAAwC,AAA7C,EAAc,EAAmC,EAA/B,AAAiC,GACjEC,KAEE,CAAC,QAFkB,CACnB,KAFqD,OAG/B,AADV,CACW,CACvB,IAkDG,GM9hGH,KN8hGW,EMnjGX,EAAOuC,EAAH,CACF,INggGqB,CACxB,CMlgGwB,GACZ,CACT,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAed,AAbI,CAFS,GAEL,CAAC,GAaD,MAbC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,OAAO,CACnB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,CAIL,EAHO,EADE,AAIL,CAAC,AAAC,GACPoG,GAA2B,GAI3C,CAAM,CAL4B,KAAI,CNy/FnC,AMx/FmD,CAAZ,AAAa,CNigGpD,IAhEA,GAuDS,CMn/FL,EN4/FM,CAdhB,CM9+Fc,CACR,EADWS,EACP,CAAC,CN27FU,CAkDD,EACpB,KM9+FoB,CNg/Fd,EAAoC,CAAA,CAAE,AAFL,CAKnC,AAAa,CALsB,EAEzB,CAGO,EAAE,GAAV,AADKrJ,CMn/FsC,INm/FJ,CAAC,OAAO,CAAC,AAAtB,CAAC,AAAsB,GAE5DC,GACE,EACA,CAAC,CAJ6C,IAGtC,CACD,CAAE,CAFU,KAEJ,CAAC,CAChBmB,GAAS,EAAW,CAAZ,GAKR,AAAc,GALI,CAKA,CALW,CAAC,AAKV,CAJrB,EAGgBpB,CACL,EM3/FR,EN0/F+C,CAAC,GM1/F1C,CACP,INy/FmC,AAAsB,CAArB,AAAsB,CAAC,IArE1D,EAAkBA,GAqE2B,AAExB,EAvE+B,CAAC,OAuEtB,AAvEhB,CAAwB,CAAC,IAA0B,CAAC,CAAC,CACtE,GADoD,EACnC,OAAL,AAAqC,EAAvB,EAA2B,EAAvB,AAAyB,GACzDC,KAAoC,CAAC,MADU,EAC1B,CAAC,IAA4B,CAAC,CAAE,KAG/BD,CAHY,IAGsB,CAAC,IAHW,CAAC,GAG1B,CAAC,IAA0B,CAAC,CAAC,CACtE,GADoD,EACnC,IAiEkB,GAjEvB,AAAqC,EAAvB,EAA2B,CAiEV,CAjEY,AAiEX,AAjEd,GAChCC,KAAoC,CAAC,MADU,EAC1B,CAAC,IAA4B,CAAC,CAAE,GAGjD,EAA0BD,CAHI,IAG8B,CAChE,IAJoE,CAAC,GAGlB,CAAC,MAAzB,IAAmC,EACzC,CACtB,CAAC,CACE,KAAiB,OAAwC,AAA7C,EAAc,EAAmC,EAA/B,AAAiC,GACjEC,KAEE,CAAC,QAFkB,CACnB,KAFqD,OAEzC,AACU,CAAC,CACvB,IAyDG,GMx+FH,KNw+FW,EM7/FX,EAAOuC,EAAH,CACF,INm8FqB,CACxB,CMr8FwB,EACb,CACR,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAaJ,CAfa,GAEL,CAAC,GAaD,MAbC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,OAAO,CACnB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,CAIL,EAHO,EADE,AAIL,CAAC,AAAC,GACPsG,GAA0B,GAI1C,EALkC,AAmBrC,KAnByC,CACG,AAAY,AAkBlD,CAlBmD,KAkB7C,CACV,CAAmC,CAAA,aNl+BrC,QMs+BM,CNt+Bc,CMs+BC,CNr+BrB,CMq+BU,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,GNv+BqC,AMu+BjC,ENv+BiC,CMs+BtB,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,SACzB,IAAI,CACR,EADWQ,EACP,CAAC,SAAS,CNv+Bd,EAAoC,CAAA,CAAE,CAGxC,AAAa,GAHH,CAGO,EAAE,CADjB,EAAYtJ,AACL,EMm+B4C,CAEnD,ENt+B8C,CAAC,CAAtC,EMs+BH,CACP,GNv+BuD,CAArB,AAAsB,CAArB,AAAsB,GAE5DC,GACE,EACA,CAAC,CAJ6C,IAGtC,CACD,CAAE,CAFU,KAEJ,CAAC,CAChBmB,GAAS,EAAW,CAAZ,GAIL,GAJe,AM8/BlB,EN9/B6B,CAAC,CAC/B,CAGY,EM+9BX,EAAOoB,EAAH,CACF,MADqB,EACb,CACR,EAAK,EAAD,EAAmC,CACxC,CACD,AAFa,EAEC,EAAK,EAAD,IAAoC,CACtD,AADW,CAAgB,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAmBJ,CArBa,GAEL,CAAC,GAmBD,MAnBC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,QAAQ,CACpB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAO,AAAN,EAAM,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,AACU,GAAR,CAAY,CADV,AACW,AAAC,IACd,AACjB,EAAS,MAFkC,AAEnC,IADkD,CADX,IAEvB,CAAG,CACzB,OAAO,CAAE,EAAa,OAAO,CACR,EADA,IAMb,IAAI,CAAC,AAAC,IACpB,OAD+B,CACzB,GNt+BN,CMq+BmC,AACzB,CNt+B0B,CAAA,CAAE,AMs+BzB+G,CNj+Bf,AAAuB,GALb,CAKiB,EAAE,CAH3B,EAAsBvJ,GMo+BgC,ENp+BE,CAC5D,IAEqB,IAH0B,AMo+BsB,CNp+BrB,AMo+BsB,ENp+B/C,EMo+BkC,INn+BxC,CAClB,CAAC,AAF0D,GAI1DC,GAAsB,EAAU,CAAC,KAAH,GAAT,SAA6B,CAAC,CAAE,GAGhD,GM89BK,EAAY,GN99BT,CM89BauJ,GAAP,AAEf,INn+BoE,CAAC,EMk+BrE,MAAM,CAAC,EADwC,EAAE,EACpC,CAAC,EAAW,GAClB,CADsB,AAE/B,CAFgC,AAE/B,CAAC,AACH,CAH0B,AAGpB,KAFa,IAGZ,GNjiCV,CMiiCc,CACR,EADWC,EACP,CAAC,ENliCS,EACpB,KMiiCoB,CN/hCd,EAAoC,CAAA,CAAE,AAFL,CAKnC,AAAa,CALsB,EAEzB,CAGO,EAAE,CADjB,EAAYzJ,AACL,CM2hC2C,EAElD,EN9hC8C,CAAC,CAAtC,EM8hCH,CACP,GN/hCuD,CAAC,AAAtB,CAAuB,AAAtB,GAEtCC,GACE,EACA,CAAC,CAJ6C,IAGtC,CACD,CAAE,CAFU,KAEJ,CAAC,CAChBmB,GAAS,EAAW,CAAZ,GAIL,GMkjCH,ANtjCkB,EAAW,CAAC,CAC/B,CAGY,EMuhCX,EAAOoB,EAAH,CACF,MADqB,EACb,CACR,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAmBJ,CArBa,GAEL,CAAC,GAmBD,MAnBC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,QAAQ,CACpB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,AACU,GAAR,CAAY,CADV,AACW,AAAC,IACd,AACjB,EAAS,MAFkC,AAEnC,IADkD,CADX,IAEvB,CAAG,CACzB,OAAO,CAAE,EAAa,OAAO,CACR,EADA,IAMb,IAAI,CAAC,AAAC,IACpB,OAD+B,CACzB,GN3hCN,CM2hCU,AADyB,CN1hCC,CAAA,CAAE,AM2hCzBkH,CNthCf,AAAuB,GALb,CAKiB,EAAE,CAH3B,EAAsB1J,GMyhC+B,ENzhCG,CAC5D,IAEqB,IAH0B,AMyhCqB,CNzhCpB,AMyhCqB,ENzhC9C,CMyhCiC,KNxhCvC,CAClB,CAF2D,AAE1D,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,SAA6B,CAAC,CAAE,GAGhD,GMmhCK,EAAY,GNnhCT,CMmhCauJ,GAAP,AAEf,INxhCoE,CAAC,EMuhCrE,MAAM,CAAC,EADwC,EAAE,EACpC,CAAC,EAAW,GAClB,CADsB,AAE/B,CAFgC,AAE/B,CAAC,AACH,CAH0B,CAsB7B,IArBsB,EAqBhB,WAAW,CACf,CAAmC,CAAA,iBAI/B,EAAe,EAAX,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,GAAI,GADW,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,CAC/B,IAAM,ENvrCI,AMurCGG,EAAH,ONvrCA,AACd,CAAoB,CACpB,CAAuC,EAAA,AAEvC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAY3J,CAFJ,EAE0B,CMirCiB,CNjrCL,CAAC,CAAtC,MAN4B,AAMO,AAAU,CAArB,AAAsB,CAAC,AAC7C,IAAI,EAAE,CAAnB,GACFC,GACE,EACA,CAHS,AAGR,KADO,CACD,CAAE,CAFU,MAEH,CAAC,CACjBmB,GAAS,EAAW,CAAZ,GAIZ,GAJsB,CAIhB,CAJ2B,CAAC,AAIbpB,CAHlB,EAGwC,EAAY,CAAC,IAAtC,GAAmC,CAAX,EAAwB,CAAC,CAAC,CACpE,GAAoB,IAAI,EAApB,EAAsB,CACxB,IAAI,EAAkBsC,GAAY,AADpB,GAEV,GAD6B,EACxB,CAAC,CADS,EAA2B,CAAC,GAC9B,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAEtB,AAFuB,CACW,CADT,AAGjC,CAAC,CAFa,AACF,AAGfrC,EAJmC,AAAc,CAI3B,EAAU,CAAC,KAAH,GAAT,EAAsB,CAAC,CAAE,EAC/C,CAED,IAAM,EAAaD,GAAsB,EAAY,CAHU,AAGT,CAHU,CAGhD,KAAmC,CAAX,AAAsB,CAAC,CAAC,CAKhE,OAJkB,IAAI,EAAE,AAApB,GACF,AAxGY,OAuGA,EAvGA,AACd,CAAmC,CACnC,CAAqC,EAAA,AAIrC,IAAM,EAAwBA,GAAsB,EAkGzB,AAlGqC,CAC9D,OAD4D,CAAX,AANZ,KAMZ,MACN,CACpB,CAAC,MACmB,IAAjB,GAAuD,EAA7B,EAAiC,EAA7B,AAA+B,GAAjD,AACdC,GACE,EACA,CAAC,QAFkB,CACP,GAFuC,OAG/B,CAAC,CACrB0B,GAAW,IAIf,CAJc,GAIR,EAAY3B,GAAsB,EAAY,CAAC,CAAtC,IAJqB,CAAC,CAClC,AAG+C,AAAU,CAArB,AAAsB,CAAC,CAC9D,QAAqB,IAAjB,GAA2C,EAAjB,EAAqB,EAAjB,EAAmB,CACnD,AADc,IACV,EAAkB,AADmB,EAErC,KAAK,CAAC,CADqB,IAAZ,EACF,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,AAEvB,CADkC,CADT,CAEZ,CADP,EAAkB,AAEhC,AAF8C,CACrB,AACxB,CADyB,AAG7BC,GAAsB,CAHC,CAGa,CAAC,OAAO,CAAvB,AAAwB,CAAE,AAAb,EACnC,CAED,IAAM,EAAuBD,GAAsB,EAAY,CAHC,AAI9D,CAJ+D,MAGJ,CAAX,IAAxB,MACN,CACnB,CAAC,MACmB,IAAjB,GAAsD,EAA5B,EAAgC,EAA5B,AAA8B,GAC9DC,AADc,GAEZ,EACA,CAAC,QAFkB,CACP,EAFsC,OAG/B,CAAC,CACpB,AAyiFA,SAAU,AACd,CAAkC,EAAA,AAElC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAA2BD,CA9iFL,AA4iFd,EAEyC,EAAY,CACjE,IANoC,GAK2B,CAAX,QAAxB,MACN,CACvB,CAAC,AACE,AAA4B,IAAI,EAAE,IACpCC,GAAsB,EAAU,CAAC,KAAH,GAAT,AADK,KACoB,CAAC,CAAE,GAGnD,IAAM,EAAqBD,GAAsB,EAAY,CAC3D,OADyD,CAAX,CAH2B,CAAC,AAGpD,MACN,CACjB,CAAC,AACwB,IAAI,EAAE,CAA5B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,CADD,OAC6B,CAAC,CAAE,GAGtD,IAAM,EAAqBD,GAAsB,EAAY,CAC3D,GAJsE,CAAC,GAGd,CAAX,EAAxB,MACN,CACjB,CAAC,AACwB,IAAI,EAAE,CAA5B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,CADD,OAC6B,CAAC,CAAE,GAGtD,IAAM,EAA4BD,GAAsB,EAAY,CAClE,GAJsE,CAAC,GAGP,CAAX,SAAxB,MACN,CACxB,CAAC,AAC+B,IAAI,EAAE,CAAnC,GACFC,GACE,EACA,CAAC,KADO,GADW,QADM,OAGD,CAAC,CACzB,GAIJ,IAAM,EAAuBD,GAAsB,EAAY,CAC7D,OAD2D,CAAX,EAJrB,CAC1B,CAGuB,MACN,CACnB,CAAC,AAC0B,IAAI,EAAE,CAA9B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,GADC,OAC6B,CAAC,CAAE,GAGxD,IAAM,EAAeD,GAAsB,EAAY,CAAC,IAAtC,CAH0D,CAAC,CAGxB,CAAX,EAAwB,CAAC,CAAC,AAChD,IAAI,EAAE,CAAtB,GACFC,GAAsB,EAAU,CAAC,GADnB,EACgB,GAAT,EAAsB,CAAC,CAAE,GAGhD,IAAM,EAAsBD,GAHgC,AAGV,CAHW,CAGC,CAC5D,OAD0D,CAAX,GAAxB,MACN,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAsBD,GAAsB,EAAY,CAC5D,IAJwE,CAAC,EAGf,CAAX,GAAxB,MACN,CAClB,CAC0B,AADzB,IAC6B,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAsBD,GAAsB,EAAY,CAC5D,IAJwE,CAAC,EAGf,CAAX,GAAxB,MACN,CAClB,CAAC,AACE,AAAuB,IAAI,EAAE,IAC/BC,GAAsB,EAAU,CAAC,GADZ,EACS,GAAT,SAA6B,CAAC,CAAE,GAGvD,IAAM,EAAyBD,GAAsB,EAAY,CAC/D,IAJwE,CAAC,EAGZ,CAAX,MAAxB,MACN,CACrB,CAC6B,AAD5B,IACgC,EAAE,CAAhC,GACFC,GACE,EACA,CAAC,KADO,GADW,KADG,OAGD,CAAC,CACtB,GAIJ,IAAM,EAAuBD,GAAsB,EAAY,CAC7D,OALwB,AAImC,CAH1D,AAG+C,IAAxB,MACN,CACnB,CAAC,AAC0B,IAAI,EAAE,CAA9B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,GADC,OAC6B,CAAC,CAAE,GAGxD,IAAM,EAAuBD,GAAsB,EAAY,CAC7D,KAJ0E,CAAC,CAGhB,CAAX,IAAxB,MACN,CACnB,CAC2B,AAD1B,IAC8B,EAAE,CAA9B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,GADC,OAC6B,CAAC,CAAE,GAGxD,IAAM,EAAyBD,GAAsB,EAAY,CAC/D,KAJ0E,CAAC,CAGd,CAAX,MAAxB,MACN,CACrB,CAAC,AACE,AAA0B,IAAI,EAAE,IAClCC,GACE,EACA,CAAC,KADO,CAFc,EACH,YAEE,CAAC,CACtB,GAIJ,IAAM,EAAqBD,GAAsB,EAAY,CAC3D,OADyD,AAJjC,CAIsB,AAH7C,EAGqB,MACN,CACjB,CAAC,AACwB,IAAI,EAAE,CAA5B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,CADD,OAC6B,CAAC,CAAE,GAGtD,IAAM,EAAoBD,GAAsB,EAAY,CAC1D,GAJsE,CAAC,GAGf,CAAX,CAAxB,MACN,CAChB,CACwB,AADvB,IAC2B,EAAE,CAA3B,GACFC,GAAsB,EAAU,CAAC,KAAH,GADX,AACE,OAA2B,CAAC,CAAE,GAGrD,IAAM,EAAWD,GAAsB,EAAY,CAAC,AAAtC,EAHwD,CAAC,GAGb,CAAT,AAAU,CAArB,AAAsB,AACxD,AAAY,IAAI,EAAE,EAAV,EACVC,GAAsB,EAAU,CAAC,KAAH,CAAS,CAAC,CAAnB,AAAqB,GAG5C,IAAM,CAH8C,CAAC,AAG5BD,GAAsB,EAAY,CAAC,OAAH,CAAnC,AAAwB,MAA4B,CAAC,CACnD,AADoD,IAChD,EAAE,CAA1B,GACFC,GACE,EACA,CAAC,KADO,EAFQ,CACG,MAEJ,CAAC,CAChB,GAAqB,IAIzB,IAAM,EAAoBD,GAAsB,EAAY,CAJnB,AAKvC,CALsB,AAAkB,CACvC,KAGuD,CAAX,CAAxB,MACN,CAChB,CAAC,AACuB,IAAI,EAAE,CAA3B,GACFC,GAAsB,EAAU,CAAC,KAAH,GADX,AACE,OAA2B,CAAC,CAAE,GAGrD,IAAM,EAAkBD,GAAsB,EAAY,CAAC,EAHW,CAAC,IAGf,AAAnC,CAAwB,KAA2B,CAAC,CAAC,AACnD,IAAI,EAAE,CAAzB,GACFC,GAAsB,EAAU,CAAC,KAAH,CADb,EACI,KAAyB,CAAC,CAAE,GAGnD,IAAM,EAAqBD,GAAsB,EAAY,CAHK,AAIhE,CAJiE,MAGR,CAAX,EAAxB,MACN,CACjB,CAAC,AACwB,IAAI,EAAE,CAA5B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,CADD,OAC6B,CAAC,CAAE,GAGtD,IAAM,EAAWD,GAAsB,EAAY,CAArC,AAAsC,GAHoB,CAAC,EAGf,CAAT,AAAU,CAArB,AAAsB,AAC5C,IAAI,EAAE,CAAlB,GACFC,GAAsB,EADZ,AACsB,CAAC,KAAH,CAAS,CAAC,CAAE,AAArB,GAGvB,IAAM,CAH8C,CAAC,AAGpCD,GAAsB,EAAY,CAAC,AAAtC,MAA4C,CAAC,AAAV,CAAW,AAAtB,CAKtC,GAJgB,IAAI,EAAE,AAAlB,GACFC,GAAsB,EAAU,AADtB,CACuB,KAAH,CAAS,CAAC,CAAnB,AAAqB,QAAQ,AAKlD,CALmD,GAInDD,GAAsB,EAAY,AACzB,CAD0B,CAEnC,MAFgC,CAAX,oBAA0C,CAAC,CAAC,CAGjE,MAAU,AAAJ,KAAS,CACb,qEAAqE,CACtE,CAGH,OAAO,CACT,EAttF+B,GAK/B,EAgE8B,AAgpFb,EAhpFyB,GAGjC,CACT,EMwpCQ,EN5pCgC,AAAU,CAAC,CM4pCvC,CNzpCK,AMypCJ,ENjuCsC,CAAC,CAC/C,KMguCiB,CACd,GA6BF,GA7BQ,CACP,GACD,EAAOwC,EAAH,CACF,MADqB,eACA,CACrB,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAmBJ,CArBa,GAEL,CAAC,GAmBD,MAnBC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,MAAM,CAClB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,AACU,GAAR,CAAY,CADV,AACW,AAAC,IAE/B,EAAS,MAFkC,AAEnC,KAFuC,IAEvB,CAAG,CACzB,OAAO,CAAE,EAAa,OAAO,CACR,CAHN,CAEM,IAMb,IAAI,CAAE,AAAD,EAR2C,QNxoC9D,CMgpC+B,CNzoC/B,EM0oCM,EAD6B,CNlpCnC,CMmpCU,CNnpC0B,CAAA,CAAE,AMmpCzBoH,CN9oCf,AAAuB,GALb,CAKiB,CAIV,CAJY,CAHR,EAAG5J,GMipCgC,ENjpCE,CAC5D,IAEqB,IAH0B,AMipCsB,CAAC,ANjpCtB,IMipCS,INhpCxC,CAClB,CAF2D,AAE1D,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,SAA6B,CAAC,CAAE,GAInD,AAAmB,IAAI,EAAE,GADLD,KAAkC,CAAC,AACxC,CAJuD,CAAC,MAG9B,CAAC,IAA0B,CAAC,CAAC,GAExEC,CAFsD,EAEhC,EAAU,CAAC,KAAH,GAAT,KAAyB,CAAC,CAAE,GAG5C,GMsoCK,EAAY,GNtoCT,CMsoCa4J,GNzoCsC,AMyoC7C,AAEf,CN3oC6D,MM0oC7D,MAAM,CAAC,EADwC,EAAE,EACpC,CAAC,EAAW,GAClB,CADsB,AAE/B,CAFgC,AAE/B,CAAC,AACH,CAH0B,AAGpB,CACL,IAHkB,AAGZ,EAAOC,AN/vCH,EM+vCA,ON/vCA,AACd,CAAoB,CACpB,CAAuC,EAAA,AAEvC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAY9J,CAFJ,EAE0B,AMyvCgB,ENzvCJ,CAAC,CAAtC,KAN2B,CAMkB,AAAV,CAAW,AAAtB,CAAuB,AAC7C,IAAI,EAAE,CAAnB,GACFC,GACE,EACA,CAHS,AAGR,KADO,CACD,CAAE,CAFU,MAEH,CAAC,CACjBmB,GAAS,EAAW,CAAZ,GAIZ,GAJsB,CAIhB,CAJ2B,CAAC,AAIbpB,CAHlB,EAGwC,EAAY,CAAC,IAAtC,GAAmC,CAAX,EAAwB,CAAC,CAAC,CACpE,GAAoB,IAAI,EAApB,EAAsB,CACxB,IAAI,EAAkBsC,GAAY,AADpB,GAEV,GAD6B,EACxB,CAAC,CADS,EAA2B,CAAC,GAC9B,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,AAEvBrB,CADkC,CADT,CAEV,CADT,EAAkB,AAAc,AAE9C,CAD2B,AAC1B,CAD2B,AAG/BhB,GAAsB,EAAU,CAAC,EAHR,GAGK,GAAT,EAAsB,CAAC,CAAE,EAC/C,CAED,IAAM,EAAaD,GAAsB,EAAY,CAHU,AAGT,CAHU,CAGhD,KAAmC,CAAX,AAAsB,CAAC,CAAC,CAKhE,OAJkB,IAAI,EAAlB,AAAoB,GA7FpB,AA8FF,OADY,EA7FA,AACd,CAAmC,EAAA,AAInC,QAAiE,IAA7DA,AAyFsB,GAzFA,EAAY,AAAoC,CAAnC,CAAqC,EALtC,IAKF,CAAX,WAAiC,CAAC,CAAC,CAC1D,MAAM,AAAI,KAAK,CACb,6DAA6D,CAC9D,CAGH,GAAIA,KAAiD,OAA3B,EAAD,AAAa,AAAwB,CAAvB,CAAyB,MAA5B,AAAU,CAAC,CAAC,CAC9C,MAAM,AAAI,KAAK,CAAC,iDAAiD,CAAC,CAGpE,QAAgE,IAA5DA,GAAsB,EAAY,AAAmC,CAAlC,CAAoC,MAAvC,CAAX,UAAgC,CAAC,CAAC,CACzD,MAAM,AAAI,KAAK,CACb,4DAA4D,CAC7D,AAIL,EAwE6B,GAGpB,CACT,EMguCQ,INpuC+B,AMouC3B,CNjuCK,AAHuB,AMouC3B,SAAS,CACd,GA6BF,GA7BQ,CACP,GACD,EAAOwC,EAAH,CACF,MADqB,eACA,CACrB,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CACtD,AADW,CAAgB,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAmBJ,CArBa,GAEL,CAAC,GAmBD,MAnBC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,MAAM,CAClB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAE,AAAD,GACG,EAAa,IAAI,EAAE,CADT,AACU,GAAR,CAAY,CADV,AACW,AAAC,IACd,AACjB,EAAS,MAFkC,AAEnC,IADkD,CADX,IAEvB,CAAG,CACzB,OAAO,CAAE,EAAa,OAAO,CACR,EADA,IAMb,IAAI,CAAC,AAAC,UNrtCpB,CMqtC+B,GNzsC/B,EMysCmC,AAC7B,GNxtCN,CMwtCU,CNxtC0B,CAAA,CAAE,AMwtCzBuH,CNntCf,AAAuB,GALb,CAKiB,CAHN,CAGQ,GAHL/J,GMstC+B,ENttCG,CAC5D,EAW+B,EATV,IAH0B,AMstCqB,CAAC,ANttCrB,GMstCQ,KNrtCvC,CAClB,CAF2D,AAE1D,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,SAA6B,CAAC,CAAE,GAInD,AAAmB,IAAI,EAAE,CADvB,EAAkBD,KAAkC,CACvC,AADwC,CAHe,CAAC,KAGtD,CAAwB,CAAC,IAA0B,CAAC,CAAC,GAExEC,CAFsD,EAEhC,EAAU,CAAC,KAAH,GAAT,KAAyB,CAAC,CAAE,GAMhB,AAA/B,IAAmC,EAAE,GAHLD,GAH8B,CAAC,CAGG,CACpE,QADuD,CAAC,GAG3B,OAHqC,MACzC,CAC1B,CAAC,GAEAC,GACE,EACA,CAAC,KADO,GADW,iBAEO,CAAC,CAC3B,GAIG,GMgsCK,EAAY,GNhsCT,CMgsCa4J,GAAP,AAEf,OADA,KNrsCyB,CAC5B,AMosCS,CAAC,EADwC,EAAE,EACpC,CAAC,EAAW,GAClB,CADsB,AAE/B,CAFgC,AAE/B,CAAC,AACH,CAH0B,CAwB7B,IAvBsB,EAuBhB,aAAa,CACjB,CAAqC,CAAA,SAIrC,IAAI,EAAe,EAAX,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,GAAI,GADW,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,CAC/B,IAAM,EAAOG,ANlhDH,EMkhDA,ONlhDA,AACd,CAAoB,CACpB,CAAyC,EAAA,AAEzC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAYhK,CAFJ,EAE0B,EAAY,CAAC,AM4gDM,CN5gD5C,MAAmC,AAAU,CAArB,AAAsB,CAAC,AAC7C,AAP4B,IAOxB,EAAE,CAAnB,GACFC,GACE,EACA,CAHS,AAGR,KADO,CACD,CAAE,CAFU,MAEH,CAAC,CACjBmB,GAAS,EAAW,CAAZ,GAIZ,GAJsB,CAIhB,CAJ2B,CAAC,AAIbpB,CAHlB,EAGwC,EAAY,CAAC,IAAtC,GAAmC,CAAX,EAAwB,CAAC,CAAC,CACpE,GAAoB,IAAI,EAApB,EAAsB,CACxB,IAAI,EAAkBsC,GADR,AACoB,GAC9B,GAD6B,EACxB,CAAC,CADS,EAA2B,CAAC,GAC9B,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAE,AAAD,EADP,CAAC,AAEvB,CADkC,CAE1C,AAHiC,CAGhC,CAFa,AACF,AAGfrC,EAJiD,AAAd,CAIb,EAAU,CAAC,KAAH,GAAT,EAAsB,CAAC,CAAE,EAC/C,CAED,OAAO,CACT,EMw/CQ,EN5/CyD,CAAC,CM4/CtD,CNz/CK,AMy/CJ,SAAS,CACd,GA6BF,GA7BQ,CACP,GACD,EAAOuC,EAAH,CACF,MADqB,iBACE,CACvB,EAAK,EAAD,EAAmC,CACxC,CACD,AAFa,EAEC,EAAK,EAAD,IAAoC,CACtD,AADW,CAAgB,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAmBJ,CArBa,GAEL,CAAC,GAmBD,MAnBC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,MAAM,CAClB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,AACU,GAAR,CAAY,CADV,AACW,AAAC,IAE/B,EAAS,MAFkC,AAEnC,KAFuC,IAEvB,CAAG,CACzB,OAAO,CAAE,EAAa,OAAO,CACR,CAHN,CAEM,IAMb,IAAI,CAAC,AAAC,EAR4C,EAShE,IAAM,EAAOyH,ANrhDf,CMohDiC,CACrB,IADyB,GNnhDzC,AADc,CACyB,EAAA,AAEvC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAsBjK,CAFd,EAEoC,EAAY,CAC5D,EM+gD2D,KNhhDD,CAAX,GALJ,AAKpB,MACN,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAiBD,GAAsB,EAAY,CAAC,IAHgB,CAAC,CAGvD,CAAmC,CAAX,IAA0B,CAAC,CAAC,CACxE,GAAsB,IAAI,EAAtB,EAAwB,CAC1B,IAAI,EAAkB,EAClB,GAFY,EAEP,CAAC,KADS,CAAiB,CACnB,CAAC,IAChB,GAAkB,EAAgB,GAAG,CAAE,AAAD,EADP,CAEtB,AAFuB,CACW,CADT,AAGjC,CAAC,AAFa,CACF,AAGfC,EAJmC,AAAc,CAI3B,EAAU,CAAC,KAAH,GAAT,IAAwB,CAAC,CAAE,EACjD,CAED,OAAO,CACT,EM6/CgE,ENjgDG,CAAC,AMkgDtD,EN//CG,AM+/CS,IAAIiK,EAD6C,CAAC,AACrD,AAEf,OADA,MAAM,CAAC,IAD0C,EAAE,AACtC,CAAC,EAAW,GAClB,CADsB,AAE/B,CAFgC,AAE/B,CAAC,AACH,CAH0B,AAIzB,KAHkB,CAEb,AACC,AAAI,KAAK,CAAC,iDAAiD,CAAC,CAO9D,MAAM,sBAAsB,CAClC,CAAsC,CAAA,eNi0BxC,SAAoB,EACpB,GM9zBM,EAAe,EAAX,AAAa,CACjB,EN6zBoC,AM7zBE,CAAA,CN6zBF,AM7zBI,CAC5C,GAAI,GADW,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,iBNi4B7B,MAuBA,EMv5BI,CNg4BK,EAnBf,CM72Bc,CACR,EADWC,CNu5BD,CMt5BN,CAAC,EN42BS,EACpB,KM72BoB,CN+2Bd,EAAoC,CAAA,CAFA,AAEE,CAGxC,AAAa,CALyB,EAE5B,CAGO,EAAE,CADjB,EAAYnK,AACL,KMn3B+C,ANk3BR,CAAC,CAAtC,MAA6C,CAAC,AAAtB,CAAuB,AAAtB,GAEtCC,GACE,EACA,CAAC,CAJ6C,IAGtC,CACD,CAAE,CAFU,MAEH,CAAC,CACjBmB,GAAS,EAAW,CAAZ,GAKR,AAAc,GALI,CAKA,CALW,CAAC,AAKV,CAJrB,AAGG,EAAapB,CACL,IADuC,CAAC,EAAtC,MAAwB,AAAsB,CAArB,AAAsB,CAAC,GAE9DC,GAAsB,EAAU,CAFiB,AAEhB,KAAH,GAAT,MAA0B,CAAE,QAAQ,CAAC,CAAE,GAI1D,AAAa,IAAI,EAAE,CAJiD,CAAC,CAGvDD,AACL,KADuC,CAAC,OAAO,CAAC,AAAtB,CAAuB,AAAtB,GAEtCC,GACE,EACA,CAAC,CAJ6C,IAGtC,GADW,MAEJ,CAAE,OAAO,CAAC,CACzB,GAAc,IAKd,AAAa,IAAI,CALM,CAAV,AAAW,AAKL,CAJpB,AAGG,EAAYD,AACL,GMx4BP,ENu4B8C,CAAC,CAAtC,EMv4BH,CACP,GNs4BuD,CAAC,AAAtB,CAAuB,AAAtB,GAEtCC,GACE,EACA,CAAC,CAJ6C,IAGtC,GADW,MAEJ,CAAE,OAAO,CAAC,CACzB,GAAc,IAKd,AAAc,IAAI,CALK,CAKH,AALP,AAAW,CACzB,AAGG,EAAaD,CACL,IADuC,CAAC,EAAtC,MAAwB,AAAsB,CAArB,AAAsB,CAAC,IAkIhE,EAhI+B,EAiI/B,CAnImD,CAER,EAqIrC,EAAaA,AALmB,EAhIG,CAqIA,CArIU,CAqIE,AArID,CAqIE,AAJjB,EAAA,AAIrB,KAAmC,CAAW,AAAtB,CAAuB,CAAC,MAC3C,IAAjB,GAA4C,EAAlB,EAAsB,EAAlB,AAAoB,GACpDC,AADc,GACQ,EAAc,CAAC,CADK,OACrB,CAAa,KAAiB,CAAE,QAAQ,CAAC,CAAE,GAG5D,EAAYD,GAAsB,EAHoC,AAGxB,CAHyB,AAGxB,CAAtC,MAAmC,AAAU,CAArB,AAAsB,CAAC,MACzC,IAAjB,GAA2C,EAAjB,EAAqB,EAAjB,AAAmB,GAArC,AACdC,GACE,EACA,CAHuC,AAGtC,QAFkB,CACP,KACG,CAAE,OAAO,CAAC,CACzB,GAAc,IAIZ,EAAYD,GAJS,AAIa,CAJvB,AAAW,CACzB,AAGiD,CAAC,CAAtC,MAAmC,AAAU,CAArB,AAAsB,CAAC,CAC1D,AAAiB,SAAS,GAAd,AAA+B,IAAI,EAAjB,AAAmB,GACnDC,GACE,EACA,CAHuC,AAGtC,QAFkB,CACP,KACG,CAAE,OAAO,CAAC,CACzB,GAAc,KApJd,AAAc,IAoJS,AApJL,CAoJM,AAAX,CACd,AArJqB,GADLD,CACL,IADuC,CAAC,QAAd,AAAsB,CAArB,AAAsB,CAAC,GAE9D,AApVY,MAkVqC,GAlVrC,AACd,CAAsC,CACtC,CAAqC,EAAA,IAm3ErC,EA/2EA,MAm3EM,EAJ+B,AAjiEP,EAiiEO,AA/2E/B,EAAqBA,GAm3EZ,AAn3EkC,EANP,AAMmB,CAC3D,OADyD,CAAX,EAAxB,MACN,CACjB,CAAC,MACmB,IAAjB,GAAoD,EAA1B,EAA8B,EAA1B,AAA4B,GAC5DC,AADc,GAEZ,EACA,CAAC,QAFkB,CAD6B,AAEpC,GACC,CAAE,aAAa,CAAC,CAC7B,GAIJ,IAAM,EAAmBD,GAAsB,EAAY,CAAC,GAJtC,CACnB,GAGsD,CAAX,AAAxB,MAAoD,CAAC,CAAC,AACxE,AAAiB,SAAS,GAAd,CAAsC,IAAI,EAAxB,AAA0B,GAC1DC,GACE,EACA,CAAC,OAH6C,CAC3B,CACP,GACC,CAAE,YAAY,CAAC,CAC5B,GAIJ,IAAM,EAAUD,GAAsB,EAAzB,AAAqC,CAAC,CAJ/B,CACjB,GAGqD,CAAC,CAAT,AAAU,CAArB,KAChB,IAAjB,GAAyC,EAAf,EAAmB,EAAE,AAAjB,GAChCC,AADc,GACQ,CADiB,CACH,CAAC,QAAhB,CAAa,GAAe,CAAE,KAAK,CAAC,CAAE,GAG7D,IAHoE,AAG9D,CAH+D,CAGzCD,GAAsB,EAAY,CAC5D,OAD0D,CAAX,GAAxB,MACN,CAClB,CAAC,MACmB,IAAjB,GAA8B,AAAuB,EAA3B,EAA+B,EAAE,GAC7DC,AADc,GAEZ,EACA,CAAC,IAHgD,IAC9B,CACP,GACC,CAAE,iBAAiB,CAAC,CACjC,GAIJ,IAAM,EAAWD,GAAsB,EAAY,CAAC,AAAtC,IAJS,CACpB,CAGuD,CAAC,AAAV,CAAW,AAAtB,MACjB,IAAjB,GAA0C,EAAhB,EAAoB,EAAhB,AAAkB,GAApC,AACdC,GAAsB,EADkB,AACJ,CAAC,QAAhB,CAAa,GAAe,CAAE,MAAM,CAAC,CAAE,GAG9D,IAAM,CAHgE,CAAC,AAG/CD,GAAsB,EAAY,CAAC,OAAtC,AAAmC,CAAX,KAA2B,CAAC,CACpD,AADqD,SAC5C,CAA1B,GAAiD,IAAI,EAAvB,AAAyB,GACzDC,AADc,GAEZ,EACA,CAAC,MAH4C,EAC1B,CACP,GACC,CAAE,aAAa,CAAC,CAC7B,GAIJ,IAAM,EAAiBD,GAAsB,EAAY,CAAC,AAJvC,CAChB,KAGiB,CAAmC,CAAX,IAA0B,CAAC,CACnE,AADoE,MACnD,MAAL,CAAkB,AAAkB,EAAtB,EAA0B,EAAE,GACxDC,GACE,EAF4C,AAG5C,CAAC,QAFkB,CACP,GACC,CAAE,YAAY,CAAC,CAC5B,GAIJ,IAAM,EAAuBD,GAAsB,EAJjC,AAI6C,CAH5D,AAID,OAD2D,CAAX,IAAxB,MACN,CACnB,CAAC,MACmB,IAAjB,GAAsD,EAA5B,EAAgC,EAA5B,AAA8B,GAC9DC,AADc,GAEZ,EACA,CAAC,QAFkB,CACP,EAFsC,CAGrC,CAAE,kBAAkB,CAAC,CAClC,GAIJ,IAAM,EAAkBD,GAAsB,EAAY,CAAC,KAJnC,CACrB,CAGkB,AAAmC,CAAX,KAA2B,CAAC,CAAC,MACrD,IAAjB,GAAiD,EAAvB,EAA2B,EAAvB,AAAyB,GAA3C,AACdC,GACE,EACA,CAAC,MAH4C,EAC1B,CACP,GACC,CAAE,aAAa,CAAC,CAC7B,GAIJ,IAAM,EAAqBD,GAAsB,EAAY,CAJ1C,AAKjB,CAJC,MAGwD,CAAX,EAAxB,MACN,CACjB,CAAC,MACmB,IAAjB,GAAoD,EAA1B,EAA8B,EAA1B,AAA4B,GAA9C,AACdC,GACE,EACA,CAAC,QAFkB,CAD6B,AAEpC,GACC,CAAE,gBAAgB,CAAC,CAChC,GAIJ,IAAM,EAAoBD,GAAsB,EAAY,CAC1D,GALoB,CACnB,GAGuD,CAAX,CAAxB,MACN,CAChB,CACoB,AADnB,SAC4B,CAA1B,GAAmD,IAAI,EAAzB,AAA2B,GAC3DC,AADc,GAEZ,EACA,CAAC,QAH8C,AAC5B,CACP,GACC,CAAE,eAAe,CAAC,CAC/B,GAIJ,IAAM,EAAoBD,GAAsB,EAAY,CAC1D,EALmB,CAClB,IAGuD,CAAX,CAAxB,MACN,CAChB,CAAC,MACmB,IAAjB,GAA8B,AAAqB,EAAzB,EAA6B,EAAE,GAA7C,AACdC,GACE,EACA,CAAC,EAH8C,MAC5B,CACP,GACC,CAAE,eAAe,CAAC,CAC/B,GAIJ,IAAM,EAAgBD,GAAsB,EAAY,CAAC,EAJpC,CAClB,EAGgB,EAAmC,CAAX,GAAyB,CAAC,CAAC,MACjD,IAAjB,GAA+C,EAArB,EAAyB,EAArB,AAAuB,GAAzC,AACdC,GACE,EACA,CAAC,IAH0C,IACxB,CACP,KACG,CAAE,WAAW,CAAC,CAC7B,GAAc,IAIlB,IAAM,EAJW,AAIWD,GAJG,AAImB,CAJlB,CAC7B,AAG2D,CAC5D,OAD0D,CAAX,GAAxB,MACN,CAClB,CAAC,CACF,GAAqB,SAAjB,AAA0B,GAAI,AAAuB,IAAI,IAAE,CAA/C,AACd,IAAI,EAAkB,EAClB,EAF+C,GAE1C,CAAC,KADS,EACF,CAAC,GADuB,EAEvC,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,CACW,CADT,EACnB,CAsxEnB,CAtxEqC,AAAc,OA0xE7C,EAJyC,AASzC,EATyC,KAIhC,EAFT,EAAoC,CAAA,CAAE,CAG3B,AAAb,GAImB,AAPT,CAGO,EAAE,GAAV,AADKA,KAzxEiC,EAyxEC,CAAC,CAzxEE,CAAC,IAyxEjB,CAAC,AAAoB,CAAC,CAAC,GAE5DC,GAAsB,EAF0B,AAEhB,CAAC,KAAH,EAAU,CAAnB,AAAoB,CAAE,GAAc,IAMvD,AAAqB,IAAI,CANuC,CAAV,AAAW,AAMtC,CANuC,EAG5CD,GAAsB,EAAY,CAC1D,EAEmB,KAHqC,CAAX,OAC9B,CAChB,CAAC,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,OAA2B,CAAC,CAAE,GAG9C,GApyEF,CAAC,CAEJA,GAkyEa,AAjyEX,EACA,CAAC,GA6xEiE,CAAC,IA/xEhD,CACP,KACG,CAAE,iBAAiB,CAAC,CACnC,EAEH,CAED,IAAM,EAAWD,GAAsB,EAAY,CAJhC,AAIL,AAAsC,CAHjD,KAGuD,CAAC,AAAV,CAAX,AAAsB,MACvC,IAAjB,GAA8B,AAAY,EAAhB,EAAoB,EAAE,EAAV,CAA1B,AACdC,GACE,EACA,CAAC,QAFkB,CACP,KACG,CAAE,MAAM,CAAC,EAmuEtB,AAluEF,EAkuEsC,CAAA,CAAE,CAGxC,AAAa,GAHH,CAGO,EAAE,GAAV,AADKD,KApuEc,EAouEoB,CAAC,KApuEtB,AAAS,CAAC,AAouEF,CAnuEpC,AAmuEqC,AAAoB,CAAC,CAAC,GAE5DC,GAAsB,EAF0B,AAEhB,CAAC,KAAH,EAAU,CAAC,AAApB,CAAsB,GAAc,IAIvD,AAAgB,IAAI,CAJ4C,CAAV,AAAW,AAI3C,CAJ4C,AAGhE,EAAeD,GAAsB,AAC3B,EADuC,CAAC,IAAtC,GAAmC,CAAX,EAAwB,CAAC,CAAC,GAElEC,GAAsB,EAAU,CAAC,KAAH,GAAT,EAAsB,CAAC,CAAE,GAGzC,IA1uEP,IA0uEe,AA1uET,CAuuEsD,CAAC,AAvuE9BD,GAAsB,EAAY,CAC/D,OAD6D,CAAX,MAAxB,MACN,CACrB,CAAC,AACE,MAAiB,MAAL,CAAkB,AAA0B,EAA9B,EAAkC,EAAE,GAChEC,GACE,EACA,CAAC,OAHmD,CACjC,CACP,GACC,CAAE,oBAAoB,CAAC,CACpC,EAKN,EA+KiC,EAAY,GAGpC,GMn4BH,ENg4BqC,AAAU,CAAC,EAGrC,EMx5BX,EAAOuC,CNiuBe,CACvB,AMluBK,CACF,MADqB,sBACO,CAC5B,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CACtD,AADW,CAAgB,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAaJ,CAfa,GAEL,CAAC,GAaD,MAbC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,MAAM,CAClB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,CAIL,EAHO,EADE,AAIL,CAAC,AAAC,UNgwBpB,CMhwB+B,KAAI,ENgwB3B,EM/vBF,GN6vBN,CM7vBU,CN6vB0B,CAAA,CAAE,AM7vBzB4H,CNgwBf,AAAY,GAHF,CAGM,EAAE,EAAV,CADKpK,KAAkC,CAAC,MAAM,CAAC,CAArB,AAAsB,CAArB,EAErCC,GAAsB,EAAU,CAAC,AMjwB4B,EN+vBd,GAEjB,CAAS,CAAC,CAAnB,AAAqB,GAIxC,AAAgB,IAAI,CAJ4B,CAAC,AAI3B,CADpB,EAAeD,GACL,AMrwBgD,ENowBT,CAAC,IAAtC,IAAwB,AMpwBiC,CNowBhC,AMpwBiC,CNowBV,CAAC,CAAC,GAElEC,GAAsB,CAF6B,CAEnB,CAAC,KAAH,GAAT,EAAsB,CAAC,CAAE,GAI5C,AAAY,IAAI,EAAE,CADhB,CACM,CADKD,AAH2C,CAAC,IAGV,CAArC,AAAsC,MAAM,CAAC,CAArB,AAAsB,CAArB,EAErCC,GAAsB,EAAU,CAAC,EAFc,GAEjB,CAAS,CAAC,CAAnB,AAAqB,GAIxC,AAAa,IAAI,CAJ+B,CAI7B,AAJ8B,CAG/C,EACO,AADKD,KAAkC,CAAC,CAAtC,MAA6C,CAArB,AAAsB,CAAC,AAAtB,GAEtCC,GAAsB,EAAU,CAAC,CAFe,IAElB,EAAU,CAAnB,AAAoB,CAAE,GAIzC,AAAgB,IAAI,EAAE,AAJ4B,CAAC,AAGjD,EAAeD,GACL,EADuC,CAAC,IAAtC,IAAwB,CAAC,CAAuB,CAAC,CAAC,GAElEC,GACE,CAHiD,CAIjD,CAAC,KADO,GADW,EAER,CAAC,CACZ,AAwJA,SAAU,AACd,CAAwC,EAAA,AAExC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAsBD,CAFd,EAEoC,EAAY,CAAC,GA7J3B,IA6JwB,CAAX,AAAsB,CAAC,CAAC,CAAhD,AACzB,CAN8C,EAM1C,AAAuB,IAAI,IAAE,CAC/B,IAAI,EAAkB,CAClB,GAFiB,EAEZ,EAAC,KADS,EACF,CAAC,GADuB,EAEvC,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,CACW,CADT,EACnB,CA88DnB,CA98DqC,AAAc,SA88D5B,EAIjB,AAJiB,EASjB,EAOA,GAZO,MAnwDP,EAAoC,CA+wDxB,AA/wDwB,AAwwDtB,CAxwDwB,CAG3B,AAAb,GAHU,CAGO,EAAE,CADjB,EACO,AADKA,GAhNoB,EAgNc,CAAC,CAhNX,AAgN3B,CAhN4B,KAgNiB,CAArB,AAAsB,CAAC,AAAtB,GAEtCC,GAAsB,EAAU,CAAC,CAFe,IAElB,EAAU,CAAnB,AAAoB,EAAE,AA6vDvC,EAAoC,CAAA,CAAE,CAGxC,AAAW,GAHD,CAGK,EAAE,CAAV,EADKD,CA/vD4C,IAAC,EA+vDX,CAAC,MA/vDmB,AA+vDjC,CA/vDkC,AA+vDjC,CA/vDkC,AA+vDb,CAAC,CAAC,GAE3DC,GAAsB,CAFwB,CAEd,CAAC,KAAK,AAAR,CAAS,CAAE,CAApB,EAMD,AAAlB,IAAsB,AANwB,CAAC,CAMvB,GAHLD,GAAsB,EAAY,AAGvC,CAFhB,OADqD,CAAX,YACtB,CACrB,CAAC,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,IAAwB,CAAC,CXphIzCS,CWohI2CF,EAAS,IAAD,AAItD,AAAgB,CXxhIU,CAAC,EWwhIP,EAAE,GADLR,CAHoD,CAAC,CAAC,AAGhC,AAC3B,EADuC,CAAC,CXvhIX,CAAC,KWuhIO,CAAX,EAAwB,CAAC,CAAC,GAElEC,GAAsB,EAAU,CAAC,KAAH,GAAT,EAAsB,CAAC,CAAE,GAGzC,IA7wDA,GApNF,CAi+DU,AAj+DT,CA89DsD,AA59D1DA,CA49D2D,EA1wD9C,AAlNS,EAAU,CAAC,KAAH,GAAT,SAA6B,CAAC,CAAE,EACtD,CAED,IAAM,EAA4BD,GAAsB,EAAY,CAClE,AAJoE,CAAC,MAGL,CAAX,SAAxB,MACN,CACxB,CAAC,AAC+B,IAAI,EAAE,CAAnC,GACFC,GACE,EACA,CAAC,KADO,GADW,QADM,OAGD,CAAC,CACzB,GAIJ,IAAM,EAA8BD,GAAsB,EAAY,CACpE,OADkE,CAAX,EAJ5B,CAC1B,QAG8B,MACN,CAC1B,CAAC,CASF,OARmC,IAAI,EAAnC,AAAqC,GACvCC,GACE,EACA,CAAC,KADO,GADW,UADQ,OAGD,CAAC,CAC3B,GAIG,CACT,EA/LuC,IAI9B,CA0LQ,EMr9BH,EAAY,GNuxByB,AAIlC,CAJmC,AMvxBtBoK,CNwxBzB,EMxxBkB,AAEf,KN+8ByB,CAC5B,CMj9BG,MAAM,CAAC,MAD4C,AACtC,CAAC,CADuC,CAC5B,GAClB,CADsB,AAE/B,CAFgC,AAE/B,CAAC,AACH,CAH0B,AAGpB,KAFa,QNkyBhB,EASA,OATS,CAqCT,EA5BU,AMxyBN,IAAI,CACR,EADWC,CNo0BD,CMn0BN,CAAC,SAAS,CN4xBd,EAAoC,CAAA,CAAE,CAGxC,AAAa,GAHH,CAGO,EAAE,GADLtK,AACL,GM9xBP,CAFqD,CN+xBP,CAAC,GM7xBzC,CACP,GN4xBuD,CAAC,AAAtB,CAAuB,AAAtB,GAEtCC,GACE,EACA,CAAC,CAJ6C,IAGtC,CACD,CAAE,CAFU,MAEH,CAAC,CACjBmB,GAAS,EAAW,CAAZ,GAKR,AAAc,GALI,CAKA,CALW,CAAC,AAKV,CAJrB,EAGgBpB,CACL,IADuC,CAAC,QAAd,AAAsB,CAArB,AAAsB,CAAC,GAE9DC,GAAsB,EAAU,CAAC,AAFgB,KAEnB,GAAT,MAA0B,CAAE,QAAQ,CAAC,CAAE,GAI1D,AAAa,IAAI,EAAE,CAJiD,AAGlE,CAHmE,CAGvDD,AACL,KADuC,CAAC,CAAtC,MAA6C,CAArB,AAAsB,CAAC,AAAtB,GAEtCC,GACE,EACA,CAAC,CAJ6C,IAGtC,GADW,MAEJ,CAAE,OAAO,CAAC,CACzB,GAAa,IAKb,AAAa,IAAI,CALL,AAAU,CAAC,AAKJ,CAJpB,AAGG,EAAYD,AACL,KADuC,CAAC,CAAtC,MAA6C,CAAC,AAAtB,CAAuB,AAAtB,GAEtCC,GACE,EACA,CAAC,CAJ6C,IAGtC,GADW,MAEJ,CAAE,OAAO,CAAC,CACzB,GAAa,IAKb,AAAc,IAAI,CALN,AAAU,CAKF,AALG,CACxB,AAGG,EAAaD,CACL,IADuC,CAAC,EAAtC,MAAwB,AAAsB,CAArB,AAAsB,CAAC,IAqJhE,EAnJ8B,EAoJ9B,CAtJmD,CAET,EAwJpC,EAAaA,AALmB,EAnJE,CAwJC,CAxJS,CAwJG,AAxJF,CAwJG,AAJjB,EAAA,AAIrB,KAAmC,CAAW,AAAtB,CAAuB,CAAC,MAC3C,IAAjB,GAA4C,EAAlB,EAAsB,EAAlB,AAAoB,GAAtC,AACdC,GAAsB,EAAc,CAAC,CADK,OACrB,CAAa,KAAiB,CAAE,QAAQ,CAAC,CAAE,GAG5D,EAAYD,GAAsB,EAAY,AAHwB,CAAC,AAGxB,CAAtC,MAA6C,AAAV,CAAW,AAAtB,CAAuB,MACzC,IAAjB,GAA2C,EAAjB,EAAqB,EAAjB,AAAmB,GAArC,AACdC,GACE,EACA,CAAC,AAHsC,QACpB,CACP,KACG,CAAE,OAAO,CAAC,CACzB,GAAa,IAIX,EAAYD,GAJF,AAAU,AAIc,CAJb,CACxB,AAGiD,CAAC,CAAtC,MAA6C,AAAV,CAAW,AAAtB,CAAuB,MACzC,IAAjB,GAA2C,EAAjB,EAAqB,EAAE,AAAnB,GAAlB,AACdC,GACE,EACA,CAAC,AAHsC,QACpB,CACP,KACG,CAAE,OAAO,CAAC,CACzB,GAAa,KAvKb,AAAc,IAuKF,AAAU,AAvKJ,CAuKK,CACxB,AAxKqB,GADLD,CACL,IADuC,CAAC,QAAd,AAAsB,CAArB,AAAsB,CAAC,GAzalD,AA2aZ,MAFiD,GAzarC,AACd,CAAsC,CACtC,CAAqC,EAAA,AAIrC,IAAM,EAAqBA,GAAsB,EAAY,CAC3D,CAoa2B,MAra8B,CAAX,EANP,AAMjB,MACN,CACjB,CAAC,CASF,QARqB,IAAjB,GAA8B,AAAsB,EAA1B,EAA8B,EAAE,GAC5DC,AADc,GAEZ,EACA,CAAC,GAH+C,KAC7B,CACP,GACC,CAAE,aAAa,CAAC,CAC7B,QAIwD,IAAxDD,GAAsB,EAAY,AAA+B,CAJ/C,AAIiB,CAHpC,AAGoE,MAAnC,CAAX,MAA4B,CAAC,CAAC,CACrD,MAAM,AAAI,KAAK,CAAC,wDAAwD,CAAC,CAG3E,QAAmD,IAA/CA,GAAsB,EAAY,AAAsB,CAArB,CAAuB,IAAlB,CAAC,CAAC,AAAV,CAAX,AACvB,MAAM,AAAI,KAAK,CAAC,+CAA+C,CAAC,CAGlE,IAAM,EAAsBA,GAAsB,EAAY,CAC5D,OAD0D,CAAX,GAAxB,MACN,CAClB,CAAC,CASF,QARqB,IAAjB,GAAqD,EAA3B,EAA+B,EAAE,AAA7B,GAAlB,AACdC,GACE,EACA,CAAC,QAFkB,CACP,CAFqC,EAGpC,CAAE,iBAAiB,CAAC,CACjC,QAIgD,IAAhDD,GAAsB,EAAmC,AAAvB,CAAC,CAJhB,AAIwC,CAH5D,IAG0C,CAAT,AAAU,CAAC,AAAtB,CACvB,MAAM,AAAI,KAAK,CAAC,gDAAgD,CAAC,CAGnE,IAAM,EAAkBA,GAAsB,EAAY,CAAC,OAAtC,AAAmC,CAAX,KAA2B,CAAC,CAAC,MACrD,IAAjB,GAAiD,EAAvB,EAA2B,EAAvB,AAAyB,GAA3C,AACdC,GACE,EACA,CAAC,MAH4C,EAC1B,CACP,GACC,CAAE,aAAa,CAAC,CAC7B,GAIJ,IAAM,EAAiBD,GAAsB,EAAY,CAAC,AAJvC,CAChB,KAGiB,CAAmC,CAAX,IAA0B,CAAC,CAAC,AACnD,SAAS,CAA1B,GAAgD,AAAlB,IAAsB,EAAE,GACxDC,AADc,GAEZ,EACA,AAH4C,CAG3C,QAFkB,CACP,GACC,CAAE,YAAY,CAAC,CAC5B,GAIJ,IAAM,EAAuBD,GAAsB,EAJjC,AAI6C,CAH5D,AAID,OAD2D,CAAX,IAAxB,MACN,CACnB,CAAC,CASF,QARqB,IAAjB,GAA8B,AAAwB,EAA5B,EAAgC,EAAE,GAAhD,AACdC,GACE,EACA,CAAC,KAHiD,GAC/B,CACP,GACC,CAAE,kBAAkB,CAAC,CAClC,QAIuD,IAAvDD,GAAsB,EAAY,AAA8B,CAA7B,CAA+B,CAJ9C,CACrB,IAGiC,CAAX,KAA2B,CAAC,CAAC,CACpD,MAAM,AAAI,KAAK,CAAC,uDAAuD,CAAC,CAG1E,IAAM,EAAqBA,GAAsB,EAAY,CAC3D,OADyD,CAAX,EAAxB,MACN,CACjB,CAAC,AACmB,SAAS,CAA1B,GAA8B,AAAsB,IAAI,EAAE,GAA9C,AACdC,GACE,EACA,CAAC,GAH+C,KAC7B,CACP,GACC,CAAE,gBAAgB,CAAC,CAChC,GAIJ,IAAM,EAAoBD,GAAsB,EAAY,CAC1D,GALoB,CACnB,GAGuD,CAAX,CAAxB,MACN,CAChB,CAAC,CASF,QARqB,IAAjB,GAA8B,AAAqB,EAAzB,EAA6B,EAAE,GAC3DC,AADc,GAEZ,EACA,CAAC,EAH8C,MAC5B,CACP,GACC,CAAE,eAAe,CAAC,CAC/B,QAIyD,IAAzDD,GAAsB,EAJL,AAIiB,AAAgC,CAHnE,AAGoC,CAAiC,MAApC,CAAX,OAA6B,CAAC,CAAC,CACtD,MAAM,AAAI,KAAK,CAAC,yDAAyD,CAAC,CAG5E,IAAM,EAAgBA,GAAsB,EAAY,CAAC,KAAtC,EAAmC,CAAX,GAAyB,CAAC,CAAC,AAClE,AAAiB,SAAS,GAAd,CAAmC,IAAI,EAAE,AAAvB,GAChCC,GACE,EACA,CAAC,IAH0C,IACxB,CACP,KACG,CAAE,WAAW,CAAC,CAC7B,GAAa,IAIjB,IAAM,CAJU,CAIYD,GAJE,AAIoB,CAJnB,CAC5B,AAG2D,CAC5D,OAD0D,CAAX,GAAxB,MACN,CAClB,CAAC,CACF,GAAqB,SAAjB,AAA0B,GAA2B,IAAI,EAA3B,EAA6B,CAA/C,AACd,IAAI,EAAkB,EAClB,KAAK,CAAC,EAFyC,GAChC,EACF,CAAC,GADuB,EAEvC,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,CACW,CADT,EACnB,EAAkB,AAAc,KAi6E7C,IAOA,IAPQ,OAA4B,CAAA,CAAE,CAG3B,AAAb,GAImB,CAJF,EAAE,CADjB,EAAYA,AACL,GALb,EA95EkD,EAk6EnC,AAAqC,CAAC,CAl6EC,CAAC,GA85ER,CAIR,CAJQ,AAIP,AAAoB,CAAC,CAAC,GAE5DC,GAAsB,EAAU,AAFgB,CAEf,KAAH,EAAU,CAAC,AAApB,CAAsB,GAAa,IAMtD,AAAqB,IAAI,CANsC,AAAV,CAM1B,AANqC,CAAC,EAG3CD,GAAsB,EAAY,CAC1D,EAEmB,KAHqC,CAAX,OAC9B,CAChB,CAAC,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,OAA2B,CAAC,CAAE,GAG9C,GA76EF,CAAC,CAEJA,GACE,AA06EW,EAz6EX,CAAC,GAs6EiE,CAAC,IAx6EhD,CACP,KACG,CAAE,iBAAiB,CAAC,CACnC,EAEH,CAED,QAAoD,IAJjC,AAIfD,CAHD,EAGuB,EAAY,AAAuB,CAAtB,CAAwB,KAAlB,CAAT,AAAU,CAArB,AAAsB,CAC7C,MAAM,AAAI,KAAK,CAAC,gDAAgD,CAAC,CAGnE,QAAkE,IAA9DA,GAAsB,EAAY,AAAqC,CAApC,CAAsC,MAAzC,CAAX,YAAkC,CAAC,CAAC,CAC3D,MAAM,AAAI,KAAK,CACb,8DAA8D,CAC/D,AAIL,EAmSgC,EAAY,GAGnC,GMhzBH,EN6yB8C,AAAV,CAAW,EAGpC,EMr0BX,EAAOwC,EAAH,CACF,MADqB,sBACO,CAC5B,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAed,AAbI,CAFS,GAEL,CAAC,GAaD,MAbC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,MAAM,CAClB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAE,AAAD,GACG,EAAa,IAAI,EAAE,CADT,CAIL,EAHO,EADE,AAIL,CAAC,AAAC,WAAW,KAAI,IAC7B,GNqrBN,CMrrBU,CNqrB0B,CAAA,CMrrBvB+H,ANqrByB,CAGxC,AAAY,GAHF,CAGM,EAAE,CADhB,CACM,CADKvK,KAAkC,CAAC,AAAtC,MAA4C,CAAC,CAAC,AAAtB,CAAC,EAErCC,GAAsB,EMzrBsC,ANyrB5B,CAAC,EAFc,GAEjB,CAAS,CAAC,CAAnB,AAAqB,GAIxC,AAAgB,IAAI,CAJ4B,CAI1B,AAJ2B,CAG/C,EAAeD,GACL,EADuC,CAAC,IAAtC,IAAwB,CAAC,CAAuB,CAAC,CAAC,GAElEC,GAAsB,CAF6B,CAEnB,CAAC,KAAH,GAAT,EAAsB,CAAC,CAAE,GAI5C,AAAY,IAAI,EAAE,CADhB,CACM,CAJgD,AAG3CD,CAH4C,EM9rBE,ENisBZ,CAAC,AAAtC,MAA4C,CAAC,CAArB,AAAsB,AMjsBc,CAAC,ANisBpC,EAErCC,GAAsB,EAAU,CAAC,EAFc,GAEjB,CAAS,CAAC,CAAE,AAArB,GAInB,AAAa,IAAI,CAJ+B,CAI7B,AAJ8B,CAG/C,EACO,AADKD,KAAkC,CAAC,CAAtC,MAA6C,CAArB,AAAsB,CAAC,AAAtB,GAEtCC,GAAsB,EAAU,CAAC,CAFe,IAElB,EAAU,CAAC,AAApB,CAAsB,GAOzC,AAAgB,IAAI,EAP8B,AAO5B,CAP6B,AAGjD,EAAeD,GAIL,EAJuC,CACrD,IADgB,IAAwB,CAAC,CAC/B,CACV,QAFmD,eAE5B,CACxB,CAAC,GAEAC,GACE,EACA,CAAC,KADO,GADW,EAER,CAAC,CACZ,AAkJA,SAAU,AACd,CAAwC,EAAA,AAExC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAsBD,CAFd,EAEoC,EAAY,CAC5D,EAxJiC,KAuJyB,CAAX,GALJ,AAKpB,OACL,CACnB,CAAC,CACF,GAA2B,IAAI,EAA3B,EAA6B,CAC/B,IAAI,EAAkB,EAClB,KAAK,CAAC,EAFW,GACF,EACF,CAAC,GADuB,EAEvC,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,CACW,CADT,EACnB,EAAkB,AAAc,eA8+D7C,SAnwDA,EAAoC,CAmwDxB,AAnwDwB,CAAE,CAGxC,AAAa,GAHH,CAGO,EAAE,CADjB,EAAYA,AACL,GA7OwB,EA4Oe,CAAC,CAAtC,AA5O0B,CAAC,KA4OkB,CAAC,AAAtB,CAAuB,AAAtB,GAEtCC,GAAsB,EAAU,CAAC,CAFe,IAElB,EAAU,CAAnB,AAAoB,EAmvDrC,AAnvDuC,EAmvDH,CAAA,CAAE,CAGxC,AAAW,GAHD,CAGK,EAAE,CAAV,AADL,EAAUD,AArvD2C,GAivD3D,EAjvD4D,AAqvD/C,EAAqC,CAAC,KAJ5B,AAIiC,CAAC,AArvDY,AAqvDhC,CAAqB,AAJnC,AAIe,AArvDgC,CAAC,EAuvDrEC,GAAsB,EAAU,CAAC,CAFa,IAEhB,AAAQ,CAAC,CAAE,CAApB,EAInB,AAAkB,IAAI,AAJwB,CAAC,CAIvB,CADtB,EAAiBD,GAAsB,EAAY,AACvC,CADwC,MAAtC,CAAmC,CAAX,MAA4B,CAAC,CAAC,GAExEC,GAAsB,EAAU,CAAC,KAAH,GAAT,IAAwB,CAAC,EAAEO,EAAS,IAIvD,AAAgB,AAJsC,IAIlC,EAAE,GADLR,CAHoD,CAAC,CAG/B,AAC3B,AAJ2D,EAGpB,CAAC,OAAH,CAAX,EAAwB,CAAC,CAAC,GAElEC,GAAsB,EAAU,CAAC,KAAH,GAAT,EAAsB,CAAC,CAAE,GAGzC,IAjwDA,GAhPF,CAAC,AAi/DS,CA/+DbA,AA4+D0D,CAAC,EA5+DrC,AA8OT,EA9OmB,CAAC,KAAH,GAAT,SAA6B,CAAC,CAAE,EACtD,CAED,IAAM,EAA4BD,GAAsB,EAAY,CAClE,AAJoE,CAAC,MAGL,CAAX,SAAxB,MACN,CACxB,CAAC,AAC+B,IAAI,EAAE,CAAnC,GACFC,GACE,EACA,CAAC,KADO,GADW,QADM,OAGD,CAAC,CACzB,GAIJ,IAAM,EAA8BD,GAAsB,EAAY,CACpE,OADkE,CAAX,EAJ5B,CAC1B,QAG8B,MACN,CAC1B,CAAC,CASF,OARmC,IAAI,EAAE,AAArC,GACFC,GACE,EACA,CAAC,KADO,GADW,UADQ,OAGD,CAAC,CAC3B,GAIG,CACT,EA3LsC,IAI7B,CAsLQ,EM54BH,EAAY,GNstBT,AAJiC,CMltBpBoK,ANktBqB,CAC9C,EMntBkB,AAEf,KNs4ByB,CAC5B,CMx4BG,MAAM,CAAC,MAD4C,AACtC,CAAC,CADuC,CAC5B,GAClB,CADsB,AAE/B,CAFgC,AAE/B,CAAC,AACH,CAH0B,CAK9B,CCrwDK,GDiwDkB,GCjwDX,UAAW,CAAQ,GAC9B,OADwC,CAAA,GACxC,CAA6B,CAAoB,CAAA,CAC/C,KAAK,EAAE,CADoB,IAAS,CAAA,SAAA,CAAT,EAU7B,MAAM,CAVgC,iBAUd,CACtB,CAGC,CAAA,CAED,IAAM,EAAY,EAAW,KAAd,GAAa,CAAU,CAChC,EAAS,EAAW,EAAd,IAAoB,CAEhC,CAFyB,EAErB,KAAmB,IAAV,EAAC,GAAkB,CAAd,EAAqC,EAAE,EAAE,CAAvB,EAAU,IAAI,CAChD,EAD2C,IACrC,AAAI,KAAK,CAAC,6BAA6B,CAAC,CAGhD,GAAI,IAAI,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,CAC/B,IACI,EADE,EAAe,EAAU,IAAI,CAAC,AACrB,EADe,CACmB,AAD/B,EAAuB,CAAC,MACgB,QADF,CAAC,CAAC,CAAC,CAAC,AAGxD,IAAU,EAAJ,WAAiB,GAAI,IAC7B,EAAc,AADqB,EAAE,AAChB,IAAD,GAAT,IAAqB,AAAX,EAGvB,IAAM,EAAe,MAAM,IAAT,AAAa,CAAC,mCAAmC,CAAC,CAClE,aAAa,CAAE,EAAU,IAAI,CAC7B,EADwB,UACZ,CAAE,EACd,MAAM,CAAE,CAAC,EADiB,SACN,CAAE,CAAW,CAAC,AACnC,CAAA,CAAC,CAEF,MAHmC,CAG5B,EAAU,OAAD,SAAiB,CAAC,CAChC,WAAW,CAAE,EACb,UADyB,AACf,EAAE,CACb,CAAA,CAAC,AACH,CAAM,AAFa,CAGlB,IAAM,EAAe,MAAM,IAAT,AAAa,CAAC,0BAA0B,CAAC,CACzD,aAAa,CAAE,EAAU,IAAI,CAC7B,EADwB,IAClB,CAAE,CACT,CAAA,CAAC,CACF,EAFgB,KAET,EAAU,OAAD,SAAiB,CAAC,CAChC,WAAW,CAAE,EACb,UAAU,AADe,EACb,CACb,CAAA,CAAC,AACH,EAFoB,AAWvB,MAAM,GAAG,CACP,CAA8C,CAAA,CAE9C,IAAM,EAAY,EAAW,KAAd,GAAa,CAAU,CAChC,EAAS,EAAW,EAAd,IAAoB,CAEhC,CAFyB,OAEF,IAAnB,EAAU,GAAkB,CAAd,EAAqC,CAA1C,CAA4C,EAAE,CAAvB,EAAU,IAAI,CAChD,EAD2C,IACrC,AAAI,KAAK,CAAC,6BAA6B,CAAC,CAGhD,GAAI,IAAI,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,CAC/B,IACI,EADE,EAAe,EAAU,IAAI,CAAC,AACrB,EADe,CACmB,AAD/B,EAAuB,CAAC,MACgB,QADF,CAAC,CAAC,CAAC,CAAC,CAGxD,GAAU,GAAJ,UAAiB,GAAI,IAC7B,EADmC,AACrB,EADuB,AAChB,IAAD,GAAT,IAAU,AAAW,EAGlC,IAAM,EAAe,MAAM,IAAI,AAAb,CAAc,mCAAmC,CAAC,CAClE,aAAa,CAAE,EAAU,IAAI,CAC7B,EADwB,UACZ,CAAE,EACd,MAAM,CAAE,CAAC,EADiB,SACN,CAAE,CAAW,CAAC,AACnC,CAAA,CAAC,CAEF,MAHmC,CAG5B,EAAU,OAAD,SAAiB,CAAC,CAChC,WAAW,CAAE,EACb,UADyB,AACf,CAAE,EACb,CAAA,CADiB,AAChB,AACH,CAAM,CACL,IAAM,EAAe,MAAM,IAAT,AAAa,CAAC,0BAA0B,CAAC,CACzD,aAAa,CAAE,EAAU,IAAI,CAC7B,EADwB,IAClB,CAAE,CACT,CAAA,CAAC,CACF,EAFgB,KAET,EAAU,OAAD,SAAiB,CAAC,CAChC,WAAW,CAAE,EACb,UADyB,AACf,EAAE,CACb,CAAA,CAAC,AACH,EAGK,AALe,MAKT,0BAA0B,CACtC,CAAoC,CAAA,iBAIhC,EAAe,EAAX,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,GAAI,GADW,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,CAC/B,QAAM,GpB2IJ,CoB3IQ,CpB2I4B,CAAA,CAAE,AoB3I3BG,CpBgJb,AAAqB,AjB0SP,OiB7SZ,EAAoBxK,GoB7IiC,EpB6IX,CAC9C,GoB9I+D,CAAC,KpB6IlB,KoB7IU,EpB+IzD,CAAC,MAGE,EACA,CAAC,GhBsagB,EgBvaT,CACD,CAAE,eAAe,CAAC,CACzB,GAIG,GoBlIH,OArBA,AAqBO,EArBAwC,EAAH,ApBmJa,CoBlJf,ApBmJH,GoB/HgB,GArBQ,WACJ,CACjB,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CACtD,AADW,CAAgB,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,CAFS,GAEL,CAAC,SAAA,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,KAAK,CACjB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAO,AAAN,EAAM,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,AAKtB,CAAM,CACL,CALuB,EADE,CpBsGvB,IoBhGI,IAAI,CpBgG4B,CAAA,CAAE,AR2oB7B,A4B3uBEiI,CpBqGb,AAAqB,MAAM,CAHzB,AhBibgB,EgBjbIzK,GoBlGgC,EpBkGE,CAC1D,GoBnG8D,CAAC,KpBkGjB,IoBlGS,GpBoGxD,CAAC,MAGE,EACA,CAAC,uBAAwB,CACzB,GAIG,GoBvFH,OAAO,AArBP,EAAOwC,EAAH,CACF,GAoBa,GArBQ,WACJ,CACjB,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CACtD,AADW,CAAgB,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,CAFS,GAEL,CAAC,SAAA,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IAAI,AADc,CACb,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,KAAK,CACjB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAO,AAAN,EAAM,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,AAKtB,EAGK,CAPmB,EADE,GAQf,mCAAmC,CAC/C,CAA6C,CAAA,SAI7C,IAAI,EAAe,EAAX,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,GAAI,GADW,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,WACzB,GpBjJJ,CoBiJQ,CpBjJ4B,CAAA,CoBiJzBkI,CpB5IjB,MAA+B,CAHzB,EAAoB1K,GoB+I0C,EpB/IR,EjB+V3B,CAAC,CqChNwC,CAAC,IpB/I5B,CAAC,OAE/C,CAAC,EAFwD,IAIlC,AoB2I2C,E5BohBlD,AQ/pBiB,CAAC,ChBgeZ,CQ+LK,cQ/pBuB,ChBgelB,GgB5djC,AAAwB,IAAI,ChB+dH,CgB/dK,CRiqBH,AQlqBrB,EAAmBA,KAAkC,CAAC,SAAb,MRgqBzB,AQhqBqD,CAAC,GAE1EC,GAAsB,EAAA,CAAW,CR8pBoB,KQ9pBd,CAAE,cAAc,CAAC,CAAE,GAGrD,GoByJH,OAAO,AArBP,EAAOuC,CpBvIiE,CAAC,AoBuIrE,CACF,GAoBa,GArBQ,gCACiB,CACtC,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CACtD,AADW,CAAgB,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,CAFS,GAEL,CAAC,SAAA,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,MAAM,CAClB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAO,AAAN,EAAM,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,AAKtB,CACC,EALuB,EADE,EAKpB,AACC,AAAI,KAAK,CAAC,iDAAiD,CAAC,CAGvE,CErCK,MAAO,MAAO,KAAQ,GAC1B,OADoC,CAAA,GACpC,CAA6B,CAAoB,CAAA,CAC/C,KAAK,EAAE,CADoB,IAAS,CAAA,SAAA,CAAT,EAuF7B,MAAM,CAvFgC,KAuF1B,CACV,CAAuC,CAAA,eAGvC,IAAI,EAAe,EAAX,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,GAAI,GADW,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAC7B,CAD+B,KACzB,AAAI,KAAK,CACb,gFAAgF,CAE7E,AADJ,UDwJC,IA/SA,MApCA,AAmVU,IA/SA,ECyJN,ED7LI,CA+Bd,CC8Jc,CACR,EADWmI,EACP,CAAC,ED/JS,EACpB,KC8JoB,CD5Jd,EAAoC,CAAA,CAAE,AAFD,CAKvC,AAAc,CALyB,EAE7B,CAGQ,EAAE,GADL3K,CACL,EC0JR,ED3J+C,ACyJO,CDzJN,GC2J1C,CACP,ID5JyD,AAAtB,CAAuB,AAAtB,CAAuB,GAE9DC,GACE,EACA,CAAC,AAJ8C,KAGvC,GADW,AAEV,CAAC,EACV,AAzDE,EAAiBD,KAAkC,CAAC,MAAtC,EAAwB,CAAC,GAAyB,CAAC,CAAC,CACpE,IADmD,CAyDvB,AAxDX,OAAL,AAAoC,EAAtB,EAA0B,EAAtB,AAAwB,GACxDC,KAAoC,CAAC,KADS,GACzB,CAAC,GAA2B,CAAC,CAAE,GAGhD,EAA2BD,EAHG,CAuDQ,EApDuB,CACjE,GAJkE,CAAC,GAuDf,CApDA,CAAC,OAAzB,GAAmC,GACzC,CACvB,CAAC,CACE,KAAiB,IAiDmC,GAjDtB,AAA4B,AAA9C,EAAc,EAAoC,CAiDF,CAAC,AAjDG,CAkDjE,EAjDDC,KAEE,CAAC,QAFkB,CADmC,AAEtD,YAAY,CACW,CAAC,CACxB,KAIaD,KAAkC,CAAC,MAAM,CAAC,CAArB,AAAsB,CAArB,AACnC,IALwB,CAKP,AAJlB,KAG8C,EACH,AAA9B,EAAc,EAAoB,EAAhB,AAAkB,GAClDC,KADwC,AACJ,CAAC,MAAM,CAAC,CAAvB,AAAyB,CAAxB,EAGlB,EAA6BD,GAHqB,CAAC,CAGY,CACnE,EAJkC,MAGoB,CAAC,SAAzB,CAAmC,KACzC,CACzB,CAAC,CACE,KAAiB,OAAL,AAAgD,EAAlC,EAAsC,EAAlC,AAAoC,GACpEC,KAEE,CAAC,QAFkB,CACnB,QAFwD,IAE5C,KACe,CAAC,EAC5B,AAyTJ,EA5RiC,EA+R3B,EAAoC,CAAA,CAAE,CAGxC,AAAa,AANG,EA5RsB,CA+R5B,CAGO,EAAE,CADjB,EAAYD,AACL,GALb,EA1T6C,EA8T9B,AAAqC,CAAC,GA9TpB,CAAC,CA0TM,CAID,CAAC,AAAoB,AAJpB,CAIqB,CAAC,GAE5DC,CAhUyC,EAiUvC,EACA,AAJ8C,CAI7C,KADO,AAjU2D,CAAC,CACrE,AAiUS,CAFW,AAET,OAAO,CAAC,CAClBmB,GAAS,EAAW,CAAZ,GAKR,AAAc,GALI,CAKA,CALW,CAKT,AALU,CAC/B,EAGgBpB,CACL,EAD2B,EAAY,CAAC,OAAH,CAAX,AAAsB,CAAC,CAAC,GAE9DC,GACE,EACA,CAAC,KADO,GADW,AAEV,CAAC,CACV,AAlOU,SAAA,AACd,CAAmC,CACnC,CAAqC,EAAA,AAIrC,IAAM,EAAuBD,GAAsB,CA4NvB,CA5NmC,CAC7D,OAD2D,AANvB,CAMY,IAAxB,MACN,CACnB,CAAC,MACmB,IAAjB,GAAsD,EAA5B,EAAgC,EAA5B,AAA8B,GAAhD,AACdC,GACE,EACA,CAAC,OAAO,CAFW,AAET,CADE,EAFsC,eAGtB,CAAC,CAC7B,GAIJ,IAAM,EAAyBD,GAAsB,EAAY,CAC/D,KALsB,CACrB,CAG4D,CAAX,MAAxB,MACN,CACrB,CAAC,MACmB,IAAjB,GAAwD,EAA9B,EAAkC,EAA9B,AAAgC,GAAlD,AACdC,GACE,EACA,CAAC,OAAO,CAFW,AAET,CADE,IAFwC,aAGxB,CAAE,oBAAoB,CAAC,CACnD,GAIJ,IAAM,EAAkBD,GAAsB,EAAY,CAAC,OAJjC,AAIL,AAAmC,CAHrD,AAG0C,KAA2B,CAAC,CAAC,MACrD,IAAjB,GAAiD,EAAvB,EAA2B,EAAvB,AAAyB,GAA3C,AACdC,GACE,EACA,CAAC,MAH4C,CAGrC,CAAE,AAFS,CACP,iBACgB,CAAE,aAAa,CAAC,CAC5C,GAIJ,IAAM,EAAWD,GAAsB,EAAY,CAJhC,AAIL,AAAsC,CAHjD,KAGuD,CAAT,AAAU,CAArB,AAAsB,MACvC,IAAjB,GAA8B,AAAY,EAAhB,EAAoB,EAAE,EAAV,CACxCC,AADc,GAEZ,EACA,CAAC,OAAO,CAFW,AAET,CADE,iBACgB,CAAE,MAAM,CAAC,CACrC,GAIJ,IAAM,CAJM,CACT,AAGcD,GAAsB,EAAY,CAArC,AAAsC,MAAM,CAAT,AAAU,CAAC,AAAtB,MACjB,IAAjB,GAA0C,EAAhB,EAAoB,EAAhB,AAAkB,GAApC,AACdC,GACE,EAFsC,AAGtC,CAAC,OAAO,CAFW,AAET,CADE,iBACgB,CAAE,MAAM,CAAC,CACrC,GAIJ,IAAM,CAJM,CAIgBD,AAHzB,GAG+C,EAAY,CAC5D,OAD0D,CAAX,GAAxB,MACN,CAClB,CAAC,MACmB,IAAjB,GAAqD,EAA3B,EAA+B,EAA3B,AAA6B,GAA/C,AACdC,GACE,EACA,CAAC,OAAO,CAAE,AAFS,CACP,CAFqC,gBAGrB,CAAE,iBAAiB,CAAC,CAChD,GAIJ,IAAM,EAAsBD,GAAsB,EAAY,CAC5D,IALqB,CACpB,EAGyD,CAAX,GAAxB,MACN,CAClB,CAAC,MACmB,IAAjB,GAAqD,EAA3B,EAA+B,EAAE,AAA7B,GAChCC,AADc,GAEZ,EACA,CAAC,OAAO,CAFW,AAET,CADE,CAFqC,gBAGrB,CAAE,iBAAiB,CAAC,CAChD,GAIJ,IAAM,EAAWD,GAAsB,EAAY,CAArC,AAAsC,IAJ7B,CACpB,CAGuD,CAAT,AAAU,CAArB,AAAsB,AACxD,MAAiB,MAAL,CAAkB,AAAY,EAAhB,EAAoB,EAAE,EAAV,CACxCC,GACE,EACA,CAAC,OAAO,CAFW,AAET,CADE,iBACgB,CAAE,MAAM,CAAC,CACrC,GAIJ,IAAM,CAJM,CACT,AAGsBD,GAAsB,EAAY,CAAC,OAAH,CAAnC,AAAwB,MAA4B,CAAC,CACtD,AADuD,SAC9C,CAA1B,GAAkD,IAAI,EAAE,AAA1B,GAChCC,AADc,GAEZ,EACA,CAAC,OAAO,AAHsC,CAC3B,AAET,CADE,iBACgB,CAAE,cAAc,CAAC,CAC7C0F,GAAoB,IAIxB,IAAM,EAAqB3F,GAAsB,CAJ1B,CAIsC,CAC3D,AALsC,CAAC,CACtC,KAGwD,CAAX,EAAxB,MACN,CACjB,CAAC,MACmB,IAAjB,GAAoD,EAA1B,EAA8B,EAA1B,AAA4B,GAC5DC,AADc,GAEZ,EACA,CAAC,OAAO,CAFW,AAET,CAHsC,AAEpC,iBACgB,CAAE,gBAAgB,CAAC,CAC/C,GAIJ,IAAM,EAA4BD,GAAsB,EAAY,CAClE,GALoB,CACnB,GAG+D,CAAX,SAAxB,MACN,CACxB,CAAC,MACmB,IAAjB,GAA2D,EAAjC,EAAqC,EAAjC,AAAmC,GAArD,AACdC,GACE,EACA,CAAC,OAAO,CAFW,AAET,CADE,OAF2C,UAG3B,CAAE,uBAAuB,CAAC,CACtD,GAIJ,IAAM,EAAwBD,GAAsB,EAAY,CAC9D,OAD4D,CAAX,EAJtB,CAC1B,EAGwB,MACN,CACpB,CACG,AADF,MACmB,MAAL,CAA2C,EAA7B,EAAiC,EAA7B,AAA+B,GAC/DC,GACE,EACA,CAAC,OAAO,CAFW,AAET,CADE,GAFuC,eAGtB,CAAC,CAhS9B,AAiSA,SAjSU,AACd,CAAyB,EAAA,AAEzB,EA8RkB,EA9RZ,EAAoC,CAAA,CAAE,CAEtC,EAAYD,AALU,CAGd,EAE0B,EAAY,CAAC,CAAtC,MAAmC,AAAU,CAArB,AAAsB,CAAC,CAC9D,GAAiB,IAAI,EAAjB,EAAmB,CACrB,IAAI,EADO,AACW,EAClB,KAAK,CAAC,CADqB,IAAZ,EACF,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAE,AAAD,EADP,CAAC,CACW,CADT,EACnB,EAAgC,AAAd,SA+Y/B,WAAW,GAqDX,WA9DA,EAAoC,CAAA,CAAE,CAKnB,AAArB,GALU,CA8DY,AAzDG,EAAE,CAHzB,EAAoBA,GAHA,EApYD,EAuYmC,CAC1D,AAEmB,CA1YQ,CAAC,GAoYkB,CAGD,CAHC,AAGzB,AAAyB,QAC/B,CAChB,CAFyD,AAExD,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,OAA2B,CAAC,CAAE,GAIjD,AAAe,IAAI,EAAE,GADLD,EACL,CAD2B,EAAY,AAHgB,CAGf,AAHgB,OAGnB,CAAX,CAAuB,CAAC,CAAC,GAEhEC,GAAsB,EAAU,CAAC,KAAH,GAAT,CAAqB,CAAC,CAAE,GAI3C,AAAkB,IAAI,EAAE,CADtB,CAHoD,CAAC,AAGpCD,GAAsB,EAC3B,AADuC,CAAC,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,GAEtEC,GACE,EACA,CAAC,KADO,GADW,IAEN,CAAC,CACd,AAtbA,SAAU,AAAY,CAAsB,CAsbjC,CAtbiC,AAChD,IAAM,EAAoC,CAAA,CAAE,AADnB,CAGzB,GAFc,KAE6C,IAAvDD,GAAsB,EAAY,AAA8B,CAA7B,CAA+B,MAAlC,CAAX,KAA2B,CAAC,CAAC,CACpD,MAAU,AAAJ,KAAS,CAAC,uDAAuD,CAAC,CAG1E,IAAM,EAAWA,GAAsB,EAAY,CAArC,AAAsC,MAAM,CAAT,AAAU,CAC3C,AADsB,AAAsB,IACxC,EAAE,CAAlB,GACFC,GAAsB,EADZ,AACsB,CAAC,KAAH,CAAS,CAAC,CAAnB,AAAqB,GAG5C,IAAM,CAH8C,CAG/BD,AAHgC,GAGV,EAAY,CAAC,IAAtC,GAAmC,CAAX,EAAwB,CAAC,CAAC,CAKpE,OAJoB,IAAI,EAApB,AAAsB,GACxBC,GAAsB,EAAU,CAAC,GADnB,EACgB,GAAT,EAAsB,CAAC,CAAE,GAGzC,CACT,EAoakB,IAKZ,AAAgB,CA1aL,CAH6C,CAAC,CA6arC,EAAE,CADpB,EAAeD,CAJS,CAAC,CAC5B,AAGwC,AAC3B,EADuC,CAAC,IAAtC,GAAmC,CAAX,EAAwB,CAAC,CAAC,GAElEC,GACE,EACA,CAAC,KADO,GADW,EAER,CAAC,CA/TZ,AAgUA,SAhUU,AACd,CAA0B,EAAA,AAE1B,GA6TmB,CA7Tb,EAAoC,CAAA,CAAE,CAE5C,GAL6B,AAGf,KAE6C,IAAvDD,GAAsB,EAA0C,AAA9B,CAAC,CAA+B,MAAlC,CAAX,KAA2B,CAAC,CAAC,CACpD,MAAM,AAAI,KAAK,CAAC,uDAAuD,CAAC,CAG1E,IAAM,EAAcA,GAAsB,EAAY,CAAC,GAAtC,IAAmC,CAAX,CAAuB,CAAC,CAAC,AAC/C,IAAI,EAAE,CAArB,GACFC,GAAsB,EAAU,CAAC,EADpB,GACiB,GAAT,CAAqB,CAAC,CAAE,GAG/C,IAAM,EAAeD,EAHqC,CAAC,AAGhB,EAAY,CAAC,IAAtC,GAAmC,CAAX,EAAwB,CAAC,CAAC,CAKpE,OAJI,AAAgB,IAAI,EAAE,GACxBC,GADc,AACQ,EAAU,CAAC,KAAH,GAAT,EAAsB,CAAC,CAAE,GAGzC,CACT,EA4SsB,IAOhB,AAAwB,CApTb,CAH6C,CAAC,CAuT7B,EAAE,CAH5B,CAJ0B,CAAC,AAIJD,CAH1B,EAGgD,EAAY,CAC7D,KAEsB,EAHqC,CAAX,IAAxB,MACN,CACnB,CAAC,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,UAA8B,CAAC,CAAE,GAIpD,AAAoB,IAAI,EAAE,CADxB,EAAmBD,GAAsB,EAAY,CAAC,CACxC,CAJwD,CAAC,IAGpB,CAAnC,AAAwB,MAA4B,CAAC,CAAC,GAE1EC,GAAsB,EAAU,CAAC,KAAH,GAAT,MAA0B,CAAC,CAAE,GAMhD,AAA2B,IAAI,EAAE,CAH/B,EAA0BD,GAAsB,CAHc,CAGF,AAHG,CAInE,OAD8D,CAGrC,AAH0B,OAAxB,MACN,CACtB,CAAC,GAEAC,GACE,EACA,CAAC,KADO,GADW,aAEG,CAAC,CACvB,GAOA,AAAsB,IAAI,EAAE,CAH1B,EAAqBD,GAAsB,EAAY,CAC3D,GAEoB,EAPK,CACxB,CAGwD,CAAX,EAAxB,MACN,CACjB,CAAC,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,QAA4B,CAAC,CAAE,GAMlD,AAAwB,IAAI,EAAE,GAHLD,GAAsB,EAAY,CAHS,AAItE,CAJuE,IAMjD,EAHqC,CAAX,UAC9B,CACnB,CAAC,GAEAC,GAAsB,EAAU,CAAC,KAAH,GAAT,UAA8B,CAAC,CAAE,GAIpD,AAAY,IAAI,EAAE,CADhB,CACM,CADKD,GAAsB,EAAY,CAArC,AAAsC,EAHwB,CAAC,GAGnB,CAAC,AAAV,CAAX,AAAsB,GAE1DC,GAAsB,EAAU,CAAC,KAAH,CAAS,CAAC,CAAnB,AAAqB,GAGrC,GA9cF,CAAC,CA2c8C,AAzclDA,CAycmD,EAGtC,AA5cS,EAAU,CAAC,KAAH,EAAU,CAAnB,AAAoB,CAAE,EAC5C,CAED,IAAM,EAAWD,GAAsB,EAAY,CAAC,AAAtC,AAH8C,CAAC,KAGH,CAAC,AAAV,CAAW,AAAtB,CAKtC,OAJgB,IAAI,EAAhB,AAAkB,GACpBC,GAAsB,EAAU,AADtB,CACuB,KAAH,CAAS,CAAC,CAAE,AAArB,GAGhB,CACT,EA2QqB0B,EA/QiC,CAAC,AA+QvB,EA5Qf,GA4Qc,AAI7B,IAAM,EAAY3B,GAAsB,EAAY,CAAC,CAAtC,GAJoC,CAAC,CAAC,CAIH,AAAU,AAHzD,CAG0D,AAAtB,CAAuB,CAC9D,QAAqB,IAAjB,GAA2C,EAAjB,EAAqB,EAAjB,EAAmB,CAArC,AACd,IAAI,EAAkB8B,AADmB,GACV,GAAD,AAC1B,KAAK,CAD+B,AAC9B,CAD+B,AAAtB,MACF,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAE,AAAD,EADP,CAqM/B,AAnMS,AAFuB,CACW,CADT,EACnB,EAAkB,AAAc,GAoMrC,CAAY,CAAsB,AAnMxB,EAmMwB,AAChD,IAAM,EAAoC,CADjB,AACiB,CAAE,CAEtC,EAA2B9B,CAFnB,EAEyC,EAAY,CACjE,OAD+D,CAAX,QAAxB,MACN,CACvB,CAAC,CACF,GAAgC,IAAI,EAAhC,EAAkC,CACpC,IAAI,EAAkB,EAClB,KAAK,CAAC,KADS,EADO,AAET,CAAC,KAChB,EAAkB,CAF0B,CAEV,GAAG,CAAC,AAAC,EADR,CAEtB,AAFuB,CACW,CADT,AAGjC,CAAC,CADW,AAGfC,AAJiB,EAAkB,AAAc,CAI3B,EAAU,CAAC,KAAH,GAAT,cAAkC,CAAC,CAAE,EAC3D,CAED,QAAyD,IAArDD,AAHuE,CAAC,EAGlD,EAAY,AAA4B,CAA3B,CAA6B,MAAhC,CAAX,GAAyB,CAAC,CAAC,CAClD,MAAM,AAAI,KAAK,CAAC,qDAAqD,CAAC,CAGxE,IAAM,EAAmBA,GAAsB,EAAY,CAAC,OAAH,CAAnC,AAAwB,MAA4B,CAAC,CAAC,AACpD,IAAI,EAAE,CAA1B,GACFC,GACE,EACA,CAAC,KADO,EAFQ,CACG,MAEJ,CAAC,CAChB,AApXA,SAAU,AACd,CAA8B,EAAA,AAE9B,IAAM,EAAoC,CAiXnB,AAjXmB,CAAE,CAEtC,EAAsBD,CAFd,EAEoC,EALjB,AAK6B,CAC5D,OAD0D,CAAX,GAAxB,MACN,CAClB,CAAC,CAKF,GAJ2B,IAAI,EAA3B,AAA6B,GAC/BC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,QAGO,IAA1DD,GAAsB,EAAY,AAAiC,CAAhC,CAAkC,AAHC,CAAC,KAGvC,CAAX,QAA8B,CAAC,CAAC,CACvD,MAAU,AAAJ,KAAS,CAAC,0DAA0D,CAAC,CAG7E,OAAO,CACT,EAmW0B,IAIxB,CAxWe,GAwWT,EAA4BA,GAAsB,EAAY,CAClE,AALsC,CAAC,CACtC,KAG+D,CAAX,SAAxB,MACN,CACxB,CAAC,CASF,GARI,AAA6B,IAAI,EAAE,GACrCC,GACE,EACA,CAAC,KADO,GADW,EADM,aAGD,CAAC,CACzB,QAK6D,IAA/DD,GAAsB,EAAkD,AAAtC,CAAC,CACnC,MADgC,AALL,CAC1B,AAIoB,aAAmC,CAAC,CAAC,CAE1D,MAAM,AAAI,KAAK,CACb,+DAA+D,CAChE,CAGH,IAAM,EAAiBA,GAAsB,EAAY,CAAC,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,AAClD,IAAI,EAAE,CAAxB,GACFC,GACE,EACA,CAAC,KAHa,AAEN,GADW,IAEN,CAAC,CACd,AAjaA,SAAU,AACd,CAA4B,EAAA,AAE5B,IAAM,CA8Ze,CA9ZqB,CAAA,CAAE,CAE5C,GAFc,AAEVD,EAL2B,GAK2B,OAAhC,EAAyC,AAA1C,AAAa,CAAC,CAA8B,MAAjC,KAAe,CAAC,CAAC,CACnD,MAAU,AAAJ,KAAS,CAAC,sDAAsD,CAAC,CAGzE,IAAM,EAAmBA,GAAsB,EAAY,CAAC,OAAH,CAAnC,AAAwB,MAA4B,CAAC,CAAC,CAK5E,OAJwB,IAAI,EAAE,AAA1B,GACFC,GAAsB,EAAU,CAAC,KAAH,EADZ,CACG,MAA0B,CAAC,CAAE,GAG7C,CACT,EAkZwB,IAItB,CAvZe,GAuZT,EAAiBD,AA1Z6C,CAAC,EA0ZxB,CAJT,CAIqB,AAJpB,CAClC,AAGuD,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,AAClD,IAAI,EAAE,CAAxB,GACFC,GAAsB,EAAU,CAAC,KADjB,AACc,GAAT,IAAwB,CAAC,CAAE,GAGlD,IAAM,EAAkBD,GAAsB,EAHkB,AAGN,CAHO,AAGN,OAAtC,AAAmC,CAAX,KAA2B,CAAC,CAClD,AAAnB,AADsE,IAC/C,EAAE,IAC3BC,GAAsB,EADL,AACe,CAAC,KAAH,GAAT,KAAyB,CAAC,CAAE,GAGnD,IAAM,EAAoBD,GAAsB,EAAY,CAHM,AAIhE,CAJiE,MAGT,CAAX,CAAxB,MACN,CAChB,CAAC,CAKF,OAJyB,IAAI,EAAzB,AAA2B,GAC7BC,GAAsB,EAAU,CAAC,KAAH,GADX,AACE,OAA2B,CAAC,CAAE,GAG9C,EACT,EA9Q2B+B,GAAQ,CA6QlB,CA7QiB,EAC3B,AADgC,CAC/B,AADgC,CAGpC/B,AAHqC,CA0Q+B,CAAC,CAvQ/C,EAAc,CAAC,OAAO,CAAvB,AAAyB,CAAZ,MAAmB,CAAC,CAAE,EACzD,CAED,IAAM,EAAwBD,GAAsB,EAAY,CAC9D,AAJuE,CAAC,MAGZ,CAAX,KAAxB,MACN,CACpB,CAAC,AACE,MAAiB,MAAL,CAAkB,AAAyB,EAA7B,EAAiC,EAAE,GAC/DC,GACE,EACA,CAAC,MAHkD,CAG3C,CAFW,AAET,CADE,kBACiB,CAAC,CAsK9B,AArKA,SAqKU,AACd,CAAyC,EAAA,AAEzC,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAaD,CAFL,EAE2B,EAAY,CAAC,CA1KpB,CA0KlB,KAAmC,CAAW,AAAtB,CAAuB,CAAC,AALpB,CAU5C,GAJkB,IAAI,EAAlB,AAAoB,GACtBC,GAAsB,EAAU,CAAC,CADrB,IACkB,GAAT,AAAoB,CAAC,CAAE,GAG1CD,KAAuD,EAHH,CAAC,IAG/B,EAAY,AAA8B,AAA3C,CAAc,CAA+B,MAAlC,MAAgB,CAAC,CAAC,CACpD,MAAM,AAAI,KAAK,CAAC,uDAAuD,CAAC,CAG1E,OAAO,CACT,EApLqC,IAInC,CA+Ke,GA/KT,EAA8BA,GAAsB,EAAY,CACpE,KALsD,CAAC,CACtD,AAGiE,CAAX,WAAxB,MACN,CAC1B,CAAC,MACmB,IAAjB,GAA8B,AAA+B,EAAnC,EAAuC,EAAE,GACrEC,AADc,GAEZ,EACA,CAAC,OAAO,CAAE,AAFS,CACP,GAF6C,qBAGtB,CAAC,CACpC,GAIJ,IAAM,EAA+BD,GAAsB,EAAY,CACrE,OADmE,CAAX,IAJ3B,CAC5B,OAG+B,MACN,CAC3B,CAAC,MACmB,IAAjB,GAA8D,EAApC,EAAwC,EAApC,AAAsC,GAAxD,AACdC,GACE,EACA,CAAC,OAAO,CAFW,AAET,CADE,UAF8C,eAGtB,CAAC,CACrC,GAIJ,IAAM,EAA0BD,GAAsB,EAAY,CAChE,OAD8D,CAAX,KAJrB,CAC7B,CAG0B,MACN,CACtB,CAAC,MACmB,IAAjB,GAAyD,EAA/B,EAAmC,EAA/B,AAAiC,GACjEC,AADc,GAEZ,EACA,CAAC,OAAO,CAFW,AAET,CADE,KAFyC,eAGtB,CAAC,CAChC,GAIJ,IAAM,EAA+BD,GAAsB,EAAY,CACrE,OADmE,CAJ1C,AAI+B,CAHvD,WAG+B,MACN,CAC3B,CAAC,MACmB,IAAjB,GAA8D,EAApC,EAAwC,EAApC,AAAsC,GAAxD,AACdC,GACE,EACA,CAAC,OAAO,CAFW,AAET,CADE,UAF8C,eAGtB,CAAC,CACrC,GAIJ,IAAM,EAAkBD,GAAsB,EAAY,CAAC,OAAtC,AAAmC,CAAX,KAJb,AAIwC,CAAC,AAHtE,CAGuE,CAS1E,OAAO,AARH,KAAiB,GAQN,IARC,AAAqC,EAAvB,EAA2B,EAAvB,AAAyB,GACzDC,GACE,EACA,CAAC,MAH4C,CAGrC,CAAE,AAFS,CACP,YACW,CAAC,CACxB,GAnMsC,CAAA,CAwM5C,AAxM8C,EA8Nf,EAAY,IAIlC,EA/BY,CAChB,CA0BoC,AAAU,AAxU3C,CAwU4C,CAC/C,AAzU8BD,EA4UlB,GA5UoD,CACjE,QADoD,CAAC,OAAzB,GAAmC,GACzC,CACvB,CAAC,CACE,KAAiB,OAAL,AAA8C,EAAhC,EAAoC,EAAhC,AAAkC,GAClEC,KAEE,CAAC,QAFkB,CACnB,EACY,CAAC,CACb,EAJsD,CArChB,CAAA,CAAE,GAuC5B,AAwBT,GCoJH,EAAOuC,EAAH,CACF,ADrJS,MCoJY,ED1KC,CACzB,IC0KgB,CACb,EAAK,EAAD,EAAmC,CACxC,CADY,AAGb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,IAAU,CACrB,CADoB,MACb,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAErB,CAFoB,GAEd,EA5OZ,AA4O8B,SA5OrB,AACP,CAAoC,CACpC,CAA0C,CA0OjB,CA1OiB,AAG1C,IAAI,EAAyD,IAAI,CAC3D,EAAgC,CAsOkB,CAtON,QANf,CAMc,EADvB,aACmD,CAA1C,AACnC,CAD4E,EAEjC,QAAQ,EAAjD,OAAO,GAC2B,IAAI,GAAtC,GACA,OAAO,GAAI,EACX,CAGA,GANoC,CAM9B,EAAc,EACjB,KAN0B,AAMrB,CADQ,AAGU,QAAQ,EAA9B,EAPoC,KAO7B,GAA0C,IAAI,EAAE,CAAtC,AAAiB,GAEpC,EAAY,KAFkC,IAEnC,eAA4B,CAAG,CAAJ,CACtC,EAAyB,GAIzB,GALoD,IACU,AAIvD,EAAY,QAJG,CAIJ,eAA4B,AAEjD,EAFgD,KAE1C,IAAsC,IAAlC,GAGT,EAHoD,EAAE,GAG/C,EAAY,SAAD,QAHoB,OAGQ,CAGhD,CAH+C,GAGzC,EAAuB,EAAY,SAAD,AAAa,CAErD,CAFoD,EAEhD,EAAwB,CAC1B,AAHwB,IAGlB,EAAwB,AAhElC,SAAS,AAAc,CAA8B,EAAA,AACnD,CA+D6C,AADnB,GA9DpB,EAAmB,CA+DI,CA/DF,CAE3B,CAHoB,AACR,GAEP,IAAM,GAAG,EAAI,EAChB,GADqB,AACjB,CADmB,KACb,CAAC,SAAS,CAAC,cAAc,CAAC,IAAI,CAAC,EAAO,GAAF,AAAK,AAAG,CACpD,AADkD,IAC5C,EAAQ,CAAK,CAAC,CAAT,CAAa,CAAD,AAEvB,GACE,AAAiB,QAAQ,SAAlB,GACE,EADG,EACC,EAAb,GACA,EADK,IACC,CAAC,IAAI,CAAC,GAAO,EAAF,CAAC,GAAO,CAAG,CAAC,CAC7B,CACA,IAAM,EAAQ,GAAH,GAAS,CAAC,IAAI,CAAC,GAAO,EAAF,CAAC,AAAI,CAAC,AAAC,EAAE,CAAK,CAAA,EAAG,EAAO,CAAJ,AAAI,EAAA,EAAE,AAAE,CAAA,CAAC,CAC5D,EAAO,IAAD,AAAK,CAAC,GAAG,EAChB,GADqB,CAAC,EAErB,CADK,CACE,IAAD,AAAK,CAAC,EAEf,CAFkB,AAKrB,CALsB,CAAC,CAAA,IAKhB,EAAO,IAAI,AAAL,CAAM,CALI,EAKD,CAAC,AACzB,EA2CgD,GAE5C,GACE,KAAK,CAAC,OAAO,GAHmD,CAAC,GAGnD,EAAA,IAAM,CAAN,CAAA,CAAA,EAAA,AAAQ,IAAR,AAAM,IAAN,MAAM,KAAN,CAA4B,CAAC,EAC3C,CADc,AACd,CADc,KACR,EAAN,GAAA,EAAA,CAAA,CAAA,EAAQ,EAAR,EAAM,IAAA,KAAN,KAAA,CAAA,CAA4B,CAAC,MAAA,AAAM,IAAK,CAAC,CAIrC,CAHJ,CAKE,EAAY,SAAD,AAAa,CAAG,CAAJ,CAEvB,KAJuB,EAAE,AAIlB,EAAY,SAAD,AAAa,CAFiB,AAEhB,CAAF,AAAE,IAG7B,GACL,OAAA,EAAA,IAAM,CAAN,CAAA,CAAA,EAAM,AAAE,IAAF,IAAN,EAJkC,IAI5B,KAAN,CAAQ,AAAoB,GAC5B,CADA,CAAA,AACO,IAAD,gBAAqB,CAAC,MAAM,CAAG,CAAC,EACb,IAAI,GAA7B,GACA,KAAK,CAAC,OAAO,CAAC,GADM,CAEpB,EAAqB,MAAM,CAAG,CAAC,CAC/B,CAIA,IANkC,AAM5B,CAN6B,CAMJ,CAC7B,CANkB,YAML,CACb,KAF0B,CAEpB,CACN,MAAM,CACN,iBAAiB,CACjB,oBAAoB,CACpB,MAAM,CACN,cAAc,CACf,CAEG,EAAwC,EAAE,CAC1C,EAAqB,MAAM,CAAG,CAAC,EAAE,CACnC,EAA8B,EAAqB,GAD7B,AACgC,CAAC,AAAC,CAF3B,EAG3B,AAAI,EADuD,AAChC,KADoC,GAC5B,CADa,AACZ,GAC3B,CAAA,CAFgB,AACgB,CAAC,EAAE,GAAlB,UACjB,EAAoB,EAAK,CAAE,CAE7B,CAF2B,CAInC,CAAC,CAGJ,CALgB,CAAC,CAAA,CAKX,EAA2B,EAAE,CAC/B,GACF,EAAe,IAFG,AAEC,CAAC,GAElB,EAA4B,EAFhB,IADS,AAGa,CAAG,CAHd,AAGe,EAAE,AAC1C,EAAe,IAH0B,AAP1B,AAUI,CAHuB,AAGtB,GAAG,GAGrB,CAHY,CAGG,AAJY,MAIN,CAAG,CAAC,CAC3B,CAD6B,CACjB,CADI,QACL,AAAa,CAAG,CAAJ,AAJ2B,CAAC,AAIT,IAAI,CAAC,GAAG,CAAC,CAInD,EAJyC,KAIlC,EAAY,SAAD,AAAa,AAElC,EAFiC,IAQhC,CANK,MAME,EAAY,SAEtB,AAFqB,AAAa,EAAD,IAML,CAJtB,GAI0B,GAA7B,GACA,KAAK,CAAC,OAAO,CAAC,GADM,CAEpB,EAAqB,MAAM,CAAG,CAAC,CAI/B,CAHA,CAGY,GALsB,CAAC,GACf,EAII,AAAb,CAAgB,CAAJ,CAAyB,IAAI,CAAC,GAAG,CAAC,CAEzD,OAAO,CAFwC,CAE5B,SAAD,AAAa,CAInC,CAJkC,MAI3B,CACT,EAmH2D,EAAM,EAAF,AAAS,IAAD,AApHnD,EAoH0D,CAAC,CAezE,OAbW,AAaJ,IAbQ,CAAC,GAaD,MAbC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,UAAU,CAAE,CADwB,CAAC,IACnB,CAClB,WAAW,CAAE,MAAA,EAAA,CAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAO,AAAN,EAAM,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,CAIL,EAHO,EADE,AAIL,CAAE,AAAD,GACZ,CADiB,CAG3B,EAFiC,AAIrC,CCrSM,CDgS6B,GChSvB,GAAwB,gBAAgB,CAC/C,CAD4B,EAEhC,qBAD4B,2BACoB,OAgBrC,GAIX,KAJmB,CAAA,KAInB,CAAY,CAAqB,CAAA,CAC/B,QAAoB,IAAhB,EAAK,EAAD,CAAqB,GAAd,CAAgB,CAC7B,IAAI,CAAC,MAAM,CAAG,EAAK,EAAD,IAAO,CACzB,MACD,CACD,MAAM,EAAoB,AAkD9B,SACE,AADO,CAC8B,EAAA,AAErC,GArDyB,CAqDrB,EACJ,GAAI,CAAC,AAtD6C,EA0DhD,GALgC,GAElB,CALa,AAMzB,AAEK,MAFC,CAAE,CAFU,AAET,EAFW,CAIJ,AAFkB,CACnC,CAID,GAAK,CAAD,AADJ,EAAc,CAAA,CAAiB,CACd,KAAD,CAAO,AADZ,EACc,AAGlB,EAR4B,CAShC,AAA8B,QAAQ,SAA/B,EAAY,MAAM,EACxB,CADiB,CACL,MAAM,GAAP,AAAY,IACxB,KAAK,CAAC,OAAO,CAAC,EAAY,IADsB,EAChB,CAAC,EACuB,AAD/B,CACgC,CAAxD,AAAyD,CAC3D,CADc,MAAM,CAAC,EAAR,KAAe,CAAC,IAE7B,MAAM,AAAI,KAAK,CACb,CAAA,OAHmD,CAAC,kCAGpD,EAA6C,GAAwB,CAAE,CACxE,AACF,MAXC,EAAY,MAAM,CAAG,CAAC,CAAX,EAAoC,AASwB,CAGzE,OAAO,CAEX,EA5EqD,EAAK,EAAD,IA0EnC,EAZ8B,SA9DuB,CAAC,CACxE,IAAI,CAAC,UAAU,CAAG,IAAI,GAAA,UAAU,CAAC,GAGnC,MAAM,QAH8C,CAAC,KAGjC,CAAC,CAAgB,CAAE,CAAY,CAAA,CACjD,QAAoB,IAAhB,IAAI,CAAC,AAAoB,MAAd,CAAgB,CAC7B,GAAI,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,cAAc,CAAC,CACxC,CAD0C,KACpC,AAAI,KAAK,CAAC,sDAAsD,CAAC,CAEzE,IAAI,CAAC,YAAY,CAAC,GAClB,IADyB,CAAC,CAE3B,CAED,OAAO,IAAI,CAAC,oBAAoB,CAAC,EAAS,GAAG,AAGvC,CAHwC,CAAN,UAGtB,CAAC,CAAgB,CAAA,CACnC,GAA2C,IAAI,EAAE,CAA7C,EAAQ,GAAG,CAAC,CAAL,IAGX,QAAoB,IAAhB,IAHiC,AAG7B,CAAC,AAH6B,AAGT,EAAE,IAAhB,CAGb,MAAU,AAAJ,KAAS,CAAC,oDAAoD,CAAC,CAEvE,EAAQ,KAAD,CAAO,CAAC,GAAuB,IAAI,CAAC,MAAM,CAAC,EAG5C,IAH8B,EAGxB,oBAAoB,CAChC,CAAgB,CAChB,CAAY,CAAA,CAEZ,QAAwB,IAApB,IAAI,CAAC,AAAwB,EAAE,QAAhB,CAIjB,MAAM,AAAI,KAAK,CACb,2DAA2D,CAC5D,CAGH,IAAK,GAAM,CAAC,EAAK,CAAF,CAAQ,GAAD,AADF,CACO,KADD,IAAI,CAAC,CACO,CAAE,QADC,CAAC,iBAAiB,CAAC,EAAG,CAAC,CAErC,IAAI,EAAE,CAA3B,EAAQ,GAAG,CAAC,CAAL,EAAQ,CAAC,AAGpB,EAAQ,KAAD,CAAO,CAAC,EAAK,CAAF,EAGvB,CCjFE,CD8E4B,CAAC,IC9DnB,GACX,MAAM,KADmB,CAAA,EACX,CACZ,CAA8B,CAC9B,CAAoB,CAAA,CAEpB,GAAI,EAAO,IAAD,QAAa,CAAE,CACvB,IAAM,EAAW,MAAM,AAAT,GAAsB,EAAQ,GAC5C,CAD0C,EACtC,CAD+B,EAAkB,CAAC,IAC1C,KAAY,GAAc,CACpC,IAAM,EAAM,CAAA,CADsB,CACnB,CAAH,EAAG,iBAAA,AAAiB,EAAC,EAAO,IAAD,QAAa,CAAC,CACrD,GAAA,QAAQ,CAAC,OAAO,CACd,EAAS,MAAD,UAAiB,CAAC,IAAkC,CAC7D,CAAC,IAAI,CAAC,EACR,IADc,CAAC,EACT,CACL,GAAA,SAAA,AAAS,EACP,EAAO,IAAD,QAAa,CACnB,EACA,CAAC,KADiB,GACT,CAAE,QAAQ,CAAC,CACpB,AAAC,IACC,CADI,EACA,EACF,CAFM,EACC,EAAE,CACH,AAAI,KAAK,CACb,CAA2B,wBAAA,EAAA,EAAO,IAAD,QAAa,CAAK,EAAA,EAAA,EAAO,CAAA,CAC3D,AAEL,CAAC,AAH6D,CAI/D,AAEJ,EAEJ,CAED,eAAe,GACb,CAA8B,CAC9B,CAAoB,EAAA,IAFK,MAIzB,IAAM,EAAO,EAAH,CAAa,EAAO,IAAD,AAAP,AAAY,CAAC,CACnC,QAAa,IAAT,EACF,EADM,CAAc,EAAE,EACf,MAAM,EAAU,OAAD,AAAQ,CAAC,CAC7B,IAAI,CAAE,CAAS,MAAA,EAAA,EAAe,EAAX,OAAW,CAAA,CAC9B,UAAU,CAAE,KAAK,CACjB,WAAW,CAAE,CACX,IAAO,CAAF,MAAS,AACf,CAAA,CACD,WAAW,CAAE,MAAA,EAAA,CAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,MAAA,EAAA,CAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,AACxC,CAAA,CAAC,CACG,CAFuB,EAEnB,GAAiB,EAAO,IAAD,AAAK,CAAC,CAAE,CACxC,IAAM,AADmB,EACN,OAAA,CAAH,CAAG,AAAC,EAAO,IAAD,AAAwB,CAAC,KAAA,AAAK,EAAE,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,GAAA,EAAA,KAAU,AAAV,CAC1D,GAA0B,AAAtB,CADsD,CAAA,MACxB,EAAE,OAAzB,EACT,OAAO,CADY,AAGnB,OAAM,AAAI,EAFO,GAEF,CACb,kEAAkE,CACnE,AAEJ,CAAM,GAAI,GAAQ,EAAO,EAAR,EAAO,AAAK,CAAC,CAAE,CAC/B,IAAM,EAAc,EAAO,IAAc,AAAf,CAAgB,CAA1B,SAAoC,CACpD,GAA0B,QAAQ,EAA9B,AAAgC,OAAzB,EACT,OAAO,CAEP,AAHmB,OAGb,AAAI,EAFO,GAEF,CAAC,wDAAwD,CAAC,AAE5E,CACC,MADK,AACC,AAAI,KAAK,CAAC,uBAAuB,CAAC,AAE5C,CChFG,MAUU,GACX,MAAM,CACJ,CAAW,CACX,CAA+B,CAC/B,CAA6B,CAAA,CAE7B,GAN6B,CAAA,GAMtB,IAAI,GAAc,EAAK,CAAF,CAAW,GAE1C,EAFwC,CAAb,GAAwB,CAAC,AAIxC,GAGX,UAHwB,CAAA,AAGxB,CACmB,CAAW,CACX,CAA+B,CAC/B,CAA6B,CAAA,CAF7B,IAAG,CAAA,GAAA,CAAH,EACA,CADG,GACI,CAAA,OAAA,CAAP,EACA,IAAS,CADF,AACE,SAAA,CAAT,EAGnB,OAH4B,AAGrB,EAAA,CACL,IAAI,CAAC,EAAE,CAAG,IAAI,GAAO,GAAD,CAAC,GAAS,CAAC,IAAI,CAAC,GAAG,CAAE,CAAC,OAAO,CAAE,IAAI,CAAC,OAAO,CAAC,CAAC,CAEjE,IAAI,CAAC,EAAE,CAAC,MAAM,CAAG,IAAI,CAAC,SAAS,CAAC,MAAM,CACtC,IAAI,CAAC,EAAE,CAAC,OAAO,CAAG,IAAI,CAAC,SAAS,CAAC,OAAO,CACxC,IAAI,CAAC,EAAE,CAAC,OAAO,CAAG,IAAI,CAAC,SAAS,CAAC,OAAO,CACxC,IAAI,CAAC,EAAE,CAAC,SAAS,CAAG,IAAI,CAAC,SAAS,CAAC,SAAS,CAG9C,IAAI,CAAC,CAAe,CAAA,CAClB,QAAgB,IAAZ,IAAI,CAAC,AAAgB,EAAd,AAAgB,CACzB,MAAM,AAAI,KAAK,CAAC,4BAA4B,CAAC,CAG/C,IAAI,CAAC,EAAE,CAAC,IAAI,CAAC,GAGf,IAHsB,CAAC,AAGlB,EAAA,CACH,QAAgB,IAAZ,IAAI,CAAiB,AAAhB,EAAkB,AAAhB,CACT,MAAM,AAAI,KAAK,CAAC,4BAA4B,CAAC,CAG/C,IAAI,CAAC,EAAE,CAAC,KAAK,EAAE,CAElB,CCife,SAAA,GACd,CAA2B,CAC3B,CAAoB,EAAA,AAEpB,UAJgC,AAI1B,EAAoC,CAAA,CAAE,CAEtC,EAAsBxC,CAFd,EAEoC,EAAY,CAC5D,OAD0D,CAAX,GAAxB,MACN,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAWD,GAAsB,EAAY,CAArC,AAAsC,IAHsB,CAAC,CAGjB,CAAT,AAAU,CAArB,AAAsB,AAC5C,IAAI,EAAE,CAAlB,GACFC,GAAsB,EADZ,AACsB,CAAC,KAAH,CAAS,CAAC,CAAE,AAArB,GAGvB,IAAM,CAH8C,CAAC,AAGnCD,GAAsB,EAAY,CAAC,CAAtC,MAA6C,AAAV,CAAW,AAAtB,CAAuB,AAC7C,IAAI,EAAE,CAAnB,GACFC,GAAsB,EAAU,CADrB,AACsB,KAAH,EAAU,CAAnB,AAAoB,CAAE2K,GAAmB,IAGhE,IAAM,CAHmE,CAGlD5K,AAHmD,CAAC,EAG9B,AAHkB,EAGN,CAAC,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,AAClD,IAAI,EAAE,CAAxB,GACFC,GAAsB,EAAU,CAAC,KADjB,AACc,GAAT,IAAwB,CAAC,CAAE,GAGlD,IAAM,EAAgBD,GAAsB,EAHoB,AAGR,CAHS,AAI/D,KADiB,EAAmC,CAAX,IAC7B,CACZ,WAAW,CACZ,CAAC,AACmB,IAAI,EAAE,CAAvB,GACFC,GAAsB,EAAU,CAAC,IADlB,CACe,GAAT,GAAuB,CAAC,CAAE,GAGjD,IAAM,EAAcD,GAAsB,CAHoB,CAAC,AAGT,CACpD,GADe,IAAmC,CAAX,IAC3B,CACZ,cAAc,CACf,CAAC,AACiB,IAAI,EAAE,CAArB,GACFC,GAAsB,EAAU,CAAC,EADpB,GACiB,GAAT,CAAqB,CAAC,CAAE,GAG/C,IAAM,EAAiBD,EAHmC,CAAC,AAGd,EAAY,CAAC,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,AAClD,IAAI,EAAE,CAAxB,GACFC,GAAsB,EAAU,CAAC,KADjB,AACc,GAAT,IAAwB,CAAC,CAAE,GAGlD,IAAM,EAAkBD,GAAsB,EAHkB,AAGN,CAAC,AAHM,OAGT,AAAnC,CAAwB,KAA2B,CAAC,CAAC,AACnD,IAAI,EAAE,CAAzB,GACFC,GAAsB,EAAU,CAAC,KAAH,CADb,EACI,KAAyB,CAAC,CAAE,GAGnD,IAAM,EAAgBD,GAAsB,EAAY,CAHU,AAGT,CAHU,IAGhD,EAAmC,CAAX,GAAyB,CAAC,CAAC,AACjD,IAAI,EAAE,CAAvB,GACFC,GAAsB,EAAU,CAAC,IADlB,CACe,GAAT,GAAuB,CAAC,CAAE,GAGjD,IAAM,EAAiBD,GAAsB,CAHiB,CAAC,AAGN,CAAC,MAAtC,CAAmC,AAAU,CAArB,AAAsB,CAAC,CASnE,OARsB,IAAI,EAAtB,AAAwB,GAC1BC,GACE,EACA,CAAC,KADO,AAFM,GACK,IAEN,CAAC,EACd,AAjJE,EAAoC,CAAA,CAAE,CAGxC,AAAa,GAHH,CAGO,EAAE,CADjB,EACO,AADKD,GA+IM,EA/I4B,AA+I7B,CA/I8B,CAAtC,KAA4C,CAAC,CAArB,AAAsB,CAArB,EA+IU,AA7IhDC,CA6IiD,CAChD,CA9IqB,EAAU,CAAC,EAFe,GAElB,EAAU,CAAC,AAApB,CAAsB,GAIzC,AAAgB,IAAI,EAJ8B,AAI5B,CAJ6B,AAGjD,EAAeD,GACL,EADuC,CAAC,IAAtC,EAA4C,CAAC,CAArB,AAAsB,CAArB,EAEzCC,GAAsB,EAAU,CAAC,EAFkB,GAErB,GAAT,EAAsB,CAAC,CAAE,GAGzC,IAyIA,CACT,CAEgB,EA5IC,CAH6C,CAAC,EA4I9C,GAGD,GACd,CAA2B,CAC3B,CAAqB,EAAA,AAErB,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAN2B,AAMLD,CAFd,EAEoC,EAAY,CAC5D,OAD0D,CAAX,GAAxB,MACN,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAWD,GAAsB,EAAY,CAArC,AAAsC,IAHsB,CAAC,CAGjB,CAAT,AAAU,CAAC,AAAtB,AACtB,IAAI,EAAE,CAAlB,GACFC,GAAsB,EAAU,AADtB,CACuB,KAAH,CAAS,CAAC,CAAnB,AAAqB,GAG5C,IAAM,CAH8C,CAAC,AAGnCD,GAAsB,EAAY,CAAC,CAAtC,MAAmC,AAAU,CAArB,AAAsB,CAAC,AAC7C,IAAI,EAAE,CAAnB,GACFC,GAAsB,EAAU,CADrB,AACsB,KAAH,EAAU,CAAnB,AAAoB,CAAE2K,GAAmB,IAGhE,IAAM,CAHmE,CAGlD5K,AAHmD,CAAC,EAG9B,AAHkB,EAGN,CAAC,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,AAClD,IAAI,EAAE,CAAxB,GACFC,GAAsB,EAAU,CAAC,KADjB,AACc,GAAT,IAAwB,CAAC,CAAE,GAGlD,IAAM,EAAgBD,GAAsB,EAAY,AAHQ,CAGP,AAHQ,KAG9C,EAAmC,CAAX,GAAyB,CAAC,CAAC,AACjD,IAAI,EAAE,CAAvB,GACFC,GAAsB,EAAU,CAAC,IADlB,CACe,GAAT,GAAuB,CAAC,CAAE,GAGjD,IAAM,EAAcD,GAAsB,CAHoB,CAAC,AAGT,CAAC,GAAtC,IAAmC,CAAX,CAAuB,CAAC,CAAC,AAC/C,IAAI,EAAE,CAArB,GACFC,GAAsB,EAAU,CAAC,EADpB,GACiB,GAAT,CAAqB,CAAC,CAAE,GAG/C,IAAM,EAAiBD,EAHmC,CAGb,AAHc,EAGF,CAAC,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,AAClD,IAAI,EAAE,CAAxB,GACFC,GAAsB,EAAU,CAAC,KADjB,AACc,GAAT,IAAwB,CAAC,CAAE,GAGlD,IAAM,EAAYD,GAAsB,EAHwB,AAGZ,CAHa,AAGZ,CAAtC,MAAmC,AAAU,CAArB,AAAsB,CAAC,AAC7C,IAAI,EAAE,CAAnB,GACFC,GAAsB,EAAU,CAAC,AADtB,KACmB,EAAU,CAAC,AAApB,CAAsB,GAG7C,IAAM,EAHgD,AAG9BD,CAH+B,EAGT,EAAY,CAAC,OAAtC,AAAmC,CAAX,KAA2B,CAAC,CAAC,AACnD,IAAI,EAAE,CAAzB,GACFC,GAAsB,EAAU,CAAC,KAAH,CADb,EACI,KAAyB,CAAC,CAAE,GAGnD,IAAM,EAAgBD,GAAsB,EAAY,CAAC,AAHS,CAAC,IAGhD,EAAmC,CAAX,GAAyB,CAAC,CAAC,AACjD,IAAI,EAAE,CAAvB,GACFC,GAAsB,EAAU,CAAC,IADlB,CACe,GAAT,GAAuB,CAAC,CAAE,GAGjD,IAAM,EAAiBD,GAAsB,CAHiB,CAAC,AAGN,CAAC,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,AAClD,IAAI,EAAE,CAAxB,GACFC,GAAsB,EAAU,CAAC,KAAH,AADd,GACK,IAAwB,CAAC,CAAE,GAGlD,IAAM,EAAoBD,GAAsB,EAHgB,AAGJ,CAHK,AAI/D,OADwD,CAAX,CAAxB,MACN,CAChB,CAAC,AACE,AAAqB,IAAI,EAAE,IAC7BC,GAAsB,EAAU,CAAC,CADd,IACW,GAAT,OAA2B,CAAC,CAAE,GAGrD,IAAM,EAA2BD,GAAsB,EAAY,CACjE,EAJoE,CAAC,IAGN,CAAX,QAAxB,MACN,CACvB,CAAC,AAC8B,IAAI,EAAE,CAAlC,GACFC,GACE,EACA,CAAC,KADO,GADW,OADK,OAGD,CAAC,CACxB,GAIJ,IAAM,EAAsBD,GAAsB,EAAY,CAC5D,OAD0D,CAAX,CAJrB,CACzB,CAGsB,MACN,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAqBD,GAAsB,EAAY,CAC3D,IAJwE,CAAC,EAGhB,CAAX,EAAxB,MACN,CACjB,CAAC,AACwB,IAAI,EAAE,CAA5B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,CADD,OAC6B,CAAC,CAAE,GAGtD,IAAM,EAA6BD,GAAsB,EAAY,CACnE,GAJsE,CAAC,GAGN,CAAX,UAAxB,MACN,CACzB,CAAC,AACE,AAA8B,IAAI,EAAE,IACtCC,GACE,EACA,CAAC,KADO,GADW,EADO,cAGD,CAAC,CAC1B,GAIJ,IAAM,EAAsBD,GAAsB,EAAY,CAC5D,OAD0D,CAAX,GAJnB,AAIL,CAHtB,KAIgB,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAiBD,GAAsB,EAAY,CAAC,IAHgB,CAAC,CAGvD,CAAmC,CAAX,IAA0B,CAAC,CAAC,AAClD,IAAI,EAAE,CAAxB,GACFC,GAAsB,EAAU,CAAC,KADjB,AACc,GAAT,IAAwB,CAAC,CAAE,GAGlD,IAAM,EAAaD,GAAsB,EAHuB,AAGX,CAHY,AAGX,EAAtC,KAAmC,CAAX,AAAsB,CAAC,CAAC,AAC9C,AAAd,IAAkB,EAAE,IACtBC,AADY,GACU,EAAU,CAAC,KAAH,GAAT,AAAoB,CAAC,CAAE,GAG9C,IAAM,EAAgBD,CAHkC,CAAC,CAGb,EAAY,CAAC,KAAtC,EAAmC,CAAX,GAAyB,CAAC,CAAC,AACjD,IAAI,EAAE,CAAvB,GACFC,GAAsB,EAAU,CAAC,IADlB,CACe,GAAT,GAAuB,CAAC,CAAE,GAGjD,IAAM,EAAkBD,GAAsB,CAHgB,CAAC,AAGL,CAAC,OAAtC,AAAmC,CAAX,KAA2B,CAAC,CAAC,AACnD,IAAI,EAAE,CAAzB,GACFC,GAAsB,EAAU,CAAC,KAAH,CADb,EACI,KAAyB,CAAC,CAAE,GAGnD,IAAM,EAAqBD,GAAsB,EAAY,CAHK,AAIhE,CAJiE,MAGR,CAAX,EAAxB,MACN,CACjB,CAAC,AACwB,IAAI,EAAE,CAA5B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,CADD,OAC6B,CAAC,CAAE,GAGtD,IAAM,EAA4BD,GAAsB,EAAY,CAClE,GAJsE,CAAC,GAGP,CAAX,SAAxB,MACN,CACxB,CAAC,AAC+B,IAAI,EAAE,CAAnC,GACFC,GACE,EACA,CAAC,KADO,GADW,QADM,OAGD,CAAC,CACzB,GAIJ,IAAM,EAAoBD,GAAsB,EAAY,CAC1D,OADwD,CAAX,CAAxB,CAJM,CAC1B,IAIc,CAChB,CAAC,CAKF,OAJyB,IAAI,EAAE,AAA3B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,AADF,OAC6B,CAAC,CAAE,GAG9C,CACT,CCjwBM,MDgwBW,AChwBJ,MD6vB2D,CAAC,AC7vBpD,IAAQ,GAC3B,OADqC,CAAA,GACrC,CAA6B,CAAoB,CAAA,CAC/C,KAAK,EAAE,CADoB,IAAS,CAAA,SAAA,CAAT,EAa7B,IAAA,CAAA,EAbsC,CAanC,CAAG,MACJ,GAEO,GAF6B,GAEvB,EADe,EACX,CAAC,WAAW,CAAC,GAYhC,GAZsC,CAAC,AAYvC,CAAA,IAAI,CAAG,MACL,EAAyC,CAAA,CAAE,EAAF,CAElC,EAD4B,EACxB,GACT,EADc,CACJ,MAAD,gBAAuB,CAChC,AAAC,CAAiC,EAAK,IAAI,CAAC,YAAY,CAAC,CAAC,CAAC,CAC3D,MAAM,IAAI,CAAC,YAAY,CAAC,GACxB,GAD8B,AAclC,CAdmC,EACzB,CACP,AAYH,CAAA,IAAI,CAAG,MACL,MAAuC,IAEvC,CAD4B,EACxB,IAAI,CAAC,SAAS,CAAC,UAAU,EAAE,CAC7B,CAD+B,EAC3B,EAAO,IAAD,KAAU,CAAC,UAAU,CAAC,WAAW,CAAC,CAAE,CAC5C,IAAM,EAAqC,CACzC,UADiB,IACH,CAAE,EAAO,IAAD,KAAU,CACjC,CACG,QAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,CAAA,CAAA,CAAA,CAAE,AAAF,GAAA,EAAA,KAAA,KAAA,CAAA,SAAE,AAAyB,EAAE,EAC5C,EAAc,WAAD,CAAa,CAAG,EAAO,IAAD,EAAO,CAAC,yBAAA,AAAyB,EAEtE,IAAM,EAAa,OAAA,IAAA,EAAA,CAAA,OAAA,MAAA,CAAA,CAAA,EACd,GAAM,CACT,EADS,CAAA,UACI,CAAE,CAAa,EAC7B,CAED,OADA,EAF8B,AAEhB,SAAS,EAAV,IAAa,EACnB,MAAM,CADsB,GAClB,CAAC,YAAY,CAAC,EAChC,KAAM,CACL,IAAM,CAFsC,CAAC,AAE1B,MAAA,CAAA,IAAA,EAAA,CAAA,CAAA,CAAA,CACd,GAEL,GAFW,CACV,GACM,MAAM,IAAI,CAAC,YAAY,CAAC,EAChC,CACI,CACL,IAAM,EAAa,GAH2B,CAAC,EAG5B,CAAA,IAAA,EAAA,CAAA,CAAA,CAAA,CACd,GAEC,EAAY,CAFP,CACV,IACuB,CAAT,GAAa,CAAC,iBAAiB,CAAC,GAC3C,EAAiB,EAAE,CAiBvB,KAlB4D,CAAC,CAGjC,AAerB,EAjBW,OAiBF,AAfqB,AAAnC,EAAU,OAAD,CAAY,EAAD,KACoB,IAAxC,EAAU,GAAuC,EACjD,EADS,CAAY,CAAC,CAAF,SAAe,CAEnC,CAFkC,CAEjB,EAAU,OAAD,CAAY,CAAC,CAAzB,AAAuB,SAAyB,EAAX,IAE7B,IAAtB,EAAU,GAAqB,CAAd,EAAD,AAChB,CADS,CACC,IAAO,CAAC,CAAF,CAAP,MAAiB,CAAC,cAAc,CAAC,EAC1C,CACA,EAAiB,EAAU,IAAO,CAAC,CAAF,CAAP,GAAZ,AAA0B,CAAC,cAAc,CAAC,CAAC,EAAC,AAAC,EAE1B,CACjC,IAAI,CAAE,EACN,KAAK,CAAE4K,GAAe,GADF,EACC,WAAiB,CAIzC,AAHE,CAIL,CAAC,CAEO,MAAM,WAAW,CACvB,CAAoC,CAAA,iBAIhC,EAAe,EAAX,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,GAAI,GADW,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,SACzB,GDgMJ,CChMQ,CDgM4B,CAAA,CAAE,AChM3BC,CDmMD,AAAZ,GAHU,CAGM,EAAE,CADhB,CACM,CADK9K,GClM0C,EDkMR,CAArC,AAAsC,GClMqB,CAAC,EDkMhB,CAAC,CAArB,AAAsB,CAArB,EAErCC,GAAsB,ACpMkC,EDoMxB,CAAC,EAFc,GAEjB,CAAS,CAAE,CAApB,KAA0B,CAAC,CAAE,GAG7C,GC3KH,EDwKwD,CAAC,EAG9C,ECtMX,EAAOuC,EAAH,CACF,MADqB,EACb,CACR,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAmBJ,CArBa,GAEL,CAAC,GAmBD,MAnBC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IAAI,AADc,CACb,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,KAAK,CACjB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,AACU,GAAR,CAAY,CAAC,AAAC,AADZ,IAEF,AACjB,EAAS,MAFkC,AAEnC,IADwC,CADD,IAEvB,CAAG,CACzB,OAAO,CAAE,EAAa,OAAO,CACR,EADA,IAMb,IAAI,CAAC,AAAC,GACPuI,GAA+B,GAI/C,CAAM,CAL4B,KAAI,CACoB,ADuJvD,CCvJwD,CAKpD,GDgJJ,ACrJ2C,CAKnC,CDgJ4B,CAE5B,AAF4B,CAAE,AChJ3BC,CDmJb,AAAY,GAHF,CAGM,EAAE,EAAV,CADKhL,GClJyC,EDkJP,CAAC,GClJoB,CAAC,EDkJf,CAAC,CAArB,AAAsB,CAArB,EAErCC,ECpJuD,CDoJjC,EAAU,CAAC,EAFc,GAEjB,CAAS,CAAE,CAApB,KAA0B,CAAC,CAAE,GAG7C,GC3HH,EDwHwD,CAAC,EAG9C,ECtJX,EAAOuC,EAAH,CACF,MADqB,EACb,CACR,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAmBJ,CArBa,GAEL,CAAC,GAmBD,MAnBC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IAAI,AADc,CACb,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,KAAK,CACjB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,AACU,GAAR,CAAY,CADV,AACW,AAAC,IACd,AACjB,EAAS,MAAD,AAFmC,IACK,CADD,IAEvB,CAAG,CACzB,OAAO,CAAE,EAAa,OAAO,CACR,EADA,IAMb,IAAI,CAAC,AAAC,GACPyI,GAA8B,GAI9C,EALkC,AAQ7B,KARiC,CACmB,AAO9C,CAP+C,GAAb,QAOtB,CACxB,CAAsC,CAAA,iBAIlC,EAAe,EAAX,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,GAAI,GADW,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,KDiM7B,MA/BA,EA+BQ,AA1BR,ECtKI,IAAI,CDgM4B,CAAA,CChMzBC,ADgM2B,CAG1B,AA7BF,AA6BZ,CAlCe,GAkCG,EAAE,CADlB,EAAalL,CACL,ECnM+C,EDkMR,CAAC,EAAtC,CClM2D,CAAC,IDkMpC,AAAsB,CAArB,AAAsB,CAAC,IAtC1D,EAAeA,AC5JuC,GDkMT,EAtCI,CAAC,IAAtC,IAAwB,CAAC,CAAuB,CAAC,CAAC,CAChE,KAAiB,CADgC,MACrC,AAAkC,EAApB,EAAwB,EAApB,AAAsB,GACtDC,KAAoC,CAAC,GADO,KACvB,AAAwB,CAAvB,AAAyB,UAAU,CAAC,CAAxB,AAA0B,KAGxCD,GAmCS,EAnCyB,CAAC,CAHiB,CAAC,KAsClC,CAnCE,CAAC,EAAwB,CAAC,CAAC,CAClE,KADkD,AACjC,OAAL,AAAmC,EAArB,EAAyB,EAArB,AAAuB,GACvDC,KAAoC,CAAC,IADQ,IACxB,AAAwB,CAAE,AAAzB,WAAoC,CAAxB,AAAyB,CAAE,KAG5CD,KAAkC,CAAC,EAHsB,CAAC,KAGrC,AAAsB,CAAC,AAAtB,CAAuB,CAC5D,KAAiB,GAD8B,CA8BR,GA7B3B,AAAkB,AAAc,EAAlB,EAAsB,CA6BW,CAAC,AA7BV,GACpDC,CAD0C,IACN,CAAC,QAAhB,AAAwB,CAAvB,AAAyB,QAAQ,CAAC,CAAE,EAAxB,EA+B7B,GC3KH,GD4IkE,CAAC,CA+BxD,ECtMX,EAAOuC,EAAH,CACF,MADqB,MACT,CACZ,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAmBJ,CArBa,GAEL,CAAC,GAmBD,MAnBC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,KAAK,CACjB,WAAW,CAAE,MAAA,EAAA,CAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAO,AAAN,EAAM,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,AACU,GAAR,CAAY,CADV,AACW,AAAC,IACd,AACjB,EAAS,MAFkC,AAEnC,IADqD,CADd,IAEvB,CAAG,CACzB,OAAO,CAAE,EAAa,OAAO,CACR,EADA,IAMb,IAAI,CAAC,AAAC,IACpB,IAAM,EAAO2I,AD+ML,CChNuB,CACrB,IADyB,GDgN3B,AACd,CAAwC,CACxC,CAAoB,EAAA,AAEpB,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAsBnL,CAFd,EAEoC,EAAY,CAC5D,CCtN4D,MDqNF,CAAX,EANH,CAMrB,MACN,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAoBD,GAAsB,EAAY,CAC1D,IAJwE,CAAC,EAGjB,CAAX,CAAxB,MACN,CAChB,CACwB,AADvB,AACE,IAAyB,EAAE,IAC7BC,GAAsB,EAAU,CAAC,CADd,IACW,GAAT,OAA2B,CAAC,CAAE,GAGrD,IAAM,EAAiBD,GAAsB,EAAY,CAAC,EAHY,CAAC,GAGnD,CAAmC,CAAX,IAA0B,CAAC,CAAC,CACxE,GAAsB,IAAI,EAAtB,EAAwB,CAC1B,IAAI,EAAkB,EAClB,GAFY,EAEP,CAAC,KADS,CAAiB,CACnB,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,AAEvB,CADkC,CADT,CAEL,CADd,EAEd,AAFgC,AAAc,CAE7C,AAD2C,CAG/CC,AAHgD,GAG1B,EAAU,CAAC,KAHH,AAGA,GAAT,IAAwB,CAAC,CAAE,EACjD,CAED,OAAO,CACT,EC/OiE,ED2OE,CAAC,AC1OtD,ED6OG,AC7OS,IAAImL,EAD8C,CAAC,AACtD,AAEf,OADA,MAAM,CAAC,KAD2C,CACrC,CADuC,AACtC,EAAW,GAClB,CADsB,AAE/B,CAFgC,AAE/B,CAAC,AACH,CAH0B,AAGpB,KDgJH,AClJgB,QDkJR,EC/IJ,IAAI,CD+I4B,CAAA,CAAE,AC/I3BC,CDkJb,AAAc,IAAI,EAAE,CADlB,EAAarL,CACL,EClJ8C,EDiJP,CAAC,EAAtC,CCjJ0D,CAAC,IDiJnC,AAAsB,CAArB,AAAsB,CAAC,IAjD1D,CChGqD,CDgGtCA,GAiD8B,EAjDI,CAAC,IAAtC,IAAwB,CAAC,CAAuB,CAAC,CAAC,CAChE,KAAiB,CADgC,MACrC,AAAkC,EAApB,EAAwB,EAApB,AAAsB,GACtDC,KAAoC,CAAC,GADO,KACC,AAAxB,CAA0B,AAAzB,UAAmC,CAAC,CAAE,AAA1B,GAG9B,EAAgBD,KAAkC,CAAC,CAHiB,CAAC,GAGxD,GAAwB,CAAC,EAAwB,CAAC,CAAC,CAClE,KADkD,AACjC,OAA8B,AAAnC,EAAc,EAAyB,EAArB,AAAuB,GACvDC,KAAoC,CAAC,IADQ,IACxB,AAAwB,CAAE,AAAzB,WAAoC,CAAC,AAAzB,CAA2B,GAGzD,EAAaD,GAyCW,EAzCuB,CAAC,EAAtC,AAH4D,CAAC,IA4CrC,CAzCsB,AAAtB,CAAuB,AAAtB,CAAuB,CAC5D,KAAiB,GAD8B,CAyCT,GAxC1B,AAAkB,AAAc,EAAlB,EAAsB,CAwCU,CAAC,AAxCT,GACpDC,CAD0C,IACN,CAAC,QAAhB,AAAwB,CAAvB,AAAyB,QAAQ,CAAC,CAAE,EAAxB,EA0C7B,GC1HH,GDgFkE,CAAC,CA0CxD,ECrJX,EAAOuC,EAAH,CACF,MADqB,OACR,CACb,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAmBJ,CArBa,GAEL,CAAC,GAmBD,MAnBC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,KAAK,CACjB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,AACU,GAAR,CAAY,CADV,AACW,AAAC,IAE/B,AADiB,EACR,MAFkC,AAEnC,IADqD,CADd,IAEvB,CAAG,CACzB,OAAO,CAAE,EAAa,OAAO,CACR,EADA,IAMb,IAAI,CAAC,AAAC,IACpB,IAAM,ED0IE,AC1IK8I,CADkB,CACrB,IADyB,GD2I3B,AACd,CAAwC,CACxC,CAAoB,EAAA,AAEpB,IAAM,EAAoC,CAAA,CAAE,CAEtC,EAAsBtL,CAFd,EAEoC,EAAY,CAC5D,ACjJ2D,ODgJD,CAAX,CANJ,EAMpB,MACN,CAClB,CAAC,AACyB,IAAI,EAAE,CAA7B,GACFC,GAAsB,EAAU,CAAC,KAAH,GAAT,EADA,OAC6B,CAAC,CAAE,GAGvD,IAAM,EAAoBD,GAAsB,EAAY,CAC1D,IAJwE,CAAC,EAGjB,CAAX,CAAxB,MACN,CAChB,CACG,AAAqB,AADvB,IAC2B,EAAE,IAC7BC,GAAsB,EAAU,CAAC,CADd,IACW,GAAT,OAA2B,CAAC,CAAE,GAGrD,IAAM,EAAiBD,GAAsB,EAAY,CAAC,EAHY,CAAC,GAGnD,CAAmC,CAAX,KAA2B,CAAC,CAAC,CACzE,GAAsB,IAAI,EAAtB,EAAwB,CAC1B,IAAI,EAAkB,EAClB,GAFY,EAEP,CAAC,KADS,CAAiB,CACnB,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAAC,AAEvB,CADkC,CADT,CAEN,CADb,EAEd,AAFgC,AAAc,CAE7C,AAD0C,CAAC,AAG/CC,GAAsB,EAAU,CAAC,IAHJ,CAGC,GAAT,IAAwB,CAAC,CAAE,EACjD,CAED,OAAO,CACT,EC1KgE,EDsKG,CAAC,ACrKtD,EDwKG,ACxKS,IAAImL,EAD6C,CAAC,AACrD,AAEf,OADA,MAAM,CAAC,KAD2C,CACrC,CADuC,AACtC,EAAW,GAClB,CADsB,AAE/B,CAFgC,AAE/B,CAAC,AACH,CAH0B,CAiB7B,IAhBsB,EAgBhB,MAAM,CAAC,CAAuC,CAAA,aAClD,IAAI,EAAe,EAAX,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,GAAI,GADW,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,KD/P7B,ICgQI,IAAI,ADhQA,CAA4B,CAAA,CAAE,ACgQ3BG,CD7Pb,AAAY,IAAI,EAAE,CADhB,CACM,CADKvL,GC8P6C,ED9PX,CAAC,AAAtC,GC8P8D,CAAC,ED9PnB,CAAC,CAAC,AAAtB,CAAC,EAErCC,GAAsB,EAAU,CAAC,AC4P0B,ED9PZ,GAEjB,CAAS,CAAE,CAApB,KAA0B,CAAC,CAAE,GAG7C,GC0PH,ED7PwD,AC6PjDuC,CD7PkD,CC6PrD,CD1PO,AC2PT,MADqB,SACN,CACf,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAErB,CAFoB,KAEd,IAAI,CAAC,SAAS,CAAC,OAAO,CAAC,CAC3B,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,MAAM,CAClB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,MAAA,EAAA,CAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,AACxC,CAAA,CAAC,AACH,EAF6B,GAEvB,SACC,GDhSJ,CCgSQ,CDhS4B,CAAA,CAAE,ACgS3BgJ,CD7Rb,AAAY,GAHF,CAGM,EAAE,CADhB,CACM,CADKxL,GC8R4C,ED9RV,CAArC,AAAsC,GC8RuB,CAAC,ED9RlB,CAAC,CAAC,AAAtB,CAAC,EAErCC,GAAsB,EC4RoC,AD5R1B,CAAC,EAFc,GAEjB,CAAS,CAAE,CAApB,KAA0B,CAAC,CAAE,GAG7C,GC0RH,ED7RwD,AC6RjDuC,CD7RkD,CC6RrD,CD1RO,AC2RT,MADqB,SACN,CACf,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CACtD,AADW,CAAgB,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAErB,CAFoB,KAEd,IAAI,CAAC,SAAS,CAAC,OAAO,CAAC,CAC3B,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,MAAM,CAClB,WAAW,CAAE,MAAA,EAAA,CAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,AACxC,CAAA,CACF,AADG,EAD0B,AAKxB,MAAM,YAAY,CACxB,CAA8C,CAAA,SAI9C,IAAI,EAAe,EAAX,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,GAAI,GADW,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAAE,OD/D7B,IAYA,ICoDI,GDlEJ,CCkEQ,CDhEK,AAFuB,CAAA,CAAE,ACkE3BiJ,CD/Db,AAAiB,GAHP,CAGW,EAAE,CAWF,EAZHzL,IACL,CADuC,CAAC,QAAd,CAAC,EAAwB,CAAC,CAAC,GAEpEC,GAFoD,AAE9B,EAAU,CAAC,EC8DiC,GD9DpC,GAAT,GAAuB,CAAC,CAAE,GAM7C,AAAqB,IAAI,EAAE,CAHzB,EAAoBD,CAHoC,CAAC,GAGH,CAC1D,EAEmB,MAH0B,CAAxB,AAAyB,MAC/B,CAChB,CAAC,EAFwD,CAIxDC,GAAsB,EAAU,CAAC,KAAH,GAAT,OAA2B,CAAC,CAAE,GAMjD,AAAuB,IAAI,EAAE,GAHLD,GCqDtB,EDxDgE,AAGR,CAC5D,AAJqE,GCyD3D,CDnDW,ACoDlB,IDvD4C,CAAC,QAC/B,CAClB,CAAC,AAF0D,GAI1D,SA4OY,AACd,CAA+B,CAC/B,CAAqC,CACrC,CAAqB,EAAA,AAIrB,IAAM,CAnPiB,CAmPJA,GAAsB,EAAY,CAAC,EAPnB,AAOnB,KAAmC,CAAW,AAAtB,CAAuB,CAC3D,AAD4D,MAC3C,MAAL,CAAgC,EAAlB,EAAsB,EAAlB,AAAoB,GACpDC,GACE,EACA,CAAC,CAHuC,OACrB,CACP,aACW,CAAE,oBAAoB,CAAC,CAC9C,GAIJ,IAAM,EAA4BD,CAJpB,CACX,CAGqD,EAAY,CAClE,OADgE,CAAX,SAAxB,MACN,CACxB,CAAC,CASF,QARqB,IAAjB,GAA2D,EAAjC,EAAqC,EAAjC,AAAmC,GAArD,AACdC,GACE,EACA,CAAC,QAFkB,CACP,OAF2C,MAGhC,CAAE,oBAAoB,CAAC,CAC9C,GAIAD,KAAoD,OAA9B,EAAD,AAAa,AAA2B,CAA1B,CAA4B,MAJtC,AAIO,CAHjC,EAG8C,CAAC,CAAC,CACjD,MAAM,AAAI,KAAK,CAAC,mDAAmD,CAIvE,AAJwE,EAxQ9C,EAAqB,GAIzC,AAAc,IAAI,CAJ2C,CAIzC,AAJ0C,CAG5D,EAAaA,CACL,IADuC,AAHV,CAGW,EAAtC,MAAwB,AAAsB,CAAC,AAAtB,CAAuB,GAE9D,MAFiD,GAvJnD,AADc,CACyB,CACvC,CAAqC,CACrC,CAAoB,EAAA,MAIpB,MA8qBM,CA3hByB,CAgiBzB,EAnrBA,EAAwBA,GAAsB,CAPT,AAqrB3B,CA9qBgD,CAC9D,OAD4D,CAAX,KAAxB,EAmrBI,IAlrBV,CACpB,CAAC,MACmB,IAAjB,GAAuD,EAA7B,EAAiC,EAA7B,AAA+B,GAAjD,AACdC,GACE,EACA,CAAC,QAFkB,CACP,GAFuC,UAG5B,CAAC,EACxB,AAqqBE,EAAoC,CAAA,CAAE,CAGxC,AAAc,GAHJ,CAGQ,EAAE,GADLD,CACL,EANd,EAlqBoC,EAuqBiB,CAAC,KALb,CAKD,CAAC,AAJzC,CAI8D,CAAC,AAvqB5B,CAuqB6B,GAE9DC,GAAsB,CAF2B,CAEjB,AANb,AAnqBgD,CAyqBlC,AAzqBmC,CACnE,AAkqBkB,IAMW,GAAT,cAAkC,CAAC,CAAE,GAMxD,AAA6B,IAAI,EAAE,CAN+B,CAAC,CAGrCD,GAAsB,EAAY,CAClE,OADgE,CAAX,EAG1B,aAFJ,CACxB,CAAC,GAEAC,GACE,EACA,CAAC,KADO,GADW,cAEI,CAAC,CACxB,GAIG,IAnrBP,IAmrBe,AAnrBT,EAA4BD,GAAsB,EAAY,CAClE,MA8qB2B,CAC1B,AAhrB+D,CAAX,SAAxB,MACN,CACxB,CAAC,MACmB,IAAjB,GAA2D,EAAjC,EAAqC,EAAjC,AAAmC,GAArD,AACdC,GACE,EACA,CAAC,QAFkB,CACP,OAF2C,OAG/B,CAAC,CACzB,GAIJ,IAAM,EAAkBD,GAAsB,EAAY,CAAC,OAAtC,AAAmC,CAAX,EAJhB,CAC1B,EAGqE,CAAC,CAAC,MACrD,IAAjB,GAAiD,EAAvB,EAA2B,EAAvB,AAAyB,GACzDC,AADc,GACQ,EAAc,CAAC,MADU,EAC1B,CAAa,IAAgB,CAAC,CAAE,GAGvD,IAAM,EAAiBD,GAAsB,EAAY,CAAC,AAHY,CAAC,KAGnD,CAAmC,CAAX,IAA0B,CAAC,CACnE,AADoE,MACnD,MAAL,CAAoC,EAAtB,EAA0B,EAAtB,AAAwB,GACxDC,GACE,EACA,CAAC,KAH2C,GACzB,CACP,aACW,CAAE,iBAAiB,CAAE,YAAY,CAAC,CACzD,GAIJ,IAAM,EAA6BD,GAAsB,EAJvC,AAImD,CACnE,AAJC,OAGgE,CAAX,UAAxB,MACN,CACzB,CAAC,MACmB,IAAjB,GAA4D,EAAlC,EAAsC,EAAlC,AAAoC,GAAtD,AACdC,GACE,EACA,CAAC,QAFkB,CACP,QAF4C,KAGjC,CAAE,iBAAiB,CAAE,wBAAwB,CAAC,CACrE,GAIJ,IAAM,EAA+BD,GAAsB,EAAY,CACrE,OADmE,CAAX,GAJ5B,CAC3B,QAG+B,MACN,CAC3B,CAAC,AACE,MAAiB,MAAL,CAAkD,EAApC,EAAwC,EAApC,AAAsC,GACtEC,GACE,EACA,CAAC,QAFkB,CACP,UAF8C,GAGnC,CAAE,0BAA0B,CAAC,CACpD,GAIJ,IAAM,EAAkBD,GAAsB,EAAY,CAAC,OAAtC,AAAmC,CAAX,KAJb,AAIwC,CAHrE,AAGsE,CAAC,CAS1E,QARqB,IAAjB,GAAiD,EAAvB,EAA2B,EAAvB,AAAyB,GAA3C,AACdC,GACE,EACA,CAAC,MAH4C,EAC1B,CACP,aACW,CAAE,iBAAiB,CAAE,aAAa,CAAC,CAC1D,GAIqD,SAAS,AAA9DD,EAAgE,CAA1C,AAJP,CAChB,CAGmC,CAAC,OAAH,CAAX,GAAyB,CAAC,CAAC,CAClD,MAAM,AAAI,KAAK,CAAC,oDAAoD,CAAC,CAGvE,GAAIA,KAAwD,OAAlC,EAAD,AAAa,AAA+B,CAA9B,CAAgC,MAAnC,OAAiB,CAAC,CAAC,CACrD,MAAM,AAAI,KAAK,CAAC,uDAAuD,CAAC,CAG1E,IAAM,EAAaA,GAAsB,EAAY,CAAC,EAAtC,KAAmC,CAAX,AAAsB,CAAC,CAAC,AAC5D,MAAiB,MAAL,CAAgC,EAAlB,EAAsB,EAAlB,AAAoB,GACpDC,GAAsB,EAAc,CAAC,CADK,OACrB,AAAwB,CAAX,AAAY,CAAE,EAIpD,EAkEkC,EAAY,GAGrC,CAzEqD,CAAC,CCgJzD,ED1EsC,AAAsB,CAAC,EAGlD,EC4CX,EAAOuC,EAAH,CACF,MADqB,MACT,CACZ,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAmBJ,CArBa,GAEL,CAAC,GAmBD,MAnBC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,MAAM,CAClB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,AACU,GAAR,CAAY,CADV,AACW,AAAC,IACd,AACjB,EAAS,MAFkC,AAEnC,IADwC,CADD,IAEvB,CAAG,CACzB,OAAO,CAAE,EAAa,OAAO,CACR,EADA,IAMb,IAAI,CAAC,AAAC,GACPuI,GAA+B,GAI/C,CACC,CANiC,KAAI,AAKhC,AACC,AAAI,CAL+C,CAAC,GAK3C,CAL8B,AAK7B,iDAAiD,CAAC,CAI9D,MAAM,iBAAiB,CAC7B,CAA8C,CAAA,SAI9C,IAAI,EAAe,EAAX,AAAa,CACjB,EAAsC,CAAA,CAAE,CAC5C,GAAI,GADW,CACP,CAAC,SAAS,CAAC,UAAU,EAAE,CAC7B,CAD+B,KACrB,AAAJ,KAAS,CACb,4DAA4D,CAC7D,AACI,gBACC,GD5JJ,CC4JQ,CD5J4B,CAAA,CC4JzBW,AD5J2B,CAGxC,AAAiB,GAHP,CAGW,EAAE,CADrB,EAAgB1L,IACL,CADuC,CAAC,KAAtC,GAAwB,CAAC,EAAwB,CAAC,CAAC,GAEpEC,GAAsB,AAF8B,EAEpB,CAAC,CCwJgC,IDxJnC,GAAT,GAAuB,CAAC,CAAE,GAMxB,AAArB,IAAyB,EAAE,CAHzB,EAAoBD,CAHoC,CAAC,GAGH,CAC1D,EAEmB,MAH0B,CAAC,AAAzB,MACN,CAChB,CAAC,EAFwD,CAIxDC,GAAsB,EAAU,CAAC,KAAH,GAAT,OAA2B,CAAC,CAAE,GAMjD,AAAuB,IAAI,EAAE,CAH3B,EAAsBD,KAH0C,AAGR,CAHS,AAIrE,IAEqB,IAH0B,CAAC,EAAzB,MACN,CAClB,CAF2D,AAE1D,GAEAC,GACE,EACA,CAAC,KADO,GADW,IAEN,CAAE,cAAc,CAAC,CAC9B,AA8OU,SAAA,AACd,CAA+B,CAC/B,CAAqB,EAAA,AAErB,IAAM,EAAoC,AAlPlB,CAkPkB,CAAE,CAE5C,GAFc,GAJoB,EAMoB,IAAlDD,GAAsB,EAAY,AAAyB,CAAxB,CAA0B,MAA7B,CAAX,AAAsB,CAAC,CAAC,CAC/C,MAAM,AAAI,KAAK,CAAC,kDAAkD,CAAC,CAGrE,QACmE,IAAjEA,GAAsB,EAAY,AAAwC,CAAvC,CACnC,MADgC,CAAX,eAAqC,CAAC,CAAC,CAE5D,MAAM,AAAI,KAAK,CACb,iEAAiE,CAClE,CAGH,IAAM,EAAeA,GAAsB,EAAY,CAAC,IAAtC,GAAmC,CAAX,EAAwB,CAAC,CAAC,CACpE,GAAoB,IAAI,EAApB,EAAsB,CACxB,IAAI,EAAkB,EAClB,CAFU,IAEL,CAAC,IADwB,CAAf,EACF,CAAC,KAChB,EAAkB,EAAgB,GAAG,CAAC,AAAC,EADR,CAEtB,AAFuB,CACW,CADT,AAGjC,CAAC,CAFa,AAIjBC,AAHe,EADoB,AAAc,CAI3B,EAAU,CAAC,KAAH,GAAT,EAAsB,CAAE,UAAU,CAAC,CAAE,EAC3D,CAED,OAAO,CACT,EA5Q2B,EAwQkD,CAAC,CAnQ1D,AAAd,CAsQW,GAtQO,EAAE,CADlB,EAAaD,CACL,ECmIR,EDpI+C,CAJG,AAIF,CAJG,CACtD,AAGa,CCqIJ,CACP,IDtImC,AAAsB,CAArB,AAAsB,CAAC,GAE9D,MAFiD,GAtNrC,AACd,CAAuC,CACvC,CAAqC,CACrC,CAAqB,EAAA,AAIrB,GAAIA,AAA6D,SAiNnC,AAjN4C,EAAE,CAAlD,EAAD,AAAa,CAAC,GAPG,IAON,YAAsB,CAAC,CAAC,CAC1D,MAAM,AAAI,KAAK,CACb,6DAA6D,CAC9D,CAGH,IAAM,EAA4BA,GAAsB,EAAY,CAClE,OADgE,CAAX,SAAxB,MACN,CACxB,CAAC,CASF,QARqB,IAAjB,GAA2D,EAAjC,EAAqC,EAAE,AAAnC,GAChCC,AADc,GAEZ,EACA,CAAC,QAFkB,CACP,IACE,CAAC,CACf,CAJuD,OAQA,IAAvDD,GAAsB,EAAY,AAA8B,CAA7B,CAA+B,MAAlC,AAJP,CAIJ,AAHtB,KAGiD,CAAC,CAAC,CACpD,MAAM,AAAI,KAAK,CAAC,uDAAuD,CAAC,CAG1E,IAAM,EAAiBA,GAAsB,EAAY,CAAC,MAAtC,CAAmC,CAAX,IAA0B,CAAC,CAAC,AACpE,AAAiB,SAAS,GAAd,CAAkB,AAAkB,IAAI,EAAE,GACxDC,GACE,EAF4C,AAG5C,CAAC,QAFkB,CACP,GACC,CAAE,iBAAiB,CAAE,YAAY,CAAC,CAC/C,GAIJ,IAAM,EAA6BD,GAAsB,EAJvC,AAImD,CAHlE,AAID,OADiE,CAAX,UAAxB,MACN,CACzB,CAAC,CASF,GARkC,IAAI,EAAlC,AAAoC,GACtCC,GApCwC,CAAA,CAAE,CAsCxC,CAAC,OAFkB,CACnB,IACa,CAAE,GADP,AAFkB,cAGM,CAAE,wBAAwB,CAAC,CAC3D,QAMF,IADAD,GAAsB,EACb,AADyB,CAAC,CAEnC,MAFgC,CALJ,AAKP,CAJpB,iBAI4D,CAAC,CAAC,CAG/D,MAAM,AAAI,KAAK,CACb,oEAAoE,CACrE,CAGH,GACEA,KACA,OADsB,EAAD,AACZ,AADyB,CAAC,CAEnC,MAFgC,oBAA8B,CAAC,CAAC,CAGhE,MAAM,AAAI,KAAK,CACb,qEAAqE,CACtE,CAGH,QAA2D,IAAvDA,GAAsB,EAA0C,AAA9B,CAAC,CAA+B,MAAlC,CAAX,KAA2B,CAAC,CAAC,CACpD,MAAM,AAAI,KAAK,CAAC,uDAAuD,CAAC,CAG1E,IAAM,EAAgBA,GAAsB,EAAY,CAAC,KAAtC,EAAmC,CAAX,GAAyB,CAAC,CAAC,MACjD,IAAjB,GAA+C,EAArB,EAAyB,EAArB,AAAuB,GACvDC,AADc,GAEZ,EACA,CAAC,IAH0C,IACxB,CACP,GACC,CAAE,iBAAiB,CAAE,WAAW,CAAC,CAC9C,GAIJ,IAAM,EAAmBD,GAAsB,CAJ9B,CACd,AAGwD,CAAC,OAAH,CAAnC,AAAwB,MAA4B,CAAC,CAAC,CAS5E,QARqB,IAAjB,GAAkD,EAAxB,EAA4B,EAAxB,AAA0B,GAA5C,AACdC,GACE,EACA,CAAC,OAH6C,CAC3B,CACP,GACC,CAAE,iBAAiB,CAAE,cAAc,CAAC,CACjD,QAIkD,IAAlDD,GAAsB,CAJN,CAIkB,AAAyB,AAH5D,CAGoC,CAA0B,MAA7B,CAAW,AAAtB,CAAuB,CAAC,CAC/C,MAAU,AAAJ,KAAS,CAAC,kDAAkD,CAAC,AAIvE,EA2HiC,EAAY,GAGpC,GC6JH,EDhKqC,AAAsB,CAAC,EAGjD,ECkIX,EAAOwC,EAAH,CACF,MADqB,OACR,CACb,EAAK,EAAD,EAAmC,CACxC,CADY,AAEb,EAAc,EAAK,EAAD,IAAoC,CAA3C,AACX,CAD2B,MACpB,EAAK,EAAD,EAAQ,CACnB,CADkB,MACX,EAAK,EAAD,IAAU,CAEV,AAmBJ,CArBa,GAEL,CAAC,GAmBD,MAnBC,CACb,OAAO,CAAC,CACP,IAAI,CAAE,EACN,EADU,SACC,CAAE,EACb,IAAI,CAAE,IADkB,AACd,CAAC,SAAS,CAAC,GACrB,CADyB,CAAC,QAChB,CAAE,MAAM,CAClB,WAAW,CAAE,OAAA,EAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACvC,GAD0B,QACf,CAAE,MAAA,EAAA,CAAA,EAAO,IAAD,EAAC,AAAM,EAAA,IAAA,CAAA,EAAA,EAAE,GAAF,OAAA,CAAa,CACxC,EACA,CAF2B,GAEvB,CAAC,AAAC,GACE,EAAa,IAAI,EAAE,CADT,AACU,GAAR,CAAY,CADV,AACW,AAAC,IAE/B,EAAS,MAFkC,AAEnC,KAFuC,IAEvB,CAAG,CACzB,OAAO,CAAE,EAAa,OAAO,CACR,CAHN,CAEM,IAMb,IAAI,CAAC,AAAC,EARsC,SAQ3B,GDoY/B,ECpYmC,IAGnC,MDiYY,CAdZ,ACnXO,EDmX6B,CAAA,CAAE,ACnXF,CDwXtC,AAAuB,GALb,CAKiB,EAAE,CAH3B,EAAsBxC,KAAkC,CAC5D,IAEqB,IAH0B,CAAC,EAAzB,MACN,CAClB,CAAC,AAF0D,GAI1DC,GAAsB,EAAU,CAAC,KAAH,GAAT,SAA6B,CAAC,CAAE,GAInD,AAAY,IAAI,EAAE,CADhB,CACM,CADKD,KAAkC,CAAC,AAAtC,CAH4D,CAAC,IAGjB,CAAC,CAArB,AAAsB,CAArB,EAErCC,GAAsB,EAAU,CAAC,EAFc,GAEjB,CAAS,CAAC,CAAnB,AAAqB,GAIxC,AAAgB,IAAI,CAJ4B,CAI1B,AAJ2B,GAGhCD,GACL,EADuC,CAAC,QAAd,CAAC,CAAuB,CAAC,CAAC,GAElEC,GAAsB,CAF6B,CAEnB,CAAC,KAAH,GAAT,EAAsB,CAAC,CAAE,GAI5C,AAAY,IAAI,EAAE,CADhB,CACM,CAJgD,AAG3CD,CAH4C,IAGV,CAArC,AAAsC,MAAM,CAAC,CAArB,AAAsB,CAArB,EAErCC,GAAsB,EAAU,CAAC,EAFc,GAEjB,CAAS,CAAC,CAAnB,AAAqB,GAIxC,AAAa,IAAI,CAJ+B,CAI7B,AAJ8B,CAG/C,EAAYD,AACL,GC9Y0C,ED6YH,CAAC,CAAtC,MAA6C,CAAC,AAAtB,AC7Y2B,CD6YJ,AAAtB,AC7Y2B,GD+YjEC,GAAsB,EAAU,CAAC,CAFe,IAElB,EAAU,CAAnB,AAAoB,CAAE,GAGtC,CC/YH,CAAC,CAAC,AACH,EAEJ,CCxZM,AFiyBiD,CAAC,CAGxC,EEpyBJ,GAAoC,sBAAsB,CAwBhE,OAxBuC,QAwBxB,GACpB,CAAU,CACV,CAAiB,CACjB,CAAoB,EAAA,AAHU,UAK9B,IAAI,EAAW,CAAC,CACZ,EAAS,CAAC,CADF,AAER,EAAyB,AADnB,IACuB,EAArB,CAAkC,IAAI,KAAL,GAAa,EAAE,AACxD,CADyD,CACzC,QAAQ,CAE5B,EAFiB,EACjB,EAAW,EAAK,EAAD,EAAK,AAAZ,CACD,EAAS,GAAU,CAAb,AACX,IADsB,AAChB,EAAY,IAAI,CAAC,EAAR,CAAW,CAAC,QAAgB,EAAW,GAChD,CADmC,CAC3B,CADqC,AAAS,CAAC,AAC1C,CAAR,CAAO,GAAM,CAAC,EAAQ,EAAS,EAAX,CAC3B,CADmC,CAC1B,GAAa,CADyB,AACzC,CAD0C,EAElD,EADoB,CACH,CADe,EAAE,OACrB,EAAI,CAAY,CAE/B,IAAI,EAAa,CAAC,CACd,MADU,AAEd,KAeE,AAfK,GADW,EAgBZ,CAhBe,IACJ,GAAG,AAed,EAAA,MAdJ,EAcY,CAdD,IAcC,AAhB6B,AACR,CAAE,AAC3B,CAAS,EAAU,AAcf,IAAR,GAdsB,AAAQ,CAAC,CACjC,GAaU,CAbN,CAAE,EAAE,CACR,AAYU,IAZN,CAAE,AAYI,CAAA,CAXV,GADW,OACD,CAAE,MAAM,CAClB,WAAW,CAAE,CACX,UAAU,CAAE,EAAE,CACd,OAAO,CAAE,EACT,OADkB,AACX,CAAE,CACP,uBAAuB,CAAE,EACzB,WADsC,WAChB,CAAE,MAAM,CAAC,GAC/B,GADqC,CAAC,YACtB,CAAE,MAAM,CAAC,EAC1B,CAAA,AACF,CAAA,AACF,EAAA,CAAC,CACU,CAJ4B,CAAC,GAI7B,CAAA,CAAR,EAAU,MAAF,CAAE,AAAO,IAAA,CAAA,CAAA,AAAG,GAAiC,AAAC,CAArC,CAAuC,CAG5D,EAHqB,EAIrB,AAJqB,KAAA,CAIf,AADI,EAAE,CACA,CAJS,CAIV,AAJU,CAKrB,EALqB,GAUvB,EAVuB,CAOvB,AAPuB,GAOb,AAHkB,CAAC,CAMzB,CAHE,AAGF,AALY,GAAG,GAEA,CAGf,EAAA,MAAA,EAAA,AAL6B,GAAG,EAKhC,CAAQ,AAAR,CAAA,EAAU,EAAF,IAAA,CAAE,AAAO,EAAG,CAL4B,AAKhD,GAAoB,CAAA,CAAA,CAAA,CAAA,CAAA,AAAZ,GAA6C,AAAC,AAAlC,EAApB,AAAoB,EAAuC,GAAvC,AAApB,CAAA,IAAoB,AAA+C,CAA/C,AACtB,CADuE,KAKzE,GAAI,GAAY,EACd,GADU,CAAU,EACV,AADY,AAChB,KAAS,CACb,wEAAwE,CACzE,AAEJ,CACD,IAAM,EAAgB,MAAA,IAAJ,GAAU,EAAQ,KAAA,CAAA,CAAR,EAAU,EAAF,EAAM,EAAN,AAAM,AAAN,CAAQ,CAAA,AAI5C,CADC,CAH2B,CAIxB,OAAA,AAJgC,EAIhC,GAJgC,IAIhC,CAJgC,CAIhC,AAJgC,KAIhC,CAAA,AAAQ,CAAR,EAAU,EAAF,IAAA,CAAE,AAAO,EAAG,CAApB,GAAoB,CAAA,CAAA,CAAA,CAAA,CAAA,AAAZ,GAAY,AAAiC,AAAC,EAAlC,AAApB,EAA2D,GAAvC,AAApB,CAAA,GAAkE,CAA9C,AACtB,CADsB,AAAgD,KAChE,AAAI,KAAK,CAAC,wDAAwD,CAAC,CAE3E,OAAO,EAAa,IAAe,AACrC,CAEO,CAHqB,IAAP,UAGC,GAAY,CAAU,EAAA,AAE1C,KAF+B,CACJ,CAAC,AACrB,IADyB,CAAE,EAAK,CACxB,CADuB,EAAK,CAAE,IAAI,CAAE,EAAK,EAAD,EAAK,CAE9D,AAF+D,CAIzD,SAAU,GAAM,CAAU,CAAX,CAAW,AAC9B,OAAO,IAAI,OAAO,CAAC,AAAC,GAAmB,UAAU,CAAf,AAAgB,EAAgB,EAAE,CACtE,AADuE,CAAC,ACzGrE,MAiBU,EDwFqD,CCvFhE,MAAM,GADiB,CACb,AADa,CACZ,CAAmB,CAAA,CAC5B,IAAM,EAAqB,CAAC,IAAI,CAAE,AAApB,CAAqB,CAAE,IAAI,MAAE,CAAS,CAAC,OAAD,AACpD,AAAoB,QAAQ,EAAE,AAA1B,OAAO,GAET,CAFa,CAEJ,IAAI,CAAG,CAAR,AADa,MAAM,EAAE,CAAC,EACF,EADM,CAAC,EAAI,CAAC,CACX,IAAI,CACjC,EAAS,IAAI,CAAG,CAAR,GAAY,CAAC,aAAa,CAAC,GAC5B,CADgC,CAAC,CAGjC,KAFQ,CAEF,GAAY,GAI7B,CAJiC,CAAC,GAAN,CAItB,MAAM,CACV,CAAmB,CACnB,CAAiB,CACjB,CAAoB,CAAA,OAEpB,AAAoB,QAAQ,EAAxB,AAA0B,OAAnB,EACF,EADM,IACA,IAAI,CAAC,kBAAkB,CAAC,EAAM,EAAF,AAAa,GAE/C,GAAW,CAFkC,CAE5B,CAFuC,CAEzC,AAF0C,AAE7B,GAU/B,AAVa,IAAgB,EAAW,CAAC,MAU5B,CAAC,CAAgB,CAAA,CAwFpC,MAHiB,CAhF0B,AAmFpC,CAlFL,IAAO,CAAF,EAkFQ,QAlFK,CAClB,IAAO,CAAF,sBAAyB,CAC9B,IAAO,CAAF,sBAAyB,CAC9B,IAAO,CAAF,gBAAmB,CACxB,IAAO,CAAF,6BAAgC,CACrC,IAAO,CAAF,yBAA4B,CACjC,IAAO,CAAF,UAAa,CAClB,GAAM,CAAF,mBAAsB,CAC1B,IAAO,CAAF,oBAAuB,CAC5B,IAAO,CAAF,kBAAqB,CAC1B,IAAO,CAAF,SAAY,CACjB,IAAO,CAAF,SAAY,CACjB,IAAO,CAAF,mBAAsB,CAC3B,KACE,CADI,wEACqE,CAC3E,IAAO,CAAF,8BAAiC,CACtC,KAAQ,CAAF,qBAAwB,CAC9B,GAAM,CAAF,iBAAoB,CACxB,IAAO,CAAF,UAAa,CAClB,IAAO,CAAF,UAAa,CAClB,KAAQ,CAAF,UAAa,CACnB,IAAO,CAAF,yBAA4B,CACjC,IAAO,CAAF,cAAiB,CACtB,IAAO,CAAF,yBAA4B,CACjC,KAAQ,CAAF,WAAc,CACpB,IAAO,CAAF,WAAc,CACnB,GAAM,CAAF,gBAAmB,CACvB,KAAQ,CAAF,iBAAoB,CAC1B,OAAU,CAAF,oBAAuB,CAC/B,IAAO,CAAF,qCAAwC,CAC7C,IAAO,CAAF,qCAAwC,CAC7C,IAAO,CAAF,gBAAmB,CACxB,IAAO,CAAF,WAAc,CACnB,IAAO,CAAF,UAAa,CAClB,KAAQ,CAAF,WAAc,CACpB,KAAQ,CAAF,oCAAuC,CAC7C,IAAO,CAAF,wCAA2C,CAChD,IAAO,CAAF,UAAa,CAClB,IAAO,CAAF,UAAa,CAClB,IAAO,CAAF,gBAAmB,CACxB,KAAQ,CAAF,WAAc,CACpB,IAAO,CAAF,SAAY,CACjB,IAAO,CAAF,UAAa,CAClB,IAAO,CAAF,gBAAmB,CACxB,IAAO,CAAF,wBAA2B,CAChC,IAAO,CAAF,8BAAiC,CACtC,KACE,CADI,0EACuE,CAC7E,IAAO,CAAF,oBAAuB,CAC5B,IAAO,CAAF,gBAAmB,CACxB,GAAM,CAAF,iBAAoB,CACxB,IAAO,CAAF,cAAiB,CACtB,IAAO,CAAF,8BAAiC,CACtC,IAAO,CAAF,kBAAqB,CAC1B,IAAO,CAAF,WAAc,CACnB,KAAQ,CAAF,WAAc,CACpB,GAAM,CAAF,WAAc,CAClB,IAAO,CAAF,SAAY,CACjB,IAAO,CAAF,WAAc,CACnB,IAAO,CAAF,sBAAyB,CAC9B,IAAO,CAAF,UAAa,CAClB,KAAQ,CAAF,WAAc,CACpB,KAAQ,CAAF,WAAc,CACpB,KAAQ,CAAF,WAAc,CACpB,KAAQ,CAAF,UAAa,CACnB,MAAS,CAAF,WAAc,CACrB,MAAS,CAAF,sBAAyB,CAChC,IAAO,CAAF,yBAA4B,CACjC,KACE,CADI,kEAC+D,CACrE,IAAO,CAAF,gBAAmB,CACxB,IAAO,CAAF,gCAAmC,CACxC,IAAO,CAAF,gBAAmB,CACxB,KAAK,CAAE,YAAY,CACnB,KAAK,CAAE,aAAa,CACpB,IAAI,CAAE,6BAA6B,CACpC,CAGyB,CAnFJ,AAmFK,EAnFI,KAAK,CAAC,AAAP,EAAgB,GAmFN,GAnFK,KAAY,CAAC,GAAG,CAAC,CAAG,CAAC,CAAC,CAmF1B,WAAW,EAAE,CAAC,CAMjD,MAAM,kBAAkB,CAC9B,CAAY,CACZ,CAAiB,CACjB,CAAoB,CAAA,eAMhB,EAJA,EAAW,CAAC,CACZ,EAAS,CAAC,CADF,AAER,AAEqC,EAH/B,AACmB,IAAI,EAArB,CAAkC,IAAI,KAAL,GAAa,EACtD,AADwD,CAAC,CACzC,QAAQ,CAE5B,EAFiB,CAEb,CAEF,GAAI,CAAC,CADL,EAAa,MAAM,CACJ,CADL,AAAW,CAAC,AACL,IADS,CAAC,EAAM,EAAF,EAAK,CAAC,CAEnC,MAAU,AAAJ,KAAS,CAAC,CAAA,mBAAA,CAAqB,CAAC,CAGxC,IADA,EAAY,AAAD,MAAH,CAAU,EAAW,IAAI,EAAA,CAAE,CAAP,AAAS,IAAI,CAClC,EAAS,GAAU,CAAb,AACX,IADsB,AAChB,EAAY,IAAI,CAAC,EAAR,CAAW,CAAC,ADrJL,IAAI,GAAG,CCqJc,EAAW,CDrJrB,ECsJ7B,CDtJgC,ACqJK,CAC5B,ADtJwB,CCqJc,AAAS,ADrJtB,CCqJuB,ADrJvB,CCsJZ,CAAhB,GACR,EADoB,CACH,ADvJmB,CCsJJ,EAAE,OACrB,EAAI,CAAY,CAE/B,IAAM,EAAS,IAAH,AAAO,UAAU,CAAC,GACxB,CAAC,KADgC,CAAC,GACxB,CAAE,CAAS,CAAC,CAAG,MAAM,EAAW,IAAI,CAClD,EACA,CAAC,AAF4C,CAG7C,EACA,AAHM,GAMR,GAHQ,AAGJ,CAJO,AAEV,GAEiB,EAChB,GADW,GACL,AAAI,CADe,EAAE,EACZ,CACb,CAAkB,eAAA,EAAA,EAChB,OADyB,oBACzB,EAAA,EACwB,IAA1B,mBAA0B,EAAA,EAAW,CAAA,CACtC,CAGH,IAAM,AAJiC,EAIzB,GAAH,CAAO,IAAI,CAAC,CAAC,EAAO,CAAC,CAC5B,EAD0B,AACb,CAAC,CACd,EDzK0B,IC0K9B,AAFc,ADxKoB,KC0K3B,AAeL,ED1LqB,CC0KL,AD1KM,GC0LlB,AAhBe,IACJ,GAAG,AAed,EAAA,OAdJ,CAcY,CAdD,IAF8B,AACR,AAerB,CAfuB,CAC3B,AAAS,EAcL,AAde,IAcvB,GAdsB,AAAQ,CAAC,CACjC,GAaU,CAbN,CAAE,EAAE,CACR,AAYU,IAZN,CAAE,AAYI,CAAA,CAXV,GADW,OACD,CAAE,MAAM,CAClB,WAAW,CAAE,CACX,UAAU,CAAE,EAAE,CACd,OAAO,CAAE,EACT,OADkB,AACX,CAAE,CACP,uBAAuB,CAAE,EACzB,WADsC,WAChB,CAAE,MAAM,CAAC,GAC/B,GADqC,CAAC,YACtB,CAAE,MAAM,CAAC,EAC1B,CACF,AADE,CACF,AACF,EAAA,CAAC,CACU,CAJ4B,CAAC,GAI7B,CAAA,CAAR,EAAU,MAAF,CAAE,AAAO,IAAA,CAAA,CAAA,AAAG,GAAiC,AAAC,CAArC,CAAuC,CAG5D,EAHqB,EAAA,AAIrB,KAJqB,CAGX,AACJ,EADM,CACA,CAJS,CAIV,AAJU,CAKrB,EALqB,CDxLC,CAAC,CCkMzB,EAVuB,CAAA,AAOvB,GAH4B,AAGlB,CAHmB,CAO3B,CANc,AAMd,AAJI,GAFa,GAEA,CAIjB,EAAA,MAAA,EAAA,AAN+B,GAAG,EAMlC,CAAA,AAAQ,CAAR,EAAU,EAAF,IAAA,CAAE,AAAO,EAAG,CAN8B,AAMlD,GAAoB,CAAA,CAAA,CAAA,CAAA,CAAA,AAAZ,GAAY,AAAiC,AAAC,EAAlC,AAApB,EAA2D,GAA3D,AAAoB,CAApB,IAAoB,AAA+C,CAA/C,AAEpB,CADA,KAGF,GAAI,GAAY,EACd,GADU,CAAU,EAAE,AAChB,AAAI,KAAK,CACb,wEAAwE,CACzE,AAEJ,CACD,IAAM,EAAgB,MAAA,IAAJ,GAAU,EAAQ,KAAA,CAAA,CAAR,EAAU,EAAF,EAAM,EAAA,AAAN,CAAQ,CAAA,AAI5C,CADC,CAH2B,CAIxB,OAJgC,CAIhC,EAAA,EAJgC,IAIhC,CAJgC,CAIhC,AAJgC,KAIhC,CAAQ,AAAR,CAAA,EAAU,EAAF,IAAA,CAAS,AAAP,EAAU,CAApB,GAAoB,CAAA,CAAA,CAAA,CAAA,CAAA,AAAZ,GAAY,AAAiC,AAAC,EAAlC,AAApB,EAA2D,GAAvC,AAApB,CAAA,GAAkE,CAA9C,AACtB,CADsE,AAAhD,KAChB,AAAI,KAAK,CACb,wDAAwD,CACzD,CAEH,OAAO,EAAa,IAAe,AACpC,EAD2B,IAAP,EACX,CAEJ,GACF,MAAM,CADM,CACK,CADH,IACQ,EAAE,AAE3B,CAFmB,CAIvB,CCrDD,SAAS,GAAO,CAAW,EAAA,AAAZ,UACb,OAAO,OAAA,EAAA,OAAA,EAAA,OAAA,EAAA,OAAO,KAAP,EAAO,EAAP,GAAO,CAAP,CAAA,MAAO,CAAA,CAAE,GAAG,AAAL,AAAE,EAAG,GAAL,CAAK,CAAA,CAAA,CAAA,CAAA,CAAG,EAAG,AAAC,CAAP,CAAO,CAAP,GAAO,CAAA,CAAA,AAAP,CAAO,CAAA,CAAA,AAAE,EAAT,CAAO,AAAP,CAAa,CAAN,CAAM,CAAE,CAAA,EAAR,AAAQ,GAAA,EAAI,AAAZ,CAC5B,AAD4B,C3IxL5B,A2IwLoC,IAAA,EAAA,CAAa,E3IxLxC,E2IwL2B,C3IxLJ,CAAQ,CAAE,CAAK,CAAE,A2IwLb,CAAA,A3IxLkB,CAAE,CAAI,CAAE,CAAC,EAC3D,GAAa,MAAT,EACA,MAAU,AAAJ,UAAc,kCACxB,GAAa,MAAT,GAAgB,CAAC,EACjB,MAAM,AAAI,UAAU,iDACxB,GAAqB,YAAjB,OAAO,EAAuB,IAAa,GAAS,CAAC,EAAI,CAAC,EAAM,GAAG,CAAC,GACpE,MAAM,AAAI,UAAU,2EACxB,MAAgB,MAAT,EAAe,EAAE,IAAI,CAAC,EAAU,GAAS,EAAK,EAAE,KAAK,CAAG,EAAS,EAAM,GAAG,CAAC,EAAU,GAAQ,CACxG,CACA,SAAS,GAAuB,CAAQ,CAAE,CAAK,CAAE,CAAI,CAAE,CAAC,EACpD,GAAI,AAAS,SAAO,CAAC,EACjB,MAAM,AAAI,UAAU,iDACxB,GAAqB,YAAjB,OAAO,EAAuB,IAAa,GAAS,CAAC,EAAI,CAAC,EAAM,GAAG,CAAC,GACpE,MAAM,AAAI,UAAU,4EACxB,MAAgB,MAAT,EAAe,EAAa,MAAT,EAAe,EAAE,IAAI,CAAC,GAAY,EAAI,EAAE,KAAK,CAAG,EAAM,GAAG,CAAC,EACxF,8B+FTU,CAAA,CAAA,CAAA,oGAMW,EAAA,IAAe,EAAA,eAAsB,CAAC,EAAE,AAAC,CAAC,EAAA,CAAM,IAAA,AAAoB,IAApB,KAAY,MAAM,EAAE,CAAW,CzEkBC,gDyEjBrD,OAAA,CAAA,SAAkB,GAC9D,CAAE,AAAF,EAAE,IAAqB,EAAE,EAAK,AAAC,CAAC,EAAG,CAAC,AAAG,CAAF,AAAG,AAAC,QAAQ,CAAC,EAAE,CAAC,CACtD,CAAC,eCe2H,CAC1H,CAAC,6FEtB6B,EAAA,OAAA,EAAA,QAA6B,CAAA,gCAAA,MAInD,GAAA,2EAI4B,kDAAA,GAA2B,6CAEO,CAAE,CAAC,AxDgDI,CAAA,GwD3C1E,gCAJsC,gCAEW,KAAA,wBACd,EACnC,mI9CAsC,CAAA,CAAA,CAAA,CAAA,2BACJ,C6CtBW,AvE6BR,CkEyCD,AKtEU,A1EKC,A6BiBN,GAAQ,CAAE,CAAC,EAAJ,CAAC,0FAOzC,CAAA,eACF,IAAA,8RAgCsB,SAAE,QAAgB,GAAY,sBAGC,UAE3C,UACS,EAAQ,EAAO,CuClBG,AjFsB+B,CAAA,4C0CInC,EAAA,EAAgB,wBAIR,0CAQb,E+CFhB,A/ErBkB,AsFDE,CPsBpB,CAAA,E/CEwC,sBAInB,EAAS,C3C3BG,CgBiDA,qC2BfX,CiDyQT,GjDvQtC,iJASsB,CAAA,MAAA,CAAA,CAAA,CAAA,mBACF,EAAA,GAAA,yBAA2C,C3BmBD,U2BhB5C,CAAC,KAAK,CAAA,CAAA,oBAIsB,8CAE1B,GAAA,yCAIgB,C7CyBD,AqFeF,AlDbF,oBUzBS,UAE5B,WAAA,IAEP,MAAA,WAAA,0CAIwC,C/CVrB,CAAC,Q+CYb,C1CuCH,UAAA,I0CrCJ,MAAO,WAAA,qBAEgC,uBAEnC,kEAAkE,CAAC,CAAC,CAIxE,E3B6BuE,EAAE,E2B7BzE,WAA8C,E6BoEA,oB7BlE3C,CAAA,oFAAqF,CAAC,CAAC,6CAMtF,yDblJwE,CjBahC,AiBbiC,A0DNhD,C3EmBe,IiBb+C,CL0BhC,AiCgBuB,AarCA,AzCLU,CyCKT,AzCLU,A4B0CV,0E5BjBzE,SAAA,UAAA,OAAA,GAAA,CAAA,MAAA,OAAiD,CAAA,uC6ClCc,EAAS,EAAE,CAAC,CCsBpD,ADtBqD,CAAN,AAAO,gBpC8J9E,QAAT,EAAuB,YxChK8B,kCwCkK9B,MACd,C1ClBD,CAAC,a0CkBsB,A1ClBtB,UAAA,E0CkBsB,QAC/B,C4CkDD,CAAA,CAAA,MAAA,EAAA,EAAA,CAAA,W5C9CC,CqD4PD,EAAA,ArD5PsB,MAOd,EAAA,WAAoB,EAAA,kBAMM,MACrC,YAAA,EAAA,uBACkC,oBACD,UAC7B,AAAa,CtC4Dd,asC5Dc,UACA,E1CVJ,AJnBA,A0FmGI,YAAA,8B5CpEb,CiCwGD,AoBmKY,CrD3QM,CAAA,MAAA,EAAS,EAAA,CAAU,CAAC,6OgDvJ3B,GAAA,CAA8D,mCAE/B,CAAC,OAAA,aAAoB,CAAA,GAAA,CAAA,CAAe,OAAO,C7FlBlF,CqCYgC,ArCZ/B,CqCY+B,KwDM0D,CAAC,kEAK1D,IAAI,0DAQtB,CvFjBH,AuC4BI,0BgDCZ,CAAA,OAAA,aAAA,CAAA,CAAA,OAAA,oDAMW,MAAA,EAAa,IAAI,GAEhC,kBADyB,WAAA,GACzB,CADwC,kBAGjC,WAAA,aAH2E,GvEgCT,cuExB9C,CtEID,AViBI,KgFrBG,WALgC,gDAUpE,OAAA,aAAoB,CAAA,mCAUkB,CAAA,4CAGrC,CAAA,CAAA,OAAc,aAAa,CAAC,ChDcD,AwCdA,kDQCc,yBAKvC,EAAgB,EAAO,CFJD,KAAA,mDXb6B,CAAA,CAAA,+DAK5C,SAAA,CAAA,QvEzFuB,aACL,GAAA,OAA2B,CAAC,mCAEZ,CsEUP,ASbH,A9DKA,A+BGA,A/CIM,A+EQN,CFnBC,C7EWO,A+EQN,AxBfA,A1DyBF,IAAA,qBJ5BrB,EAAA,IAAA,CAAA,GAAA,OACO,MAAM,EAAI,G2EwBsB,AvDhBE,MpBRf,SAAS,CAAC,IAAI,CAAC,E2EwBqB,CAAC,C3ExBlB,CAAC,KoBQ0B,CpBRpB,AoBQqB,CAAA,SpBRX,CAAC,eAAc,CAAC,CAAC,EAAA,OAI9D,8EAGyB,WAAW,iBAmPjE,SAAA,GAAuB,CAAQ,CAAE,CAAe,CwFVtB,CxFW9B,GAAA,GAAA,GAAkB,KACV,CwFVC,CAAA,EAAA,KxFWF,IAAA,EAAA,EAAW,CAAC,CAAA,EAAO,MAAM,CAAA,GAAA,EAAU,AACtC,CADuC,CD6BnC,EwFkDsC,ExFlDtC,CC5BQ,EAAA,CAAA,CAAA,EAAA,mBAIT,EAAA,EACT,+ED7PkC,EAAA,+EAQ2C,GAAgB,CAAC,sBAM5E,+CAGH,qFAKI,WCsGN,CAAA,EAAA,EAAA,EAAA,EAAA,uFAeyB,CAAC,CmBgDP,AoE6BE,AXnDM,GAAA,CAAA,G5EzB3B,UAAA,OAAA,MACA,CDKC,MAAA,EAAA,gFCAD,SAAA,SAAA,EAAA,KAA4B,CAAC,GAAA,IAAA,cAI9B,iDAEqB,CqG5EG,AJ2IN,CjG7FhB,EA8BuB,GAAQ,EAAO,KAAK,CAAC,CAAC,CAAA,QAAe,qBAGlD,CsFyEc,CtFzEN,MAAM,CAAE,EAAE,CAAC,CAAE,C2EqGH,A3ErGI,C2EqGH,kB3EpGV,CAAC,CAAC,4BAKrB,SAAA,GAAA,E8FkGyF,CAAC,CAAC,A9FlG3F,GAAA,IAEL,CAAC,A2EwGA,EAAA,IAAA,GAAA,IAAA,GAAA,IAAA,GAAA,KAAA,YAAA,I3EtGuB,KAAD,CAAC,CAAb,CAAa,AAAmB,CsFiFX,CCDa,GvFhFrB,CuFgFqB,CvFhFE,C2E4GS,A3E3GzD,ADQmD,ACTF,CAAE,IAE3C,EAFiD,IAEjD,CAAA,CAAA,EAAA,MAAwB,CAAC,CAAC,EAClC,mBAIA,CuFgFC,AvFhFE,CAAA,EAAA,MAAW,CAAC,CAAG,EAAA,CAAU,CAAC,ADWhB,CAAA,sBCNV,CAAA,EAAA,MAAW,CAAA,CAAI,EAAA,CAAA,IAAA,GAAA,EAA2B,CAAA,EAAY,CAAA,IAAA,AAAa,CsFkF1C,EtFlF6B,EsFkF7B,sBtF9EZ,CAAC,AqG1EA,EAAA,MrG0EY,CAC7B,CiGyDC,AjGzDE,CAAC,E8FyGM,A9FzGF,MAAM,CAAA,CACZ,EiGyDI,CjGzDM,IAAQ,GAAK,GAAK,CAAG,EAAS,CAAC,IAAI,AAAK,GAAK,CAAC,C2FoBtC,A3FpBuC,AAAG,GAAM,CAAA,EAAY,CAAC,IAAI,AAAQ,GAAJ,CAAC,AAAO,CAAE,CAAC,SAItG,CAAC,EAAA,IACG,OAAY,CAAA,KAAA,CAAA,GAAe,CDiCK,ECjC0B,KAAxB,EAAA,UAAkB,CAAC,CAAC,CAAC,AmB2EE,AnB3EC,CAAM,CAAC,CAAC,CAElE,AD+BuE,CyFxC/C,CxFSpB,MAAA,CAAA,CAAA,EAAA,CACI,IAAA,GAAa,C+FwRK,C/FxRH,CAAA,CAAA,EAChB,CAAC,IAAS,CAAC,EAAI,GAAM,CiGuDK,EjGvDC,C2FzDpB,EAAA,C3F0DN,IAAA,GAAc,EAAA,GAAW,CAAA,EAAA,CAAA,IACb,GAAJ,C2FzDW,A3FyDV,AAAO,C2FzDI,A3FyDH,AAC/B,CAAC,SAEc,CAAA,WAGV,uDD5KE,CwF8HD,exF7HM,4BAC8B,CAAC,IAAA,CAAA,IAAA,CAAU,KAAA,SAAc,CAAA,YAAY,CAAC,CAAA,CAAC,AAAC,IAAI,CAAC,CAAC,IsFOzC,yBtFJ7B,0CFxBmC,EAAA,+BAAA,MAAA,CAAA,IAAA,CAAA,EAAA,CAA2C,EAChG,mCAQ+C,EAAoB,CsB8CV,AiDhDA,ANAA,MjEExC,WAAA,WAA8B,EiEFU,MAAA,CjEEyB,IAAA,CAAA,EAAA,CAAA,EAAA,8JqFD5E,EAAA,aAAA,YAC2B,ClDJD,GAAA,WAAA,GAAA,UAAA,OAAA,EAAA,GAAA,GAAA,akDQjB,SrFjCH,AOAM,CNCa,ACDlB,AKAK,CHAM,ADAV,EEAE,ACAA,ACAA,CCEC,CFFC,ACAA,CPChB,CyBCG,AuCAA,AlCAA,ACQA,AgCRA,A9BAA,A9BAA,A+BAA,A3Ba8B,A0Db9B,ACAA,ACAA,ACEP,AOFO,ACAA,ACAA,A3EDA,AmECA,ACAA,ACAA,ACAA,ACAA,AvBAA,AwBAA,AvCAA,ACAA,ACAA,AjCAA,AkCAA,ACAA,ACAA,ACAA,ACAA,AhBAA,ACAA,ACAA,ACAA,AcAA,ACAA,ACAA,ACAA,ACAA,ApCAA,AqCAA,ACAA,ArCAA,AEAA,ACCP,ACDO,ACAA,ACAA,ACCA,ACDA,ACAA,ACAA,ACAA,AVAA,AWAA,A2BAA,ACAA,ACAA,ACAA,ACAA,ACAA,AzDDA,A8DCA,ACAA,AFAA,ADAA,ADAA,ADAA,AzBAA,CkBAA,oBlDCK,EAAA,MAAA,6EqF8BiB,iBAAe,iBAEhB,MAE2D,IAAI,KAgD7F,C/EHG,CAAC,OAAA,CAAA,CAAA,C+EKuB,MAKpB,IAAA,EAAQ,GAAA,EAAA,EAAA,EAAA,MAAA,CAAoC,CAAC,GAAI,yCAEhB,EAAG,C/DuCC,CoBzCD,O2CEU,EAAK,CpCoBI,AoCpBF,C/DuCC,A+DvCA,SAJpC,KAAK,sCAQuB,CAAI,CAAE,CAAC,oBA7DZ,CAAA,GAAA,KAAU,GAAA,IAAI,CAAA,GAAA,KAAqB,CAAC,CAAC,CAAU,CAAC,e/EL5D,M+EMD,C/ENC,EAAA,IAAA,CAAA,GAAA,K+EMkC,CAAC,ArDgB1D,aqDdoC,KAAK,CesIhC,2Cf/HA,KAAA,GAAA,GAAA,IAAA,CAAA,GAAA,KAAA,GAA2C,EAAa,QAAA,AAAQ,CAAC,CAC/E,CAAC,MACS,CAAA,G7EuCmG,A6EvCnG,C7EwCX,CAAC,C6ExCU,IAAA,CAAA,GAAA,CKwH+D,ILxH/D,QAAiC,CAAC,CAAC,CAAA,GAAE,IAAI,CAAA,GAAA,IAAqB,CAAG,CAAC,CAAC,CAAC,CAAC,CAAC,AAChF,CXEG,EWFH,IAAA,CAAA,GAAe,GAAA,IAAI,CAAA,GAAA,KAAA,QAAiB,CAAC,GAAA,IGFiB,AHEb,CGFkC,GAAA,MHEZ,IAAA,CAAC,WACpC,KAAA,oBAKE,uBAAA,EAAoB,SAAS,CAAG,CAAC,CAAC,AAAE,CAAD,CAAc,SAAS,CAAV,AAAW,qBAEtD,CzCX6C,CAAC,CAAC,ExBId,GAAA,CiEOxB,CAAC,CAAA,yBAGhC,GpCcsC,AdtBJ,AkDQlC,IAAI,CAAA,GAAA,IAAQ,CAAC,QAAQ,CAAC,EAAa,KAAK,CAAC,CAAA,GAAP,CAAO,CAAC,gBACzB,mDAOV,EAAE,CAAC,kDAzDtB,GAAA,aAAA,CAAA,IAAA,IAAA,+BACiB,4ExEaxB,QAEK,wFAOyB,KAAK,SAAA,CAAU,GAAA,kBAAA,EAAgC,KAAK,SAAS,CACvF,MAAM,CAAC,IAAI,CAAC,KACb,CAAE,CACJ,CAAC,IAF0B,CAAC,CAC1B,4BAOmF,8GAkB9D,CAAc,+BAEF,kCAKE,CAAA,SAClB,CkEsBG,AY3BZ,AECU,AfkEJ,AxElFM,CwEkFN,EAAA,GAAA,gFjEvDiB,0CAIR,OAEnB,EAGF,IAAA,GAAA,uCAamC,kDAIpB,OAAA,WAAkB,CAClC,CAAA,EAAS,OAAA,YAAA,QAA6B,aAAmB,CAAC,CAAC,AAAE,CAAD,KAAO,CAAC,OAAO,CAAC,EAAQ,KAAD,GAAQ,CAAC,CAAC,AAAC,GAAG,CAC/F,CAAC,CAAC,EAAM,EAAF,AAAQ,EAAE,CAAG,AAAN,CAAK,EAGd,kBAAA,EAAA,WAAA,IAAA,WAAA,EAAA,WAAA,IAAA,eAAA,EAAA,WAAA,GAAA,MAAA,oEAYY,EAAQ,mBAAA,SAErB,EAAA,mBAA2B,CAAC,iJ8EnFpB,EAAA,GAAA,GAAA,8JASa,GAAA,EAAA,yCAGa,CpEGO,ApBbE,AwFUR,yCAKC,UAAU,CAAC,YAiB9C,IAAA,EACA,GAAA,cACoB,EZ2Bc,IAAA,CY1BlC,CAAC,AzFOU,AAAC,MAAA,EAAA,oByFNG,CAAA,oCAAqC,CAAE,C1CcS,AzCyBA,CyCzBA,IAAA,gB0Cb/C,aAAa,CAAE,EAAI,GAAG,OAIrB,CHHO,ArFAI,QwFGF,8BACW,KAAK,CnE4CS,AFPA,AqErCP,EAAA,OAAA,CAAA,KAAA,EAE5C,MAAA,oBAAgC,OA7B0B,aAIjD,CvDbe,IAAA,KAAA,CAAA,EAAA,IuDaI,QACnB,EAAA,mDAC0C,CAAE,E1EdW,I0EcH,CAAC,CAAC,A5CLS,O4CM1D,CAAA,cAAA,EAAoB,CZ0Ba,CAAC,CAAA,EYzBxC,QAGI,EAAA,KAAA,WACA,QAAS,EAAW,EAAA,KAAU,MAAE,EAAA,EAAoB,OAAO,CAAC,CAAC,WDwT/D,yDC3RlB,CvBqkLK,AuBrkLJ,WAEU,GAAA,EAAiB,EAAY,CnBgBH,CMkEqC,4Ba1E5C,C5FXK,A4FYnC,CzFOqC,AyFPV,CAC3B,CAAe,C5FbwC,wD4FqBpC,CrE4CG,OqE7C8B,cAAc,CAAC,CAAC,G9CmBO,K8CjBlC,CAAC,GACpC,CKyDS,GL1DmC,CAAC,AFuD0B,CJxDrB,AW2DzC,iBLrDkB,CnBeL,A3BIQ,I8CnBE,GAAI,AACtC,CADuC,KACjC,aA0BC,wBArBL,YACQ,GAAA,+EAED,MACP,EAAA,CAAA,gBAES,C5FZK,GAAA,KAAA,K4FaV,MAAM,0BAId,CAAA,MAAS,EAAA,gBAGP,OAAA,UAGK,ExFKU,A0CiBA,AiC6EN,CanGE,EAAW,KAAA,KAIE,EAAY,GzFWK,iByFR9C,OAAO,aAAA,AAAa,EAAC,EAAA,qBACA,EzFaE,AyFbA,WAQhB,EAAA,EAAA,CACA,EAAA,EAAA,CACA,EAAW,IAAI,CAAA,QAAA,GAEf,EAAc,+BAGU,CAAC,AACvB,IAAM,EAAA,EAAkB,IAAA,KACnB,IAAI,CAAC,SACA,CAAA,GAEZ,CrE4ES,A4E6MU,ATjMZ,MnEZE,EAAA,KqE5ES,wBAML,EAAA,GAAmB,ErE+EE,EAAA,CAAA,UqE/Ea,CAAE,GAAA,IAAI,CAAA,GAAA,IAAQ,CAAC,QACvD,IAAM,EAAY,GAAA,IAAA,CAAA,UAAuB,CAAE,GAAA,IAAI,CAAA,GAAA,MAE9D,CAAC,ApF8EA,AeCA,A4E2MA,uBPjRK,gBAEG,GAAA,OACC,mBACe,aAAa,CAAA,UAE5B,KAAK,CMiHU,AlGvIL,A4FsBI,EAClB,GO+RkB,AP/Rd,EO+RgB,CAAC,gBP9RA,Ca9DK,CAAA,MAAA,Eb8DW,Ea9DM,EAAA,Gb+DzC,GAAI,EAAA,OAAa,EAAA,KAAA,OAEX,EAAA,GAAA,KAAwB,CDwFO,CAAC,OCxFC,CAAC,GAAS,EAAJ,CAAC,YAElC,CAAA,oBAED,EACb,CAAC,+BAGgB,SAMlB,eAAA,GACL,CAAkB,CAClB,CAA2B,aAEP,CAAC,IOqSA,ADjLF,MNnHD,EAAE,AOsSA,CPpSW,KAAA,IAAnB,WAAmB,SAAA,EAAA,AACU,gBADV,WACP,SAAS,CAAC,OAAO,CAErC,MAAM,IAAA,GAAA,gKAC4J,CACjK,AAEH,CAFI,AFiGS,MAAA,IAAA,GAAA,mDE/F4D,CAAC,CAG5E,AAH6E,IAG7E,EAAA,IAAA,GACM,EAAA,IAAkB,GAGxB,CDmFC,SAAA,ICnFgB,KAAY,GADhB,EavEA,CbuEqC,EAAS,IAAI,CAAC,CAAN,AAAO,AACtB,CFiGH,AEhGtC,CFiGC,CADuC,EEhGnC,CAD2C,GACrC,KAAQ,EAAY,MAAA,CAAA,GAAA,eACA,CAAA,aACd,CAAA,EAInB,ExFUI,EAAA,IAAA,KwFVe,EAAA,KAAA,GAAA,KACX,EAAA,EAAiB,MAAA,CAAA,aACR,CAAA,qBAQW,CAAsC,IS6DhC,IT5DvB,IAAA,WAEX,UAAA,IAAA,KAAA,EAAA,OACE,GAAA,MAAA,eAIM,EACJ,KAAK,QAAY,WAAW,CAAG,AAAF,CAAC,GAAK,UAAU,CAAC,GAC3B,EADgC,CAAC,OAClD,OAAO,EAAU,GAAsB,GACvC,EzFwCC,EAAA,IyFtCa,WAAA,EAAgB,MAAM,CAAG,EAAY,MAAM,CAAC,CAAC,SACpD,CAAC,CD4FC,AUlCF,wBTrDJ,AAAkD,CAAC,CAAC,CAAE,CAAC,CAAvD,CAAA,ENzKL,AMyKK,SNzK4B,CAAA,2BAOE,IAAA,IAHjC,WAAA,AAIc,GAAA,EAAA,CAAA,CAAA,EAAA,EAAA,KAA6B,EnFIA,WmFAjB,CAAM,CKwEN,ALxEM,CtFbL,CsFaK,EAAO,eAAe,CAAC,UARvD,aAcgB,EAAA,CAAA,CAAA,EACH,MAAM,EAAA,KAAA,CAdF,AAcE,CAAA,EAAA,EAAA,EAfnB,AAemB,KAAA,CAAA,CAAA,EAEV,EAAA,KAAO,GAGX,EAAA,IAFP,CAAC,A9CqGiC,AMlFN,A9ChCA,Q4FgKvB,EAAA,SACC,EAAA,KAAA,CAAA,EAAA,OACM,KAAA,CAAA,KAIP,MAAA,CAAS,CAAC,kBAKf,C5FvCC,oB4F6CC,CAAC,KAAK,CAAA,eACE,CDgJC,CAAA,MC/IR,MAAA,CAAS,EAAE,CAAC,AAGnB,CzFmCC,MyFnCM,CAAA,CAAA,KA4CU,GAAW,UA3CjB,CA2CoC,CDoG1C,GAuCoB,Cc7MK,EbuBX,CAAC,OAAO,CAAC,AACxB,COmTyB,CPnTzB,EAAY,COoTG,QPpTM,CAAA,EAAA,EAAS,MAAM,CM3KG,EAAA,GN8KpC,EAAI,EOoTA,APpTA,EAEH,CAAC,COsTG,GAAA,CAAA,KAAA,EPtTW,CAAC,IAAI,CAAC,IAAA,CAAK,MAAA,CAAA,OAAA,YAG5B,GOsTO,GPtTA,CSoDK,AFkQA,GPtTD,CAAC,KAAA,CACZ,GM/JO,EAAA,IN+JG,CAAA,IAAA,CAAM,EF2YA,CQ1iBO,CN+JH,CAAA,UACf,IAAI,CAAA,MAAA,SAGX,IAAA,CAAA,KAAU,CAAG,Ca/DK,SbgEb,IAAI,CzF0DM,CAAA,CAAA,KyFzDX,CAAA,MAAA,CAAU,EAAA,CAEP,EAKT,GAFA,IAAA,CAAK,MAAM,CAAA,IAAK,CAAC,CD2IL,ECzIZ,EAAS,UAAU,CAAA,KACjB,CADwB,CAAC,Ga/DC,CNqXC,CPrTpB,WAGO,CAAC,CAAE,EAAM,CAkBb,EAlBY,AAAI,EAkBZ,CAAC,GADL,GAjB0B,AAiBvB,GAAC,CAjB0B,MAiBnB,OAEhB,CAAC,CD2IH,CC3IM,CAAA,QAAU,CAAC,CAAC,CAAE,OAAmB,EAAI,CAAD,QAAC,CAAU,EAnBd,GAmBmB,AAAqB,CAAC,AAGhF,CAAC,EAAK,CAAF,AD2ID,EQ2K8D,APtTvD,GAAG,CAVlB,EAO4E,IOyTjB,CAAC,AP1U5D,EAAA,UAAoB,CAAA,MAAO,CAAC,EAClB,CajEmB,AtGqHA,CyFpDb,SAAS,CAAA,EAAA,EAGzB,SAA2B,CAA3B,YACY,CAAG,EACJ,GADS,AOoTF,MPnTP,GACT,IAAA,CAAK,IAAI,CAAC,IAAA,CAAK,GAGV,yDxE3TS,CAAA,qBAAc,CiBdoB,A4B6CjB,A7C/BgB,C0CXf,A7BIA,A+CGF,ApERE,ARAA,A2CGA,CYJC,C9BAC,AmDSpB,AvBHoB,ArDLA,AmDCA,CLAnB,AIDoB,AzCAA,A8DDA,OvDac,CAAS,CAAE,CAAG,yEAGlB,MAAA,CAAA,EAAA,GAAA,CAAsB,EAAS,K4Efc,CAAC,CAAA,C5EeN,C4EdvF,C5EcgG,E4DHE,E5DGE,CAAC,CAAC,yBAMlG,EAAA,OAAA,CAAA,aAAA,CAAA,eAAA,CAAA,EAAA,EAAA,UAAA,CAAA,6HAeiC,GAAG,CAAC,gCACC,EAAA,EAAA,kDAC2B,SAAS,YAE/D,MAAA,EAAA,IAAA,MAIF,MAAA,EAAA,IAAA,IAEd,kDAGsB,CDnBwD,yCCsB1D,MAAA,mCAKd,cAQuB,CAAA,CAAA,CAAA,gCACa,MAAM,OAAO,CAAA,QAAS,CAAC,eqEpBW,CAAC,CAAC,sEhF8CyC,CACjH,CAAC,mL8FhEgB,IAAI,CNDwB,GAAA,KMCd,IAAI,CAAC,eAAe,CAAA,MAAA,EAAiB,IACvE,CAD4E,AAAI,EACnE,AADiE,EACvD,MAAM,CAAP,AAAV,GAAqB,CAAC,aAAa,CAAC,EAAQ,GAAQ,CAAV,CAAO,CAAC,AAAU,EAAH,AAAS,CAAR,EAAO,KAAS,CAAC,CACxF,CAAC,kHA+B8C,CAAC,ClFVC,IAAA,OkFUY,CAAC,CzCZD,EzBEM,OkEUK,kDACpB,CAAC,GAAA,CAAA,qCAI5C,aAAA,OACJ,CAAC,aAAa,CAAA,IAAA,CAAA,eAAA,CAAA,IAAA,CAAA,GAAA,IAAA,CACX,GjCjB2D,AmBYD,CAAC,ScK9C,CAAC,GAAA,IAAI,CAAA,GAAA,IAAQ,CAAE,GAAK,CACH,AADE,CACD,kBAG1C,uBAMc,KAAA,GAAA,IAAA,CAAA,EAAA,SAIZ,CAAA,CAAA,QAEO,IAAA,CAAA,KAAA,GAAA,KAAA,CAAA,YAGmD,CAAA,aAC9C,KAAA,GAAA,OAAA,CAAA,+CN/E6E,CAAA,uIAaxE,uOAYS,CxBH0C,awBG5B,CAAC,IAAA,CAAK,WAAkB,CAAE,UAG7D,CAHwE,CAAC,CAAC,QAG1E,wBAGE,EAAA,WAAA,iIAQM,KAAA,EAAA,iBAAA,GAAkC,C3BhBE,A2BgBD,+DA+BvC,EAAA,IAAA,IACD,C/CC2C,AmBqFY,C4BrFzD,E5BqF+D,AnD5GZ,A+EwBnD,EAAM,QAAA,CAAA,MACA,GAAqB,EAAQ,GACnC,CADiC,CAAO,AAClC,CADmC,EACpC,IAAQ,CACc,CAChC,AACH,CAJkC,AAG9B,OAUG,CAAA,OAAA,aAAA,CAAA,EAAA,iHAyBgB,C5D3CG,AuDOC,A1CsBI,A6ByDL,CAAA,EAAA,ekB1CL,MAAA,iCAIP,IAAA,EAAA,EAAA,wEA6BE,CAAA,CAAA,CAEd,CjBpBiD,CAAA,CAAA,CAAA,SiBuBnC,CQ9IY,CAAA,ER8II,qBAEL,EAAA,yBACI,EAAA,CAAA,wCAIT,EAAA,yCAQb,KAAA,CAAM,6CAIA,IAAI,CAAA,iBAAkB,EAAE,ANaA,CMbC,ANaA,Ac3JJ,IR+IlB,EAAA,MAAW,CAAA,EAAK,CCmBC,CAAA,oCDX7B,GAAA,GAAA,IAAA,CAAA,OAAA,CAAA,KAA8B,CAAA,OACvB,IAPF,CPEG,uCOqCZ,CAAA,CACA,CAAA,CAAA,CAAA,CAAA,WAGwB,EAAA,YAEf,CAAA,EAAA,IAAA,EAAA,EAAA,KACL,CAAA,QAAA,CAAA,EAAA,QAAA,EAA6B,yBACN,EAAI,EAAE,A1BzDA,A0B0DnC,C1EzC4B,A0EwCQ,A1BzDA,C2BkED,A3BlEE,0B0B6D5B,IAAA,CAAA,IAAA,EAAa,EAAA,qBAIH,CAAA,OAAY,EAApB,CNZH,OMYW,qDAQF,IAAA,CAAA,OAAA,kBAMN,CAAA,OAAA,OACA,OACO,IAAI,CAAC,OAAO,CAAA,KAAM,CAAC,OACxB,QAGb,CAAC,CzFlBG,OwE5O0B,kJD6BW,oBCzBrB,CLTqB,ARCA,AYiCA,SAAA,MCzBuD,EAAE,CAA/C,AAAgD,EpDc9B,CRVG,MAAA,E4DJJ,IWD5C,EACxB,EXAoE,CAAS,CpDgBzC,CAAC,EoDhB4C,CAAC,KAAK,CAAA,KWApE,GACpB,+IX8B8C,C1ChBrC,AiENsD,AnELzB,cAAA,oE4CmCV,EAAA,IAAU,EAAA,OAAA,EAAiB,IAAI,GAAA,QAAA,GAAA,EAAA,GACtB,EAAI,OAAA,EAAa,GAAG,C5DXD,A4DWE,CAAC,AvEKlD,CRjC0D,aAAA,G+E6BlC,EAAA,QAAc,EAAA,OAAA,EAAiB,QAAA,GAAA,SAAA,GAAA,EAAA,IACzB,C5ExBH,CAAC,AiBHE,O2D2BW,EAAM,EXgFN,EAAA,CAAA,CWhFY,CUkCX,AVlCY,CTjBH,ASiBI,EAAA,CACzD,CAAA,KAAA,CAAA,SAAA,GAAA,IAAA,KAAA,YAQG,SAAA,AAAyB,UAAzB,OAAA,GAAyB,AAAmD,UAAU,CAAC,CAA9D,OAAmB,CAAK,CzEjCoC,AyEiCnC,CzEjCoC,AcGD,CAAC,K2D8B7B,aAAa,CAAC,YAQhF,gBAIS,GAAA,CAAA,qBAAyC,CAAA,0CAST,EAAA,IAAS,CAAE,KAGhD,CxCMD,AjBDA,EAAA,IyDL2C,C9BjBL,ChCxBC,AyEuUA,kDXrRE,C3DxCR,oB2DwCqB,EAAA,EAAA,KAAA,sDAMnD,aAAA,EAAA,EAAA,QAAA,CAAA,CAAA,MAAA,EAAA,SAAA,EAAA,WAAA,GAGW,IAAA,uCACoC,CY5BP,EAAA,IZ4BiB,sCAQ9D,mBAC8B,eAQO,yKAMN,CAAC,GAAQ,CAAA,GAAI,ExEPE,CwEOC,CAAA,CAAE,CAAA,EAAM,EAAM,GAAA,GAAkB,EAAA,EAAW,KAAK,AACzF,CAD0F,CAAC,CAAC,AAM/F,CANgG,EAMhG,GAAA,KS1BmE,CACpE,CAAC,MTyBmD,MAAA,SAAA,EAOnD,GAAA,OAJG,EkBsBsC,elBtBtC,GAAA,UAAA,CAAA,aAAA,UAAA,OAEiD,KAAA,CAAkB,CAAC,C5BrC/B,A4BqCgC,CAA9B,gBAIpC,OAAA,CAAA,GAAA,OAAuB,EAAA,IAAA,CAAW,UACd,UAAU,CAAC,EPdR,WOe1B,IAAA,KAAA,YACqC,CAAC,CAAA,MAAA,CAAA,SAGtC,CACT,C9BfqE,A8BepE,CAAC,WAE0C,EAAA,mIAIgD,CACvF,CAAC,uBAI8C,iBAAV,GAAuC,AAAjB,EmB2OF,CDhMN,CGrDX,OrBU+C,CAAC,MAAtB,aAClD,OAAA,SACZ,GAAA,aAAA,kBACO,EAAA,GAAA,SAA2B,IAAA,IAAS,GAAQ,EyB/GzC,CACN,2BzBgHQ,GAAS,WAAW,IqBiCE,KrBjCO,GAAmB,IAAA,IAAY,EAAE,CAAC,CAAE,GTCD,ASDS,KAAK,CAAC,ATCJ,CAAC,ASDI,CTCH,ASDI,CAAC,CAC9F,GAAA,GAAA,ckB2De,AlB1DH,EYhCe,AzFWb,AyFXa,GAAA,2CZkClB,GAAG,CAAC,EiB8DE,AQ1KJ,AJkJI,AVaN,GAAA,CAAA,AXnDe,GAAA,GAAuB,EUyCE,AVzCI,EAAM,IAAI,CAAE,KAAK,CAAC,CAAC,CAAC,CAAC,GzDsBL,CAAC,CAAC,SyDrBxC,CAAC,cAC/B,QAAA,GAAA,CAAA,OAAA,OAAA,CAAA,GAAA,GAAA,CAAA,CACuB,CAAA,EAAA,EAAA,GAAA,GAAA,EAAoC,CDoED,EAAA,EAAA,CAAA,EAAA,ECpEe,CAAA,CAAG,CAAE,gBAG9E,UACJ,CAAA,qGAAA,EAAwG,EAAK,GAAA,KAAA,CAAU,CACxH,CAAC,qC3E7JS,mBAAA,IAAA,EAAA,UAAA,OAAA,EAAA,IAAA,EAAA,YAAA,OAAA,EAAA,IAAA,EAAA,YAAA,OAAA,EAAA,KAAA,EAAA,YAAA,OAAA,EAAA,WAAA,oBAwDgC,CAAA,CAAA,CAAA,CAER,CyCnBK,KzCpBtC,EAeA,UAfA,OAAA,UA4CU,IA5CV,UAAA,OAAA,GAAA,UAAA,OAAA,EAAA,IAAA,EAIqB,AAJrB,UAAA,OAAA,EAIS,YAAY,EAAA,GAAA,wCA+CA,EAAM,WAAW,CS5BG,CAAC,AT4BF,AoF1CF,QpF0Ce,CAAC,IApCtD,AACK,OADL,MACK,AACQ,UADR,OAAA,GACQ,UAAA,OAAA,EAAA,GAAA,EAAA,YAAA,OAAA,EAAA,IAAA,iDAuCW,EAAE,QAAA,CAAA,KAAc,CAAC,SAAS,GAAG,EAAA,CAAE,yBAKrD,EAAA,MAAA,GAAA,oBAID,GAAA,KAAA,KACG,EAAA,EAAA,IAAA,CAAA,GAAA,AAA4C,C6CzBD,S7CyB3C,OAAA,G6CzB2C,S7CyBuB,CkGxCC,ElGwCO,EAAK,IAAI,CAAC,CAAC,kFAUhE,EAAA,oCAGf,CgGjBC,AhEpC8B,KAAA,CAAA,iBhCsD1B,6BADgD,kCAKtB,MAAM,CoEhCC,CpEgCK,IoEhCI,AvDbF,Ob6CS,EAAE,AIEF,CJFG,AIEF,CS/CC,Ab6CE,sDAKtC,MAHiC,OAM3D,EAAA,GAAA,aAAA,OAHiF,IL3DZ,AK+DjE,MAAA,CAAA,sBAAA,EAAA,OACwB,EAAA,EAAA,EAChB,CAAA,ML1DyD,SAAA,EAAA,EAAA,CK0D1B,CAAC,AAAE,CAAD,CACjD,CAAA,EAAG,aAAa,EAQT,iBAAA,GAAA,AAAgC,OAAhC,EAAgC,MAAA,oCACF,SAClC,CAAA,UAAA,EAAA,EAAA,GAAA,CAAA,AAAwB,GAAA,CAAA,CAAA,EAAA,EAAA,CAAA,CAAA,EAAA,IAAoB,CAAC,C2ET3B,K3ESgC,CAAA,CAAA,EAVpC,GAAM,CAAE,CAC1B,AADuB,CACtB,AADuB,qCkFtIrB,CAAA,OAAA,CAAA,sEhFGiD,CUwBY,0BVrBvD,KAAA,EAAA,MAAA,CAA8C,OAAA,MAAA,CAAA,OAyE/C,GAAA,MAvEoD,CqEShC,EAAA,SrERjB,C4E2B+D,A5E3BrC,CAAA,CqEQY,ErERP,CAAA,6CAKrC,EAAA,EAAA,sFAM6D,gGAO5B,cAAA,CAAA,EAA8B,CHMA,aAAA,EGNkB,KAAU,KAAK,AyEiCvC,QAAA,yBzE5BlD,EAAA,MAAA,CAAA,EAAA,MAAA,uBAEA,CAAA,cAAA,EAAA,OAAA,SAAiC,CAAA,QAAA,CAAA,IAAA,CAAA,GAAA,KAAA,CAAA,EAAA,IAAA,8BAAA,CAAA,MAKrB,EAAe,CAAA,IAAW,C4F8KtD,A9E1KqC,CdJwB,MAAlB,AAAwB,CAAG,GAAK,CAAA,CAAO,yEAQpC,YAAL,CFiDH,AyFlCJ,GvFfW,CAAC,EAAA,UACpB,oHAOE,CuCyBL,AvCzBM,AiGGvB,GAAA,EAAA,KAAA,CAAA,EjGHwC,KAAA,yDAKd,CAAA,EAAA,KAAc,CAAA,SACpB,MAAA,CAAO,EAAA,MAAA,aACR,KAAA,CAAQ,EAAA,MAAA,kBAItB,IAAI,GAAA,CAAA;AAAA,EACkD,C4FqS7B,CAAA,GAAA,CAAA,GAAA,EAAA,KAAA,EAAA,I5FnStB,CAAA;AAAA,EAAA;AAAA,EAAoB,EAAA,CAAA,aAUtB,0G+CxDP,ElBN+D,CAAC,AkBMX,OxBF1B,AwBE0B,AACnD,ExBHgC,GwBGtB,CAAO,ayBJT,GAA6B,CrEzBc,SqE0BlD,KAAA,IAAA,GAAA,aAAoC,QAA0B,IAAlB,EAAA,QAAa,E/CDjE,Y+C8DqB,4EAuDb,GAAO,GAAD,MAAC,mExDmCV,EAAA,KwDEsB,0BAAA,2EAQ0B,EAAA,OAAA,CAAe,IC7CM,MD6CI,CAAC,CAAC,MAI3E,QAAA,IACK,EAAA,OAAA,cACgB,UAAA,CAAA,cAGN,OAAA,CAAA,UAAkB,EAAE,IAAI,AAAC,WAAa,gBAAc,IAAQ,CWxB7D,GX+DA,Ca/FL,CAAC,Ab+FW,CkBHD,IlBGM,EAAE,KAC9B,GAAA,GAAA,IAC6C,EAAU,EN/EwC,CAAC,CAAC,GM+E3C,CAAS,EAAE,IAAI,GAAK,EAAS,MAAD,EAAS,CAAC,IAAI,CACvD,CAAC,AoB+K3C,CpB/K4C,GAExC,CAAA,cAEE,EAAA,QAAA,kBAED,GAAmB,CANsE,EAMtE,EAAA,SAAgC,CAAC,EAAA,QAAA,CAAkB,GCpEK,MDoEI,CAAC,CCpEK,CAAD,AAAE,CACzF,CDoEgB,ACpEf,SDoEwB,OAAS,KAAA,KAAU,CAAC,EAAS,QAAQ,CAAC,SAAS,CAAC,CAAA,UAjDG,KAAA,kCAIjD,EAAA,CAAK,EAAO,C5E1EO,M4E0EA,CAAC,OAAO,CAAC,A5E1EM,CoBmD5D,AiBqBiE,ArCxEJ,A4E0EN,C5E1EO,CAAA,EoBmD9D,EpBnD8D,E4E2ErB,OAAA,CAAA,OAAA,oBAajB,C3E1FD,AiG4BF,MtB8DY,E7BpEK,CyC2DR,YZSkB,CAAC,M7BpEQ,oE6ByElB,C/EhGC,mD+E8EC,eAMtC,iBA8DH,SAAA,GAAA,CAAA,QACJ,EAAA,GAAA,EAAwC,eAAe,CYvBL,AZuBM,EAAE,CAAC,SAK3C,KAAA,GAAA,GACc,CAAC,CAAC,EAAA,AAAgB,CgBpFtB,YhBoFM,EAAA,IAAW,EAAyC,IAAI,CAA1B,AAA2B,CAA1B,AAC5D,CAD6D,EgBpFhC,CAAC,CAAC,IhBoFsC,CAAC,MAAM,IACxE,CAAA,CAET,AAFc,CAEb,AADE,CAAC,iCAMsC,CAAC,mCAGnC,CAAA,iEAAA,EAAoE,EAAS,E/ElIkB,CAAN,C+EkIR,CAAA,EAAA,CAAI,CACtF,CAAC,OpE7R0B,wJoFAO,CZgCW,IYhCJ,CAAC,EAAC,oDAIf,KAAO,oGAUd,cAGC,C7ECkC,AHGA,GgFJ9B,QAAA,CAAA,EAAA,gBACK,EAAA,yCAIf,ChEOmC,AXUC,G2EjBhC,QAAc,CAAC,ChEO6B,C2CUC,CAAA,iCqBfzC,EAAA,iCAOC,CAAC,KAAO,mBACnB,KAAK,CAAC,GAAG,EAAI,CAAC,CAAC,CAAC,GrBiB4C,wCqBTpE,UAAA,OACD,CAAC,KAAA,CAAA,2BACc,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,STQkB,aSH5C,KAAA,MACT,IAAI,CAAA,GAAA,KAAyB,IAAA,CAAA,IAAA,iFAStB,GAAA,IAAA,CAAA,GAAA,wFAmBD,CAAA,GACJ,IAAI,C3FMkC,GAAA,IAAA,C2FNtB,ENiBE,AMjBI,GAAK,CAAD,EAAC,IAAI,CAAA,ENkBW,CAAA,IAAA,CMlBC,EAAM,CAAG,EAAA,CAAE,CAAC,CAAC,ChFuBG,IgFtB9C,kBAEjB,cAUQ,EAAA,GAAA,IAAA,CAAA,GAAA,IAA2B,CAAC,CtBoBuC,CsBpBjC,CtBoBmC,EsBpBpC,WAChB,CjD8BX,GAAA,mBiD7BsB,AAAC,GAAM,CAAC,A1FqDE,CAAA,Q0FrDO,GAAK,2BAChB,cASO,CAAA,CAAA,CAAA,eAEzC,C7C2B0D,GAAA,I6C3B/C,CAAC,EAAM,GAAD,AAAM,CAAD,EAAC,IAAI,CAAA,GAAA,EG0FS,EH1FE,CAAC,EAAM,CAAA,EAAA,CAAK,CAAC,CAAC,iBAC/B,MAAM,uCAsBd,CAAA,EAAA,iBACc,EAAI,EAAA,+EAON,CvFoEsC,CAAC,AuFpEnC,EtBoBmC,AsBpBnC,gBACzB,CAAA,GAAA,WA4BV,CAAA,CAAA,GAAA,CAAA,CAAA,OAII,IAAA,CAAA,GAAA,MAAa,CAAC,CfK2B,0CeCvC,CAAA,GAAA,KAAmB,IAAA,CAAvB,IAAI,wBAG0E,CAAC,EAAM,CAAC,EAAF,uBAE9D,C3FtB6C,A2FsB1C,EAAU,MAAM,CAAC,AAAC,CAAC,EAAE,AAAG,CAAD,CAAG,CAAC,IAAI,CAAQ,CAAC,AACjE,C/FtCG,CAAA,OAAA,C+FsCe,CAAA,CAAA,SAAA,CAAA,CAAA,GAAuB,GhB6EjC,EAAA,iBgB1Ea,WACqB,CACrC,GAAA,IAAA,CAAA,GAAA,MAAiC,EAAD,CAAY,MAAF,EAAU,CAAC,CvF8CuB,MuF7CvE,MAAA,CAAO,UAEb,CAAA,GAAA,KAAA,IAAA,CAAJ,E5FbyF,CAAC,C4FatF,CAAyB,KAAK,CAAC,CAAC,YACd,IAAA,CAAtB,GhBoFsD,CgBpFlD,CAAmB,OACnB,CAAA,KAAA,CAAA,OACJ,EL2DI,qBKrDJ,IAAA,EAAc,CAAA,CAAK,CH7BH,AG6BI,CAAA,IACf,IAAA,CAAA,GAAA,MAAiC,EAAD,CAAY,MAAF,AAAQ,EAAE,CAAC,OAOhD,MAAM,CAAA,GAEhB,C/F9CC,EAAA,IAAA,CAAA,GAAA,K+F8C2B,IAAA,CAA5B,IAAI,CAAyB,GAC7B,EADkC,CAClC,AADmC,A5FYuD,CAAC,A4FZvD,C3FnBf,AD+BuE,EC/BvE,CAAA,GAAA,K2FoBC,IAAA,CAAtB,C3FpBoE,CAAC,E2FoBjE,CAAmB,KAAK,CAAC,CAAC,CACzB,KAAK,CAAC,uNAtE6B,CAAc,iBACxC,EAAI,IAAA,CAAC,aACA,CL6IH,AW7BN,MAAA,cNhH+C,CMgH/C,EAAA,IAAA,KN/GF,CMgHL,AHiDE,GAAA,EAAA,eH/Jc,CGmKH,A9FzGA,CAAC,e2FzDb,CGmKoB,GAAA,CAAA,EHnKJ,IAAA,CAAC,AACd,IAAI,CAAA,KAAM,CAAC,C5F2FD,CyF1CL,AS+DE,MAAA,GN9GhB,GAAA,aAAA,eACc,KAAA,CAAA,QAAe,mBAER,MAAA,OACc,IAAI,GAAA,EAAkB,OAAO,CAAC,CAAC,2BAG/C,CAAC,CGwKH,AC4KE,A/FtRA,O2F9DU,GAE7B,CIoVD,MJpVQ,IAAI,CAAA,KAAA,CAAA,QAAA,IAAoB,GAAY,ELoJe,KKpJR,IACpD,CAAC,AADwD,CAAC,CAAC,CAAC,CJ0IL,AI1IM,CJ0IL,CAAC,MxF7CU,M+F9N3D,mLAUA,EAAU,EAAA,OAAsB,CAAA,EAAA,EAAK,0DAQhC,CAAA,IAEN,CAAA,WAAA,GAAA,CAAA,EAAA,OAAA,CAAA,IAAA,kCAKC,CAAA,KAAM,CAAA,UAAY,UACQ,EAAA,OAAe,qCAEN,CTtBG,CSsBK,OAAA,6BACa,CAC1D,CAD4D,GAC5D,IAAA,KAAA,EAAgC,UAAA,2BAEvB,KAAA,CAAA,mBAAA,EAAA,QAAA,iFAagC,CAAC,gBAAgB,CAAA,MAAO,CAAG,CAAC,CAAC,CAAC,oIAehE,CAAA,C3FzB0B,EAAA,IAAA,I2FyBT,IAAA,CAArB,IAAI,CAAmB,CAAC,iEA0BH,IAAA,CAArB,IAAI,CAAmB,CAAC,uDAoBxB,GAAA,IAAA,CAAA,GAAA,IAAA,IAA8B,IAAA,CAA9B,IAAI,CAA4B,CAAC,oEAyB7B,CAAA,GAAA,IAAA,IAAgC,IAAA,CAApC,IAAI,CAAkC,CAAC,+CAqBvC,IAAI,CAAA,GAAA,IAAA,IAAqB,IAAA,CAAzB,IAAI,CAAuB,CAAC,2BAI5B,QAAQ,CAAC,CpD3DG,AwCrBA,eAAA,qBYsFA,IAAI,CAAA,gBAAA,CAAA,IAAsB,CAAC,gBAAA,CAAiB,MAAM,CAAG,CAAC,CAAC,CAAC,E1DThE,CACR,CAAC,I0DSiB,KAAK,CAAC,sBAAA,YACN,IAAA,CAAA,GAAA,IAAA,IAAqB,IAAA,CAArB,IAAI,CAAmB,AAC5C,CAD6C,AAC7C,GAAA,IAAA,CAAA,KAAA,CAAA,eAAA,OACM,EAAe,GAAA,IAAI,CAAA,GAAA,IAAA,IAAiB,IAAA,CAArB,EH1F6B,EG0FzB,CAAmB,eACf,eAAA,GAE7B,ClG5FC,A0FoEA,AnEVE,GAAA,EAAA,G2EkCuB,IAAI,CAAA,GAAA,IAAA,IAA0B,IAAA,CAA9B,IAAI,CAA4B,CAAC,sCACA,OAErD,EAA0B,GAAA,IAAI,CAAA,CpD1DwB,EAAA,IAAA,IoD0DQ,IAAA,CAApC,IAAI,CAAkC,CAAC,oBACvB,8BAA+B,iCAEzC,CzB/DL,AyB+DM,CAAC,KAAK,GAAG,CAAC,SACrC,CAAA,aAAA,GAAA,IAAmB,CAAA,GAAA,IAAA,IAAqB,IAAA,CAAzB,IAAI,CAAuB,CAAC,CAAC,MAY1C,sBACd,ClBxD2B,AmB2OJ,CDlLvB,CAAkC,CPdC,AOenC,CAAwB,CAAA,OAET,GAAA,qCAEsB,CAAC,ClB3Db,AmB4OA,IDjLkB,CO7KrB,6BP8Ka,IAAA,IAAU,CAAC,UAAA,CAAW,KAAK,EAAE,A9C3FC,sB8C6F7C,IAAA,CAApB,IAAI,CAAiB,MAAM,CAAC,AAEtB,CAFuB,CAEvB,MAAuB,EAAO,IAAA,CAAA,WAAA,CAAiB,MAAM,CACzD,ClGvGuD,KkGuG1C,G1FnC+D,CAEnE,ARtE8D,CAAC,AQsE9D,CRtE+D,AkGuGtD,ClGvGuD,CkGuGrD,CAAK,CAAE,CAAA,CAC1B,CADwB,EACrB,CAAO,CAAE,OAAA,IAAY,CAAA,UAAW,CAAC,MAAM,CAAE,CAC/C,CAAC,sBACa,8BACoC,EAAA,UAGrC,mBAAA,CAAA,CAAA,CAEoB,CAClC,CR7B2E,AnBrCrC,CAAA,K2BoEjC,IAAA,KAAA,EAAA,QAAA,qBACuB,GAE5B,CR9BC,MQ8BM,MAAM,IAAA,CAAK,qBAAqB,CAAA,EAAS,COjL5B,CPiLoC,SAG1C,UACd,CnBLK,AmBKS,CPrBD,CAAA,CAAA,CAAA,CAAA,cO4BP,CAAA,YAAA,EAAA,MAAA,QAAwB,CAAA,CAAA,GAAA,EAAA,CAA0B,CHlFpC,A5FfiB,C+FkG/B,EACJ,UAAA,OAAA,GAAwD,UAAU,GAA/B,EAAY,IAAA,EAAuB,GAAa,QAAF,AAAU,EAAE,IAAI,CAAC,AAC9F,CAAA,mBAAA,IAAmD,CP1BD,AO0BG,CAAG,GAAW,CAAA,CAAE,CAAC,IAGlD,KAHG,AAGH,CAAM,A/FpGF,CuF6DD,CCUC,CO6BE,ARvCD,CQuCC,AAAK,UACZ,GAAA,kBACA,SACT,GAAA,+EAGL,0BAEK,CACR,SAAA,EAAe,SAAS,MAClB,ClG3H2C,AImBtC,CAAA,QAAA,C8FwGS,IAAA,eACF,QAAA,CAAS,WAAW,CnBCZ,CAAA,wBmBAD,CAAA,UAAkB,OACpC,CRvBP,CQuBY,SAAS,SACb,WAKP,CACT,C1FjCC,A0FiCA,EAEK,EAAA,CAAA,UACK,CpDlGyB,AoDkGxB,CpDlGyB,GAAA,EvBmE5B,e2EgCD,C3EhCC,GAAA,oB2EiC0B,C9FxGC,C8FwGG,EAAA,QAAU,CAAC,QAAQ,CAAC,IAAA,CAAA,CAAQ,CAAC,A9FxGC,CAAA,QAAA,M8F4G/D,EAAA,UAAA,EAAA,EAAA,GAEY,CAAC,AAAC,CAAC,EACT,aAAN,EAAE,IAAI,CAAA,iBAGF,ClGrIC,AmGoTE,QnGpTF,CkGsIC,KAAM,EAAE,CPzBH,CpETW,MAAA,C2EkCC,IAAI,EAAI,EAAA,QAAU,CAAA,QAAS,CAAC,IAAI,YACrC,CAAC,CAAA,QAAA,CAAU,UAAA,wBACC,WAAW,C/FxEK,CAAC,M+FyEjC,C9FxGC,AwFRI,AMgHJ,CAAA,QAAS,CAAC,MAAM,GAG5B,QAEJ,UAEM,KAAW,C/FxEG,CAAC,AsGxGF,APgLK,QAAA,CAAU,CAAC,gBACrB,GAAS,OAGvB,IAAI,EAAA,EAAA,EAAW,EAAoB,EAAE,EAAG,CRtBkB,AQsBjB,CRtBkB,KQuBvB,ClGzIjB,A+F3BQ,I5F0FuB,CH/D/B,AG+DgC,CAAC,GH/DjC,CkGyI4B,GNnHjB,kBAAA,CMoH/B,EAAA,0BAIE,kCNlHH,EAAA,EMuH8B,OAAO,CAAC,CAAC,AP9BA,CO8BC,EAAE,OAAO,CAAC,IAC9C,EACH,MAAA,IAAA,GAAA,iDAEE,CAAA,EAAS,UAAA,EAAY,QAAQ,CAAC,mBAIF,E/F7EI,CAAC,O+F6EK,CAAE,CAAC,A/F7EE,CAAC,CwFkDD,OU7BrB,mBHyDN,CGzDM,EAAD,CV8BD,AU9BE,cH0DO,EAAE,CAAC,OACtB,CAAE,UAAW,CAAI,CAAA,CAAA,EAAe,CNjH7C,CDwF+B,CAAC,CAAC,CAAC,GOyBmB,CAAC,EAC1C,CAAe,CAAA,EP1BiB,AO0BX,CAAC,APzBF,GO2B1B,CAAD,CAAG,AGxDI,CHiEJ,AC0KK,AE3OA,AV8BV,GOmCS,GAAA,IAAiD,EAAM,CAAC,AACjE,CAD8D,GAC9D,EAAA,CAAA,mBAAA,EAAsC,KAAK,C9FxGS,AD4BF,QAAA,C+F4EG,GAAK,ClGlJF,CAAA,EkGkJO,KAAA,SAAA,CAAA,GAE9D,4BAAA,CAA8B,CAAC,AAEhC,IAAA,CAAK,WAAA,CAAY,CP7BK,oBO6BG,GRjBS,OQiBK,CAAO,iBAdvC,CACP,IAAA,EAAA,CAAA,mBAAA,EAAsC,IAAI,CAAC,SAAS,CAAC,GAAK,CAAD,CAAC,uBAAA,EAA4B,MAAM,CAAC,IAAI,CAC/F,GAEC,GAAA,CAAA,GAAA,KAFc,AAEK,C9F1GW,A8FyGhC,AlGhJ0B,CAAC,AIuCM,O8F0GH,CAAC,IAC7B,AADiC,C/F7EL,A+F6EM,C/F7EL,A+F6EM,EACnC,CAAA,E9F3GqD,CAAC,GAAA,kBAAA,C8F2GxB,CAAC,gBAElB,CAAC,qBAAQ,CP9BK,CAAC,QO8BQ,CAAO,CAAE,AAAX,CAAY,CAAC,GAAJ,SAY5C,CAAC,CP5BC,4BO6BuC,G/F9EN,CAAC,CAAC,CAAA,E+F8Ea,C/F9ER,I+F8Ea,CAAC,GAAQ,CAAJ,CAAC,AAC/D,CADgE,CAAC,IACjE,EAAA,oBACiC,MAAQ,EAAM,M/F7EY,CAAA,C+F6EF,OAAO,OAC5D,CAAA,WAAA,CAAA,qBAAqB,GPzBO,OOyBO,KPzBS,OO2BlD,CAAC,AlGtJiE,MkGyJ/C,ERgSE,CAAC,ES3GM,CDrLH,EAAG,EPxBI,AQ6ME,MAAA,CAAA,EDrLW,IAAI,CAAC,CAAC,AAC7C,EAAA,GAAU,CPzB2C,GOyBvC,CAAA,GAAA,IAAA,IAA6B,IAAA,CAAjC,IAAI,CAA8B,UAAU,CAAC,CAAC,WAC7C,CGvDC,AlGrBI,oB+F2E2B,gBAI/C,QAMR,CAAC,C/F5EG,A+FqFL,UAhBiC,iCAjSnB,CAAA,GAAA,IAAA,IAAiB,IAAA,CAArB,IAAI,CAAmB,CAAC,OAAO,EAAI,IAAI,CAAC,CAChD,GAAA,sBAYc,QAAA,CAAS,CGyOyC,KHzOnC,CAAC,KACtB,CAAC,E/FsNF,A+FtNI,EAAA,GAAA,WACY,CAAA,QAAS,CAAC,CAAC,AOyGR,CAAA,IPxGnB,GAAmB,SAE6B,CAChD,AAIK,GAJL,CAAU,SACA,EAAkC,CCsexB,MAAA,EDtemC,eACX,GCsetB,CE3PH,GH3OgC,EAAI,CG2O9B,eHtOrB,GAAY,6EACxB,CAAC,CAAA,GAAA,eAYM,IAAI,EAAI,IAAI,CAAC,QAAA,CAAA,MAAA,CAAkB,EAAG,GAAK,CAAC,CAAE,CAAC,CC8dH,ED9dO,CC8dH,AD9dI,AACnD,EN2KE,EM3KI,EAAU,IAAI,CAAC,QAAQ,CAAC,CRojBT,AQpjBU,CAAA,IAC3B,CP0TH,EAAA,IO1TkC,CC+dD,ED/dU,CC+dD,WAAA,QD/dqB,CAAC,OAChD,UAAA,CAAW,GN2KC,GAAA,CAAA,AM3KO,CC+dC,AD/dA,EC+dA,AD/dgB,aC+dhB,ED/dO,IAAI,EAAiB,CC+dd,CAAC,AD/de,CAAC,CAAC,CAAC,GAAA,SAK1E,CAAC,CAAA,GAAA,WAYC,IAAK,IAAA,EAAQ,E/FqMF,AsGxGA,EP7FM,CAAA,QAAS,CAAC,MAAA,CAAS,EAAA,GAAA,EAAA,IAAgB,CAAC,AACnD,IAAM,EAAA,IAAc,CAAC,QAAQ,CAAC,CAAC,AR0iBV,CAAA,OQxiBL,I/FqML,A+FrMK,MAAA,EACN,C/FoMC,MAAA,E+FnMkB,A/FmMlB,CuFuWa,SvFvWb,O+FnMF,EAAA,OAAe,CCudC,CTmFD,IAAA,CQziBjB,QAAQ,CAAC,CP8SH,AxFtGQ,G+FxMD,CAChB,GAAA,AACa,CRwiBe,EvFhWvB,W+FzML,EACI,IAAI,E/FwMH,E+FvMD,UAAU,CGqNG,ATvDJ,CAAA,KAAA,AM9JS,CAAC,EAAK,AAAW,CP4SL,AO5SL,cAAA,IAAK,EAAmB,CAAC,CAAC,EAAE,GAAK,EAAQ,KAAD,OAAa,CAAC,CACpF,EACD,CAAC,cACqB,CAK5B,AAL6B,C/FsNG,A+FjN/B,CAAA,GAAA,WAQC,IAAM,EAAA,mBACe,EACnB,CNuJD,aMvJgB,eACD,CAAC,EAEjB,IAAA,GAAW,OAAE,CAAK,CAAE,GAAI,IAAI,CAAA,gBAAiB,CAAE,CAAC,wBAEjB,EAAM,C/F+MG,CAAC,CAAC,c+F/MY,CAAC,EAC7C,aAAA,EAAA,EAAA,aAAoC,GACpC,CRyjBC,WQzjBW,EC8cA,ED9cU,YAAY,CAAC,CAG7C,OAAO,CACT,CAAC,CAAA,GAAA,SAgCe,CAAkC,KACrC,MAAP,CR+hBS,CQ/hBF,CAAA,EAAa,CR+hBS,CQ/hBF,CAAC,CAAG,EACjC,CADoC,KAC9B,IAAI,GACR,OCibqB,wHD9a3B,CAAC,CAAA,GAAA,SAmK4B,CAAmB,QAEtB,QAAQ,CAAC,CAAC,AAAhC,CC6QC,APxTI,MM2CE,EAA0B,OAChB,IAAf,EAAe,YACf,IAAI,CAAC,EC+QE,OAAA,CD/QQ,2ClEpW0B,CAAA,CAAA,CAAA,kCAM7B,GAAA,OAAA,uCAAyD,oEAWpE,CAAA,YAAA,EAAA,qBAC+C,wChCnClD,UAoBA,WAAA,mCAkNA,EA5LA,CA4LgB,AAAhB,GAAkC,YAtMD,IAAuB,MAUxD,EAAA,GAVwD,aA4EtD,IAsDA,EAqBA,iBAtJ8B,+CACQ,OAAO,EAAA,CAAY,mDAQ3D,WAAA,mCAKQ,GAAA,CAAA,EAAA,EAAA,aAAA,EAAA,EAAA,CAAA,eAIJ,IAAA,GAAA,CAAA,EAAA,EAAA,aAAA,EAAA,EAAA,CAAA,iBAKO,GAAA,EAAA,2CAEQ,QAAN,EAAM,CAAA,mBAGwB,CsFiBK,4BAAA,GAAA,GAAA,EAAA,EAAA,GAAA,OtFhBI,G0EsCK,O1EtCK,CAAC,EAAW,C0EsCG,AAAT,Q1EtCe,CAAC,KAAK,CAAC,CAAC,CAAC,CAC5F,CAAC,G2FkVa,6C3F5U+B,IKyDR,ELzDc,CAAA,UAAW,CAAC,CK0DjD,CAAC,AL1D2D,SAAS,CAAA,QAE1E,CADT,CAAC,AKyD4C,CLvDtC,GAGoC,8BAAA,GAC7B,GAAS,EAAA,EAAA,GAAA,QAA8B,IwC6DI,MxC7DM,CAAC,EAAW,SAAS,CAAC,SACrF,CAAC,IAK0C,6BAAP,CAAC,AGmBA,CyDZC,A5DPA,EAAK,IACzB,GAAA,EAAA,EAAA,GAAH,AAAkC,WAAA,UAAqB,CAAA,EAAY,QoDYpD,CpDZ6D,CAAC,KAE5F,C8CkCG,A8CpBA,EAAA,O5FVwC,CkG8Fe,iCjBxG/D,AjFWM,IAAuB,GAAA,EAAA,EAAA,GAAA,EAEb,EAAQ,C+E4FH,A/E5FI,AyGpEE,EzGoEF,YAAA,UACI,CAAC,EAAA,SAAoB,CAAC,KAAK,CAAC,CAAC,CAAC,CACtD,CAAC,MAK0C,CyE4BP,uBzE5BA,IACnC,GAAA,GAAA,EAAA,EAAA,GAA2C,MAAM,EyE4BR,CAAC,AyB8D+B,CAAC,CAAC,KlG1FhB,CAAC,CoDWE,CAAA,SAAA,CpDXmB,KAAK,CAAC,CAAC,CAAC,CAC1F,CAAC,WAOC,KACJ,CiGsEC,AIrCA,GrGjCK,EAAA,KACO,YAEE,IAAiC,GAAG,GAAzB,AAAD,CAAW,CAAC,EAAM,C+EgGC,C/EhGY,GAAU,AAA0B,QqGiCxD,ArGjCwC,CAAC,EAAQ,CqGiCjD,ArGjCkD,CqGiCjD,ArGjCkD,AAAK,CAAK,AAAD,AAAd,CAAgB,CAAE,CAAC,CAC1F,OAAA,CAAA,CAAA,EAAA,EAA6B,CAAC,IkD4BU,KlDzB7B,CAH4B,IAGb,SAAf,yBAEA,EAAA,SAAoB,CAAC,EmGwRQ,AAAF,CAAC,CAAC,AnGxRC,EAAQ,OAAA,gCAIrD,GAxIC,AAwID,EiGuGY,OjGvGC,AAAU,CiGuGX,AjGvGY,4BAEY,EAAA,EAAe,C+E6Gb,AmBGkB,MlGhHE,G2F6FK,C3F7FM,KACxE,MAAA,EAAA,QAEO,KAAK,KAAA,CAAM,EAAW,SAAA,CAAU,EGuBd,EHvBgC,WAAW,CAAC,IAAI,CAAC,CAAC,CAAG,CGuBf,EHvBkB,IAGrE,iEAQe,YAAA,gBAEQ,EAAO,EAAb,CqG8ED,ArG9EY,IAAE,QAC9B,CiG6GC,6BjG3GS,GAGb,CQ2FS,aR3FK,CAAA,EAAA,EAAA,OAAa,YAAiB,EAAM,CqG+EH,UrG/EG,CAAA,EAAkB,aAAc,C+EkIf,C/ElImB,eAEzF,EAAY,CuB8FO,CAAA,OvB9FO,CACzB,OAAM,CAAC,A8C8BS,C9C9BR,AyGlDG,ClFkJC,GvB7FO,YAAA,IAE9B,CAAC,IAF2C,EAE3C,EAAW,CG4DC,AgGmPU,AnG/SV,KACE,EAAU,KAAV,EAAU,IACF,EuByGG,+CvBvGjB,AAIM,CqGqFL,AT/DE,gB5FpBE,IACV,MAC2B,E4FqBI,C5FrBD,A4FqBE,O5FxBJ,EAI5B,C2F8GK,C3F9GD,CyGvCG,GAAA,CzGuCE,S0FuH6B,O1FrHxB,CAAA,EAAO,C0FqHiB,mB1FhHxB,C2FgHG,G3FpHO,GAIb,EACJ,IAEO,uCAElB,IACO,CACT,CAAC,CAAC,EAEe,KACf,C0F2HC,EAAA,IAAA,EAAA,C1F1HoB,CGiEK,KHvEI,GAMF,EAAM,C2FoHP,E3FpHO,CAAA,CAA6B,KmGkUlC,uBnGhUzB,CIuCO,AqG7EF,MAAA,KzGsCO,KAAA,CAAA,iBAEC,EACX,GAAI,CAAC,AACH,CAFS,EAEL,GAAG,GAAK,CAAU,C4FkCA,A5FlCC,EAAA,MAAiB,CAAG,CAAC,CAAA,CAC1C,OAAA,KAAY,KAAK,CAAA,EAAA,SAAqB,CAAA,EAAI,CGsEW,CHtEA,WAAW,CAAC,GAAG,IACtE,OAAO,C0FoIS,ASiMA,ITjMA,K1FpIC,CAAC,CkGqJG,ClGrJQ,C0FoIS,Q1FpIA,CAAC,CAAC,CAAA,EAAa,WAAW,CAAC,GAAG,UAC7D,CAAC,CAAE,CAAC,CAEf,EAAoB,E2F2HE,CAAC,I3F3HI,SAIzB,EAAQ,MAEO,OAAP,CAAA,EAAO,EAAA,KACJ,CAAA,EAAA,EAAA,CAAA,MAAkB,EmG0UE,MnG1UM,CAAC,CAAU,AGyET,AgGiQA,CnG1UU,EAAA,GAAA,UAE9B,EAAY,C2F6HD,CAAC,C3F7HM,EAApB,AAAmB,AAAmB,CAArC,AAAmB,GkGuJvB,2ClGpJN,KAAK,CAAA,EAAY,G2F+HK,M3F/HI,CAAC,EAAO,IkGsJE,MlGrJzC,EAAG,CAAC,AACX,AAA2C,MAA3C,EAAA,SAAwB,CAAA,EAAQ,CG2EG,CAAC,CAAC,CH3Ea,EG2EI,AH3EQ,GAAK,AAAZ,CAAC,CAAW,AACjD,EADyC,0BAGzD,OAAO,G4FsCK,C5FtCD,CAAC,CqGiGG,IrGjGE,CAAA,EAAY,O4FsCS,E5FtCA,CAAC,EAAO,C4FsCF,C5FtCa,QAAD,GAAY,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,kBAEjD,CAAC,CAAC,KAK7B,EAAY,CyG9BL,CtG6GK,AuF2WJ,a1Fzba,SAAU,QAAQ,CAAC,CAAU,CAAC,EAAO,CAAC,CAAE,CAAC,AAAN,KAKvD,MAIyC,EAAO,CG8ET,GuFuWC,E1Frbc,GAAG,SAAS,GAAG,CAAC,C0FqbX,A1FrbY,C0FqbX,6GC/hBlD,EAAA,6GAeS,CAAA,CAAA,cACgB,8CACK,oCAM7C,CAAA,CAAA,CAAA,CAAA,CAGA,IAAA,EAAA,IAAA,GAAA,qBAEE,EAAA,kBAAA,CAAA,EAEE,CAAE,GAAA,CAAA,CAAW,OAAA,CAAA,CAAY,EAAA,IACpB,CpBjH6E,AoBiHtE,C1DtG6E,A0DsG3E,QAAS,CAAE,GAAG,GAAS,CL1HgC,GK0HlC,GAAS,CAAE,4BAA6B,QAAQ,CAAE,CAAE,CACxF,CACF,CAAC,iCAwMgC,CAClC,CAAA,CAAA,wHAM8C,CX9RgC,SAAA,CAAA,KW8RhB,EzC/SE,AyC+SA,sBAE9C,IAAA,CAAlB,IAAI,CAAgB,CAAC,kBAEW,CAAA,WAAA,CAAA,MAAA,CAAA,CAC5B,GAAG,CAAA,CAAQ,OAAA,CAAA,CAAY,CAAE,CAAA,IACtB,ChB/T2B,CgB+TlB,EhB/TkB,KgB+TV,IAAA,CAAK,UAAA,CAAW,MAAA,+CAGN,CAAC,cACnB,IAAA,CAAA,IAAV,CAAW,8EAKa,CAAA,GAAC,IAAA,CAAA,GAAA,IAAA,IAAgB,IAAA,CAAhB,IAAI,CAAc,CAAC,CAAC,4BAKnD,CAAA,CAAA,6EAK0B,QAAA,IAAA,IAAmB,CAAA,UAAA,CAAA,KAAA,wBAE3B,GQpCI,CAAA,CRoCtB,IAAI,CAAgB,CAAC,QQpCiB,CAAC,2CRsC2C,CAAA,UAAW,8BAGlE,EAAA,EAAA,6BAEC,IAAI,CAAA,GAAA,IAAA,IAAY,IAAA,CAAhB,IAAI,CAAc,CAAC,CAAC,OAG1C,CAAA,GAAA,IAAA,EAHsC,EAG5B,IAAA,CAAd,IAAI,CAAW,KAAK,CAAC,CAAC,kBAGH,CAAA,MAAA,EAAA,uDAGU,CcpZwB,GdoZpB,CAAA,GAAA,IAAA,IAAY,IAAA,CAAhB,IAAI,CAAc,CAAC,CAAC,AAwHrD,CAAA,CAAA,GAAA,IAAA,QAxHiD,AAwHjD,GAAA,IAAA,QAAA,GAAA,IAAA,QAAA,GAAA,IAAA,QAAA,GAAA,8BA5WM,CQw0BoC,QRx0BF,EAAS,IAAA,CAAC,EAAD,WAG5B,CAAqC,eACxC,CAAA,GAAA,COKgB,GPLG,CAAC,EAAO,ElEPgD,CAAC,CkEOlD,AlEPmD,CkEO7C,CAAC,CAAC,gJAWvB,aAEvB,CAAA,GAAA,IAAmB,CAAC,CnDOoD,CAAC,AmDP9C,CnDO+C,GmDPhD,CAAM,CAAC,CAAG,KAAK,CAAC,aAIyB,Cc5JC,Qd6JhE,CAAC,KAAA,CAAA,gBAEU,GxFnEoB,CAAA,CAAA,GAAA,IAAA,IwFmEU,IAAA,CAA9B,IAAI,CAA2B,KAAK,CAAC,CAAC,0CAGvB,EAAE,CAAC,AlB1DN,AwB4CM,ACmBA,IPJ7B,EAAiB,EAAW,OAAA,CAAQ,CxFpEG,CAAA,KAAA,CAAA,AwFuEnB,cAAZ,CAAC,OAAO,EAAI,EAAA,OAAA,EACA,OAAS,aAAA,EAAA,OACX,EAAA,SACtB,CAAC,uBAC4B,KAAA,CAAA,OAAA,CAAA,EAA8B,KQ+LG,EAAA,CAAA,OR/LY,CAAC,CAAC,UAClE,CAAA,gBAAA,SACM,KAAK,CAAA,OAAA,UACT,EAAe,CX7CO,AyBhHxB,Md6JwB,CAAA,OAAQ,CACxC,OAAA,EAAA,OAAA,CAAA,MAAA,IAIJ,AACsB,MADtB,EAAA,KAAA,CAAA,OACsB,EAAA,EAAA,OACE,EAAE,CQ+LK,MAAA,aAAA,EAAA,OAAA,EAAA,cR5LxB,KAAK,CAAA,gBAAkB,C3F3FC,AiGqGI,CAAC,AjGrGJ,CiGqGK,AzF1BE,AR3EN,W2F4FV,CAAA,OAAA,YACM,OAAA,CAAA,OAAA,uCAIiC,EAAA,OAAW,EXpDZ,WWoDyB,AACpF,CZgBC,AvE/BF,GAAA,CmFeM,CnFfD,IAAA,CAAA,yBmFeiC,SAC1B,CDTO,CAAA,QCSQ,EAAE,CUdK,OVe/B,SAAA,EAAyB,QAAA,EAAA,SAAA,EAAA,wBAIG,IAAI,EAAA,EAAA,OAA0B,EAAE,CO0BG,GP1BC,GAAK,WAAW,EAAE,CAAC,mCAChD,C3F/FK,U2FgGxB,QAAA,EAAU,CxFtES,AK2DA,kBmFYV,CvF9EO,AiG+DJ,OVeK,EAAA,SAAA,EAAe,4BAIb,IAAA,CAAzB,IAAI,CAAsB,cAAc,CAAC,CAAC,eAExB,EAAE,CAAC,GACjC,IAAA,CAAA,GAAA,IAAA,IAA2B,IAAA,CAA3B,IAAI,CAAwB,GAES,IAAI,OAFC,CAAC,CAAC,kBAEX,EAC/B,GAAA,C3FjG0B,AQuFI,A6FTN,GVmBpB,CAAA,GAAA,IAAA,IAAuB,IAAA,CAA3B,IAAI,CAAwB,EAAgB,EAAM,GAAD,OAAP,aAA+B,CAAC,CAAC,QAI5C,CAAC,UAAU,EAAI,EAAE,CAAE,CAAC,yBACpB,CvFhFC,CDSG,CAAA,EwFuEU,KAAK,EAAE,CAAC,GACrD,IAAA,CAAA,GAAA,IAAA,IAA2B,IAAA,CAA3B,IAAI,CAAwB,GAGK,WAHS,CAAC,CAAC,kBAGX,EAC/B,GAAA,IAAI,CAAA,GAAA,IAAA,IAAuB,IAAA,CAA3B,IAAI,CAAwB,EAAgB,EAAM,GAAD,OAAP,aAA+B,CAAC,CAAC,CAAhD,EAIzB,uBAAuB,CAAG,EAAS,KAAK,CAAN,AAAO,QAGtC,KAAiB,EAAO,KAAK,CAAA,UAAA,EAAA,EAAA,CAAA,2BACoB,EAAE,CAAA,EAAA,KAAoB,CAAC,CAAC,AAC7E,GAAA,MAAwB,IAIP,OAAS,YAAY,CAAC,EACtC,CAAA,KAAA,CAAO,GvFjFG,mCAAA,MuFkFN,EAAiB,QAAQ,EAAE,IAAI,CACrC,MAAO,EAAc,CQwMS,IRxMJ,GQwMW,URvMT,QAAQ,CAAC,SAAS,kBAC5B,EAAiB,GpELW,KoEKH,CAAA,gBAAA,mBACZ,QAAQ,C3F9GQ,CAAA,W2F8GO,EAAE,MAG9C,EvF9EA,CuF8EkB,EIvIL,A3FyDV,QuFkFtB,GAAA,SAEsB,CAA6C,CAAE,CAAqB,EpEDc,CAAC,CAAC,CoEEnG,GAAQ,IAAI,CAAA,GAAA,IAAA,IAAqB,IAAA,CAAzB,IAAI,CAAsB,cAAc,CAAC,CAAC,EAC/B,CAAA,GAAI,CAAA,GAE3B,aAGuB,AALqB,CAAC,CAKP,OAAO,CAAC,UAAU,EAAE,CAAC,EAAc,CAAC,IACvE,MADqE,qCAIrE,EAAA,IAAA,EAAuB,KACpB,AAAI,MAAA,wCAGkB,CctJL,ArGyEI,cuF6ER,IAAI,CAAiB,KAClC,EAAA,GAAY,IAAI,CAAA,GAAA,IAAQ,EAAE,KAAK,EAAE,IAAI,CACzC,AAAC,GAAS,CAAD,AAAJ,EAAkC,AAAhC,IAAoC,AAAK,CAAJ,CAAS,EAAD,MAAS,CAAC,IAAI,GAAK,EAAiB,CAAlD,OAA0D,CAAC,IAAI,CAAd,AAC9C,CAAC,CAAC,+CAEI,GAF8C,aAG9D,CAAC,IAAI,CQ4MG,CAAC,OR1MxC,UAAW,ECxFa,QDwFY,CAAC,ECxFa,ODwFJ,kBAE5C,GAAmB,GAAa,ECzFmB,ADyFT,COyBD,QPzBU,CAAC,EAAiB,QAAQ,CAAC,KAAV,IAAmB,CAAC,CACtF,EOyBI,A/F5EM,CHjEF,CAAA,QAAA,O2FoHqB,KAAK,KAAK,CAAA,EAAkB,QAAQ,CAAC,SAAS,CAAC,CAAA,aAG7E,IDK6B,ACJL,CCpFK,CMkHP,EAAA,GP5B9B,GAAA,SAEsB,CAA6C,MAC5D,EAAQ,CCrFC,EDqFD,IAAI,CAAA,GCrF4B,AAAC,CAAA,GAAA,IDqFR,IAAA,CAAzB,IAAI,CAAsB,MAEpC,EAAe,MAFmC,CAAC,AAE7B,CAF8B,AAE9B,OAAQ,EAAA,CAAA,EAAW,YAAA,CAAA,GACrC,YAAA,CAAA,CAAA,QAEiB,GAAA,IAAI,CAAA,GAAA,IAAA,IAAgC,IAAA,CAApC,IAAI,CAAkC,CAAC,UAEpD,CAAC,eAAgB,CDYG,QCXnB,CO4BC,CAAC,AP5Ba,CAHiC,IxFhDrC,EwFmDW,CAAC,OAAO,QAC/B,CvF9ES,CuF8EQ,C3F3HC,A4FmCM,CDwFQ,SAAS,CAAC,EAAe,OAAO,CAAC,IAAT,GAAgB,CAAC,CAAC,AAAG,CAAF,GAAc,YAI3E,CAAC,OAAA,EAAA,CAAY,EAAM,GxFnDG,CAAC,CAAC,OwFmDO,kBAClC,OAEjB,CAAA,KAAM,CAAC,eAAgB,CAAE,EOyBF,MPzBW,EAAe,COyBH,A/F5ET,MwFmDmB,CAAC,OAAO,CAAE,CAAC,CAAC,GAGvD,QAAQ,EAAA,SAAa,CAAC,EAAA,qBAAA,EAA6B,CAAC,EAC/D,qBAAA,CAAA,CAAA,OAED,KAAA,CAAA,wBAAA,CAAiC,QAAS,EAAe,QAAQ,CAAC,OAAO,CAAE,CAAC,CAAC,aAGvD,EOuBF,ClGtJG,MAAA,C2F+HW,EAAA,qBAA2B,EAAE,CAAC,gCAGhE,KAAK,CAAC,CDuTC,CEpZG,sBD6FqB,WAA0B,QAAQ,CAAC,OAAO,CAAE,CAAC,CAAC,AAEtF,CAAC,CAAA,GAAA,wBAGe,CUlCD,CVkCG,CAAC,AC9FA,ID+FT,IAAI,GAAA,yCAAqD,CAAC,CAAC,MAElD,GAAA,IAAI,CAAA,GC5FiC,KAAA,ID6FjD,EC5FE,MD6FC,EADO,EACH,GAAA,0CAAsD,CAAC,CAAC,cAEhE,CAAA,QAAkC,EAAS,IAAA,CAAC,EAAD,SACrB,EAAA,CAAA,KACnB,AAkPX,SAAS,CACyB,CgB3cK,AhB4crC,CAAyC,CD7HN,UC+H7B,IAAE,CAAE,AZ7cgB,CY6cd,MgB7cW,GAAA,ShB6cF,CAAO,CAAA,MAAA,CAAO,oBAAE,CAAkB,CAAE,GAAG,EAAM,CAAG,CAAL,OgB3cpC,AhB2ciD,CAAC,AA2FvE,GgBriBsB,CAC1B,EhB2cE,CAAI,cAEE,EAAQ,EAuFa,CAvFV,CAClB,CADc,AACb,SAAE,CQuNuB,CRvNd,EQuNc,aRvND,CAAA,MAAA,CAAO,UAAE,CAAQ,CAAE,GAAG,CQuNoB,CAAC,ARvNT,EAAyB,EAAE,IAC/E,EACH,MAAA,IAAU,CQuNC,ERxNO,AACI,CADH,AACG,CQsNF,AACI,CQjqBD,+BRiqBC,ERvNkC,EAAK,CAAE,CAAC,CAGpE,AAHqE,AAAJ,GAG3D,CgBrcG,AhBqcD,EgBzciB,CAC5B,IhBwckB,EQsNF,CRtNK,IAAI,eAAE,CAAa,IQsNZ,CAAC,ORtNa,CAAU,CAAE,GAAG,EAAa,CAAG,EAChE,EAAO,EAAH,AAAW,CADwD,CAAZ,AAAa,EACtC,CAApB,AAAqB,AACzC,CAD0C,EACtC,CAAC,EACH,EADO,AgBjcD,EhBicG,CAAC,CACJ,CgBlc8B,EjBqUlB,CC6HR,GAAY,CAAA,wBAAA,EAA2B,EAAK,CAAE,CAAC,CAAH,GAGpD,EAAa,KACP,GgBlcK,CADE,CRwpBD,CRtNC,IgBjcF,CAAA,CAAA,KAAA,ChBkcgB,CAAA,CAAK,KACtB,MAAR,AAAc,CAAC,CACjB,CQqNK,IQxpBoB,CAAC,AhBmcpB,CgBlcG,ERwpBA,CRtNC,GAAY,CAAA,EgBlcK,QhB0bgI,iCgB1bhI,EhBkcyC,EAAK,CAAE,CAAC,CAAH,AAAI,GAG3E,CAAA,EACF,CD5HG,GC2HM,CAAC,CACJ,GQoNG,CRpNC,GAAA,CAAA,sCAAA,EAAqD,EAAK,CAAE,CAAC,CAAC,AAG1E,AAHsE,MAG/D,CACL,GAAG,CAAU,ED5HI,AiBvUI,IjBqUL,GC+HP,CACP,CgBpca,CjBuUH,CSiVD,ORnNT,IQoNQ,UAAA,WRpNoB,QAAU,CAAE,MACxC,UACS,EAAQ,KAAD,EAAQ,EAAI,sBAG9B,iBACA,EAEJ,CAAC,OAED,AAAI,EACK,CgB3bA,AhB4bL,GAAG,CAAU,EQuNH,GRzNE,CAAC,CAGb,OQmNqB,SRlNrB,WACA,EACA,EgBtba,MhBsbJ,CACP,CgBvboB,EhBubjB,CAAW,4BAGG,IQ8NsC,GR9N/B,EAAI,IAAI,CAChC,IQ6NuE,CAAC,CAAC,KR7N7D,EAAW,GAAG,CAAC,CAAC,CDzHF,CCyHa,CAAC,EAAE,EAAE,AAC1C,EADmC,CAC7B,CQ6N+B,SR7NnB,CAAE,CAAA,KAAA,CAAM,IAAE,CgBjbkB,ChBibd,GAAA,EAAa,CAAG,EAChD,CAAQ,UAAA,CAAe,MAAE,CAAA,CAAM,GAAG,EAAM,CAAK,GAAL,AAAW,CAAA,CAAE,CAAC,AACtD,GAAI,MAAA,EACF,MAAA,IAAU,GAAY,CAAA,KQ6NgB,WAAA,ER7NG,CQ6NW,CR7NN,GQ6Nc,UAAA,ER7NE,CAAC,AQ6NU,CAAA;AAAA,ER7ND,GAAG,AQ6NU,GAAA,CR7NE,CAAC,CAAC,AAE3F,GAAY,GDzHW,GCyHnB,AAAc,CAAC,CACjB,EADM,ADzHQ,IC0HR,IAAI,GAAY,CAAA,gBAAA,EAAmB,EAAK,GAAA,UAAA,EAAgB,CAAC,CAAA;AAAA,EAAW,GAAG,AAAC,GAAS,CAAE,CAAC,CAE5F,AAF6F,EAAL,CAAC,AAE7E,MAAR,AAAc,CAAC,CACjB,EADM,IACA,CgB7aoC,GhB6ahC,GACR,CAAA,gBAAA,EAAmB,EQ6NuC,EAAA,WAAA,ER7NlB,CAAC,CAAA;AAAA,EAAoB,GAAG,AAAC,GAAS,CAAE,CAC7E,CAAC,AAEJ,EAH6E,CAAC,AAGlE,IAAI,EAAZ,AAAc,CAAC,CACjB,MAAM,IAAA,GACJ,CAAA,EgB7aU,cAAA,EhB6aS,EgB3alC,EADkB,ChB4aqB,AgB3avC,UAAA,EhB2auD,CAAC,CAAA;AAAA,EAAyB,GAAG,AAAC,GAAS,CAAE,CAClF,CAAC,AAGJ,EAJkF,CAAC,GQ8NrE,AR1NP,CAAE,GAAG,CAAQ,CAAE,CQ0NC,IR1NG,IAAI,GAAE,QAAQ,CAAE,CAAE,GAAG,CAAM,CAAE,IAAI,GAAE,SAAS,CAAE,CAAI,CAAE,CAAE,AAClF,CAD8E,AAAK,AAClF,CAAC,GAID,CACL,GgBzaS,AhByaN,CQoOK,AT9VE,AC0HG,GQoOmB,CTnWN,KCgIjB,IAAK,CAAW,SAAE,OAAO,AAAE,EAAM,MQoOM,ERpOG,EAAQ,KAAD,EAAQ,CDzHC,CAAC,ACyHE,CDzHD,GCyHK,CAAE,eAC5E,MgBxae,EhByaf,IDxHM,CCwHD,AQqOE,MRpOP,EAEJ,CgBraW,CjB4SD,SC2HZ,QACA,8BAEI,EAAqB,oBAAE,CAAkB,CDtHd,AS0VN,ARpOsB,CDtHf,ACsHgB,AAAE,CAAD,AAAC,CAAE,CAAC,OAGX,IgBhaW,c5BjHhB,UAtBQ,CAAC,UAGZ,AAAC,iBACkC,UAAU,CAAC,CAAC,AazEN,C9EqBxB,A8ErByB,uCbgFpE,GAAI,EAAA,OAAA,CAAe,UAAA,CAAA,qBAEW,CAAC,UAAU,aY2hBrD,CAAC,CAlVU,EAAiC,GAAA,IAAI,CAAA,GAAA,IAAQ,CAAC,CAAC,mBA2DhD,EAAiB,GAAA,IAAI,CAAA,GAAA,IAAQ,EAAE,eAAe,CAAC,UACX,GACxC,EAGK,CU9F2D,WV0FP,CAAC,AU1FkB,KViGtD,CAA0B,cAClD,COrUG,GPqUC,EAAW,GAAA,CDyPkB,CAAC,CAAC,CCzPhB,CAAA,GAAA,cACX,CAAA,CAAA,GAAY,EAAM,CAAG,MAUxB,GAAM,CAAA,MAAA,CAAO,CAAA,cAAA,CAAe,OAAE,CAAK,UAAE,EAAW,IAAI,CAAE,GAAG,EAAO,GAThE,EAMH,OAAA,MAAa,CAAA,EAAW,KALb,GAAA,IAAI,CD0PsB,GC1PY,KACxC,CACP,QAAS,EAAE,OAM0D,EAAM,EUzF3C,CAAC,IVyFiD,EAAE,CAAC,IACnF,EAAS,EC/IoC,AD+I3B,CC/I4B,MD+I5B,CAAQ,EAAA,IAC1B,AAAC,QAAQ,AACO,CADN,AchNO,CADN,KdkNY,CAAA,EAAO,CAAG,Cc/MvB,cd+MyB,EAAe,Ec7M5C,Md6MmD,QAAS,CAAA,CAAE,Cc5MzD,Wd4MqE,GAAG,CAAK,CAAA,CAAE,CAAC,EAI7F,GAAK,CAAD,CAAC,QAAA,CAEE,CAAC,AQ2KE,GR1KF,CAAA,QAAA,CAAA,SAAW,CQ2KO,AR3KA,CQ2KC,AR3KC,GAAG,EAAM,CAAG,CAAL,CACjC,GAAc,GACd,Ac7MqB,Ad2MyB,CAAC,MAExC,EC3IQ,COuTD,AMrXA,Ab8DE,CAAC,EAAA,CD2IH,CczM8B,CdyMvB,IAAD,IAAS,CAAE,GAE/B,SAAa,AACJ,QAAA,EAAS,GQ2Kc,EAAE,CAAC,CR3KV,GAAA,CAAA,CAAP,OAAO,CAAK,EAAA,AAAE,EAAC,EACxB,QAAQ,CAAC,OAAO,CAAC,IAAA,IAAQ,CD0PK,UCtPrC,EAAA,QAAA,AAAe,EAAC,OAAO,GAAA,CAAA,CAAP,OAAO,CAAK,EAAA,AAAE,EAAC,AAC/B,EAAO,QAAQ,CAAC,Cc1MK,MAAA,CAAA,Id0MO,CAAC,Cc1MK,CAAC,Cd0MH,WAb3B,QAAA,CAAW,CO5SO,MP4SA,CUvFS,CAAC,IVuFJ,CAAC,CAAA,EAAI,GAkBxC,GAAA,CO9TqD,CP4SL,CAAC,CAAC,EAmBzC,aAAA,CAAA,KAEH,IAAI,CAAA,GAAA,MAAY,GAAsB,GAAA,IAAI,CAAA,GAAA,IAAQ,CAAC,EAAd,AAAgB,CAAC,GAClC,UAAU,CAAC,AAA7B,aAAa,EAIjB,GAAsB,AAAtB,gBAAsC,EAAE,CAAxC,AAAyC,EACvC,MAAA,IAAA,GAON,gBAFa,CAAC,EAAQ,CQgLC,ER9KvB,CAFoB,AAEf,CAFsB,CAEtB,AAFuB,CAAC,SAEP,EAEhB,SAAE,CQ+KG,CAAA,CAAA,OAAA,CR/Ka,CAAE,WAF8B,IAEjB,MAAE,CAAI,CAAE,YAAU,CAAA,GAAK,CDrItC,CAAC,ACqI2C,CAAG,CAAL,CA4BlE,GA5B4E,CAAC,EAC/D,UACP,MAAA,CAAO,EAAO,OAAO,CAAE,GAE9B,CAFkC,CAAC,CAAC,CAGlC,EAAO,GADI,CACL,GAAQ,CAAC,OAAO,CAAI,AAAD,GAAQ,GAAD,IAAQ,CAAC,OAAO,EAAI,EAAA,CAAE,CAAC,AAAG,CAAA,CAAO,CAAC,AAGhE,IAAI,AAAE,EAAO,IAAD,ADpIS,CAAC,ASoTR,ERhLM,CAAA,IAAK,CAAG,CAAA,CAAI,CQgLH,ARhLI,AACjC,IACG,EQgLI,ARhLG,EQgLI,KRhLG,CAAA,CADF,YACgB,EAAE,AAG7B,CAH8B,CAGhB,CQ6KoB,EAOzB,CRpLK,GAAM,EAAO,CQqLf,GRrLc,ADjIP,GCiIe,CAAC,QQqLR,KRrLqB,CAAC,IAAI,CAAG,EAAc,IAAA,AAAI,CAAC,CAC3E,EQqLY,GRtLyD,IDhIpD,CSsTL,CRrLW,EAAE,CAC3B,CAAA,EAAA,EAAO,OAAO,CAAC,aAAA,AAAa,EAAC,SAAS,GAAA,CAAA,CAAT,SAAS,CAAK,EAAA,CAAE,CAC7C,CAD8C,CACvC,CQsLA,CAAC,ERtLF,GDlIK,ACkIG,CAAC,SQsLa,IRtLA,CAAC,IQsLQ,KRtLC,CQsLK,CRtLD,AQsLE,ERtLY,SAAS,CAAC,CAAX,CALzD,CQgLK,CAAC,ARhLC,IAAD,GAAQ,CAAC,CDnIS,YCmII,CAAG,GAS/B,IACF,EAAO,GQwLG,CRlMoC,CAAC,EAUjC,CAAC,KQwLK,ERxLE,CAAG,CAAC,EAAO,OAAO,CAAC,OAAO,EAAI,EAAA,CAAE,CAAC,AAAG,EAEtD,CAAC,EAAO,EAFqD,CAAC,CQyLvD,ARvLA,GAAQ,CAAC,CQuLC,MRvLM,EAAI,GAAA,IAAI,CAAA,GAAA,IAAA,IAAgC,IAAA,CAApC,IAAI,CAAkC,EAAE,CAAC,AACtE,EAAO,GQuLK,CRvLN,GAAQ,CAAC,GDjIW,GCiIL,CAAG,CQuLC,ERvLY,EAAO,IAAD,GAAQ,CAAC,MADa,EACN,CAAC,CAAC,CAI7D,EAGF,IAAK,GAAM,CAHC,AgB7dG,AR+pBJ,CQlqBM,ChBgeH,CAAC,GAGF,CAAK,GgBheK,ChBgeH,CAAE,CDjIO,KCiIL,CAAI,CAAE,AQ+LF,SR/LY,CAAE,CAAE,EQ+LS,CR/LN,CQ+LQ,CR/LF,GAFjD,AAAC,EgBheM,AhBgeC,EQ6LI,ER7LL,GAAQ,CAAC,KDjIW,CAAC,ES8TF,CAAC,CAAA,GR7LC,CQ+LzB,CR/LgC,OAAO,CAAC,UAAU,CAAG,EAAA,AAAE,CAAC,CAEN,GQ+LU,AR/LE,CACnE,AADoE,EgB/drD,EhBgeT,EAAY,CAAA,EAAC,CQ+LW,CR/LJ,EgBhegB,KhBgeT,CAAC,UgBhe4B,AhBgelB,CAAA,CAAC,EAAK,GAAA,CAAA,CAAL,EAAK,CAChD,EADgD,AAChD,CAAoD,CACtD,CADuD,CAAC,IAClD,CAAC,CQ8LK,KR9LC,CAAC,EAAW,GACrB,CADyB,CAAC,AQ8LI,CAAC,AR9LJ,CQ8LK,AR7L5B,EAAA,EAAY,CAAG,CAAA,CAAE,CAAC,AACtB,GQkMS,CRlML,AQkMK,CAAA,CRlMO,IAAI,CAAG,CAAA,CAAI,CAAC,AAC5B,GAAA,CAAA,EAAc,CQoMC,ORpMO,GAAlB,CAAkB,CAAR,OAAD,CAAS,CAAK,CAAE,IAAI,CAAE,EAAE,AAAC,IAAI,EAAI,EAAE,CAAE,SAAS,CAAE,EAAE,CAAA,CAAE,EAAC,AAClE,EAAE,AQoMI,CAAA,GTpU2E,CACtF,CAAC,EC+Hc,EAAU,QAAS,CAAC,IAAI,CAAG,EAAE,AAAC,IAAA,AAAI,CAAC,eAC9B,CAAC,EACR,QAAS,CAAC,SAAS,EAAI,EAAE,AAAC,SAAS,CZnRnD,AYmRoD,AAE1C,GgBxdkB,M5BoMhC,CAAA,CAAA,CAAA,MAGK,GAAU,EAAE,UAAA,CAAA,CAAiB,CAAC,CAAI,CAAA,EAAA,KAAa,QAC3C,sBAIN,GAAA,GAC8B,IAAc,EAAU,CN7E5B,CAAA,MM6EoC,EAAE,IAAI,GAAK,EAAS,IN5E5D,IM4EoE,CAAC,EN5EvD,EAAA,iBMgFpC,GAAA,IAAA,GAAA,SAAqD,QAAA,CAAA,CAAA,GYuQtB,GgBxdkB,AhBwdlB,CgBxdmB,GhBwdf,CAAA,GAAA,IAAQ,CAAE,OAC1B,EADmC,CAAC,AQwMvB,CAAC,CRxMwB,AQwMvB,CRxMwB,EAC9B,CAAC,gBAAgB,CAAG,GDzH9B,ACyH2C,EAAU,OAAX,AAAU,CAAU,CAAC,UAAS,CAAC,CAAC,AAGzF,CAEJ,CAAC,AACD,OAAO,CgBtdG,EhBydX,OAAO,aAAA,AAAa,EAAC,EgBxdU,OhBydW,EAAE,CAAC,ADxHrB,ACyHjB,EAGA,CD3He,CC2Hb,CACJ,AgB3dS,ERkqBL,CAAA,aRrMJ,CAAC,EAAA,CAAG,QAAS,AAAC,IAChB,CgB5d4B,AhB2dP,GACf,EAAS,EAAU,EAAb,GAAkB,EAAN,AAAQ,CAAC,AAC7B,CD3HO,CC4HT,EgB1dM,AhB0dC,GQiNE,CRlNC,AACJ,GAAQ,CAAC,GAEf,EAFoB,AgBvdV,ChBudW,AD3HM,CC2HL,AgBvdZ,EAAA,ChBydK,KAInB,IAAA,CAAK,EAAE,CAAA,MAAA,KAEL,IAAK,IAAM,KADX,GAAO,EQuNI,ARtNU,ADzHV,CACW,ECyHpB,EgBldQ,OhBkdM,MAAC,GAEjB,EAAU,EgBjdF,ER2qBF,ER1NI,CAAA,IAGZ,IAAA,CAAK,EAAE,CAAC,EQyNA,MRzNS,AAAC,IAEhB,IAAK,GgBjdO,ChBidD,OADJ,GACc,GACnB,EQyNM,IR1NsB,CAAE,CAAC,AQ0NzB,CRzNQ,CgBjdY,IhBmdlB,MAAM,CAAG,CAAC,AACtB,CADuB,AACtB,CAAC,CgBjdkC,AhBidjC,IAEC,CAAC,EAAE,CAAC,QAAS,AAAC,GAAG,ED1HF,AC0HI,AgBjdO,GhBmdvB,EgBhdM,EhBgdA,QADJ,EACc,EADV,CgB/cwB,AhBidjC,CgBhdO,ChBgdA,KADuB,CAAC,AACxB,CAAA,CgBjdqC,EhBmd9C,EAAU,MAAM,CAAG,CAAC,AACtB,CADuB,AACtB,EAEM,CACL,IgBjdY,AhBidR,CAAE,IgBhda,KhBidjB,AAAI,EAAW,EAAX,IAAiB,CASd,CATgB,AQ8NoB,CR9NnB,ED3HN,GCmIJ,CACE,CADQ,CQsNK,GRrNR,CADQ,EAAG,CAAC,AACV,IAAI,EAAE,CAAK,CAAE,CARlC,AAAI,AAQ+B,EAP1B,AAOuB,CAPrB,GADD,CAAC,OACO,EQwNU,ARxNC,MAAM,CAAI,CAAE,CAAC,AAEnC,CAFgC,CQ2NxB,ERzNJ,GQsN8C,CAAC,CAAC,GRtNP,CAAC,EAAS,IAC5D,CAD0D,AAAY,CAC5D,AADwD,EAAE,EACtD,CAAC,EAAN,OAAQ,OAAO,EAAE,CAAM,CAAE,CAAC,CACpC,CAAC,CADgC,GAC5B,CAAC,AAAC,GAAW,CAAF,CAAJ,AAAc,AAAT,CAAW,CAAd,CAAS,CAAC,CAAC,CAAQ,CAAE,EAAO,GAAF,CAAM,EAAE,CAAK,CAAE,CAAC,AAAE,CAAE,AAAH,CAAJ,IAAY,MAAE,EAAW,IAAI,EAAE,CAAR,AAAY,CAAE,CAAC,CAAC,AAAJ,CAAK,gBAMhG,CgBzcK,GhBycD,CAAC,EQqN+B,CAAC,EAAA,GRpN9B,CAAE,EgBzcI,ShBycG,EAAW,EgBzcI,GAAA,CAAA,ChBycM,CgBzcI,AhBycF,CAAC,CAG9C,CAAC,AAED,EgB9cmD,gBhB8cnD,CAEE,OADe,AACR,IADY,EACN,CADa,IAAI,CAAC,ED1HJ,IC0HU,CAAC,aAAa,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAE,IAAI,CAAC,UAAU,CAAC,CACnE,AADoE,gBACpE,EAChB,CAAC,UAqGM,GAAI,CAAU,EACrB,OAAO,KAAA,SAAc,CAAC,CAAC,CAAC,AAC1B,CAD2B,AAC1B,AA+JD,SAAS,GAAA,CAAiD,EAE1D,CAAC,AAED,SAAS,GAAY,CAAA,EAAY,CAAC,8DR30BmB,CQzBrB,EAC9B,CRwBuD,CAAC,CAAC,wCACV,CKzBG,gCLkC1C,EAAA,IAAA,qCAM4B,4BAA6B,CGzBhC,iBHoBwB,+G3ChBC,IAAA,CAAA,OAAA,SAyCxD,CAAA,CAAA,CAAA,CAAA,8CAG8C,YAAkB,C6DgBf,AlF7De,OqB6CU,EAAK,MAAA,EAAU,mGAqC7E,OAAA,CAAA,IAAA,CAAA,EAAA,CAAA,kBAAA,EAAsC,EAAA,CAAc,CAAE,MAAE,EoDpCP,ApDoCa,GAAG,CAAO,CAAE,CoDpCf,ApDoCgB,MAgBvF,EAAA,CAAA,CAAA,CAAA,CAAA,CAAA,oDAGoD,GAA4B,SAAS,GAAA,CAAU,CAAE,CAAC,CAAC,QgEpD7C,WhEkEnD,IAAA,C6DhCkC,A7DgClC,OAAA,CAAA,MAAA,CAAA,EAAwB,CAAA,kBAAA,EAAqB,EAAY,C8C3CV,A9C2CY,CAAA,uDuCiKpC,cACtB,IAAA,GAAA,CAAA,wEAAA,EACuE,EAAK,CavHhB,CAAC,EbuHmB,CAAA,EAAA,CAAI,CACzF,CAAC,AAGJ,GAAA,AAAiB,CAAA,IAAjB,EAAmC,AAA1B,C0B5LD,O1B4LS,CAAA,MAAA,kCAEU,IAAA,CAAI,0FAAA,CAA4F,CACxH,CAAC,WvCjKO,CAAA,OAAA,CAAA,IAAA,CAAA,WAAA,CACR,MAAA,CAAA,EAAA,4BAGsB,CACnB,CjBJG,2BAAA,4BiBON,WAAA,CAAA,GAA4B,GAAA,EAAgC,eA2B/D,CAAuB,CAAA,oBAGgB,QAAQ,CAC3C,IAAI,CAAC,OAAA,CAAA,EAEL,4BAI+C,EAA6C,AjB9B3C,CvB1DG,qBwCkGjD,GAAA,oBAAyC,CAAA,IAAA,CAAM,OAAO,CAAE,EAAM,uJhB5LpB,OAAA,gCAyD9C,GAAA,AAAsB,oCAGtB,CYdD,AqCUA,GrCVA,KAAA,EAAA,uEZ3BgC,CwCbG,AyBbA,CjE0BM,E0BPP,C6CtBW,4HvEyChC,OAAA,uCAKkB,CAAA,gBAGhB,CsBQG,AtBRF,CAAA,IACP,UAAP,OAAO,EAAA,MAAA,UAAA,kDACwB,EAAA,EAAM,CAAA,CAAA,EAAA,CAAS,KAAO,2BAGzC,WAIK,CAAC,yCAc+B,CAAC,wBAEnC,GAAA,CAAA,kFASG,CAAC,CsBWG,UtBPrB,gBAAgD,qFGlEX,iCAGP,4BAA8B,GAAS,QAAQ,C1BEY,A0BFX,2EOsBhE,CAAA,IAAA,CAAA,wBAEjB,GAAA,+JQb4B,CRaD,KQbG,EAAM,EAAF,CAAK,CsCnBiC,AtCmB1B,CAAE,UAAU,CAAE,CAAE,KAAK,CAAE,EAAK,EAAD,GAAM,CAAE,CAAE,CAAE,IAAI,CAAC,OAAO,CAAC,CACnG,CAAC,WoDrBiJ,CACpJ,CAAC,yE7Ce0F,CAAC,C4CtBvB,EzEkBL,AyElBO,IzEkBP,4D6BMjB,IAAI,CAAA,OAAA,6HMrBX,wBAMjB,CAAA,CAAA,CAAA,2CAC6B,yEAUuB,CAAA,mMKFjB,EAAI,GAAS,CzBOE,oByBOjE,CAAA,CAAA,CAAA,CAAA,8FAGkD,yBAcjC,CAAA,CAAA,CAA+B,CAAA,CAAA,YAC5C,CAAA,OAAQ,CAAA,IAAA,CAAA,EAAU,CAAA,YAAA,EAAA,EAA0B,CAAE,CjBDC,AlBsDD,wCmClDf,eAAe,CAAE,CmCFvC,GnCEkD,QAAQ,CdsBU,ActBT,QAgB/E,EAAA,CAAA,CAAA,CAAA,CAAA,CAAA,QAGO,IAAA,CAAA,OAAA,CAAA,UAAA,CAAA,cAAA,GAA8D,0DAGR,GAAA,QAAiB,CAAC,GRDI,OQc9E,CAAmB,CAAA,CAAA,CAAA,4BACG,EAAA,CAAA,YAAA,EAAA,EAAA,CAAgC,CAAE,CoBuCe,Ce1CZ,Af0Ca,Ce1CZ,CAAC,cnCKzC,eAAiB,eAAe,EAAI,GyC8BD,AzC9BU,QAAQ,+SY5ErB,iGIJG,CAAC,OAAA,oCAEV,IAAI,CAAC,OAAO,CAAC,0H/DFlB,YAElC,kDAC4D,6RECb,aAAqB,CAAC,2BAmBtE,CAAA,OAAA,CAAA,UAAA,CAAA,mBAAA,GAA+E,+DAGlB,GmCgBG,CAAC,wEnCDf,CAAE,MUmDK,YVjD3C,CAAE,AmCqBD,A9CnBA,cWFgB,8BAAsC,cAkBhF,CAAA,CAAA,EAAA,CAAA,CAAA,CAAA,CAAA,CAAA,YAYW,CAAA,OAAQ,CAAA,UAAA,CAAA,EAAA,CAAA,iBAAA,EAAA,EAAA,MAAA,CAAA,CAAA,GAUjB,OAAE,EAAO,GAAG,CAAO,C0EJhB,Q1EI2B,GAAa,EAAG,IgFvBE,UhFuBa,iBAAiB,CAAE,CAAE,GAAS,IAAF,GAAS,CAAC,CAAC,CAAE,CACvG,CAAC,oEEzEI,CAAA,IAAA,GAAA,IAAA,CAAA,OAAA,kCACyD,2FCdtC,EAAA,CAAA,SAAA,EAAA,EAAA,SAAA,CAAA,CAAA,yDAGoC,GAAA,QAAiB,oBAU9E,GAAA,CAAA,UAAA,CAAA,CAAA,CAAA,yBACuB,CAAC,EAAA,CAAA,SAAA,EAAgB,EAAS,CyEuHL,A5D7GA,SbVK,EAAa,EaU0B,CbVf,CAAE,AaUa,iCbR9C,iBAAmB,GAAS,CqBeiB,CwDfvD,qB7ESqB,CAAA,CAAA,kEAEH,CgCuBC,A8BgBhC,SAAA,EAAA,EAAA,CAAA,C9DvCyD,yDAGf,GAAS,GYaI,KZbI,iDAchD,CAAC,EAAA,CAAA,SAAA,EAAgB,EAAA,SAAA,CAAA,CAAA,GAA0C,Cb+CL,+EalCpF,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,iBAImB,CAAA,sBACC,MAAA,CAAA,EAAA,CAAA,SAAA,EAAuB,EAAA,UAAA,EAAsB,EAAA,CAAA,CAAa,IACzE,CAAO,6CACiD,GAAS,QAAQ,CAAC,sEChE1C,CAAG,8EAG5B,gDAC0D,2CAUhD,EAAA,CAAU,C+EwBD,kC/EvBI,CAAA,E6ERE,OAAA,EAAA,EAAA,MAAA,EAAA,E7EQiC,CqB+CE,CAAC,CAAC,GAAA,CrB/CI,CAAE,CmEIpC,EnEJyD,yCAG3D,eAAe,KAAa,QAAQ,qImFzBzC,MAAA,IAAA,6GZmEa,CAAA,4YAcnD,MAAM,CAAC,aAAA,AAAa,EAAC,EAAA,2CASF,QACV,EAAA,EAAmB,KAAA,cAET,CAAA,0CAQL,UAAA,0DAQN,IAAA,UAAA,GACH,EAAA,MAAA,CAAA,YAEiB,CAAC,mDAKY,CAAC,AVxBrB,iBU8BP,uBAEkB,CASrB,OADc,EAAA,KAAe,EAAG,CAAC,KACJ,sDAJX,CAAC,uBACf,GtFzDgF,CsFyD5E,CAAE,AAAD,GAAY,CnBjCW,CmBiCH,CAAE,EAAL,CAAC,CAAC,CAAQ,CAAE,EAAO,GAAF,CAAM,EAAE,CAAK,CAAE,CAAC,AAAE,CAAD,AAAG,CAAP,IAAY,MAAE,EAAW,IAAI,EAAE,CAAR,AAAY,CAAE,CAAC,CAAH,AAAI,CAAC,gBAMhG,IAAA,CAAK,C5E7BK,IAAA,wB4E8B2B,CAAE,CAAC,yCAMzB,uBACM,mBAAA,CAAA,gCAKzB,CAAA,CAAA,CAAA,CAAA,KAGM,EAAA,GAAA,gEAGmB,CAAA,QAAA,IAAgB,IAAI,CAAC,UAAU,CAAC,KAAA,6BAG1C,GAAA,kBAAyB,CAAA,EAAuC,IAAI,CAAC,UAAU,CAAC,CAAC,cAC/E,KAAA,KACf,IAAA,CAAA,GAAA,IAAA,IAAA,IAAA,CAAA,IAAI,CXwB+E,yBWtBzD,EAAE,CKlEC,2BLqExB,IAAA,CAAK,CnENC,AwD+BN,MAAA,CAAA,GWzBa,IAAA,CAAA,GAAA,IAAA,IAAgB,IAAA,CAAhB,IAAI,CAAc,CAAC,CAAC,0DAIW,CAAA,CAAA,IAAA,CAAO,IAAI,CAAC,CAAE,IAAA,CAAA,UAAe,uDAKnE,CAAA,CACH,Ce5IyB,CAAA,Cf8InC,Ce9I6C,CAAA,KfgJvC,EAAA,IAAa,YACZ,IAAA,CAAA,IAAA,EAAA,uBACyB,CAAA,EAAQ,EAAA,EAAA,KAC1B,SACD,CvFvDC,GuFuDI,GAAS,CXuBG,AYTN,CpE3BC,A4E0NF,AnB3OM,KU8BK,CnBhCC,4BmBgC8B,CCcH,YDXvD,QAGO,2BAAA,CACL,CAAA,CACI,CQwByB,ARvBtC,CAAA,CAAA,CACwB,CAAA,qBSuLga,CACrb,CAAC,cTpLuB,UAAA,CAAA,KAAA,sBACD,CnEjBL,OAAA,ImEiBoB,IAAA,CAAK,EQ0BI,A/FtFA,QuF4DM,CAAA,KAAM,CQ0BG,CR1BD,UAGZ,GAAA,CAAS,oBACxC,EAAA,iBAAqB,CAAC,EAAO,CVzCC,CAAA,KU0CvC,4EAOV,IAAI,CAAA,GAAA,IAAA,IAAU,IAAA,CAAd,IAAI,CAAW,KAAK,CAAC,CAAC,WAEH,CAAA,MAAA,EAAA,gDAIG,CAAA,GAAA,IAAA,IAAY,IAAA,CAAhB,IAAI,CAAc,CAAC,CAAC,OAGnC,4BAAA,CAAA,CAAA,CAAA,CAAA,CAGmB,CAAA,OAET,IAAI,gBACR,CAAA,IAAA,EAAA,sBAAA,CAAA,EAC6B,EAAA,eAEzB,GAAA,GAAA,OAAA,6BAAkD,QAAQ,cAMpE,sBACL,CvFnES,CuFoET,CerJkC,ArGwEF,AsF6EtB,CACV,CAAiC,CX2BN,CAAA,CAAA,KWxBrB,EAAA,IAAa,YACZ,IAAA,CAAA,IAAA,EACE,EvFxEgB,A+F+FN,A9FxGI,iBsFiFK,CAAC,EAAA,EAAgB,EAAQ,eAEtC,GAAA,GAAY,OAAA,CAAS,4BAA6B,aAG1D,wBAIA,GAAA,IAAI,CAAA,GAAA,kBAIX,OAAO,GAAA,IAAI,CAAA,GAAA,IACb,CAAC,gCAGQ,GAAA,Ce5JiD,APmLrC,GOnLqC,CAAA,GAAA,If6J1D,CAAC,mCAGQ,IAAA,CAAA,GAAA,IACT,OAEM,eAAA,iCAGU,MAAA,CAAO,GAAA,ECJiB,ApELQ,EoEKR,CAAA,GAAA,YDOlC,eAAA,cACE,IAAA,CAAA,IAAA,GAEC,OAAO,Ce5JD,Kf4JO,CAAC,GAAA,ECPmB,CAAC,CAAA,CAAA,GAAA,YDUrC,CtFrFD,SAAA,0BsFuFE,CSiMsB,CAAC,CEhOD,CAAA,CAAA,GAAA,KAAA,MAAA,MAAA,sCXiCpB,GAAA,IAAA,CAAA,GAAA,wCAIP,CAAA,CAAA,CACoC,CACpC,CAAwB,CAAA,iBAGpB,eACkB,IAAA,CAAA,UAAe,CAAC,CtFtFb,A2F7DE,ILmJgB,8BACR,CKnJK,CAAC,CAAC,ALmJJ,CAAG,CAAD,GAAK,CAAC,CWnCH,SXmCa,CAAC,KAAK,EAAE,CAAC,CAAC,CAGlE,IAAM,EAAA,MAA8C,QAAQ,GACtD,EAAS,MAAM,EtFtFA,YAAA,CsFsFoB,EAAM,CAAE,CAAJ,EAAO,CAAO,CAAE,MAAM,CAAE,IAAI,CAAC,UAAU,CAAC,MAAM,CAAE,CAAC,CAAC,UAIpF,IAAM,UAFZ,UAAA,GAEY,OAAiB,CAAC,AtFxFJ,csFyFf,IAAA,CAAd,IAAI,CAAW,KAAK,CAAC,AAEnB,CAFoB,CAEpB,UAAA,CAAkB,CelK0B,KAAA,EfkKlB,SAAS,CSqMC,ATrMA,CSqMC,qCTjMjB,CAAA,GAAA,IAAA,IAAY,IAAA,CAAhB,IAAI,CAAc,CAAC,CAAC,MAG1B,uBAAA,CACL,CACT,CAAgB,CAChB,CAA2B,CSiMwC,ATjMxC,CAAA,ASiMyC,CAAC,ATjM1C,UAGH,eACZ,CAAC,IACO,EAAA,IAAA,CAAO,CvF9Df,SAAA,CAAA,KAAA,KuF+DH,gBAAgB,CAAA,QAAA,IAAA,IAAoB,CAAC,UAAU,CAAC,KAAK,EAAE,CAAC,CAAC,OAG3B,CvF9DzB,AkGwBJ,kBXuCK,MAAM,EAAA,MAAA,CAAW,EAAU,E1FpIN,A0FoIY,CQiBL,ARjBO,GAAG,CAAA,QAAiB,IAAI,CAAC,UAAA,CAAA,MAAiB,CAAE,CAAC,CAAC,UAIrF,IAAM,SAFb,CAAC,UAAU,GAEW,EWzCF,CAAC,AlGtBZ,AwFmDc,ADazB,CWzCC,EXyCD,CADgC,CAAC,EACjC,CAAA,GAAA,IAAA,IAAc,IAAA,CAAd,IAAI,CAAW,KAAK,CAAC,CAAC,WAEH,CAAC,MAAM,EAAE,IEpGI,CAAC,CAAC,CFoGC,EAAE,CAAC,IAChC,IAAI,UAGL,IAAA,CAAA,OAAA,CAAA,GAAA,IAAA,CAAA,GAAA,IAAA,IAA6B,IAAA,CAAhB,IAAI,CAAc,CAAC,CAAC,OAiTnC,gBAAgB,CAAwB,CAAA,CAA4B,CAAA,KACpE,GAAA,CAAA,EAAY,EAAW,GAAI,OAAO,OAAA,CAAA,GAAgB,CAAC,IvF5WZ,AuF6WrC,CvF7WsC,CAAC,AuF6WvC,cAAkB,CAAC,E1FtbI,CAAA,K0FublB,CAAG,iBAIE,CAAG,CAAC,EAAI,CAAC,EEpZM,AanEF,Uf8dhB,CvF5WO,YuF4WO,KAND,GAMc,CAAhB,EAN0B,CAAC,AAMxB,CALrB,CAAC,EAAI,CvF7WK,MwFqD8C,KDmU7D,GAAA,UAAA,OAAA,GAA0D,QAAQ,EAA9B,AAAgC,CAAC,MAA1B,UAAU,EAE9C,GAAwB,CEjZD,AM/KI,CN+KH,CAAC,KS0DD,AXuVQ,EAA5B,EEjZA,KFiZO,GAA+C,AAAtB,EWvVN,CFwP+B,OT+FO,CAAC,GS/FG,CAAC,CAAC,CT+F/B,AS/FgC,CExPvC,CXwVzC,GAAY,UACH,GAAA,IAAmB,ESzFE,CAAC,ATyFG,CerdF,CfqdC,MerdS,Cfsd3B,CAAC,GAD+B,CAAC,UerdU,Cfsd1C,Aetd2C,Cfsd3C,EAAiD,QAC5D,CvFvWG,AH9EE,E0FqbD,MAAM,CSxFD,CnG7Ve,K0FqbP,CAAA,IAAc,MAAA,OAAa,CAAC,GAAa,CAAC,WAC7C,GAAoB,QAAQ,EAArB,OAAA,GAAsC,QAAQ,CAAC,CAAtB,OAAO,CAAC,EAAgB,CAAC,EACjE,IAAA,IAAQ,GACjB,CSxF2B,CAAC,CAAC,KTyF/B,CAEA,CvFtWO,GuFsWF,IAAM,KAAc,EAAY,CACnC,AADoC,EAAjB,CACf,CAAA,GAAA,SACI,AAAI,Ee7cQ,If6cR,CAAA,KAN6D,+CAM7D,EAA6D,EAAU,CAAE,CAAC,CAAC,AAGvF,IAAM,CAH6E,CAG7E,EAAkB,KAAS,CACjC,EADwB,CSrFf,ATsFI,MAAT,AAAe,CAAC,oBACL,CAAC,EC5PQ,CAAC,AD6PjB,AvFrWY,CwFwGM,AQ0KT,ChGlRG,GgGgRR,ChGhRQ,6DuFwWhB,UAAA,OAAA,EACF,MAAM,AAAI,MAAA,CAAA,qEAAA,EAA8E,EAAK,CAAE,CAAC,CAAC,AAAJ,OAGtE,CAAC,EAAA,AACV,MAAM,CAAlB,AAAmB,EACrB,EQ3iB+B,AR2iBtB,IAAA,CAAA,IAED,CAAC,EAAA,CAAS,IAAI,CAAC,CvF/UW,cuF+UI,CAAA,EAAW,EAErD,Ce1cgE,Af0c/D,AACD,Ce3ciE,af6cjE,CADK,CAAC,GQ3hBK,CR4hBL,MAAM,CAAA,CC1PF,sBAAA,ED0P4B,EAAG,KC1PE,CAAC,CAAC,OAAA,ED0Pa,EAAU,QAAA,IAAA,EAAe,EAAQ,CAAE,CAAC,CAAC,CAE9F,CAAC,CAFyF,CAEzF,CAAO,SAGN,EA8BC,OAAO,CAAA,CAAS,CAAA,QACjB,CACT,CAAC,MAEe,uBAAA,CAAA,CAEd,CAAe,CACf,CAAwB,CAAA,CCzRgB,CAAC,CQ6KnB,KT8Gf,MAAM,IAAI,CAAC,aS5GS,eT4GmB,CAAC,EAAQ,EAAQ,EAAV,AACvD,CAAC,CAD8D,GAAS,EAGxD,IQ/hBJ,gBAAA,CRgiBM,CAChB,Ceze6B,AfyenB,CAAA,CACiB,CAAA,CACH,CAAA,QAEjB,MAAM,IAAI,CAAC,CSlHH,qBTkHyB,CAAC,EAAM,EAAF,AAAY,EAAQ,GAGzD,CAH+C,AAAQ,GAAS,CAAC,AAG5D,CAH6D,AAG5D,KE1aL,mBAAA,CAAA,CAAA,CF4aC,CACV,CSrHoC,ATqHI,CACxC,CAAwB,CAAA,QAEjB,MAAM,IAAI,CAAC,GQpYC,oBAxK+G,CAC/H,CAAC,CR2iBwC,CAAC,EQpYA,ARoYM,EAAF,AAAS,EAAQ,CAAV,CAC1D,CAAC,CADiE,GAAS,CAAC,CAAC,aApanE,CAA2B,EACnC,IAAA,IAAA,CAAS,KAAK,CSoTL,AT9ST,CANgB,ECqIJ,IDnIZ,GAAA,IAAA,CAAA,GAAqB,EAAA,KAErB,GAAA,GCoIoB,CAAA,CAAA,GAAA,IAAA,IAAA,IAAA,CDpIpB,IAAI,CAAc,GAElB,EAFuB,AAET,CAFU,CAAC,GAEN,EACjB,IAAK,sBAIL,CSkTD,ITlTM,yBACA,oBACL,IAAK,yBACL,IAAK,6BACL,IAAA,2BACK,4BACA,oBACL,IAAK,wBACL,IAAK,uBACL,IAAK,qBACH,GAAA,CCiIU,GDjIN,CAAA,GAAA,IAAA,IAAW,IAAA,CAAf,IAAI,CAAY,GAChB,EADqB,CAAC,CAAC,CAGzB,KAAK,0BACL,IAAK,8BACL,IAAA,wBACA,IAAK,4BACL,IAAK,yBACL,IAAK,4BACL,IAAK,0BACH,GAAA,IAAI,CAAA,GiBjW2C,IAAA,IjBiW5B,IAAA,CAAnB,IAAI,CAAgB,KAAK,CAAC,CAAC,CAG7B,KAAK,6BACA,6BACL,IAAK,2BACA,2BACL,IAAK,+BACH,GSgUwB,CThUpB,CSgUsB,GAAA,IAAA,IThUP,IAAA,CAAnB,IAAI,CAAgB,KAAK,CAAC,CAAC,MAGxB,QAEH,MAAM,AAAI,MACR,ISiUgB,kFT7TtB,CAAC,AACH,CAAC,CAAA,GAAA,cAGK,IAAA,CAAK,KAAA,CACP,MAAM,EiB9VE,EAAA,GjB8Vc,CAAA,ECyHP,sCDzHgD,CAAC,CAAC,IAG9D,GAAA,IAAI,CSgUA,ARvMU,GAAA,KAAA,MDzHQ,GSiUlB,GTjUwB,mCAEjC,OAAO,GAAA,IAAI,CAAA,GAAA,IACb,AADuB,CACtB,AADuB,CACvB,GAAA,SAEqC,CAAyB,EAC7D,GAAM,CAAC,EAAoB,EAAW,CAAG,GAAA,IAAI,CAAA,GAAA,IAAA,IAAmB,IAAA,CAAvB,IAAI,CAAoB,EAAO,GAAF,AAAE,IAAI,CAAA,GAAA,IAAiB,CAAC,CAAC,AAI/F,CCsHD,CD1HiE,EC0HjE,IDtHY,KAHX,EiB7VqB,AjBgWH,CAHlB,ESgUqB,EThUjB,CAAA,EiB/VgC,CjB+VZ,EAAkB,IAAA,CAAC,AAC3C,GAAA,IAAI,CAAA,ESgUuB,CTjUe,ASiUf,IThUL,CAAC,EAAmB,EAAE,CAAC,CAAG,EAE1B,GAAY,CAAC,CiBhWI,GjBiW/B,EAAkB,AAHe,ESoUf,ATjUmB,IAHqB,CAAC,EAGf,CAAC,CSiUD,CTjUS,KAAK,CAAC,CAAC,AAC9D,GAAiB,ISgUkD,AThU9C,EiB/VU,CAAA,OjB+VE,CAAC,CiB/VQ,GjBgWvC,KAAK,CAAC,CC2HC,aD3Hc,EAAgB,IAAI,CAAC,AAEnD,CAFoD,ASwUrD,ATtUE,OAF4C,aAKtC,6BACC,CAAC,KAAK,CAAC,MS4UM,CAAC,CQ3qBC,QjB+VQ,CAAA,EAAQ,IAAI,CAAC,CAAC,AACzC,ES2U6E,QTzU1E,6BACH,CCyHD,SDvHI,KSgVG,iBThVmB,QACrB,CAAC,CS+US,IT/UJ,CAAA,eAAiB,EAAK,ES+UO,CT/UP,CAAK,CAAA,KAAM,CAAE,IS+UY,CT7U/C,CCwHD,GDxHK,CAAC,KAAK,CAAC,CS+UC,MT/UM,CAC1B,CAD4B,CAAC,EACxB,IAAM,CSgVG,CAFuB,ARtNxB,GDxHS,ESiVN,ERzNU,AQyNV,ETjVgB,CAAC,KAAK,CAAA,OAAQ,CAAE,CAAC,AAE/C,GS+UwC,AT/UpC,AAAgB,ESkVV,ITlVgB,AiBzVa,IjByV3B,GiBzVgB,CAAA,EjByVE,EAAQ,GiBzVU,CjByVN,CAAE,CAAC,IACvC,ESkVM,ATlVM,EAAQ,IAAI,CACxB,AADmB,AAAM,ESmVnB,ATlVK,CSkVJ,AQ3qBS,AAAS,CR2qBjB,ATlVsB,OAAO,CAAC,EAAQ,KAAD,AAAM,CAAC,CAAC,AACzD,GAAI,CCyHO,EAAE,ADzHG,AAAiB,ECyHlB,GDzHH,CAA2B,EAAf,AAAiB,CAAC,CAAjB,IAAI,CAC3B,IAAI,CAAC,KAAK,CAAA,YAAA,EAAA,EAAkC,IAAI,CAAC,CAAC,KAElD,MAAM,KAAK,CAAC,uEAIhB,EiBvVa,CjBuVT,EAAQ,KAAK,EiBvVc,CAAA,EjBuVV,IAAI,CAAA,GAAA,IAAqB,CAAE,CAAC,AAE/C,GAAI,CC0HK,ED1HL,IAAI,CAAA,GAAA,KACN,CADwB,CAAC,KACzB,GAAQ,IAAI,CAAA,GSmVqC,CAAF,CAAC,CAAC,ETnVpB,IAAI,EAC/B,AADiC,CAAC,GAC7B,IiBtVqB,GjBuVxB,IAAI,CAAC,KAAK,CAAC,UAAU,CAAE,GAAA,IAAI,CAAA,GAAA,IAAgB,CAAC,IAAI,CAAE,GAAA,IAAI,CAAA,GAAA,IAAiB,CAAC,CACxE,AADyE,GiBpVjD,EjBsV1B,KAAK,YAAY,CACf,IAAI,CAAC,GiBnVR,EjBmVa,CAAA,gBAAkB,GAAA,IAAI,CAAA,CiBlVD,CAAC,CAC/C,KjBiVgE,CiBlV/B,SjBkVyC,CAAE,GAAA,IAAI,CAAA,GAAA,IAAiB,CAAC,AAEvF,CAFwF,AAEvF,AAGH,GAAA,IAAI,CAAA,GAAwB,EAAQ,KiBhVH,AjBgVE,AAAM,CAAA,IAAA,CAAC,AAG5C,GAAA,ASiVqC,CAAC,EQ/pBC,CAAA,CAAA,CAAxB,EjB8UQ,EAAmB,OAAO,CAAC,EAAQ,KAAD,AAAM,CAAtB,AAAuB,CAAA,IAAA,CAAC,UAMlE,KCyHC,sBDxHN,IAAK,oCAE+B,OAA9B,EAAuC,EAAnC,CAAA,GiBhVsB,KjBgVe,CAAC,AAC5C,IAAM,CS8U4B,CAAC,AT9UZ,EAAM,GAAD,CAAK,CAAC,KAAd,EAAqB,CAAC,GAAA,IAAI,CAAA,GAAA,IAAqB,CAAC,CACpE,AADqE,GACjE,EACF,OAAQ,EAAe,CiBhVD,GjBgVK,CADT,CAAC,AACU,AAC3B,CAD4B,CiBhVY,EjBiVnC,IC0HU,SDzHb,IAAI,CAAA,KAAM,CAAC,CC0HS,CAAC,WgBzcoB,GjB+Ub,EAAe,KiB/US,KjB+UC,CAAE,GAAA,IAAI,CAAA,GAAA,IAAiB,CAAC,CAAC,AAC9E,KACF,KAAK,MAAM,CACT,GC2He,CD3HX,CAAC,KAAK,CAAC,WAAY,EAAe,IAAI,CAAE,GAAA,IAAP,AAAW,CAAA,GAAA,IAAiB,CAAC,AAEtE,CAFuE,AAEtE,AAEL,CS8UoB,AT9UnB,AAEG,GAAA,IAAI,CAAA,GAAA,MAAmB,AACzB,CAD0B,AC8H2B,EgB1clC,CjB6Uf,CAAC,KAAK,CAAC,GC8HK,WD9HU,CiB3UK,CjB2UC,IAAI,CAAC,CAGvC,AAHwC,CCgIvC,ED7HD,IAAA,CAAA,QAAwB,EAAS,IAAA,CAAC,AAExC,CAAC,CAFsC,AAEtC,GAAA,SAEqC,CAAyB,EAC7D,IAAM,EAAqB,GiBxUiB,IjBwUb,CAAA,GAAA,CiBxUa,GjBwUb,IAAmB,IAAA,CAAvB,IAAI,CAAoB,KAAK,CAAC,CAAC,MAC1D,IAAI,CAAA,GAA2B,AADmB,CC6HvB,CD5HsB,IAAA,CAAC,EAEpC,KAAK,EAAE,CAAC,CAF2B,EiBpU1B,AjBuUhB,CSiVe,8BThVb,KAAA,CAAM,iBAAA,EAAA,IAA4B,CAAC,CAAC,KAE3C,ISgVkD,CAAC,ARtNA,AD1H9C,CC0H+C,AQsNA,2BT/U5C,EAAQ,EAAM,GAAD,CAAK,CAAC,KAAK,CAAC,KAEvB,CiBxUuB,EhBocpB,SD5HS,EAAA,AC6HK,cD7HL,EACZ,YAAY,CAAC,CSgVD,GThVK,EC4HA,AD3HvB,CC4HC,CD5HI,GAAA,SAAa,CAAC,UAAU,EAAA,AACW,YAAY,EADvB,AAE7B,CAAC,CiBzU2C,AjBwUzB,YAAY,CAAC,IAAI,CAEpC,IAAK,IAAM,KAAY,EAAM,GAAD,IiBvUmB,KjBuUN,CAAC,KiBvUgB,KjBuUN,CAAE,AAChD,CADiD,CACxC,CC4HN,ID5HW,EAAI,GAAA,IAAI,CAAA,GAAA,IAAsB,EAAE,CAAC,EAC7C,CAAC,KAAK,CACR,gBACA,EACA,ES6U8C,EAAA,UT7Uf,CAAC,UAAU,CAAC,EAAS,KAAK,CAAN,AAAmB,CACvE,CAAC,CAEE,GCyHG,ADzHH,IAAI,CCyHwB,GAAA,MDzHL,AACzB,CAD0B,GACtB,CAAC,CS6US,CAAC,EQlpBI,CjBqUT,CAAC,eAAA,GAAgB,IAAI,CAAA,GAAA,IAAiB,CAAC,CAAC,AAGpD,CCwHG,EDxHH,IAAI,CAAA,GAAyB,EAAS,KAAK,CAAN,AAAM,IAAA,CAC3C,AAD4C,GAC5C,CCwHM,GDxHF,CAAA,GAAoB,AiBtUL,EjBsUwB,CS8Ub,WT9UyB,CAAC,GAAd,OAAwB,CAAC,EAAS,KAAK,CAAN,AAAO,CAAA,IAAA,CAAC,AAC/E,GS8US,AQnpBb,AjBqUI,IAAI,CAAA,EiBpUU,CAAA,MjBoUS,IAAI,CAAC,CS+UhB,IT/UqB,CAAC,iBAAiB,CAAE,GAAA,IAAI,CAAA,GAAA,IAAiB,CAAC,CAAC,CAKtF,IAAI,CAAC,CiB9TG,IAAA,CAAA,ejB8TmB,EAAM,GAAD,CAAK,CAAC,KAAK,CAAE,GAC7C,UACG,KAF4D,CAAC,CAAC,yBAG9D,yBACL,CSmVC,GTnVI,SSmVS,uBTlVT,0BACH,GAAA,IAAI,CAAA,QAA2B,EAAS,IAAA,CAAC,AAEzB,EAFwB,YACxB,AACZ,ECwHS,AgBjbL,ChBibK,GAAA,CDzHc,YAAY,CiBxT/B,IjByTQ,EACV,GAAA,CCyHkB,CQ6N+B,EAAA,CAAA,GAAA,MTtV1B,CAAC,AAC1B,IAAI,CAAC,KAAK,CAAC,ESsVM,aTtVU,GAAA,IAAI,CCyHoB,GAAA,MDxHnD,EiBxTa,CAAA,IjBwTT,CAAA,QAAoB,EAAS,IAAA,CAAC,CAGtC,CAHqC,GAGjC,CAAC,CSuVD,ITvVM,CAAC,cAAe,EAAA,IAAU,CAAE,EAI1C,CAAC,AACH,CAAC,CAAA,GAAA,SAEmC,CAA2B,AAPD,CAAC,CAQ7D,AAR8D,GAQ9D,IAAI,CAAA,GAAA,KAAS,IAAI,CAAC,GAClB,EADuB,CAAC,CAAC,AACrB,CAAC,KAAK,CAAC,QAAA,EACb,CAAC,CAAA,GAAA,SAEkB,CAAyB,SAClC,EAAM,CiBlTD,CRsoBD,GTpVO,ESoVF,ATpVI,AACnB,CADoB,GACf,iCACH,GAAA,IAAI,CAAA,GAAA,IAAkB,CAAC,EAAM,GAAD,CAAK,CAAC,EAAE,CAAC,CAAG,EAAM,GAAD,CAAK,CAAC,AAC5C,EAAM,IAAI,CAAC,AS+VA,IT7Vf,8BACY,GAAA,IAAI,CAAA,GAAA,IAAkB,CAAC,EAAM,GAAD,CAAK,CAAC,EAAE,CAAiB,CAAC,AACrE,GAAA,CAAK,QACG,CCyHC,CD1HM,CAAC,GACF,yDAGd,IAAA,EAAW,EAAM,IAAI,CAAC,ES6VE,GT3Vf,GCuHC,EDvHI,CAAE,CAAC,AACf,CS2Vc,GT3VR,EAAc,EAAe,CAAC,MAAnB,SAAkC,CAAC,EAAU,EAAK,EAAD,EAAN,CAAY,CAAiB,CAAC,GAC1F,GS4VwB,CT5VpB,CAAA,GAAA,IAAkB,CAAC,EAAM,GAAD,CAAK,CAAC,EAAE,CAAC,CAAG,CAC1C,CAAC,AAED,CCuHC,CADE,KDtHI,EAH8C,CAAC,AAG/C,IAAI,CAAA,GAAA,IAAkB,CAAC,EAAM,GAAD,CAAK,CAAC,EAAE,CAAiB,CAAC,IAE1D,CCsHD,CgBhaG,8BjB2SF,yBACL,IAAK,4BACL,IAAK,mEAEC,CAAA,CS0VwB,CAAC,CQnoBY,EAAA,EjBySnB,CAAC,EAAM,GAAD,CAAK,CAAC,EAAE,CAAC,CAAG,EAAM,GAAD,CAAK,CAAC,GAInD,GAAA,IAAI,CAAA,GAAA,IAAkB,CAAC,EAAM,GAAD,CAAK,CAAC,EAAE,CAAC,CAAE,OAAO,GAAA,IiBxS7B,AjBwSiC,CAAA,GAAA,IAAkB,CAAC,EAAM,GAAD,CAAK,CAAC,EAAE,CAAiB,CAAC,MAClG,AAAI,KAAK,CAAC,0BACjB,GAAA,SAGC,CAA2B,CAC3B,CAA6B,MAEzB,EAAoC,EAAE,CAAC,KAA7B,EAEN,CSuVO,CTvVD,IC2QI,CAAA,+BDxQd,GiBzSK,GAAA,CjBySG,EAAM,IAAI,CAAE,EAAW,CAAC,IAE7B,GAF2B,oBAG9B,GAAI,CAAC,EACH,MADW,AACL,EADO,AiBxSD,CjBwSE,GAEZ,0FAIJ,IAAA,EAAW,EAAM,IAAI,CAAC,GAGlB,ESmVqB,ATnVhB,CiB7SQ,IjB6SH,CAAC,OAAO,EAAE,CSqVD,ATrVE,EAClB,IAAM,GiB9S4B,EjB8SV,EAAK,EAAD,GAAM,CAAC,CAAf,MAAsB,CAAE,AAC/C,CADgD,CiB3SxC,CRioBL,ETrVgB,KAAK,IAAI,CSqVC,CAAC,AQjoBa,AjB4SN,CSqVN,KQjoByB,CAAA,CjB4SV,CAAC,MACxB,EAAS,MAAD,CAAQ,CAAC,EAAe,KAAK,CAAC,CAAC,KAAR,IACpC,CAAC,EAAe,CiB5SC,CRioBuB,GTrVnB,CAAC,CAAG,GAAA,IAAI,CAAA,GAAA,IAAA,IAAmB,IAAA,CAAvB,IAAI,CAC3C,EACA,EAEJ,CAAC,KACC,CADK,CAAC,AACG,EAJO,EACA,CACf,CAAC,AAEM,CAAQ,CAAC,CAL+C,CAKhC,KAAK,CAAC,CAAG,EAEzC,EAAW,CAFoB,GAEhB,CAAC,GAKtB,AALgB,MAKT,CAAC,EAAU,EALkB,AAOtC,CAPuC,CAAC,GAOxC,KS4UoD,wBT3UpD,IAAK,GSkVH,wBTjVF,IAAK,4BAEH,GAAI,EACF,MADU,AACH,CAAC,CADI,CAAC,AACK,EAAW,AAE7B,IAFgB,GAEV,KAAK,CAAC,yDAAyD,CAAC,CAAC,AAG7E,MAAM,KAAK,CAAC,yCAAyC,CAAC,CAAC,CACxD,GAAA,SAGC,CAAmC,CACnC,CAA0C,EAE1C,OAAO,EAAe,CAAC,eAAe,CAAC,CS2UnB,AAAS,CAAC,ITxU/B,GAAA,SAkEiC,CAAqB,EAGrD,UAFA,IAAI,CAAA,GAAuB,EAAM,GAAD,CAAK,CAAA,IAAA,CAAC,AAE9B,EAAM,GAAD,EAAM,EACjB,IAAK,qBAEL,EkBtsBa,ElBssBR,oBAEL,IAAK,8BAEL,KAAK,6BACL,IAAK,uBACL,IAAK,oBACL,IAAA,uBACA,IAAK,oBAAoB,CAAC,AAC1B,IAAA,wBACE,GAAA,IAAI,CAAA,GAAa,EAAM,GAAD,CAAK,CAAA,IAAA,CAAC,AACxB,ESgSM,CAAC,AThSP,EkBrrBV,ElBqrBc,CAAA,GAAA,IAAiB,EAAE,CAAC,KACrB,GkB9rBK,ElB8rBA,CAAA,eAAiB,GAAA,IAAI,CAAA,GAAA,IAAiB,CAAC,CAAC,AAClD,GAAA,CSgSU,CAAC,EThSP,CAAA,GAAoB,OAAS,EAAA,EAAA,CAAC,AAKxC,oEnExrBsB,IAAA,GAAmB,IAAA,CAAA,OAAA,SAmBzC,CAAA,CAAA,CAAA,CAAA,CAEwB,CAAA,oNAkBP,CAAA,CAAK,yBACC,CAAA,EAAA,CAAA,SAAA,EAAiB,EAAA,MAAA,EAAA,EAAA,CAAA,CAAA,4EAWK,CAAA,CAAA,sBACjB,CAAA,yCACa,EAAA,MAAA,EAAkB,EAAA,CAAO,CAAA,qBAGvD,GAAa,gBAAkB,iBAAmB,C8C+DC,E9C/DQ,CkEtCC,CAAC,CAAC,KlEsCK,CAAC,gBAYvD,CAAA,gFAKb,ChBjDG,AEoDW,EAAA,uDcMpB,CAAA,CAAA,CAAA,CAAA,CAAgE,CAAA,IAC/D,CAAA,UAAA,CAAA,CAAA,CAAA,mDACqD,CqC5CA,CAAA,OAAA,CAAA,CrC4CgB,iCAEjC,CuEtCK,COwBP,e9EcqB,EiBIG,CjBJM,IiBIK,CAAC,CAAC,CjBJA,CAAC,CAAC,+CAcxD,MAAA,CAAO,EAAA,EAAA,yBACR,CAAA,EAAA,EAAO,CAAA,WAAe,CAAQ,CAAE,CAAE,CgDlBX,MhDkBkB,CAAC,WAShE,CAAA,CAAA,CAAA,CAEA,CAAwB,CkF9Hc,QlFgI/B,GAAgB,qBAAqB,CAAC,EAAU,IAAI,CAAC,IiB8B2C,CAAC,CAAC,CjB9BtC,CAAC,IAAI,CAAC,OAAO,CAAC,IAAI,CAAE,EAAM,EAAF,KAAS,CAAC,CAAC,AAQlG,KACJ,CAAa,CAAA,CAAA,CAEb,CAAsD,CAAA,KAEhD,EAAA,GAAA,iFAIkC,GAAS,gBAAgB,C2E6BsC,gB3E7BxB,SAAS,EAIjF,CAAA,qBACc,CmEab,AjB/CY,CAAA,CAAA,MlDkCoB,IAAA,CAAK,QAAA,CAAA,EAAA,EAAA,IACtC,CAAA,uBAC2B,C8E3BK,qG9EqC7B,GAAA,iCACoC,UAEhC,CyDtBS,CAAA,EAAA,OzDsBwB,CAAA,GAAI,CAAC,CyDtBS,uBzDuBrD,GAAA,EAAA,gBACoC,KfeD,Seb/B,EAAA,CAAA,YAIM,2GASZ,OAAO,GAGf,CAAC,A4E4NA,ApBnKA,AW5BA,OnExBM,CAAA,CAAkB,CAAA,CAAiC,CAAA,CAAA,gCACZ,CAAC,EAAU,CpBrCD,GoBqCK,CAAA,CAAN,CpBrCD,KoBqCe,CAAC,IAAI,CAAA,OAAA,CAAS,CpBrCD,GoBqCK,CAAE,EAAM,EAAF,KAAS,CAAC,CAAC,YA2BtG,CAAa,CACb,CAAkC,CAAA,CAAA,CAAA,IAG5B,CAAA,UAAA,CAAA,CAAA,GAAgB,EAAA,CAAA,SACf,IAAA,CAAA,OAAY,CAAC,CvB9FL,GuB8FS,CAAA,EAAK,CAAA,EvB9FF,CqGgFC,MAAA,EAAA,E9EcsB,GpB5DpC,GAAA,EoB4D6C,EAAK,UpB3DzC,UAAA,CoB2D+D,CAAE,MACtF,MACU,2CAC6C,EAAI,CoESC,EpETQ,IAAF,GAAS,CAAC,CAAC,UAC9D,CqE/EC,A9CaI,KAAA,GvBkEK,mCAU3B,CAAa,CACb,CAA8C,C8EjBnB,A9EkB3B,CAAsD,CAAA,kBAE/B,iBAAiB,CAAA,EAAQ,EAAQ,gBAC3C,IAAI,CAAA,IAAA,CAAA,EAAA,EAAY,C2E8BH,A3E9BK,EAAA,2BAS/B,CAAa,CAAA,CAC2B,CpB3CJ,CoB4CZ,C8EvBiB,oC9EyBO,CAAC,EAAO,IAAI,CAAC,ImEO1C,GnEPiD,CAAC,IAAI,CAAC,OAAO,CAAC,IAAI,CAAE,EAAQ,IAAF,AAkuBlG,GAAA,KAAA,CAAa,CpB5wBH,wHsBvK8D,6EAW5C,iCAAqC,GAAA,QAAiB,CAAC,EKhDG,CAAC,CAAC,SLyD7D,CAAA,CAAA,CAAA,aACX,OAAA,CAAA,GAAW,CAAA,EAAA,CAAA,SAAA,EAAA,EAAA,CAAA,CAAA,KACX,4BAC8B,oBAA4B,QAAQ,CAAC,UAS1E,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,4CACgD,wCAGX,iBAAmB,GAAS,GyEnCkB,CAAC,CAAC,EzEmCb,CAAC,CAAC,UAS1E,CAAA,CAAA,CAAA,CAAA,aACO,OAAA,CAAA,MAAA,CAAA,EAAA,CAAA,SAAA,EAAA,EAAA,CAAA,CAA2C,6DAEuB,CFPC,AEOA,8DAsBrC,CXvCC,YW0CzC,QAAS,GAAA,CAAc,2CAAqD,CAAC,EiD3C9C,cjD4CZ,EAAA,CAAA,4CAaH,IAAI,CAAA,YAAa,CAAA,EAAO,OAAO,AgFrJA,ChFqJC,YACjC,CAAA,IAAA,CAAA,IAAA,CAAA,EAAe,CuDjCG,CAAA,CAAA,WvDiCc,CuDjCG,CvDiCC,SAAA,EAAa,OAAO,CAAC,CAAC,AuDjCE,uDvDwC3B,CAAA,EAAA,IAAW,CAAC,CepBD,MAAA,CAAA,IfoBa,CAAC,OAAA,CAAS,6GC9ExB,CAAA,OAAA,uEAEkB,sBAC3B,IAAA,CAAA,OAAA,wIEpER,YAAkB,OAAQ,EAAI,C+DjBzD,CXGyC,ApDcgB,IAAO,CoDdf,EpDcmB,KAAK,wDClBhE,sDACwC,EAAM,QAAA,CAAU,CAAE,MSKM,oBTHtD,sBAAwB,GAAA,iLCYtC,EAAA,MAAA,CAAmB,CAAA,GAAA,MACR,EAAM,CwBG7B,ExBHgC,CAAO,CAAE,CAAA,IAAM,CAAC,OAAO,CAAC,CAChE,CAAC,aASF,CAAwB,CAAA,8CAGD,CAAA,EAAA,CAAA,YAAA,EAAoB,CoBQA,CzC0BG,OAAA,EqBlCmB,CuEkIA,CpExH3B,AoEwH4B,CvElIO,CAAA,gDAW3C,CAAA,EAAA,CAAA,YAAA,EAAA,EAAA,MAAA,CAAuC,CAAE,CfPiB,EeOa,iCAU/F,CAAA,aAAA,CAAA,CAAA,CAAA,qBACa,CAAA,MAAA,CAAQ,EAAA,CAAA,YAAA,EAAA,EAAA,OAAA,EAAyC,CZbA,CYaM,CAAA,CAAA,cAE/D,CtBcD,AiFpBI,EAAA,E3DMa,OAAQ,CPiCG,AqE/BV,S9DFyB,I9BlBM,Y8BoKzD,CyE/ID,MAAA,CAAA,oJxEzC+C,GAAA,CAAU,6DAOF,CAAE,+CAU3B,cAAe,GAAmC,OAAE,EAAO,GAAA,CAAU,AAAV,CAAY,CAAC,CAAC,wDAO1D,EAAA,CAAA,CAAA,iCAEF,GAAS,0GE9B5B,EAAA,CAAA,eAAA,EAAsB,EAAA,MAAA,CAAsB,C1BbI,sI0B6BF,CaXlB,CAAA,CAAA,CbW4B,CpBdA,AoBcE,CaXT,WbW0B,qEAY5E,EAAA,MAAA,CAAA,CACtB,GAAA,OACE,EqDhB4D,ArDgBrD,GAAG,CAAO,CAAE,sEAaQ,CAAA,eAAA,EAAA,EAAA,OAAA,EAA2C,E0DqG7C,CAAA,CAAA,iGxD7I7B,EAAA,CAAA,CAAA,CAAA,CAAA,CAAA,mDAGmD,GAAA,CAAU,gFAgBrC,CAAA,8CAEuB,EAAA,CAAgB,CAAE,QAAQ,GAAG,CsCPC,CAAA,qHrCpBvE,EAAA,CAAA,CAAA,EAAuC,eAAA,sBAIS,CAAC,AAAE,C2DAlB,A3DAiB,mBAGvC,OAAA,EAAA,KAAA,CAAA,2CAA2D,CsCiBC,CtCjBI,C2DA1B,EAAE,Y3DAuC,8CAIxF,oKAoBkB,+IfDG,CAAA,EAAA,UAAA,CAAA,EAAsB,CdJmB,CAAC,IcId,CAAG,aAAa,CgF+IzD,gBAAA,uFhFvIkB,8CAEa,MePK,CKkBM,CLjBtD,kEErCa,CAAA,CAAA,CAAW,gDAC0B,CTLC,A8BAA,CAAA,cAAA,EAAA,ErBKkC,CAAE,CAAE,OAAO,CAOpG,AAPqG,CAOrG,AAPsG,CAOtG,CAAA,CAAA,CAAA,CAAA,wDAMM,CAAA,OAAA,EAAA,EAAA,MAAA,EAA0B,EAAK,aAAA,CAAe,CAClD,GACA,OAAE,EAAO,E+BiES,C/BjEN,C+BiEQ,A/BjED,CAAE,CACtB,CAAC,wJCNkD,CAAA,oFAYd,EAAA,MAAA,EAAgB,EAAA,CAAO,CAAA,UAQ7D,EAAA,CAAA,CAA4C,CAC5C,CAAA,CAAA,4CAE6C,EAAA,KAAA,CAAA,CAAe,GAA6B,CwDfvD,Af+BM,0BzCPK,CAAA,CAAA,4CAEnB,CAAA,EAAA,CAAA,OAAA,EAAA,EAAA,MAAA,EAA+B,EAAA,CAAA,CAAS,UAM7D,CAAA,CAAA,CAAsC,CAAA,CAAA,CAAA,0CAEnB,CAAA,EAAA,CAAA,OAAA,EAAA,EAAA,MAAA,EAAA,EAAA,CAAA,CAAwC,qHE/BX,CAAA,8CACP,CAAA,uDAOF,CAAE,CAAA,UAMzC,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,iHAWkE,SAAS,GAAG,CAAO,CAAE,CkCXjB,AlCWkB,uCAOnE,CAAA,EAAA,CAAA,OAAA,EAAA,EAAA,CAAA,CAAA,IAszB9B,CtCv0BC,EsCu0BK,IAAA,CAAA,gFEz1BqE,GAAG,CRkBE,AAAF,CAAC,CfGvD,AeHwD,AQlBS,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,M8CKI,CAAC,CAAC,sG9CYjE,GAAA,SAAiC,CSAV,EAAA,CAAA,aTMnB,CAAA,0CACE,CAAE,CnBcE,mCmBPhC,CAAA,GAAA,CAAA,EAAA,CAAA,OAAA,EAAA,EAAA,QAAA,CAAmC,CAAA,0BAEnB,oBAAoB,CAAE,IAAW,QAAQ,oBACxD,iDASC,C7B+BZ,Q6B/Bc,EzBG6B,IAAA,AyBHL,CAAT,AAAS,CAAA,CAAA,CAAoD,CAAA,CAAxD,eAEV,YAAa,CxCaC,AuF8CR,CjFVO,gBkCjDmB,2BAG5C,CAAA,QAAA,CAAA,0BAEuB,EAAA,MAAA,EAAc,UAClD,GAAA,uCAGW,EAAA,yDAE6B,EAAE,4BAAA,EAA+B,E0D2BC,CAAA,aAAA,C1D3BsB,UAKjG,uHExE4D,GAAA,CAAU,YAoBtE,CAA0B,CAAA,CAA0B,CAAA,0BAClC,sCAAA,WAAkD,CAAO,yNGfV,CACtE,GACA,CAD8B,CvC8BZ,AuC9BY,IAC5B,EAAM,CsCD8B,CtCChC,IAAQ,CAAE,EsCDmC,KtCC3B,EsCD6B,CtCC1B,CAAO,CAAE,CACrC,CAAC,UAkB8B,CAAA,EACqB,CAAA,CAAE,CACvD,CAAA,CAAA,oBAEmB,CAAA,GAAA,CAAA,EAAS,CAAA,yBAAA,EAAA,EAAA,YAAA,CAAA,CAAA,+DA6BO,CAAA,CAAK,2DAEN,EAA2B,aAAA,EAAgB,EAAY,CAAE,CACzF,EAEJ,KAFW,CADgF,AAExF,CAAC,yIGnEiD,CAAA,CAAA,CAAA,uDAIxB,EAAA,YAAA,CAA6B,CgBGjB,AvDJV,AuCE3B,GAAA,OACE,EAAO,CgBGV,CAAC,CAAA,ChBHmB,qOCyB4B,EAAe,CAAA,CAAI,EkCQlC,QlCOQ,CAAA,CAAA,CAAA,CAAA,CAAA,oDAGU,GAAA,OAA6B,qEAc/B,EAAe,GQCG,CyC8BL,GAAA,CjD/BW,CAAE,EQCC,oBRkBrD,CAAA,iEAG2B,CACjD,CpDZiF,EoDajF,OAAE,EpDb+F,AoDaxF,CpDbyF,AACjG,CADkG,CoDa5F,ApDb6F,AoDaxF,CAAO,CAAE,CACtB,CAAC,MAaE,CAAA,CAAA,CAAA,CAAA,YACO,CAAA,OAAQ,CAAC,IAAA,CAAA,EAAA,CAAA,kBAAA,EAA8B,EpDXC,AoDWc,MAAA,CAAQ,CpDXA,UoDwBpE,CAAA,CAAyB,CAAA,CAAA,yBACN,CAAA,EAAA,CAAA,kBAAA,EAA0B,EAAA,OAAA,CAAwB,CAAE,IA4ehF,C6C5aC,E7ChEsF,AA4elF,WAAA,CAAc,kFCtlByC,OAAA,uBAChB,CAAA,OAAA,8BACmC,CAAA,OAAA,2EAMtD,4OKjBnB,CHF6C,AmC4DC,EhC1DlB,MAAE,CiCmHJ,CpBhHiD,AoBgHhD,AjCnHS,GAAG,CAAO,EAAI,GrCJ0C,CqCItC,CAAC,OAAO,CAAC,CAChE,CAAC,mDA2BA,GAAA,QAAoC,CxC5BuC,EAAA,CAAA,CwC4B3B,EqC7Ba,CJwHrB,CAAC,EjC3Fa,CAAE,EAAK,EAAD,IAAO,GAAI,CAAK,CAAE,CAAE,EAAJ,EAAQ,CAAC,OAAO,CAAC,CACrB,CAAC,SAwB3E,CAAA,CAAA,CAAA,CAAA,wDAGwD,GAAG,C5CnCG,A4CmCI,CAAE,OAAA,EAAa,MAAM,EzBxCC,CAAA,8D0B1BjE,CAAA,EAAA,CAAA,QAAA,EAAgB,EAAA,CAAA,CAAA,8GAgBG,EAAA,CAAA,CAAS,wDElB/B,IAAA,CAAA,eAAA,QAA6B,CkCNT,ElCMY,CqCsBvB,ArCtB8B,CAAE,CAAC,CAAC,iFCWf,EAAA,OAAA,CAAe,COyEH,ApE5Ec,2H6DmBX,CAAE,0BAE9B,8DAeN,CAAA,gBAAA,EAAmB,EAAM,IYyBkB,CAAA,CAAA,CAAA,CZzBR,wBAGxC,mBAA6B,CyCYG,CvB8BU,yElBzBlB,EZ0BG,OAAA,CAAA,CY1Bc,0BAGtC,C3DgBG,AuF8CR,MAAA,kB5B9DuC,CnBGG,AnBQE,AsCXJ,4LE3DuB,CAAC,OAAO,gDxD6C7E,CAAA,CAAgB,gEAKnB,sCAiImC,SAAxB,IAUkB,KAAA,EAVM,AAUN,EAAA,CAVM,EAUO,EiEhDA,AjEgDS,IAAA,WATlB,eAAT,IAAI,EAAmB,EAAK,IAAI,GRpEH,AQoEQ,mBAavE,CAAA,kBAjBE,AAmBgB,GAnBhB,SAAA,sBAmB6B,EAAU,CefD,OAAe,CAAA,CAAA,EfeK,SAAS,CAAC,CAAA,GAAA,OAAA,KAAA,KAAA,CAAA,EAAA,SACpB,EAAA,KAGzD,CAAC,A+D/BA,C/DrHyC,EAAA,8CAI6B,CAAA,QAgD9D,EAAA,+BA9CU,cA8CV,IAAA,IA5C6C,IAAA,sC6DwlL7C,C7DxiL0C,wBAInB,EAAE,OACxB,CAAA,EAAA,IAAA,EAAA,MAAA,kGApCqF,0CACzD,CAAA,EAAA,gBAA2B,kKAaE,CiB0CK,MjB1CxB,CkFiCmC,CAAA,MlFjCrB,C+DC/C,e/DAkB,CAAC,eASzB,EAiIH,SAAA,GAAA,CAAA,UACsB,CAC1B,Ce1BC,A4EoOA,G3F1MI,CkFSC,CACH,EAAA,KAAA,EAAA,MAAA,IlFTmB,WAAW,CAAC,AoF9EL,CAAC,CpF8EjB,IAAA,KAIN,IAAA,KAAiB,EAAO,OAAA,CAAS,AAChC,CADiC,eACjC,EAAA,IAAA,sCAMqB,OwDyxItB,aAAA,CAAA,WACK,CAAA,8HqCx9IN,CAAA,GAAA,EAAA,8BAKwB,CAAA,CAAA,CAAA,mEAKuB,ClGhEmB,C6FAL,A7FAM,EkGiEhE,CAAA,oDAC0D,I3CjCpC,2C2CiH7B,CAAc,CACd,CAA4B,CtBzFa,AsB0FzC,CAAwB,CAAA,qFAKW,CjF1HM,GAAA,IiF0HI,CAAA,UAAW,CAAA,KAAA,wBAEtC,IAAA,CAAA,IAAd,CAAgB,CAAC,yBAmBJ,2CAdgB,CAAA,QAAA,CAC7B,CVhB0F,CAAC,WAAA,CAAA,SUiBjF,CAAI,CAAE,CAAA,CACd,GAAG,CAAO,CAAE,MAAM,CAAE,IAAI,CAAC,UAAU,CAAC,MAAM,CAAE,MAAM,EAAE,CAAI,CAAE,CAC7D,CAD2D,AAC1D,IACsB,cAAc,EAAA,sCAGzB,CAAE,G5BtIwC,K4BsIhC,CAAI,CAAE,A5BtIqC,C4BsIrC,CACzB,CfzI8B,EAAA,CeyIpB,CAAE,MAAM,CAAE,IAAI,CAAC,EZ3IU,QY2IA,CAAC,MAAM,CAAE,CAC/C,CAAC,GZ5IgD,eYgJnC,2BACf,IAAI,CAAW,CfxI0C,CAAC,AewIpC,CfxIqC,aewIvB,CAAC,CAAC,8CAK7B,CAAA,GAAA,IAAA,IAAA,IAAA,CAAA,IAAA,CAAc,4FA1GzB,IAAA,CAAA,GAAA,KAAA,EAAA,oBAGmE,ChGgBC,Aa/CA,CAAA,6BmFkCjD,EAAA,0CAEV,KAAA,CAAA,EAAA,yBAIgC,IAAA,CAAxB,IAAI,CAAqB,KAAK,CAAC,CAAC,KACvC,QAAA,eAGH,6BAA8B,OAClB,EAAA,MAAA,CAAgB,EAAM,CrGxCsB,AgDgBjB,CyCAvC,AzFhByD,AgDgBjB,UqDwBM,CAAC,CAAC,AACnD,GZxBW,AYwBX,C5FkBuD,A4FlBvD,QAAa,oCAC4C,I7EtBY,Q6EsBA,CAAA,CAAE,CAAC,CAAC,6BAGvD,CrG1CO,AIgBN,CAAA,OAAA,CAAA,EAAA,aiG0BiC,CAAC,cACrC,OACU,yBAAA,EAAA,EAAA,aAAA,CAAA,CAAiD,CAAC,CAAC,kBAEvC,CAAC,AfzBI,oBe0BjB,CAAA,CrBOX,yCAAA,EqBPwD,EAAQ,G1D3BK,CAAA,CAAA,C0D2BC,CAAC,CAAC,AAGrF,EAAA,6BAAA,MAEE,SAAA,EAAkB,IAAI,SAK5B,IAAK,ChGoBkD,wCgGpBR,CAC7C,AZZoD,AlE6BJ,A8ElBF,CrBUrC,GAAA,EAAA,EAAA,MAAA,CAAA,EAAA,YqBTwC,CAAA,CACjD,CNjCK,ATUE,AKwEF,EUjDD,CAAA,QACI,IAAI,GAAY,CAAA,wBAAA,EAAA,EAAiC,YAAY,CAAA,CAAE,CAAC,CAAC,AAErD,iBAAiB,CAAC,uDAE/B,CAAA,UACO,EAAO,CTrBO,C1CgBqB,OAAA,mBmDWvC,EAAM,IAAA,CAAA,2BAMX,CrBQK,IAAA,sEqBLO,CAAA,GAAA,iBAEb,IAAA,GAAgB,0CAA0C,kBAElC,EAAS,GrBU6C,CqBV7C,OA6M7C,AA5M2B,SA4MlB,CACW,CHpNN,AGqNZ,CAAsC,ClGblB,ckGeb,U7FnOkE,CACxC,EAAO,IAAA,EAAA,SAAe,CAAC,E6FkOjD,EAA6B,CHrND,MGqN5B,CAAA,G7F9UwC,CgF7BkC,AhF6BjC,C6B3BG,CAAC,AmDF+B,AhBI/B,qB6BuW7C,Y7F1UwB,CAAA,+HAcpB,M6F6Tb,CAAC,CAjN0B,EAAA,GAAA,IAAwC,CAAA,GAAA,oBAC3D,CAAA,C9BQoC,E8BRlB,ErGjCwC,qBqG4ElB,WAC7B,IAAA,CAAA,GAAA,SACV,EAAA,INpEY,2BMqED,C7FNO,AuF/DN,MMsEP,IAAA,GACJ,CAAA,0EAAA,EAA6E,EAAM,CH6BnE,GG7BmE,CAAA,CAAM,CAC1F,CAAC,OAGG,WADoC,EAAM,GAAD,KAAS,CAAA,IAAA,CAAC,wDAMzC,CAAA,IAAA,CAAA,EAAA,IAAgB,CAAC,CAAC,C9EhBL,S8EmBzB,8BAA+B,CAAC,IVcA,EUbpB,C5BhD6B,C4BgDpB,MAAA,CAAO,EAAA,YAAkB,CAAA,iBAErC,C9EhBC,E8EgBW,CAAA,wBAAA,EAA2B,EAAM,YAAA,CAAA,CAAA,MAEnD,CrGhFK,A+FuCA,CMyCE,EAAO,IAAI,CAAC,AACzB,EAAA,EAAA,IAAA,gBACmC,yBAAA,mBAEf,iBAA6B,AAA7B,mBAAA,EAAoB,IAAI,CIxIC,CAAC,CJyI5C,EAAA,OAAA,EAAqB,iBAGd,OAAA,CAAA,IAAA,CAAa,C7FSO,iD6FJd,EAAS,CTlEH,KSkES,CAAC,EAAM,YAAY,CAAA,aAEzC,IAAA,GAAgB,CAAA,wBAAA,EAA2B,EAAM,YAAY,CAAA,CAAA,KAEjD,ClGlDK,WkGkDrB,EAAO,IAAI,CvDrDiB,A3CGP,KkGmDjB,EAAA,EAAiB,OAAA,CAAA,EAAc,E9EcO,W8EdM,CAAC,CAAC,AACpD,C9Ea0D,E8Eb1D,CAAK,QACG,CADM,GACN,GAAA,CAAA,yBAAA,EAAA,EAAkD,ElGxCc,CAAC,CAAC,SkGwCH,CAAA,CAAE,CAAC,CAAC,GlGvCvE,AkGyCY,kBAAJ,IAAI,CACd,MAAM,IAAA,GAAA,CAAA,0CAAA,EAA6D,EAAQ,IAAI,CAAA,AAAL,CAAO,CAAC,CAAC,eAE1D,oDAIgB,CAAC,EFgOI,EE/N5C,EAAS,EAAA,MAAe,CAAC,EAAM,YAAY,CAAC,CAAC,IAC9C,YACO,GAAY,CAAA,wBAAA,EAA2B,EAAM,GAAD,AVwBF,SUxBe,CAAA,CAAE,CAExD,AAFyD,CAAC,AAE1D,gBAAsB,CAAC,AjGvDJ,GiGuDvB,IAAI,cACG,EAAA,EAAU,KAAA,iDAKtB,EAAA,EAAA,MAAwB,CAAC,EAAK,AFgOD,GEhOC,SAAa,CAAC,CAAC,GAC/C,CAAA,YACQ,GAAA,CAAY,wBAAA,EAAA,EAAA,YAA6C,CAAA,CAAE,CAAC,CFgOtB,AEhOuB,GAE1D,cAAX,EAAA,IAAW,CAAkB,CAAC,eACF,EAAE,CAAC,EAAM,GAAD,UAAc,CAAC,CAAC,GAClD,CAAA,QACI,CADM,GACF,GAAY,CAAA,CI5HI,CAAC,uBAAA,EJ4HuB,EAAM,GAAD,UAAc,CAAA,CAAE,CAAC,CAAC,GAEtD,EXmCM,gBWnCY,CAAnC,AAAoC,EAApC,IAAY,CjGlDO,AiGmDrB,CjGnDsB,KiGmDtB,IAAU,GAAA,CAAA,6CAAA,EAA4D,EAAQ,CI3H7B,CAAC,CACnD,CJ0HmF,CAAA,AAAL,CAAO,CAAC,AAEvF,CAFwF,EAExF,IAAY,CjGlDK,CAAA,EiGkDK,CHwDK,IGxDA,mCAK7B,IAAI,CAAA,GAA4B,EAAM,GAAD,KAAS,CAAA,IAAA,CAAC,OAK5C,UAGD,CFyOD,AR7MA,YU5Bc,AV4Bd,EU5Bc,EAAA,OACsB,EAAA,GAInC,EAAE,oBAGD,CAAA,QAAU,AAAC,IAChB,CT5DK,GS4DC,EAAA,EAAmB,KAAK,CXqCC,CWrCC,CAC5B,EACF,CjGpDO,CiGoDA,OAAO,CAAA,oBAMb,EAAE,CAAC,CT5DC,CFoGC,IAAA,qBWvCD,CjGlDG,CiGmDW,UAAW,EAChB,CAAA,KAAA,GAEhB,EAAA,MAAA,CAAA,SAGG,EAAE,CAAA,QAAU,AAAC,CrG/FC,EqG+FE,KAEd,IAAM,EI/HI,AfsdJ,QWvVU,UAAW,CAAC,aAGd,CAAC,CXwVC,AWxVA,OAGlB,EAAA,CAAA,QAAa,AAAb,oBACI,OAEE,MAAA,CAAO,CXwVG,IWtVT,MAAM,CAAG,UAIb,SACA,EAAA,EAAA,IAAA,CASG,OADO,EAAU,KAAA,SACK,CAAK,CAAE,CAAC,AH3OwB,EG2O3B,CAPrB,GADD,CAAC,AIhIA,EJiIA,KAAA,EAAkB,MAAM,GAE5B,IAAA,QAA6C,CAAA,EAAU,IAC5D,EAAU,IAAI,CAAA,EAAL,OAAQ,OAAO,EAAE,CAAM,CAAE,CAAC,CACpC,CAAC,CADgC,GAC5B,CAAC,AAAC,GAAW,CAAF,CAAJ,AAAK,AAAS,CAAE,CAAd,CAAS,CAAC,CAAC,CAAQ,CAAE,EAAO,GAAF,CAAM,EAAE,CAAK,CAAE,CAAC,AAAE,CAAD,AAAG,CAAP,IAAY,MAAE,EAAW,IAAI,EAAE,CAAI,AAAZ,CAAc,CAAC,CAAC,AAAJ,CAAK,gBAMhG,IAAA,CAAK,KAAK,EXmVA,AWnVE,CACL,qBAA8B,oCAU/B,CAAC,IAAI,OACT,EAAW,GAAA,IAAI,CAAA,GVyF6B,CAAA,gBUxF7B,CFkQV,EPtTA,AzFqCA,A+FrMI,CGoNU,GAAA,0DAClB,CACT,CAAC,kGlC1U6C,CAC1C,C4BNuC,C5ECoC,CAAA,OgDMzE,EvDLgC,GuDKtB,CAAA,8BCbd,EAAA,CAAA,CAAA,CAAA,CAAA,CAAA,+DAG+D,CAAA,sFCwCQ,OAAA,+BACK,OAAA,uFAqC1E,CyB5DmF,UAAA,CzB4DvE,8BACsC,gFAuCf,EAAU,CAAA,CAAA,YAExC,CAAA,QACK,GAAA,QAAA,CAAA,0HAsBiC,C9D7GM,AgCgBL,C8B6FS,CAAA,CAAA,iCAEX,GnBnFK,EAAA,8FmBoGjD,CAAA,CAAA,CAAA,CAAA,sCAG0D,CAAE,CW3EV,CAAA,UX0F7C,CAAA,CAAA,CAAA,CAAA,QACE,IAAI,CAAA,OAAA,CAAA,IAAA,CAAA,EAAA,CAAA,WAAA,EAAA,EAAA,OAAA,CAAmD,CAAE,qBA69KpE,C1BnkLC,A2CGA,AjF4CA,EAAA,WAAA,CAAA,qFO1HqC,CAAA,GACJ,QAAQ,CuDK7B,EAAA,CvDLuC,CAAE,CAAA,IAAM,CAAC,OAAO,CAAC,AuCG1C,CvCFtB,AuCGA,CvCHC,AuCGA,uImBKmC,CAAE,mEAOU,C7BuBoB,CAAA,AuCed,CAAC,IAAA,CVtCE,CAAA,mFAmBsB,CAAE,CAAC,CAAC,SA2H3E,CAAA,UkBrLsB,MAAA,mCACQ,CPqFH,AWtFM,gBJEwC,aAAP,EAAO,MAAA,wJAWtD,wBAEf,CAAA,EAAA,KAAA,2GjBM8D,C1CRA,4D0CWL,QAAQ,CbH1C,AaG2C,wFAajC,EAAA,cAAA,EAAA,EAAA,CAAA,CAAA,iCAEJ,iBAAmB,GAAS,IAAF,GAAS,CAAC,CAAC,WAShE,CAAA,CAAA,CAAA,CAAA,CAAA,2FAKuE,OAAA,CAAS,CAAA,0C9DgBmH,CAC/M,CAAC,2B8DRA,cAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,KAKE,EAAA,MAAA,IAAA,CAAA,MAAA,CAAA,EAAA,8BACsC,EAAA,CAAA,0CAWnB,GAAA,EAAU,CAAG,mCAEhC,CAAA,eAAA,EAAkB,EAAA,cAAA,EAAgC,EAAO,KAAA,CAAA,CAAQ,CACrE,GACA,OAAE,AADkC,CAAA,CAC3B,GAAF,AAAK,CAAO,CAAE,OAAO,CAAE,GAAa,CAAC,CAAE,OAAJ,MAAiB,CAAE,eAAe,CAAE,CAAE,GAAS,IAAF,GAAS,CAAC,CAAC,CAAE,CACrG,CAAC,cAWa,CAAA,CACuC,CkBrBf,2FlB2BC,GAAS,gBAAgB,CkBjBzD,gBlBiBuE,CkBjBzD,ElBmBrB,iCAGmC,MAAA,IAAA,CAAW,QAAA,CAC3C,EAAA,iBACmB,CmBgCoB,CACpC,CnBhCH,CmBgCmB,CAAC,wEnBxBE,UAEP,uCAGX,IAAM,EAAA,EAA0B,OAAO,CAAC,CSQW,ETRR,CAAC,6CAER,EAC9B,CkC7GyC,AlC6GzC,MAAO,CzBHa,AqD03BK,M5Bt3BX,ChDkBc,C4Eq2BY,A5Er2BZ,CgDfpC,SAJkC,CrBNW,AqBMV,CrBNW,C3BwBC,CAAC,CAAC,kDgDRjD,OAAA,UAUF,cAAA,CAAA,CAAA,OAEF,CzBH8B,CAAA,QAAA,EyBGb,EAAE,CzBH8B,AyBGiB,CACpE,CAA+E,CAAA,IAElE,SAAc,GAAN,AAAmB,CAAC,AhDuBJ,CgDvBV,MAAA,6HAEyF,CACjH,CAAC,WAM8B,GAHK,gBAAA,EAGkB,EAAM,CmBiCnB,AehJY,ClFmIG,IkFnIH,ElCiHlD,EAAA,IAAA,CAAA,OAAA,WAC2B,WACQ,CAAC,EoB8CZ,epB1CF,CAAA,wBAER,ChDmBC,AyDpBI,KTCC,EAAA,KAAY,CAAA,MAAO,CAAC,CAAE,IAAI,CAAA,EAAQ,QAAA,YAAqB,CAAE,CAAA,UAC/D,EAAA,EAAA,kBAKoB,CmBqCsC,EjBtDnC,CAAA,CAAA,GFiBgB,GAAG,CAAC,CwBrCzC,CAAC,EtBoB4C,CAAC,CAAC,MFiBM,CAAC,CAAC,+EE/J7E,CAAsB,CAAA,CAAA,CAAA,iHAMuC,GAAA,+GAakB,CAAE,GrDQI,CAAC,CAAC,0B6EPI,CACxF,CAAC,AxBAsC,eAAe,aAAqB,CAAC,mJAYrC,eAAe,CAAE,C4BsIpC,A5BtIsC,GAAA,QAAiB,CAAC,AaF3C,CAAC,oEbcgB,EAAA,MAAA,CAAA,CAAA,GAAoD,yCAG/D,oBAA4B,ClCGE,OkCHM,CAAC,IrEJI,kGqEoBH,CAAE,CpChBI,gDoCkB7B,CCQE,ADRA,CAAE,CjCqCiB,EiCrCR,kBAOlE,cAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,6BAKgD,qBAClC,IAAA,CAAA,EAAA,EAAA,EAA2B,CjEWL,AoD1BM,SauB1C,KAAA,CAAA,CAAA,CAAA,CAAA,CAGkD,CAAA,kIAQrD,CAAC,AblBE,kCaqBsC,CACtC,CMiEwC,CAAA,kCN7D1B,gBACF,CzE9B2B,CyE8BzB,COkB+B,APlB9B,QAEa,UAEjB,COiBK,KAAA,EPhBhB,IAAA,cACE,IAAA,EAAA,6BAG0B,cAAc,CAAC,aAEH,QAAA,CAAA,OAAgB,CAAC,GAAG,CAAC,2BACrD,CzE7BO,CAAA,KyE8BH,EAAmB,CMgEO,QAAA,aN9D9B,GAAA,CAAA,WAD4B,CAAC,CzE5BS,4CyEqCrC,sBAU+D,CAAA,+BACnC,CAAC,CM8EhC,KAAA,CN9EuC,CAAE,KAAM,EAAM,EjEgDA,AiEhDF,MAAE,YAAqB,CM+E5C,AN/E8C,CM+E7C,AN/E+C,wBACtD,CAAE,QAAS,EAAS,EAAE,EAAI,SAKxD,CFmBD,aAAA,CAAA,CEjBH,CtEXgC,AAAE,CAAD,AAAC,CAAA,CAAA,KsEc5B,EAAA,MAAiB,CrEjBG,GAAA,CAAA,MAAA,CAAA,EqEiBwB,EAAM,EAAF,cACzC,IAAI,CAAA,IAAK,CAAA,EAAA,EAAA,EAAA,CAA6B,yCAWvB,aACjB,CAAA,OAAQ,CAAA,UAAW,CAAA,EACxB,CAAA,eAAA,EAAA,EAAiC,MM8ET,CAAA,EN9EmB,EAAM,IAAA,IAAA,CAAU,CAC/D,EM6EoD,CN5EpD,CAAE,GAAG,CAAO,CAAE,QAAS,GAAa,EAAG,aAAa,CAAE,eAAe,CAAE,CAAE,GAAS,IAAF,GAAS,CAAC,CAAC,CAAE,CAC9F,CAAC,6EC1J2C,CAAA,OAAQ,8FAOV,yDAGkB,EqBjB/B,CrBiBwC,EqBjBzB,CQUX,K7BO4C,4CAQlD,CAAA,eAAA,EAAkB,EAAA,CAAA,CAAA,iCAEJ,iBAAmB,GAAS,QAAQ,CAAC,WAQ1D,CAAA,CAAA,CAAA,CAAA,CAAA,kDAI2C,YAEpD,QjEa8H,CACvI,CAAC,iCiEbqD,aAAqB,CAAC,gEAW9B,GZzBK,EAAA,2DY4BgB,QAAQ,YAOpD,CAAA,CAAA,CAAA,oBACP,CAAA,MAAA,CAAA,EAAA,CAAA,eAAA,EAAA,EAAA,CAAA,CAAA,4IAgB2B,CAC5C,GAAA,qEAKyD,CAAE,IAAW,QAAQ,CAAC,IAIpF,AA6YD,GAAA,KAAA,CAAA,8ECnf6B,UAAA,GAAA,QAAoD,GAAA,CAAA,EAAc,IAAI,CAAC,CkBJI,CAAC,KlBIE,CAAC,CAAC,CAAC,mHAiBjC,uDAO9C,EAAA,CAAA,QAAA,EAAe,EAAA,CAAA,CAAA,gHAcP,iCAAyC,ClDgDC,AkDhDA,6BAQzE,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,YACO,CAAA,OAAA,CAAA,IAAA,CAAA,EAAA,CAAA,QAAA,EACM,EAAA,MAAA,CAAe,CAAA,GACG,MAAE,EAAM,GAAG,CAAO,CAAE,CAAE,IAAI,CAAA,OAAA,8FcpDrB,CAAA,OAAA,CAAA,aAAA,CAAA,EAAA,GAAA,CACjB,mCAEI,EAAA,EAAA,EAAA,2CAkB3B,EtECsC,AsEDF,IAAI,CAAA,OAAA,CAAA,aAAsB,CAC9D,EAAoB,GAAG,CAAA,IAGH,4BAAA,AACY,YADZ,OAAA,OAAA,MAAA,CAAA,SACY,EAAA,YAAA,AAE9B,CAAC,GSqB6C,GTvBhB,OAAA,MAAA,CAAA,MAAA,iIAM5B,CAAA,YAE4B,CAAC,EAAQ,EAAA,MAAQ,sBACF,IAAA,CAAA,IAAnB,CAAoB,EAAY,8BACtC,CAAA,GAAA,IAAA,IAAmB,IAAA,CAAvB,IAAI,CAAoB,EAAY,mBAAmB,CAAC,CAAC,qBAClC,IAAA,CAAvB,IAAI,CAAoB,EAAY,QAAF,IAAc,CAAC,CAAC,WAGlC,EAAW,gCAChB,CAAC,oCAIxB,EAAA,KAAA,KAAuB,CAAA,KAAM,GAAG,CjFqBL,AmCzBM,EAAA,Y8CMH,QAC5B,GADuC,CGQT,AHRU,AACpC,GAAA,sDAI6B,mDAQtC,GAAA,CAAA,GAAe,CEmUe,A3F/UZ,CAAA,UyFYY,CAAC,OAAA,EAAA,SAAuB,CAAA,GAAA,kBAIrC,CKEmB,SAAA,OAAA,IAAA,CAAA,EAAA,OAAA,CAAA,SLDE,IAAK,CT+BgB,IhF5CX,CyB4DA,IAAA,OAAA,IAAA,CAAA,EAAA,WgE3C7B,EAAY,CAAA,CrFDE,AoBKJ,CiEJK,EAAA,CAAA,EAAa,EAAS,CAAA,EhF6CJ,AgF7CQ,EAAA,CAAS,ChF6CC,AgF7CA,AAAE,CAAD,AAAC,EAAG,EAAS,CAAA,EAAI,ChF6CP,CgF7CO,CAAS,CAAC,EhF6CE,oBgF1CvE,CrFDG,CAAC,OqFCK,CACvC,MACA,ElBkB6C,CkBjB3C,ClBiB2D,IkBjBrD,KlBiB+D,CkBjBzD,ClBiB2D,AkBjBzD,KAAM,MlBiBgE,GkBjBvD,CAAE,EACjC,EACA,CAAC,EADI,MACI,CAAC,CACX,CAAC,oDAMQ,MAAA,OAAA,MAAA,CAAA,MAAA,CAAA,OAEJ,EAAA,EAEA,CMlBiB,GNkBb,cAAA,MAAoB,CAAC,E1EKtB,sI0EYK,CAAiC,CzF5BgD,EAAH,CAAC,qByF6BzC,CYWL,AFu3Bc,AVl4BR,CYWL,UZXD,gLAEwH,CACpK,CAAC,aAIa,CAAgB,CAAE,A7BvBiC,C6BuBrB,MAC1C,cACa,sBAAsB,MAGlC,EAAA,EAAgB,GAAA,CAAA,oBAGV,MAAA,CAAA,aADoB,WAAW,CAC/B,EAAA,EAAA,CAAwC,CGhBL,AHgBM,CAAC,AGhBN,oFO0PvC,GAAQ,iBAAiB,cAClC,EAAe,GRoCG,MpF1U2D,C4FsSjE,WAA+B,IAAI,SAC/C,EAAU,GAAQ,EAAX,EAAU,eAAoB,CAAC,EAAI,IAAI,eAC9C,EAAgB,GAAQ,IAAD,IAAV,eAAkC,CAAC,EAAI,IAAI,CACxD,GAAG,EAAI,CACU,CADV,AACU,CAAE,CAAA,sDAmnBU,IAAA,GAAA,IAAwB,mBACzB,IAAA,yCAEzB,CAAc,IAAA,GAAA,IAAkB,yBACG,YACnC,CAAA,IAAA,GAAA,IAAA,kBACM,CAAA,IAAA,GAAwC,C9Fv2BK,GAAA,yB8Fw2BhB,6BACY,CAAC,CAAC,C1Fp2BR,gB0Fq2BnB,GAAA,IAAA,0DAEmB,CAAC,yCAEpB,CnB/2BH,EAAA,ImB+2BmB,0BACA,wBACE,IAAA,gDAEV,IAAA,GAAA,IAA0B,iBACtC,GAAA,IAAc,wEApoBT,QAEtB,oOAagC,EpBzLF,WoB+LtB,CAAG,EAAQ,OAAQ,MAC1B,OAAO,CAAA,EAAA,OAAA,EAAsB,GAAA,eAAA,YACvB,CAAG,EAAA,MAAA,EAAkB,CTpNC,eSqNT,qBAER,EnGtRkB,KmGuR7B,QAAA,CACH,GAAc,EAAQ,QAAQ,CAAA,yBAA4B,IAAI,CAAC,EAAA,GAAA,GAAA,cAC1B,CpBtLS,2BoBsLoB,IAAI,GAAA,uCAGpE,CAAA,UAAA,CAAc,ChGnQG,CAAA,UAAA,EgGmQmB,CAAC,ChGnQG,AgGmQF,kBAChB,EAAA,4NAC1B,IAAA,CAAA,GAAgB,GAAoB,CAAhB,CAAC,CAAe,CAAA,CAAC,cAErB,OAEX,MAAA,CAAA,UAAA,OAAA,EAAsC,EAAS,gCAChC,4DASd,IAAA,IAAA,CAAA,WAAA,CAAA,IACD,IAAA,CAAA,QAAA,qBACkB,CPlRG,mCOoRf,IAAA,CAAA,OAAY,aACR,C5E5NH,KAAA,e4E6NK,QAAQ,sFAIJ,C5E5ND,AmE2BiB,CnE3BhB,CfqBS,S2FuMG,oCAEhB,IAAI,CAAC,aAAa,IAC9B,CAAA,yBAaE,IAAA,CAAA,QAAa,CAAA,YAAA,AACtB,iBAE0B,CAAA,OAAA,CAAA,CAAA,MAAA,CAAe,CAAmB,CAAA,iDAKpB,CAAA,OAAA,EAAU,IAAI,CAAC,MAAM,CAAA,CAAE,CAAE,kBAGxC,CAAA,CAAA,QhG1JrB,AgG2JK,ShG3Je,CAAW,CAAA,EAA2B,CAAA,CAAA,YAExD,EAtFR,AAsFQ,SAtFC,EAAA,EAC0B,WAE7B,KAAA,IAAA,EAAA,gBAAA,EAAA,AAAiF,SAAS,EAA1F,AAA4F,CAAC,MAAtC,EAAK,EAAD,cAAiB,OACxE,AAAI,UAAA,6EAGwB,0BAAL,C+FyEH,C/FzEQ,AAA+C,EuFkD9C,CAAC,MvFlDsD,EAAxD,AAA0D,CAAC,MAArC,EAAK,EAAD,aAAgB,OACtE,AAAI,UAAA,4EAGS,SAAZ,OAAA,EAAY,AoB0C2B,KAAA,IpB1CZ,EAAK,OAAO,EoB0CA,ApB1C4C,AoB0C5C,UpB1CsD,EAAE,AoB0CxD,CpB1CyD,MAA9B,EAAA,OAAY,OAC/E,AAAI,CChCD,SAAA,gDDmCiB,EAAA,GAAa,OAAO,SACpB,eAAgC,AAAhC,OAAuC,GAAvC,EAAA,OAA2B,E4F1FI,A5F0F6B,YAAY,EAAE,CAA/B,AAAgC,EAA3B,EAAD,KAAQ,+HAM5D,CoB6CC,CpB7CI,MAAA,GAAS,CAAC,IAC5B,UAAc,GHhEG,A4FqBE,oCzF6Cb,EyFzCJ,AxFUQ,IAAA,KDiCd,EAAY,EAAA,CAAA,EAAA,aAgBlB,GAbA,CgGsPqB,AhGtPrB,YAAA,OAAA,EAAA,MAAsB,EgGsPF,AAAC,CRxME,AQwMF,EhGtP4B,EAAK,EAAD,KAAO,CAAC,EAAE,CAAC,gBAKvD,WAAA,EAAA,EAAoB,WAAW,EuFuD0B,AKpJtB,E5F6FA,CuFuDyB,EvFtDrD,E4F9FmC,A5F8FnC,WAAgB,CAAC,AACtB,QAF0D,CAAC,GAE3D,IACU,EADS,CAAC,AgG8Pd,IhG7PW,CAAG,UAAY,YAElB,G+F6ED,ECmLM,MAAA,ChG7P1B,CkGoBD,AF2OA,kBhG/PqB,GAAuC,SAAS,EAAxC,AAA0C,OAA1C,EAAA,cAAA,OACxB,AAAI,UAAU,qDAGhB,EACJ,KAA0B,IAA1B,EAAA,SAAqB,CAAK,AACG,IADH,CACvB,CAAC,EAAK,GgG+PC,AThMA,YvF/Dc,CsG1GH,CtG0GQ,E+F6EX,C/F3EL,SAAS,CACpB,AkGwBuB,ClGxBtB,CAAA,EAAM,SAAS,CAEpB,MAAO,gBAC0C,kCAAL,CAAK,EAAA,cAA+B,CAAC,A+F4EN,A/F5EQ,GAAA,cAAuB,CAExG,K+F2E4B,CACrB,I/F5EI,mBAEwB,SAAS,CAAC,CAA3C,AAA4C,OAArC,EAAK,gBAAgB,CAAiB,CAAC,CAAC,EAAK,EAAD,cAAiB,CAAC,AAAE,CAAD,EAAU,KAAD,WAAiB,CAClG,YAAa,EwFmDF,QxFlDF,EyFrCI,gBzFuCqB,E+F8EW,CAAC,CAAC,CAAC,M/F9E9C,CkGsBgB,AHwDN,EGxDQ,IlGtBX,EAAK,eAAe,CAAiB,E+F8EW,A/F9EN,C+F8ET,c/F9EwB,C+F8EU,A/F9ET,AAAE,C+F8EQ,A/F9ET,EAAU,KAAD,UAAgB,iBAC5E,CAAC,EAAK,EAAD,MuF8DO,EAAE,CAAC,GvF9DK,WACd,KAAA,IAAL,EAAK,SAAA,CAA4B,GAAA,SAAkB,CAAC,AAAE,CAAD,CAAM,EAAD,OAAU,QAC9E,AAAuB,CwFmDxB,AU7BqB,iBV6BrB,EAAA,MAAA,CU7BqB,ElGtBoB,MAAM,CAAG,AAAF,C+F6EH,A/F7EI,EAAU,C+F6EL,CAAC,I/F7EU,G+F6EH,c/F3EnC,kBAAzB,EAAA,eAAoB,CAAiB,C+F4EU,C/F5EL,eAAe,CAAC,AAAE,CAAD,EAAU,KAAD,UAAgB,SAC7E,YAAP,OAAO,EAAA,OAAA,CAA8B,EAAK,EsG1GI,KtG0GG,CAAC,AHzEC,CGyEA,AHzEA,EGyEU,OAAO,CAC7E,CkGqBC,CAAC,CAAC,cAAA,AlGpBgC,CuF4WiB,CAAC,SWxVlD,OlGpBM,EAAA,gBAAA,CAAsC,EAAK,EAAD,cAAiB,CAAG,AAAF,CAAC,EAAU,KAAD,WAAiB,6BAGrF,gByFvCc,mBzFwCH,CyFxCG,CAAA,aAAA,CAAA,EzFwCsC,aAAa,CAAC,AAAE,CAAD,EAAU,KAAD,QAAc,WACnF,kBAAA,EAAA,SAAA,CAA+B,EAAK,EAAD,OAAU,CAAC,AAAE,CAAD,EAAU,KAAD,IAAU,MAEzD,YAArB,OAAO,EuF6WF,AvF7WO,IAAA,CAAsB,CH3ED,CAAC,AG2EK,EAAD,EAAK,CH3ED,AG2EE,AAAE,CAAD,uBAEd,AAAnC,CkGqBmB,ErGjGF,AqGiGI,MlGrBuB,CAAC,CAAC,OAAvC,EAAK,EAAD,AgGkQkB,gBhGlQC,CAAiB,EAAK,EAAD,gBAAmB,CAAC,AAAE,CAAD,EAAU,KAAD,aAAmB,CAE1G,CAAC,CAI6C,GAKd,CALkB,CAAC,CAAC,SAKR,CAAC,MAAhC,EAAA,MAAA,MACT,EAAA,MAAA,EACa,CyFvCD,EzFuCK,GACR,GAAA,EAAgB,MAAM,CAAC,KACvB,EAAQ,MAAM,CAAC,KAIpB,EAAiB,EAAA,IAEJ,GuFuWC,OvFvWhB,OAAO,GuFuWS,OAAA,QvFtWX,OAGH,EAAA,EAAA,CAAA,EAAsD,WAAW,CAAC,CAAC,AACnE,CsGzGkB,CtGyGuB,EgGgRF,KhGhRS,GAA/B,CsGvGC,EtGuGkC,EAAQ,KAAD,SAEjE,AAFgF,CAE3E,AAF4E,CkGoB7E,AF6PA,CAAC,WhG9Qe,I+F3NgF,A/F2NhF,C+F3NiF,A/F2NjF,C+F3NkF,C/F2NlF,EAGpB,EAAY,IAAA,EAAM,CAAC,CACR,IAAI,CAAC,CyFpCD,CzFoCS,CuFsWL,GAAA,4BvFlWV,EAAI,EAAG,CAAC,AsGvGF,CAAA,EAAA,MAAA,CtGuGsB,EAAE,CAAC,CAAE,CAAC,MAC7B,CAAA,CAAS,CAAC,CAAA,GAEV,SAAS,EAAA,AAAiB,CwFyGD,KxFzGO,CAAvB,AAAwB,CAAjB,A+FrMsB,C/FqMrB,EAAA,EAG7B,CgGiRG,CAAC,CACH,EhGhRC,SA/RG,EAAA,CACI,CACX,CAAmB,CAAA,CAC6E,CAChG,CAAA,CAAA,CACyB,CACzB,CAA2B,CAC3B,CAAkB,CAClB,CAAwB,AwFiUC,CxFhUzB,AwFgU0B,CxFhUU,CACpC,CAAkC,CAClC,CAA8B,CAC9B,CAAwC,CwF6TtB,AxF5TlB,CAAgD,CAChD,CAAkC,CAClC,CAAwC,CACxC,CAAyB,CACzB,CAAoC,CACpC,CAA8B,QCsKN,GAAQ,mDD/J6B,CAAC,GAAW,CAAC,CqGlB1D,gGrG0BQ,iBAIpB,EAAA,CAAA,iBAI8B,+BAER,cAES,aAAA,GAAA,sBACG,SAC9B,aAAA,2CASe,OADG,YAGyB,GmFJK,GnFIE,E2CgBa,CAAA,U3CpF9D,iBAAA,CAFiC,KAEjC,AACM,UADN,OAAA,GACM,WAAA,OAAA,GAAA,UAAA,OAAA,GAGN,AAHM,UAAA,OAGN,MAuEsC,ECwH1C,EAAA,UAAA,AAAgC,CAAC,IwFPI,ExFOrC,GAII,EAAA,WAAgB,EAAA,EAAA,WAAA,CAAoB,QAAA,EAAY,C8FwGP,CAAA,W9FxGsB,CAAC,C8FwGP,O9FxGe,CAAA,GD5H5B,CC4HiC,AD5HhC,CC4HiC,WDzHjF,EAAA,EAAA,EAAA,EAEkB,GAAA,OAAA,CAAA,EAAA,MAAkC,yBAKtC,CkGiBK,AXiCE,CvFlDC,EAAK,GAAA,OAAA,CAAkB,CCXO,CDWE,QAAS,MAAM,KAGlE,YAA6B,CoEuBC,AoB6CF,GAAA,OAAA,IxFpE0B,CAAC,IAG1D,EAAA,EAAA,wCAOiC,GAAA,MAAc,CsGzFzB,AtGyF0B,CsGzFzB,ItG6FnB,GAAA,EAAe,EAAA,cAEE,MAAA,CAAS,CAAC,AuF4DF,CvF5DG,EAAA,IAAU,CAAC,MAAQ,KAAO,KAAK,CuF4DD,AvF5DU,CAAE,CAAC,CAAC,E+FsFP,CAAC,CAAC,CAAC,A/FtFA,AACvE,GAAA,GAAA,WAEA,CAAC,iBACkB,CAAA,SACD,IAAI,CAAC,GAAQ,MAGhC,EAAiB,EAAA,OAAA,GAAiC,EwFyEN,KAAA,CAAA,MxFzEqB,KAAK,CAAC,CAAC,AAAE,CAAD,KAAO,CAAC,GAEjF,EAAA,CAFuF,CAAC,CAAC,AAEzF,CuF8DY,EvF9DZ,IAAA,AAC6C,CAAC,CAAC,CAAC,CADhD,EACkC,MAAM,CAAS,EAAiB,CHvBiB,GGuBb,CAAC,AAAE,CAAD,OAEtD,GAAQ,GAF6D,CAAC,AAE9D,AAAuB,GAAG,CAA1B,EAAA,MAAkB,C+FiG5B,S/FhGK,C+FiGC,Q/F9FvB,IAAA,EAAA,EAAA,EAAA,EAAA,MAAA,CAAA,EAAA,EAAA,QACiB,CAAA,EAAA,uBAGS,KAAqB,IAArB,EAAW,EsGlFF,GtGkFO,CAAK,EAAA,KAAuB,C4E+FzE,A5E/F0E,CAAK,CAAC,EAAW,CAAC,AAE5F,C8FkFC,EAAA,GAAA,OAAA,e9F7EK,EAAA,GAAA,EAA8C,EAAY,OAAO,CAAC,KAAK,CAAA,OAAW,EAClF,EAAA,GAAA,GAAA,AAE6B,YAF7B,OAAA,EAE6B,EAAA,EAAA,GAE7B,EAAA,GACiB,EAAA,IAAA,EAAgC,IAAA,EAAoB,GAAA,iBAGrE,EAAmB,C4Fac,GAAA,iB5FZR,MAE7B,CCVS,CAAA,EDYP,CCZ+B,CDa/B,EACA,CkG6CsC,ClG5CtC,EACA,EACA,EACA,EACA,OADS,GAFO,IACE,CAEH,AAEoB,GAAA,GAA4B,GAAO,CkGwCX,IlGxCkB,EAC7E,EACA,EACA,EADI,AAEJ,EACA,EACA,EACA,CAJS,CAEH,AAGN,EACA,GALa,AAEJ,EAEF,OADS,EAwIhB,CAAG,CAtIa,AAsIZ,CArIL,CACF,AuFueoC,CvFnW1B,AuFmW0B,AvFvenC,AAqIE,EAEA,CAFG,CAEH,EAEA,CgG6QgC,ChG7QxB,CuFgWoB,ASnFM,MDrdR,S/FwMF,CACxB,EAAQ,KAAD,aAAmB,CAC1B,EAAQ,KAAD,IAAU,CACjB,EAAQ,KAAD,UAAgB,CACvB,EAAQ,KAAD,CAAO,CAAC,AAAE,CAAD,CAAS,KAAD,EAAQ,CAAC,AAAE,CAAD,GAAK,CACvC,EAAQ,KAAD,CAAO,CACd,EAAQ,IAAI,CAAL,AACP,EAAQ,KAAD,IAAU,CACjB,EAAQ,KAAD,QAAc,CACrB,EAAQ,KAAD,CAAO,CACd,EAAQ,KAAD,IAAU,CACjB,EAAQ,KAAD,WAAiB,CACxB,EAAQ,KAAD,EAAQ,CACf,IAKN,IAAM,EAAS,CALE,CACZ,AAIe,CAHjB,CAAC,EAGoB,CAAC,EAAQ,SAAS,CAAC,CACvC,AgG6PsC,AhG9PE,CgG8PD,ADndtC,CAAA,CAAA,IAAA,EAAA,cAAA,C/FsN0C,IAAA,YAEnC,eAAA,GsGzHQ,ctG0HoB,CAAC,SAApB,CsG1HD,GtG4HN,0BAGA,mBAIP,EAAA,MAAa,CAAA,EAAA,EAAgB,EAAS,AgG+P3B,EhG/P6B,AgG+PpB,CAAC,AhG/PoB,CgG6E1B,EAAO,CAAE,EhGhQM,UAAA,UgGgQiB,CAAE,uBAI/C,CAAA,EAAG,IAAA,CAAK,WAAW,CAAC,ERlMF,EQkMM,CAAA,GRlMA,CAAA,EAAA,GAAA,CQkMgB,CAAC,wBAIhD,CpBhKC,KoBgKM,CAAA,qBAAA,EAAA,KAAA,CAAiC,CAAC,MDzKd,CAAC,CPzBiB,AOyBhB,UC8K7B,CJlQmB,AIkQN,CAAA,CAAA,CAAA,CAEG,CAAA,QAET,GAAA,QAAwB,CAAC,EAAQ,ERxMZ,AQwMmB,EEhOA,AFgOS,CEhOR,MFgOe,CAAC,CAAC,AAG7D,aAAA,SACW,IAAA,AhG5P4E,CgG4P5E,AhG5P6E,CAAC,OgG4PjE,CAAA,MAAA,IACjB,YAAP,OAAO,EAAA,OAA8B,QAI/B,MAAA,gCAE+B,MAAA,YAC7B,C/FnRO,EAAA,CAAA,4CAAA,E+FoRgC,EAAI,OAAO,CAAA,CAAE,QAEnD,CAAG,CAAE,AEhOJ,KFoOO,iBAAV,GAAsB,CAAA,EAC/B,KADuC,CACjC,ChGtPK,GgGsPD,GACR,CAAA,uEAAA,EAA0E,EAAK,CAAE,CAClF,CADgF,AAC/E,YAEC,MAAA,CAAS,GACP,EAGT,SACE,CAAY,CAAA,CAAA,CAAA,CAEuB,CExOR,KF0OrB,EAAU,CAAA,GAAE,IAAI,CAAA,GAAA,IAAA,IAAmB,IAAA,CAAvB,IAAI,CAAqB,EAAI,GAAmB,IAAI,CAAC,MAAV,CAAC,AAAgB,CAAC,AACzE,MACJ,A/F5RO,CAAA,GiC5NJ,GAAA,IAAA,CjC4NI,G+F6RG,EACA,GAAW,EAAQ,CAA3B,IAAkB,GAAiB,CAAC,MAAQ,EAAK,UAAU,CAAC,GAAG,CAAC,CAAG,AAAF,CAAC,CAAM,EAAD,GAAM,CAAC,CAAC,CAAC,CAAC,AAAE,CAAD,AAAC,CAAI,CAAC,CAAC,AAEvF,CAFwF,CAExF,IAAmB,CAAC,YAAY,SAClC,CAAC,6DAAW,CR7MH,C3FnHO,KmGiUV,KAAiB,CAAE,GAAG,CAAK,CAAA,CAAE,CAGlB,CR7MT,C3FrHkD,QmGkU1D,OAAO,GAAsB,GAAS,CAAC,CAAL,EnGlU+C,CAAC,CAAC,AmGkUvC,CAAC,OAAO,CAAC,KAAK,AAC5D,CAD6D,AExO1D,AV4BF,CAAA,CQ4M8D,CAAC,ChGhQC,CAAC,CAAC,CgGiQzD,CAAG,IAAI,CAAA,cAAe,CAAC,EAAA,oCASN,CAAA,CAAA,OACvB,IAAA,CAAK,WAAA,GASH,CPrST,KOqSe,eACd,CAAoB,CAAA,CAClB,CR7MyB,A3F1HE,C2F0HD,GAAA,CAAA,QAAA,CQ6Md,ChGhQ2B,AgGgQsB,CAAA,CAC/C,CAElB,CTnMC,ESmME,CAAA,CAAA,CAAoB,CAAqC,CnG1UpB,YmG2U3B,CAAA,aAAA,CAAe,MAAA,EAAa,EACzC,CAAC,A/F9RA,K+FgSS,CAAA,CAAA,CAAmD,CT2GjD,QS1GH,IAAA,CAAA,aAAkB,CAAC,OAAQ,CDrLH,CAAA,ECsLjC,CAAC,APzSE,AO2SH,MAAW,CAAY,CAAA,CAAA,CAAA,0BACI,CAAC,QAAA,EAAe,CM5WC,CN6W5C,CAAC,AAED,GAAG,CAAA,CAAA,CAAA,CAAyD,CAAA,YAC/C,CAAC,GE7OG,UAAA,CF6OW,MAAO,EAAM,EACzC,ChGlQC,AgGkQA,AAED,ChGpQE,MgGoQU,CAAY,CAAA,CAAA,CAAA,QACf,IAAA,CAAK,EE9OF,WAAA,CAAA,SF8O0B,EAAM,EAAF,CAGlC,cACN,CAAA,CACA,CAAY,CAAA,CACyB,CAAA,QAE9B,IAAA,CAAK,OAAO,CACjB,GP9SqB,KO8Sb,CP9SmB,MO8SZ,CAAA,GAAO,IAAI,CAAC,AAAC,IAAI,AACvB,EADyB,EAAE,WACjB,EAAM,CMnXD,CNmXD,CAAK,CMnXD,CNmXK,CAAE,CAAC,EAKvC,QAAA,CAC8C,CAAA,EAAA,IAAA,CAAA,QAGrC,IAAI,CnG1VD,EAAA,ImG0VgB,CAAA,IAAM,CAAA,WAAY,CAAA,EAAA,EAA4B,GT+FG,KS9F7E,CAAC,MAEa,YACZ,CAAiD,CACjD,CAA+B,CE3PP,AF4PxB,CE5P0E,AV0FlB,AQkKjB,CRlKkB,AQkKlB,CE5PqC,AF8P5E,IAAM,EAAU,MAAM,EM5XE,Ad0NvB,CADsB,CACtB,EQmK0B,IE3PA,MAAA,EF2Pc,IAAI,CAAC,ETyFqB,QSzFX,CAAC,GTyF6C,CAAC,CAAC,ASxF1E,gBAIxB,IAAA,CAAK,cAAA,CAAe,YAEf,CAAA,IAAA,CAAK,SAAE,CAAA,CAAS,CAAG,GE7PD,CV0FK,EQmKE,IAAI,CAAA,YAAa,CAAC,EAAS,YACjD,CDxeO,CAAA,cC2eX,CAAA,cAAe,CAAA,EAAM,KAAE,CTsFL,SStFU,QAGhC,EAAe,CD/dG,AN2KF,MOoTQ,CAAmB,CAAC,SAAlB,KAAK,KD/dO,CC+dD,IAAkB,CAAb,CAAa,QAAW,CAAC,EAAE,CAAC,CAAC,QAAQ,CAAC,CAAC,CAAE,GAAG,CAAC,CAAC,AACxF,EhGhRE,AyFpCF,AzFoCe,KAAA,IgGgRD,ChGhRC,CgGgRmC,EAAE,CAAC,AAAE,CAAD,AAAC,GD/dI,CAAC,OAAA,EAAA,EAAA,CC+d8B,CAAC,OAC1E,GAAA,aAET,CE/PG,AF+PF,CAAA,KAAM,CACnB,CAAA,CAAA,EAAA,EAAgB,CToFc,CAAC,CAAC,cAAA,CSpFG,CACnC,GAAqB,CACnB,gBADkB,qBAEI,iBAGtB,QAAS,CRxKH,CAAA,OQwKc,cAIJ,SAAS,CAAC,IACtB,IAAI,OAGN,EAAA,IAAiB,wBACA,IAAI,CAAC,ETiFN,cSjFsB,CAAC,ChG9PG,CAAC,AAAC,CgG8PF,AhG9PE,CAAA,EgG8Pc,GAAY,CTiFP,ISjFY,CAAC,IAC5E,ChG7PG,CAAA,KgG4PoF,AACpE,ChG7PG,AgG4PkE,CAAC,CACnE,mCAEY,CAAE,CAAC,EMxXA,CAAC,gBNyXR,EAAgB,mBAAA,CAAqB,CAAC,GACpE,EAAQ,MAAM,CR3KH,AC3IM,CAAA,SOsTQ,CAAC,EhG9PE,CAAC,CgG+PzB,CPtTG,GOsTC,SAOV,GAAa,CD9cmB,GAAA,eAAA,IAAA,CAAA,OC+cL,IAAa,IAAL,CAAC,EAAW,CAAR,EAAY,EAAW,MAAH,AAAS,CAAR,AAAS,CAAR,CAAiB,KAAK,CAAN,AAAO,CAAC,AAAE,CAAD,CAAC,CAAE,CAAC,CAAC,CAAC,EAC1F,CD9cG,QC+cL,GAAU,GR1KK,CQ0KD,EADM,AACJ,CADK,GACD,CAClB,CAAA,CAAA,EAAI,EAAY,UAAA,GAAA,EAAgB,EAAY,OAAH,CAAC,CAAC,EAAY,CAAC,AAAE,CAAD,OAAS,CAAA,GAAA,EAAM,EAAY,CAAE,CACvF,CAAC,GACQ,IAF4E,AAExE,CAAC,CAAC,KAAK,CACnB,CAAA,CAAA,EAAI,CMzXiB,CAAC,ANyXN,aAAA,EAAgB,EAAY,OAAH,CAAC,CAAC,EAAY,CAAC,AAAE,CAAD,OAAS,CAAA,EAAA,EAAK,EAAY,CAAA,CAAG,CACtF,GAAqB,IAD8D,aAC/D,UAElB,GAAG,UACS,EAAA,YACM,OAAO,QAGlB,CAAC,YAAA,CAAA,EAAsB,EAAkB,GAAuB,MAE7E,GAAU,GAF+E,CAAC,AAE5E,CAF6E,AAE5E,CAAC,IAAI,CAAA,CAAA,CAAA,EAAA,EAAA,aAAA,EACc,EAAY,MPzT2B,MOyTb,SAAQ,8BAAA,CAAgC,CACnG,CAAC,GACQ,IAAI,CAAC,CAAC,KAAK,CACnB,CAAA,CAAA,EAAI,CDhRqB,CAAC,ACgRV,CD/QnB,CAAC,QC+QkB,GAAA,EAAgB,EAAY,OAAH,CAAC,CAAC,EAAY,CAAC,AAAE,CAAD,OAAS,CAAA,8BAAA,CAAgC,CAClG,GAAqB,iBAAD,IAClB,MACA,aACY,EAAc,CM/XkB,CNgY5C,OADmC,CAC1B,EAAS,OAAO,IAGzB,CTnTO,OSoTH,CR/KG,EQ8KI,CAAC,AACJ,GTnTS,CCkID,EQiLF,CAAC,EAEb,IAAI,GAA0B,CAAE,EAAtB,CAAC,EAAkB,AAAQ,CAAE,CAAQ,CAAE,CAAC,CAAC,IAAJ,AAGjD,CALwC,CAKvB,CALyB,AAKxB,ATnTE,CS8SuB,AT9StB,ISmTS,OAAO,CAAC,OAAO,EAAE,CAAC,CAAA,MAC7C,CAAC,CAAC,CAAC,EAAK,EAAD,AAAG,ARhLA,CQgLY,cAAc,CAAC,EAAxB,GAAwB,CAApB,CTnTK,CAAC,ASmTc,CACvC,CAAC,CAAC,EAAM,ERhLA,AQgLM,EAAE,CAAA,KAAU,EAAO,EAAH,GAAU,IAAI,CAAC,SAAS,CAAC,IAAO,CAAF,CAAC,CAAC,CAC9D,CAAC,IACF,EAAA,CAAA,CAAA,EAAmB,EAAY,CTnTP,CAAC,ASmTS,EAAW,EAAG,EAAc,EAA/B,AAA+B,EAAK,CAAtB,CAA0B,CAAD,KAAR,AAAe,CAAA,CAAA,EAAI,EAAG,CAAA,EACxF,EAAS,EAAE,CAAC,AAAE,CAAD,EAAL,QAAiB,CAAC,AAAE,CAAD,OAC7B,CAAA,aAAA,EAAgB,EAAS,MAAD,AAAO,CAAA,IAAA,EAAO,EAAc,EAAS,EAAA,CAAI,CAAC,GAAjB,AAAY,AAEzD,CAAA,EAAA,EAAY,CAAE,CAAC,AACjB,IAAA,EAAoB,ITtTQ,CAAC,ACkIR,CAAA,IAAA,CQoLU,WAAW,CAAC,EOlqBI,CAAC,APmqBhD,GAAI,EAD+C,CAAC,AAChD,CADiD,CAChB,CAAC,AACpC,IAAM,EAAA,CAAA,UAAA,EAAA,EAA4C,mBAAA,CAAqB,CAAC,AAexE,EQxpBQ,AjB+VF,KS6SN,ETvTM,ISuTA,GAA2B,EAAS,IAAA,EAC1C,GAAU,IAAI,CAAC,CAAC,IAAI,CAAC,CTtTO,CAAC,CSsTL,EAAY,GAAA,EAAM,EAAY,CAAE,CAAC,CAArB,AAAsB,GAChD,IAAI,AADwC,CACvC,CAAC,KAAK,CACnB,CAAA,CAAA,EAAA,EAAgB,kBAAA,EAAqB,EAAY,CAAA,CAAG,CACpD,GAAqB,CACnB,GAF+C,aTtTzB,ASuTJ,CTvTK,ESwTJ,GACnB,GRxLK,AQwLF,CAAA,EAAW,GAAG,CACjB,ETzT0B,ACiIxB,CDjIyB,ISyTnB,EAAA,MAAe,KRxLK,IQyLnB,EAAS,ETxTQ,CAAC,ISwTF,YACb,EAAc,KAGvB,IAHgC,AAG5B,CR1L2B,AQ0L1B,YAAY,CACtB,EACA,EACA,GAAuB,AAFhB,EAGP,EAAS,MAAD,CAAQ,AAFA,CACmB,AAEpC,CAAC,AAGJ,GALuB,CAKjB,EAAe,EAAc,CAAA,2BAAA,CAA6B,CAAC,AAAE,CAAD,AAAC,oBAAA,CAAsB,CAAC,AAE1F,GAAU,IAAA,EAAM,IAAI,CAAC,CAAA,EAAA,EAAA,GAAA,EAAqB,EAAY,CAAE,CAAC,CAAC,AAE1D,IAAM,EAAU,CAFsC,KAEtC,EAAe,IAAI,EAAE,CAAC,IR/LE,CQ+LG,CAAA,AAAE,GAAa,ER/LL,CQ+LiB,GAAG,AAAE,CAAD,AR/LL,MQ+La,CAAC,CAAC,AAC9E,E9DtmBL,A8DsmBe,C9DtmBf,EsEzD2B,iCtE4DvB,EAAA,W8DmmBoB,CR/LH,EQgMhB,EAAa,EAAA,KAAA,EAAsB,CAezC,MAfgD,CAAC,AAEjD,GAAU,GTjUF,CSiUM,CAAC,CAAC,KAAK,CACnB,CAAA,CAAA,EAAI,EAAY,GQhqBmC,AAAX,eAAW,ERgqBd,EAAY,CAAA,CAAG,CACpD,GAAqB,iBAAD,IAClB,EACA,ETnUQ,CSmUL,CAAE,CQjqBU,CRiqBD,CQjqBU,ERiqBP,CACjB,OAAA,EAAiB,MAAM,CACvB,GQhqBO,KRgqBE,CRnMH,CQmMY,MAAD,CAAQ,CACzB,OAAO,AThUE,CSgUA,EACT,ETjUe,CAAC,CAAC,EC4HA,KQqMjB,KAAiB,GAAG,EAAE,CAAG,EQ/pBa,GRmqB1C,IAAA,CAAiB,MQ9pBiB,SR8pBF,CAAC,CQ9pBY,CR8pBH,CQ9pBY,KR8pBN,CAAE,EAAS,EAAY,EAAS,CAAvB,KAAY,AAAU,CAAQ,CAAC,CAAC,UAIjF,IAAI,CAAC,CAAC,IAAI,CAAC,MACX,CTjUsB,GSiUlB,CAAC,CAAA,KAAM,CACnB,CAAA,CAAA,EAAI,EAAY,GQ/pBsB,AAAW,aAAA,CAAA,CRgqBjD,GAAqB,iBAAD,IAClB,EACA,GAAG,CAAA,EAAW,GAAG,CACjB,CQjqB0B,AhBwd3B,KQyMO,CAAE,EAAQ,MAAA,AAAO,CACvB,KTjUiC,CiB9VzB,CR+pBD,CAAE,EAAS,OAAO,CACzB,QQhqB2C,GRgqB/B,EAAc,KAIvB,IAJgC,MAI9B,MRzMM,EQyME,EAAE,aAAS,UAAU,KAAE,ETjUI,oBSiUU,ITjUM,QSiUe,CAAS,CAAE,CAAC,MAAH,KAIpF,CAAA,CAAA,CAAA,CAAA,CAEqB,CAAA,GTrUO,SSuUjB,CAAC,EQrqBS,YRqqBK,CAAC,EAAM,CAAE,CAAJ,MAAY,EQrqBS,CAAC,ERqqBL,MAAE,EAAM,EAAF,CAAK,CAAI,CAAE,CAAC,CAAC,eAOnE,CR/MY,CAAA,CgB1dI,AR0qBY,ARhNhB,CQgNgB,KQ1qBY,GR6qBjC,IAAI,GAAwC,IAAqB,CADxD,CAC0D,GADtD,CAAC,WAAW,CAAC,EAAS,IAAI,CAAN,KAAQ,GACmC,EACrF,EADyF,CAAC,CAAC,AADhC,CAAC,CAAC,CAIvD,iBACJ,CQ7qBsB,AR6qBN,CAChB,CAAA,CAAA,CACU,CT/UyB,ASgVnC,CAA2B,CAAA,IAErB,QAAE,CTjVE,CAAA,OSiVM,CAAM,CQhrBZ,ARgrBc,GAAG,EAAO,CAAA,GAAa,CAAb,AAAa,CAAE,CAAC,AAC9C,GAAA,EAAA,gBAA+B,CQ/qBF,AR+qBG,CT/UP,OS+UgB,GAAG,CAAG,EAAW,KAAK,EAAE,CAAC,CAAC,AAEvE,ITjVmE,ASiV7D,CTjV8D,CAAC,ASiVrD,WAAW,GAAG,CAAG,EAAW,KAAK,EAAE,CAAE,EAAE,CAAC,AAElD,CAFmD,CAGrD,WAAA,cAAA,EAAqC,EAAQ,IAAI,YAAa,UAAkB,CAAC,cAAc,CAAC,CACzE,GRzNC,CAAC,CAAC,GQyNK,EAAhC,OAAA,EAAe,IAAI,EAA6B,OAAZ,EAAQ,IAAI,CAAL,CAAkB,MAAM,CAAC,aAAa,IAAI,EAAQ,IAAI,CAAL,AAAM,AAE/F,CAFgG,CAEpE,EQ3qBtB,AjByVO,eSoVjB,GAAG,EQ3qBgB,CR2qBI,CTlVH,EiBzVD,IjByVC,MSkViB,CAAE,AQ3qBS,CR2qBN,AQ3qBO,AR2qBT,CAAC,AAAC,CAAE,CAAC,ATlVJ,ASmVzC,OAAQ,GRzNK,GQ0Nb,GAAG,CRzNC,EQ2NF,IAGF,EAAa,EAHH,AQtqBF,CRsqBG,CRzNH,AgBjdW,ER6qBA,CAAG,EAAO,IAAD,OAAY,EAAA,CAAE,CAAC,AAG7C,GAAA,CAEE,OAAO,MAAA,IAAA,CAAA,KAAgB,CAAA,IAAK,MAAC,EAAW,EAAK,CAAF,CAC7C,CAAC,EADuC,KAC9B,CACR,AADS,IRxNA,MgB9cK,ERuqBF,CAAA,GAEhB,CAAC,AAEO,KAAK,CAAC,YAAY,CAAA,CAAA,CAExB,IAAM,EAAoB,EAAS,ERxNb,IAAW,CQwNS,CAAA,GAAI,CAAA,wBAG9C,AAA0B,IRzNF,IQyNU,CAA9B,GACsB,GQlqBd,ARiqB6B,ERrNd,IQsNQ,CAA/B,AThVC,ISmVmB,EAHkB,CAGf,IT/UM,CS+UpB,AT/UqB,IS+UE,ARtNrB,EAAA,EQyNf,AAAwB,CQlqBiB,ERkqBd,EAAE,CAA7B,AQ9pBG,CAAC,CR8pBS,IAAuB,EAAjB,EAGK,KAAK,CAAzB,EAAS,CQ/pBQ,GR+pBe,CRpNxB,CQoNO,KAGf,EAAS,MAAD,AAAO,EAAI,GAAA,CAAG,AT/UR,ES+UU,AAKtB,KAAK,CAAC,CALuB,IAAI,QAMvC,CAA4B,CAC5B,CAAwB,CACxB,CAAoB,CACpB,CAAqC,CAAA,CAKrC,IAHI,EAGE,CRxNC,CAAA,GAAA,IQwN6C,kBACpD,GAAI,EAAwB,CAAC,IACrB,EAAY,CQ/pBV,UR+pBqB,EACzB,CAAC,MAAM,CAAC,KAAK,CAAC,EQ/pBQ,GRgqBxB,EAAgB,CAAA,CAEpB,CAGA,EANgC,CAAC,CAM3B,EAAmB,CTlVZ,ESkV6B,GAAG,CAAC,GQxpBY,GAAX,gBRypBtB,EQxpBI,ARwpBW,CAAC,IACjC,EAAiB,WAAA,KAClB,OAAA,KAAY,CAAC,ERtNE,CQyNF,KAAK,KAAA,CAAA,GAHY,AAGc,CAHb,GAGiB,CAAC,GAAG,EAAE,CAFxB,AAEyB,IAF1C,CAIpB,CAAC,AAID,ET1V8B,CS0V1B,CAAC,AAAC,GR9NuB,CQ8NvB,GAAsB,GAAiB,EAAgB,EAAE,CAAG,CAAI,CT9UlD,AS8U8C,AAAK,AT7UzC,CAAA,AS8U5B,EADuC,CT/Ud,CSgVnB,EAAa,EQvpBM,URupBY,CRpNH,CQoNO,GRpND,CQoNK,CAAC,IRpNA,MQoNU,CAAC,AACzD,EAAgB,GQtpBR,CRspBY,CAAC,GQvpBF,+BRupBoC,CAAC,EAAkB,EAC5E,CAAC,OADqF,AAEtF,CAFuF,CAAC,EAAd,CQppB/C,CRspBrB,GAAM,CRpNH,CQoNE,CAEJ,IAAI,CAAA,WAAY,CAAC,CQnpBC,AhB8bJ,CQqNY,EAAmB,CAAC,CAAE,CAAxB,CACjC,UADmD,AAAkB,CAAC,CAAC,yBAGJ,CAAE,CAAkB,CAAA,CAYrF,OALqB,AAKd,EQ/oBI,GR0oBU,GAAQ,CANH,AAMI,GAND,AAMqB,CANpB,EAWR,CALgC,CAAC,GAAG,CAAC,AAK/B,CALgC,CAHzC,CAG2C,CAH9B,GAFV,IAQP,CAAC,CAHwD,AAGrC,CAHsC,EAAE,CAGxD,GAN6B,CAAC,AAM1B,CAAC,CRxNH,GgBtbgB,ER8oBP,CAH0D,CAGxD,AAAG,AAHsD,CAAC,AAGnD,AQ9oBS,CR8oBR,AAET,CTlVG,CAAC,CSmVrC,CADqC,AACpC,AAED,CAHsC,KAGhC,aACJ,CAAiC,CACjC,YAAE,CTrVgC,CSqVnB,ATrVoB,CSqVnB,CAAA,CAA8B,CAAA,CAAE,CAAA,EAApC,GAEN,EAAO,CAAK,EQlpBL,AhBqbC,CQ6NO,CAAR,AAAoB,CAAE,CAC7B,AAD8B,MTtVJ,ESuVxB,CAAM,MAAE,CAAI,OAAE,CR7NL,AQ6NU,gBAAE,CAAc,CAAE,CAAG,EAE1C,EAAM,CAAH,EAF8C,CAAC,AAExC,CAAA,QAAA,CAAU,CQlpBU,CAAA,ERkpB+B,GAC/D,YAAa,GAAS,iC9Dr0BE,OAAA,SAAA,CAAiB,SACvC,IAAA,GAAA,CAAA,EAAA,EAAA,mBAAA,CAAA,uDAGoD,CjBuBG,AiBvBF,CAAC,E8Di0BlC,UAAA,EAA2C,OAAO,EAC5E,EAAQ,CQ9oBG,IR8oBJ,EAAQ,CAAG,EAAA,OAAe,EAAA,IAAQ,CAAC,OAAA,IACpC,aAAE,CAAW,MAAE,CQ9oBS,CAAA,AR8oBH,CAAG,GQ9oBU,CAAA,CAAA,SR8oBI,CAAC,SAAE,IACzC,EQ/oBoD,AR+oBvC,MAAM,IAAI,CAAC,YAAY,CAAC,CAAE,QAAS,SAAc,ER7NR,YQ6NgB,aAAa,IAazF,MAAO,KAX2B,kBAEvB,EACT,GAAI,EQ3oBM,AR2oBE,GADO,GACD,EAAI,CAAE,MAAM,ATvVI,CSuVF,EAAQ,KAAD,CAAO,CAAE,CAAC,GAC5C,ETvVG,QSuVe,CAAA,cAAe,EACpC,CR/NwB,AgB5aiB,GR2oBrC,GQ1oBO,MAAA,WR0oByB,UR9NL,IQ8NmB,EAAI,CAAE,MAAM,CAAA,QAChE,GAAI,GAAQ,CAAJ,KAAM,CAAI,CAAE,CAAC,AACrB,GAAK,IAAI,CAAC,IQ1oBO,QAAA,ER0oBiB,CAAA,CAAE,CACpC,GAAK,ETrVW,IiBrTG,AjBqTH,QSqViB,EAAA,CAAA,CAAA,MAGrB,EAAK,QAAS,EAAQ,OAAO,CAC7C,CAAC,AAEO,MAAM,aAAa,SACzB,CAAO,QACP,CAAM,aACN,CAAW,YACX,CAAU,CAMX,CAAA,CACC,IAAA,EAAsC,CAAA,CAAE,AACxC,CADyC,AACzC,IAAQ,CAAC,UQ7oBY,OR6oBK,ET9VI,AS8VW,KAAK,CQ7oBU,CR6oBR,CAAlB,IACvB,EAAQ,AADqB,AQ7oBS,cR8oBhB,EAAA,CAAA,EAAU,CT7VtB,aS6VoC,CAAG,IAAI,CAAC,qBAAqB,EAAA,CAAE,CAAC,AACnF,CAAA,CAAmB,EQ5oBM,ER4oBF,CAAC,iBAAiB,CAAC,CAAG,CRpOD,CQoOC,cAAsB,CAAC,CAGtE,IAAM,EAAU,GAAa,CT7VT,USgWR,CQvoBc,kBRwoBtB,EQroBQ,WRqoBM,IAAI,CAAC,YAAY,EAAE,CACjC,CQpoBO,yBRooBoB,EQpoBe,KRooBR,GQpoBgB,GRqoB9C,EAAQ,CQpoBC,IhBgaQ,EQoOF,CAAC,AAAE,CAAD,AAAG,CT1VO,oBS0Vc,CAAE,MAAM,CAAC,IAAI,CAAC,KAAK,CAAC,EAAQ,KAAD,EAAQ,CAAG,IAAI,CAAC,AAAC,CAAA,AAAE,CAAC,AAAE,CAAD,AAAC,CAAE,CrD7tB9F,AqD6tB+F,OrD7tB/F,EAAA,qGArK4E,oBAElF,CAAC,+BAF4B,KAAA,eAAA,OAAA,CAA2B,WAAmB,OAAO,CAAA,+FAmCjD,kCACgB,EAAE,wBACf,C6CkGG,AOrGA,IpDGE,KAAA,CAAA,IAAU,CAAC,4DAG7B,UAAnB,EkCKqC,KAAA,KAAA,OlCLlB,CAAA,KAAqB,OAAO,CAAC,AAAE,CwCpBhB,AxCoBe,GAAK,CAAC,OAAO,EAAE,IAAI,EAAI,SAAS,kBAG/C,yBAC/B,6MAMsD,OAAA,0CAMvC,0DAEiB,EctBC,SdsBkB,OAAO,CAAA,QAAS,EAAI,CctBV,2CduBZ,OAAA,CAAA,IAAY,EAAI,E3CJH,8J2C0C/B,CAAA,0BAenC,GAAA,CAAQ,KAAA,SAAK,CAAA,CAAS,gEARvB,IAAA,aAA6B,sCAAsC,CAAE,EACrE,A3CjB4D,CAAC,G2CiB7D,8DqDkPmG,CAClG,CAAC,yDrDlPuE,CAAE,EAC3E,C3CfC,GAAA,8D2CgBD,IAAA,oFAAoG,CAAE,EAI/E,aACC,CAAA,UAAA,SAAoB,C2DtGN,A3DsGO,CAAC,cAE1B,EAAA,EAAA,KACD,CAAA,EAAG,EAAA,IACR,CAAK,CAAA,EAAA,EAAA,mBAEI,CILQ,OJKC,CAAA,EAAG,EAAK,CAAA,CyBG1B,CAAA,EAAA,CAAA,EzBHuC,EAAA,CAAO,CAAE,CAAC,QAI5D,kBAvDH,mBAAoB,CzC4BG,mHyCxBA,CAAA,QAAA,EAAW,EAAY,OAAO,CAAA,CAAE,wCACL,sBAMhC,oFAGA,wEAEW,cAiFzB,CqD8tBF,CACA,EADG,GQpoBc,gBRqoBI,CADE,AACA,CT1VO,CAAC,ES0VJ,CAAC,YAAY,CACxC,QQnoBc,SRmoBI,CRnOO,GQmOH,CAAA,OAAA,QAElB,IAAI,CAAC,QQnoBiB,GAAA,CAAA,QRooBvB,CT1VG,OAAA,CAAA,cS0VoB,CAC5B,EACA,EAAQ,KAAD,CQnoBO,CRkoBH,AACI,CQloBK,ARmoBrB,CAAC,CAAC,AAIH,OAFA,IAAI,CAAC,eAAe,CAAC,GAEd,EAAQ,EQnoBF,ARioBe,CAAC,CAAC,CAEhB,CAAO,CAAC,ET7ViB,CAAC,CAAC,MSgWzB,CAAE,CTvVL,OSuVc,MAAE,CAAI,CAAE,QAAS,CAAU,CAAE,CAAoC,CAAA,CAI5F,GAAI,CAAA,EACF,IADS,CAAC,AQloBD,CRmoBF,CAAE,WAAW,CAAA,KAAA,EAAa,UAAM,CAAS,CAAE,CAAC,EQnoBI,ERqoBnD,EAAU,GAAa,CAAC,CAAjB,AQnoByB,CAAjB,CAAS,QRooB9B,IACE,QACY,MAAM,CAAC,CQloBD,GRkoBK,AAAC,CAAA,KADC,OAET,CQpoBwB,YRqoBxC,IAAI,MQloBU,GRkoBE,EQloBM,QRmoBL,EQloBW,QRkoB3B,OAAA,GAEC,EAAA,MAAc,CAAC,GAAG,CAAC,GTrVG,cSuVtB,SQjoBiB,ERioBE,EAHgC,EAG5B,EAAI,CQjoBD,YRioBkB,OTrVP,IAAA,ISqV8B,CAAC,CAEtE,EADA,EACI,GQhoBO,MRgoBK,QAAQ,EAExB,EADA,EACI,SAAY,IAHsB,WAGP,EAE7B,WAAmB,cAAc,EAAI,IAAI,AAHgB,QTnVsB,CAAC,ASsV1B,UAAkB,CAAC,cAAc,CAAC,AAEnF,CADP,AACS,CADR,UACmB,MAAE,EAAW,IAAI,CAAE,CAAgB,CAAE,AAA1B,CAA2B,AAE1D,AAAgB,CAFuC,MTjVzB,KSoV9B,KADO,GACP,CTpVkB,ASmVP,AACX,OAAQ,aAAa,IAAI,GACtB,CTnV8B,ASkVJ,CTlVK,ISmVzB,CAAC,QAAQ,IAAI,GTlVS,ASkVD,CTlVE,ASkVN,KAAU,GAAI,GAA6B,CAAzB,WAAI,OAAO,EAAK,EAAD,EAAK,AAAK,CAAU,AAAC,CAAC,AAE1E,CAAE,AS/7BI,CT87Bb,CAAC,SACmB,MAAE,EAAW,ITnVD,ASmVK,CAAE,EAAR,CAAiC,EAAkC,AAAtD,CAAC,AAAuD,CAAH,AAAI,AAE9F,CAF2F,AAAnC,EAExD,ETlVyB,ESkVrB,CAAA,GAAA,IAAS,CAAA,IAAA,CAAb,IAAI,CAAU,MAAE,IAAI,MAAE,CAAO,CAAE,CAE1C,AAF2C,CAE1C,AAF2C,GAAJ,sDSz7BxC,kCTqaa,CAAC,OAAO,AACrB,CStaA,ATsaC,UAuhBY,CAAG,EAAI,AAAP,CAAQ,kBACC,CAAG,QAAQ,UAEf,CT7UoE,AS6UjE,MAAM,CAAC,AS57B5B,OT67Be,CAAG,GACX,GAAA,AADiB,CAAC,iBACA,CTvQD,ASuQI,GACrB,GAD2B,AAC3B,CAD4B,kBAAV,AAA4B,CAAC,KACtB,CTvQH,ASuQM,MAAM,CAAC,gBAClB,CAAG,MAAM,CAAC,CADiC,AAAnC,CAAoC,GS37BpE,OT67BoB,CAAG,CS78BN,kBT88BG,CAAG,GAChB,GADsB,AACtB,CADuB,aACT,AADD,AAAuB,CAAC,AACpB,MAAM,CAAC,MTvQE,QSuQY,AAAxB,AACC,CADwB,AACrB,MAAM,CAAC,eAAV,AAAyB,CAAC,EACtB,CAAG,GACtB,GAD4B,AAC5B,CAD6B,KTvQC,CAAC,YSwQZ,CAD6B,AAA7B,AACG,CAD2B,EAEjD,GAD4B,AAC5B,ATxQwB,CSuQK,ATvQJ,mBSuQuB,AAA7B,CAA8B,AAC5B,CAAG,CTvQH,CAAC,ISuQQ,CAAC,qBAAqB,AAA/B,CAAgC,CAC7B,CAAG,CTvQH,AkBrrB/B,iCT67BmC,CAAG,GAE/B,GAAA,AAFqC,CAAC,KAEtC,CAAS,MAyBX,CAzBkB,CAAC,MAAX,AAAiB,CAAC,EAyBf,CAAG,ETjSa,ESsQyC,AAAtC,CAAuC,CA4BrE,IAAI,CADqB,AAClB,CADmB,KAE1B,IS99Ba,MT89BH,CAAA,GACjB,GAAO,GAAD,EAAM,CAAG,GACf,GAAO,MAAA,CAAS,MAAM,AACf,CADgB,IAChB,CAAQ,GThSD,ESgSM,CAAC,AACd,WAAW,CAAG,GACrB,GAAO,GAAD,EAD0B,CAAC,AACpB,CAAG,ETjSkB,AACpB,CSiSd,GADsB,AACf,CADgB,SACN,CAAG,MACb,IADuB,CAAC,EACjB,CAAG,GACjB,GAAO,CADiB,CAAC,UACN,CThQC,ASgQE,GACtB,GAAO,GAAD,KAAS,CAAG,MACX,EADmB,CAAC,CAChB,CAAG,IAAI,CAAC,CACZ,OAAO,CAAG,MACV,CADiB,CAAC,KACX,CAAG,GACjB,GAAO,GAAD,MAAU,CAAG,CADe,CAAC,CAEnC,GAAO,GADqB,CAAC,IACd,CAAG,GAClB,GAAO,EADmB,CAAC,UACP,CAAG,GACvB,GAAO,KAAK,CAAG,GACf,EADoB,CAAC,AACd,GAAD,OAAW,CAAG,GACpB,GAAO,IADuB,CAAC,CAClB,CAAG,GdjhChB,GcihCsB,CAAC,AdjhCvB,GAAA,EAAA,CAAA,CAAA,OAKK,QAAQ,GAAG,CAAC,cAAc,CAG7B,CAH+B,OAGvB,GAAG,CAAC,2DAFZ,QAAQ,KAAK,CAAC,0EAKX,QAAQ,GAAG,CAAC,cAAc,CAG7B,CAH+B,OAGvB,GAAG,CAAC,2DAFZ,QAAQ,KAAK,CAAC,0EAKhB,IAAM,GAAS,IAAI,AoDgDhB,MACU,AAkBX,WAlBsB,AAkBtB,CAlBsB,AAkBV,CAA2B,CAAA,iBAErC,GAAI,CAAC,EAAQ,KAAD,EAAQ,EAAI,EAAQ,KAAD,GAAC,AAAQ,GAAK,EAAQ,KAAD,CAAO,CACzD,CAD2D,KACrD,AAAI,KAAK,CACb,gFAAgF,CACjF,CAGH,IAAI,CAAC,QAAQ,CACX,OAAA,EAAA,OAAA,EAAA,EAAQ,KAAD,GAAC,AAAQ,EAAA,EAAA,AA4FtB,AA5F0B,EAAJ,IAAA,GA4Fb,AAAc,CAAW,AA5FZ,EA4FY,AA5FZ,CAAiB,IAAjB,CA6FpB,IADoB,AA5FA,CAAA,EA6Fb,AAIP,IAAI,CAAQ,EAAL,GADgB,EAHA,CAGY,CACd,CAJC,AAAQ,AAGK,CACZ,EAJM,AAAI,CAAC,CAAC,AAON,MAAM,GAA5B,EAAI,CAAD,UAAY,EANxB,AAM0B,EApGc,4BAA2B,CAAC,EAAI,EAAA,AACpE,EADoE,CAAA,GAC9D,AAD8D,EAAK,AACvD,AAsGtB,EAvGwE,EAAA,GACrD,EADqD,AAuG/D,EACP,GAxGsE,CAwGhE,AAxGgE,CAClC,CAuGZ,CAvGc,EAuGP,GAAD,EADP,GAAA,EACF,MAA0B,CAAC,CAC1C,EAAkB,GAAO,GAAD,OAAT,MAA0B,CAAC,CAMhD,OALI,GAAmB,GACrB,OAAO,CAAC,CADS,GAAmB,AACxB,CACV,CAFoC,sEAEmC,CACxE,CAEI,GAAmB,QAAmB,CAC/C,GADwB,CA7Gd,EA6GiC,AA7GpB,EA6GiC,CA7G1B,GAAD,EAAT,iBAAgC,CAAC,CAC3C,EAAc,GAAO,GAAD,GAAT,iBAAiC,CAAC,CAEnD,IAAI,CAAC,MAAM,CAAG,OAAA,EAAA,EAAQ,KAAD,CAAC,AAAM,EAAI,EAAA,EAAA,AAChC,IADgC,AAC5B,CAAC,EADoC,CAAT,EAAA,EACpB,CAAG,EADiB,IACjB,CADiB,CACjB,AADiB,CACjB,EAAQ,KAAD,EAAC,AAAO,EAAI,EAAA,EAClC,AADkC,IAC9B,AAD8B,CAC7B,GAD6B,AAAU,EAAV,GACrB,CAAG,CADkB,KAAA,CAClB,AADkB,EAClB,EAAQ,KAAD,GAAS,AAAR,EAAY,EAAA,EAAA,AAGhC,EAAQ,EAHwB,GAGzB,CAHyB,CAAW,CAG3B,AAHgB,EAGd,EAChB,CAJ8B,KAI9B,AAJ8B,CAAA,EAI9B,EAAQ,KAAD,YAAC,AAAiB,EAAA,IAAA,CAAA,CAAA,CAAA,CAAA,CAAE,AAAF,GAAA,EAAA,KAAA,CAAa,AAAX,EAAa,EAE1C,AAF2B,CAAA,MAEpB,CAAC,KAAK,CACX,iEAAiE,GAC/D,+CAEJ,GAFsD,CACrD,AACG,CAAC,MAAM,MAAG,GAGZ,CAAC,GAAc,CAAA,CAAW,AAHL,EAGU,EAAQ,CAA5B,IAA2B,CAAO,EAAE,AAEjD,OAAO,CAAC,KAAK,CACX,+DAA+D,GAC7D,oDAEJ,GAF2D,CAEvD,AADH,CACI,OAAO,MAAG,EACf,IAAI,CAAC,EADmB,MACX,MAAG,GACP,CAAC,EAAQ,GADO,EACR,EAAQ,EAAI,EAAQ,KAAD,GAAC,AAAQ,GAAK,GAElD,MAF2D,CAEpD,CAFsD,AAErD,KAAK,CACX,8DAA8D,GAC5D,2CAEJ,GAFkD,CACjD,AACG,CAAC,MAAM,MAAG,IACJ,GAAc,CAAA,CADD,AACY,EAAK,GAApB,CAEpB,KAFiD,EAAE,AAE5C,CAAC,KAAK,CACX,+DAA+D,GAC7D,2DAEJ,GAFkE,CACjE,AACG,CAAC,MAAM,MAAG,IAIlB,KAJ2B,CAIrB,EAAU,KAAH,IjChFD,CiCgFc,AjChFd,CAAA,CAEe,CAAA,CACW,CtFEiB,CsFDjB,EAAA,sBAEnC,EAAa,E1DsBiE,CAAC,IAAA,A0DtB3D,CAAA,EAAE,qBAGa,YAEA,CAK1C,EiCiEM,EAAQ,GjCxEgD,EiCwEjD,MAAY,CACnB,EAAQ,KAAD,GjCvEyB,AiCuEhB,CAChB,CjGpBgD,ArCjCJ,CqGrBZ,ArGqBa,CqCiCK,AgEpDlB,ArGmBc,AsIqDvC,GAAD,CjCxE0B,AAFA,CAAA,CAEA,C/BeuB,ACQA,C8BzBvB,EAAA,ciC0ED,CAAC,CAChC,GAAO,GAAD,qBAAyB,CAAC,CACjC,CACG,IACE,EAAQ,CADH,EAAE,EACA,MAAY,CACrB,CADuB,CACf,KAAD,MAAY,CAAC,OAAO,CAAG,EAE9B,EAAQ,GAF6B,EAE9B,MAAY,CAAG,CAAC,OAAO,CAAE,CAAO,CAAC,EAI5C,GAJ2C,CAIvC,CAAC,UAAU,CAAG,EAAQ,KAAD,KAAW,CACpC,MAAM,EAAO,EAAH,EAAO,GAAS,CACxB,IADuB,EACjB,CAAE,IAAI,CAAC,MAAM,CACnB,iBAAiB,CAAE,EAAQ,KAAD,YAAkB,AAC7C,CAAA,CAAC,CACF,IAAI,CAAC,SAAS,CAAG,IAAI,GAAU,CAC7B,IAAI,CADwB,AACtB,EACN,EADU,KACH,CAAE,IAAI,CAAC,OAAO,CACrB,QAAQ,CAAE,IAAI,CAAC,QAAQ,CACvB,UAAU,CAAE,IAAI,CAAC,UAAU,CAC3B,MAAM,CAAE,IAAI,CAAC,MAAM,CACnB,QAAQ,CAAE,IAAI,CAAC,QAAQ,CACvB,WAAW,CAAE,EAAQ,KAAD,MAAY,CAChC,cAAc,CA7IU,AA6IR,UA7IkB,CA6IM,OAAO,CAAC,EAAX,KAAkB,CACvD,QAAQ,CAAE,IAAI,GACd,SAD0B,CAChB,CADkB,AAChB,IAAI,EACjB,CAAA,CAAC,CACF,IAAI,CAAC,IAF2B,EAAE,AAEvB,CAAG,IAAI,GAAO,GAAD,CAAK,CAAC,SAAS,CAAC,CACxC,IAAI,CAAC,IAAI,CAAG,IAAI,GAAK,CAAD,GAAK,CAAC,SAAS,CAAE,EAAM,EAAF,EAAM,IAC/C,IAAI,CAAC,OAAO,CAAG,GADoD,CAChD,CADkD,CAAC,CAC3C,IAAD,AAAK,CAAC,SAAS,CAAC,CAC1C,IAAI,CAAC,KAAK,CAAG,IAAI,GAAM,EAAD,EAAK,CAAC,MAAM,CAAE,IAAI,CAAC,SAAS,CAAC,CACnD,IAAI,CAAC,MAAM,CAAG,IAAI,GAAO,GAAD,CAAK,CAAC,SAAS,CAAC,CACxC,IAAI,CAAC,KAAK,CAAG,IAAI,GAAM,EAAD,EAAK,CAAC,SAAS,CAAC,CACtC,IAAI,CAAC,UAAU,CAAG,IAAI,GAAW,IAAI,CAAC,EAAN,OAAe,CAAC,CAChD,IAAI,CAAC,UAAU,CAAG,IAAI,GAAO,GAAD,CAAK,CAAC,SAAS,CAAC,CAC5C,IAAI,CAAC,OAAO,CAAG,IAAI,GAAQ,IAAD,AAAK,CAAC,SAAS,CAAC,CAE7C,EpDlK8B,CAAE,OAAQ,QAAQ,GAAG,CAAC,cAAc,AAAW,GACxE,GAAS,IAAI,GAAO,CAAE,OAAQ,QAAQ,GAAG,CAAC,cAAc,AAAW,GAKzE,eAAe,KACb,IAAM,EAAW,MAAM,CAAA,EAAA,GAAA,WAAA,AAAW,IAClC,GAAI,CAAC,EAAU,MAAM,AAAI,MAAM,iDAC/B,OAAO,CACT,CAKO,IAAM,GAAmB,MAC9B,EACA,EACA,KAEA,QAAQ,GAAG,CAAC,kEAEZ,IAAM,EAAW,MAAM,KAEjB,EACJ,EAAS,mBAAmB,CAC5B,CAAC;OACE,EAAE,EAAM;QACP,EAAE,EAAS;qBACE,EAAE,cAAc;;AAErC,CAAC,CAEC,EAFE,EAAE,IAEI,GAAG,CAAC,CAAC,yBAAyB,EAAE,EAAA,CAAO,EAC/C,QAAQ,GAAG,CAAC,CAAC,2BAA2B,EAAE,EAAA,CAAU,EACpD,QAAQ,GAAG,CAAC,CAAC,mCAAmC,EAAE,EAAA,CAAe,EACjE,QAAQ,GAAG,CAAC,CAAC,+CAAyC,CAAC,CAAE,EAAS,mBAAmB,EAErF,GAAI,CACF,IAAM,EAAW,MAAM,GAAO,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC,CACpD,MAAO,cACP,SAAU,CACR,CACE,KAAM,OACN,QAAS,CACX,EACD,CACD,YAAa,EACf,GAEM,EAAO,EAAS,OAAO,CAAC,EAAE,EAAE,SAAS,SAAW,GAEtD,OADA,QAAQ,GAAG,CAAC,mDACL,EAAK,IAAI,EAClB,CAAE,MAAO,EAAO,CAEd,MADA,QAAQ,KAAK,CAAC,6BAA8B,GAClC,AAAJ,MAAU,kDAClB,CACF,EAKa,GAAsB,MAAO,IACxC,QAAQ,GAAG,CAAC,6DAEZ,IAAM,EAAW,MAAM,KACjB,EACJ,EAAS,sBAAsB,CAC/B,CAAC;;;AAGL,EAAE,YAAY;;AAEd,CAAC,CAEC,EAFE,EAAE,IAEI,GAAG,CAAC,+CAAgD,EAAS,sBAAsB,EAE3F,GAAI,CAMF,IAAI,EAAc,CALD,MAAM,GAAO,MAAM,CAAC,eAAe,CAAC,CACnD,MAAO,EAAS,eAAe,EAAI,mBACnC,SAAU,CAAC,CAAE,MAAO,CAAC,CAAE,KAAM,CAAO,EAAE,AAAC,EAAE,AAC3C,EAAA,EAE2B,IAAI,EAAI,GAKnC,OAJI,EAAY,UAAU,CAAC,aAAY,EAAc,EAAY,KAAK,CAAC,EAAA,EACnE,EAAY,QAAQ,CAAC,SAAQ,EAAc,EAAY,KAAK,CAAC,EAAG,CAAC,EAAA,EAErE,QAAQ,GAAG,CAAC,4DAA6D,EAAY,MAAM,EACpF,EAAY,IAAI,EACzB,CAAE,MAAO,EAAO,CAEd,MADA,QAAQ,KAAK,CAAC,8CAA+C,GACvD,AAAI,MAAM,wCAClB,CACF,EAKa,GAA+B,MAC1C,EACA,KAEA,QAAQ,GAAG,CAAC,uEAEZ,IAAM,EAAW,MAAM,KACjB,EAAS,EAAS,gBAAgB,CAExC,QAAQ,GAAG,CAAC,wDAAyD,EAAS,gBAAgB,EAE9F,GAAI,CACF,IAAM,EAAW,MAAM,GAAO,MAAM,CAAC,eAAe,CAAC,CACnD,MAAO,EAAS,SAAS,EAAI,mBAC7B,SAAU,CAAC,CAAE,MAAO,CAAC,CAAE,KAAM,CAAO,EAAE,AAAC,EAAE,CACzC,OAAQ,CACN,iBAAkB,mBAClB,eAAgB,CACd,KAAM,GAAK,MAAM,CACjB,WAAY,CACV,SAAU,CAAE,KAAM,GAAK,KAAK,CAAE,MAAO,CAAE,KAAM,GAAK,MAAM,AAAC,CAAE,EAC3D,gBAAiB,CAAE,KAAM,GAAK,MAAM,AAAC,CACvC,CACF,CACF,CACF,GAEM,EAAS,KAAK,KAAK,CAAC,EAAS,IAAI,EAEvC,OADA,QAAQ,GAAG,CAAC,iDAAkD,GACvD,CACL,SAAU,EAAO,QAAQ,EAAI,EAAE,CAC/B,gBAAiB,EAAO,eAAe,EAAI,EAC7C,CACF,CAAE,MAAO,EAAO,CAEd,OADA,QAAQ,KAAK,CAAC,6CAA8C,GACrD,CAAE,SAAU,EAAE,CAAE,gBAAiB,0CAA2C,CACrF,CACF,sGxF1JA,IAAA,GAAA,EAAA,CAAA,CAAA,OAMA,GAFA,GAAA,UAAU,CAAC,oBAAoB,EAAG,EAE9B,CAAC,QAAQ,GAAG,CAAC,YAAY,CAC3B,CAD6B,KACvB,AAAI,MAAM,mDAGlB,IAAM,GAAM,CAAA,EAAA,GAAA,IAAA,AAAI,EAAC,QAAQ,GAAG,CAAC,YAAY,EAKnC,GAAmB,AAAD,IAA8B,CACpD,CADmD,EAC/C,OAAO,EAAI,EAAE,EACjB,eAAgB,EAAI,eAAe,CACnC,MAAO,EAAI,KAAK,CAChB,WAAY,EAAI,WAAW,CAC3B,iBAAkB,EAAI,iBAAiB,EAAI,GAC3C,UAAW,EAAI,SAAS,CACxB,SAAU,MAAM,OAAO,CAAC,EAAI,QAAQ,EAChC,EAAI,QAAQ,CACZ,AAAwB,iBAAjB,EAAI,QAAQ,CACnB,EAAI,QAAQ,CAAC,KAAK,CAAC,KAAK,GAAG,CAAC,AAAC,GAAc,EAAE,IAAI,IACjD,EAAE,CACN,gBAAiB,EAAI,gBAAgB,EAAI,GAC3C,CAAC,CAKM,eAAe,KACpB,GAAI,CACF,MAAM,EAAG,CAAC;;;;;;;;;;;IAWV,CAAC,CACD,QAAQ,GAAG,CAAC,qDACd,CAAE,MAAO,EAAO,CAEd,MADA,QAAQ,KAAK,CAAC,6CAA8C,GACtD,AAAI,MAAM,kDAClB,CACF,CAKO,eAAe,GAAY,CAAkC,EAClE,GAAI,CACF,IAAM,EAAS,MAAM,EAAG,CAAC;;;;;QAKrB,EAAE,EAAQ,cAAc,CAAC;QACzB,EAAE,EAAQ,KAAK,CAAC;QAChB,EAAE,EAAQ,UAAU,CAAC;QACrB,EAAE,EAAQ,gBAAgB,EAAI,GAAG;QACjC,EAAE,EAAQ,SAAS,GAAI,EAAM;QAC7B,EAAE,MAAM,OAAO,CAAC,EAAQ,QAAQ,EAAI,EAAQ,QAAQ,CAAG,CAAC,EAAQ,QAAQ,CAAC,CAAC;QAC1E,EAAE,EAAQ,eAAe,EAAI,GAAG;;;IAGpC,CAAC,CAEK,EAAM,MAAM,OAAO,CAAC,GAAU,CAAM,CAAC,EAAE,CAAI,EAEjD,OADA,QAAQ,GAAG,CAAC,CAAC,iCAAiC,EAAE,EAAI,EAAE,CAAC,CAAC,CAAC,EAClD,GAAgB,EACzB,CAAE,MAAO,EAAO,CAEd,MADA,QAAQ,KAAK,CAAC,2BAA4B,GACpC,AAAI,MAAM,4BAClB,CACF,CA6BO,eAAe,GAAe,CAAmB,EACtD,GAAI,CACF,IAAM,EAAS,MAAM,EAAG,CAAC,kCAAkC,EAAE,EAAG,SAAS,CAAC,CACpE,EAAM,MAAM,OAAO,CAAC,GAAU,CAAM,CAAC,EAAE,CAAI,EACjD,GAAI,CAAC,EAAK,OAAO,KAIjB,OAFA,QAAQ,GAAG,CAAC,wBACZ,QAAQ,GAAG,CAAC,GACL,GAAgB,EACzB,CAAE,MAAO,EAAO,CAEd,MADA,QAAQ,KAAK,CAAC,2BAA4B,GACpC,AAAI,MAAM,mCAClB,CACF,CAKO,eAAe,GAAc,CAAU,CAAE,CAA4B,EAC1E,GAAI,CACF,IAAM,EAAO,OAAO,IAAI,CAAC,GACzB,GAAoB,IAAhB,EAAK,MAAM,CAAQ,OAGvB,IAAM,EAAY,EACf,GAAG,CAAC,CAAC,EAAK,IAAM,CAAA,EAAG,EAAI,OAAO,CAAC,WAAY,OAAO,WAAW,GAAG,IAAI,EAAE,EAAI,EAAA,CAAG,EAC7E,IAAI,CAAC,MACF,EAAS,OAAO,MAAM,CAAC,GAEvB,EAAQ,CAAC;;UAET,EAAE,UAAU;kBACJ,EAAE,EAAK,MAAM,CAAG,EAAE;IAChC,CAAC,AAED,OAAM,GAAI,EAAO,IAAI,EAAQ,EAAG,EAChC,QAAQ,GAAG,CAAC,CAAC,UAAU,EAAE,EAAG,aAAa,EAAE,EAAK,IAAI,CAAC,MAAM,CAAC,CAAC,CAC/D,CAAE,MAAO,EAAO,CAEd,MADA,QAAQ,KAAK,CAAC,8BAA+B,GACvC,AAAI,MAAM,+BAClB,CACF,CAiCO,eAAe,KACpB,GAAI,CACF,IAAM,EAAS,MAAM,EAAG,CAAC,qDAAqD,CAAC,CAE/E,MAAO,CADM,MAAM,OAAO,CAAC,GAAU,EAAU,EAAS,CAAC,EAAO,CAAG,EAAE,AAAF,EACvD,GAAG,CAAC,GAClB,CAAE,MAAO,EAAO,CAEd,MADA,QAAQ,KAAK,CAAC,4BAA6B,GACrC,AAAI,MAAM,8BAClB,CACF,CuFxLO,eAAe,GACpB,CAAa,CACb,CAAgB,CAChB,CAAqB,EAErB,GAAI,CAEF,IAAM,EAAa,MAAM,GAA+B,EAAO,EAAU,GAGnE,EAAmB,MAAM,GAAkC,GAG3D,UAAE,CAAQ,CAAE,iBAAe,CAAE,CAAG,MAAM,GAA2C,EAAY,GAG7F,EAA2C,CAC/C,MAAO,aACP,EACA,mBACA,eAAgB,IAAI,OAAO,WAAW,GACtC,UAAW,YACX,kBACA,CACF,EAEM,EAAe,MAAM,GAAsB,GAKjD,MAFA,CAAA,EAAA,GAAA,cAAA,AAAc,EAAC,sBAER,CAAE,GAAG,CAAY,CAAE,WAAW,CAAK,CAC5C,CAAE,MAAO,EAAO,CAEd,MADA,QAAQ,KAAK,CAAC,0CAA2C,GACnD,AAAI,MAAM,CAAC,kCAAkC,EAAE,aAAiB,MAAQ,EAAM,OAAO,CAAG,OAAO,GAAA,CAAQ,CAC/G,CACF,CAOO,eAAe,GAAiB,CAMtC,EACC,GAAI,CACF,IAAM,EAA2C,CAC/C,MAAO,EAAK,KAAK,CACjB,WAAY,EAAK,OAAO,CACxB,iBAAkB,GAClB,eAAgB,IAAI,OAAO,WAAW,GACtC,WAAW,EACX,SAAU,CAAC,GAAG,CACd,gBAAiB,EACnB,EAEM,EAAQ,MAAM,GAAsB,GAG1C,OAFA,QAAQ,GAAG,CAAC,CAAC,yBAAyB,EAAE,EAAM,EAAE,CAAA,CAAE,EAClD,CAAA,EAAA,GAAA,cAAA,AAAc,EAAC,sBACR,CACT,CAAE,MAAO,EAAO,CAEd,MADA,QAAQ,KAAK,CAAC,6BAA8B,GACtC,AAAI,MAAM,4BAClB,CACF,CAGO,eAAe,GAAe,CAAU,EAC7C,GAAI,CAEF,OADgB,AACT,MADe,GAAyB,EAEjD,CAAE,MAAO,EAAO,CAEd,OADA,QAAQ,KAAK,CAAC,2BAA4B,GACnC,IACT,CACF,CAGO,eAAe,GAAkB,CAAU,CAAE,CAAwB,EAC1E,GAAI,CACF,MAAM,GAAwB,EAAI,kBAAE,CAAiB,GACrD,QAAQ,GAAG,CAAC,CAAC,6CAA6C,EAAE,EAAA,CAAI,EAChE,CAAA,EAAA,GAAA,cAAc,AAAd,EAAe,qBACjB,CAAE,MAAO,EAAO,CAEd,MADA,QAAQ,KAAK,CAAC,4BAA6B,GACrC,AAAI,MAAM,uCAClB,CACF,CAIO,eAAe,GACpB,CAAU,CACV,CAA+E,EAE/E,GAAI,KAEE,EAGF,EADE,MAAM,OAAO,CAAC,EAAK,QAAQ,EAClB,CADqB,CAChB,QAAQ,CACf,AAAyB,UAAU,OAA5B,EAAK,QAAQ,CAClB,EAAK,QAAQ,CAAC,KAAK,CAAC,KAAK,GAAG,CAAC,AAAC,GAAM,EAAE,IAAI,IAE1C,EAAE,CAGf,IAAM,EAAkB,EAAK,eAAe,EAAI,EAEhD,OAAM,GAAwB,EAAI,UAChC,kBACA,EACA,WAAW,EACX,eAAgB,IAAI,OAAO,WAAW,EACxC,GAEA,QAAQ,GAAG,CAAC,CAAC,2BAA2B,EAAE,EAAG,uBAAuB,CAAC,EACrE,CAAA,EAAA,GAAA,cAAA,AAAc,EAAC,qBACjB,CAAE,MAAO,EAAY,CAEnB,MADA,QAAQ,KAAK,CAAC,2BAA4B,GACpC,AAAI,MACR,GAAO,SAAW,gDAEtB,CACF,CAOO,eAAe,KACpB,GAAI,CAGF,OAFA,AAEO,MAFD,KACW,MAAM,IAEzB,CAAE,CAHiC,KAG1B,EAAO,CAEd,OADA,EAJkD,MAI1C,KAAK,CAAC,+BAAgC,GACvC,EAAE,AACX,CACF,0CAjJsB,GA2CA,GA6BA,GAWA,GAaA,GAwCA,KAxIA,CAAA,EAAA,GAAA,uBAAA,EAAA,GAAA,6CAAA,MA2CA,CAAA,EAAA,GAAA,uBAAA,EAAA,GAAA,6CAAA,MA6BA,CAAA,EAAA,GAAA,uBAAA,EAAA,GAAA,6CAAA,MAWA,CAAA,EAAA,GAAA,uBAAA,EAAA,GAAA,6CAAA,MAaA,CAAA,EAAA,GAAA,uBAAA,EAAA,GAAA,6CAAA,MAwCA,CAAA,EAAA,GAAA,uBAAA,EAAA,GAAA,6CAAA","ignoreList":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195]}